Summarizing: [
  "ï»¿1 Hello, this is Darren Pulsipher, chief solution, architect of public sector at Intel. And welcome to Embracing Digital Transformation, where we investigate effective change, leveraging people process and technology. He and Mike, welcome to the show. Thank you. Good to be here. Hey, Ian, you're the CTO of Metify. Let's hear first from you. Give me a little bit about your background and how you got started. Sure. So I have actually worked in the data center space for a very long time. I've probably been in it since 1999, and through that I've worked in different roles anywhere from engineering roles up through systems architecture. And yeah, it's just I've focused on all the different domains, storage, network data center facilities. And one of the things that I've learned over the years is how to optimize some of that infrastructure. And we're really going to talk to you about today is what we've created, you know, something that really gets down into the data center, deep into the data center, and allows you to automate different aspects of it from servers to storage up through network devices and so forth. Hey, before we get started there, though, Mike, tell us a little bit about your background and then why you hooked up with Ian here to start Modify? Yeah, sounds great. So I started with IBM many, many moons ago and I was a network engineer and from there I actually stayed with IBM for quite some time and shifted into direct sales. So working a lot with Enterprise is and getting a look inside their data centers, understanding the problems that they face. Consultative selling, of course, trying to understand the patterns and what it takes to run and operate a data center and do the things that you need to do to keep the company going and then to eventually use it as a competitive edge. So that led me to going to Red Hat, and I spent several years at Red Hat as well, and Red Hat introduced me to the channel side, which was really, really cool. So I went from direct sales into really channel led sales exclusively. And like I said, that was really aperture opening for me and a fantastic experience. It was through that that I actually met Ian. He was with one of our top business partners, a very large multibillion dollar organization, and that led directly to solution development and the launching of Modify three years ago. So that's what got me here. Well, three years ago. So you guys have known each other for how long? Five, six, six years now? Yeah, Five and six years. Yeah. Yeah, that's. That's awesome. Yeah. And you're still talking to each other? Yeah. Okay. I've been in startups before. I've done three startups, and. Yeah, I don't talk to any of those founders. Oh, wow. Yeah, that's. That's a show on to its own. I look forward to having our little help. Yeah, that'll be an interesting show. We'll have to do that one of these days, you know? So what led you guys What led you guys to create modify? You talked about optimizing the data center. So there's a big elephant in the room, and it's called RWC Azure and GCP. Yeah. So if if I'm going to be the devil's advocate here, I'm going to say, why in the world do I need to automate my own data center? Data centers are dead, but hey, WC comes and tells me that all the time. Yeah. Yeah. Well, I think it, I think there's there's a lot to that the automation piece of it is really around all the components in the data center is really be the big one right now as it stands, you have all these different problems you have to deal with within the data center, you know, different, you know, with Supermicro, Dell, HP, I mean, you go down the list, right? There's just a ton of different servers, a lot of different products, and each one kind of has its own specific managed management toolset associated with it. And while there's a state, there's open standards coming together like redfish, you know, where you can issue one specific command that will do something on all the servers. That's great, but you still have to fall back to all those tools, you know, to manage full lifecycle those servers, right? So I think for for us and where I really view it is if you're going to talk about the data center and you're going to build a successful infrastructure footprint that's fully automated, you need to be able to take a lot of those tools ",
  "and bring them together, which then brings you closer to an experience that you would see on the public cloud. There's less emphasis on the underlying infrastructure, less focus on the individual pieces for your, you know, anywhere from a firm update you have to do on a server, which is time consuming. Sometimes that's still very much a manual process. All of that really needs to be wrapped into what I consider a single stream of automation. And then there needs to be something that effectively, you know, kind of almost establish like a single pane of glass server over that entire thing. So, so so you're cutting out because a lot of the complaints that people have on why they want to move to the cloud is speed. Yeah. And OpEx cost, right? I can't find the right people. They cost too much, too much variability in my data center. And you guys have kind of come in and said, hey, let's automate as much of that as we possibly can. We can run it more efficiently and so you can compute your own data center can compete with the cloud service providers on OpEx cost for sure. On OpEx cost, right? Yeah, Yeah. Your overall costs could actually be cheaper in a data center using a tool like what you guys have. Is that right? Exactly. And that's that's a really important point because there's an absolute break even point. What I what we loved about the space in particular getting getting very low was, first of all, it wasn't possible to do what we're doing six or seven years ago. Right. I mean, because open standards and the promise of open standards just became real. Essentially in the last five years. The DMCA came out with the red redfish specification. The red Cross specification. Ian bet on it early. He saw the potential for it, wrote a thesis. As soon as he showed it to me, I was like, Holy moly, you're right, this is beautiful. We can do something with this. And, and we just started working from that point and with the ubiquity of the red four specification now across all the motherboard manufacturers, all the motherboards that are going out at the enterprise class have the VMC built into the board that adhere to the retro specification. All the players just got in line with it. Okay. So and this is why do you think why do you think that is, though, that they've finally got in line? Because the redfish spec has been out for a long time. Yeah. Five years. Six years now, yeah. So it just took off. So, you know, I think that it was led by the industry because so HP and Dell are on the board of the MTF and the guys there. So they had big champions to begin with. They recognized that there was a need to have this low level compatibility across multiple different hardware profiles to allow for other tools to come in and do what they need to do and integrate with the products in ways that they couldn't do if it was strictly proprietary. So and they also saw ahead a bit on the white box side, right? Because the white box guys are coming in providing this low level availability without all the expensive proprietary tools necessarily. So you don't want to get priced out of a game. And so there was, you know, financial pressures as well as open standards, pressures from the users to allow them to do these things, self-service outside of, you know, expensive proprietary tools to always have to purchase and maintain in order to run these servers that they've already purchased. Right. So lots of different, you know, pressures happening to make it all come together. Yeah, that's absolutely correct. And I think I'll add a couple of things to it. One is, you know, there are good restful standard was still very much absent. I mean, you use tools like PMI that was very common. Problem with PMI is that, you know, you have security concerns with it. You know, when you start to deal with things like the DMG redfish standard, you're actually full rest with that. So, you know, you're communicating a secure manner. And once people start to see that there was actually a serious specification that had a consortium backing it, like Mike mentioned, all the major OEMs are on board. You know, I think they started to take it much more seriously in terms of implementation and what they could do with it. And after they saw the capabilities and how extensible it was being, it was, oh, data compliant and there's all these things that really enhance the overall capability of server management that really helped kind of seal the standard. I think it was just a matter of seeing some of the big guys go in on it and then a lot of the other ones started to follow. And now you see it as, you know, kind of the common standard. Do you think there's some pressure on the OEMs to do this as well to to help improve ",
  "data center efficiency On the optics side, yeah. So they can compete against cloud service providers because. Yes. Yes. Right. I mean, I mean, ultimately that's their biggest competition is IWC as well, as I mentioned. What they ultimately what it comes down to is everybody has their own tools. You know, a lot of people have their own automation frameworks, right? They want to be able to use those tools. They want to be able to integrate those with the standard. So I think that, you know, it really helped quite a lot. So, you know, that's what might go ahead. I would just want to know for sure. I mean, you know, the pressures and the and the commoditization, right? The technology commoditization curve gets everybody eventually. So the hardware providers have been facing this for some time. So what do you do to differentiate? Well, sometimes it's join the herd and make sure that you are that you have similar offerings, in this case, more of a scaled down white box server that across the board. Now HP, Dell Supermicro kind of was the original heavy in the space, right? Well, they're trying to take on the inspiration the quant is they want to make sure they're not giving the market weight to the hyperscale. And especially at the tier two level, there's a number of opportunities with large enterprises that want some of the resilient resiliency features in Dell servers, the fantastic servers, but they also want to be able to automate and do the things that they the way they like doing them at a very at a low level. So what our tool allows them to do is for the first time have a single pane of glass that can heterogeneous sleep provide lights out management across any manufacturer and that's not just so server storage, networking and really any device that's BMC enabled and adheres to the red specification. So we've done some really cool stuff on the edge as well, which is you're going to ask about about the edge because that's a huge concern that a lot of my customers and my listeners have is how do I manage the edge? Because it's highly heterogeneous, its connectivity is questionable. Yeah, right. Yeah. And but I still want to be able to push patches out like firmware patches or BIOS patches out. Yeah. And do that in an effective way. So you guys provide kind of a common common management plane that is long as you said it was only BMC and redfish. If I can I can take a look at everything then Yeah yeah, yeah we do. And we even took it farther during COVID in, in Ian's neighborhood, there were some teachers that were having trouble connecting to the Internet and they because they had these new well, they had broadband issues, right? So they're real broadband users. He lives in the Blue Ridge Mountains, beautiful granite range. Not exactly easy to get a signal through there. Dense forest as well, densely forested. So, you know, we saw an opportunity to help out the local community did that. And, you know, we built another product that works really well with Mojo platform and that's called Photon as photon router. And it's a it's a it's a proprietary I mean, I should say it's a it's a very unique built in has got a lot of skill in this area. He was a distinguished engineer at Verizon prior to joining by prior to launching Modify and a lot of a lot of skill and expertise in the space. And what he created was a rather amazing router that could do a hell of a lot with less from a bandwidth perspective. So taking that, you know, sort of next step from core edge and then into the customer premise is where we've taken it all the way, so to speak, and it's all provisioned and maintained by module platform. So so that's interesting because you brought up network. Yeah. And do you do network routers, Do they talk redfish as well. Can I. Well at that lower level, yeah. So it's really interesting if you look at you know like in the stand up space, you look at some of the white box, which is, you know, there is emerging standards to manage small devices through redfish because at the end of the day, a lot of those are, you know, x86 64 boxes are, you know, they Yeah, yeah, yeah. We hope they're using. Yeah, exactly right. They are. So with that, there's really no reason why there can't be a VMC in there. Expose some of that functionality. The question is, is how far does the extensibility get down to the networking specific, you know, you know, stack parts of the stack and you know, you see Yang to redfish, you know where you can do things with with Yang in that top. And that certainly lends itself to that. But you're also starting to see more native capabilities rolled in. So it's our hope, you know, as the redfish standard does continue to emerge in networking devices, ",
  "we start to see more coverage for what we consider just white box type of switches. Yeah, So so I'm still wrap my head around this whole thing. Yeah. Most organize Asians that I work with now they have what I call a multi hybrid cloud strategy. Yes. Where I have data center, I have edge, I have cloud. Yes. You guys don't work in the cloud, right? Because the cloud doesn't let you guys manage their hardware, right? That's right. That would be a bad thing, right? Oh, yeah. I'm going to I'm going to knock every one off. There's one server so I could take control of it. But you guys can provide a a much a much more cloud like experience from the operations side of things like my sysadmins. Yeah, I can now go to one place and manage my edge, my data center or multiple data centers, you know. Yeah. All through all through a common API, right. Yeah. That's great because you mentioned the API and that's really the key is that we, we, we make the product extensible in that way that the API is exposed. So if there is a set of automations as an example, that do certain things in the public cloud and there's some elasticity or there's requirements, it needs to reach back into the hybrid cloud or private data center. You know, we're working basically customers are working both those APIs. And so those two systems are kind of working in tandem with each other to do certain things. So we see as long as we manage the API, we have the API exposed. You know, the customer can do certain things within that hybrid environment that certainly pertain to the private data center in in tandem with their public cloud deployments of because of that API. Does that mean you guys have integrations into management tools that people are already used to? Yeah. So it's a very common use case where we kind of the way we look at our the way we look at the APIs, we want to keep that as open and as standardized as possible. So if customers want to be able to take, you know, they have TerraForm, they have Ansible, whatever they're using, right? Yeah, they can essentially use our API like they would any other API, and they can build their own specific automation framework that works with a bunch of different things that Mojo might not even manage. So, you know, that's that's been a huge focus for us, is keeping that as accessible and open as we possibly can to facilitate exactly what you mentioned. All right, cool. Mike, I know you're etching your kitchen. Yeah. There to say something so well, so the hybrid experience, I mean, it is all hybrid. So when we talk about you mentioned earlier, one of the first questions was public cloud growth. Everyone saying the data centers dead mean. The fact is the growth in data centers in North America last year, Okay. A good percentage of that was hyperscalers. But there is also a massive growth in the private cloud space. So and this is this is an area that we we've always seen and it's been very consistent across the years. Yes. The public cloud is growing, the hyperscalers are growing faster, but the growth of the enterprises is continuing. It's not shrinking. It's growing. So there is a moment when companies recognize that their public cloud instantiation is that's a big bill. There's a there is a specific price related to that ease of use and functionality, as well as being able to turn things on and off. So there's a breakpoint. And from a OpEx perspective, it's becomes much more efficient and palatable for a CFO to say, let's buy the equipment or write it off and we know that we can use this well enough to do all the things that we needed to do. Okay. Yeah. And you can watch that. You can watch that from a price perspective, you know, save millions and millions of dollars a year which which there's, you know, very public examples of like Dropbox was a big one a couple of years ago. And this idea of cloud repatriation is only picking up steam because you know the Yeah, you guys well, speaking of, you know, I was a grandmother who just passed You're the founder of. Yeah Gordon Gordon Moore passed last Friday. Yeah. So I mean he's been banging on about, you know, Moore's Law and you keep making better and better processors. You can do more with less and less. So what you can do now and Ian loves talking about this, what you can do on a single rack now used to be a couple rows, right? So the ability to bring in what you need to run the compute that you need is often ",
  "much more efficient than spinning up and dropping multiple cycles. And you get that, you know, shadow it thing under control as well. So there's a number of reasons from security to governance to to cost that really drive this. Yeah. And, and to that point that Mike just made on the governance that we see that is, you know, you can create whatever bare metal tools you want and you can have as much extensibility and as many systems support whatever you need. If you don't have a good framework of governance and policy and security controls that are built around that, where basically the platform becomes the custodian of the hardware and you're you're controlling things like what moves from staging to production, you know, what can be overwritten, who can do that, who can place a specific workload on those machines, who can place firmware, but they can't do specific other things in the system. These are all things that are critically important from the CXOs ise or, you know, somebody that is very much interested in the security posture of their data center. And since BMC is notoriously have a history of, you know, security vulnerabilities and things like that, yeah, I was going to say, yeah, that was level of oversight on that. So we see that as critically important has to be there. And that's where a huge focus on our products has been for, for controlling the datacenter. Yeah. All right. So this I'm glad you brought this up because this is an issue any time you have an open standard, right. If security wasn't thought about upfront and like you said with BMC, yeah, I don't really know who's logged in. I don't know who's made those changes. Right. So you guys have put command and control together in in your platform so I can have an auditability trail. Yeah, I know who has access to what sets of machines or individual machines, whatever the case may be. Is that is that of Tuesday. That it is. Yeah. We've that in fact that was one of the areas we put a very specific level of focus on very early in the product is that we had to have that. And the Audibility trail, like you mentioned, be able to see what's happened over a period of time, who did what. You know, somebody breaks a couple servers mistakenly. Well, this person or this one never done that. Yeah right right so we yeah And then we also, you know on top of that we also see importance around verification and validation, checking for for specific things that are done to infrastructure. So you don't have things like cascading failure. If something fails, you should have some logic in there. It stops it from doing that again. So there's a lot of different things we see in that governance model. But yeah, that's, that's really okay. So, so I can really see some real value here where before I'm like, okay, well you put a, an interface in there, blah blah, blah, blah blah, everyone's got this. But you guys are actually treating this like a first class prop from. Right? A first class up operations thing. And you've exposed the dirty little secret that everyone has in data centers. And Right. Which is a handful of people hold the keys to all the kingdom. Right? Yeah, right. They really do. The sysadmin undoing patch updates. I'm doing all I have complete control and access of of that machine. Right. And you know, no one's watching me, right. Yeah. And it is you're right. That is a huge issue. It's been a longstanding issue and we addressed that and we yeah we offer a level controls that not only prevent you know some some of these less desirable things from happening, but also that know the auditing pieces of it and everything else that are critically important. So that's that's pretty cool. Have you integrated with any any workflow management or tools that already exist out there or you provide, you know, those types of workflows where I can actually do some automation workflows. Is that part of your tool or do you rely on a tool above you to do that part? We do. We've got so we've what we've done is there's a couple of things that we focus on there. We mentioned one, I mentioned the API so we can bring your own tools. You know, we're very friendly towards that. We see that as very important. The other one is we do have workflows and automation built into the product, so customers that do have a very specific requirement, let's say they have 1000 servers across three different ACS and they want to make sure that they're ",
  "only provisioned on systems that have this Xeon Gold 6244 processor with two Optane drives. And I'm talking up Intel here. That's right. About some persistent memory in their existing memory or some of our new Flex GPUs, Right? Yeah, but you can, you can put those constraints based profiles in there and then you can mobilize a service catalog item against that. So as an example, if they want to deploy OpenShift, you know, they can do that. They can put those constraints in there. Those systems are then presented as the systems that would then be part of that automated workflow based on those specific constraints. Yeah, that's pretty cool because I could span multiple OEM vendors. Yes. Yeah. In that's in that, which is super cool. What you just mentioned. That's it. That, that is, that is really the important thing for customers. They, they don't want to be focused on all of these different OEMs all over the place and they would really like to to focus more on, you know, the capability of the systems, what it provides, you know, not having to get into the proprietary tool required to create the pool of, you know, hardware specific items that they need for a runtime, for a workload, for an OpenShift cluster, for an Anthos cluster, for a rancher cluster, for a Tansey cluster, where we work with all of them or partners with all those organizations. You guys have Major League Baseball. And what we did for them specifically is was an edge based bare metal is going to say probably edge, right? Yeah, absolutely. So I mean that that build was a lot of fun for us. And you know it's they're amazing customer. And what's cool about Major League Baseball is they have this advanced media group that they publish in a technical blog I think weekly things that they're doing from a technical perspective, this is a really advanced group. They're actually their own consulting outside Major League Baseball purchase. I'm assuming they must have been building them and you know, a lot. And they said, You know what, we just need to hire. You guys are going to hire you guys. Yeah, well, and you know, when you think about it, Major League Baseball was the they were the first ones that really got into this big data importance of having as much information that's right. Yeah. I mean, think about it. Moneyball, right? I mean, you know, the true data nuts that knew every possible detail about, you know, what a guy batted under duress, how he batted on Monday, Wednesday, Friday, where did he sleep last exactly? In a hotel. It's all correlated. Well, I'm Tonya. Did he sleep at home? Was it a Holiday Inn Express? There we go. We had a better, better day. There's data. There's data on it. So, I mean, so. But but what were you guys helping Major League Baseball with? I mean. Right. You said Edge. Is this in the stadiums? Is it? I mean, yeah. So what? Yeah, yeah. So exactly that. So this is this is a perfect example of hybrid. Okay. So and this is Google was our partner as well. And the solution itself was every ballpark had to be refreshed with new hardware and there's because they are that's a high value target. Major League Baseball, you know, from a security perspective, they had to make sure that everything was updated and all their security features were enabled. So we provided an important layer to make that happen across any hardware profile for them. So specifically the build, I don't know if we can share, but it was so we'll just say that the builds. Yeah, the builds were I believe it's five servers per ballpark across North America and we now we're working with the minor league parks as well. So that's expanded from the first year we're in our I think our third year now with Major League Baseball. I mean they started early with us. So, so with with Major League Baseball then. Yeah, if I have like five servers in each stadium for example. Yeah, I can, I can sit at headquarters. I don't even know where headquarters is. Yeah, it's, well so and I know so Kevin Beckman is the he's their senior principal. He's their senior architect who really spearheaded the bare metal project. And so he can sit in one place and manage all these stadiums. Yeah, the idea. Yeah, that is super cool. Isn't that cool? Yeah. So they save money on, you know, travel expenses and flying around to, you know, have to do the thumb drive, low level reboots to get an OS upgraded or a firmware upgrade at the specific firmware. So yeah, there's just a ton of advantages to being able to remotely control low level infrastructure like that. ",
  "So it's interesting because a lot of times when we talk about private cloud, we always talk about the software defined infrastructure layer as virtualizing everything and you guys don't do any virtualization at all. We do software defined infrastructure. Yep, Yes, for bare metal, which to me is even more interesting. It is because I can do a mix match of some bare metal, some VMs. Yes. Some containers. Yes. And you guys, you guys can manage the underlying infrastructure. That's right. More effectively. Exactly. Yeah. Yeah, yeah. That's very cool. I mean, yeah. So absolutely. And you know, we, we, we love VMware, we work very well with VMware. We, we just also have we work well with everybody. I mean, just like you and Intel, we work at the chip level and you know, when you're as low level as us, we get along with everybody because frankly, we just want to make it really easy for you to access the chips and do what you need to do at that low level to provide, you know, the pooling and automation to take away the manual overhead that's required with a lot of this. And once we once we get that solid, once we get that sort of cloud like experience to be truly frictionless, so you are able to discover provisioned hundreds, thousands of nodes from a single location either in a data center or through hybrid and into cloud, which is the cool part about what Major League Baseball does. And they publish this, like I mentioned Kevin back when he published on in Medium. I have you familiar with the Yeah yeah yeah yeah medium as well as their Major League Baseball blog A really great article about how they did it bare metal to all the stadiums, you know And he put some nice diagrams with Mojo platform right at the right at the top of of and so yeah so so so this is this is really interesting yeah because I can see you guys is helping actually one big push that we have at Intel is what we call heterogeneous compute. Yeah. The CPU is a great general purpose machine. It's been around for 5060 years now. Yeah, amazing. It is. But we're starting to see different types of processors starting to emerge like visual processing units, neuromorphic processing, unit chip use, all these things. You guys could easily let me manage this heterogeneous compute environment. Yep, I'm down at the chip level, which is actually pretty cool. Yeah, that's and, and what exposes more. Yeah. And what's exciting about that, what you just mentioned is that, you know, with redfish it's great because it's an extension of the schema at that point, you know, so. Right. Yeah. You need, you need some additional functionality. There's there's standards board that reviews it. They go through the process of extending that and then next thing you know, you have some control there that you you have and as long as the the lifecycle on the VMs the in the firmware supports that functionality you know you can certainly go in and control those new devices. So we look forward with the expanding ecosystem where it goes into, you know, the rack feed you, it goes into server storage. I mean, swordfish is another standard that we didn't really talk about, but, you know, that's that's very much centric to obviously storage stuff. So, yeah, we're following all that stuff very closely and we see all those extensions is incredibly valuable as we move through the development of the product. Yeah, that's one of the best parts about community driven innovation in general. Coming from RedHat and seeing the power of open source. I mean, to have that open source community really driving the R&D, owning the R&D budget for us and, you know, this broad community saying, okay, we absolutely know we need to add this into the red for specification. In the case of data centers, you know, they're looking at power cooling all the way back to the plug. Right. And you know, those are we have a we have a a green data center solution that we're working with some crypto companies on. And it's just the way efficiencies are going to be driven today and in the very near future. It's just in its infancy, but it's all really being enabled through open standards so everyone can, you know, figure out how to work these things together, control them in ways that are AI driven, frankly. Right. So you are powering up workloads at specific times, powering down? Yeah. I was going to say, depending on the bitcoin price, I may throttle back my power. There you go. Which is what? Which is what they do, right. So sure they do. Yeah. No, if prices aren't right, the mining the miners will just shut them off. But there's, there's ways of having that be automated is, is actually pretty cool. ",
  "Yeah. Or depending on price of is it a cloudy day or not. Do I have solar panels or I mean there's a lot of really cool things that you guys can actually help enable. Yeah. And right right on that point, Darren, is the chat tea revolution, right? So don't get me started on that, right? Yeah. I don't know if you guys know this. If you haven't, you should go. Listen, I interviewed Chad GPT on this podcast. Wow. Okay. I did not hear that yet. I can't wait. No, no, you got to go. Listen. Yeah, that's hilarious. Oh, I mean, so. Yeah. And I work with Chad. Yep. Quite a bit as an augment. As an augment or to the work that I do. Very cool. Yeah. Great stuff. And when you look at what they're doing and the specialization that's involved in the workloads, right, the compute intensive specialization that Chatbot requires, Right. With these new chips and the new frameworks that are being built around it. So this is just center of the bull's eye for us, right? So we're I don't know how much we can talk about it right now. Well, we're we're we're looking at a hosted offering, frankly, in this space to provide specialized bare metal workload optimization across this specifically for chatbot type startups that are looking to quickly scale that super cool their infrastructure. Right. So I mean, and these are the things these are the barriers of entry. Right. There could be some great ideas that are out there from a chat, CBT or other, you know, GPU heavy or one of these new chip heavy workload perspectives that we can quickly get up and running. And it's very easy for us to spin up any of these workloads because again, we operate at the chip level and whatever the peripherals are that need to be added into the box to make it optimized to run specific workloads, we can easily do that. So it's something that we're we're kicking around and we certainly see potential for. And given and given this this very interesting moment with chat CBT and the potential for it, not to mention the investment in this space, there's just going to be a need for infrastructure, specialized infrastructure that we are confident we we know how to deliver well in possibly excuse me, possibly specialized infrastructure that spread across the edge. That's right. That's right. Because I don't necessarily want to move all that data right from the edge back into a data center. And in some cases where I'm starting to see some really cool data architectures where there is no center, there is no yeah, data center. It's federated across an edge, yet no one's in control in that in that per box power. Now you know what you can put in one for how many cores you can in one processor you know, and just that piece of new PCI advancements, you know, all these things and VMware, it just it's amazing what you can put in to a small box. So yes, we that point in there and we totally recognize that and that's absolutely true. Yeah. So hey guys, this has been wonderful. Any last words for our listeners today? Anything you want to share? Oh, boy. No, I think we seem to cover quite a few bases there, no pun intended. So if they want to find out more, it's metaphorical. I o correct. You mean t if y dot io a to find out more about your company and the products that you offer. Right. That's it. Yeah. All right, cool. Thanks. Thanks, guys, for coming on today. Thank you, Daryn, very much. Daryn. Thank you for listening to Embracing Digital Transformation today. If you enjoyed our podcast, give it five stars on your favorite podcasting site or YouTube channel. You can find out more information about embracing digital transformation and embracingdigital,org. Until next time, go out and do something wonderful. "
]
In this podcast, Darren Pulsipher, Chief Solution Architect of Public Sector at Intel, hosts Mike and Ian, the CTO and co-founder of Modify, respectively. With over two decades of experience in the data center space, Ian shares his insights on optimizing infrastructure, automating server management, and streamlining different components in a data center. On the other hand, Mike, who previously worked with IBM and Red Hat, focuses on consultative selling and channeled-led sales to better understand the problems and patterns of enterprises in operating their data centers. Together, they created Modify three years ago to provide automation solutions for managing servers, storage, and network devices in data centers, despite the rise of public cloud services like RWC Azure and GCP.
In this podcast, the speakers discuss how automating data center management can bring it closer to a cloud experience while reducing costs. They emphasize the importance of standardization and open standards like the DMCA redfish specification in making this automation possible. The ubiquity of this specification across enterprise-class motherboards has made it accessible for all players to integrate with it. The speakers also note that financial pressures and user demand played a role in pushing OEMs towards implementing these open standards. Overall, they believe that automation and standardization can help data centers compete with cloud service providers on OpEx cost while improving server management capabilities.
In this podcast episode, the hosts discussed how data center efficiency can be improved by using tools that allow automation and integration with standard frameworks. The hardware providers face pressure due to technology commoditization, so they need to differentiate themselves by offering similar scaled-down white box servers. The tool provided by the guest allowed for a single pane of glass that can manage any manufacturer's devices as long as they are BMC enabled and adhere to the redfish specification. They even created a unique router called Photon that could do a lot with less bandwidth perspective. While there are emerging standards to manage small devices through redfish, the question remains about how far the extensibility gets down to the networking specific parts of the stack.
In this podcast episode, the hosts discussed the rise of hybrid cloud strategies and how companies are managing their data centers, edge, and cloud environments. They noted that while public cloud growth is significant, there is also a massive growth in private cloud spaces. The guests explained that their product offerings provide a more cloud-like experience from an operations standpoint, allowing sysadmins to manage their edge, data center, or multiple data centers all through a common API. They emphasized the importance of keeping their APIs open and standardized to allow customers to use familiar management tools like TerraForm and Ansible. Overall, the conversation highlighted the benefits of hybrid cloud approaches for companies looking to optimize costs and efficiency.
In the podcast, the speakers discussed the importance of governance, security, and cost control in data centers. They highlighted how an open standard can be vulnerable to security breaches without proper command and control measures in place. The platform should have auditability and verifiability features to prevent unwanted changes in the system. The speakers emphasized that their product focused on providing a level of controls to prevent undesirable incidents, and they integrated with workflow management tools for automation. They also discussed the importance of a good governance framework and policy to ensure that the platform becomes the custodian of the hardware. Overall, the speakers stressed the significance of having a comprehensive approach to data center management for better efficiency, security, and cost-effectiveness.
In this podcast, the hosts discussed Intel's new provision of persistent memory in their existing memory and Flex GPUs. These are only available on systems that have an Xeon Gold 6244 processor with two Optane drives. Customers can put constraints-based profiles in place and then mobilize a service catalog item against them. This allows for automated workflows based on specific constraints and can span multiple OEM vendors. The hosts provided an example of Major League Baseball, who hired them to refresh hardware at every ballpark in North America with five servers per stadium. This allowed for remote management of all stadiums from one location and saved money on travel expenses.
In this podcast episode, the hosts discussed a unique approach to private cloud infrastructure that doesn't rely on virtualization. Instead, they use software-defined infrastructure for bare metal, allowing for a mix of bare metal, VMs, and containers. This approach enables them to manage the underlying infrastructure more effectively and provide a frictionless cloud-like experience. They also discussed how their approach can support heterogeneous compute environments, which is a big push at Intel. With Redfish, an extension of the schema, they can easily control new devices, and they see the expanding ecosystem as incredibly valuable for product development. Community-driven innovation through open standards is driving R&D and enabling AI-driven efficiency and automation.
In this podcast, the speakers discussed the potential for specialized infrastructure to support chatbot startups and other GPU-heavy workloads. They highlighted the benefits of operating at the chip level and being able to easily add peripherals to optimize specific workloads. The speakers recognized the need for edge computing infrastructure and the potential for federated data architectures. They also mentioned that they are considering a hosted offering in this space to provide workload optimization. The discussion ended with a mention of the company and its products, and listeners were encouraged to check out their website for more information. Overall, it was an informative conversation about the possibilities and challenges of digital transformation.
Done
