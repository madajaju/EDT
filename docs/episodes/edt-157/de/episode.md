---
layout: posts
title: "Operationalisierung von GenAI"
number: 157
permalink: episode-EDT157-de
lang: de
nav_exclude: true
nav_order: 157
tags:
    - generativeai
    - infrastructuremanagement
    - multicloud
    - reinforcementlearning
    - edgecomputing
    - datagovernance
    - dataquality

date: 2023-09-07T00:00:00.000Z
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "In dieser Podcast-Episode diskutiert Gastgeber Darren Pulsipher, Chief Solution Architect des öffentlichen Sektors bei Intel, die Operationalisierung von generativer Künstlicher Intelligenz (AI) mit dem wiederkehrenden Gast Dr. Jeffrey Lancaster. Sie erkunden verschiedene Sharing-Modelle von generativer KI, einschließlich öffentlicher, privater und gemeinschaftlicher Modelle. Der Podcast behandelt Themen wie Open-Source-Modelle, Infrastrukturmanagement und Überlegungen zur Bereitstellung und Wartung von KI-Systemen. Es wird außerdem auf die Bedeutung von Kreativität, Personalisierung und dem Einstieg in AI-Modelle eingegangen."
video: "https://youtu.be/url"
description: "In dieser Podcast-Episode diskutiert Gastgeber Darren Pulsipher, Chief Solution Architect des öffentlichen Sektors bei Intel, die Operationalisierung von generativer Künstlicher Intelligenz (AI) mit dem wiederkehrenden Gast Dr. Jeffrey Lancaster. Sie erkunden verschiedene Sharing-Modelle von generativer KI, einschließlich öffentlicher, privater und gemeinschaftlicher Modelle. Der Podcast behandelt Themen wie Open-Source-Modelle, Infrastrukturmanagement und Überlegungen zur Bereitstellung und Wartung von KI-Systemen. Es wird außerdem auf die Bedeutung von Kreativität, Personalisierung und dem Einstieg in AI-Modelle eingegangen."
---

<div>
{% include transistor.html id="0fb3d4b8" title="#157 Operationalizing GenAI" %}

{% include youtube.html id="url" %}
</div>

---

## Erkunden verschiedener Sharing-Modelle für generative Künstliche Intelligenz

Der Podcast stellt verschiedene Modelle für die gemeinsame Nutzung von generativer KI vor. Am einen Ende des Spektrums befinden sich offene Modelle, bei denen jeder mit dem Modell interagieren und zum Training beitragen kann. Diese Modelle verwenden Verstärkungslernen, wodurch Benutzer Daten eingeben und relevante Antworten erhalten können. Andererseits sind einige private Modelle stärker eingeschränkt und schwerer zugänglich. Diese Modelle eignen sich für Unternehmensszenarien, in denen Kontrolle und Einschränkung entscheidend sind.

Es gibt jedoch einen kombinierten Ansatz, der die sprachliche Grundlage offener Modelle mit zusätzlichen Einschränkungen und Anpassungen verbindet. Mit diesem Ansatz können Organisationen von vortrainierten Modellen profitieren, während sie ihre eigenen Kontroll- und Anpassungsebenen hinzufügen. Durch die Anpassung der Gewichtungen und der verwendeten Wörter im Modell können Organisationen die Antworten nach ihren spezifischen Bedürfnissen anpassen, ohne bei Null anzufangen.

## Die Implementierung von Gen AI in der Infrastrukturverwaltung.

Der Podcast taucht in die Operationalisierung von generativer Künstlicher Intelligenz im Infrastrukturmanagement ein. Er hebt die Vorteile der Verwendung von Open-Source-Modellen hervor, um spezialisierte Systeme zu entwickeln, die private Clouds effizient verwalten. Zum Beispiel hat einer der genannten Partner generative KI implementiert, um die Leistung ihrer Infrastruktur in Echtzeit zu überwachen und zu optimieren, was proaktive Fehlerbehebung ermöglicht. Durch die Nutzung der Kraft der KI können Organisationen ihre operative Effizienz steigern und den reibungslosen Betrieb ihrer Infrastruktur sicherstellen.

Die Gastgeber betonen die Bedeutung der Berücksichtigung von Art und Qualität der in das Modell eingegebenen Daten sowie des gewünschten Outputs. Es ist nicht immer notwendig, ein Modell mit Milliarden von Indikatoren zu trainieren; ein kleineres, den spezifischen Bedürfnissen angepasstes Datenset kann effektiver sein. Durch das Verständnis der Feinheiten der Daten und der speziellen Ziele des Systems können Organisationen den Trainingsprozess optimieren und die Gesamtleistung des KI-Modells verbessern.

## Verwalten und Feinabstimmen von KI-Systemen

Die Verwaltung von KI-Systemen erfordert durchdachte Entscheidungsfindung und laufende Überwachung. Die Gastgeber diskutieren die Bedeutung der Auswahl der geeigneten Infrastruktur, sei es cloud-basiert, lokal oder hybrid. Darüber hinaus gewinnt Edge Computing an Beliebtheit, da es AI-Modelle ermöglicht, direkt auf Geräten ausgeführt zu werden und Datenrückläufe zu reduzieren.

Der Podcast betont die Notwendigkeit von Fachkenntnissen für den Aufbau und die Aufrechterhaltung von KI-Systemen. Geschultes Personal ist erforderlich, um KI-Modelle zu entwerfen und fein abzustimmen, um gewünschte Ergebnisse zu erzielen. Abhängig vom Anwendungsfall können spezifische Funktionalitäten erforderlich sein, wie z.B. Empathie im Kundenservice oder Kreativität bei Brainstorming-Anwendungen. Es ist entscheidend, ein kompetentes Team zu haben, das die Feinheiten von KI-Systemen versteht und deren optimale Funktionsweise sicherstellen kann.

Darüber hinaus bedürfen KI-Modelle einer ständigen Überwachung und Anpassung. Modelle können unerwünschtes Verhalten aufweisen, und es ist wichtig, bei Bedarf einzugreifen, um angemessene Ergebnisse zu gewährleisten. Der Podcast unterscheidet zwischen Verstärkungsproblemen, bei denen das Feedback der Benutzer das Modell in potenziell schädliche Richtungen lenken kann, und Halluzinationen, die absichtlich für kreative Zwecke angewendet werden können.

## Den Einstieg in AI-Modelle finden.

Der Podcast bietet praktische Ratschläge für den Einstieg in KI-Modelle. Die Gastgeber schlagen vor, mit den verfügbaren Tools herumzuspielen und sich mit ihren Möglichkeiten vertraut zu machen. Das Anmelden für Konten und das Erkunden, wie die Tools verwendet werden können, ist eine großartige Möglichkeit, praktische Erfahrungen zu sammeln. Sie empfehlen außerdem, eine Sandbox-Umgebung innerhalb von Unternehmen zu erstellen, damit Mitarbeiter AI-Modelle testen und damit interagieren können, bevor sie sie in die Produktion implementieren.

Der Podcast betont die Bedeutung, KI-Modellen ausreichend Kreativität zu ermöglichen, während gleichzeitig Kontrolle und Grenzen gesetzt werden. Organisationen können ein Gleichgewicht zwischen kreativer Leistung und verantwortungsbewusstem Einsatz erreichen, indem sie Leitplanken festlegen und Entscheidungen darüber treffen, was das Modell aus Interaktionen lernen sollte oder nicht.

Zusammenfassend bietet die Podcast-Episode wertvolle Einblicke in die Operationalisierung von generativer Künstlicher Intelligenz, das Management von Infrastrukturen und Überlegungen zur Verwaltung und Feinabstimmung von KI-Systemen. Sie bietet auch praktische Tipps für den Einstieg in KI-Modelle in persönlichen und beruflichen Umgebungen. Durch das Verständnis der verschiedenen Sharing-Modelle, Infrastrukturanforderungen und der Bedeutung von Kreativität und Grenzen können Organisationen die Kraft der KI nutzen, um die digitale Transformation zu unterstützen.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
