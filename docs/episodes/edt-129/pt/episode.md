---
layout: posts
title: "HPC OnDemand"
number: 129
permalink: episode-EDT129-pt
has_children: false
lang: pt
parent: Episodi
grand_parent: Português
nav_order: 129
tags:
    - hpc
    - technology
    - compute
    - openondemand
    - ohiosupercomputercenter
    - osc

date: Mon Mar 20 2023 17:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Darren W Pulsipher
    - Alan Chalker

img: thumbnail.png
image: thumbnail.png
summary: "Neste episódio, Darren entrevista Alan Chalker, diretor do programa estratégico no Ohio Super Computer Center, sobre o Open OnDemand para clusters de HPC em todo o mundo."
video: "https://youtu.be/url"
description: "Neste episódio, Darren entrevista Alan Chalker, diretor do programa estratégico no Ohio Super Computer Center, sobre o Open OnDemand para clusters de HPC em todo o mundo."
---

<div>
{% include transistor.html id="c106fb2a" title="#129 HPC OnDemand" %}

{% include youtube.html id="url" %}
</div>

---

Neste episódio de podcast, Darren Pulsipher, arquiteto-chefe de soluções do setor público na Intel, entrevista Alan Chalker do Ohio Supercomputer Center sobre a quebra de barreiras para a computação de alto desempenho (HPC, na sigla em inglês). Alan é diretor de programas estratégicos no Ohio Supercomputer e tem trabalhado em um projeto financiado pela NSF chamado Open OnDemand há mais de uma década. O projeto tem como objetivo tornar a HPC mais acessível aos consumidores em geral, que estão acostumados a fazer coisas online, como operações bancárias e compras online. O Open OnDemand simplifica o processo de uso da HPC, eliminando a necessidade de inserções de linha de comando. O histórico de Alan inclui obter seu diploma de graduação em engenharia elétrica e de computação na Universidade Estadual de Ohio e depois obter seu doutorado em engenharia biomédica na USC Chapel Hill.

## História do Open OnDemand

Em 2006 e 2007, uma interface web foi desenvolvida em colaboração com alguns especialistas tecnológicos pelo Edison Welding Institute, que posteriormente a batizou de Open OnDemand. Inicialmente, começou como uma simulação de soldagem online e foi expandida para incluir uma simulação geral de polímeros. Após apresentá-la em várias conferências, outras instituições de pesquisa em computação expressaram interesse em implementá-la em seus sistemas. Para torná-la de código aberto, a National Science Foundation concedeu a eles um programa de três anos e US$ 300.000 que tornou o protótipo mais robusto. O sucesso do Open OnDemand resultou em outro programa de cinco anos no valor de US$ 3 milhões. Hoje, está implantado em todos os continentes, exceto na Antártida, atendendo a mais de 400 instituições de pesquisa em computação.

## Expandindo a influência da HPC.

Supercomputadores expandiram além de campos tradicionais como ciência da computação e engenharia. Na OSC, estudantes de antropologia e ciência política estão utilizando o supercomputador para suas pesquisas, assim como estudantes de horticultura e ciências de plantações. A demanda pelo supercomputador está aumentando, com mais de 8.500 pessoas utilizando os supercomputadores da OSC de todo o mundo no último ano fiscal. Além disso, durante a pandemia, muitas universidades puderam continuar ensinando e pesquisando remotamente através de desktops virtuais fornecidos pelo supercomputador.

## Comparação entre os Modelos de Preços de CSP e HPC

Os modelos de precificação para o supercomputador são baseados em horas de núcleo e meses de terabyte, e o mandato governamental permite precificação subsidiada para entidades acadêmicas sediadas em Ohio. Provedores de serviços em nuvem cobram pelo tempo do relógio de parede, não pelas horas de núcleo, e cobram pelos custos de armazenamento de dados e de rede de egresso. Clientes da indústria comercial estão começando a utilizar supercomputadores para cargas de trabalho de simulação HPC tradicionais, economizando dinheiro ao executá-las nas nuvens públicas de varejo.

## Exemplos de uso comercial

No dia anterior a Darren e Alan se sentarem e conversarem, houve tornados na região de Columbus, Ohio. A previsão do tempo é significativa para muitas indústrias e os supercomputadores são muito adequados. O centro gera previsões meteorológicas a cada 4 a 6 horas para clientes, como empresas de transporte marítimo e companhias aéreas. Embora as cargas de trabalho tradicionais de computação de alto desempenho ainda sejam comuns, as emergentes incluem a análise de tweets de membros do congresso em relação à COVID-19, antropologia, horticultura e ciências agrícolas. Qualquer coisa que seja limitada pelo tempo ou envolva muitos dados pode se beneficiar das capacidades de computação de alto desempenho. A demanda por essas capacidades deve crescer devido ao aumento da acessibilidade. Tornar a HPC mais fácil de consumir é semelhante ao que a nuvem fez para a computação em grade nos velhos tempos.

## Capacidade de OSC

A capacidade massiva do sistema de computação de alto desempenho da OSC está constantemente expandindo para atender à demanda. No momento da gravação, eles tinham 55.000 núcleos, principalmente da Intel, com 400 aceleradores distribuídos em 1600 nós. Eles antecipam uma nova aquisição que os levaria a 75.000-80.000 lugares devido à demanda crescente nas áreas biomédicas. O sistema pode lidar com grandes quantidades de dados, com 20 petabytes de armazenamento em disco real e conectividade de rede a uma velocidade de leitura/escrita de 350 gigabits por segundo. Um dos benefícios significativos da OSC é a ausência de custos de saída para seus clientes, devido à fundação da organização por meio de uma bolsa da National Science Foundation.

## Abrir OnDemand

Muitas universidades e centros de HPC estão aproveitando o Open OnDemand como uma interface web simples para tornar o HPC mais disponível para pesquisadores que precisam aprender ou entender as complexidades de agendar tarefas, decompor conjuntos de problemas e gerenciar dados em um cluster. Até mesmo os provedores de serviços em nuvem possuem interfaces Open OnDemand para sua oferta de HPC.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
