---
layout: posts
title: "Sicherheit in Generative AI"
number: 160
permalink: episode-EDT160-de
has_children: false
lang: de
parent: Folgen
grand_parent: Deutsch
nav_order: 160
tags:
    - collectiongenerativeai
    - personalizedphishingattacks
    - promptinjection
    - sharingcodeai
    - harnessingai
    - digitaltransformation
    - generativeai
    - cybersecurityrisks
    - serviceproviders
    - duediligence
    - riskschallenges
    - digitallandscape
    - proactivecybersecurity
    - llm
    - multifactorauthentication
    - voicerecognition
    - typingcadence
    - github
    - stackoverflow
    - samsungipleak
    - securityaspects
    - embracingdigital
    - edt160

date: Tue Sep 19 2023 00:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "In dieser Folge wird Moderator Darren Pulsipher von Dr. Jeffrey Lancaster begleitet, um in die Schnittstelle zwischen generativer KI und Sicherheit einzutauchen. Das Gespräch geht ausführlich auf die potenziellen Risiken und Herausforderungen ein, die mit der Verwendung generativer KI für böswillige Aktivitäten, insbesondere im Bereich der Cybersicherheit, verbunden sind."
video: "https://youtu.be/url"
description: "In dieser Folge wird Moderator Darren Pulsipher von Dr. Jeffrey Lancaster begleitet, um in die Schnittstelle zwischen generativer KI und Sicherheit einzutauchen. Das Gespräch geht ausführlich auf die potenziellen Risiken und Herausforderungen ein, die mit der Verwendung generativer KI für böswillige Aktivitäten, insbesondere im Bereich der Cybersicherheit, verbunden sind."
---

<div>
{% include transistor.html id="17e65174" title="#160 Security in Generative AI" %}

{% include youtube.html id="url" %}
</div>

---

## Personalisierte und überzeugende Phishing-Angriffe

Eine der hauptsächlichen diskutierten Bedenken besteht in der Möglichkeit für immer ausgefeiltere und personalisierte Phishing-Angriffe. Phishing steht derzeit als die effektivste Methode für Cyberangriffe da, und mithilfe generativer künstlicher Intelligenz können Angreifer hochgradig personalisierte und überzeugende Phishing-E-Mails oder -Nachrichten erstellen. Durch das Abrufen von Informationen aus sozialen Medien oder anderen Online-Plattformen können Angreifer ihre Phishing-Versuche schwerer erkennbar machen. Dies wirft die Frage auf, wie wir feststellen können, was echt ist und was nicht, und wie wir die Authentizität der empfangenen Informationen vertrauen können.

Um dem entgegenzuwirken, müssen Einzelpersonen möglicherweise neue Methoden zur Überprüfung von Informationen entwickeln, wie z.B. die Verwendung von persönlichen Codewörtern oder anderen Authentifizierungsmaßnahmen bei nahestehenden Personen. Darüber hinaus müssen Organisationen und Sicherheitsagenturen ihre Strategien anpassen, um der zunehmenden Raffinesse von durch generative KI ermöglichten Cyberangriffen entgegenzuwirken. Es ist entscheidend zu verstehen, dass generative KI selbst eine neutrale Technologie ist und ihre Auswirkungen davon abhängen, wie sie eingesetzt wird.

## Klone Stimmen und Vertrauen in Informationen

Der Podcast untersucht auch das Potenzial von generativer KI zur Klonung von Stimmen, was bereits bei virtuellen Entführungsangriffen beobachtet wurde. Kriminelle verwenden geklonte Stimmen, um ein Gefühl von Dringlichkeit und Angst zu erzeugen und sich als geliebte Personen des Opfers auszugeben. Dies wirft Bedenken hinsichtlich des Vertrauens in die Echtheit der Informationen auf, die wir erhalten.

In einem solchen Szenario wird es unerlässlich, Techniken zur Überprüfung der Authentizität von Stimmen und Informationen zu entwickeln. Als Individuen sollten wir wachsam bleiben und Vorsicht walten lassen, wenn wir auf dringende Anfragen am Telefon reagieren. Eine offene Kommunikation mit vertrauenswürdigen Kontakten sicherstellen, kann helfen zu überprüfen, ob solche Anfragen echt sind.

## Den Schutz des geistigen Eigentums bei Kodierung und Programmierung

Der Podcast führt zu einer Diskussion über die Bedeutung des Schutzes des geistigen Eigentums beim Codieren und Programmieren über. Die Moderatoren betonen die Risiken des unbeabsichtigten Teilens von Code auf Plattformen wie StackOverflow und GitHub sowie das versehentliche Durchsickern von geistigem Eigentum beim Suchen von Hilfe in diesen öffentlichen Foren. Entwickler werden ermutigt, sensible Informationen durch Platzhalter zu ersetzen, bevor sie Code teilen, um das Risiko eines Verlusts geistigen Eigentums zu mindern.

Darüber hinaus diskutieren die Gastgeber die Einführung von Tools wie GitHub Copilot, die generative KI nutzen, um Code-Vorschläge zu liefern. Obwohl solche Tools wertvoll sein können, werfen sie Bedenken hinsichtlich der Sicherheit und Privatsphäre von proprietären Informationen auf. Entwickler müssen sorgfältig die Vertrauenswürdigkeit des Dienstanbieters prüfen und für angemessenen Schutz ihrer Daten und geistigen Eigentumsrechte sorgen.

## Die Balance zwischen Innovation und Sicherheit im Zeitalter der künstlichen Intelligenz

Das Gespräch schließt mit der Betonung der Bedeutung, ein Gleichgewicht zwischen der Akzeptanz der Fortschritte und potenziell positiven Veränderungen, die durch generative KI verursacht werden, und der Bewältigung der damit verbundenen Risiken im Bereich der Cybersicherheit und des Schutzes des geistigen Eigentums zu finden. Es ist entscheidend, informiert zu bleiben, Sicherheitsstrategien anzupassen und Vorsicht walten zu lassen, um die sich wandelnde Landschaft der digitalen Transformation erfolgreich zu bewältigen. Indem wir dies tun, können wir die Vorteile von KI nutzen, ohne die Sicherheit und persönliche Informationen zu gefährden.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
