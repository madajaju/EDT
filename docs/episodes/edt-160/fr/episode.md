---
layout: posts
title: "Sécurité en IA Générative."
number: 160
permalink: episode-EDT160-fr
has_children: false
lang: fr
parent: Épisodes
grand_parent: Français
nav_order: 160
tags:
    - collectiongenerativeai
    - personalizedphishingattacks
    - promptinjection
    - sharingcodeai
    - harnessingai
    - digitaltransformation
    - generativeai
    - cybersecurityrisks
    - serviceproviders
    - duediligence
    - riskschallenges
    - digitallandscape
    - proactivecybersecurity
    - llm
    - multifactorauthentication
    - voicerecognition
    - typingcadence
    - github
    - stackoverflow
    - samsungipleak
    - securityaspects
    - embracingdigital
    - edt160

date: Tue Sep 19 2023 00:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "Dans cet épisode, l'animateur Darren Pulsipher est rejoint par Dr Jeffrey Lancaster pour explorer l'intersection entre l'IA générative et la sécurité. La conversation plonge profondément dans les risques potentiels et les défis liés à l'utilisation de l'IA générative dans des activités néfastes, notamment dans le domaine de la cybersécurité."
video: "https://youtu.be/url"
description: "Dans cet épisode, l'animateur Darren Pulsipher est rejoint par Dr Jeffrey Lancaster pour explorer l'intersection entre l'IA générative et la sécurité. La conversation plonge profondément dans les risques potentiels et les défis liés à l'utilisation de l'IA générative dans des activités néfastes, notamment dans le domaine de la cybersécurité."
---

<div>
{% include transistor.html id="17e65174" title="#160 Security in Generative AI" %}

{% include youtube.html id="url" %}
</div>

---

## Attaques de phishing personnalisées et convaincantes.

L'une des principales préoccupations discutées est le potentiel d'attaques de phishing de plus en plus sophistiquées et personnalisées. Le phishing est actuellement la méthode d'attaque cybernétique la plus efficace, et avec l'intelligence artificielle générative, les attaquants peuvent créer des e-mails ou des messages de phishing hautement personnalisés et convaincants. En récupérant des informations à partir des médias sociaux ou d'autres plateformes en ligne, les attaquants peuvent rendre leurs tentatives de phishing plus difficiles à détecter. Cela soulève la question de comment nous pouvons déterminer ce qui est réel ou non et comment nous pouvons avoir confiance en l'authenticité des informations que nous recevons.

Pour lutter contre cela, les individus peuvent avoir besoin de développer de nouvelles méthodes de vérification des informations, comme l'utilisation de mots de code personnels ou d'autres mesures d'authentification avec leurs proches. De plus, les organisations et les agences de sécurité doivent adapter leurs stratégies pour contrer la sophistication croissante des attaques cybernétiques facilitées par l'IA générative. Il est crucial de comprendre que l'IA générative elle-même est une technologie neutre, et ses implications dépendent de la manière dont elle est utilisée.

## Voix clonées et confiance dans les informations

Le podcast explore également le potentiel de l'intelligence artificielle générative pour cloner des voix, ce qui a déjà été observé lors d'attaques de kidnapping virtuel. Les criminels utilisent des voix clonées pour créer un sentiment d'urgence et de peur, en prétendant être les proches d'une victime. Cela soulève des inquiétudes quant à la confiance que nous pouvons accorder à l'authenticité des informations que nous recevons.

Dans un tel scénario, il devient essentiel de développer des techniques pour vérifier l'authenticité des voix et des informations. En tant qu'individus, nous devrions rester vigilants et faire preuve de prudence lorsque nous répondons à des demandes urgentes par téléphone. S'assurer d'avoir des lignes de communication ouvertes avec des contacts de confiance peut aider à vérifier si de telles demandes sont authentiques.

## Protéger la propriété intellectuelle dans la codification et la programmation

Le podcast enchaîne avec une discussion sur l'importance de protéger la propriété intellectuelle dans le codage et la programmation. Les animateurs mettent en évidence les risques de partager involontairement du code sur des plateformes comme StackOverflow et GitHub, ainsi que la fuite involontaire de propriété intellectuelle lors de la recherche d'aide dans ces forums publics. Les développeurs sont encouragés à remplacer les informations sensibles par des espaces réservés avant de partager du code afin de réduire le risque de perte de propriété intellectuelle.

De plus, les hôtes discutent de l'introduction d'outils tels que GitHub Copilot, qui utilisent une IA générative pour fournir des suggestions de code. Bien que ces outils puissent être précieux, ils soulèvent des préoccupations quant à la sécurité et à la confidentialité des informations propriétaires. Les développeurs doivent soigneusement considérer la fiabilité du fournisseur de services et garantir une protection adéquate de leurs données et de leur propriété intellectuelle.

## Équilibrer l'innovation et la sécurité à l'ère de l'IA

La conversation se conclut en mettant l'accent sur l'importance de trouver un équilibre entre l'adoption des avancées et des changements positifs potentiels apportés par l'IA générative, et la prise en compte des risques associés dans le domaine de la cybersécurité et de la protection de la propriété intellectuelle. Il est essentiel de rester informé, d'adapter les stratégies de sécurité et de faire preuve de prudence pour naviguer avec succès dans le paysage en constante évolution de la transformation numérique. En agissant ainsi, nous pouvons exploiter les avantages de l'IA sans compromettre la sécurité et les informations personnelles.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
