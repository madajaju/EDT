---
layout: posts
title: "Sicurezza nell'IA generativa"
number: 160
permalink: episode-EDT160-it
lang: it
nav_exclude: true
nav_order: 160
tags:
    - collectiongenerativeai
    - personalizedphishingattacks
    - promptinjection
    - sharingcodeai
    - harnessingai
    - digitaltransformation
    - generativeai
    - cybersecurityrisks
    - serviceproviders
    - duediligence
    - riskschallenges
    - digitallandscape
    - proactivecybersecurity
    - llm
    - multifactorauthentication
    - voicerecognition
    - typingcadence
    - github
    - stackoverflow
    - samsungipleak
    - securityaspects
    - embracingdigital
    - edt160

date: 2023-09-19T07:00:00.000Z
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "In questo episodio, l'ospite Darren Pulsipher viene affiancato dal dottor Jeffrey Lancaster per approfondire l'intersezione tra intelligenza artificiale generativa e sicurezza. La conversazione si addentra nei potenziali rischi e sfide legate all'utilizzo dell'intelligenza artificiale generativa in attività negative, in particolare nel campo della sicurezza informatica."
video: "https://youtu.be/qk1KRCZajIY"
description: "In questo episodio, l'ospite Darren Pulsipher viene affiancato dal dottor Jeffrey Lancaster per approfondire l'intersezione tra intelligenza artificiale generativa e sicurezza. La conversazione si addentra nei potenziali rischi e sfide legate all'utilizzo dell'intelligenza artificiale generativa in attività negative, in particolare nel campo della sicurezza informatica."
---

<div>
{% include transistor.html id="17e65174" title="#160 Security in Generative AI" %}

{% include youtube.html id="qk1KRCZajIY" %}
</div>

---

## Attacchi di phishing personalizzati e convincenti

Uno dei principali problemi discussi è il potenziale per attacchi di phishing sempre più sofisticati e personalizzati. Attualmente, il phishing è il metodo di attacco informatico più efficace e, con l'intelligenza artificiale generativa, gli aggressori possono creare email o messaggi di phishing altamente personalizzati e convincenti. Recuperando informazioni dai social media o da altre piattaforme online, gli aggressori possono rendere i loro tentativi di phishing più difficili da individuare. Questo solleva la domanda su come possiamo determinare cosa è reale o meno e come possiamo fidarci dell'autenticità delle informazioni che riceviamo.

Per contrastare ciò, gli individui potrebbero dover sviluppare nuovi metodi per verificare le informazioni, come utilizzare codici personali o altre misure di autenticazione con i propri cari. Inoltre, le organizzazioni e le agenzie di sicurezza devono adattare le loro strategie per contrastare la crescente sofisticazione degli attacchi informatici facilitati dall'intelligenza artificiale generativa. È fondamentale capire che l'intelligenza artificiale generativa è di per sé una tecnologia neutra, e le sue implicazioni dipendono da come viene utilizzata.

## Voci clonate e fidarsi delle informazioni

Il podcast esplora anche il potenziale dell'intelligenza artificiale generativa nel clonare voci, fenomeno che è già stato osservato negli attacchi di rapimento virtuali. I criminali utilizzano voci clonate per creare un senso di urgenza e paura, fingendo di essere familiari dell'eventuale vittima. Questo solleva preoccupazioni sulla fiducia nell'autenticità delle informazioni che riceviamo.

In uno scenario del genere, diventa essenziale sviluppare tecniche per verificare l'autenticità delle voci e delle informazioni. Come individui, dovremmo rimanere vigili e fare attenzione quando rispondiamo a richieste urgenti al telefono. Assicurare linee di comunicazione aperte con contatti fidati può aiutare a verificare se tali richieste siano autentiche.

## Protezione della Proprietà Intellettuale nel Codice e nella Programmazione

Il podcast passa a una discussione sull'importanza di proteggere la proprietà intellettuale nella codifica e nella programmazione. Gli ospiti sottolineano i rischi di condividere involontariamente il codice su piattaforme come StackOverflow e GitHub, e la perdita involontaria di proprietà intellettuale quando si cerca aiuto in questi forum pubblici. Ai developer viene consigliato di sostituire le informazioni sensibili con segnaposto prima di condividere il codice per mitigare il rischio di perdita della proprietà intellettuale.

Inoltre, gli ospiti discutono dell'introduzione di strumenti come GitHub Copilot, che utilizzano l'intelligenza artificiale generativa per fornire suggerimenti di codice. Sebbene questi strumenti possano essere preziosi, pongono preoccupazioni per la sicurezza e la privacy delle informazioni proprietarie. Gli sviluppatori devono considerare attentamente l'affidabilità del fornitore di servizi e garantire una adeguata protezione dei loro dati e della proprietà intellettuale.

## Trovare l'equilibrio tra innovazione e sicurezza nell'era dell'intelligenza artificiale.

La conversazione si conclude sottolineando l'importanza di trovare un equilibrio tra abbracciare le innovazioni e i potenziali cambiamenti positivi portati dalla generative AI e affrontare i rischi connessi nell'ambito della sicurezza informatica e della protezione della proprietà intellettuale. È essenziale rimanere informati, adattare le strategie di sicurezza ed esercitare cautela per navigare con successo nel paesaggio in continua evoluzione della trasformazione digitale. In questo modo, possiamo sfruttare i benefici dell'AI senza compromettere la sicurezza e le informazioni personali.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
