---
layout: posts
title: "Security in Generative AI"
number: 160
permalink: episode-EDT160-en
has_children: false
lang: en
nav_exclude: true
parent: Episodes
grand_parent: English
nav_order: 160
tags:
    - collectiongenerativeai
    - personalizedphishingattacks
    - promptinjection
    - sharingcodeai
    - harnessingai
    - digitaltransformation
    - generativeai
    - cybersecurityrisks
    - serviceproviders
    - duediligence
    - riskschallenges
    - digitallandscape
    - proactivecybersecurity
    - llm
    - multifactorauthentication
    - voicerecognition
    - typingcadence
    - github
    - stackoverflow
    - samsungipleak
    - securityaspects
    - embracingdigital
    - edt160

date: Tue Sep 19 2023 00:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "In this episode, host Darren Pulsipher is joined by Dr. Jeffrey Lancaster to delve into the intersection of generative AI and security. The conversation dives deep into the potential risks and challenges surrounding the use of generative AI in nefarious activities, particularly in the realm of cybersecurity."
video: "https://youtu.be/url"
description: "In this episode, host Darren Pulsipher is joined by Dr. Jeffrey Lancaster to delve into the intersection of generative AI and security. The conversation dives deep into the potential risks and challenges surrounding the use of generative AI in nefarious activities, particularly in the realm of cybersecurity."
---

<div>
{% include transistor.html id="17e65174" title="#160 Security in Generative AI" %}

{% include youtube.html id="url" %}
</div>

---

## Personalized and Convincing Phishing Attacks

One of the main concerns discussed is the potential for more sophisticated and personalized phishing attacks. Phishing currently stands as the most effective cyber attack method, and with generative AI, attackers can create highly personalized and convincing phishing emails or messages. By retrieving information from social media or other online platforms, attackers can make their phishing attempts harder to detect. This raises the question of how we can determine what is real or not and how we can trust the authenticity of the information we receive.

To combat this, individuals may need to develop new methods of verifying information, such as using personal code words or other authentication measures with loved ones. Additionally, organizations and security agencies must adapt their strategies to counter the increased sophistication of cyber attacks facilitated by generative AI. It's crucial to understand that generative AI itself is a neutral technology, and its implications depend on how it is used.

## Cloned Voices and Trusting Information

The podcast also explores the potential for generative AI to clone voices, which has already been observed in virtual kidnapping attacks. Criminals use cloned voices to create a sense of urgency and fear, pretending to be a victim's loved ones. This raises concerns about trusting the authenticity of information we receive.

In such a scenario, it becomes essential to develop techniques to verify the authenticity of voices and information. As individuals, we should remain vigilant and exercise caution when responding to urgent requests over the phone. Ensuring open lines of communication with trusted contacts can help verify if such requests are genuine.

## Protecting Intellectual Property in Coding and Programming

The podcast segues into a discussion about the importance of protecting intellectual property in coding and programming. The hosts highlight the risks of unintentionally sharing code on platforms like StackOverflow and GitHub, and the inadvertent leakage of intellectual property when seeking help in these public forums. Developers are encouraged to replace sensitive information with placeholders before sharing code to mitigate the risk of intellectual property loss.

Additionally, the hosts discuss the introduction of tools like GitHub Copilot, which use generative AI to provide code suggestions. While these tools can be valuable, they raise concerns about the security and privacy of proprietary information. Developers must carefully consider the trustworthiness of the service provider and ensure adequate protection of their data and intellectual property.

## Balancing Innovation and Security in the Age of AI

The conversation concludes by emphasizing the importance of striking a balance between embracing the advancements and potential positive changes brought about by generative AI, and addressing the associated risks in the realm of cybersecurity and intellectual property protection. It is essential to remain informed, adapt security strategies, and exercise caution to navigate the evolving landscape of digital transformation successfully. By doing so, we can harness the benefits of AI without compromising security and personal information.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
