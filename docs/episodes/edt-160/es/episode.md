---
layout: posts
title: "Seguridad en la IA Generativa"
number: 160
permalink: episode-EDT160-es
lang: es
nav_exclude: true
nav_order: 160
tags:
    - collectiongenerativeai
    - personalizedphishingattacks
    - promptinjection
    - sharingcodeai
    - harnessingai
    - digitaltransformation
    - generativeai
    - cybersecurityrisks
    - serviceproviders
    - duediligence
    - riskschallenges
    - digitallandscape
    - proactivecybersecurity
    - llm
    - multifactorauthentication
    - voicerecognition
    - typingcadence
    - github
    - stackoverflow
    - samsungipleak
    - securityaspects
    - embracingdigital
    - edt160

date: Tue Sep 19 2023 00:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Jeffrey Lancaster
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "En este episodio, el anfitrión Darren Pulsipher se une al Dr. Jeffrey Lancaster para adentrarse en la intersección entre la inteligencia artificial generativa y la seguridad. La conversación profundiza en los riesgos y desafíos potenciales que rodean el uso de la inteligencia artificial generativa en actividades maliciosas, especialmente en el ámbito de la ciberseguridad."
video: "https://youtu.be/qk1KRCZajIY"
description: "En este episodio, el anfitrión Darren Pulsipher se une al Dr. Jeffrey Lancaster para adentrarse en la intersección entre la inteligencia artificial generativa y la seguridad. La conversación profundiza en los riesgos y desafíos potenciales que rodean el uso de la inteligencia artificial generativa en actividades maliciosas, especialmente en el ámbito de la ciberseguridad."
---

<div>
{% include transistor.html id="17e65174" title="#160 Security in Generative AI" %}

{% include youtube.html id="qk1KRCZajIY" %}
</div>

---

## Ataques de suplantación de identidad personalizados y convincentes.

Una de las principales preocupaciones discutidas es el potencial para ataques de phishing más sofisticados y personalizados. Actualmente, el phishing se destaca como el método de ataque cibernético más efectivo y, con la inteligencia artificial generativa, los atacantes pueden crear correos electrónicos o mensajes de phishing altamente personalizados y convincentes. Al obtener información de las redes sociales u otras plataformas en línea, los atacantes pueden hacer que sus intentos de phishing sean más difíciles de detectar. Esto plantea la pregunta de cómo podemos determinar qué es real o no y cómo podemos confiar en la autenticidad de la información que recibimos.

Para combatir esto, es posible que las personas necesiten desarrollar nuevos métodos para verificar la información, como utilizar palabras clave personales u otras medidas de autenticación con seres queridos. Además, las organizaciones y agencias de seguridad deben adaptar sus estrategias para contrarrestar la creciente sofisticación de los ataques cibernéticos facilitados por la inteligencia artificial generativa. Es crucial entender que la inteligencia artificial generativa en sí misma es una tecnología neutral y sus implicaciones dependen de cómo se utilice.

## Voces clonadas y confiar en la información.

El podcast también explora el potencial del IA generativa para clonar voces, lo que ya se ha observado en ataques de secuestro virtual. Los criminales utilizan voces clonadas para crear un sentido de urgencia y miedo, pretendiendo ser seres queridos de la víctima. Esto plantea preocupaciones sobre confiar en la autenticidad de la información que recibimos.

En un escenario así, se vuelve esencial desarrollar técnicas para verificar la autenticidad de las voces y la información. Como individuos, debemos permanecer vigilantes y tener precaución al responder a solicitudes urgentes por teléfono. Asegurarse de mantener líneas de comunicación abiertas con contactos de confianza puede ayudar a verificar si dichas solicitudes son auténticas.

## Protegiendo la propiedad intelectual en la codificación y programación

El podcast se adentra en una discusión sobre la importancia de proteger la propiedad intelectual en la codificación y programación. Los anfitriones destacan los riesgos de compartir involuntariamente código en plataformas como StackOverflow y GitHub, así como la filtración inadvertida de propiedad intelectual al buscar ayuda en estos foros públicos. Se alienta a los desarrolladores a reemplazar la información confidencial con marcadores antes de compartir código para mitigar el riesgo de pérdida de propiedad intelectual.

Además, los anfitriones discuten la introducción de herramientas como GitHub Copilot, que utiliza IA generativa para proporcionar sugerencias de código. Si bien estas herramientas pueden ser valiosas, plantean preocupaciones sobre la seguridad y privacidad de la información propietaria. Los desarrolladores deben considerar cuidadosamente la confiabilidad del proveedor de servicios y garantizar una protección adecuada de sus datos y propiedad intelectual.

## Equilibrar la innovación y la seguridad en la era de la IA.

La conversación concluye enfatizando la importancia de lograr un equilibrio entre abrazar los avances y los posibles cambios positivos que aporta la IA generativa y abordar los riesgos asociados en el ámbito de la ciberseguridad y la protección de la propiedad intelectual. Es esencial mantenerse informado, adaptar las estrategias de seguridad y tener cautela para navegar exitosamente por el paisaje en constante evolución de la transformación digital. Al hacerlo, podemos aprovechar los beneficios de la IA sin comprometer la seguridad y la información personal.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
