---
layout: posts
title: "Raccolta e preparazione dei dati"
number: 18
permalink: episode-EDT18-it
has_children: false
lang: it
parent: Episódios
grand_parent: Italiano
nav_order: 18
tags:
    - dataarchitecture
    - datacentric
    - data

date: Sun Aug 30 2020 17:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "Sarah Kalicin, Lead Data Scientist presso Intel, e Darren Pulsipher, Chief Solution Architect, Pubblico Settore presso Intel, parlano del processo e dei vantaggi della raccolta e preparazione dei dati nel diventare un'organizzazione centrata sui dati. Questo è il secondo passo nel percorso verso il diventare un'organizzazione centrata sui dati."
video: "https://youtu.be/xdt93M5isEA"
description: "Sarah Kalicin, Lead Data Scientist presso Intel, e Darren Pulsipher, Chief Solution Architect, Pubblico Settore presso Intel, parlano del processo e dei vantaggi della raccolta e preparazione dei dati nel diventare un'organizzazione centrata sui dati. Questo è il secondo passo nel percorso verso il diventare un'organizzazione centrata sui dati."
---

<div>
{% include transistor.html id="ef0bf710" title="#18 Data Collection and Preparation" %}

{% include youtube.html id="xdt93M5isEA" %}
</div>

---

## Abbiamo bisogno dei dati! I nostri dati sono un caos!

La prima cosa da considerare in questa parte del processo è il flusso dei dati. Come identifichiamo quali dati grezzi abbiamo bisogno e come li otteniamo attraverso il flusso dei dati e li trasformiamo in informazioni? Ci sono cinque passaggi chiave nel flusso dei dati: determinare il valore commerciale dei dati, assimilarli, prepararli, analizzarli e, infine, agire in base alle informazioni ottenute.

Guardiamo alla produzione come esempio. Nell'individuare quali dati offrano valore alle imprese, dovresti fare tre domande fondamentali: Qual è la domanda per il mio prodotto? Qual è l'offerta attuale? Qual è la perdita di resa? Queste sono domande apparentemente semplici, ma poi devi pensare a cose più complesse come ad esempio come quantificare la domanda, le capacità di produzione, l'offerta e la perdita di resa. Da dove provengono i dati? Come li acquisisco? Quanto sono affidabili e stabili questi dati? Ci sono molte domande e variabili, come ad esempio i tempi di consegna delle materie prime, la domanda proiettata e la perdita di resa sconosciuta, che possono creare una grande complessità.

Il pipeline semplifica il modo in cui tutti questi componenti si uniscono. Ogni tipo di dato passa attraverso i passaggi chiave nel pipeline, ma ognuno sarà diverso. Ad esempio, l'assunzione di un tipo di dato varierà rispetto all'assunzione di un altro. L'idea, però, è quella di riunire tutti i dati per creare un quadro chiaro.

## Abbiamo dei dati! Cosa ne facciamo?

A seconda del tipo di dati e delle domande a cui si cerca di rispondere, si utilizzano diverse tecniche di analisi. Ad esempio, per rispondere a quanti widget dovrebbero essere prodotti, si potrebbe analizzare l'offerta e la domanda storica tramite l'analisi dei dati e l'intelligence di base in ambito aziendale. Per determinare quali widget presentano difetti visivi, potrebbe essere il miglior approccio un algoritmo che impara a identificare difetti nelle immagini tramite il deep learning. Non esiste una singola tecnica che risolve tutti i problemi; ognuna è unica per il problema e i dati stessi.

Inoltre, è importante coinvolgere esperti del settore per aiutare a comprendere gli schemi che i dati producono. L'esperto del settore comprenderà i dati e da dove provengono, mentre lo scienziato dei dati comprenderà il miglior approccio per gli algoritmi al fine di ottenere una maggiore comprensione. Ad esempio, se attraverso un algoritmo di apprendimento automatico si prevede un calo nella resa del prodotto, gli ingegneri incaricati di risolvere il problema potrebbero non sapere dove guardare senza il contesto del problema. Una delle ragioni per cui le organizzazioni non ottengono il ritorno sugli investimenti nel grado in cui dovrebbero è perché non hanno costruito i loro modelli per essere azionabili o riflettenti dei comportamenti all'interno dei sistemi che cercano di prevedere.

Come tutto ciò funziona insieme si riduce alle domande aziendali che stai facendo e alle sfide che hai. Ad esempio, potresti avere una serie di algoritmi che ti dicono quanti widget produrre. Potresti avere un algoritmo di apprendimento profondo che riconosce se un widget ha un difetto e anche classifica i difetti. Ma ciò non aiuta necessariamente se non sai perché quel difetto è accaduto. Quindi devi collegare quelle informazioni ad alcuni altri algoritmi per ottenere correlazioni per spiegare i difetti e hai bisogno di un piano d'azione per correggere il problema.

## Dobbiamo creare conoscenze. Come addestriamo i nostri dati?

Come possiamo realizzare questo? Fondamentalmente, stai riunendo tutti i dati, preparandoli e collegandoli al fine, ad esempio, di quantificare l'approvvigionamento e le previsioni di perdita di resa. Avrai bisogno di pratiche di risoluzione dei problemi e miglioramento continuo nel tempo per far fronte alle condizioni mutevoli. È qui che entra in gioco la cultura dell'organizzazione. Risolvere un problema una volta senza un impegno per il miglioramento continuo può far perdere all'organizzazione il vero valore dell'analisi nel lungo periodo.

Stiamo assistendo oggi a un importante cambiamento verso organizzazioni con un'infrastruttura incentrata sui dati. I dati non sono più solo nel data center, ma anche nel cloud e nell'edge. Con il processo aziendale in cima, che porta a un miglioramento continuo, comprensione del business e dei dati, fino alla distribuzione, le organizzazioni costruite su questa infrastruttura possono notare una differenza notevole nel mondo.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
