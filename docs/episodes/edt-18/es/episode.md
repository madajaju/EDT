---
layout: posts
title: "Recopilación y preparación de datos"
number: 18
permalink: episode-EDT18-es
lang: es
nav_exclude: true
nav_order: 18
tags:
    - dataarchitecture
    - datacentric
    - data

date: Sun Aug 30 2020 17:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Darren W Pulsipher

img: thumbnail.png
image: thumbnail.png
summary: "Sarah Kalicin, científica de datos principal en Intel, y Darren Pulsipher, arquitecto principal de soluciones en el sector público en Intel, hablan sobre el proceso y los beneficios de la recopilación y preparación de datos al convertirse en una organización centrada en los datos. Este es el segundo paso en el camino para convertirse en una organización centrada en los datos."
video: "https://youtu.be/url"
description: "Sarah Kalicin, científica de datos principal en Intel, y Darren Pulsipher, arquitecto principal de soluciones en el sector público en Intel, hablan sobre el proceso y los beneficios de la recopilación y preparación de datos al convertirse en una organización centrada en los datos. Este es el segundo paso en el camino para convertirse en una organización centrada en los datos."
---

<div>
{% include transistor.html id="ef0bf710" title="#18 Data Collection and Preparation" %}

{% include youtube.html id="url" %}
</div>

---

## ¡Necesitamos data! ¡Nuestra data está desordenada!

Lo primero en lo que hay que pensar en esta parte del proceso es en la tubería de datos. ¿Cómo identificamos qué datos sin procesar necesitamos y cómo los transmitimos a través de la tubería y los transformamos en conocimiento? Hay cinco pasos clave en la tubería: determinar el valor empresarial de los datos, ingestarlos, prepararlos, analizarlos y, finalmente, actuar en base a las perspectivas resultantes.

Veamos la fabricación como ejemplo. Al determinar qué datos ofrecen valor empresarial, debes hacer tres preguntas fundamentales: ¿Cuál es la demanda de mi producto? ¿Cuál es la oferta actual? ¿Cuál es la pérdida de rendimiento? Estas preguntas parecen simples, pero luego debes pensar en cosas más complejas, como cómo cuantificar la demanda, las capacidades de fabricación, la oferta y la pérdida de rendimiento. ¿De dónde provienen los datos? ¿Cómo los absorbo? ¿Qué tan confiables y estables son estos datos? Hay muchas preguntas y variables, como el tiempo de entrega de los productos, la demanda proyectada y la pérdida de rendimiento desconocida, que pueden generar gran complejidad.

El pipeline simplifica cómo todos estos componentes se unen. Cada tipo de datos pasa por los pasos clave del pipeline, pero cada uno será diferente. Por ejemplo, la ingesta de un tipo de datos variará de la ingesta de otro. Sin embargo, la idea es reunir todos los datos para crear una imagen clara.

## ¡Tenemos datos! ¿Qué hacemos con ellos?

Dependiendo del tipo de datos y las preguntas que estés tratando de responder, utilizarías diferentes técnicas analíticas. Por ejemplo, al responder cuántos widgets se deben fabricar, podrías analizar el suministro y la demanda histórica a través de análisis e inteligencia básica de negocios. Para determinar qué widgets tienen defectos visuales, un algoritmo que aprenda a identificar defectos en imágenes a través de aprendizaje profundo podría ser el enfoque más adecuado. No hay una técnica que resuelva todos los problemas; cada una es única para el problema y los propios datos.

Además, es importante contar con expertos en el campo para ayudar a comprender los patrones que arroja los datos. El experto en el campo comprenderá los datos y de dónde provienen, y el científico de datos comprenderá la mejor manera de enfocar los algoritmos para obtener más información. Si, por ejemplo, se predice una disminución en el rendimiento del producto a través de un algoritmo de aprendizaje automático, los ingenieros que necesitan corregir el problema no sabrán necesariamente dónde buscar sin el contexto del problema. Una de las razones por las cuales las organizaciones no están obteniendo el retorno de inversión que deberían es porque no han construido sus modelos para que sean ejecutables o reflejen los comportamientos dentro de los sistemas que intentan predecir.

Cómo todo esto funciona en conjunto se reduce a las preguntas comerciales que estás haciendo y a tus desafíos. Por ejemplo, podrías tener una variedad de algoritmos que te indiquen cuántas piezas fabricar. Podrías tener un algoritmo de aprendizaje profundo que reconozca si una pieza tiene un defecto e incluso categorice los defectos. Pero eso no necesariamente ayuda si no sabes por qué ocurrió ese defecto. Por lo tanto, tienes que relacionar esa información con unos cuantos algoritmos más para obtener correlaciones que expliquen los defectos, y necesitas un plan de acción para corregir el problema.

## Necesitamos crear conocimientos. ¿Cómo entrenamos nuestros datos?

¿Cómo logramos esto? Básicamente, estás reuniendo todos los datos, preparándolos y vinculándolos para, por ejemplo, cuantificar el suministro y las predicciones de pérdida de rendimiento. Vas a necesitar prácticas de resolución de problemas y mejora continua con el tiempo para enfrentar condiciones cambiantes. Aquí es donde entra en juego la cultura de la organización. Resolver un problema una sola vez, sin un compromiso con la mejora continua, puede hacer que una organización pierda el verdadero valor de realizar análisis a largo plazo.

Estamos presenciando hoy un cambio importante hacia organizaciones con una infraestructura centrada en los datos. Los datos ya no solo se encuentran en el centro de datos, sino también en la nube y en los dispositivos periféricos. Con el proceso empresarial en la cima, llevando a una mejora continua, comprensión empresarial y de datos, y hasta el despliegue, las organizaciones construidas sobre esta infraestructura pueden ver un mundo de diferencia.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
