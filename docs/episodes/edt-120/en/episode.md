---
layout: posts
title: "An Argument for Global Data Networks"
number: 120
permalink: episode-EDT120-en
lang: en
nav_exclude: true
nav_order: 120
tags:
    - clouddatamanagement
    - multicloud

date: 2023-01-26T00:00:00.000Z
guests:
    - Darren W Pulsipher
    - Alan Evans

img: thumbnail.jpeg
image: thumbnail.jpeg
summary: "On this episode Darren interviews Alan Evan, principle technologist at MacroMeta, about distributed data management and the impact of global distribution of data in the cloud to edge ecosystem."
video: "https://youtu.be/url"
description: "On this episode Darren interviews Alan Evan, principle technologist at MacroMeta, about distributed data management and the impact of global distribution of data in the cloud to edge ecosystem."
---

<div>
{% include transistor.html id="90c59b10" title="#120 An Argument for Global Data Networks" %}

{% include youtube.html id="url" %}
</div>

---

Alan Evans is the principal technologist at Macrometa and focuses on bringing Global Data Networks to customers worldwide. As Darren finds out in this interview, his insight into data management and the complexities of data management in global organizations is invaluable. The focus of this interview is to understand the Laws of Edge computing and the characteristics of data that drive these new data architectures.

## Laws of Edge Computing

To effectively deploy edge computing architectures, three laws must be considered: the law of physics, the law of economics, and the law of the land.

### Law of Physics

The law of physics refers to the distance between edge devices and their corresponding on-prem and cloud data centers. The fact is that data currently cannot travel faster than the speed of light, which introduces latency in the movement of data from edge devices into the cloud or data center. Sometimes this latency does not affect the analytics and insight demanded by organizations’ use cases. However, there are some use cases where real-time data analytics and understanding are critical.

### Law of Economics

the following law is the law of economics, not all network, storage, and computing devices are created equal. Typically better performance devices cost more money, but how much money to spend is determined by the value of the movement of the data and the insight gained from collective analytics. Some organizations are finding additional costs in the direction of data in cloud technology. While ingress costs are typically free egress costs, moving data out of the cloud or from one region to another is costly. Understanding the economics behind edge computing is critical when developing distributed data architectures.

## Law of the Land

The last law to consider, the law of the land, is primarily regulated by local, regional, and country governments that want to protect the privacy of their citizens, industries, or government operations. Understanding the regulations around data generated at the edge and the governance around accessibility, distribution, and storage must be considered. Ignoring the law of the land concerning data can be costly through fines, re-architecture, and complex solutions.

## Data Characteristics

Understanding the laws of the land is the first aspect to consider. However, understanding data characteristics are just as important as understanding the operating rules they must adhere to when building business insight. These characteristics include data size, frequency, storage location, type, privacy and access regulations, and spoilage.

### Data Size

Traditional data warehouses require the data to be in the exact location, meaning all data needs to be moved or copied to the data center or cloud location. The data is also normalized based on the analysis performed. Because the raw data can be used to solve multiple business problems, a copy of the information is required. Data duplication is multiplied when organizations create different data warehouses for business problems they are trying to solve. This increases data size, driving up storage costs and administration.

### Data Frequency

Because data is constantly being generated, it is critical to understand the generation rate. With the number of different data sources generating increasing volumes of data, it is essential to catalog its frequency and volume. Organizations This impacts how the data is collected, stored, and processed.

### Data Source Location

The location of the data generation--machine, human, or software—is another critical driving factor for data analysis architectures. As the number of source locations increases, the architecture becomes more complex. Additionally, the location and the connectivity of the data source, combined with the volume and frequency of data generation, drive architectural data decisions.

### Type of Data

Data sources generate databases, video, audio, emails, texts, and reports. This data can be grouped into three categories: structured, unstructured, and semi-structured—these characterizations aid in processing the data and impact the type of data architecture used. Additional groups can be made within different categories of data to increase reusability, understanding, and, ultimately, insight into the data. Developing a data taxonomy is critical in building a robust data architecture that generates real business value.

### Privacy and Access

Governments and industries are increasingly regulating data privacy to protect the privacy of their citizens, patients, and customers. Understanding and adhering to the data regulations include who has access to the data, what can be done, and how long it must be stored. Several regulations focus on the location of data, healthcare patient data, financial data, and payment information. The National Institute of Science and Technology (NIST) documents key privacy and access controls used for compliance with regulations.

### Data Spoilage

Three factors slow down business decisions due to increasing data’s time to value—time to identify the data sources, collect the data, and normalize and clean the data. In the past, all of an organization’s data resided in the data center. Adopting IoT, cloud, and remote work technologies have scattered data to several locations, including workers’ homes, the cloud, and the edge. Gathering data into one place to perform data analysis takes time and increases the time to produce value for an organization.

## Call to action

Now that you've been armed with the laws of edge computing and the characteristics of data, explore different data 
architectures that meet your needs and help you build genuine business and mission insight from your data. For more information and a white paper, check out the links on our blog. Embracingdigital.org. 


<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
