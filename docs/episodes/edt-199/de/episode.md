---
layout: posts
title: "Cyber Verteidiger: Schutz von GenAI gegen aufkommende Bedrohungen"
number: 199
permalink: episode-EDT199-de
lang: de
nav_exclude: true
nav_order: 199
tags:
    - ai
    - cybersecurity
    - artificialintelligence
    - zerotrust
    - technology
    - people
    - process
    - policy

date: 2024-05-07T07:00:00.000Z
guests:
    - Darren W Pulsipher
    - Chris Sestito

img: thumbnail.jpg
image: thumbnail.jpg
summary: "In dieser Folge wird Darren vom Gast Chris Sestito, CEO von Hiddenlayer, begleitet, während wir die Schwachstellen aufdecken, die unsere digitale Zukunft bedrohen, und innovative Lösungen zur Absicherung von KI-Systemen vor Ausbeutung und Missbrauch erkunden."
video: "https://youtu.be/3nzQK2I3yEU"
description: "In dieser Folge wird Darren vom Gast Chris Sestito, CEO von Hiddenlayer, begleitet, während wir die Schwachstellen aufdecken, die unsere digitale Zukunft bedrohen, und innovative Lösungen zur Absicherung von KI-Systemen vor Ausbeutung und Missbrauch erkunden."
---

<div>
{% include transistor.html id="97572d30" title="#199 Cyber Defenders: Safeguarding GenAI Against Emerging Threats" %}

{% include youtube.html id="3nzQK2I3yEU" %}
</div>

---

KI-Technologien erregen erhebliche Aufmerksamkeit für ihr transformatives Potenzial in mehreren Branchen. Dieser rasche technologische Fortschritt ebnet jedoch auch den Weg für neue und einzigartige Schwachstellen. Ungechützte KI-Modelle stellen eine andere Art von Sicherheitsrisiko dar, das nicht von herkömmlichen Cybersicherheitsmaßnahmen abgedeckt wird. Vorfälle wie der Diebstahl von maschinellen Lernmodellen zeigen die einzigartigen Bedrohungen, denen KI-Systeme ausgesetzt sind, und unterstreichen die Notwendigkeit entwickelter Cybersicherheitsmaßnahmen für die KI.

## Die Entwicklung von Cybersicherheitsmaßnahmen für KI

Die herkömmliche Cybersicherheit konzentriert sich überwiegend auf den Schutz der Infrastruktur, um die Daten zu sichern. Obwohl dies für traditionelle Computersysteme effektiv ist, übersieht dieser Ansatz kritische Schwachstellen in AI-Modellen, insbesondere in generativen Modellen und solchen, die auf bestärkendem Lernen basieren. AI-Technologien wurden schnell in verschiedenen Sektoren übernommen, was die Dringlichkeit für die Cybersicherheit erhöht, Schritt zu halten.

Der freie und uneingeschränkte Austausch von KI-Modellen heute entspricht den Anfangstagen des Internets. In der heutigen strengen Cybersicherheitsumgebung sorgen Verschlüsselung, strenge Zugriffsberechtigungen und digitale Signaturen für die Sicherheit unserer Daten. KI-Modelle jedoch, die ähnlich wie der Austausch und die Ausführung von Code funktionieren, bleiben hinsichtlich der Sicherheit weitgehend unbeachtet. KI-Plattformen wie Hugging Face beispielsweise, beherbergen zahlreiche KI-Modelle, die leicht heruntergeladen und verwendet werden können, oft ohne ernsthafte Überlegungen zu potenziellen Sicherheitsimplikationen.

## Die aufkommende Bedrohungslandschaft in der KI

KI-Modelle und maschinelle Lernsysteme werden schnell zu bedeutenden Akteuren im Bereich der Cybersicherheit. Die Bedrohungen reichen von bösartigem Code, der innerhalb der Modellgewichte versteckt ist, bis hin zu einfacheren Taktiken wie dem Anhängen eines Coin Miners. Diese Modelle sind attraktive Ziele für Cyber-Bedrohungsschauspieler geworden, was die dringende Notwendigkeit für einen weiterentwickelten Ansatz in der Cybersicherheit unterstreicht.

Die sogenannte Prompt Injection ist eine Technik, die gewaltige Bedrohungen für die Datencommunity darstellt. Diese Technik manipuliert ein KI-Modell, um Informationen über seine eigentliche Funktion hinaus zu liefern. Zum Beispiel könnte ein Modell, das angewiesen wurde, eine Geschichte zu schreiben, dazu getäuscht werden, Netzwerkzugriffe preiszugeben. Die Offenlegung solch sensibler Daten kann zu schwerwiegenden Folgen führen, insbesondere in Branchen wie der Finanzbranche, in der die Enthüllung von Kundendaten oder IP-Adressen illegale Aktivitäten wie Datendiebstahl erleichtern könnte.

KI-Modelle können Daten 'halluzinieren', aber dies ist nicht Teil ihrer Ausbildung. Wenn inkorrekte Informationen geteilt werden, könnte dies zu Rufschädigung und rechtlichen Problemen für Unternehmen führen, insbesondere in Sektoren wie dem Gesundheitswesen. Die Lösung besteht darin, Modelle vom Internet zu isolieren, um die Angriffsfläche zu verkleinern und AI-fokussierte Cybersicherheitsplattformen wie Hidden Layer zu nutzen, die das Verhalten von Modellen analysieren können um potenzielle Bedrohungen während der Ausbildung und Laufzeitoperationen zu identifizieren.

## Wachsam bleiben

Das Aufkommen der KI hat die potenzielle Angriffsfläche für die Cybersicherheit vergrößert. Die Erkennung von KI-zentrierten Bedrohungen und die Einbeziehung dieser sich schnell entwickelnden Technologien ist das unmittelbare Erfordernis der Stunde. Der umfassende Schutz von KI-Modellen ist von entscheidender Bedeutung und Unternehmen müssen mögliche Schlupflöcher für unbefugten Datenzugriff und Missbrauch berücksichtigen.

Der Weg nach vorn besteht darin, Cybersicherheit und KI von der Entwicklung bis zur Bereitstellung zu verbinden. Wenn dies nicht geschieht, können verschiedene Organisationen und ihre wertvollen Daten einzigartigen Bedrohungen ausgesetzt sein, die herkömmliche Cybersicherheitsmaßnahmen möglicherweise nicht ausreichend bekämpfen können. Die Schnittstelle von KI und Cybersicherheit ist mehr als eine technologische Notwendigkeit - es ist ein zwingender Schritt, um eine sicherere und sicherere digitale Zukunft zu gewährleisten.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
