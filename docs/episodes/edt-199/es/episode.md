---
layout: posts
title: "Defensores Cibernéticos: Protegiendo a GenAI contra Amenazas Emergentes"
number: 199
permalink: episode-EDT199-es
lang: es
nav_exclude: true
nav_order: 199
tags:
    - ai
    - cybersecurity
    - artificialintelligence
    - zerotrust
    - technology
    - people
    - process
    - policy

date: 2024-05-07T07:00:00.000Z
guests:
    - Darren W Pulsipher
    - Chris Sestito

img: thumbnail.jpg
image: thumbnail.jpg
summary: "En este episodio, Darren está acompañado por el invitado Chris Sestito, CEO de HiddenLayer, mientras descubrimos las vulnerabilidades que amenazan nuestro futuro digital y exploramos soluciones innovadoras para proteger los sistemas de IA de la explotación y el mal uso."
video: "https://youtu.be/3nzQK2I3yEU"
description: "En este episodio, Darren está acompañado por el invitado Chris Sestito, CEO de HiddenLayer, mientras descubrimos las vulnerabilidades que amenazan nuestro futuro digital y exploramos soluciones innovadoras para proteger los sistemas de IA de la explotación y el mal uso."
---

<div>
{% include transistor.html id="97572d30" title="#199 Cyber Defenders: Safeguarding GenAI Against Emerging Threats" %}

{% include youtube.html id="3nzQK2I3yEU" %}
</div>

---

Las tecnologías de IA atraen una atención significativa por su potencial transformador en múltiples industrias. Sin embargo, este rápido avance tecnológico también allana el camino para nuevas y únicas vulnerabilidades. Los modelos de IA, si no están protegidos, exponen un tipo diferente de turbulencia de seguridad que no está cubierta por las medidas tradicionales de ciberseguridad. Incidentes como el robo de modelos de aprendizaje automático ilustran las amenazas únicas que enfrentan los sistemas de IA, lo que aumenta la necesidad de desarrollar medidas de ciberseguridad específicas para la IA.

## La Evolución de las Medidas de Ciberseguridad para la IA

La ciberseguridad convencional se centra predominantemente en proteger la infraestructura para salvaguardar los datos. Aunque es eficaz para los sistemas de computación tradicionales, este enfoque pasa por alto vulnerabilidades críticas en los modelos de Inteligencia Artificial, especialmente los modelos generativos y aquellos que implican aprendizaje por refuerzo. Las tecnologías de IA han sido adoptadas rápidamente en diversos sectores, aumentando la urgencia de que la ciberseguridad siga el ritmo.

El intercambio libre y sin verificación de modelos de IA actualmente se asemeja a los primeros días de internet. En el estricto entorno actual de ciberseguridad, la encriptación, los permisos de acceso estrictos y las firmas digitales garantizan la seguridad de nuestros datos. Sin embargo, los modelos de IA, que funcionan de forma similar al intercambio y ejecución de código, a menudo pasan desapercibidos en términos de seguridad. Plataformas de IA como Hugging Face, por ejemplo, albergan numerosos modelos de IA que se pueden descargar y utilizar fácilmente, a menudo sin considerar seriamente las posibles implicaciones de seguridad.

## El Paisaje Emergente de Amenazas en la IA

Los modelos de IA y los sistemas de aprendizaje automático se están convirtiendo rápidamente en actores significativos en la arena de la ciberseguridad. Las amenazas van desde código malicioso oculto dentro de los pesos del modelo hasta tácticas más simples como adjuntar un minero de monedas. Estos modelos se han convertido en objetivos atractivos para los actores de amenazas cibernéticas, destacando la necesidad urgente de un enfoque de ciberseguridad evolucionado.

La Inyección de Prompts es una técnica que representa grandes amenazas para la comunidad de datos. Esta técnica manipula un modelo de IA para proporcionar información más allá de su función diseñada. Por ejemplo, un modelo instruido para "escribir una historia" podría ser engañado para revelar el acceso a la red. La divulgación de datos tan sensibles puede tener consecuencias graves, especialmente en industrias como la financiera, donde la exposición de datos de cuentas de clientes o direcciones IP podría facilitar actividades ilícitas como el robo de datos.

Los modelos de IA pueden "alucinar" datos, pero esto no forma parte de su entrenamiento. Si se comparte información incorrecta, podría llevar a daños a la reputación y problemas legales para las empresas, particularmente en sectores como el de la salud. La solución reside en aislar los modelos de internet para reducir la superficie de ataque y usar plataformas de ciberseguridad centradas en IA, como Hidden Layer, que pueden analizar el comportamiento del modelo para identificar amenazas potenciales durante el entrenamiento y las operaciones en tiempo real.

## Manteniendo la Vigilancia

La llegada de la IA ha aumentado la superficie potencial de ataque para la ciberseguridad. Reconocer las amenazas centradas en la IA e incluir estas tecnologías en rápida evolución es la necesidad inmediata de la hora. La protección integral de los modelos de IA es crucial y las empresas deben considerar las posibles lagunas para el acceso no autorizado a los datos y su mal uso.

El camino a seguir implica unir la ciberseguridad y la inteligencia artificial desde el desarrollo hasta la implementación. No hacerlo puede exponer a diversas organizaciones y sus valiosos datos a amenazas únicas que las medidas de ciberseguridad tradicionales podrían no combatir adecuadamente. La intersección de la inteligencia artificial y la ciberseguridad es más que una necesidad tecnológica, es un paso imprescindible para garantizar un futuro digital más seguro y protegido.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
