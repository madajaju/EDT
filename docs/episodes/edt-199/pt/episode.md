---
layout: posts
title: "Ciber Defensores: Protegendo o GenAI contra Ameaças Emergentes"
number: 199
permalink: episode-EDT199-pt
lang: pt
nav_exclude: true
nav_order: 199
tags:
    - ai
    - cybersecurity
    - artificialintelligence
    - zerotrust
    - technology
    - people
    - process
    - policy

date: 2024-05-07T07:00:00.000Z
guests:
    - Darren W Pulsipher
    - Chris Sestito

img: thumbnail.jpg
image: thumbnail.jpg
summary: "Neste episódio, Darren é acompanhado pelo convidado Chris Sestito, CEO da HiddenLayer, enquanto descobrimos as vulnerabilidades que ameaçam nosso futuro digital e exploramos soluções inovadoras para proteger sistemas de IA de exploração e mau uso."
video: "https://youtu.be/3nzQK2I3yEU"
description: "Neste episódio, Darren é acompanhado pelo convidado Chris Sestito, CEO da HiddenLayer, enquanto descobrimos as vulnerabilidades que ameaçam nosso futuro digital e exploramos soluções inovadoras para proteger sistemas de IA de exploração e mau uso."
---

<div>
{% include transistor.html id="97572d30" title="#199 Cyber Defenders: Safeguarding GenAI Against Emerging Threats" %}

{% include youtube.html id="3nzQK2I3yEU" %}
</div>

---

As tecnologias de IA atraem atenção significativa pelo seu potencial transformador em diversas indústrias. No entanto, esse rápido avanço tecnológico também abre caminho para novas e únicas vulnerabilidades. Modelos de IA, se desprotegidos, expõem um tipo diferente de turbulência de segurança não coberta pelas medidas tradicionais de cibersegurança. Incidentes como o roubo de modelos de aprendizado de máquina destacam as ameaças únicas que os sistemas de IA enfrentam, escalando a necessidade de medidas desenvolvidas de cibersegurança para IA.

## A evolução das medidas de segurança cibernética para IA

A cibersegurança convencional concentra-se predominantemente na proteção da infraestrutura para salvaguardar os dados. Embora eficaz para sistemas de computador tradicionais, essa abordagem ignora vulnerabilidades críticas em modelos de IA, especialmente modelos generativos e aqueles que envolvem aprendizado por reforço. As tecnologias de IA têm sido adotadas rapidamente em vários setores, aumentando a urgência para que a cibersegurança acompanhe esse ritmo.

A livre e irrestrita troca de modelos de IA hoje paraleliza os primeiros dias da internet. No rigoroso ambiente de segurança cibernética de hoje, criptografia, permissões de acesso rigorosas e assinaturas digitais protegem nossos dados. No entanto, os modelos de IA, que funcionam de maneira semelhante à troca e execução de código, geralmente permanecem negligenciados em relação à segurança. Plataformas de IA como Hugging Face, por exemplo, hospedam vários modelos de IA que são facilmente baixados e usados, muitas vezes sem ponderação séria sobre as possíveis implicações de segurança.

## A Ameaça Emergente na Paisagem da IA

Modelos de IA e sistemas de aprendizado de máquina estão rapidamente se tornando participantes significativos na arena da cibersegurança. As ameaças variam desde códigos maliciosos escondidos dentro dos pesos do modelo até táticas mais simples, como anexar um minerador de moedas. Esses modelos emergiram como alvos atraentes para os atores de ameaças cibernéticas, enfatizando a necessidade urgente de uma abordagem de cibersegurança evoluída.

A Injeção de Prompt é uma técnica que apresenta grandes ameaças à comunidade de dados. Esta técnica manipula um modelo de IA para fornecer informações além de sua função projetada. Por exemplo, um modelo instruído para "escrever uma história" pode ser enganado a divulgar acesso à rede. A divulgação de dados tão sensíveis pode resultar em graves consequências, especialmente em indústrias como a financeira, onde a exposição de dados de contas de clientes ou endereços IP poderiam facilitar atividades ilícitas como roubo de dados.

Modelos de IA podem "alucinar" dados, mas isso não faz parte de seu treinamento. Se informações incorretas forem compartilhadas, isso poderia levar a danos à reputação e problemas legais para as empresas, particularmente em setores como a saúde. A solução está em isolar os modelos da internet para reduzir a superfície de ataque e usar plataformas de cibersegurança focadas em IA, como a Hidden Layer, que podem analisar o comportamento do modelo para identificar ameaças potenciais durante o treinamento e as operações em tempo real.

## Permanecendo Vigilante

A chegada da IA aumentou a superfície potencial de ataque para a segurança cibernética. Reconhecer ameaças centradas na IA e incluir essas tecnologias em rápida evolução é a necessidade imediata da hora. A proteção abrangente dos modelos de IA é crucial e as empresas devem considerar potenciais lacunas para acesso não autorizado a dados e mau uso.

O caminho a seguir envolve combinar a cibersegurança e a IA desde o desenvolvimento até a implementação. A falha em fazer isso pode expor várias organizações e seus dados valiosos a ameaças únicas que as medidas tradicionais de cibersegurança podem não combater adequadamente. A intersecção da IA e da cibersegurança é mais do que uma necessidade tecnológica - é um passo imperativo para garantir um futuro digital mais seguro e protegido.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
