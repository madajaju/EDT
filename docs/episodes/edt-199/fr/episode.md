---
layout: posts
title: "Défenseurs du Cyberespace : Protéger GenAI contre les Menaces Émergentes"
number: 199
permalink: episode-EDT199-fr
lang: fr
nav_exclude: true
nav_order: 199
tags:
    - ai
    - cybersecurity
    - artificialintelligence
    - zerotrust
    - technology
    - people
    - process
    - policy

date: Tue May 07 2024 00:00:00 GMT-0700 (Pacific Daylight Time)
guests:
    - Darren W Pulsipher
    - Chris Sestito

img: thumbnail.jpg
image: thumbnail.jpg
summary: "Dans cet épisode, Darren est rejoint par l'invité Chris Sestito, PDG de HiddenLayer, alors que nous découvrons les vulnérabilités menaçant notre avenir numérique et explorons des solutions innovantes pour protéger les systèmes d'IA contre l'exploitation et l'abus."
video: "https://youtu.be/3nzQK2I3yEU"
description: "Dans cet épisode, Darren est rejoint par l'invité Chris Sestito, PDG de HiddenLayer, alors que nous découvrons les vulnérabilités menaçant notre avenir numérique et explorons des solutions innovantes pour protéger les systèmes d'IA contre l'exploitation et l'abus."
---

<div>
{% include transistor.html id="97572d30" title="#199 Cyber Defenders: Safeguarding GenAI Against Emerging Threats" %}

{% include youtube.html id="3nzQK2I3yEU" %}
</div>

---

Les technologies de l'IA suscitent une attention significative pour leur potentiel transformateur dans de nombreuses industries. Cependant, cette avancée technologique rapide ouvre également la voie à de nouvelles et uniques vulnérabilités. Les modèles d'IA, s'ils ne sont pas protégés, exposent à un type de turbulence de sécurité différent qui n'est pas couvert par les mesures traditionnelles de cybersécurité. Des incidents tels que le vol de modèles d'apprentissage automatique mettent en évidence les menaces uniques auxquelles sont confrontés les systèmes d'IA, intensifiant ainsi le besoin de mesures de cybersécurité de l'IA développées.

## L'évolution des mesures de cybersécurité pour l'IA

La cybersécurité conventionnelle se concentre principalement sur la protection de l'infrastructure pour sauvegarder les données. Bien qu'efficace pour les systèmes informatiques traditionnels, cette approche néglige les vulnérabilités critiques dans les modèles d'IA, en particulier les modèles génératifs et ceux impliquant l'apprentissage par renforcement. Les technologies d'IA ont été rapidement adoptées dans divers secteurs, ce qui augmente l'urgence pour la cybersécurité de suivre le rythme.

L'échange gratuit et non contrôlé de modèles d'IA aujourd'hui est parallèle aux premiers jours d'internet. Dans l'environnement de cybersécurité strict d'aujourd'hui, le cryptage, les permissions d'accès strictes et les signatures numériques sécurisent nos données. Cependant, les modèles d'IA, qui fonctionnent de manière similaire à l'échange et à l'exécution de code, restent largement négligés en matière de sécurité. Des plateformes d'IA comme Hugging Face, par exemple, hébergent de nombreux modèles d'IA qui sont facilement téléchargés et utilisés, souvent sans grande réflexion sur les implications de sécurité potentielles.

## Le Paysage de Menaces Émergentes en IA

Les modèles d'IA et les systèmes d'apprentissage automatique deviennent rapidement des acteurs importants dans le domaine de la cybersécurité. Les menaces vont du code malveillant caché dans les pondérations des modèles à des tactiques plus simples comme l'ajout d'un mineur de pièces. Ces modèles se sont révélés être des cibles attrayantes pour les acteurs de menaces cybernétiques, soulignant le besoin urgent d'une approche de cybersécurité évoluée.

L'injection de prompt est une technique qui représente une menace massive pour la communauté des données. Cette technique manipule un modèle d'IA pour fournir des informations au-delà de sa fonction conçue. Par exemple, un modèle auquel on demande d'"écrire une histoire" pourrait être trompé pour divulguer un accès réseau. La divulgation de ces données sensibles peut entraîner des conséquences graves, en particulier dans des industries comme la finance, où l'exposition de données de comptes clients ou d'adresses IP pourrait faciliter des activités illicites comme le vol de données.

Les modèles d'IA peuvent « halluciner » des données, mais cela ne fait pas partie de leur formation. Si des informations incorrectes sont partagées, cela pourrait nuire à la réputation et entraîner des problèmes juridiques pour les entreprises, en particulier dans des secteurs comme le système de santé. La solution réside dans l'isolation des modèles d'Internet pour réduire la surface d'attaque et l'utilisation de plateformes de cybersécurité axées sur l'IA, comme Hidden Layer, qui peuvent analyser le comportement du modèle pour identifier des menaces potentielles pendant la formation et les opérations d'exécution.

## Rester Vigilant

L'arrivée de l'IA a augmenté la surface d'attaque potentielle pour la cybersécurité. Reconnaître les menaces centrées sur l'IA et inclure ces technologies en constante évolution est le besoin immédiat du moment. La protection complète des modèles de l'IA est cruciale et les entreprises doivent prendre en compte les failles potentielles pour l'accès non autorisé aux données et leur mauvaise utilisation.

La voie à suivre implique de marier la cybersécurité et l'IA, du développement à la mise en œuvre. Le fait de ne pas le faire peut exposer diverses organisations et leurs précieuses données à des menaces uniques que les mesures traditionnelles de cybersécurité ne peuvent pas combattre de manière adéquate. L'intersection de l'IA et de la cybersécurité est plus qu'une nécessité technologique, c'est une étape impérative pour garantir un avenir numérique plus sûr et plus sécurisé.



<details>
<summary> Podcast Transcript </summary>

<p></p>

</details>
