<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!-- Titre de page dynamique -->
        <title>Adopter la Transformation Num√©rique</title>

        <!-- Meta Description pour le SEO -->
        <meta name="description" content="&lt;p&gt;Dans cet √©pisode, Darren parle de la diminution de la congestion d&amp;#39;ingestion en utilisant la m√©moire persistante Optane DC d&amp;#39;Intel et de l&amp;#39;exp√©rience qu&amp;#39;il a men√©e avec des r√©sultats surprenants. Cela pourrait bien changer notre mani√®re de penser √† la programmation √† l&amp;#39;avenir.&lt;/p&gt;
">

        <!-- Mots-cl√©s pour le SEO -->
        <meta name="keywords" content="podcast, ia, edge computing, cybers√©curit√©, transformation num√©rique">

        <!-- Meta Auteur -->
        <meta name="author" content="Darren W Pulsipher">

        <!-- Tags Meta Open Graph pour les R√©seaux Sociaux -->
        <meta property="og:title" content="Adopter la Transformation Num√©rique">
        <meta property="og:description" content="&lt;p&gt;Dans cet √©pisode, Darren parle de la diminution de la congestion d&amp;#39;ingestion en utilisant la m√©moire persistante Optane DC d&amp;#39;Intel et de l&amp;#39;exp√©rience qu&amp;#39;il a men√©e avec des r√©sultats surprenants. Cela pourrait bien changer notre mani√®re de penser √† la programmation √† l&amp;#39;avenir.&lt;/p&gt;
">
        <meta property="og:image" content="thumbnail.png">

        <meta property="og:url" content="https://embracingdigital.org">
        <meta property="og:type" content="website">

        <!-- Tags Meta Twitter Card -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:title" content="Adopter la Transformation Num√©rique">
        <meta name="twitter:description" content="&lt;p&gt;Dans cet √©pisode, Darren parle de la diminution de la congestion d&amp;#39;ingestion en utilisant la m√©moire persistante Optane DC d&amp;#39;Intel et de l&amp;#39;exp√©rience qu&amp;#39;il a men√©e avec des r√©sultats surprenants. Cela pourrait bien changer notre mani√®re de penser √† la programmation √† l&amp;#39;avenir.&lt;/p&gt;
">
        <meta name="twitter:image" content="thumbnail.png">

    <title>Adopter la Transformation Num√©rique</title>

    <link rel="stylesheet" href="../../../css/styles.css">
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-P4XHVE79DL"></script>
    <script> window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-P4XHVE79DL'); </script>
</head>
<body>

<!-- üåç Barre de Navigation -->
<header>
    <div class="logo-container">
        <img src="../../../images/logo.png" alt="Adopter la Transformation Num√©rique" class="site-icon">
    </div>
    <nav>
        <ul>
            <li><a href="../../../fr/home/index.html">Accueil</a></li>
            <li><a href="../../../fr/about.html">√Ä propos</a></li>
            <li><a href="../../../fr/episodes/index.html">Interviews</a></li>
            <li><a href="../../../fr/briefs/index.html">Nouvelles</a></li>
            <li><a href="../../../fr/community.html">Communaut√©</a></li>
            <li><a href="../../../fr/guests/index.html">Invit√©s</a></li>
            <li><a href="https://6704f0-2.myshopify.com/">Boutique</a></li>
            <li><a href="../../../fr/search.html">Recherche</a></li>
            <li class="dropdown">
                <a href="#">Langues</a>
                <ul class="dropdown-menu">
                    <li><a href="../../../ar/home/index.html">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a></li> <!-- Arabe -->
                    <li><a href="../../../de/home/index.html">Deutsch</a></li> <!-- Allemand -->
                    <li><a href="../../../en/home/index.html">English</a></li> <!-- Anglais -->
                    <li><a href="../../../fr/home/index.html">Fran√ßais</a></li> <!-- Fran√ßais -->
                    <li><a href="../../../it/home/index.html">Italiano</a></li> <!-- Italien -->
                    <li><a href="../../../pt/home/index.html">Portugu√™s</a></li> <!-- Portugais -->
                    <li><a href="../../../ja/home/index.html">Êó•Êú¨Ë™û</a></li> <!-- Japonais -->
                </ul>
            </li>
        </ul>
    </nav>
</header>
<section id="one-episode">
    <h1 id="episode-title">#16 R√©duire la congestion d'ingestion avec Intel Optane DCPMM</h1>
    <div class="episode-container">
        <!-- YouTube Video Section -->
        <div class="video-container">
            <iframe width="auto" height="auto" src="https://www.youtube.com/embed/url?autoplay=1" title="Episode Playback"></iframe>
        </div>

        <!-- Podcast Audio Section -->
        <div class="podcast-container">
            <iframe width="100%" height="180" frameborder="no" scrolling="no" seamless="" src="https://share.transistor.fm/e/7ca179aa"></iframe>
        </div>
        <div class="show-summary">
            <p><p>Dans cet √©pisode, Darren parle de la diminution de la congestion d&#39;ingestion en utilisant la m√©moire persistante Optane DC d&#39;Intel et de l&#39;exp√©rience qu&#39;il a men√©e avec des r√©sultats surprenants. Cela pourrait bien changer notre mani√®re de penser √† la programmation √† l&#39;avenir.</p>
</p>

            <!-- Tags Section -->
            <div class="tags">
                
                    <a href="../../../fr/search.html?query=artificialintelligence"><span>artificialintelligence</span></a>
                
                    <a href="../../../fr/search.html?query=machinelearning"><span>machinelearning</span></a>
                
                    <a href="../../../fr/search.html?query=edgecomputing"><span>edgecomputing</span></a>
                
                    <a href="../../../fr/search.html?query=datamanagement"><span>datamanagement</span></a>
                
                    <a href="../../../fr/search.html?query=multicloud"><span>multicloud</span></a>
                
                    <a href="../../../fr/search.html?query=zerotrust"><span>zerotrust</span></a>
                
                    <a href="../../../fr/search.html?query=process"><span>process</span></a>
                
                    <a href="../../../fr/search.html?query=technology"><span>technology</span></a>
                
            </div>

            <!-- Guests Section -->
            <div class="guests">
                
                <a href="../../../fr/guests/darren-w-pulsipher/index.html" target="_blank">Darren W Pulsipher</a>
            </div>
        </div>

        <!-- Show Notes Section -->
        <div class="show-notes">
            <h2>D√©tails de la pile de services</h2>
<p>Un client de l&#39;industrie automobile avait du mal √† obtenir efficacement des informations de leurs voitures et de les transf√©rer vers leur centre de donn√©es afin de pouvoir effectuer de l&#39;apprentissage automatique et des analyses. Des recherches ont √©t√© men√©es dans ce domaine, mais seulement pour un petit nombre de voitures, pas les centaines de millions de voitures du client. Lorsque j&#39;ai examin√© l&#39;ensemble de leur pile de services et la fa√ßon dont tout arrivait au centre de donn√©es, l&#39;ingestion des donn√©es est devenue le probl√®me clair: Comment puis-je ing√©rer autant de donn√©es, et comment le faire rapidement ?</p>
<h2>Pr√©sentation g√©n√©rale de l&#39;architecture Kafka √† haut niveau</h2>
<p>Le client souhaitait utiliser Kafka pour leur ingestion. Kafka est un courtier qui peut bien se mettre √† l&#39;√©chelle, et la cl√© est qu&#39;il peut g√©rer plusieurs producteurs, diff√©rents consommateurs et beaucoup de donn√©es. Utiliser plusieurs courtiers Kafka pour placer et transf√©rer les donn√©es dans les endroits les plus appropri√©s offre une grande flexibilit√©.</p>
<p>Kafka, cependant, a √©t√© principalement con√ßu pour des tailles de message d&#39;environ un √† 10 kilo-octets et les donn√©es du client √©taient d&#39;environ 240 kilo-octets par voiture. Il existe des solutions de contournement, mais je voulais transf√©rer l&#39;int√©gralit√© du message de 240 kilo-octets dans le bus Kafka afin de pouvoir le d√©placer selon mes besoins.</p>
<h2>Pratiques optimales de performance</h2>
<p>J&#39;ai examin√© les meilleures pratiques de performance des autres personnes travaillant avec Kafka pour voir si je pouvais les adapter aux besoins de mon client. Augmenter la taille du tampon pour pouvoir stocker le message en entier est une solution d&#39;ajustement fine, tout comme la gestion de la taille des lots pour des performances optimales. Une autre pratique courante consiste √† disperser les journaux. La flexibilit√© de Kafka me permettrait de placer les donn√©es dans diff√©rents sujets. Je peux diviser ces sujets en plusieurs partitions et les r√©partir sur plusieurs disques. La question est donc de savoir sur combien de disques je r√©partis les journaux de Kafka. De plus, je souhaite les disques les plus rapides possibles.</p>
<p>Un exemple que j&#39;ai examin√© √©tait LinkedIn. Leurs chiffres publi√©s il y a un an indiquent qu&#39;ils peuvent traiter 13 millions de messages par seconde, soit 2,7 gigaoctets par seconde. Ils affirment avoir environ 1 100 courtiers Kafka et plus de 60 sur un cluster, ce qui repr√©sente une configuration plut√¥t importante.</p>
<h2>Espace automobile</h2>
<p>Si je regarde les chiffres bruts du client (1,6 million de messages par seconde et 800 gigaoctets par seconde) et que je les compare √† LinkedIn, qui n&#39;est probablement pas optimis√© pour 240 kilooctets, j&#39;obtiens 44 000 courtiers. Si je l&#39;optimisais, je pourrais probablement r√©duire ce nombre √† 4 400 courtiers, ce qui reste 240 clusters. C&#39;est un nombre √©norme de machines, donc j&#39;ai d√ª trouver un moyen de rendre les choses plus rapides. Avec une optimisation suppl√©mentaire, je pourrais probablement le r√©duire √† 400 √† 500 courtiers, mais je voulais voir ce que je pouvais faire d&#39;autre.</p>
<h2>Intel Optane DC Persistent Memory</h2>
<p>M√©moire persistante Intel Optane DC</p>
<p>J&#39;ai examin√© notre Optane Persistent Memory. Il s&#39;int√®gre au format DDR4, donc il se trouve directement sur le bus DDR4. Il peut atteindre des modules de 512 gigaoctets, donc dans un serveur √† deux sockets, je peux disposer de six t√©raoctets de m√©moire persistante. Je voulais trouver un moyen d&#39;exploiter cette technologie extr√™mement fiable avec des fonctionnalit√©s avanc√©es telles que le chiffrement mat√©riel int√©gr√© pour m&#39;aider √† r√©soudre ce probl√®me.</p>
<h2>Soutien √† la vari√©t√© des applications</h2>
<p>Il existe deux modes de fonctionnement avec cette m√©moire Optane: le mode d&#39;application directe et le mode m√©moire. Le mode m√©moire est simple. Il utilise la m√©moire persistante comme une RAM normale car c&#39;est moins cher que la DDR4 normale. Ce n&#39;est pas exactement la m√™me chose que la DDR4, mais c&#39;est assez proche pour que dans la plupart des applications, on ne puisse pas voir de diff√©rence. En mode d&#39;application directe, vous pouvez r√©ellement √©crire depuis votre programme directement dans la m√©moire persistante. De cette fa√ßon, je n&#39;ai pas besoin de marshalliser et d√©marshaser les structures de donn√©es et de les diffuser en continu; je peux simplement les pousser dans la m√©moire persistante. Je peux √©galement monter le mode d&#39;application directe en tant que syst√®me de fichiers, ce qui est beaucoup plus rapide que sur le bus d&#39;E/S. Maintenant, que puis-je faire avec cette m√©moire?</p>
<h2>Utilisation du noyau Linux</h2>
<p>Il existe deux outils principaux disponibles en utilisant le noyau Linux : ndctl et ipmctl. Ndctl est un contr√¥leur de p√©riph√©rique de m√©moire non volatile, et puis il y a IPM, le contr√¥leur de la m√©moire persistante Intel, qui me permet de manipuler et de contr√¥ler cette m√©moire persistante. Je peux le configurer en mode m√©moire ou en mode d&#39;application directe. J&#39;ai d√ª apprendre un peu sur ces outils et comment ils fonctionnent.</p>
<h2>Approche d&#39;ingestion</h2>
<p>Ma premi√®re pens√©e a √©t√© que si je donnais √† Kafka beaucoup plus de m√©moire avec de grandes tailles de tampon, il devrait fonctionner beaucoup plus rapidement. Les modifications de code dans la configuration seraient inutiles ou minimes. Une autre option √©tait de changer Kafka pour √©crire dans une m√©moire persistante plut√¥t que d&#39;√©crire dans un syst√®me de fichiers, en contournant le disque dur. La derni√®re chose que j&#39;ai examin√©e √©tait la cr√©ation d&#39;un syst√®me de fichiers persistant utilisant une m√©moire persistante, puis de placer les journaux de Kafka sur ce nouveau syst√®me de fichiers.</p>
<p>La plus facile des trois options √©tait la premi√®re - plus de m√©moire. J&#39;ai ex√©cut√© toutes mes t√¢ches avec plus de m√©moire et il n&#39;y a eu aucun changement de performance. La raison en est qu&#39;√† un moment donn√©, mes tampons se sont remplis et j&#39;ai d√ª les transf√©rer vers un disque. Au final, tout devait passer par les journaux Kafka, ce qui constituait mon goulot d&#39;√©tranglement.</p>
<p>La deuxi√®me option implique la r√©√©criture du code et l&#39;attente des approbations, alors j&#39;ai saut√© √† la troisi√®me option. Les r√©sultats de cette exp√©rience, o√π j&#39;ai dirig√© les journaux vers ce nouveau syst√®me de fichiers ultra-rapide, √©taient fascinants. Jetons un coup d&#39;≈ìil au processus et aux r√©sultats.</p>
<h2>Contraintes de test</h2>
<p>Pour √©liminer les obstacles √† la performance des tests, j&#39;ai exclu le r√©seau de l&#39;√©quation en ex√©cutant mon test sur la m√™me machine que celle sur laquelle √©tait mon courtier. De plus, j&#39;ai d&#39;abord ex√©cut√© uniquement les producteurs, puis uniquement les consommateurs, puis un m√©lange des deux, afin de pouvoir √©valuer les diff√©rences. Mon objectif n&#39;√©tait pas de regarder l&#39;am√©lioration totale de la production, mais de voir si ce disque aurait vraiment un impact sur un courtier individuel.</p>
<h2>Premi√®re approche 50/50</h2>
<p>La premi√®re chose que j&#39;ai faite a √©t√© de prendre la moiti√© de ma m√©moire persistante et de la mettre en mode app direct, puis de la convertir en syst√®me de fichiers. J&#39;ai laiss√© l&#39;autre moiti√© en tant que m√©moire. J&#39;ai utilis√© les commandes ndctl et ipmctl et cr√©√© des espaces de noms. J&#39;ai mont√© ces syst√®mes de fichiers et ex√©cut√© mon test.</p>
<h2>Modifier la taille du message</h2>
<p>J&#39;ai ex√©cut√© les tests sur plusieurs tailles de messages diff√©rentes. Je m&#39;attendais √† certaines optimisations, principalement pour 1 kilo-octet. J&#39;ai constat√© que j&#39;obtenais des performances de plus en plus √©lev√©es jusqu&#39;√† environ 10 producteurs. Au-del√† de 10 producteurs, j&#39;ai commenc√© √† saturer le bus et √† observer une certaine variabilit√©. Cela me dit que j&#39;avais mis en cache des √©l√©ments. Je peux maintenant comparer ces chiffres √† ce que j&#39;ai ex√©cut√© auparavant uniquement sur un lecteur SATA pour les journaux Kafka. J&#39;ai √©galement essay√© nos lecteurs Optane NVMe pour les journaux.</p>
<h2>Comparaison des technologies</h2>
<p>Jetons un coup d&#39;≈ìil aux diff√©rences. Pour 240 kilo-octets, avec un disque SATA normal, c&#39;est plut√¥t plat. J&#39;ai obtenu une l√©g√®re am√©lioration, puis √ßa a diminu√© √† mesure que le nombre de producteurs augmentait. Avec le disque Optane NVMe, j&#39;ai eu un pic impressionnant, presque deux fois plus rapide qu&#39;un disque SATA, ce √† quoi je m&#39;attendais car c&#39;est un bus NVMe au lieu d&#39;un bus SATA. Le Pmem est presque cinq fois plus rapide qu&#39;un disque SATA et deux fois et demie plus rapide que le disque Optane NVMe. C&#39;est parce que j&#39;utilise un bus de m√©moire au lieu du bus SATA ou NVMe.</p>
<h2>Optimisation suppl√©mentaire (100% directement dans l&#39;application)</h2>
<p>Cela fonctionnait rapidement et je remplissais rapidement ce disque temporaire de 750 Go. Comme j&#39;avais besoin de prolonger un peu le test, je suis retourn√© et j&#39;ai reconfigur√© ma machine pour passer en mode d&#39;application directe √† 100 pour cent, afin de pouvoir prendre maintenant l&#39;int√©gralit√© des 1,5 t√©raoctets.</p>
<h2>PMEM optimis√© et 100% App Direct</h2>
<p>Apr√®s avoir fait cela et ex√©cut√© les m√™mes tests, j&#39;ai obtenu un r√©sultat surprenant. J&#39;ai pu ajouter plus de producteurs et mon d√©bit a augment√© d&#39;environ deux ou trois fois de plus. Maintenant, il est entre 12 et 15 fois plus rapide qu&#39;un disque SATA avec 25 √† 30 producteurs et une taille de message de 240 kilooctets. C&#39;est incroyable et cela r√©duirait consid√©rablement le besoin de nos clients en termes de courtiers, de rang√©es et de machines. J&#39;ai fait le test plusieurs fois car je ne croyais pas les r√©sultats que j&#39;obtenais. J&#39;ai appel√© l&#39;un de nos architectes qui a con√ßu cette technologie et j&#39;ai appris qu&#39;une des raisons de l&#39;augmentation de la vitesse √©tait que lorsque j&#39;utilisais une partie de la m√©moire persistante comme m√©moire, les donn√©es devaient passer par deux ou trois sauts qui ne sont pas n√©cessaires en mode app direct. Cela cr√©e moins de contention sur le bus de la m√©moire et le d√©bit a augment√© de mani√®re spectaculaire.</p>
<h2>Appel √† l&#39;action</h2>
<p>Le r√©sultat final est que j&#39;ai pu utiliser Kafka avec la m√©moire persistante Optane DC comme un syst√®me de fichiers ultra-rapide pour obtenir d&#39;importantes am√©liorations de d√©bit √† la fois pour les producteurs et les consommateurs. Un courtier unique peut g√©rer 15 fois plus de messages et de d√©bit qu&#39;auparavant, r√©duisant ainsi le nombre de serveurs n√©cessaires pour g√©rer des architectures syst√®me larges et complexes. Il est temps d&#39;√©valuer votre architecture actuelle et de voir si cela serait b√©n√©fique pour votre organisation.</p>

        </div>
    </div>
</section>
<footer id="footer">
    <div class="footer-content">
        <p>Droit d'auteur &copy; 2025 Paidar Productions LLC</p>
        <p>Tous droits r√©serv√©s</p>
    </div>
</footer>
