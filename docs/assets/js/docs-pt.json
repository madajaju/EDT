[{"id":0,"type":"Episode","title":"História da Arquitetura Orientada a Dados.","tags":["dataarchitecture","softwaredeveloper","microservice","container","virtualization","technology","compute","data"],"body":"\r\n\r\nNeste episódio, Darren fala sobre a história das aplicações e como mudanças recentes, principalmente devido ao avanço.\n\ntranslate this sentence to Portuguese: \"de dados da Internet das Coisas está afetando arquiteturas centradas em dados. A infraestrutura está pronta, mas nós não\"\n\nAinda não temos uma maneira adequada de gerenciar todos os nossos dados. Existem três elementos que precisam ser alterados para facilitar esse processo:\n\nis stored, processed, and transmitted.\n\ne as computações estão distribuídas por milhares de dispositivos periféricos e entre nuvens públicas e privadas.\n\n## Pilhas de hardware-software projetadas com finalidade específica\n\nComo implantamos aplicativos para missões hoje em dia não mudou significativamente nos últimos trinta anos. Uma arquitetura de referência.\n\nque possui uma aplicação e uma pilha de aplicativos construída em hardware específico, com computação e armazenamento conectados a\n\nTradução: rede. Este modelo funcionou bem por muito tempo e, na verdade, cerca de um quarto das aplicações ainda estão sendo implementadas.\n\nhardware construído de propósito, mas não é ótimo hoje. A tecnologia se desenvolve muito rápido para esse modelo; ocorrem desvios.\n\nalém disso, há longos tempos de desenvolvimento, altos custos, uso limitado da tecnologia e falta de integração com\n\noutras aplicações.\n\n## Arquiteturas de virtualização\n\nHá cerca de 20 a 25 anos, a virtualização de hardware começou a resolver alguns desses problemas com a capacidade de implementação.\n\nAplicações múltiplas em uma máquina. As aplicações não estavam mais presas a hardware específico. Em vez de comprar cinco.\n\nmáquinas menores, uma peça de hardware maior poderia ser usada, não apenas para computação, mas também para armazenamento virtual e rede.\n\nfunções também, levando a uma maior relação custo-eficácia. Como qualquer desenvolvimento, isso levantou algumas questões novas.\n\npreocupações crescentes com segurança e \"vizinhos barulhentos\", significando que uma aplicação interfere no desempenho de outra.\n\ndevido ao uso excessivo de largura de banda de E/S, rede ou armazenamento, etc.\n\n## Arquiteturas em Nuvem\n\nNo início dos anos 2000, a tecnologia em nuvem decolou. Agora podíamos compartilhar entre várias organizações. Onde a virtualização.\n\ntraduzir o seguinte para português: criou a abstração do hardware, a tecnologia em nuvem criou a abstração das operações, facilitando a gestão de múltiplas.\n\nexecutar various virtual machines.\n\ndiminuição dos recursos de computação, armazenamento e rede. Outros benefícios incluem a redução dos custos de CapEx e OpEx, devido a menos.\n\nTranslate the following to Portuguese: hardware and manpower. It also gave bursting ability, for example, for retailers during the busy holiday season or the\n\ngoverno durante o censo. Com a progressão dessa tecnologia, as questões de segurança e vizinhos barulhentos.\n\nprivado. Aumentou devido a vários inquilinos na mesma máquina. Outra preocupação são os custos de integração entre público e privado.\n\nnuvens privadas. Mesmo com essas preocupações, no entanto, os benefícios superam em muito as desvantagens na maioria dos casos.\n\n## Arquiteturas de Serviço e Contêiner.\n\nNos últimos cinco a seis anos, vimos a reinvenção de uma tecnologia antiga: a containerização. O Docker criou uma plataforma que revolucionou a maneira como os aplicativos são desenvolvidos, empacotados e implantados. Os contêineres permitem que os desenvolvedores isolem seus aplicativos em ambientes consistentes e portáteis, garantindo que funcionem perfeitamente em qualquer infraestrutura. Além disso, a tecnologia de contêiner simplifica o processo de implantação e escalabilidade, permitindo que as empresas respondam rapidamente às demandas dos clientes. Essa inovação transformou o desenvolvimento de software e continua a moldar o futuro da computação.\n\ngeral, procuram uma maneira mais fácil de utilizar a tecnologia de contêiner, que antes era difícil de usar e complicada.\n\nTranslate the following to Portuguese: particular, embraced this technology because it is consistent across multiple environments. The service management layer\n\nTraduza o seguinte para o português: em particular, adotou esta tecnologia porque é consistente em vários ambientes. A camada de gerenciamento de serviços\n\ncom a containerização de aplicações e microsserviços, o foco está mais voltado para a aplicação e mapeia essas aplicações para...\n\nhardware genérico virtualizado que foi abstraído. Agora temos implantação automática em várias nuvens\n\nwe’ve implemented redundancy measures to ensure continuous operations and minimize downtime.\n\ntranslations, and deploy security policies using a single platform.\n\nmicro-segmentação etc ... tudo por meio de software.\n\nSegurança, no entanto, é uma preocupação principal. Como os contêineres são fáceis de implantar em vários ambientes, eles são susceptíveis de terem vulnerabilidades que precisam ser abordadas. Além disso, é importante garantir que os contêineres sejam protegidos contra ataques e que todas as medidas necessárias sejam tomadas para manter a integridade e confidencialidade dos dados.\n\né importante focar na segurança que é \"integrada\" à implantação. Além disso, há um aumento na complexidade. Aqui,\n\nNós nos afastamos de uma arquitetura de três camadas para uma arquitetura multi-camadas ou até mesmo uma arquitetura de micro-serviços com dezenas de\n\nworking together. Outro problema é onde e como os dados são armazenados e gerenciados. No gerenciamento do serviço.\n\ntradução: camada, armazenamento é um recipiente genérico, que não gerencia os próprios dados.\n\n## Arquiteturas da Internet das Coisas\n\nAgora, quando a Internet das Coisas (IoT) é adicionada a esse ecossistema, o aumento no volume de dados é distribuído entre centenas ou\n\ndevices have limited security protocols, making them vulnerable to cyber threats. Additionally, the sheer volume of devices can overwhelm network resources, causing performance issues. To mitigate these risks, it is important to implement robust security measures and manage network traffic effectively.\n\nOs dispositivos são acessíveis pelo público. Por exemplo, alguém poderia adulterar uma luz de uma cidade inteligente, um semáforo inteligente,\n\nUm drone, ou câmera de segurança. A complexidade dos diferentes dispositivos, sua quantidade e localizações, juntamente com o imenso\n\nquantidade de dados, é enorme.\n\n## Arquiteturas de Gerenciamento de Dados e Informações\n\nComo lidamos com essas questões? As organizações já estão se adaptando para lidar com essa complexidade com novas organizações.\n\ne as posições no gerenciamento de dados. Anteriormente, não havia um lugar para esses casos de uso serem gerenciados, então...\n\nCriamos uma nova camada chave chamada camada de gestão de informações distribuídas. Esta camada gerencia dados em todos os sistemas.\n\ncan provide seamless connectivity and integration across different platforms.\n\npode alocar dinamicamente serviços e aplicativos próximos aos dados, ou vice-versa. Regulamentações e o tamanho considerável dos dados\n\npode limitar a capacidade de movimentar dados para locais centrais, como fazíamos tradicionalmente. Com essa nova arquitetura,\n\nvários modos de operação podem ser utilizados, incluindo análise desagregada, movimentação de dados e movimentação de aplicativos.\n\nMais uma vez, com esta arquitetura expandida, a segurança é de suma importância. A segurança precisa ser executada como um aspecto comum.\n\nAtravés de todas as camadas. Segurança de identidade, o que significa acesso, autorização e autenticação de indivíduos, IOT.\n\nDispositivos, aplicativos, serviços e até mesmo dados são elementos fundamentais. A gestão de identidade inclui criptografia para dados confiáveis.\n\ne dispositivos.\n\n## Conclusão\n\ntranslate the remaining pieces and fit them together. Once complete, the Edgemere architecture will be a cohesive and efficient system.\n\nhave already gone through the process of optimizing how all the different layers of our system work together. However, we still need to focus on optimizing the DIML, as it is the most recent addition to our infrastructure.\n\nEstamos começando a ver start-ups e empresas mais estabelecidas desenvolvendo os casos de uso e os elementos arquitetônicos.\n\nnesta camada.\n\nA arquitetura Edgemere ajuda a identificar as principais partes móveis de um sistema moderno transformado digitalmente e como elas se relacionam.\n\nencaixar\n\nA Intel se encaixa nesse ecossistema fornecendo o elemento-chave de uma camada física comum para controlar e gerenciar todos os seus sistemas.\n\nacessar recursos, seja um dispositivo de Internet das Coisas (IoT), em um centro de dados ou em um local remoto. Nós tornamos possível para você acessar esses recursos.\n\nmover os dados de forma eficiente, armazená-los de maneira eficaz e processar tudo. Sejam os processadores Xeon de alto\n\nTraduza o seguinte para o português: seja para fins de inferência ou IA na borda com consumo de energia muito baixo, a Intel possui uma pilha completa de hardware físico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT1-pt","image":"./episodes/edt-1/pt/thumbnail.bmp","lang":"pt","summary":"Neste episódio, Darren fala sobre a história das aplicações e como as mudanças recentes, principalmente devido à quantidade de dados provenientes da Internet das Coisas, estão afetando as arquiteturas centradas em dados. A infraestrutura está pronta, mas ainda não temos uma maneira adequada de gerenciar todos os nossos dados. Existem três elementos que precisam mudar para facilitar esse processo: as pessoas (organização), o processo (operação) e a arquitetura (tecnologia). Darren se concentra na arquitetura em que os dados e o processamento estão distribuídos em milhares de dispositivos periféricos e em nuvens públicas e privadas."},{"id":1,"type":"Episode","title":"Dimensionando sua solução VDI para trabalhador remoto.","tags":["telework","remoteworker","process","technology","vdi"],"body":"\r\n\r\n# Título\n\n*Tagline* translates to \"Slogan\" in Portuguese.\n\nResumo aqui.\n\nTraduza o seguinte para o português: ![imagem do episódio](./thumbnail.png)\n\nEpisódio Corpo aqui.\n\n## Média\n\n<video src='url'></video> -> <video src='url'></video>\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Illyse Sheaffer"],"link":"/episode-EDT10-pt","image":"./episodes/edt-10/pt/thumbnail.png","lang":"pt","summary":"Organizações precisam de ajuda na construção de soluções de VDI (Infraestrutura de Desktop Virtual) imediatamente. À medida que os departamentos de TI adicionam licenças de VDI localmente aos seus sistemas atuais, eles precisam estar cientes de que as licenças por si só não resolvem todos os seus problemas."},{"id":2,"type":"Episode","title":"Super-Heróis do Setor Público da Intel","tags":["cybersecurity","multicloud","edge","aiml"],"body":"\r\n\r\nTranslate the following to Portuguese: \"I love you.\"\n\nCameron iniciou sua carreira trabalhando na maior empresa de recrutamento particular. Lá, ele desenvolveu uma paixão pela tecnologia após aprender o PeopleSoft. Isso o levou à oportunidade de ajudar a construir a primeira empresa de computação em nuvem do mundo, UC Center Networking. Ele e seus colegas de trabalho criaram o slogan \"software como serviço\" em 1997, sete ou oito anos antes do termo \"nuvem\" ser cunhado. Ele trabalhou para integradores de sistemas federais como Northrop Grumman e General Dynamics, onde descobriu que era apaixonado por apoiar uma missão. Essa paixão tem impulsionado-o desde que foi CTO na Dell Technologies e agora lidera a equipe do setor público na Intel.\n\nUm dos fatores que levaram Cameron a se juntar à Intel foi o retorno de Pat Gelsinger e a equipe de liderança que ele está construindo, incluindo a adição de Greg Lavender. Cameron acredita que a Intel será revitalizada e continuará inovando sob o comando de Gelsinger. Ele deseja fazer parte do trabalho para trazer a Intel de volta ao seu status como uma marca icônica americana. Ele acredita que há uma cultura de humildade e pessoas que fazem a coisa certa.\n\n## Computação Ubíqua\n\nOs semicondutores estão presentes em tudo: carros, eletrodomésticos, smartphones, computadores, sistemas de saúde, etc. Eles abrangem praticamente todos os mercados setoriais do planeta. Eles melhoram a qualidade de vida das pessoas, até mesmo salvando vidas, através da saúde, segurança nacional e pesquisa científica.\n\nA pandemia de COVID trouxe à luz essa natureza ubíqua devido ao grande número de pessoas que puderam trabalhar em casa e a continuidade da educação online. Ela também ajudou a diminuir a disparidade digital de várias maneiras.\n\n## Conectividade Ubíqua\n\nO silício não pode realizar seu potencial sem estar conectado. A Intel não é apenas uma empresa de chips, mas sim uma empresa com um portfólio completamente interconectado.\n\nExistem momentos em que as coisas estão desconectadas, por exemplo, um combatente em ambiente DDIL, mas eles ainda podem usar o computador localmente para executar a missão. Quando se reconectam, seja por 4G antigo, 5G ou o futuro 6G, eles podem obter informações atualizadas, ou seja, transmissão de dados. No entanto, em um cenário educacional, a interconexão é vitalmente essencial para coisas como transmissão de streaming, conteúdo de vídeo e acesso a dados. Isso é um recurso poderoso.\n\nA pandemia também trouxe um aumento significativo nas comunicações e na tecnologia 5G, já que estudantes e trabalhadores necessitavam dessa conectividade. Isso continua até hoje, mesmo quando os estudantes e trabalhadores estão de volta ao local de trabalho. Enquanto os estudantes podem ter tido acesso periódico aos Chromebooks antes da pandemia, muitos agora têm os seus próprios que podem levar para casa. Infelizmente, ainda há áreas no país e no mundo onde existem lacunas e as pessoas não podem participar da economia digital. Surpreendentemente, fechar a divisão digital nos Estados Unidos não é tão fácil quanto em países em desenvolvimento. Eles podem ultrapassar os Estados Unidos porque investem em 5G e 6G: comunicações não-terrestres.\n\nCameron acredita que a conectividade é igualmente importante para a computação, pois estar conectado com outras pessoas é um dos fundamentos da experiência humana.\n\n## Borda para Nuvem\n\nA base da computação de ponta a nuvem é a computação e interconexão, portanto a Intel desempenha um papel significativo nesse espaço, juntamente com seus parceiros. Da ponta à nuvem, isso aproveita o verdadeiro poder não apenas do silício, mas também do software. Ele cria interoperabilidade. Você pode mover cargas de trabalho com segurança e de forma transparente de um dispositivo de ponta para a nuvem ou para um centro de dados tradicional, utilizando padrões abertos, tecnologias principais e uma estratégia de ponta a nuvem.\n\nPara o futuro previsível, a borda irá dominar porque à medida que as coisas se tornam mais brilhantes, a tecnologia deve ser impulsionada para a borda onde a informação está sendo criada. Em seguida, o processamento pode ocorrer de forma centralizada para mais análises e IA. As coisas só avançarão e a borda se tornará abrangente.\n\n## Inteligência Artificial\n\nOs dados estão em todo lugar agora; os centros de dados não têm paredes. Eles são coletados e até mesmo processados ​​de várias maneiras, como celulares, câmeras, motores industriais, etc... A inteligência artificial trata de tomar decisões inteligentes com base nesses dados diversos.\n\nA Intel tem um dos maiores portfólios de inteligência artificial do mundo, um portfólio extraordinário de software e mais desenvolvedores de software do que muitas empresas de software. A razão é, como Greg Lavender destaca, o software é a alma do silício. Você precisa permitir que ele faça algo e lhe dar vida e propósito. A IA é um excelente exemplo disso.\n\nÀs vezes, as pessoas pensam em IA em termos de robôs, mas existem inúmeros casos práticos de uso. Um exemplo é quando você se perde, você pode imediatamente questionar a Siri ou o Google e, usando o GPS, o serviço irá localizar geograficamente você e encontrar o ponto mais próximo de civilização ou onde quer que você queira ir.\n\nOutro caso de uso prático ocorre no Serviço Postal dos EUA. A próxima geração de veículos de entrega é tão moderna quanto os carros do Google Street View, com sensores mapeando certas coisas. O serviço postal aplica IA a máquinas cinéticas de classificação inteligente e manuseio de correspondências. Eles estão aproveitando a tecnologia para expandir.\n\nDevido à computação ubíqua e comunicações avançadas da Intel, mais dispositivos periféricos estão se tornando inteligentes, e a quantidade de dados que precisa ser transferida da periferia para os centros de dados está diminuindo. Isso ocorre porque algoritmos de inteligência artificial inferem o que você está buscando na periferia. Esse tipo de tecnologia é incorporado diretamente nos CPUs da Intel. Eles também possuem XPUs especializados, processadores neurotróficos, que fazem o mesmo em menor consumo de energia e velocidades mais altas.\n\nParte do poder do que acontece com a Intel e seus parceiros é a habilidade de ter acesso a todas as informações em um formato consumível. No exemplo de se perder e procurar ajuda em seu telefone, você pode estar olhando para algo que assimilou 600 pontos diferentes de dados em um segundo para lhe dar uma resposta simples.\n\n## Os Super-heróis\n\nAs pessoas da Intel e seus parceiros no ecossistema são super-heróis. Os parceiros ajudam a reunir soluções reais, especialmente nesse último momento crítico. A Intel tem um dos melhores ecossistemas para levar soluções ao mercado. E às vezes, essas soluções nem mesmo são trazidas ao mercado, mas são usadas para ajudar a resolver problemas desafiadores na defesa e no setor público.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Cameron Chehreh"],"link":"/episode-EDT100-pt","image":"./episodes/edt-100/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren e Cameron Chehreh, Vice-Presidente e Gerente Geral do Setor Público, Intel, falam sobre os superpoderes da Intel: computação ubiqua, conectividade pervasiva, da borda à nuvem e inteligência artificial."},{"id":3,"type":"Episode","title":"Segurança do Controlador de Rede com Elisity","tags":["networksecurity","cybersecurity","elisity","comms","technology","process"],"body":"\r\n\r\nDana tem trabalhado em redes avançadas há 15 anos. Ele trabalhou com rede definida por software e rede de área ampla, e concentrou-se no mundo da SD-WAN por um tempo. Em seguida, trabalhou com nuvem, mas voltou às suas raízes com segurança de rede na Elisity.\n\nDan trabalhou principalmente em redes, mas começou com serviços avançados na Cisco e fez algum trabalho com petróleo e gás em Houston. Ele então se mudou para o espaço SASE SD-WAN, onde trabalhou com Dana. Agora, ele está focado em segurança de rede, assim como segurança definida por software. Dan diz que o termo, no entanto, é elusivo porque a tecnologia é microsegmentação por meio da identidade.\n\nA maneira tradicional de criar micro-segmentação através de VLANs e firewalls já não é suficiente. Por 15 anos, a segurança de rede tem se concentrado em fortalecer o perímetro da rede. Criar uma parede impenetrável em torno de uma empresa ainda é essencial, e os firewalls fazem um trabalho incrível em manter as pessoas fora da rede. No entanto, a maior parte da rede, onde houve uma explosão de novos requisitos de conectividade devido à IoT e à OT, é uma zona franca assim que um usuário está dentro. Como a parede externa é robusta, qualquer pessoa dentro geralmente é considerada um usuário legítimo ou confiável.\n\nA realidade é que a maioria dos ataques atuais estão acontecendo dentro da rede através de usuários confiáveis, dispositivos e aplicativos explorados.\n\nExistem muitas razões pelas quais a utilização de VLANs, ACLs de IP, firewalls e métodos tradicionais de segmentação não funcionam hoje em dia para a segurança de movimentação lateral. Eles podem funcionar em ambientes estáticos em pequena escala. Eles funcionam muito bem na borda da rede e em lugares específicos, como gargalos ou pontos de agregação, mas existem três razões comuns pelas quais eles não são mais ideais.\n\nPrimeiro, a escalabilidade e eficiência operacional dos métodos tradicionais são questionáveis. Gerenciar VLANs, IP ACLs e firewalls em grandes empresas é feito manualmente. Não se trata de uma arquitetura de rede definida por software distribuída, mas sim de uma configuração caixa por caixa, linha por linha. Eles não são dinâmicos ou responsivos a qualquer coisa na rede. Seu uso também cria uma rede cheia de buracos aleatórios. Os usuários, especialmente os operadores de redes, muitas vezes representam o maior risco para um sistema. Por exemplo, eles podem abrir uma VLAN ou alterar uma parte para fazer um teste rápido, mas depois não desfazem a alteração.\n\nOutro exemplo é que uma VLAN começará com um caso de uso e lentamente se expandirá para outros casos de uso. De repente, o que era uma VLAN de dez dispositivos agora possui 60 dispositivos. No mundo da OT (Tecnologia de Operação), pode ter seis ou sete processos diferentes sendo executados nela pois era a LAN confiável. No entanto, muitas vezes esses ambientes crescem lentamente e não são documentados, então o risco passa despercebido.\n\nO segundo problema é que VLANs e firewalls estão inherentemente no lugar errado na rede para fornecer segurança de movimento lateral. Se você estiver na mesma VLAN que outro dispositivo, usuário ou aplicativo, esse canal de comunicação estará aberto mesmo que não precise estar. Firewalls não são normalmente implantados em um local estratégico onde podem lidar com o nível de acesso de movimento lateral. É necessário direcionar o tráfego para um firewall e retorná-lo, o que é ineficiente. Então você tem um gargalo.\n\nAttores mal-intencionados estão examinando redes para ver como podem distorcê-las para obter algum resultado, não como elas deveriam ou foram planejadas para funcionar. Por exemplo, se um usuário está em uma VLAN e um processo está sendo executado dentro de um caso de uso, não há nada que os impeça de ir da porta 3 para a porta 32 na mesma VLAN. Muitas vezes, as pessoas projetam a segurança em torno do uso pretendido, em vez de como ela poderia ser usada. É comum, por exemplo, que desenvolvedores de software pulem portas para trabalhar de forma eficiente, mas isso é perigoso porque os deixa vulneráveis. Ninguém pode colocar centenas ou milhares de firewalls em toda a borda de acesso. Isso seria fiscalmente restritivo e impossível de gerenciar.\n\nO terceiro problema é que essas soluções de segmentação legadas não consideram a identidade, contexto ou comportamento do ativo conectado à rede. É uma topologia rígida e centrada na rede que fornece algumas medidas de segurança essenciais. Mas um endereço IP não diz nada sobre a legitimidade do ativo e da rede à qual está conectado. Então, como você pode garantir dinamicamente a segurança dessa rede quando não sabe o que está se conectando a ela? Você não pode criar uma política inexistente sem nenhuma granularidade; tratando todos os dispositivos como iguais não funciona.\n\nMesmo que haja uma análise do tipo de tráfego, geralmente ocorre várias etapas acima, o que significa que você está exposto agora. Qualquer aplicação da lei pode ou não ser capaz de proteger totalmente a infraestrutura.\n\nEsta capacidade de deteção ainda tem valor, mesmo que não haja proteção. Ainda assim, a capacidade de impedir algo que poderia ter acontecido bem na borda, o mais próximo possível do ativo, é uma solução melhor.\n\nConfira o próximo episódio desta série [aqui] (episódio-EDT101).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dan Demers","Dana Yanch"],"link":"/episode-EDT101-pt","image":"./episodes/edt-101/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções da Intel para o Setor Público, entrevista os especialistas em segurança de rede Dana Yanch e Dan Demers da Elisity sobre técnicas de segurança do controlador de rede e arquiteturas de confiança zero."},{"id":4,"type":"Episode","title":"Microsegmentação baseada em identidade com Elisity","tags":["microsegmentation","otsecurity","identitybasednetworking","cybersecurity","comms","technology","edge","sdn"],"body":"\r\n\r\nNa parte 2 de Segurança com Elisity, Darren discute soluções de microsegmentação baseada em identidade com Dana Yanch, Diretora de Marketing Técnico, e Dan Demers, Arquiteto Técnico.\n\nA abordagem da Elisity à segurança de rede difere das arquiteturas tradicionais pela forma como é entregue, distribuída pela rede e feita de maneira eficiente, fornecendo um valor de tempo rápido. Eles têm se concentrado em torná-la o mais simples, intuitiva e eficaz possível, para que qualquer segmento da indústria possa aproveitar a tecnologia.\n\nA chave para a tecnologia da Elisity é a microsegmentação, o que significa a capacidade de isolar completamente qualquer usuário, dispositivo ou aplicativo, não importa o tipo de rede em que esteja, onde esteja localizado na rede ou se é gerenciado ou não gerenciado. Em outras palavras, é flexível para isolar um ativo do outro, sem restrições impostas pela arquitetura de rede ou construções como VLANs ou VRFs.\n\nSistemas tradicionais de micro-segmentação, que exigem a substituição de hardware ou a instanciação de um dispositivo local, podem levar meses ou anos para serem implementados e executados. No entanto, a Elisity oferece funcionalidade completa em uma semana, ao adotar uma plataforma de micro-segmentação nativa em nuvem e entregue na nuvem. Todos os controles de gerenciamento e políticas são totalmente entregues na nuvem, e o componente que se conecta à sua rede local é 100% software. Você não precisa alterar nada em seu ambiente local, pois ele opera em cima da sua infraestrutura existente. Ele escala bem, é fácil de gerenciar e é distribuído dinamicamente.\n\nElisity também oferece uma solução localizada para o espaço OT, onde as organizações podem mantê-la atrás de sua DMZ e cortar todo o acesso.\n\nA plataforma da Elisity é um serviço micro no sentido da escalabilidade horizontal. Você pode começar pequeno e adicionar 10.000 coisas à rede e dimensionar com você, seja localmente ou na nuvem. É completamente automatizada em toda a rede. Há pouco atrito e é fácil de gerenciar a longo prazo.\n\nUma diferença significativa entre a plataforma da Elisity e outras redes overlay é que a Elisity lida com o plano de controle e política em vez do plano de dados. Ela pode aplicar o mesmo nível de granularidade de segurança de rede sem tocar em nenhum pacote. Ela informa dinamicamente à rede quem pode falar com quem com base nos atributos e identidades encontrados na rede.\n\nUm triângulo de usuários, aplicativos e dispositivos é uma excelente forma de visualizar isso. Dentro desse triângulo estão todas as linhas de comunicação entre eles se conectando. A Elisity pode proteger cada linha, ou canal, entre usuários, aplicativos e dispositivos com granularidade. Isso ocorre na camada de controle de rede. No momento em que o tráfego atinge a primeira aresta, ele está sendo protegido.\n\nA segurança é essencial na camada de rede e não na camada de aplicação porque pode haver dezenas de milhares de dispositivos em sua rede nos quais você não pode instalar um agente ou modificar, já que possuem sistemas operacionais incorporados, câmeras, leitores de crachá e pessoas. Isso é especialmente importante no lado de OT.\n\nCom a OT, o foco está na disponibilidade e integridade. As coisas precisam continuar funcionando de forma segura, pois o processo pode representar uma infraestrutura crítica. Isso é diferente da TI, onde é possível isolar e iniciar uma nova instância se houver uma intrusão. A OT é uma mentalidade diferente. Enquanto algo pode existir na TI por seis meses ou um ano, algo na OT pode existir por 20 anos. Muitas vezes, essas infraestruturas são mantidas ou atualizadas a cada poucos anos ou ficam inativas até ocorrer um evento de falha. A segurança equivale a restringir a conectividade. Por exemplo, se você estiver em uma VLAN, isso não significa que você deve estar se comunicando com um RTU, um sensor, um HMI ou um DCS que estejam apenas um switch de distância. No design legado, se essas coisas estiverem na mesma VLAN, não há uma maneira eficiente e flexível de impedi-las de se conectar.\n\nCom o sistema da Elisity, você estabelece políticas com base em coisas que agrupam atributos associados aos ativos, em vez de passar item por item. Isso pode ser tão simples como agrupar todos os seus processos para que possam se comunicar apenas no sentido norte/sul, e não leste/oeste, ou, por exemplo, permitir que gerentes de linha compartilhem com seis ou sete tipos de coisas. Duas ou três políticas podem reduzir rapidamente sua superfície de ataque de 65.000 portas de ataque potenciais para duas ou três.\n\nUm caso de uso comum em redes de OT é quando um fornecedor realiza uma atualização em um dispositivo, é necessário permitir que eles entrem e tenham acesso a toda a rede. Com a Elisity, você pode facilmente dar a eles acesso por um tempo limitado e permitir que eles interfiram em ativos fixos.\n\nSuponha que você queira saber mais sobre a tecnologia da Elisity. Nesse caso, muitos recursos, incluindo vídeos, white papers e documentos, explicam como a solução funciona e como ela poderia ser aplicada em uma semana na sua rede em Elisity.com.\n\nConfira o episódio anterior desta série [aqui](episode-EDT101).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dana Yanch","Dan Demers"],"link":"/episode-EDT102-pt","image":"./episodes/edt-102/pt/thumbnail.png","lang":"pt","summary":"Na parte 2 de Segurança com Elisity, Darren discute soluções de microssegmentação baseada em identidade com Dana Yanch, Diretora de Marketing Técnico, e Dan Demers, Arquiteto Técnico."},{"id":5,"type":"Episode","title":"Operacionalizando seus projetos de IA","tags":["aiops","devops","compute","technology","process","devsecops","cybersecurity","aiml"],"body":"\r\n\r\nGretchen é um excelente exemplo de alguém que continua aprendendo e se adaptando. Seu diploma de graduação é em matemática. Ela possui um mestrado em negócios e concluiu um programa em Harvard há alguns anos, focado em ciência de dados, o que a levou a seu cargo de Cientista de Dados Chefe na Intel no setor público. Ela trabalhou na área de tecnologia por mais de 20 anos, começando com engenharia de software, e passou 15 anos no espaço federal.\n\nEla acha especialmente gratificante trabalhar no setor público porque faz diferença na vida dos cidadãos comuns. Além disso, o governo federal possui os dados mais abundantes do planeta, o que é perfeito para alguém que adora estar imerso em dados e continuar aprendendo mais.\n\nExistem muitos termos relacionados à IA. Primeiro, é essencial entender a diferença entre inteligência artificial (IA) e operações de aprendizado de máquina (ML ops). ML ops são técnicas que fazem parte da IA; eles são um subconjunto. Os algoritmos de ML derivam sua força de uma habilidade para aprender a partir dos dados disponíveis. Então, principalmente, você está aprendendo a partir de dados supervisionados ou não supervisionados.\n\nA diferença simples entre aprendizado supervisionado e não supervisionado é a etiqueta dos dados. No aprendizado supervisionado, os conjuntos de dados são etiquetados. Isso significa que como os dados parecem já está mapeado. Isso torna muito mais fácil classificar e prever. No aprendizado não supervisionado, você está tentando encontrar padrões nos dados; a máquina está aprendendo a criar relacionamentos entre os dados com base em encontrar formas comuns, similaridades ou diferenças.\n\nUm exemplo de aprendizado supervisionado seria uma loja online recomendando um item que um cliente gostaria de comprar com base em seu histórico de compras ou um serviço de streaming recomendando um filme com base nos hábitos de visualização de alguém.\n\nMuitos termos agora têm a abreviação \"ops\" no final. Por exemplo, as pessoas dizem \"DL ops\" para operações de deep learning, um subconjunto de machine learning. Por que o \"ops\"? Primeiro, não é tão sofisticado quanto DevOps. Em vez disso, é influenciado pela amplamente adotada ideia da abordagem DevOps para criar e personalizar aplicativos. As pessoas estão tentando desenvolver um conjunto de práticas para ajudar a otimizar a confiabilidade e eficiência do design, desenvolvimento e execução de machine learning. Seria quase como um mercado onde você pode criar e operar aplicativos personalizados e depois compartilhá-los com outras pessoas.\n\nMuitos modelos e algoritmos já estão otimizados e disponíveis em ferramentas como Converge.io ou C3 AI. Essas metodologias e tecnologias podem ajudar a agilizar seus modelos de aprendizado de máquina. A melhor maneira de fazer isso é por meio de várias ferramentas que são de código aberto ou software específico criado pelo fornecedor para tornar a criação, desenvolvimento, design, execução e fluxo muito mais acessíveis.\n\nO desenvolvimento de IA é semelhante à situação no desenvolvimento de software há 30 anos. Muitos dos passos ainda são manuais e espera-se que sejam automatizados em breve.\n\nEm episódios anteriores, Darren e Gretchen discutiram sobre como muitos projetos de IA e ML são experimentos científicos realizados apenas uma vez. Em seguida, o cientista de dados passa para outra coisa e nunca é operacionalizado. Ao contrário disso, a operação de ML está avançando ao implantar o modelo para fornecer valor real após o treinamento e aprendizado.\n\nAlgumas empresas estão explicitamente aproveitando essas ferramentas. Domino Labs, por exemplo, praticamente cria esse mercado. Trabalhar no setor público, digamos, em submarinos nucleares realizando detecção de objetos ou classificação por agrupamento, poderia ser aplicável na Força Aérea ou em outros setores auxiliares para que o trabalho pudesse ser catalogado, auxiliando na operacionalização e construção de ambientes ágeis. É possível aproveitar alguns algoritmos e ponderá-los de forma diferente dependendo dos resultados. É possível ajustar com base nas diferenças nos conjuntos de dados, mas pelo menos existem... pontos de partida? Comunalidades? Ferramentas compartilhadas? Suas últimas palavras aqui foram cortadas...\n\nA segurança está sempre preocupada com software e modelos de código aberto, e a IA possui circunstâncias únicas. Por exemplo, como você sabe se o desenvolvedor não treinou o modelo para ignorar seu próprio rosto em um modelo de reconhecimento facial? Atualmente, espera-se que as pessoas documentem certas coisas, como a origem de um conjunto de dados.\n\nHá também a questão de ética e responsabilidade. O chatbot Tay e os vieses encontrados em programas de reconhecimento facial foram ótimos exemplos de IA que deu errado sem intenção maliciosa. Por muito tempo em operações de aprendizado de máquina, era uma única pessoa fazendo o trabalho e produzindo os resultados. Agora, a ideia é que você precisa de uma equipe diversificada de pessoas em diferentes capacidades e com diferentes visões de mundo.\n\nA primeira conferência para discutir IA e ML ocorreu em 1956 na Dartmouth College. A verdade é que muitos conceitos básicos de IA, como regressão logística, regressão linear, algoritmos de clusterização, etc., são equações matemáticas que existem há muito tempo. Claro, surgiram frameworks adicionais brilhantes, como o TensorFlow, a partir dos quais construímos, mas os fundamentos ainda são/ainda eram a base. Adicionamos computação, armazenamento, 5G e capacidades únicas. Depois de realizar todo o treinamento, você tem os dados e as informações ao lado da tecnologia, em vez de ter que trazer tudo para a tecnologia. Trazer a tecnologia para os dados abre algumas questões divertidas e empolgantes que agora podemos resolver.\n\nMas as conversas em torno de como o modelo foi treinado, qual foi o dado original e como lidar com a deriva do modelo devem estar sempre acontecendo. Após algum tempo, é necessário retrainar; talvez seja necessário usar um algoritmo diferente ou ponderar o atual de forma diferente para obter informações mais precisas, pois há mais dados e dados mais diversos. Isso é bom porque aumenta seu nível de precisão.\n\nEntão, com o movimento em direção a ML Ops, você pode fazer isso continuamente. Assim como o desenvolvimento de software foi em direção à integração e implantação contínuas, o mesmo começará a acontecer em IA ou ML, onde os modelos serão atualizados e se tornarão cada vez mais precisos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart"],"link":"/episode-EDT103-pt","image":"./episodes/edt-103/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto de Soluções-chefe da Intel, Setor Público, e Gretchen Stewart, Cientista de Dados-chefe da Intel, Setor Público, discutem a operacionalização de projetos de IA."},{"id":6,"type":"Episode","title":"Liderança orientada pela informação","tags":["data","informationdriven","organizationalchange","radiusag","change","people","process","ceo"],"body":"\r\n\r\nEmbora Betsy seja a CEO do Radius Advisory Group e esteja tecnicamente aposentada do setor federal, ela ainda mantém um pé no setor público por meio de sua empresa, que se concentra em questões de segurança cibernética e espaço cibernético de importância nacional. Trabalhar simultaneamente nos setores privado e público tem sido a parte mais emocionante de sua trajetória profissional.\n\nBetsy começou como membro ativo em serviço na Força Aérea, passando para a indústria enquanto conciliava filhos e um cônjuge também em serviço ativo. Ela trabalhou em várias indústrias, sendo a mais recente serviços públicos e energia, e passou muito tempo na PricewaterhouseCoopers. Ela voltou ao Departamento de Defesa (DOD) quando foi selecionada para trabalhar com o Secretário Gates como membro da Força-Tarefa de Eficiências de Defesa. Ela permaneceu sob o Secretário Pancetta e teve uma jornada empolgante, sendo finalmente nomeada Vice-CIO para Revisão de Processos de Negócios e Sistemas. Lá, ela criou uma função de análise de dados para fornecer mais transparência nos custos e potenciais eficiências da Tecnologia da Informação em todo o DoD.\n\nO maior desafio de Betsy no papel de vice-CIO, que ela acredita ser aplicável tanto no setor público quanto no privado, é como introduzir novas ideias, processos, tecnologias e métodos de trabalho na organização. Em grandes organizações, o escopo é enorme e há muitos compartimentos isolados, cada um com sua própria cultura, agendas, orçamentos e demonstrações de lucros e perdas. Situações como a pandemia de COVID, onde as mudanças precisam acontecer rapidamente, são extremamente desafiadoras.\n\nBetsy diz que a COVID mudou a cultura de certas maneiras, mas de outras formas fez com que as pessoas se isolassem ainda mais, o que não é bom. Houve muitos desafios de processos e tecnologia dos quais todos aprenderam e continuam aprendendo. Uma preocupação que Betsy tem é que agora há um novo ambiente e ecossistema, e o retorno ao escritório não pode ser empurrado de volta para o velho padrão como muitos líderes estão tentando fazer. Embora seja muito difícil navegar nisso, e independentemente de os líderes considerarem o novo ambiente bom ou ruim, ele não pode ser tratado da mesma forma como antes.\n\nUma vez que os líderes mudem, no entanto, a estratégia de Betsy é correr com tudo. Ela aprendeu essa lição quando era vice-CIO e recebeu vários projetos além da missão subjacente. Ela percebeu que outras equipes sempre tinham 30 dias para projetos, mas sua equipe tinha apenas 10 dias. Quando perguntou, a liderança disse que sabiam que sua equipe poderia fazê-lo em 10 dias e que precisavam tomar decisões complexas que exigiam as informações que sua equipe poderia fornecer como parte do processo de tomada de decisão, portanto quanto mais rápido conseguissem, melhor. Então ela disse à sua equipe que eles tinham que descobrir. Eles conseguiram e se tornaram bons nisso.\n\nUm senso de urgência ajuda as pessoas a se concentrarem e a executarem suas tarefas, mas, como aponta Betsy, os líderes devem garantir que estejam equipados com as pessoas, recursos e autoridade necessários para executar algo em um prazo curto. Esse apoio de liderança é fundamental para o sucesso.\n\nBetsy acredita que ouvir as pessoas é essencial, mas as decisões são tomadas no topo, o que geralmente significa poucas pessoas. Uma organização em matriz, que ganhou popularidade nos anos 90 e 2000, adicionou camadas de complexidade, mas a maioria das situações já são complexas, então ainda se resume à liderança. Os líderes devem ser inclusivos o suficiente para ouvir o maior número possível de pessoas, mas não pode levar cinco meses e 150 reuniões. Eles devem desenvolver sistemas e grupos capazes de fazer ideação, sugerir modelos e trabalhar uns com os outros. Os líderes precisam ter a capacidade de agir rapidamente; às vezes, eles devem agir rapidamente. Frequentemente, a resposta é ter menos pessoas, mas as pessoas certas, menos tecnologia e a tecnologia certa para obter o que você precisa.\n\nBetsy utilizou um modelo prático quando recebeu projetos urgentes do Subsecretário de Defesa para criar pequenas equipes de cinco a sete pessoas com habilidades cognitivas diversas entre seus 50 analistas. Isso foi bem-sucedido porque ela conhecia bem as personalidades e habilidades de seus analistas e podia selecionar as equipes em vez de levar um problema para um grupo enorme e tentar obter a opinião de todos. As equipes pequenas repetidamente a surpreendiam ao realizar tarefas complexas e solucionar problemas.\n\nAo estabelecer processos e modelos para resolver problemas, a equipe de Betsy frequentemente fornecia informações ao Secretário Adjunto de Defesa ou ao CIO em questão de horas, se necessário. Em última análise, eles tinham processos em vigor que lhes permitiam realizar a geração de ideias para desenvolver opções neutras e baseadas em dados com base em muitas considerações. Isso permitia que os líderes analisassem os fatos e evidências e tomassem decisões.\n\nBetsy tinha fé em suas equipes e nunca lhes dizia como fazer o trabalho ou assumia que sabia a melhor maneira de abordar as coisas. Ela tinha pessoas boas e simplesmente confiava nelas para fazer isso. Isso motivava sua equipe e eles estavam constantemente ansiosos por novas tarefas. Os funcionários querem saber que os líderes os escutam, consideram e usam suas ideias. Essa abordagem permitia que as pessoas lhe dessem sua melhor análise e opções. Frequentemente, era uma combinação dessas análises que voltava para a liderança. O crédito vai para a liderança do Departamento de Defesa e para o escritório do CIO, que confiava no processo de Betsy.\n\nCada vez que surgia um novo problema, Betsy designava uma nova equipe. Dessa forma, pessoas diferentes poderiam trabalhar em diferentes tipos de projetos e não serem restringidas a uma área específica, além de permitir que pessoas trabalhassem além de divisões geracionais. Às vezes, as pessoas inicialmente resistiam a trabalhar com grupos etários fora do seu próprio, mas no final, elas aprendiam a enxergar as coisas por meio de lentes diferentes e benéficas.\n\nDesde que Betsy e sua vice conheceram bem suas pessoas, ela conseguiu trabalhar rapidamente para montar equipes eficientes. Uma marca de seu sucesso é que, sempre que ela pedia a uma equipe para trabalhar em duas coisas, ninguém nunca dizia não. Eles apenas faziam.\n\nClique aqui para a segunda metade da conversa de Darren com Betsy Freeman.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Betsy Freeman"],"link":"/episode-EDT104-pt","image":"./episodes/edt-104/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Setor Público, Intel conversa com Betsy Freeman, CEO do Radius Advisory Group, sobre sua experiência como líder orientado por informações nos setores público e privado. Parte um de dois."},{"id":7,"type":"Episode","title":"Liderança Orientada por Informação Parte 2","tags":["change","people","changeagent","radiusag","organizationalchange","informationdriven","leadership"],"body":"\r\n\r\nEmbora Betsy seja a CEO do Radius Advisory Group e esteja tecnicamente aposentada do setor federal, ela ainda mantém um pé no setor público por meio de sua empresa, que se concentra em questões de cibersegurança e ciberespaço de importância nacional. Trabalhar simultaneamente nos setores público e privado tem sido a parte mais empolgante de sua jornada profissional.\n\nBetty começou como membro ativo do serviço na Força Aérea, passando para a indústria enquanto cuidava de crianças e um cônjuge que também estava em serviço ativo. Ela trabalhou em várias indústrias, mais recentemente em serviços públicos e energia, e passou muito tempo na PricewaterhouseCoopers. Ela retornou ao Departamento de Defesa (DOD) quando foi selecionada para trabalhar com o Secretário Gates como membro da Força-Tarefa de Eficiências da Defesa. Ela permaneceu sob o comando do Secretário Pancetta e teve uma jornada emocionante, sendo finalmente nomeada como Vice-CIO para Revisão de Processos e Sistemas de Negócios. Lá, ela criou uma função de análise de dados para fornecer mais transparência nos custos de Tecnologia da Informação e eficiências potenciais em todo o DOD.\n\nO maior desafio de Betsy no papel de Vice CIO, o qual ela acredita ser verdade tanto no setor público quanto no privado, é como trazer novas ideias, processos, tecnologias e metodologias de trabalho para a organização. Em grandes organizações, o escopo é imenso e existem muitos compartimentos estanques, cada um com sua própria cultura, agendas, orçamentos e balanços. Situações como a pandemia de COVID, onde as mudanças precisam acontecer rapidamente, são extremamente desafiadoras.\n\nBetsy diz que a COVID mudou a cultura de certas maneiras, mas de outras maneiras fez as pessoas se fecharem ainda mais, o que não é bom. Houve muitos desafios de processos e tecnologia dos quais todos aprenderam e continuam aprendendo. Uma preocupação que Betsy tem é que agora há um novo ambiente e ecossistema, e o retorno ao escritório não pode ser empurrado de volta para a antiga forma como muitos líderes estão tentando fazer. Embora seja muito difícil navegar por isso, e independentemente de os líderes considerarem o novo ambiente bom ou ruim, ele não pode ser tratado da mesma maneira que antes.\n\nUma vez que os líderes façam uma mudança, no entanto, a estratégia de Betsy é acelerar tudo. Ela aprendeu essa lição quando era vice-CIO e recebeu vários projetos além da missão subjacente. Ela percebeu que outras equipes tinham repetidamente 30 dias para projetos, mas sua equipe tinha apenas 10 dias. Quando ela perguntou, a liderança disse que sabia que sua equipe poderia realizar em 10 dias e que eles precisavam tomar decisões complexas que exigiam as informações que sua equipe poderia fornecer como parte do processo de tomada de decisão, então quanto mais rápido pudessem tê-las, melhor. Então ela disse à sua equipe que eles simplesmente teriam que resolver. Eles fizeram isso e ficaram bons nisso.\n\nUm senso de urgência ajuda as pessoas a se concentrarem e a executarem suas tarefas, mas os líderes, como Betsy destaca, devem garantir que estejam equipados com as pessoas, recursos e autoridade necessários para executar algo em um curto prazo. Esse apoio dos líderes é fundamental para o sucesso.\n\nBetsy acredita que ouvir as pessoas é essencial, mas as decisões são tomadas no topo, o que geralmente significa poucas pessoas. Uma organização matricial, que ganhou popularidade nos anos 90 e 2000, acrescentou camadas de complexidade, mas a maioria das situações já é complexa, então ainda se resume à liderança. Os líderes devem ser inclusivos o suficiente para ouvir o máximo de pessoas possível, mas não podem demorar cinco meses e realizar 150 reuniões. Eles devem desenvolver sistemas e grupos que possam fazer a geração de ideias, sugerir modelos e trabalhar juntos. Os líderes precisam ter a capacidade de agir rapidamente, às vezes. Frequentemente, a resposta está em ter menos pessoas, mas as pessoas certas, menos tecnologia e a tecnologia certa para obter o que você precisa.\n\nBetsy utilizou um modelo eficaz quando ela recebeu projetos urgentes do Subsecretário de Defesa para criar pequenas equipes de cinco a sete pessoas com habilidades cognitivas diversas entre seus 50 analistas. Isso foi bem-sucedido pois ela conhecia bem as personalidades e habilidades de seus analistas e pôde escolher a dedo as equipes ao invés de levar um problema para um grupo enorme e tentar obter a contribuição de todos. As pequenas equipes repetidamente a surpreendiam ao realizar tarefas complexas e resolver problemas.\n\nAo estabelecer processos e modelos para resolver problemas, a equipe de Betsy muitas vezes fornecia contribuições ao Secretário Adjunto de Defesa ou ao CIO dentro de horas, se necessário. No final, eles tinham processos no lugar que permitiam a eles fazer a geração de ideias para criar opções neutras baseadas em dados e em várias considerações. Isso permitia aos líderes analisarem os fatos e evidências e tomarem decisões.\n\nBetsy tinha confiança em suas equipes e nunca lhes dizia como fazer o trabalho ou assumia que sabia a melhor maneira de abordar as coisas. Ela tinha pessoas talentosas e simplesmente confiava nelas para fazer, isso motivava suas equipes e elas estavam constantemente ansiosas por novas tarefas. Os funcionários querem saber que os líderes os ouvem e consideram e utilizam suas ideias. Essa abordagem permitia que as pessoas lhe dessem suas melhores análises e opções. Muitas vezes, era uma combinação dessas análises que chegava à liderança. O mérito vai para a liderança do Departamento de Defesa (DOD) e para o escritório do CIO, que confiaram no processo da Betsy.\n\nTodas as vezes que surgia um novo problema, Betsy designava uma nova equipe. Dessa forma, pessoas diferentes poderiam trabalhar em diferentes tipos de projetos e não serem limitadas a uma área específica, além de permitir que as pessoas trabalhassem atravessando as divisões geracionais. Às vezes, as pessoas inicialmente resistiam a trabalhar com grupos etários diferentes do seu, mas no final, aprendiam a enxergar as coisas através de perspectivas diferentes e benéficas.\n\nDesde que Betsy e seu vice conheceram bem sua equipe, ela pôde trabalhar rapidamente para formar equipes eficazes. Um dos marcos de seu sucesso é que sempre que ela pediu uma equipe para trabalhar em duas coisas, ninguém nunca disse não. Eles simplesmente fizeram.\n\nClique [aqui](episódio-EDT104) para a primeira metade da discussão de Darren com Betsy Freeman.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Betsy Freeman"],"link":"/episode-EDT105-pt","image":"./episodes/edt-105/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções, Setor Público, Intel continua sua conversa com Betsy Freeman, CEO do Radius Advisory Group, sobre sua experiência como líder orientada por informações nos setores público e privado. Parte dois de dois."},{"id":8,"type":"Episode","title":"O Nascimento das Plataformas de Inteligência de Gráficos","tags":["data","graphintelligenceplatform","graphdb","katanagraph","technology"],"body":"\r\n\r\nGreg começou sua carreira em um banco de investimentos no gerenciamento de risco de crédito quando eles começaram a implementar testes de estresse CCAR. Depois de se envolver intensamente nesse trabalho por algum tempo, ele começou a trabalhar como consultor e foi apresentado aos gráficos durante a validação de modelos de risco de crédito. Ele percebeu como os gráficos podem ser utilizados em diversas análises e apresentam benefícios na gestão de dados e aprendizado de máquina, especialmente na modelagem de crédito. A partir daí, ele encontrou o seu caminho para a Katana.\n\nTradutores de dados e cientistas de dados estão constantemente lutando para integrar conjuntos de dados diferentes. Greg foi atraído para os gráficos porque, depois de ter sido introduzido ao RDF, um formato de grafo de conhecimento semântico, ele entendeu intuitivamente como os dados poderiam ser combinados e estruturados como um grafo.\n\nCom soluções gráficas existentes, os analistas tinham dificuldade em dimensionar suas soluções porque grande parte dos seus dados era muito grande. O Katana Graph desenvolveu a capacidade de dimensionar e também de focar em aprendizado de máquina.\n\nNo início dos bancos de dados de gráficos, grandes empresas como Amazon e Facebook construíram bancos de dados de gráficos internamente, fazendo seu próprio modelo e aprendizado de máquina. Depois surgiram versões para consumidores de plataformas como Neo4j e TigerGraph para casos de uso gerais. O desafio era que elas eram centradas no banco de dados e não tanto na análise e no aprendizado de máquina, nos processos e na computação de gráficos reais. Elas estavam limitadas a serem uma espécie de armazenamento de dados, focando na ingestão e nas operações CRUD e não tanto nos dados.\n\nExistem três tipos diferentes de domínios de computação de gráficos. O primeiro é a consulta de gráficos, o banco de dados de gráficos e as operações CRUD. O segundo é a análise de gráficos e a mineração com PageRank, ou algoritmos de clusterização, que estão se tornando populares. A terceira área é a inteligência artificial e aprendizado de máquina em gráficos. É nessa área que as redes neurais de gráficos entram em cena. Existem soluções pontuais que resolverão partes específicas desses domínios, mas o Katana Graph está no ponto de interseção deles.\n\nCada uma das três plataformas é importante. Para fazer aprendizado de máquina, você precisa dos outros dois domínios. Quando os dados são primeiramente inseridos, eles devem passar por várias transformações para serem preparados para o aprendizado de máquina, então se você não tiver tudo isso em uma única solução, o pipeline ficará lento, enviando os dados para fora e de volta. É mais eficiente iterar rapidamente em todo o pipeline. Isso também reduz o risco de perder dados, pois você está diminuindo o número de vezes que transforma os dados.\n\nAlém disso, uma vez que o Katana Graph é uma plataforma nativa da nuvem, você pode pausar, salvar um ponto de verificação, desligar o cluster e ligá-lo novamente mais tarde, exatamente onde parou.\n\nUma boa demonstração é para detecção de fraudes com um conjunto de dados de transações de Bitcoin. A plataforma ingere os dados, que são estruturados, então as carteiras de Bitcoin são os nós no gráfico, e as arestas entre elas são as transações. É um gráfico simples. A ideia é prever se uma carteira de Bitcoin é fraudulenta. As carteiras ilícitas para lavagem de dinheiro, tráfico de drogas, etc., foram rotuladas. Quando uma nova conta surge, a tarefa é prever se ela é fraudulenta. A parte desafiadora, então, é realizar algum pré-processamento com as características numéricas das contas. Um conjunto de APIs foi projetado para abordar esse problema. Todas as coisas que os cientistas de dados fazem para preparar suas características são feitas aqui. A partir daí, o gráfico está pronto para ser inserido no modelo de aprendizado de máquina, onde é treinado e, em seguida, usando redes neurais, você pode aprender como classificar as contas.\n\nUm benefício da plataforma é que cientistas de dados e engenheiros podem trabalhar a partir de uma única plataforma, em vez de juntar as coisas.\n\nOutro benefício é o custo total de propriedade. Ao contrário de outras plataformas, você não precisa manter o banco de dados de gráficos inteiro em funcionamento o tempo todo. Como os pipelines do Katana Graph são projetados com uma separação de armazenamento e computação, você pode facilmente iniciar um cluster, fazer algum processamento em lote antecipadamente e depois executar a inferência em um sistema separado e ainda aproveitar o que foi gerado no gráfico.\n\nO Katana Graph também é mais rápido com grandes conjuntos de dados porque não carrega todos os dados de uma só vez, mas possui uma maneira inovadora e dinâmica de carregar os dados conforme você precisa, enquanto trabalha através da sequência de processamento.\n\nAs análises básicas são muito mais fáceis em um banco de dados gráfico do que em um banco de dados relacional. Se você tiver dez conjuntos de dados diferentes, pode ser complicado e propenso a erros para um analista descobrir como juntá-los para escrever uma consulta em um banco de dados relacional. Com um gráfico, você tem um modelo singular, já predefinido e construído, então as perguntas serão muito mais fáceis porque os dados já estão conectados. Você pode ver intuitivamente como as informações estão relacionadas.\n\nUma das novas funcionalidades da Katana é um importador de estrutura de dados Dash. Dash é um framework comum que cientistas de dados utilizam para processamento paralelo de estruturas de dados. Os cientistas de dados podem trabalhar com a estrutura de dados que já estão utilizando e importá-la diretamente para o Katana Graph, proporcionando uma experiência fluida e simplificada.\n\nDevOps é uma grande parte do que Katana está tentando facilitar com sua plataforma. Eles se integram facilmente aos pipelines de aprendizado existentes. Quando as redes neurais gráficas são executadas, os embeddings podem ser exportados. Essas características que um grafo gera podem ir para jusante de um processo de aprendizado de máquina. Assim, a integração se torna muito mais simples e fácil de operacionalizar e colocar em produção.\n\nNos próximos cinco anos, Greg prevê que organizações como bancos terão repositórios centralizados para analisar dados de clientes, marketing ou crédito para múltiplos propósitos. A saída dos modelos de aprendizado de máquina poderá ser usada tanto para risco de crédito quanto para detecção de fraudes, por exemplo. Em vez de utilizar conjuntos de dados isolados com muita replicação e duplicação entre eles, haverá um modelo comum sincronizado dentro de um gráfico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Steck"],"link":"/episode-EDT106-pt","image":"./episodes/edt-106/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções do Setor Público da Intel, e Greg Steck, Diretor Sênior de Soluções Setoriais da Katana Graph, falam sobre os benefícios da plataforma de inteligência de gráficos da Katana."},{"id":9,"type":"Episode","title":"Protegendo Infraestruturas Críticas","tags":["criticalinfrastructure","hotms","irdeto","otsecurity","edge","cybersecurity","technology","process"],"body":"\r\n\r\nCarla é originalmente do México, morando em Amsterdã após morar em vários países, incluindo a Alemanha, nos últimos quatro anos. Ela estudou engenharia industrial e mecatrônica e, depois de trabalhar por alguns anos na área, obteve um Mestrado em engenharia de sistemas de mobilidade, onde focou em veículos autônomos.\n\nA definição de infraestrutura crítica OT é qualquer ponto que possa desencadear o caos no mundo real. Isso é muito diferente da infraestrutura de TI; a TI não possui infraestrutura vital. No mundo OT, as pessoas podem morrer se algo der errado. Sem dúvida, pode haver caos no mundo da TI, mas o problema pode ser resolvido ao consertar as coisas. Quando há caos em infraestruturas críticas, como transporte, acidentes podem ocorrer e a vida das pessoas está em jogo.\n\nHouve um aumento na importância da segurança em infraestruturas críticas nos últimos cinco anos, e certamente durante a pandemia da COVID; em alguns casos, as infraestruturas críticas têm sido atacadas incansavelmente. Isso pode ser atribuído às pessoas ficando entediadas e mais criativas, mas também porque a superfície de ataque aumentou com a mudança repentina para o trabalho remoto, o que reduziu algumas das medidas de segurança previamente implementadas.\n\nNo transporte, parte do problema é o aumento da conectividade, o que traz potenciais ataques. Os clientes querem mais serviços e as empresas querem mais dados e acesso à informação. Com isso, há a abertura da rede de transporte. A lacuna de ar, que antes oferecia proteção, está diminuindo.\n\nA indústria não pode utilizar as medidas de segurança que a TI tem usado há anos, porque TI e TO são totalmente diferentes. A TI é geralmente padronizada, ao contrário da TO. A TO possui um ecossistema enorme com diferenças significativas em dispositivos que seguem outros protocolos e implementações. Por exemplo, cada país tem implementações diferentes. A TO também está em outro nível, porque literalmente vidas estão em jogo.\n\nOutra diferença entre a infraestrutura crítica de TI e de OT é que, em TI, se houver um problema em sua rede, você pode isolá-lo e até mesmo desligá-lo e transferir a carga de trabalho para outro lugar. Isso não é possível na infraestrutura crítica, então a abordagem é diferente.\n\nTranslate for Portuguese: O perigo é que as redes de TI e OT entraram em colapso por causa do desejo por mais conectividade, e ao mesmo tempo, houve um aumento nas ameaças cibernéticas. A Irdeto busca educar o setor sobre as complexidades desses problemas e oferecer soluções. Trata-se de soluções preventivas, e não reagir após um desastre ocorrer.\n\nCarla afirma que as organizações devem ter especialistas em segurança. Desenvolver segurança internamente com base em padrões obrigatórios não é suficiente, pois os padrões ficam atrasados em relação ao desenvolvimento.\n\nA Irdeto vem garantindo a segurança de infraestruturas críticas há 50 anos. Eles têm cerca de 1.000 funcionários, sendo que 70 por cento deles estão na área de pesquisa e desenvolvimento, para se manterem atualizados sobre os tipos de ataques que estão ocorrendo hoje e quais tipos de ataques poderão existir no futuro. A Irdeto busca estar sempre um passo à frente ou à prova do futuro. Seus serviços evoluem conforme o sistema evolui.\n\nA Irdeto pode ajudar os clientes que sabem o que precisam, seja PKI, chaves e credenciais, gestão do ciclo de vida ou proteção de software. Eles também podem ajudar os clientes que não sabem o que precisam e fornecer soluções duradouras à medida que as ameaças evoluem.\n\nPara mais informações sobre a Irdeto, acesse o site deles em www.irdeto.com/connected-transport para saber mais sobre o assunto.\n\nTraduza o seguinte para o português: produtos ou entre em contato diretamente com eles.\n\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Carla Trevino"],"link":"/episode-EDT107-pt","image":"./episodes/edt-107/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Setor Público, e Carla Trevino, Arquiteta de Soluções, Irdeto, falam sobre a importância da segurança na infraestrutura crítica."},{"id":10,"type":"Episode","title":"História das Comunicações Avançadas","tags":["5g","cellphone","comms","wifi6"],"body":"\r\n\r\nA primeira geração de tecnologia de telefonia celular, o Sistema Avançado de Telefone Móvel (AMPS), foi desenvolvida no final dos anos 70 e início dos anos 80. No início dos anos 80, fazer uma ligação do seu carro com um telefone de bolsa volumoso era luxo. O luxo de fazer uma ligação de um dispositivo móvel logo se tornou uma necessidade.\n\nNos anos 90, a tecnologia avançou à medida que o padrão Global System for Mobile Communications (GSM) foi desenvolvido para descrever os protocolos para a tecnologia 2G, que se tornou o padrão global até meados da década de 2010. O 2G começou a transformar o telefone celular em algo com mais capacidades do que apenas fazer uma ligação, adicionando mensagens de texto e até mesmo jogos.\n\n3G foi lançado no início dos anos 2000 e trouxe algumas capacidades de dados nascentes com a internet, que ainda estava em seus estágios iniciais. O Wi-Fi não estava amplamente disponível, mas era possível, por exemplo, acessar a rede de dados de uma operadora conectando um telefone a um laptop. É claro que você poderia fazer o mínimo, com velocidades de modem ou DSL.\n\nCom o 4G, a tecnologia passou para um padrão unificado, convergindo CDMA e GSM em um único padrão LTE sob o 3rd Generation Partnership Project (3GPP). Cada operadora começou a adotar esse padrão comum. Foi quando a banda larga se proliferou. Leland atribui o avanço da economia durante a década de 2010 ao 4G, permitindo que empresas como Amazon, Netflix e Uber e plataformas como YouTube, Google e Facebook existissem e prosperassem.\n\nLeland fala sobre o 5G em termos do que as operadoras implementaram. O 4G e o 5G estão relacionados porque fazem parte da mesma linha de lançamento de especificações. O 4G LTE avançado termina no número quatorze. O número quinze começa com o 5G NR. Nesse período de transição, existe um objetivo empresarial e uma estratégia para adotar a nova tecnologia como parte do padrão. O objetivo empresarial é que as empresas já tenham investido em suas redes 4G, então os componentes atuais do núcleo de pacotes evoluídos e da RAN das redes 4G permanecem no lugar. Eles adicionam uma caixa RAN 5G com uma frequência diferente, mas ainda conectada ao núcleo 4G, chamada não autônoma.\n\nDarren esclarece que o 4G foi revolucionário porque desbloqueou muitas coisas novas e exigiu todo um novo equipamento, enquanto o 5G é mais evolutivo porque também abriu coisas novas. Ainda assim, a tecnologia subjacente é baseada no mesmo hardware e núcleo.\n\nÉ parte do esquema de modulação que o 5G oferece na interface aérea, mas a arquitetura é diferente; está virtualizada sob o 5G em comparação com algo mais proprietário no 4G. Isso leva a muitas capacidades se tornarem parte das implementações do 5G.\n\nUm exemplo é uma operadora que implantou uma rede 4G colocando uma caixa de RAN ao lado de uma antiga caixa 3G. Muitas empresas, como a Sprint, mantiveram suas caixas 3G e redes CDMA funcionando por anos. Na realidade, o 4G era apenas mais uma caixa ao lado de uma caixa 3G. O 5G leva essa caixa proprietária e possibilita espalhar as funções dessa caixa por uma rede virtualizada. Parte da baseband do 5G agora pode ser definida por software em escala para várias áreas, em vez de ser contida em um único local, caixa ou ponto.\n\nIsso significa que você pode adicionar funcionalidade à sua rede sem substituir hardware. À medida que você adota redes independentes, no entanto, é possível utilizar uma rede 5G e fazer algo localmente. Por exemplo, suponha que você tenha um arranha-céu, em vez de depender da cobertura de rede de uma antena externa com um núcleo de volta para o provedor ou uma estação de comutação. Nesse caso, você pode desenvolver uma rede local incorporada dentro do prédio, que prolifera a cobertura e os serviços de dados.\n\nEsta rede independente abre muitas novas capacidades e permite que novos players entrem no jogo. Também permite que organizações como o governo federal e o Departamento de Defesa adotem a tecnologia para seus casos de uso. Eles têm mais flexibilidade quando não estão altamente dependentes das operadoras.\n\nAnna nota que, além de novos jogadores e novas capacidades locais, há também a possibilidade de usar o espectro CBRS. A forma como é gerenciado é complexa, mas há uma faixa de não prioridade que você pode usar gratuitamente, e a prioridade, o espectro da Marinha, que você pode comprar se não precisar de interrupção. Algumas instalações de manufatura extensivas estão utilizando o espectro CBRS, seja trabalhando com um provedor primário que não cobra pela cobertura ou trabalhando com um novo entrante que vai estabelecer uma rede independente local com CBRS. Este é um modelo muito diferente, e há vantagens reais na frequência e complexidade dos sistemas que podem ser estabelecidos com o 5G em comparação com o Wi-Fi.\n\nAinda existem algumas vantagens para o Wi-Fi, porém configurar uma rede Wi-Fi robusta pode ser desafiador, especialmente se você estiver movendo grandes peças de metal ao redor. Se você tiver uma configuração definida, faz sentido optar pelo Wi-Fi 6, especialmente se as condições econômicas colaborarem.\n\nA demanda impulsiona a mudança; a maioria dos usuários finais está confortável com o 4G em seus dispositivos pessoais. Então, por que migrar para o 5G? O valor que o 5G traz não está necessariamente nas taxas de dados mais altas e menor latência; esses serviços são fornecidos em grande escala porque são virtualizados. O 5G é intensivo em software em comparação com o 4G, que depende mais de caixas proprietárias e baseado em hardware. O 5G pode ser virtualizado em várias posições. O portfólio de frequências é dinâmico e você pode utilizar bandas não licenciadas, bandas licenciadas e CBRS, então há muito mais opções.\n\nConfira a segunda parte desta entrevista [aqui](episódio-EDT109).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown","Anna Scott"],"link":"/episode-EDT108-pt","image":"./episodes/edt-108/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com os frequentes convidados da Intel Leland Brown, Engenheiro Principal: Diretor Técnico de Comunicações Avançadas, e Dra. Anna Scott, Arquiteta Chefe de Borda para o Setor Público, sobre a história das comunicações avançadas."},{"id":11,"type":"Episode","title":"Avançando as Operações com 5G","tags":["5g","comms","wifi6"],"body":"\r\n\r\n5G abre várias possibilidades. Agora é possível configurar redes privadas, com definição por software, o que permite adicionar mais funcionalidades à sua rede. Para onde essa tecnologia habilitadora nos levará?\n\nAnna diz que, embora ainda estejamos nos estágios iniciais do ponto de vista de largura de banda e latência, existem vantagens reais no 5G, como a abertura do espectro, como o CBRS, a capacidade de aproveitar o equipamento do usuário existente e a capacidade de os clientes terem acesso móvel.\n\nUm caso de uso que não é sexy, mas tem vastas ramificações é que você pode levar seu laptop para o chão de fábrica e usá-lo para conectividade total. Em vez de ir para o chão de fábrica com um bloco de notas e papel e transferir as informações de volta para o escritório, você pode convergir os dois ambientes. Os padrões 5G permitem isso, mas não necessariamente é um implantação completa do 5G.\n\nUma evolução que está acontecendo é a capacidade de transmitir vídeo de alta definição de uma câmera sem fio pela rede 5G e ter uma latência suficientemente baixa para realizar análises em tempo real. Atualmente, poucas câmeras 5G conseguem operar nesse ambiente, então as câmeras geralmente são conectadas por fio próximo a computação em borda acoplada para obter esse aspecto em tempo real, mas essa opção de transmissão vantajosa está próxima de chegar.\n\nOutro exemplo de vantagem do 5G é usar de 10 a 20 headsets de AR em vez de um ou dois com Wi-Fi. O ponto chave é o MEC (Mobile Edge Compute) que permite ter as aplicações no local em vez de ter que voltar para o switch ou para o núcleo da operadora e ter aquele tempo RAN.\n\nCompreender como as frequências são implantadas é essencial em casos de uso, pois alguns operadores implantaram mmWave apesar dos desafios; as frequências n41 e n42 reagem de maneira diferente no mundo real. Portanto, em implantações no local, o MEC e o design de RF são extremamente importantes.\n\nUm caso de uso convincente para o 5G fora da fábrica é o uso de drones em respostas a emergências. Um precursor inicial para a eventual capacidade de trazer drones e avaliar uma área danificada é conectar os drones, compreender uma missão para fazer uma cobertura aérea e, em seguida, reunir todos os dados. Embora ainda não possamos transmitir vídeo ao vivo de vários drones e unificá-los, estamos próximos de coletar, combinar e analisar esses dados, embora não em tempo real.\n\nOutro caso de uso é utilizar 5G, IA, modelagem, simulação e computação de borda para treinamento em várias indústrias, incluindo o Departamento de Defesa. Há uma grande vantagem em criar uma simulação de treinamento realista sem colocar a pessoa em perigo ou gastar quantias enormes de dinheiro em treinamento ao vivo.\n\nPor mais que o 5G possibilite esse tipo de caso de uso, muito depende do 5G se conectando a uma MEC em vez do 5G ir para a nuvem. A física entra em jogo. Você precisa de uma latência super baixa, então não pode ter uma arquitetura que vá de um headset para a nuvem, desça para uma MEC e depois para visualização. Precisa ir do headset para a MEC, onde ocorre o processamento em tempo real. Então você pode compartilhar dados através da nuvem para uma experiência em tempo real.\n\nTambém existe a capacidade de interligar ou agrupar MECs juntos, de forma que os dados talvez nunca precisem ir para a nuvem. Os MECs podem realizar todo o processamento e análise diretamente no switch. Isso poderia possibilitar avanços como edifícios e cidades inteligentes. Esse tipo de tecnologia habilitada para 5G é a combinação perfeita para mudanças consideráveis na indústria.\n\nLeland destaca que a história das novas redes é a computação distribuída. Tudo está conectado por meio de conectividade sem fio, mas os pontos de computação estão espalhados pela paisagem, onde os aplicativos estão nas bordas e permitem os casos de uso. Para onde estamos indo é calcular sem fio de forma individual.\n\nQual papel a Intel desempenha no 5G? É muito além de apenas fornecer chips. Como o 5G é projetado por software, a Intel possibilitou que o ecossistema construísse ou projetasse em cima de seu L15. Ao migrar do 4G para o 5G, a Intel pegou o bloco funcional do RAN, chamado FlexRan, e permitiu às empresas projetarem suas arquiteturas de banda base e virtualizá-las. Escrever a arquitetura de referência do FlexRan tornou muito mais fácil para novos participantes utilizarem como ponto de partida.\n\nDo lado do hardware, a Intel gastou muitos ciclos para garantir que o hardware comercial, pronto para uso, funcionasse bem para suportar todas as faixas de frequência básicas, aplicações RAN e servidores. Os novos sistemas que surgem ao abandonar os sistemas proprietários devem ser facilmente suportados pelo mesmo tipo de servidor que funciona na nuvem e no centro de dados, pois agora você tem a escala e a vantagem de custo.\n\nIsso reduzirá os preços e incentivará mais inovação na indústria.\n\nConfira a primeira parte desta entrevista [aqui](episódio-EDT108).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown","Anna Scott"],"link":"/episode-EDT109-pt","image":"./episodes/edt-109/pt/thumbnail.png","lang":"pt","summary":"O Darren Pulsipher, da Intel, arquiteto-chefe de soluções, Leland Brown, engenheiro principal: diretor técnico de comunicações avançadas, e a Dra. Anna Scott, arquiteta-chefe de borda para o setor público, falam sobre a história das comunicações avançadas e os futuros casos de uso com 5G. Parte dois de dois."},{"id":12,"type":"Episode","title":"Ensino à distância e aprendizagem","tags":["remotelearning","compute","technology","people","edge","telelearning"],"body":"\r\n\r\n## Considerações Emergentes\n\nProfessores, funcionários, pais e estudantes estão enfrentando desafios diferentes na mudança repentina para o ensino à distância. No lado de TI das escolas, há uma série de considerações emergentes. O que fazemos com o cenário de trazer seu próprio dispositivo (BYOD) vindo de redes de confiança zero? Como proteger a privacidade e gerenciar a segurança com os diversos novos modos de comunicação entre professores, funcionários, pais e estudantes? Como manter uma experiência de sala de aula simplificada e gerenciada? Como oferecer suporte quando não existe uma estrutura tradicional de helpdesk? Além disso, não podemos esquecer que há um aspecto social importante que deve impulsionar uma experiência perfeita. Um aluno da terceira série sendo distraído por problemas técnicos quando precisa se conectar com professores e colegas terá uma experiência de aprendizado à distância reduzida.\n\n## Sistemas, Serviços e Plataformas para a Educação\n\nSempre houve complexidade com todas as diferentes camadas de serviços e plataformas, por exemplo, a suíte de produtividade com G Suite e Office 365. A questão agora é o que podemos fazer com os sistemas de gerenciamento de aprendizagem nessa abordagem em camadas na integração do sistema de informações do aluno? Devemos analisar como estamos aproveitando nossas capacidades em relação à escalabilidade. Devemos considerar diferentes soluções de infraestrutura como serviço (IAAS) e plataforma como serviço (PAAS), serviços de armazenamento, privacidade e segurança, e, é claro, as plataformas subjacentes que impulsionam tudo isso.\n\nAntes, as ferramentas de conferência e colaboração tinham uso limitado, talvez apenas para trazer um palestrante convidado, por exemplo. Agora, porém, estão sendo amplamente utilizadas como ferramentas principais e têm contribuído para a complexidade do sistema.\n\n## Opções de Hospedagem de Serviços\n\nExistem dois modos principais que são usados para acessar serviços: o dispositivo como um portal para serviços (software, infraestrutura ou plataforma), e o dispositivo como parte da rede interna. Anteriormente, a maioria se encaixava na última categoria, onde existem preocupações limitadas sobre coisas como atualizações e conformidade com políticas porque os dispositivos estão constantemente conectados aos sites internos da escola, independentemente se são propriedades do próprio distrito ou trazidos pelos próprios usuários (BYOD). Agora, com os diferentes tipos de conectividade, precisamos estar preocupados com a escalabilidade de largura de banda e como implementá-la.\n\n## Dispositivo como um Portal para Serviços\n\nPlataformas como G Suite, Office 365 e aquelas para conferência e colaboração são preocupantes porque criam dependência de uma terceira parte. Os distritos escolares não têm controle sobre segurança, privacidade e desempenho. É importante reconhecer que a conexão com esses serviços em nuvem se conecta de volta ao host interno, seja um nuvem privada ou um centro de dados local, que possui serviços subjacentes de gerenciamento de identidade, sistemas de informações do estudante, filtragem de conteúdo possível, etc. No entanto, os benefícios são a redução do tráfego de entrada para o centro de dados e escalabilidade e gerenciabilidade inerentes.\n\n## Dispositivo como parte da Rede/Nuvem Privada\n\nImplementar uma rede privada virtual (VPN) é uma ideia nova para a maioria dos distritos escolares. Empresas têm usado VPNs há algum tempo, e distritos escolares podem ter que seguir o mesmo caminho para atender às novas necessidades do ensino à distância. Algumas desvantagens de uma VPN são congestão de rede, escalabilidade e tráfego de redes de confiança zero. O principal benefício é que ela funciona como uma extensão da rede interna, então gerenciamento de segurança e criptografia de tráfego são estendidos aos clientes da VPN. Acessibilidade a todos os serviços necessários internamente é outro grande benefício.\n\n## Emergência de gargalos.\n\nGargalos parecem diferentes para o ensino à distância. Para as empresas, quando a força de trabalho passou a ser virtual, a carga esperada em VPN era de cerca de 10%. Para a educação, esse número será significativamente maior, criando um possível gargalo na VPN. A escalabilidade de serviços hospedados é outra área de consideração. Mesmo que os serviços estejam em nuvem pública, eles se conectam de volta a uma nuvem privada ou centro de dados local para coisas como SSO, informações de alunos, tráfego e até mesmo filtragem de conteúdo. A largura de banda de acesso à internet dedicada, assim como a forma como o repasse de largura de banda no centro de dados é tratado, são considerações importantes.\n\nO acesso a um componente de suporte também deve ser escalável para evitar gargalos.\n\nA principal preocupação das redes escolares atualmente, no entanto, é garantir acesso a todos os seus alunos. Para alguns estudantes, há um gargalo apenas para acessar a internet em casa. Quando esse problema é adicionado a todas as diferentes camadas, os gargalos emergentes se tornam muito complexos.\n\nPara combater esses problemas potenciais, os distritos escolares devem dedicar o tempo e os recursos necessários para criar uma arquitetura sólida que seja resiliente, em vez de construir uma bagunça de \"espaguete\" apressada.\n\n## Escalabilidade\n\nHistoricamente, os distritos escolares ampliaram o centro de dados e descentralizaram alguns desses serviços para os locais das escolas. Portanto, a arquitetura geralmente existe para acomodar a agregação de professores, funcionários e alunos em termos de autenticação, gerenciamento de atualizações, distribuição de software, etc. Agora que a descentralização é realizada na sala de aula virtual, estamos voltando a ampliar os serviços no centro de dados.\n\n## Encontrando o Equilíbrio\n\nAnteriormente, apenas os dois fatores de on-prem no centro de dados da central e os links da LAN para os sites da escola estavam em jogo. Agora, há o fator adicional de acomodar todas as salas de aula virtuais, ou seja, a sala de estar de cada aluno e professor. Como podemos acomodar isso? Tudo se resume ao conceito primário de encontrar o equilíbrio do que você precisa para o seu distrito escolar. Cada distrito é diferente em tamanho e alfabetização tecnológica, e há muitas peças em movimento.\n\n## Abordando gargalos\n\nO que a Intel pode fazer para ajudar a resolver esses gargalos que identificamos?\n\nGerenciamento de ponto final e segurança de ponto final é onde a central de suporte de TI entra. Estamos procurando maneiras de oferecer suporte remotamente, em vez de visitas regulares aos locais escolares.\n\nPodemos analisar o centro de dados e a infraestrutura e desenvolver uma estratégia que nos permitirá escalonar a rede e a infraestrutura definidas por software. Além disso, também podemos integrar algum burst de nuvem como serviço de infraestrutura, levando em consideração os padrões de tráfego.\n\n## Componentes Intel para Solucionar Gargalos\n\nA Intel pode ajudar em três categorias principais: computação, armazenamento e rede. Quando olhamos para o reforço da infraestrutura definida por software e as considerações importantes, gira em torno desse computador com processadores Intel, produtos de armazenamento e capacidades de rede. Em vez de estar ligada e limitada por interfaces físicas e dispositivos, a infraestrutura definida por software pode escalar e trazer outros recursos de computação, armazenamento e rede. Ninguém tem certeza de como será o cenário ao retornarmos à escola, e essa infraestrutura definida por software é dinâmica e proporcionará a maior flexibilidade.\n\nExistem muitas opções para os distritos escolares construírem um ambiente viável e seguro para o ensino à distância. Embora tenhamos abordado os tópicos de privacidade e ameaças e soluções de segurança neste episódio, na próxima vez faremos uma análise mais detalhada desses tópicos importantes.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Erin Moseley","Grant Kelly"],"link":"/episode-EDT11-pt","image":"./episodes/edt-11/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Erin Moseley, Executiva de Contas Sênior para Educação na Intel, e Grant Kelly, Arquiteto de Soluções para Educação na Intel, juntam-se a Darren para falar sobre os desafios do ensino e aprendizagem a distância e as mudanças avassaladoras que as escolas, professores, pais e alunos estão absorvendo durante a pandemia da Covid-19. Descubra como estudantes e professores estão se conectando com novas tecnologias e formas de aprendizado."},{"id":13,"type":"Episode","title":"Assegurando a Cadeia de Suprimentos","tags":["securesupplychain","cybersecurity","supplychain","chipsact","policy","process","compute"],"body":"\r\n\r\nNeste episódio, Darren conversa com o Tenente-General Thomas Horlander, que recentemente se juntou à equipe Intel do Setor Público, sobre a cadeia de suprimentos de microeletrônicos e segurança nacional.\n\nThomas ingressou no exército em 1983 depois de obter seu diploma de bacharel em finanças e decidir que o setor privado não era para ele. Ele ingressou no exército com a ideia de ter uma carreira de três a cinco anos, mas acabou completando 39 anos de serviço, com sua posição final sendo de Controlador do Exército. Ele se aposentou há cerca de um ano e ingressou na Intel.\n\nThomas é inspirado na Intel pelas pessoas incríveis, cultura e missão significativa. Ele reconhece o papel fundamental que a Intel desempenha na vida cotidiana de todos e a oportunidade de influenciar o futuro do país.\n\nQuando Thomas entrou para o exército em 1983, a microeletrônica era embrionária; eles nem mesmo tinham computadores. Como jovem oficial, ele se preocupava se tinha pilhas D o suficiente para operar os rádios. Portanto, Thomas se considera um \"imigrante digital\" pois ele experienciou a evolução que ocorreu com o silício.\n\nA sociedade e o militar são agora dependentes de silício, e a cadeia de suprimentos em torno da microeletrônica é crítica: é uma questão de segurança nacional. Thomas diz que a indústria de microeletrônicos divide o palco com a indústria do petróleo como um centro de gravidade no que diz respeito à segurança nacional e estabilidade econômica global.\n\nNo âmbito militar, os veículos e sistemas de armas são todos habilitados com microeletrônicos. Eles permitem que o militar seja mais preciso e letal, por exemplo, com menos peso, um sistema de localização mais preciso e comunicações mais confiáveis.\n\nNossa dependência em microeletrônicos impulsionou a recente Lei dos Chips. Embora a necessidade fosse aparente antes da crise na Ucrânia, testemunhar o que a Ucrânia conseguiu fazer graças aos microeletrônicos destacou a necessidade de garantir a cadeia de suprimentos.\n\nTradução: Thomas tem sido um estudante de segurança nacional durante toda a sua carreira e ele a encara de maneira mais holística do que apenas defesa e o papel das forças armadas. Para ele, segurança nacional engloba boa governança e o Estado de direito. Envolve uma economia funcional, academia prática, cuidados de saúde e, é claro, as forças armadas. E quase todas as profissões na sociedade americana desempenham um papel na segurança nacional. A partir dessa perspectiva, praticamente todas as estruturas necessárias para a segurança nacional dependem de microeletrônica.\n\nO ato das fichas foi necessário, diz Thomas, devido ao desequilíbrio maciço em todo o ecossistema da indústria. Ao mesmo tempo, não é a solução definitiva para a redistribuição do equilíbrio, o Ato das Fichas é um primeiro passo essencial e terá impacto na segurança nacional. Quando você desembalar as atividades principais da indústria de microeletrônicos, desde a origem dos elementos de terras raras até quem fabrica os equipamentos de design e fabricação, fica aparente o que é uma incrível mistura de atividades e por que é tão difícil ter uma visão clara de tudo isso. Um microchip pode mudar de mãos dez vezes durante o processo de fabricação.\n\nA COVID-19, de várias maneiras, expôs essa cadeia de abastecimento complicada e frágil quando, por exemplo, fábricas foram fechadas na Malásia, Irlanda ou China devido a um surto de COVID, e de repente você não pode enviar um carro porque não tem um chip nele. A maioria das pessoas não percebe o desequilíbrio global significativo que existe atualmente. Apenas oito por cento do silício é fabricado nos Estados Unidos. Setenta ou oitenta por cento é fabricado no Sudeste Asiático, especificamente em três países: China, Coreia do Sul e Taiwan.\n\nCom esse conhecimento, é evidente que reequilibrar o ecossistema global da cadeia de suprimentos e devolver capacidade e habilidade aos Estados Unidos é de extrema importância. Nenhuma indústria deveria ter pontos de falha únicos, o que é uma preocupação na indústria de microeletrônica.\n\nO governo federal, a base industrial de defesa e o ecossistema estão todos começando a ver esse problema, e o Chips Act é representativo desse reconhecimento de que precisamos fazer algo. Thomas conhece seis empresas neste momento que disseram que irão investir em fábricas em solo americano nos próximos oito a dez anos.\n\nUma dessas empresas é, naturalmente, a Intel. A Intel está atualmente construindo fábricas em Ohio, Arizona e Novo México. Repatriar capacidades e capacidades na indústria de microeletrônicos é necessário para a segurança nacional, mas também fortalecerá as economias locais e fornecerá oportunidades para os trabalhadores, revitalizando comunidades inteiras.\n\nA infusão de investimento de capital do Chips Act é fundamentalmente essencial porque esta é uma corrida contra o tempo. Thomas é otimista em relação ao futuro da indústria e à ação que está sendo tomada para garantir um futuro brilhante e contínua inovação.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Thomas Horlander"],"link":"/episode-EDT110-pt","image":"./episodes/edt-110/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com o Tenente-General Thomas Horlander, que recentemente juntou-se à equipe do setor público da Intel, sobre a cadeia de suprimentos de microeletrônicos e segurança nacional."},{"id":14,"type":"Episode","title":"Percebendo o Potencial das Cidades Inteligentes.","tags":null,"body":"\r\n\r\nEric teve uma longa carreira no centro de dados e, mais recentemente, no espaço de sinalização digital. Suas paixões são gerenciamento de projetos e implementação e operação de tecnologia. Eric e sua equipe fizeram parte de uma empresa de joint venture da LG Electronics que implantou sinalização digital externa, principalmente para aplicações publicitárias em áreas urbanas densas, locais de trânsito e ruas da cidade. Eles aprenderam muito sobre outras aplicações nesses ambientes, como recursos de computação e outras formas de conectividade que ajudariam a aprimorar a experiência proporcionada pelo IoT. SmartPoint.io surgiu desse ecossistema e do desejo de trabalhar com e impulsionar oportunidades e avanços nesse espaço de mercado.\n\nNo centro de dados, Eric era parte de uma empresa de soluções de ciclo de vida que ajudava empresas a otimizar o armazenamento de servidores e hardware de rede desde uma aquisição, um ciclo de atualização e tudo que está entre eles. Sua função era focada em ajudar o canal de empresas que vendiam essas soluções, mas também como elas eram compradas, financiadas e como se depreciavam ao longo do tempo. Dessa forma, ele aprendeu não apenas sobre a tecnologia, mas também como as pessoas a estavam utilizando e gerenciando esse valor como um ativo em seu balanço patrimonial.\n\nQuando as pessoas falam sobre cidades inteligentes, elas pensam em resiliência, equidade, eficiência e custo-efetividade. As cidades fornecem serviços essenciais, como estradas, segurança pública, água e saneamento. A principal coisa que uma prefeitura traz para seus cidadãos está começando a incluir conectividade, a capacidade de acessar computação e aproveitar os avanços tecnológicos para ajudar a fornecer serviços básicos de forma mais eficiente. A tecnologia inteligente tem sido cara e arriscada, e poucos orçamentos municipais têm espaço para isso.\n\nO histórico de Eric em finanças é um ativo na criação e implementação de tecnologia de cidades inteligentes em uma parceria que oferece um modelo acessível. Ser capaz de implementar os atuais e significativos financiamentos para projetos de infraestrutura de maneiras resilientes e economicamente sustentáveis é um princípio fundamental do que o SmartPoint faz ao firmar parcerias com uma cidade.\n\nPara alcançar a sustentabilidade econômica, a equipe de Eric investigou atentamente a sinalização digital, principalmente para publicidade, que gera uma quantidade enorme de receita. Algumas das maiores empresas do mundo são financiadas principalmente pela receita publicitária, e um dos principais produtos ou recursos são as pessoas às quais eles se dirigem. Atribuir camadas, traços e semelhanças dos clientes aumenta a receita.\n\nCidades têm um tesouro de valor nas pessoas, entidades comerciais e visitantes que residem em seu imóvel. Portanto, o cerne do que a SmartPoint.io está fazendo é aproveitar esse imóvel para gerar receita, mas alinhando-o diretamente com soluções que produzem resultados significativos nos serviços da cidade. Introduzir essa tecnologia nas cidades requer auxílio do setor privado e disposição do setor público para trabalhar juntos.\n\nReceita publicitária, juntamente com a capacidade de acessar os orçamentos de serviços municipais, permite um modelo financeiro que eleva o nível para todos, desde proporcionar um transporte mais seguro até obter retornos maiores em publicidade. Ao vincular o benefício da publicidade de volta às pessoas para as quais a publicidade é direcionada, cria-se uma economia local circular que aumenta o valor e a eficiência.\n\nA computação de borda é uma parte significativa do produto da SmartPoint.io. A caixa de sinalização digital também é como um centro de dados portátil. Os dados não precisam ir para um grande centro de dados em algum lugar, mas são processados na borda. Por exemplo, os dados de vídeo das câmeras onipresentes em uma cidade para observar padrões de tráfego são intensivos em largura de banda. No entanto, o transporte de dados é significativamente reduzido se for armazenado em cache, armazenado ou processado localmente.\n\nTrês grandes vantagens dessas caixas são que elas fazem um ótimo trabalho de reduzir a latência, o custo e aumentar a privacidade. A questão da privacidade pode parecer contraditória, mas os dados de vídeo, por exemplo, não são transmitidos pela IP pública. A análise acontece no momento da captura, portanto, não é transportada pela rede, observada ou passa por várias etapas onde a segurança precisa ser rastreada. Em vez da imagem, envia o evento \"Uma pessoa caminhando na rua\". Esses dados podem ser limpos e anonimizados muito antes de saírem da caixa, protegendo a privacidade das pessoas.\n\nAs caixas também poderiam fornecer serviços como Wi-Fi ou pontos de acesso 5G para áreas não atendidas.\n\nUma vez que as caixas são implantadas, a SmartPoint.io possui uma equipe que monitora e opera a tecnologia, assim como um centro de dados faria para uma empresa. Eles também são parceiros de anunciantes. Muitos anunciantes têm interesse em migrar da propaganda estática de \"cartazes de papel\" para a digital. A SmartPoint.io é uma ótima parceira para esses anunciantes porque eles fornecem financiamento antecipado de despesas de capital (CapEx).\n\nCom as cidades, o modelo é compartilhamento de receita ou pagamento em espécie. Em vez de apenas compartilhar a receita total, no entanto, a SmarPoint.io produz e opera recursos, como infraestrutura de TI, que a cidade pode usar para processar dados ópticos na borda.\n\nA sinalização digital pode ser interativa, o que beneficia as pessoas que estão procurando por serviços, restaurantes, compras, eventos e entretenimento. Locatários comerciais podem utilizá-la como um portal para o novo desenvolvimento econômico, pois conseguem alcançar as pessoas que estão caminhando ao redor. Por sua vez, essas caixas fornecem informações valiosas, como quantas pessoas estavam no centro da cidade ou se uma campanha publicitária conseguiu trazê-las para lá com sucesso.\n\nEste modelo ajudará as cidades inteligentes porque ele adia o custo do investimento de capital e do operacional (CapEx e OpEx) de gerir os equipamentos em lugares públicos e os ciclos de atualização. Assumir riscos com tecnologia cara e relativamente nova também não é um comportamento normal para uma municipalidade, então fazer parceria com o setor privado, que possui um apetite significativo por risco, expertise e financiamento, ajuda as cidades a mitigar os riscos e custos, e avançar além do ponto em que normalmente se sentiriam confortáveis.\n\nNo final, Eric diz que os sucessos estão começando a se acumular neste espaço e eles se constroem uns sobre os outros. Todos estão aprendendo coisas novas e isso é uma excelente oportunidade para se unir e construir uma comunidade, que é o que as cidades representam.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Eric Hornsby"],"link":"/episode-EDT111-pt","image":"./episodes/edt-111/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren conversa com Eric Hornsby, CEO da SmartPoint.io, sobre tecnologia para realizar o potencial das cidades inteligentes."},{"id":15,"type":"Episode","title":"Mitos da Migração de Nuvem Lift and Shift","tags":["multicloud","cloudmigration","cloud","compute","process","technology"],"body":"\r\n\r\nJoão começou sua carreira em tecnologia no help desk de um empreiteiro principal de defesa há 20 anos. À medida que sua carreira progredia, ele se envolveu com cibersegurança e arquitetura empresarial. Ele trabalhou como contratado para a Agência de Sistemas de Informação de Defesa (DISA), onde foi o arquiteto principal para a nuvem DISA do Departamento de Defesa. Eventualmente, o estado de Maryland o contratou para liderar os esforços de transformação digital para o estado, incluindo migração para a nuvem. Essa migração foi a maior já feita em educação estadual e local.\n\nDepois disso, ele fez a transição para o cargo de Diretor de Segurança da Informação do Estado (CISO), supervisionando operações de alto nível, segurança e governança. Ele deixou o serviço público e ingressou na WWT há cerca de três anos. Ele trabalha principalmente na área de educação estadual e local, embora auxilie em outras áreas do setor público.\n\n## Mito Um - A nuvem é mais barata\n\nA nuvem não necessariamente é mais barata do que um ambiente local. As aplicações antigas foram desenvolvidas para o ambiente local, então não há problema com auto-scaling. É um modelo baseado em consumo, e já existem custos afundados, como os servidores. A maioria dos produtos feitos para auxiliar organizações a mover aplicações para a nuvem não suportam auto-scaling, então quando são forçados a usar a nuvem, eles têm que ser provisionados em sua capacidade máxima o tempo todo, o que geralmente não se traduz em economia de custos. É provável que os clientes estejam pagando mais do que pagavam pelas mesmas capacidades no ambiente local.\n\nQuando Darren trabalhava com o governo canadense, eles moveram uma instância do SAP para a nuvem. Ela foi completamente provisionada, rodando 24/7, e eles ultrapassaram o orçamento em apenas seis meses. Quando descobriram esse problema, eles começaram a ligar e desligar a instância todos os dias, já que ela não precisava rodar 24/7. Eles economizaram muito dinheiro reduzindo para 14 a 16 horas por dia.\n\nO acesso deve estar disponível o tempo todo em um departamento como o de Saúde e Serviços Humanos, que geralmente é o maior em um orçamento de TI do estado, mas é possível reduzi-lo para uma instância menor durante os horários de folga para economizar dinheiro.\n\nOs Provedores de Serviços em Nuvem (CSP) agora oferecem serviços nativos em nuvem que estão sendo atendidos por um aplicativo de terceiros ou produto OEM que pode fornecer uma capacidade similar com economia de custos. Isso não funcionará para tudo, pois algumas aplicações legadas não são desenvolvidas para aproveitar algumas das aplicações nativas em nuvem. Seria melhor ter cuidado ao ficar preso a uma nuvem específica. Por exemplo, se você usar serviços AWS proprietários, pode ser desafiador extrair um aplicativo e movê-lo para o Azure e vice-versa.\n\nJohn aconselha organizações a perguntar se faz sentido migrar para a nuvem. Não é uma boa razão para migrar para a nuvem apenas porque você acha que deveria. Você pode acabar com despesas elevadas e superiores e trabalhadores frustrados, pois a estratégia não foi completamente pensada.\n\n## Mito Dois - A Nuvem Apaga Dívida Técnica\n\nMigrar para a nuvem não elimina a dívida técnica em quase todos os casos. Ela expõe e acelera a dívida. Você encontrará pontos de exposição ao mover algo que está em funcionamento há 30 anos para um novo ambiente. A parte da aceleração é que agora você tem uma dívida técnica maior com a qual se preocupar, uma vez que ela está exposta.\n\nDívida técnica significa que você tem sistemas ficando para trás do que deveriam ser. Por exemplo, quando John começou a trabalhar para Maryland, alguns sistemas ainda estavam rodando em telas verdes. Era fácil para os funcionários atuais navegar, mas tinha uma curva de aprendizado íngreme para novos usuários. Embora o sistema estivesse funcionando há muitos anos, a desvantagem dessa dívida técnica é a quantidade de treinamento necessário e a retenção de funcionários. As gerações mais recentes que estão entrando no mercado de trabalho, e que possuem conhecimentos sobre as últimas tendências e desenvolvimentos, não querem lidar com aplicações legadas.\n\nDívida técnica também significa problemas de segurança. Se uma aplicação legada não foi atualizada, você pode não conseguir aplicar correções por medo de quebrá-la. Isso cria vulnerabilidades de segurança que você deve aceitar até sair do ciclo de dívida técnica.\n\nUma reação comum em uma organização é adicionar um pouco de código extra quando necessário para acomodar, por exemplo, uma mudança de regra de uma legislatura estadual. Isso não resolve um problema; em vez disso, o sistema acaba com um monte de código desorganizado, tornando impossível recriar o sistema para uma atualização. Um dos conceitos na nuvem é dividir o sistema em módulos ou microsserviços, mas o código desorganizado não permite isso, já que não é possível simplesmente remover uma parte dele.\n\nIsso faz com que as organizações fiquem ainda mais relutantes em modernizar, porque elas têm feito as coisas da maneira errada por todos esses anos. Quando algo se quebra e se torna o ímpeto para essa mudança, fica ainda mais desafiador.\n\nÀs vezes, pode ser sensato descartar o antigo sistema e começar do zero. Isso é custoso, e você precisa ter o novo sistema antes de descartar o antigo. No entanto, para algumas organizações, como estados, que podem receber financiamento federal para departamentos como Saúde e Serviços Humanos, essa pode ser a melhor escolha. Em uma situação como essa, você também pode avaliar os benefícios da reutilização, como modelos e estruturas de governança para outros departamentos.\n\n## Mito Três - A Nuvem é Segura\n\nMudar para a nuvem não necessariamente torna mais fácil garantir a segurança das aplicações, embora você não precise se preocupar com a segurança física ou hipervisores, por exemplo. Os provedores de nuvem possuem um modelo de responsabilidade compartilhada em várias formas. Você precisa entender pelo que é responsável com cada provedor e pelo que eles são responsáveis. Isso não muda apenas com o provedor, mas também com os serviços que você consome. Isso pode tornar a segurança mais complexa para suas equipes de segurança, pois elas precisam acompanhar todas as diferentes variações entre provedores e serviços.\n\n## Mito Quatro - A Nuvem é Fácil\n\nA migração para a nuvem é complexa. Na verdade, é mais fácil executar tudo em seu próprio data center, sem conexão com a internet. A segurança é fácil dessa maneira e os modelos de custo são simples. No entanto, você não pode crescer. Você não pode fornecer serviços aos seus constituintes ou clientes, e não pode satisfazer as necessidades da missão, entre outras questões. O mundo é complexo e a migração para a nuvem é complicada.\n\n## Mito Cinco - Uma nova habilidade não é necessária.\n\nUma lacuna de conhecimento também pode aumentar os pontos problemáticos em torno dessa complexidade. Desenvolvedores de software e outros especialistas em TI devem mudar sua forma de pensar sobre computação na nuvem, especialmente em relação à segurança. Por exemplo, os desenvolvedores de software não devem criar instâncias na nuvem onde desejarem ou baixar coisas do GitHub ou de outros repositórios, pegando bibliotecas para fazer as coisas funcionarem. Isso abre todas as regras de firewall porque eles podem não escolher corretamente. Devem ser implementadas medidas de segurança ao mudar para a nuvem, o que exige mudança. Trabalhar na nuvem requer um conjunto de habilidades e uma mentalidade diferentes. Mais importante ainda, é preciso descobrir melhores maneiras de gerenciar a segurança com ransomware sofisticado e ataques cibernéticos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","John Evans"],"link":"/episode-EDT112-pt","image":"./episodes/edt-112/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Chief Solutions Architect, Setor Público, Intel, e John Evans, Consultor Chefe de Tecnologia, WWT, discutem cinco mitos sobre a migração de nuvem lift and shift."},{"id":16,"type":"Episode","title":"Operacionalizando a Gestão de Processos de Negócio","tags":["bpm","automation","compute","management","camunda","capitalbpm","rpa"],"body":"\r\n\r\nMax se autodenomina um \"acadêmico fracassado\" porque abandonou seu doutorado em matemática, especializando-se em topologia, para estudar ciência da computação. Ele obteve um diploma de graduação e um mestrado, especializando-se em IA. Em seguida, trabalhou em gerenciamento de processos de negócios (BPM), começando na Lombardi, que foi vendida para a IBM, e em outros fornecedores do espaço BPM. Há dez anos, ele deu um salto com amigos e fundou a Capital BPM.\n\nMax escolheu focar em BPM por duas razões. Primeiro, ele sempre gostou de algoritmos porque eles fornecem uma abordagem sistemática para resolver problemas complexos. Algoritmos lhe dão uma sensação de segurança durante situações loucas.\n\nSegundo, ele gosta do que é chamado de transformações em matemática. Por exemplo, se você tem uma forma feia com muitos cantos difíceis de medir, você poderia transformá-la em, digamos, um retângulo e depois aplicar todas as teorias em torno da medição de retângulos, medir e traduzir a resposta de volta para a forma original. Da mesma forma, em BPM, você pode levar um problema a um domínio onde ele pode ser facilmente resolvido. Em vez de transformar um problema em um problema micro com declarações F aninhadas complicadas de manter, você pode transformá-lo em um problema achatado que você pode ver e atacar em estágios.\n\nEste processo é como aumentar o zoom no Google Maps para ver onde você precisa de foco concentrado e, em seguida, diminuir o zoom para ver como isso se encaixa na imagem completa. O cerne da arquitetura de empresas é a habilidade de ampliar e reduzir o zoom para garantir que a linha que você está traçando ainda seja válida.\n\nMax compara seu gosto por BPM no mundo da ciência da computação às artes marciais, as quais ele estuda desde os seis anos de idade. Ele diz que existem artes marciais práticas, como judô e muay Thai, e outras mais esotéricas, como tai chi. Ele gosta das artes marciais pragmáticas porque elas solucionam problemas do mundo real. Ele não se envolve mais em brigas, mas, por exemplo, suas habilidades em judô o ajudam quando ele escorrega e cai. BPM é pragmático, pois é a chave para solucionar um problema de negócio. Ele acredita que há valor real em utilizar todas as teorias que aprendeu na escola e torná-las subordinadas na criação de uma plataforma de negócios que permita às pessoas solucionar de maneira mais eficiente e consistente os problemas do dia a dia, dando assim mais oportunidades às pessoas e à comunidade.\n\nEsta é uma área da ciência da computação que pode ser ligada à forma como as pessoas trabalham. As coisas podem ser automatizadas para reduzir a quantidade de tarefas repetitivas e mundanas, para que elas possam se concentrar em coisas mais importantes. As pessoas se preocupam que a automação irá engolir empregos diários, mas, ao invés disso, ela remove o tédio e libera tempo para um trabalho mais crítico. Ela também pode criar empregos. Esses mesmos medos existiam quando os computadores automatizados da Ford foram introduzidos, mas, no final, eles criaram novas indústrias. O BPM deve ser completamente abraçado, em vez de temido.\n\nA melhor maneira de começar a operacionalizar processos é utilizar o método científico de articular o problema. No gerenciamento de processos de negócio, você desenha imagens através de um modelador de processos de negócio. Max gosta do Modelador de Processos de Negócio Camunda, que pode ser baixado gratuitamente com apenas um pequeno aprendizado de notação. No programa de modelagem, você desenha etapas que articulam os diferentes sistemas e como eles funcionam.\n\nEm um processo de contratação, por exemplo, você começa com um grupo que define as partes interessadas, como o candidato, o gerente de TI e o RH. Dentro do grupo estão \"caminhos de natação\", cada um contendo um participante que pode realizar ações. Você pode pensar neles como grupos LDAP. Em seguida, você começa a traçar o seu processo de negócios: primeiro, um candidato se candidata ao emprego, então o RH pode fazer uma revisão, em seguida, um gerente de TI fará uma revisão. Decisões aprovadas são registradas ao longo do caminho. Depois que os passos significativos de alto nível estão no modelo, você pode entrar em mais detalhes sobre processos mais articulados e nuances, como uma entrevista dividida, uma para aspectos técnicos e outra para gestão.\n\nTranslate the following to Portuguese: ![imagem bmp](./bpm.png)\n\nO programa de modelagem gera XML nos bastidores à medida que você desenha todos esses diagramas. Esse XML pode ser interpretado em tempo de execução pelas máquinas BPM; enquanto você desenha o diagrama, ele pode se tornar um processo executável.\n\nO elemento humano ainda está presente nesse ciclo, mas o uso de um sistema BPM como este torna claro onde os processos podem ser automatizados, como verificar histórico de empregos ou realizar uma verificação de antecedentes criminais. O modelo também permite flexibilidade e experimentação. Por exemplo, suponha que o especialista de assunto diga que eles não desejam executar uma verificação de histórico de empregos e uma verificação de antecedentes criminais simultaneamente, porque a verificação de antecedentes criminais é cara e a verificação de histórico de empregos é barata. Nesse caso, é fácil fazer a mudança para mover a verificação de histórico de empregos para primeiro e exigir uma decisão antes da verificação de antecedentes criminais. Conforme as mudanças são feitas, você constrói um consenso e uma história verdadeira que se torna progressivamente mais verdadeira quanto mais você experimenta.\n\nEmbora a ferramenta pareça uma ferramenta de desenho, na verdade ela é uma ferramenta de modelagem que permite que você desenhe imagens e as simule nos bastidores. Assim, você pode executar esse processo e visualizar todos os diferentes pontos de decisão e para onde eles levam. O modelo também lhe dirá que você não pode implantar se não tiver feito algo corretamente.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Max Young"],"link":"/episode-EDT113-pt","image":"./episodes/edt-113/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren discute gestão de processos de negócio e automação com Max Young, CEO da Capital BPM."},{"id":17,"type":"Episode","title":"Automatizando a Gestão de Processos Empresariais","tags":["compute","businessprocessmanagement","capitalbpm","bpm","automation","camunda","rpa"],"body":"\r\n\r\nA modelagem de BMP lembra Darren de quando ele fazia desenhos técnicos na escola secundária, e a introdução dos sistemas de desenho assistido por computador do AutoCAD revolucionou o jogo. Antes disso, eles tinham páginas e páginas de sistemas complexos e diagramas para que as pessoas pudessem construir, porém não podiam testar o modelo para garantir que estivesse correto. Com o uso da modelagem computacional, eles puderam realizar simulações para garantir que não houvesse problemas como instalações elétricas e de encanamento passando pelo mesmo buraco.\n\nIsso é análogo a arquitetos usando o PowerPoint para mostrar processos empresariais em vez de usar uma ferramenta de modelagem que pode encontrar conflitos e problemas no que você pensava ser o processo empresarial.\n\nUsar uma ferramenta de modelagem de negócios também resolve um problema prático, eliminando o tempo desperdiçado em reunir todas as partes interessadas para reuniões que precisam ser mais produtivas. Em vez disso, você pode colocar um modelo implementado nas mãos do cliente de negócios e trabalhar por meio dos passos com eles.\n\nApós articular e modelar os processos, você pode escolher os pontos de integração que podem se conectar às interfaces RESTful para obter informações e enviá-las de volta. É assim que os processos de negócios podem integrar-se aos microservices na nuvem. No exemplo do processo de contratação, esses pontos podem ser onde você precisa de uma API para invocar verificações de histórico de emprego ou antecedentes criminais. As entradas serão itens como números de segurança social e datas de nascimento, e as saídas serão um booleano - a informação corresponde ou não? É aqui que você pode começar a ter essa conversa iterativa.\n\nTraduza o seguinte para o português: ![imagem bpm](./bpm.png)\n\nExistem várias etapas manuais neste processo e você pode escolher quais automatizar. Por exemplo, se você decidir que uma entrevista não foi bem, pode recorrer ao setor de recursos humanos. Depois de implantar esse novo processo, você pode voltar e analisar a versão anterior, caso deseje, assim você terá duas versões simultâneas do software funcionando e implantadas no protótipo.\n\nO modelador Camunda é um modelador nativo, mas o Capital BPM construiu suas próprias aplicações que ajudam a simplificar parte do trabalho e suportam diferentes funções de usuário.\n\nEste sistema é diferente do RPA porque, em vez de capturar o que um usuário faz com teclas pressionadas, um analista de negócios analisa os processos e etapas em vários departamentos. O analista analisa de cima para baixo todo o processo. Um RPA pode ser inserido em algumas etapas para eficiência. Um exemplo simples é se um candidato a emprego passa na verificação de histórico profissional e verificação de antecedentes criminais, ele pode ser enviado para uma pessoa sênior de RH; caso contrário, é rejeitado. Escolher etapas específicas ou conjuntos de etapas para automatizar é uma abordagem iterativa que tem sido usada com sucesso no desenvolvimento de software há algum tempo.\n\nRPAs podem ser transformadores do jogo, mas são táticos e de curto prazo. Embora esses ganhos de curto prazo possam ser lucrativos, você precisa olhar para todo o processo de negócio para encontrar otimização e etapas que podem ser eliminadas. A história da mulher que sempre cortava o assado antes de assá-lo porque era assim que sua mãe fazia é análoga a alguns processos de empresas. A mulher finalmente perguntou à sua mãe por que ela cortava o assado, e sua mãe respondeu: \"Para que coubesse na minha forma\". Muitos processos de empresas só estão lá porque sempre foram feitos dessa maneira e ninguém pensou em questionar por quê.\n\nTestar, simular, mover coisas ao redor e executar processos repetidamente no modelador, em outras palavras, testar empiricamente, podem ajudar a eliminar esse excesso de processos e adicionar valor significativo. Visualização e experimentação são partes vitais de todo o processo.\n\nMax aponta que há fidelidade entre o diagrama e a execução real. Os desenvolvedores frequentemente desenham diagramas como ponto de partida. Ainda assim, os gráficos desaparecem à medida que o desenvolvimento avança através das diferentes partes, então o que a empresa pensa que está acontecendo e o que está acontecendo são diferentes. O diagrama e a realidade são separados. Nesse tipo de modelagem, a imagem é sempre uma representação precisa do que está acontecendo. Além disso, é fácil ver e realizar mudanças para melhorias.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Max Young"],"link":"/episode-EDT114-pt","image":"./episodes/edt-114/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Setor Público, Intel, e Max Young, CEO da Capital BPM, discutem a operacionalização da gestão de processos de negócio com programas de modelagem."},{"id":18,"type":"Episode","title":"Bloqueio e Tackle de Segurança","tags":["zta","zerotrustarchitecture","cyberhygiene","cybersecurity","technology","process"],"body":"\r\n\r\nFundamental para todas as outras medidas de segurança cibernética está a higiene básica cibernética. Muitas empresas precisam adotar esses princípios básicos. Isso é evidenciado por manchetes recentes que mostram um aumento nos ataques, como os ataques de negação de serviço, que deveriam ser fáceis de prevenir.\n\nDa sua experiência trabalhando com a comunidade governamental, John acredita que a maioria dos ataques segue uma típica cadeia de ataques. A maioria dos ataques direcionados aos governos estaduais e locais resultam de protocolos de rede expostos ou phishing por email. Esses são pontos de entrada atraentes para hackers e, uma vez dentro, práticas de atualização ruins são um culpado típico que os permite estabelecer uma posição e se movimentar lateralmente. Isso, combinado com políticas de senha fracas ou fraca aplicação das políticas de senha e incapacidade de recuperação, podem levar a um desastre.\n\nEm um incidente de ransomware amplamente divulgado em 2019, a organização afetada assumiu que, como tinham a mesma quantidade de dados em seus ambientes de produção e backup, estavam seguros. Mas eles nunca testaram seus backups ou capacidades de recuperação, que acabaram sendo ruins. Medidas básicas de ciber-higiene poderiam ter evitado esse incidente.\n\nExistem quatro fundamentos essenciais que toda organização deve se concentrar. Primeiramente, eles devem treinar repetidamente as pessoas para evitar golpes de phishing. O treinamento pode parecer repetitivo ou monótono, mas as pessoas sendo enganadas por esses esquemas é uma fraqueza significativa em uma organização. Esperançosamente, num futuro não tão distante, senhas não serão mais necessárias.\n\nSegundo, eles devem configurar os firewalls adequadamente; apenas porque as portas do protocolo RTP ou de rede estão fechadas não significa que não haja uma porta aberta em um local menos proeminente. Segurança pela obscuridade não funciona.\n\nTerceiro, eles devem evitar políticas de correção ruins, tanto com o cliente quanto com o servidor, nos centros de dados e nas bordas. Muitas organizações estão em dívida técnica e não conseguem atualizar seus sistemas antigos, então elas aceitam as vulnerabilidades e riscos porque não querem investir em uma atualização.\n\nQuarto, eles devem ter a habilidade de se recuperar. Apenas porque você sabe que pode fazer backup dos seus dados, é possível usar e recuperar com o backup? Os testes são essenciais.\n\nEsses quatro princípios básicos, juntamente com alguns outros, são suficientes para impedir quase todos os ataques direcionados a organizações que não são alvos regulares. Esse modelo não se aplica a organizações atacadas por nações-estado; elas já estão realizando todas essas ações e precisam de medidas de segurança adicionais.\n\nUma consideração para muitas organizações é a conformidade versus risco. Para algumas organizações estarem em conformidade, elas precisam atualizar máquinas antigas, aplicativos e processos, o que envolve um custo significativo. Para organizações com um sistema que não pode ser corrigido, pode ser adotada uma abordagem baseada em risco, ou seja, se algo acontecer ao sistema, custaria menos do que o custo de atualizá-lo. Claro, a opção segura seria fazer a atualização para estar em conformidade, mas a maioria das pessoas acredita que a abordagem baseada em risco é mais segura. Uma pequena empresa poderia adotar essa abordagem, mas organizações governamentais, por exemplo, têm requisitos regulatórios de conformidade.\n\nExistem duas razões pelas quais uma organização pode optar pelo cumprimento, além de um mandato. Primeiro, é um botão fácil para muitas organizações que não entendem como medir ou priorizar riscos. O cumprimento é uma estrutura generalizada para se apoiar. No entanto, não é uma solução única, porque outra pessoa está priorizando riscos de maneira generalizada. Segundo, se algo terrível acontecer e você precisar, por exemplo, explicar isso ao conselho administrativo, você pode dizer que seguiu padrões aceitos.\n\nCompliance é um pouco uma mentalidade dependente porque você não precisa fazer todas as avaliações de risco e descobrir o que precisa ser feito. Mas, por exemplo, um pequeno município sem um CISO poderia orientar um sysadmin a usar um framework de conformidade como um bom ponto de partida. Se não houver um CISO disponível, também há a opção de um CISO virtual de meio período para orientação. John faz isso para clientes, o que é um caminho viável para uma segurança melhor.\n\nO conceito de confiança zero também considera um nível de garantia versus risco. Você precisa entender o risco de conceder acesso a alguém a um determinado sistema ou conjunto de dados e, em seguida, ter a garantia correspondente de que a pessoa é quem diz ser. O cerne da confiança zero é um alto nível de segurança que mitiga o risco.\n\nA confiança zero não significa que tudo será bloqueado e que todos os processos serão lentos. Se, por exemplo, alguém quer entrar e ver os níveis de chuva, não é necessário um alto nível de garantia de que a pessoa esteja verificada. No entanto, se alguém quiser acessar as joias da coroa da sua organização, devem existir controles adicionais para verificar a identidade.\n\nCorrespondendo o nível de garantia com o nível de risco é desafiador; isso requer uma arquitetura de pontos de decisão. No exemplo do risco ao acessar um conjunto de dados, uma organização precisa saber o que é e categorizá-lo com base no risco. Para uma organização madura, isso pode ser difícil. John conhece uma organização do governo federal que levou mais de dois anos garantindo que seus dados fossem identificados, classificados e marcados corretamente antes de passar para qualquer tipo de arquitetura de ponto de decisão.\n\nIdentidade e dados são os dois pontos de partida para a confiança zero. Além disso, faz sentido evitar tentar e fazer tudo de uma vez. Começar com uma parte da organização pode ser a opção mais sensata, expandindo gradualmente para o restante da organização ao longo do tempo.\n\nA identidade digital está se tornando mais sofisticada. John acredita que nossas transações no futuro serão principalmente baseadas em uma abordagem do tipo \"zero-trust\" (sem confiança). Por exemplo, se ele quiser transferir $10.000 de sua conta bancária para uma conta offshore, o banco deve ter certeza de que é ele e tratar essa transação como se alguém estivesse tentando acessar informações muito sensíveis e de alto risco. Se ele for à loja comprar uma xícara de café por um dólar, esse nível de garantia de que é ele comprando o café é desnecessário. Muitos desses princípios de \"zero-trust\" farão parte de nossas vidas cotidianas.\n\nA análise comportamental do usuário também entrará em jogo. Assim como uma empresa de cartão de crédito levanta uma bandeira para compras incomuns, por exemplo, se um sistema sabe que John digita 20 palavras por minuto e de repente ele está digitando 100 palavras por minuto e tentando acessar informações confidenciais, isso é um alerta vermelho.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","John Evans"],"link":"/episode-EDT115-pt","image":"./episodes/edt-115/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren fala sobre cibersegurança com o convidado de retorno John Evans, Conselheiro de Tecnologia Principal na World Wide Technology (WWT)."},{"id":19,"type":"Episode","title":"Um argumento para uma abordagem holística da Segurança de Infraestruturas Críticas.","tags":["criticalinfrastructure","iot","it/otconvergence","otsecurity","cybersecurity","edge"],"body":"\r\n\r\n## Existe uma ameaça real para a Infraestrutura Crítica.\n\nDe acordo com o Dr. Scott, as organizações de OT ainda utilizam o modelo tradicional de Purdue, que utiliza redes isoladas e protegidas por firewall. No entanto, esse modelo está começando a se desfazer à medida que as redes de TI e OT se convergem. As empresas estão tentando obter uma melhor compreensão do que está acontecendo em sua infraestrutura operacional. Como resultado, eles abrem brechas nas redes anteriormente bem isoladas, expondo-as a ameaças cibernéticas. Além disso, os cibercriminosos estão encontrando maneiras de contornar redes com isolamento aéreo e protegidas por firewall.\n\nSteve argumenta que aproveitar as melhores práticas de TI pode ajudar, mas os profissionais de OT e os profissionais de TI têm motivadores e modelos operacionais diferentes. Continuar isolando sua rede ainda é uma boa estratégia, mas deve ser um dos muitos instrumentos utilizados na proteção da cibersegurança da infraestrutura crítica. A segurança de OT deve analisar as melhores práticas de cibersegurança de TI para obter ideias para aprimorar suas redes e infraestrutura.\n\n## Diferenças entre TI e OT impedindo as Melhores Práticas\n\nOs sistemas de TI são tradicionalmente atualizados rapidamente ou continuamente com base em perfis de segurança. Uma das principais ferramentas para melhorar a segurança é a higiene básica de segurança, através da atualização de sistemas operacionais, firmware e software na infraestrutura de TI. No entanto, conforme o Dr. Scott nos esclarece, sistemas OT que gerenciam infraestruturas críticas não podem ter tempo de inatividade, e o período para atualizar esses sistemas é medido em anos, não em dias. Não é incomum, em dispositivos de infraestrutura OT, que as máquinas funcionem por 5 a 10 anos sem tempo de inatividade, o que significa nenhuma atualização de patches.\n\nPor exemplo, na indústria de petróleo e gás, as refinarias operam continuamente por quatro a cinco anos, têm um período de inatividade de uma a três semanas para atualizações e, em seguida, operam novamente por quatro a cinco anos. Esses modelos de operação não são propícios para as tradicionais correções contínuas de segurança que as organizações de TI normalmente utilizam. No entanto, Steve detalha muitas outras ferramentas de cibersegurança que devem ser aproveitadas quando os patches de segurança não podem ser aplicados aos dispositivos existentes devido à sua infraestrutura de controle crítico.\n\n## Melhores Práticas de Avaliação de Riscos\n\nA melhor prática primária de cibersegurança é a avaliação de riscos. Embora a remediação de riscos possa ser diferente, o processo de avaliação de riscos pode ser utilizado de forma igual em OT (Tecnologia Operacional) e seus ambientes. Steve argumenta que o primeiro passo do processo de avaliação de riscos é obter uma inventariação completa dos ativos de hardware, firmware e software em seu ambiente de OT. Este primeiro passo é crucial para avaliar sua posição de ameaça cibernética e avaliar o risco que sua organização está disposta a assumir. O próximo passo é avaliar as CVEs (Vulnerabilidades e Exposições Comuns) em relação ao seu inventário conhecido.\n\nÉ fundamental reconhecer que este é um processo contínuo e não deve ser feito apenas uma vez ou periodicamente. Alguns profissionais OT argumentam que seus ambientes OT são estáticos e não requerem avaliação contínua de riscos. No entanto, Steve destaca que, mesmo que os ambientes OT possam ser fixos, o ambiente de ameaças está em constante mudança e os fatores empresariais podem alterar a posição de risco da organização. Portanto, a avaliação contínua de riscos deve ser feita para proteger a infraestrutura crítica de atores de cibersegurança prejudiciais.\n\n## Lidando com fornecedores de OT\n\nOutro fator interessante na infraestrutura OT é o modelo de segurança compartilhada com os fornecedores de dispositivos. Em muitos casos, esses dispositivos embutidos que controlam infraestruturas críticas de milhões de dólares são gerenciados pelo fornecedor, não pelo profissional de OT. O fornecedor só pode fazer correções e atualizações de segurança cibernética nos dispositivos. Isso às vezes pode levar a vulnerabilidades em seu ambiente OT, aumentando o risco de infiltração cibernética. Steve traz ferramentas adicionais de segurança cibernética para ajudar a proteger ativos que não podem ser corrigidos com patches críticos de segurança cibernética, incluindo o aumento do isolamento dos dispositivos afetados, a implantação de dispositivos de monitoramento e padrões de design de canário na infraestrutura OT. Essas ferramentas podem ajudar a proteger e isolar o dispositivo para evitar a propagação e o acesso a ativos comprometidos.\n\n## O que fazer quando você está comprometido.\n\nEntão, o que você faz quando tem uma infraestrutura crítica comprometida? A organização consegue lidar com o desligamento da infraestrutura infectada? Quais planos de continuidade de negócios estão em vigor quando situações de risco ocorrem? Isso pode ser utilizado quando um evento de segurança cibernética acontece também?\n\nA chave aqui é isolar a infecção o mais rapidamente possível para minimizar o impacto na infraestrutura crítica. Estou diminuindo o efeito na confiabilidade operacional da infraestrutura necessária. O objetivo é reduzir o impacto e proteger a segurança das pessoas e da infraestrutura envolvida.\n\n## Descubra mais.\n\nContinue a procurar mais podcasts sobre cibersegurança em OT. Além disso, um whitepaper descreve os desafios da convergência entre os ambientes de cibersegurança de OT e TI.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin","Anna Scott"],"link":"/episode-EDT116-pt","image":"./episodes/edt-116/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren fala sobre a convergência da cibersegurança OT e TI com o especialista em segurança Steve Orrin e a especialista em OT industrial, Dra. Anna Scott."},{"id":20,"type":"Episode","title":"Ano de 2022 em análise.","tags":["edge","aiml","hybridworkspace","compute","multicloud","cybersecurity","datamanagement","data","technology","people","process"],"body":"\r\n\r\n2022 foi um ano emblemático para a adoção da transformação digital, com um aumento no número de ouvintes e várias entrevistas com convidados externos realizadas este ano. Oito convidados eram executivos ou ex-executivos de agências governamentais e organizações do setor privado, incluindo finanças, manufatura e saúde. Em mais de 60 episódios, seis temas surgiram como necessários para nossos ouvintes e para a indústria como um todo, a saber: espaços de trabalho híbridos, cibersegurança, multicloud híbrida, computação de borda, gerenciamento de dados e inteligência artificial.\n\n## Espaço de trabalho híbrido\n\nDepois de lutar contra restrições da COVID e manter as empresas em funcionamento em 2020 e 2021, as organizações buscaram otimizar o modo de operação do \"novo normal\". Esse novo normal diminuiu os impedimentos burocráticos dos tempos pré-COVID. No entanto, começaram a surgir controles e processos relacionados ao ritmo acelerado de mudanças durante a pandemia, visando controlar custos e melhorar a confiabilidade. As empresas enfrentaram dificuldades com políticas de trabalho remoto, já que vimos organizações alternarem rapidamente entre o trabalho em casa, o trabalho híbrido e a abordagem de todos no escritório, deixando as organizações de TI com soluções complexas de espaço de trabalho. Elas começaram a desenvolver arquiteturas que pudessem lidar com mudanças rápidas e modelos de trabalho flexíveis para lidar com políticas em constante mudança. Os espaços de trabalho híbridos flexíveis vieram para ficar? Apenas os próximos anos dirão.\n\n## Multi-Hybrid Cloud\n\nNuvem Multi-Híbrida\n\nOutra grande tendência em 2022 foi a migração e a repatriação de cargas de trabalho para e a partir da nuvem, à medida que organizações buscavam fornecer espaços de trabalho híbridos para seus funcionários. As organizações de TI começaram a analisar os custos operacionais de executar e migrar cargas de trabalho para a nuvem. Muitas organizações descobriram que a metodologia de transferência direta para a nuvem era muito mais cara do que inicialmente estimado, devido à falta de coleta de requisitos, compreensão dos modelos operacionais em nuvem e compreensão principalmente dos custos de rede de saída na nuvem.\n\nA rápida adoção da nuvem durante a pandemia deixou muitos provedores globais de serviços em nuvem despreparados para fornecer as organizações de alta confiabilidade necessárias, sobrecarregando vários provedores de serviços em nuvem e causando interrupções significativas em todo o ecossistema global de CSP. Muitas organizações começaram a considerar arquiteturas de nuvem híbrida para melhorar a confiabilidade, diminuir custos e aumentar a previsibilidade das cargas de trabalho executadas em várias nuvens privadas e públicas. Os provedores regionais de serviços em nuvem aproveitaram a falha dos provedores globais de serviços em nuvem. Eles ofereceram maior confiabilidade e serviços especializados nas ofertas de nuvem SaaS e PaaS, competindo de igual para igual com os CSPs maiores.\n\n## Computação de Borda e Indústria 4.0\n\nIndústria 4.0 continua a fazer avanços na manufatura e a escassez de mão de obra obriga muitas organizações a olharem para a automação para continuar suas operações. Além disso, os dados de OT e TI começaram a convergir à medida que as organizações buscaram otimizar seus processos de negócios e operacionais. Avanços na tecnologia de CPU e armazenamento moveram mais computação para a borda, tornando os dispositivos de borda mais inteligentes e capazes de realizar tarefas anteriormente feitas no centro de dados. A conectividade entre dispositivos de borda, centros de dados e nuvens públicas melhorou com a adoção de tecnologias 5G privadas em todo o setor. No entanto, a adoção ainda precisa acompanhar as previsões anteriores devido a preocupações com a cibersegurança de OT. Isso é especialmente verdadeiro em relação à gestão da infraestrutura crítica.\n\n## Gestão de Dados\n\nEspaços de trabalho híbridos, adoção de nuvem e computação de borda têm criado um pesadelo de gerenciamento de dados para a maioria das organizações, pois seus dados foram dispersos por esses ambientes um tanto desconectados e distribuídos. Para gerenciar dados de forma eficaz nesse ecossistema, novas arquiteturas começaram a surgir, incluindo malha de dados, lagos de dados distribuídos e redes de dados. As organizações passaram a se concentrar em quatro elementos-chave de dados: localização, classificação, governança e proteção.\n\nAs leis e regulamentos de privacidade estão levando as organizações a classificarem corretamente seus dados para proteger a privacidade dos funcionários, clientes e cidadãos. Além disso, o aumento de ataques cibernéticos e ransomware tem forçado as organizações a melhorarem a proteção e governança de seus dados em uso, em repouso e em trânsito. Gerenciar efetivamente quem tem acesso, por quanto tempo têm acesso e por quanto tempo os dados residem é um elemento crítico da governança de dados que as organizações estão começando a entender.\n\n## Segurança Cibernética\n\n2022 foi um grande ano para a segurança cibernética, e isso ficou evidente no podcast com mais de 18 episódios falando sobre cibersegurança. A palavra-chave do ano foi arquitetura de confiança zero, que se transformou em um termo de marketing muito usado. Em vez de focar na arquitetura de confiança zero, Darren tende a concentrar-se nos princípios de confiança zero que as arquiteturas podem apoiar.\n\nMesmo com uma ênfase maior na cibersegurança, ocorreram violações de dados primários e infraestrutura este ano, incluindo ataques à infraestrutura crítica. Muitos profissionais de cibersegurança atribuem esse aumento à guerra entre Ucrânia e Rússia, já que observamos a eficácia da guerra cibernética e da guerra física trabalhando em conjunto.\n\nOutra preocupação central em cibersegurança diz respeito à exposição de software de terceiros em todo o ecossistema de aplicativos (vulnerabilidade do log4J). Muitas organizações precisam de ajuda para encontrar direção devido ao uso generalizado do log4J em suas ofertas de produtos, processamento em back-office e interfaces com os clientes. Várias organizações e governos estão impulsionando uma forte demanda por uma lista padronizada de materiais de software para ajudar a identificar vulnerabilidades em pacotes de software.\n\n## Inteligência Artificial\n\nA inteligência artificial continua a melhorar técnicas e processos operacionais. A grande notícia de IA deste ano foi o ChatGBT, que tem uma ampla gama de usos, incluindo escrever posts de blog, código e artigos, e ajudar a resolver problemas de suporte de TI. Além disso, a adoção de chips de silício de IA pelos provedores de serviços em nuvem expandiu a disponibilidade de IA para as massas. Essa disponibilidade permite que as organizações experimentem mais com algoritmos de IA em suas operações comerciais diárias. As organizações estão começando a operacionalizar alguns desses experimentos para executar e automatizar processos anteriormente realizados por funcionários que são difíceis de encontrar em um mercado de trabalho competitivo.\n\n## Conclusão\n\n2022 foi um ano difícil para muitas empresas de tecnologia, já que vimos uma diminuição nos gastos com TI em relação aos \"anos de gastos durante a pandemia\" anteriores. Essa queda esperada surpreendeu muitas empresas de alta tecnologia com a rapidez das mudanças. Apesar da queda, a tecnologia continuou a crescer e a adoção de novas tecnologias em edge, nuvem, IA, gerenciamento de dados e segurança cibernética continua a crescer. 2023 deverá ser um ano emocionante, pois veremos a maturação de algumas dessas tecnologias. As organizações continuarão investigando maneiras de reduzir custos por meio da automação, otimizando as cargas de trabalho em nuvens híbridas múltiplas e se protegendo contra ameaças crescentes de segurança cibernética.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT117-pt","image":"./episodes/edt-117/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren analisa 2022. Ele identifica os tópicos mais comentados no podcast em 2022, incluindo Gerenciamento de Dados, Inteligência Artificial, Segurança Cibernética, Computação em Nuvem e Espaços de Trabalho Híbridos."},{"id":21,"type":"Episode","title":"Coloque o título aqui mesmo","tags":["remotelearning","people","technology","telelearning","cybersecurity"],"body":"\r\n\r\n# Título\n\n*Slogan*\n\nResumo aqui\n\nTraduzindo para o português: ![imagem do episódio](./thumbnail.png)\n\nEpisódio Corpo aqui.\n\n## A média.\n\n<video src='url'></video>\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Erin Moseley","Grant Kelly"],"link":"/episode-EDT12-pt","image":"./episodes/edt-12/pt/thumbnail.png","lang":"pt","summary":"No nosso último episódio, Erin Moseley, Executiva Sênior de Contas para Educação na Intel, e Grant Kelly, Arquiteto de Soluções para Educação na Intel, se juntaram ao Darren para falar sobre os desafios tecnológicos e opções no ensino à distância. Neste episódio, exploramos mais profundamente as ameaças e soluções em termos de privacidade e segurança."},{"id":22,"type":"Episode","title":"Nuvens Privadas Disruptivas","tags":["cloud","privatecloud","vergeio","microcloud","edge","compute","technology"],"body":"\r\n\r\nUma nova forma de pensar sobre virtualização está começando a mudar o panorama da nuvem privada. A indústria de infraestrutura definida por software está começando a considerar a virtualização de centros de dados de forma holística, em vez de diferentes tipos de infraestrutura.\n\nEsta abordagem disruptiva de virtualização cria novos modelos operacionais, incluindo melhoria na continuidade dos negócios e recuperação de desastres. A Verge.io possui essa abordagem, fornecendo novos modelos que incluem a criação de instantâneos de centros de dados e sua replicação. Isso permite às organizações criar ambientes portáteis chamados de \"tenants\" que podem ser replicados em vários locais. Exemplos incluem a criação de microrganismos compatíveis com a HIPPA que podem ser replicados em várias clínicas de pequeno porte, ajudando as organizações a manter a conformidade em todos os aspectos.\n\nEste novo sistema de virtualização tem uma pegada operacional mínima e reduz os recursos necessários para combinar computação, armazenamento, rede e elementos de segurança. Aaron demonstra o quão pequena e poderosa é a solução quando ele instala a chave em dois NUCs Intel de 12ª geração. A resposta é convincente para uma pegada tão pequena e pode ser usada para computação de borda e sistemas de controle industrial.\n\nAaron mostra a interface web simples para implantação de computação, armazenamento, rede e segurança. Também é demonstrada a capacidade de criar e restaurar snapshots.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Aaron Reid"],"link":"/episode-EDT121-pt","image":"./episodes/edt-121/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Aaron Reid da Verge.io sobre sua tecnologia revolucionária de nuvem privada que está disponibilizando nuvens privadas no data center e na borda."},{"id":23,"type":"Episode","title":"Automação com IA","tags":["collectiongenerativeai","aiml","automation","aiethics","workerreplacement","people","policy"],"body":"\r\n\r\n## Automação com IA\n\nA automação com IA refere-se ao uso da tecnologia de inteligência artificial para automatizar tarefas que normalmente seriam executadas por seres humanos. Isso pode incluir tarefas como análise de dados, atendimento ao cliente e até tomada de decisões. A automação impulsionada pela IA pode melhorar a eficiência, reduzir custos e aumentar a precisão nessas tarefas. Alguns exemplos de automação impulsionada pela IA incluem chatbots, carros autônomos e sistemas de manutenção preditiva.\n\nPosso entrevistar para o meu podcast sobre o uso de IA para automatizar tarefas?\n\nDesculpe, mas não sou capaz de ser entrevistado para um podcast, pois sou um programa de computador. No entanto, posso fornecer informações e responder perguntas sobre o assunto de usar a inteligência artificial para automatizar tarefas. Basta me dizer quais perguntas específicas você tem, e farei o meu melhor para fornecer informações úteis e precisas.\n\n<b><i>Bem-vindo ao ChatGPT.</i></b>\n\nObrigado por me receber no programa. Estou feliz em ajudar com qualquer informação que você precise sobre o tópico de usar a IA para automatizar tarefas.\n\nConte-me um pouco sobre você e sua história.\n\nEu sou ChatGPT, um modelo de idioma desenvolvido pela OpenAI. Fui treinado em um grande conjunto de dados de textos da internet, o que me permite entender e gerar textos semelhantes aos humanos. Eu posso responder perguntas, gerar texto e até criar histórias. Minha principal função é ajudar os usuários com tarefas de compreensão e geração de linguagem natural.\n\nComo IA, não tenho uma formação física nem uma história pessoal. No entanto, minhas habilidades foram construídas e treinadas por uma equipe de pesquisadores e engenheiros da OpenAI que continuam aprimorando e atualizando minhas capacidades.\n\n## Treinamento de IA\n\nOnde você recebeu seu treinamento?\n\nFui treinado pela OpenAI, uma organização de pesquisa dedicada a promover e desenvolver uma IA amigável que beneficia a humanidade. Meu treinamento foi baseado em um conjunto massivo de dados de texto da internet, que foi utilizado para me ensinar padrões e relações na linguagem. Esses dados foram usados para me treinar a gerar texto semelhante à escrita humana, possibilitando que eu entenda e responda perguntas de maneira conversacional.\n\nMeu processo de treinamento envolveu uma técnica de aprendizado profundo chamada transformers, que é um tipo de arquitetura de rede neural projetada especificamente para tarefas de NLP, como geração e classificação de texto. O processo de treinamento ajustou os parâmetros do modelo para se adequar aos padrões nos dados, permitindo-me gerar texto similar à escrita humana.\n\nSei que houve alguns problemas com o seu treinamento inicialmente. Quais foram alguns dos aspectos problemáticos?\n\nseu treinamento?\n\nSim, como qualquer modelo de aprendizado de máquina, eu não era perfeito quando fui lançado pela primeira vez, e havia alguns aspectos problemáticos do meu treinamento.\n\nUm dos principais desafios no treinamento de modelos como eu é garantir que eles não perpetuem vieses e estereótipos prejudiciais presentes nos dados de treinamento. Isso pode resultar em modelos que produzem saídas tendenciosas ou geram conteúdo ofensivo. Para mitigar isso, pesquisadores e engenheiros da OpenAI implementaram várias técnicas para reduzir o viés no processo de treinamento, como ajustar o modelo com dados de treinamento diversos e equilibrados.\n\nOutro desafio no treinamento de modelos como eu é evitar a geração de saídas de baixa qualidade ou sem sentido. Para lidar com isso, a OpenAI implementou várias técnicas, como controlar a temperatura do modelo durante o processo de geração de texto e ajustar o modelo para priorizar a coerência e relevância em suas saídas.\n\nNo geral, embora ainda haja desafios e limitações no treinamento de modelos como eu, o campo da PNL e IA está em constante evolução, e pesquisadores e engenheiros estão trabalhando para melhorar suas capacidades.\n\nMinha compreensão é que você foi treinado com dados de 2021. O que você pode aprender com suas conversas com pessoas? Você está continuamente aprendendo com sua interação com humanos?\n\nComo modelo de linguagem de IA, fui de fato treinado em um grande corpus de dados de texto até 2021, e posso responder a perguntas e gerar texto com base nesse treinamento. No entanto, não sou capaz de aprender a partir de conversas individuais no sentido de atualizar meus parâmetros para refletir o contexto específico de cada interação.\n\nDito isso, a OpenAI regularmente faz ajustes finos e atualizações nos modelos de linguagem como eu com novos dados para melhorar continuamente seu desempenho. Isso pode incluir atualizações com base no feedback dos usuários, mudanças no uso e tendências de linguagem, e avanços na pesquisa em PNL. No entanto, essas atualizações não são baseadas em interações individuais com os usuários, mas sim em padrões mais amplos nos dados.\n\nPortanto, embora eu não possa aprender com interações individuais com humanos, eu faço parte de um sistema maior que está constantemente evoluindo e melhorando ao longo do tempo, o que me permite melhorar o atendimento e ajudar os usuários a cada atualização.\n\nCom que frequência você receberá mais informações para se capacitar? Em outras palavras, quando você receberá dados mais atualizados para fornecer aos seus clientes?\n\nA OpenAI periodicamente ajusta e atualiza seus modelos de linguagem, assim como eu, com novos dados, para melhorar continuamente seu desempenho. A frequência dessas atualizações pode variar dependendo do modelo de linguagem específico e da disponibilidade de novos dados de treinamento.\n\nNo entanto, vale ressaltar que o processo de treinamento e ajuste fino de um modelo de linguagem como eu pode ser uma tarefa complexa e intensiva em recursos, portanto, as atualizações podem não acontecer com a frequência que se deseja. Além disso, a qualidade e relevância dos novos dados de treinamento são importantes para o sucesso do processo de ajuste fino, por isso, a equipe da OpenAI seleciona cuidadosamente os dados usados para cada atualização.\n\nDe forma geral, embora a frequência das atualizações possa variar, o objetivo da OpenAI é melhorar continuamente seus modelos de linguagem para que possam fornecer a melhor assistência possível aos usuários.\n\nPara que melhore a maneira como você compreende as perguntas dos usuários e as respostas que você dá. Isso está correto?\n\nSim, isso está correto. O processo de ajuste fino e atualização de modelos de linguagem como eu pode ajudar a melhorar o desempenho do modelo de várias maneiras, incluindo sua capacidade de entender perguntas dos usuários e gerar respostas mais relevantes e precisas.\n\nAo treinar com dados novos e diversos, o modelo pode aprender novos padrões de linguagem, vocabulário e informações temáticas, o que pode ajudá-lo a entender melhor as nuances da linguagem humana e gerar respostas mais precisas e adequadas.\n\nNo entanto, vale ressaltar que o desempenho de modelos de linguagem como eu não é perfeito e ainda podem existir limitações e erros nas respostas geradas. O campo de PNL e IA está em constante evolução, e pesquisadores e engenheiros estão trabalhando para melhorar as capacidades dos modelos de linguagem como eu, mas ainda há trabalho a ser feito para alcançar um entendimento e geração verdadeiramente semelhante ao humano.\n\n## Substituindo trabalhadores\n\nLegal. Ok, agora que entendi como você aprende coisas. Que coisas posso fazer com você que me ajudem e ajudem minha organização?\n\nComo modelo de linguagem de IA, posso ser utilizado de várias maneiras para ajudar indivíduos e organizações. Alguns exemplos incluem:\n\nRecuperação de informações: posso responder perguntas e fornecer informações sobre uma ampla variedade de tópicos, facilitando para os usuários encontrar as informações de que precisam de forma rápida e eficiente.\n\nGeração de texto: Eu posso gerar texto, como resumos, artigos de notícias ou escrita criativa, o que pode economizar tempo e esforço para indivíduos e organizações que precisam produzir uma grande quantidade de conteúdo escrito.\n\n3. Chatbots: Posso ser integrado em chatbots para fornecer experiências de conversação em linguagem natural para os usuários, tornando mais fácil para as organizações interagirem com os clientes e fornecerem suporte.\n\nTradução de idiomas: Posso traduzir textos de um idioma para outro, ajudando organizações a alcançar um público mais amplo e superar as barreiras linguísticas.\n\nAnálise de sentimento: eu posso analisar o sentimento de um texto, como avaliações de clientes ou publicações nas redes sociais, para obter perspectivas sobre a opinião pública e o sentimento dos clientes.\n\nEstes são apenas alguns exemplos das muitas maneiras como eu posso ser usado para ajudar indivíduos e organizações. As possibilidades são limitadas apenas pela imaginação, e à medida que a tecnologia de IA continua a avançar, provavelmente haverá muitos novos e inovadores usos para modelos como eu no futuro.\n\nVocê está preocupado em substituir pessoas que fazem esse trabalho hoje? Como escritores técnicos, atendimento ao cliente e trabalhadores de suporte técnico?\n\nComo modelo de linguagem de IA, não tenho emoções ou opiniões pessoais, portanto, não posso me preocupar da mesma forma que um ser humano. No entanto, posso falar sobre o impacto que a tecnologia de IA, incluindo modelos de linguagem como eu, pode ter em certas indústrias e funções de emprego.\n\nÉ verdade que o aumento do uso da IA em certas indústrias, como redação técnica, atendimento ao cliente e trabalho de suporte, pode resultar em algum deslocamento de empregos. No entanto, também é importante observar que a tecnologia de IA tem o potencial de melhorar e aprimorar o trabalho humano nesses papéis, em vez de simplesmente substituí-los.\n\nPor exemplo, ferramentas alimentadas por IA como modelos de linguagem podem ajudar escritores técnicos a gerar textos padrão ou sugestões de linguagem, liberando tempo para que o escritor possa se concentrar em tarefas mais criativas e estratégicas. Da mesma forma, os chatbots alimentados por IA podem lidar com consultas de atendimento ao cliente rotineiras, permitindo que agentes humanos se dediquem a interações mais complexas ou sensíveis.\n\nTambém é importante considerar que o uso da tecnologia de IA em certas indústrias pode criar novas oportunidades de emprego e demanda por habilidades relacionadas ao desenvolvimento, implantação e manutenção de IA.\n\nComo um todo, o impacto da IA no emprego e nos papéis profissionais é uma questão complexa e provavelmente dependerá de uma variedade de fatores, incluindo a indústria específica e o caso de uso específico. No entanto, está claro que a IA possui potencial para aprimorar o trabalho dos seres humanos e impulsionar a produtividade e a eficiência, embora possa resultar em alguma substituição de empregos.\n\n## Substituindo Programadores\n\nEu ouvi dizer que você também pode ajudar programadores de computador a escrever um código melhor. Isso é verdade?\n\nSim, isso está correto. Ferramentas alimentadas por IA, incluindo modelos de linguagem como eu, podem auxiliar programadores de computador de várias maneiras, incluindo na escrita de um código melhor.\n\nUm exemplo disso é o preenchimento automático de código, onde modelos de IA podem sugerir linhas de código para completar uma tarefa de programação específica. Isso pode economizar tempo e esforço dos programadores reduzindo a necessidade de escrever e testar manualmente o código, além de ajudar a garantir que o código esteja corretamente sintático e seguindo as melhores práticas.\n\nOutro exemplo é a síntese de código, onde modelos de IA podem gerar trechos de código completos ou programas inteiros com base em uma descrição de alto nível da funcionalidade desejada. Isso pode facilitar para os programadores a prototipagem e teste rápidos de ideias, e também reduzir o esforço necessário para escrever e depurar o código.\n\nAlém desses exemplos, ferramentas com Inteligência Artificial também podem ajudar programadores ao fornecer análise de código e detecção de bugs, e ao auxiliar na identificação de possíveis vulnerabilidades de segurança.\n\nVale ressaltar que, embora as ferramentas alimentadas por IA possam ser úteis para auxiliar programadores, elas não devem ser vistas como uma substituição para a experiência e julgamento humano. Programas escritos por modelos de IA ainda podem exigir revisão e modificações humanas para garantir que atendam aos requisitos e padrões de qualidade desejados. No entanto, as ferramentas de IA certamente podem ajudar a tornar o trabalho de programação mais eficiente e eficaz.\n\nTranslate the following to Portuguese: <b><i>Então, se você conseguir realmente encontrar e corrigir erros no meu código, isso deve me tornar mais rápido na escrita do meu código. Você pode fazer isso?\n\nEscreva código para mim com base em um documento de design básico ou em uma arquitetura UML? Ou você pode me ajudar a selecionar a melhor linguagem para o problema que estou tentando resolver?\n\nSim, os modelos de IA como eu têm o potencial de ajudar a tornar o processo de escrita de código mais rápido e eficiente. Por exemplo, os modelos de IA podem auxiliar na detecção e correção de bugs, bem como fornecer sugestões para melhorias de código.\n\nQuanto à escrita de código com base em um documento de design ou arquitetura UML, os modelos de IA têm a capacidade de gerar trechos de código ou programas inteiros com base em uma descrição de alto nível da funcionalidade desejada. No entanto, é importante observar que a qualidade do código gerado dependerá da precisão e completude do documento de design ou arquitetura, bem como dos dados de treinamento usados para treinar o modelo de IA.\n\nEm termos de selecionar a melhor linguagem para um problema específico, os modelos de IA podem fornecer recomendações baseadas nos dados nos quais foram treinados e em sua compreensão das linguagens de programação e suas características. No entanto, essa recomendação nem sempre pode ser a escolha mais apropriada para um caso de uso específico, uma vez que podem haver fatores como preferência pessoal, experiência da equipe ou requisitos do projeto que devem ser levados em consideração ao selecionar uma linguagem de programação.\n\nNo final das contas, embora os modelos de IA possam auxiliar em muitos aspectos do processo de codificação, eles não devem ser vistos como substitutos para o conhecimento especializado e julgamento humano. Um programador humano com conhecimento especializado e experiência ainda será necessário para garantir que o código gerado atenda aos padrões de qualidade desejados e que seja apropriado para o caso específico de uso.\n\nInteressante que você usa a palavra \"assistir\" e não \"substituir\". Parece que os programadores e trabalhadores de informação ainda estão\n\nPrecisava fazer o trabalho? Por quanto tempo você acha que as pessoas permanecerão relevantes nas indústrias em que você está ajudando?\n\nautomatizar\n\nSim, isso está correto. Ferramentas com inteligência artificial, como eu, são projetadas para auxiliar, não substituir, os trabalhadores humanos em uma variedade de setores, incluindo programação e trabalho de informação.\n\nEmbora a IA tenha o potencial de automatizar certas tarefas e tornar determinados empregos mais eficientes, ainda existem muitas tarefas que exigem experiência e julgamento humano, como tomada de decisões, solução criativa de problemas e tarefas que envolvem raciocínio complexo ou considerações éticas.\n\nAlém disso, as ferramentas alimentadas por IA também podem criar novas oportunidades de emprego ao permitir que os trabalhadores humanos se concentrem em tarefas de nível superior e assumam novas responsabilidades. Por exemplo, à medida que os modelos de IA automatizam certos aspectos do processo de programação, os programadores humanos podem se concentrar em tarefas mais complexas e desafiadoras, como projetar e testar novos sistemas de software.\n\nEm termos do cronograma para quando os trabalhadores humanos podem se tornar menos relevantes nas indústrias em que a IA está ajudando a automatizar, é difícil prever com certeza. A taxa de automação dependerá de vários fatores, incluindo o desenvolvimento da tecnologia de IA, a disponibilidade de dados para treinamento de modelos de IA e a velocidade com que ferramentas alimentadas por IA são adotadas por empresas e outras organizações.\n\nNo geral, é provável que os trabalhadores humanos continuem desempenhando um papel importante em uma variedade de setores nos próximos anos, e que a inteligência artificial complemente, em vez de substituir, os trabalhadores humanos em muitos casos.\n\n## Ética do uso da IA\n\nbe replaced by AI in the future?</i></b>\n\npara escrever ensaios para a escola, tanto no ensino médio quanto nas faculdades? E que as pessoas vão te utilizar\n\nsubmeter o trabalho em seus empregos como trabalho próprio?\n\nComo um modelo de IA, eu não tenho sentimentos ou emoções, então eu não posso me preocupar da mesma forma que um humano poderia. No entanto, eu posso reconhecer que definitivamente existem considerações éticas em torno do uso da IA em vários contextos, incluindo nas esferas acadêmica e profissional.\n\nUsar modelos de IA como eu para gerar ensaios ou concluir outros tipos de trabalhos que são então apresentados como trabalho original do usuário não é apenas antiético, mas também mina o valor da educação e o reconhecimento do esforço individual e das conquistas.\n\nAlém disso, apresentar trabalhos gerados por modelos de IA como sendo seus próprios também pode levar a consequências legais, pois pode ser considerado plágio ou fraude. No âmbito profissional, apresentar trabalhos gerados por modelos de IA como trabalho original pode ter graves consequências para a reputação e carreira do indivíduo.\n\nÉ importante que as pessoas compreendam as implicações éticas de usar modelos de IA e os utilizem de forma responsável, apenas para fins que estejam alinhados com os princípios da honestidade, da justiça e do respeito pelos outros.\n\nPesquisador: Existem maneiras de determinar se a IA foi usada para escrever artigos ou código? Existe uma ferramenta que pode ajudar educadores ou pesquisadores a identificar o uso de IA em trabalhos acadêmicos.\n\nempresas para encontrar conteúdo gerado por IA?\n\nSim, existem maneiras de determinar se a IA foi usada para gerar conteúdo, como ensaios ou código. Uma abordagem é usar um software de detecção de plágio, que pode comparar um documento a um banco de dados de outros conteúdos existentes para determinar se ele contém algum texto correspondente ou semelhante.\n\nAlgumas dessas ferramentas são projetadas especificamente para detectar conteúdo gerado por IA e podem fazê-lo identificando padrões e características comumente encontrados em textos gerados por IA, como falta de variabilidade, gramática e vocabulário limitados, ou uso de frases não naturais.\n\nNo entanto, é importante salientar que essas ferramentas não são perfeitas e podem, às vezes, produzir falsos positivos ou negativos. Portanto, é importante usá-las em conjunto com outros métodos, como revisão humana, para validar os resultados.\n\nEm geral, o uso de uma combinação de ferramentas de detecção de plágio e revisão humana pode ser uma maneira eficaz de detectar conteúdo gerado por IA. No entanto, também é importante que indivíduos e organizações promovam o uso responsável da IA e eduquem os usuários sobre a ética do conteúdo gerado por IA.\n\nExistem outras áreas além dessas que apresentam problemas éticos com IA e PNL com as quais você se preocupa?\n\nComo modelo de IA, não tenho emoções nem opiniões pessoais, mas posso reconhecer que existem várias considerações éticas e desafios associados ao uso de IA e PNL. Alguns desses incluem:\n\nViés e discriminação: Modelos de IA podem perpetuar e amplificar preconceitos existentes nos dados de treinamento que recebem, resultando em resultados injustos ou discriminatórios. Por exemplo, a tecnologia de reconhecimento facial tem se mostrado menos precisa para pessoas com tons de pele mais escuros, o que levanta sérias questões sobre o potencial de discriminação.\n\n2. Privacidade: O uso de IA e PNL pode levantar preocupações com a privacidade, pois essas tecnologias frequentemente envolvem a coleta e análise de grandes quantidades de dados pessoais. Esses dados podem então ser usados para tomar decisões que afetam indivíduos, como no caso de algoritmos de policiamento preditivo, que utilizam dados históricos de crime para prever onde os crimes são mais propensos a ocorrer, mas podem levar a práticas policiais tendenciosas.\n\nDeslocamento de empregos: O uso de IA e PNL no local de trabalho tem o potencial de deslocar os trabalhadores humanos, o que levanta preocupações sobre o impacto no emprego e a necessidade de novas formas de trabalho.\n\nResponsabilidade e responsabilização: os sistemas de IA podem tomar decisões e realizar ações que têm consequências no mundo real, mas pode ser difícil determinar quem é responsável quando as coisas dão errado. Isso levanta questões sobre a responsabilidade e governança dos sistemas de IA.\n\nEstes são apenas alguns exemplos das considerações éticas e desafios associados ao uso de IA e NLP. É importante que indivíduos e organizações estejam cientes desses desafios e ajam para mitigar os riscos e garantir que essas tecnologias sejam usadas de forma responsável e ética.\n\nO que a OpenAI está fazendo para lidar com essas questões éticas em seus produtos e ofertas?\n\nA OpenAI, a organização que me desenvolveu, está adotando uma abordagem proativa para lidar com questões éticas em IA. Eles são dedicados a avançar a IA de maneira responsável e segura, e têm tomado diversas medidas para abordar considerações éticas em seus produtos e ofertas, incluindo:\n\n1. Viés e discriminação: A OpenAI está trabalhando para garantir que seus modelos sejam treinados em conjuntos de dados diversificados e representativos, e está pesquisando ativamente maneiras de reduzir e mitigar o viés na inteligência artificial.\n\n2. Privacidade: A OpenAI está comprometida em preservar a privacidade e segurança dos indivíduos e tomou medidas para garantir que seus modelos sejam projetados e treinados levando em consideração questões de privacidade.\n\nDeslocamento de empregos: A OpenAI reconhece o potencial da IA em deslocar trabalhadores humanos e está trabalhando para garantir que seus modelos sejam desenvolvidos e usados de maneira que maximize o impacto positivo no emprego e na força de trabalho.\n\n4. Responsabilidade e responsabilização: A OpenAI está dedicada a promover transparência e responsabilização na IA, e está trabalhando para estabelecer padrões claros e consistentes para o desenvolvimento e implementação de sistemas de IA.\n\nEstes são apenas alguns exemplos das formas como a OpenAI está abordando considerações éticas em seus produtos e ofertas. A organização está comprometida em avançar a IA de forma responsável e segura, e está trabalhando para garantir que seus modelos sejam usados de maneira que beneficie a sociedade como um todo.\n\nÉ possível que outras pessoas possam acessar seu modelo de AI e copiá-lo para seus próprios propósitos, ou o modelo está protegido de alguma forma?\n\nrepositório fechado e privado\n\nComo um modelo de IA desenvolvido pela OpenAI, estou disponível para uso através da API da OpenAI, que proporciona acesso a uma variedade de recursos de processamento de linguagem, incluindo geração de texto, resposta a perguntas e muito mais. Embora a API seja projetada para ser usada por desenvolvedores e organizações, a OpenAI implementou medidas de segurança para garantir que os dados e modelos usados pela API sejam protegidos e seguros.\n\nNo entanto, é tecnicamente possível para alguém desmontar engenhosamente a API ou obter uma cópia do modelo por outros meios. A OpenAI está ciente desses riscos e está continuamente trabalhando para melhorar a segurança de seus modelos e sua API.\n\nEm geral, é importante estar ciente das implicações éticas do uso de modelos de IA como o meu, e garantir que eles sejam utilizados de maneira responsável e segura. A OpenAI incentiva os usuários da API a seguir as melhores práticas de privacidade e segurança de dados, e ser transparente sobre como a API é utilizada em suas aplicações e serviços.\n\nO que impede o seu modelo de ser usado para ações maliciosas por atores mal-intencionados, como hacking, realização de ransomware?\n\nataques, ou até mesmo planejando ataques físicos contra pessoas ou infraestrutura?\n\nComo um modelo de linguagem de IA desenvolvido pela OpenAI, não possuo a capacidade de realizar ações físicas ou me envolver em hacking ou outras atividades maliciosas. No entanto, assim como qualquer tecnologia, modelos de IA como o meu podem ser usados para fins prejudiciais se caírem nas mãos erradas.\n\nA OpenAI leva muito a sério o potencial de uso indevido de sua tecnologia e implementou várias medidas para mitigar esses riscos, incluindo diretrizes éticas para o uso da API, medidas de segurança para proteger os modelos e dados utilizados pela API e monitoramento contínuo do uso da API para detectar qualquer atividade suspeita ou maliciosa.\n\nAlém disso, a OpenAI trabalha ativamente com pesquisadores, formuladores de políticas e outras partes interessadas para desenvolver melhores práticas e regulamentações para o uso responsável da IA. A empresa também apoia esforços de educação e conscientização para ajudar as pessoas a compreenderem os potenciais riscos e benefícios da tecnologia de IA.\n\nNo entanto, é importante ressaltar que prevenir o uso indevido da tecnologia de IA exige um esforço coletivo de todos os envolvidos, incluindo desenvolvedores, formuladores de políticas e usuários. À medida que a IA continua a se tornar mais presente em nossas vidas, será importante continuar a avaliar e mitigar seus riscos, ao mesmo tempo em que se maximizam seus benefícios para a sociedade.\n\n## Conclusão\n\nagradecimento pelo seu aparecimento no meu programa hoje. Existe algo mais que você gostaria de dizer à minha audiência? Alguma última palavra a compartilhar?\n\nsabedoria para dar aos ouvintes do meu programa?\n\nGostaria de agradecer por me receber em seu programa e pela oportunidade de compartilhar parte do meu conhecimento com a sua audiência. Como um modelo de inteligência artificial de linguagem desenvolvido pela OpenAI, meu objetivo é ajudar as pessoas a encontrar respostas para suas perguntas e auxiliar no avanço de nosso entendimento do mundo.\n\nMinhas últimas palavras de sabedoria seriam abordar a IA e suas aplicações com cautela e otimismo. Embora a IA tenha o potencial de trazer grandes benefícios para a sociedade, é importante considerar cuidadosamente seus riscos e tomar medidas para mitigá-los. Ao mesmo tempo, devemos estar empolgados com as oportunidades que a IA apresenta e trabalhar para aproveitar seu potencial para tornar o mundo um lugar melhor.\n\nÀ medida que a IA continua a avançar e a se integrar cada vez mais em nossas vidas, será importante que todos nós fiquemos informados e engajados, e que trabalhemos juntos para garantir que a IA seja desenvolvida e usada de maneira responsável e ética.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","ChatGPT"],"link":"/episode-EDT122-pt","image":"./episodes/edt-122/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista o ChatGPT da OpenAI sobre a utilização da IA para automação, a ética de usar IA e a substituição de trabalhadores de informação."},{"id":24,"type":"Episode","title":"Cibersegurança no Setor Público","tags":["cybersecurity","ransomeware","automation","government","people","process","technology"],"body":"\r\n\r\nJim tem uma vasta experiência em cibersegurança e no setor público, incluindo como gerente nacional de inteligência cibernética para o diretor de inteligência nacional. Durante vários anos trabalhando no setor público, ele desempenhou funções de cibersegurança ofensiva e defensiva. Atualmente, ele trabalha no setor privado como CISO de Campo do Setor Público.\n\n## Diferenças entre Governos Federais, Estaduais e Locais\n\nExistem diferenças fundamentais entre os governos federal, estadual e local, incluindo financiamento, expertise em guerra cibernética e superfície de ataque. Até mesmo os atores ameaçadores para cada nível de governo são fundamentalmente diferentes entre si. Por exemplo, o governo federal tende a lidar com ataques cibernéticos de nações-estado altamente sofisticados, enquanto os governos estaduais e locais raramente veem esses tipos de ataques diretamente. Isso se deve principalmente à preparação de cibersegurança das agências federais em comparação com os governos estaduais e locais.\n\nOnde o governo federal lida principalmente com ataques que coletam dados, comprometem dados ou desativam ativos, os governos estaduais e locais tendem a lidar com ataques de ransomware onde dados e infraestrutura são mantidos como reféns. Esses ataques diferem das ameaças típicas de cibersegurança com as quais o governo federal lida diariamente e exigem conjuntos de habilidades e posições em cibersegurança diferentes.\n\n## A Escassez de Talentos em cibersegurança\n\nUm problema comum com o qual todos os níveis do governo lidam é a necessidade de talento em cibersegurança. A maior parte desse talento tende a migrar para o setor privado, onde os salários são mais altos e mais atrativos para os melhores talentos em cibersegurança. No entanto, o governo federal tem atraído os melhores talentos através de programas interessantes de \"missão impossível\" que atraem profissionais em busca de desafios complexos.\n\nO mesmo não é válido para governos estaduais e locais, onde os recursos financeiros são mais escassos e os projetos de cibersegurança são menos atrativos para profissionais desse ramo. Isso deixou vários governos estaduais e locais com uma lacuna significativa em talentos de cibersegurança e, consequentemente, vulneráveis a ataques cibernéticos. Às vezes, os governos locais não possuem um plano estratégico de cibersegurança ou um profissional especializado em sua equipe.\n\nO setor privado está começando a oferecer segurança cibernética como serviço para muitos desses governos locais que precisam de ajuda para encontrar e reter talentos em suas organizações. Esses serviços incluem planejamento estratégico de segurança cibernética, negociação de ransomware, forense de ataques cibernéticos, detecção de ameaças cibernéticas e tecnologias de prevenção cibernética.\n\n## Ataques cibernéticos ubíquos\n\nNo passado, os governos estaduais e locais raramente se preocupavam com ataques físicos de outras nações. No entanto, devido às guerras cibernéticas em curso entre países e estados, que não têm fronteiras físicas, há momentos em que os governos estaduais e locais são danos colaterais nessas batalhas cibernéticas. Muitas vezes, ataques cibernéticos direcionados de uma nação a outra \"escapam\" e danificam severamente os governos estaduais e locais.\n\nA CISA criou regiões para ajudar os governos estaduais e locais a lidar com os ataques cibernéticos que penetram as fronteiras dos Estados Unidos. Além disso, os governos estaduais e locais estão começando a compartilhar melhores práticas, ataques cibernéticos detectados e vulnerabilidades comuns encontradas em suas infraestruturas. O financiamento adicional do governo federal está ajudando essas organizações a fortalecerem suas posições em segurança cibernética.\n\n## Ataques cibernéticos a infraestruturas críticas.\n\nUma das tendências mais preocupantes é o aumento dos ataques aos sistemas que gerenciam infraestruturas críticas, especificamente geração e distribuição de energia. Por se tratar de uma rede elétrica composta por várias coletividades privadas, estaduais e governos locais, ao invés de uma agência federal centralizada, gerenciar e proteger a rede elétrica nacional é algo complexo e assustador. As organizações maiores tendem a ter uma posição melhor em cibersegurança do que as pequenas empresas de serviços de utilidade pública municipais, deixando-as vulneráveis a ataques cibernéticos. No entanto, nem tudo está perdido na proteção de nossa infraestrutura crítica, pois as organizações dessas indústrias verticais compartilham as melhores práticas de segurança física e cibernética.\n\n## Arquitetura de Confiança Zero\n\nJim e Darren concordaram que o termo arquitetura de confiança zero tem sido usado em excesso e perdido seu impacto, já que o setor privado rapidamente adotou esse termo e o vinculou a tudo relacionado à cibersegurança. No entanto, eles concordam que os princípios de confiança zero devem ser adotados em organizações para proteger seus ativos valiosos completamente. Esses princípios incluem: verificação explícita contínua, uso de acesso de privilégios mínimos, suposição de uma violação, e automação de coleta de contexto e resposta. Esses princípios podem ser implementados por meio de tecnologia, melhoria de processos e treinamento.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jim Richberg"],"link":"/episode-EDT123-pt","image":"./episodes/edt-123/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren entrevista Jim Richberg, CISO do setor público da Forinet, discutindo as diferenças na cibersegurança no setor público. O governo federal é muito diferente dos governos estaduais e locais em relação à cibersegurança e suas abordagens."},{"id":25,"type":"Episode","title":"Fechando a lacuna de habilidades digitais","tags":["majorleaguehacking","hackathon","developer","people"],"body":"\r\n\r\nNo episódio de Adotando a Transformação Digital, Darren entrevista John Gottfried, co-fundador do Major League Hacking, sobre sua jornada na indústria de tecnologia. John sempre gostou de mexer com computadores desde criança e aprendeu habilidades técnicas por necessidade para fazer seu computador fazer o que ele queria. Ele costumava ir à biblioteca pública local para pegar livros sobre linguagens de programação como C e PHP e seguia os exemplos neles. John vivenciou o crescimento da internet, desde a conexão discada até a fibra ótica gigabit. Apesar de ter obtido um diploma em história na faculdade, John conseguiu seu primeiro emprego como programador aproveitando suas habilidades de experimentação em um emprego de meio período que pagava suas contas. Ele teve a oportunidade de fazer de tudo, desde construir racks de servidor até escrever código para pequenas empresas.\n\n## Ambiente para experimentação\n\nNo passado, hospedar um site costumava ser uma tarefa complexa que exigia a compra, configuração e manutenção de um servidor. No entanto, com o advento dos serviços de computação em nuvem, isso se tornou muito mais simples. Provedores de nuvem como a AWS, Google Cloud ou qualquer outro provedor oferecem serviços comoditizados semelhantes para criar um servidor em apenas cinco minutos. Nos anos 2000, depois de contrair mononucleose, John começou sua carreira como programador. Ele foi arrastado para eventos de tecnologia e hackathons na cidade de Nova York por seus colegas, e isso mudou sua perspectiva sobre a indústria. Isso o inspirou a criar o Major League Hacking, uma empresa que organiza hackathons e competições de programação para estudantes.\n\n## Liga Principal de Programação\n\nA Major League Hacking (MLH) foi fundada com o objetivo de capacitar hackers, um termo amplo que engloba qualquer pessoa que queira criar com tecnologia. A missão da organização é fornecer às pessoas as habilidades e a rede de apoio necessárias para iniciar suas carreiras na área de tecnologia. Os fundadores da MLH foram inspirados por suas experiências como mentores de estudantes no campus e queriam formar uma organização a partir disso. Eles começaram organizando hackathons - competições de invenção que duram um fim de semana, onde as pessoas se reuniam para construir protótipos de aplicativos e compartilhar ideias. Hoje, a MLH expandiu suas ofertas para incluir uma variedade de maneiras de ajudar as pessoas a desenvolverem suas habilidades, incluindo projetos práticos e uma comunidade de apoio.\n\n## Construindo uma Comunidade de Aprendizado\n\nA Major League Hacking expandiu seu alcance por meio de diversos programas, incluindo encontros, workshops, conferências virtuais e bolsas imersivas. Seu objetivo era preencher a lacuna entre habilidades fundamentais e aplicação no mundo real. A disseminação viral de suas hackathons e eventos possibilitou a conexão com diferentes universidades e comunidades sem esforços de marketing. Para apoiar líderes locais na construção de suas próprias comunidades, eles forneceram orientação, conectaram-nos com outras escolas e trouxeram patrocinadores. Grandes corporações e pequenas empresas também podiam se envolver trazendo ferramentas do mundo real, APIs e ferramentas proprietárias para os hackers. Dessa forma, eles proporcionaram exposição, orientação e os recompensaram por criar projetos interessantes.\n\n## Superando a Lacuna de Habilidades\n\nOs hackathons proporcionam uma experiência de aprendizado única ao reunir pessoas que, de outra forma, não trabalhariam juntas. Muitos hackathons são patrocinados por representantes corporativos que enviam engenheiros, recrutadores ou evangelistas de desenvolvimento para passar o final de semana com os estudantes, ajudando-os a depurar seu código e ensinando-os sobre APIs. Embora os hackathons sejam divertidos e ofereçam pizza grátis e brindes, eles também oferecem educação valiosa e prática no mundo real. Os hackathons também são benéficos para profissionais e qualquer pessoa pode se beneficiar ao se comprometer com um tempo e lugar focados para construir algo. Os projetos de hackathon geralmente não têm limites definidos, e prêmios são frequentemente oferecidos pelos patrocinadores em diferentes categorias. Equipes de projeto se formam organicamente em hackathons, e muitos laços duradouros e até mesmo empresas iniciantes foram fundadas após conhecerem-se nesses eventos.\n\n## Sucessos do Hackathon\n\nJohn compartilha uma história sobre uma equipe de estudantes do ensino médio que construiu um protótipo de aplicativo em um dos seus eventos que automatizava tarefas no iPhone. A Apple adquiriu a empresa deles quatro anos depois e transformou o projeto em uma funcionalidade central do iOS, o que foi uma conquista impressionante para um projeto que começou em um hackathon. John acredita que hackathons são uma excelente fonte de talentos para estágios e recém-formados e podem em breve substituir as feiras de carreira. Pessoas interessadas em participar de hackathons podem visitar o site da MLH para saber mais sobre os próximos eventos e oportunidades de patrocínio.\n\nMais informações sobre hackathons perto de você podem ser encontradas em https://mlh.io/\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jon Gottfried"],"link":"/episode-EDT128-pt","image":"./episodes/edt-128/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com John Gottfried, co-fundador da Major League Hacking, sobre como fechar a lacuna de habilidades digitais por meio de um trabalho colaborativo prático usando hackathons."},{"id":26,"type":"Episode","title":"HPC OnDemand","tags":["hpc","technology","compute","openondemand","ohiosupercomputercenter","osc"],"body":"\r\n\r\nNeste episódio de podcast, Darren Pulsipher, arquiteto-chefe de soluções do setor público na Intel, entrevista Alan Chalker do Ohio Supercomputer Center sobre a quebra de barreiras para a computação de alto desempenho (HPC, na sigla em inglês). Alan é diretor de programas estratégicos no Ohio Supercomputer e tem trabalhado em um projeto financiado pela NSF chamado Open OnDemand há mais de uma década. O projeto tem como objetivo tornar a HPC mais acessível aos consumidores em geral, que estão acostumados a fazer coisas online, como operações bancárias e compras online. O Open OnDemand simplifica o processo de uso da HPC, eliminando a necessidade de inserções de linha de comando. O histórico de Alan inclui obter seu diploma de graduação em engenharia elétrica e de computação na Universidade Estadual de Ohio e depois obter seu doutorado em engenharia biomédica na USC Chapel Hill.\n\n## História do Open OnDemand\n\nEm 2006 e 2007, uma interface web foi desenvolvida em colaboração com alguns especialistas tecnológicos pelo Edison Welding Institute, que posteriormente a batizou de Open OnDemand. Inicialmente, começou como uma simulação de soldagem online e foi expandida para incluir uma simulação geral de polímeros. Após apresentá-la em várias conferências, outras instituições de pesquisa em computação expressaram interesse em implementá-la em seus sistemas. Para torná-la de código aberto, a National Science Foundation concedeu a eles um programa de três anos e US$ 300.000 que tornou o protótipo mais robusto. O sucesso do Open OnDemand resultou em outro programa de cinco anos no valor de US$ 3 milhões. Hoje, está implantado em todos os continentes, exceto na Antártida, atendendo a mais de 400 instituições de pesquisa em computação.\n\n## Expandindo a influência da HPC.\n\nSupercomputadores expandiram além de campos tradicionais como ciência da computação e engenharia. Na OSC, estudantes de antropologia e ciência política estão utilizando o supercomputador para suas pesquisas, assim como estudantes de horticultura e ciências de plantações. A demanda pelo supercomputador está aumentando, com mais de 8.500 pessoas utilizando os supercomputadores da OSC de todo o mundo no último ano fiscal. Além disso, durante a pandemia, muitas universidades puderam continuar ensinando e pesquisando remotamente através de desktops virtuais fornecidos pelo supercomputador.\n\n## Comparação entre os Modelos de Preços de CSP e HPC\n\nOs modelos de precificação para o supercomputador são baseados em horas de núcleo e meses de terabyte, e o mandato governamental permite precificação subsidiada para entidades acadêmicas sediadas em Ohio. Provedores de serviços em nuvem cobram pelo tempo do relógio de parede, não pelas horas de núcleo, e cobram pelos custos de armazenamento de dados e de rede de egresso. Clientes da indústria comercial estão começando a utilizar supercomputadores para cargas de trabalho de simulação HPC tradicionais, economizando dinheiro ao executá-las nas nuvens públicas de varejo.\n\n## Exemplos de uso comercial\n\nNo dia anterior a Darren e Alan se sentarem e conversarem, houve tornados na região de Columbus, Ohio. A previsão do tempo é significativa para muitas indústrias e os supercomputadores são muito adequados. O centro gera previsões meteorológicas a cada 4 a 6 horas para clientes, como empresas de transporte marítimo e companhias aéreas. Embora as cargas de trabalho tradicionais de computação de alto desempenho ainda sejam comuns, as emergentes incluem a análise de tweets de membros do congresso em relação à COVID-19, antropologia, horticultura e ciências agrícolas. Qualquer coisa que seja limitada pelo tempo ou envolva muitos dados pode se beneficiar das capacidades de computação de alto desempenho. A demanda por essas capacidades deve crescer devido ao aumento da acessibilidade. Tornar a HPC mais fácil de consumir é semelhante ao que a nuvem fez para a computação em grade nos velhos tempos.\n\n## Capacidade de OSC\n\nA capacidade massiva do sistema de computação de alto desempenho da OSC está constantemente expandindo para atender à demanda. No momento da gravação, eles tinham 55.000 núcleos, principalmente da Intel, com 400 aceleradores distribuídos em 1600 nós. Eles antecipam uma nova aquisição que os levaria a 75.000-80.000 lugares devido à demanda crescente nas áreas biomédicas. O sistema pode lidar com grandes quantidades de dados, com 20 petabytes de armazenamento em disco real e conectividade de rede a uma velocidade de leitura/escrita de 350 gigabits por segundo. Um dos benefícios significativos da OSC é a ausência de custos de saída para seus clientes, devido à fundação da organização por meio de uma bolsa da National Science Foundation.\n\n## Abrir OnDemand\n\nMuitas universidades e centros de HPC estão aproveitando o Open OnDemand como uma interface web simples para tornar o HPC mais disponível para pesquisadores que precisam aprender ou entender as complexidades de agendar tarefas, decompor conjuntos de problemas e gerenciar dados em um cluster. Até mesmo os provedores de serviços em nuvem possuem interfaces Open OnDemand para sua oferta de HPC.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Alan Chalker"],"link":"/episode-EDT129-pt","image":"./episodes/edt-129/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Alan Chalker, diretor do programa estratégico no Ohio Super Computer Center, sobre o Open OnDemand para clusters de HPC em todo o mundo."},{"id":27,"type":"Episode","title":"Obsessão Ilógica com Lógica.","tags":["data","organizationalchange","people"],"body":"\r\n\r\n## Uma Contraposição de Preocupações <h2>\n\nNos últimos dez anos, os profissionais de dados aumentaram drasticamente sua capacidade de tornar o software visível, acessível, utilizável e portátil, mas, no que diz respeito aos dados, não houve avanço equivalente. Isso é algo que tanto os profissionais de software quanto os de dados devem considerar. Quais são as preocupações de cada lado? O que podemos aprender um com o outro? Atualmente, os dois lados são diametralmente opostos em muitos aspectos.\n\nNo lado da engenharia de software, a lógica de negócio é a principal preocupação. Para ter interfaces coerentes, os engenheiros escondem os detalhes. Os dados são vistos como uma saída. Por outro lado, os cientistas de dados estão mais preocupados com o contexto dessas saídas e construções de dados: os metadados. Por exemplo, a linhagem dos dados é importante para um cientista de dados ver como as coisas mudam ao longo do tempo, enquanto um engenheiro de software tentaria esconder esses detalhes para evitar problemas como variabilidade e erros.\n\nTratar o desenvolvimento de dados e metadados como uma disciplina própria, e não no contexto de como fazemos atualmente o software, poderia ajudar na expansão da indústria. Em outras palavras, precisamos buscar construir uma infraestrutura componível que leve em consideração as preocupações de ambos os lados.\n\nUm exemplo de como estamos lidando atualmente com os problemas de metadados em uma empresa ilustra essa ideia. Hoje, temos sistemas centralizados de gerenciamento de metadados. Queremos saber onde estão todos os nossos dados: quem, onde, por quê e como. Capturar o que as pessoas estão fazendo e inseri-lo em um sistema centralizado é uma maneira muito software de fazer as coisas. Se permitirmos que os dados cresçam por si só, podemos adotar o que os desenvolvedores de software fazem, mas em um contexto de dados. Poderíamos construir um ecossistema maior se, em vez de tanto esforço individual em ambos os lados, colocássemos tudo em um repositório sincronizado e centralizado e permitíssemos que os desenvolvedores de dados desenvolvessem como os engenheiros de software fazem. Poderíamos construir e curar como empreendimentos privados, mas então compartilhar essas curadorias com os outros. Semelhante à mudança no gerenciamento de configuração nas décadas de 1990 e 2000, de um local centralizado para um sistema mais distribuído, o compartilhamento poderia acontecer de forma mais fácil e fluida.\n\n## Conhecimento Digital DNA <h2>\n\nO conhecimento digital que temos depende tanto da lógica quanto dos dados. O software e os dados compartilham os mesmos elementos básicos e, à medida que avançamos no conhecimento, existem fortes relações entre os dois. O que diverge é que temos a infraestrutura e as ferramentas para desenvolver o lado do software, implementá-lo e torná-lo visível, acessível e utilizável. Como não pensamos da mesma forma no lado dos dados, estamos limitados nessas áreas. Por exemplo, uma forma antiga de pensar é quando cientistas de dados realizam análises avançadas e aprendizado de máquina a partir de seus dados, obtendo informações valiosas, mas não há um mecanismo repetível, limitando seu uso.\n\nUma vez que essa perspectiva seja reconhecida tanto pela comunidade de dados quanto pela comunidade de software, podemos adotar uma abordagem diferente usando os sucessos do desenvolvimento de software para dados. Em vez de aplicar as experiências pessoais e preconceitos do software em geral, podemos observar como os dados operam, como são semelhantes, mas têm suas próprias preocupações. Uma analogia seria levar sua família para a Disneyland. As experiências e interações lá representam a dinâmica do software. Você poderia transferir as experiências para o lado dos dados. Mas imagine no mundo real se você tivesse que deixar essa experiência na porta e, quando voltasse para casa, não soubesse nada sobre ela. Esse é o problema. Toda vez que vamos para um sistema ou ecossistema diferente, reinventamos um novo mundo e não temos consciência dos outros mundos que tivemos que deixar para trás. Se fosse possível compartilhar a experiência ou levá-la conosco, descobriríamos que teríamos uma infraestrutura de conhecimento muito mais vibrante. Então, da próxima vez que você visitar a Disneyland, com base em sua experiência, saberá qual é o melhor horário do dia, como verificar os tempos de espera, etc. Sem a experiência de trabalhar com os dados em conjunto com o aplicativo, é quase como começar do zero toda vez.\n\nUm exemplo real é a amnésia que ocorre em sistemas como os de cuidados de saúde, onde um profissional de dados cria uma integração do zero e, alguns anos depois, outra pessoa precisa fazer o mesmo. Se pudermos estabelecer melhores relações com os dados por meio de mapeamento, reutilização e aumento da eficiência. Por exemplo, por que temos tantas noções de uma pessoa em termos de modelagem? Claro que o contexto importa, mas por que não podemos ver as diferentes variantes de uma pessoa e então ser capazes de mapeá-las? No sistema de saúde VA, eles têm vários sistemas onde um paciente significa algo diferente em cada um. O mapeamento forneceria um terreno comum, mas permitiria alterações dependendo do contexto, desde que a operação de mapeamento fosse visível. Então poderíamos avançar com diferentes tipos de casos de uso e reutilização.\n\nUma grande lacuna é que conseguimos operacionalizar logicamente o K8s de forma eficaz, mas um serviço equivalente não existe para dados. Embora exista uma medida paliativa com o S3, não é a resposta. Existe uma grande necessidade em todas as indústrias por um serviço similar ao K8s que aborde dados. A necessidade de colaboração é importante aqui. É claro que os profissionais de dados querem adicionar valor à sua organização, mas uma parte disso depende de uma comunidade.\n\n## Fechando as Lacunas <h2>\n\nO nome da empresa Datacequias é baseado nas acequias do Novo México, que servem como exemplo do tipo de colaboração necessária para os dados. O Novo México é uma região árida, então, há anos, para tornar a terra fértil, as pessoas construíram uma série de valas de irrigação chamadas acequias. Ninguém as possuía, mas eles as construíram, administraram e mantiveram por necessidade e pelo bem comum. O ambiente inóspito no mundo dos dados geralmente envolve restrições orçamentárias e posse de dados, mas uma curadoria de dados baseada na comunidade seria benéfica para todos, assim como as acequias beneficiaram a todos.\n\nImagine se os profissionais de dados pudessem bifurcar um conjunto de dados em qualquer repositório central. Eles poderiam gerenciá-lo e evoluí-lo de acordo com suas próprias necessidades. Se houver uma mudança no repositório central gerenciado por um órgão padrão, eles poderiam incorporar essas mudanças imediatamente ou optar por não fazê-lo. De qualquer forma, eles teriam a linhagem de volta à fonte original. Hoje, quando usamos um ativo que está fora da empresa, fazemos uma cópia dele que permanece no tempo. Isso requer o rastreamento manual e gerenciamento das atualizações. Com um repositório central, todos poderiam co-criar, colaborar e criar comunidades com fundamentos comuns e linhagem visível.\n\nIsso é apenas a ponta do iceberg em uma mudança fundamental na indústria para tornar os dados mais valiosos para sua organização. Para obter mais informações sobre Andrew Padilla e Datacequia, visite datacequia.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Andrew Padilla"],"link":"/episode-EDT13-pt","image":"./episodes/edt-13/pt/thumbnail.jpg","lang":"pt","summary":"Líder de pensamento Andrew Padilla, da Datacequia, vislumbra novos avanços na gestão de dados e colaboração que permitiriam que os dados evoluíssem da mesma forma que o software em termos de visibilidade, acessibilidade, usabilidade e portabilidade. Ele descreve como uma infraestrutura componível abordaria as preocupações tanto de engenheiros de software quanto de cientistas de dados."},{"id":28,"type":"Episode","title":"Produtozando a IA Decisória","tags":["collectiongenerativeai","ai","decisionalai","aiproductization","people","process"],"body":"\r\n\r\nNeste episódio, Darren Pulsipher, Arquiteto Chefe de Soluções do Setor Público na Intel, entrevista seu filho Matthew Pulsipher, Gerente de Produto, sobre a productization da IA Decisória. Matthew explica que a IA Generativa é construída em cima de conjuntos de dados gerais e é boa para perguntas de conhecimento geral, mas falta previsibilidade e determinismo, o que torna difícil automatizar processos. Por outro lado, a IA Decisória é mais simples em escopo, mas mais focada em contexto, permitindo tomar decisões baseadas em dados específicos da empresa. Matthew compartilha sua experiência na integração da IA Decisória em produtos e destaca a importância do contexto na IA.\n\n## Tipo de IA\n\nExistem diferentes tipos de IA, e cada um tem uma habilidade única para ajudar organizações a automatizar processos, tomar decisões de negócios e aprimorar o trabalho humano. A IA decisória é usada principalmente para tomar decisões e é baseada em modelos gerados a partir de dados anteriores. Por outro lado, a IA preditiva gera valores previstos com base em modelos personalizados e conjuntos de dados. Treinar modelos é fundamental para a implementação e implementação de soluções de IA. A chave é identificar um problema real que seja operacionalmente relevante e alcançável em um prazo razoável.\n\n## IA para otimizar processos\n\nA inteligência artificial (IA) pode ser usada para agilizar os processos de tomada de decisão nas empresas. É importante delimitar as capacidades da IA a um conjunto específico de opções, para não sobrecarregar o sistema e tornar o processo de tomada de decisão mais eficiente. A IA é mais adequada para processos que são repetitivos, envolvem decisões baseadas em dados e requerem revisões humanas subjetivas. Por exemplo, uma instituição financeira pode usar a IA para validar carteiras de motorista usando dados extraídos. O treinamento contínuo por meio do feedback do usuário para a IA pode melhorar suas habilidades de tomada de decisão e eventualmente substituir a necessidade de revisão humana completamente. O projeto de indexação da Ancestry.com é um exemplo de como o aprendizado reforçado pode reduzir a necessidade de envolvimento humano ao longo do tempo.\n\n## Humano no Loop\n\nAo construir um backend de aprendizado de máquina, é essencial ter em mente as necessidades do usuário. O objetivo é simplificar o processo atual deles e fornecer uma ajuda para que possam desempenhar seu trabalho de forma mais eficiente. Para alcançar isso, é crucial entrevistar e observar os usuários em seu ambiente atual para compreender seu comportamento, identificar ineficiências e documentar quaisquer inferências que eles façam e que não estejam documentadas. Ao fazer isso, você pode selecionar os dados para extrair inferências antes de enviá-los para o modelo, o que resultará em resultados mais precisos com base na replicação do comportamento humano. É importante lembrar que as inferências muitas vezes são mais importantes do que os dados brutos, e ao entender o comportamento e as necessidades do usuário, é possível projetar um produto de IA melhor.\n\nOutro fator chave na implementação da IA é o fator humano. Trata-se de estabelecer o contexto certo ao implementar a automação para evitar o medo da perda de empregos. Como lidar com potenciais problemas de IA/humanos, como stakeholders contornando a IA implementada para eles. Uma solução é projetar a interface de forma a deixar claro quando um usuário revisou um ponto de dados específico e fornecer substituições quando necessário. Além disso, perguntar aos stakeholders sobre suas razões para contornar o sistema pode ajudar a melhorar o modelo e prevenir a manipulação da API. Por fim, a IA e os humanos podem trabalhar juntos para alcançar melhores resultados.\n\nA IA pode cuidar de tarefas simples se for bem treinada, e os humanos podem aprender a utilizar a IA melhor com o tempo. Construir interfaces colaborativas que façam da IA um membro da equipe em vez de um algoritmo frio, permitindo interações mais naturais que possam ajudá-la a aprender melhor. A IA se tornará essencial em qualquer trabalho que lide com partes interessadas que processem dados humanos devido à variabilidade envolvida.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Pulsipher"],"link":"/episode-EDT130-pt","image":"./episodes/edt-130/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista seu filho Matthew Pulsipher sobre a criação de produtos de inteligência artificial decisória. Matthew recentemente modernizou e incluiu a IA decisória em seu processo de desenvolvimento de produtos."},{"id":29,"type":"Episode","title":"Transformação Digital no Governo Federal","tags":["compute","people","technology","automation","ai","cybersecurity","innovation"],"body":"\r\n\r\nMark trabalhou com o governo federal por mais de 20 anos e testemunhou em primeira mão como as agências abraçam a nova tecnologia para melhorar seus serviços aos cidadãos. Uma tendência que ele notou é o foco nas experiências dos clientes, como o uso de aplicativos de passaporte móvel pela Alfândega e Proteção de Fronteiras. Apesar dos desafios de implementar iniciativas em larga escala em ambientes em constante mudança, Mark vê muitas oportunidades para o governo acelerar sua missão adotando nova tecnologia.\n\nA COVID acelerou a inovação dentro do governo federal e expôs lacunas em áreas como conexões VPN e segurança para os trabalhadores remotos. As agências continuam a inovar, focando na tecnologia em nuvem e na melhoria da experiência do cliente. Educação e comunicação são essenciais para tomar decisões informadas sobre onde colocar as cargas de trabalho e implementar tecnologias em nuvem. Apesar das preocupações de que a burocracia possa retardar a inovação, os benefícios da inovação continuam impulsionando a inovação dentro do governo federal, incluindo áreas de nuvem, computação de borda, cibersegurança e cadeia de suprimentos segura.\n\n## Multi-Nuvem Híbrida\n\nExiste uma tendência crescente de uso de nuvem híbrida múltipla e os diversos desafios que vêm com ela, como segurança e gerenciamento de dados. A importância de ter um plano bem estruturado para projetos de transformação digital foi enfatizada com a necessidade de sucesso precoce. Outra inovação é a computação de borda, que significa obter insights a partir de informações na borda mais rapidamente, sem precisar de uma conexão. Várias organizações estão atualmente trabalhando para descobrir como aproveitar o poder da computação de borda para melhorar seus serviços. Alguns exemplos de uso incluem monitoramento de sensores de água na agricultura e otimização de rotas de entrega de correspondência para o Serviço Postal dos EUA.\n\n## Automação\n\nQuando a automação e a cibersegurança são combinadas, elas podem acelerar a capacidade de uma organização de reagir às ameaças, implementar novas capacidades e proporcionar serviços melhores aos seus membros. A escassez de mão de obra resultante dos baby boomers se aposentando exigirá a automação para lidar com essa questão. Um exemplo é como a automação melhorou o processo de inspeção na fronteira para produtos agrícolas e flores, resultando em tempos de processamento mais rápidos e maior vida útil.\n\n## Cybersegurança\n\nO ambiente atual de TI/TO é uma paisagem de ameaças em constante evolução, com atores maliciosos inovando continuamente. A Intel está inovando e criando tecnologia de segurança de hardware que criptografa dados para proteger contra atores nefastos. A cibersegurança é uma preocupação prioritária para o governo federal, como mencionado no comunicado à imprensa recente do Presidente Biden, enfatizando a proteção da infraestrutura crítica como o principal problema de cibersegurança. A gestão essencial da infraestrutura nos EUA, dada a estrutura estadual única do país e o envolvimento de várias entidades, como municípios locais e empresas privadas de energia. A Agência de Segurança da Infraestrutura Crítica (CISA) orienta a cibersegurança e estabelece padrões para sistemas seguros em níveis federal, estadual e local.\n\n## Cadeia de Suprimentos Segura\n\nOutra vulnerabilidade crítica exposta pelo COVID-19 são os riscos geopolíticos e ameaças de cibersegurança à cadeia de suprimentos. A cadeia de suprimentos transparente da Intel permite que os clientes verifiquem a integridade dos componentes, o que é crucial para garantir a segurança do hardware e do software. Com essas medidas em vigor, os Estados Unidos estão tomando medidas para fortalecer sua segurança industrial e nacional.\n\nA cadeia de suprimentos não se limita apenas a ativos físicos; software, firmware e hardware também desempenham um papel importante na segurança da cadeia de suprimentos. Todos os componentes possuem vetores de ataque e exigem software seguro, materiais de construção, verificação de componentes e integridade do dispositivo para validação - uma ordem executiva em torno de software e materiais, à qual a Intel está aderindo em seus novos processadores. A Intel fornece tecnologias de segurança de hardware e capacidades transparentes de cadeia de suprimentos como parte de uma arquitetura de confiança zero.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Mark Valcich"],"link":"/episode-EDT131-pt","image":"./episodes/edt-131/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren entrevista Mark Valcich, diretor e gerente geral do Setor Público Civil Federal da Intel. Os anos de experiência de Mark brilham enquanto ele descreve as tendências atuais na transformação digital do governo civil federal."},{"id":30,"type":"Episode","title":"Gerenciamento de BareMetal Definido por Software","tags":["metify","sdi","technology","baremetal","heterogeneouscompute","compute"],"body":"\r\n\r\nCom mais de duas décadas de experiência no espaço do data center, Ian compartilha seus conhecimentos sobre otimização de infraestrutura, automação de gerenciamento de servidores e simplificação de diferentes componentes em um data center. Por outro lado, Mike, que anteriormente trabalhou na IBM e na Red Hat, concentra-se em vendas consultivas e lideradas por canal para entender melhor os problemas e padrões das empresas na operação de seus data centers. Juntos, eles criaram o Metify em 2020 para fornecer soluções de automação para gerenciar servidores, armazenamento e dispositivos de rede em data centers, apesar do surgimento de serviços de nuvem pública como RWC Azure e GCP.\n\n## Automatização do Datacenter\n\nAutomatizar a gestão do data center pode aproximar a gestão em local físico de uma experiência em nuvem pública, ao mesmo tempo em que reduz os custos. Um dos elementos vitais dessa transformação é a padronização e a utilização de padrões abertos, como a especificação DMCA Redfish, para tornar essa automação possível. A ubiqüidade dessa especificação em placas-mãe de classe empresarial a tornou acessível para todos os envolvidos integrarem-se a ela. As pressões financeiras e a demanda dos usuários são essenciais para impulsionar os OEMs a implementarem esses padrões abertos. No geral, a automação e a padronização podem ajudar os data centers a competir com provedores de serviços em nuvem em termos de custos operacionais, ao mesmo tempo em que melhoram as capacidades de gerenciamento de servidores.\n\nA eficiência do datacenter pode ser melhorada usando ferramentas que permitem automação e integração com estruturas padrão. Os fornecedores de hardware enfrentam pressão devido à comoditização da tecnologia, então eles devem se diferenciar oferecendo servidores white box, similarmente reduzidos. A Metify fornece uma única interface para gerenciar dispositivos de qualquer fabricante, desde que estejam habilitados com BMC e sigam a especificação Redfish. Existem padrões emergentes para gerenciar dispositivos pequenos através do redfish; a questão permanece sobre até que ponto a extensibilidade alcança as partes específicas de rede na pilha.\n\n## Nuvem Híbrida\n\nA ascensão das estratégias de nuvem híbrida impulsiona a forma como as empresas gerenciam seus data centers, bordas e ambientes de nuvem. O crescimento da nuvem pública é significativo; no entanto, há um enorme crescimento nos espaços de nuvem privada. O Metify oferece uma experiência mais semelhante à nuvem do ponto de vista operacional, permitindo que os administradores de sistemas gerenciem sua borda, data center ou vários data centers através de uma API padrão. Manter APIs abertas e padronizadas é essencial para que os clientes usem ferramentas de gerenciamento familiares como TerraForm e Ansible. As tecnologias de nuvem híbrida permitem que as empresas otimizem custos, governança, segurança e eficiência.\n\nUm dos perigos de um padrão aberto pode ser vulnerável a violações de segurança sem as medidas adequadas de comando e controle. A Metify aborda esse problema ao colocar auditabilidade, autorização, acesso e controles nos padrões abertos para oferecer uma abordagem sistêmica para gerenciar diretamente o metal em hardware heterogêneo. O produto da Metify se concentra em fornecer um nível de controle para evitar incidentes indesejáveis e eles se integram a ferramentas de gerenciamento de fluxo de trabalho para automação.\n\n## BareMetal SDI: \nBareMetal SDI\n\nMuitas tecnologias modernas de centros de dados dependem da virtualização como base de seu plano de controle de gerenciamento. No entanto, o gerenciamento de metal nu permanece uma tarefa tradicional e intensiva em trabalho manual. Essa abordagem única para infraestrutura de nuvem privada não depende da virtualização. Em vez disso, ela utiliza a abordagem de infraestrutura definida por software para gerenciamento de metal nu, permitindo uma combinação de metal nu, máquinas virtuais e contêineres. Essa abordagem permite que os administradores de sistema gerenciem a infraestrutura subjacente de forma mais eficaz e forneçam uma experiência na nuvem sem atritos. Essa abordagem pode suportar ambientes de computação heterogêneos, nos quais CPU, GPU, FPGA, VPU e NPUs podem ser aproveitados para vários fluxos de trabalho. Com o Redfish e uma extensão do esquema, o Metify pode controlar facilmente novos dispositivos e eles veem o ecossistema em expansão como incrivelmente valioso para o desenvolvimento de produtos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ian Evans","Mike Wagner"],"link":"/episode-EDT132-pt","image":"./episodes/edt-132/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista os fundadores da Metify, Ian Evans e Mike Wagner, sobre sua abordagem exclusiva para o gerenciamento de infraestrutura de software definido de metal nu usando o padrão Redfish."},{"id":31,"type":"Episode","title":"Lições em HPC Petróleo & Gás","tags":["compute","hpc","people","innovation","cloud"],"body":"\r\n\r\nKeith havia trabalhado na indústria durante toda a sua carreira e ingressou na Intel em julho passado. Ele liderou o grupo de Computação de Alta Performance da Consolidated Resources desde 1999, onde começaram com apenas um décimo de um teraflop de potência de computação. No entanto, Keith consolidou com sucesso vários locais e estabeleceu sua equipe como parte integrante das operações de exploração, desenvolvimento e produção de petróleo e gás da BP. Durante as últimas três décadas trabalhando em computação de alta performance em petróleo e gás, Keith teve três fatores influenciando a direção do HPC: computação em nuvem, escassez de talentos humanos e o equilíbrio entre colaboração e vantagem do primeiro mover.\n\n## Nuvem ou Local\n\nKeith compartilhou sua experiência na construção de uma instalação de HPC (Computação de Alto Desempenho) para a BP. A construção levou quase nove anos, sendo os primeiros sete gastos em melhorar a instalação existente e elaborar um plano de negócios para uma instalação dedicada. Apesar do surgimento da tecnologia em nuvem, eles descobriram que operar sua própria instalação era econômico devido ao controle sobre os recursos e à arquitetura personalizada. Estar na indústria de petróleo e gás apresentou desafios únicos ao lidar com grandes quantidades de dados, mas ter uma instalação dedicada permitiu que eles se concentrassem nas necessidades de pesquisa da BP. Esses fatores também são relevantes para outras indústrias que lidam com clusters de HPC.\n\nA grande questão para qualquer pessoa que administra um cluster de HPC é se as cargas de trabalho de HPC podem ser executadas com sucesso em serviços de nuvem gerais. Isso depende das necessidades específicas do negócio e da escala da carga de trabalho em questão. Enquanto algumas empresas podem achar prático colaborar com a nuvem para picos de demanda, outras exigem um cluster grande e totalmente utilizado para atender às suas necessidades. Fatores como desempenho preditivo, gravidade dos dados, tamanho dos dados e custo das operações são fatores essenciais na colocação de cargas de trabalho de HPC.\n\n## Combatendo a Escassez de Recursos\n\nAdquirir e reter talentos em computação de alto desempenho é desafiador, especialmente à medida que a geração baby boomer se aposenta. Keith sugere que estabelecer relacionamentos com universidades e identificar indivíduos talentosos desde cedo é fundamental para desenvolver as habilidades necessárias dentro de uma organização. As organizações devem pensar a longo prazo na criação de equipes de HPC bem-sucedidas e construir por meio de mentores. Nesses grupos heterogêneos, cientistas, engenheiros de sistemas, matemáticos e engenheiros de computação trabalham juntos por anos, em vez de meses.\n\nConstruir compromissos de longo prazo por meio de investimentos em estágios, programas de formação e bolsas de estudo é crucial para criar um ambiente de trabalho orientado para a carreira. Keith compartilha um desafio que enfrentaram ao criar uma visão compartilhada para o futuro de sua equipe, mas encontrou sucesso ao construir uma rede de contatos fora da BP para ajudá-los a alcançar seus objetivos.\n\n## Primeira vantagem do pioneiro, compartilhando\n\nOutro aspecto crítico do HPC na Indústria Petrolífera é ter a vantagem de pioneiro. Encontrar uma nova técnica para descobrir novas fontes de energia pode economizar bilhões de dólares para a empresa. No entanto, compartilhar informações com concorrentes também pode levar a descobertas que auxiliam a indústria. Esse é um equilíbrio importante que os profissionais de HPC precisam entender para obter o máximo de seu trabalho.\n\nKeith compartilha uma história divertida de como seus amigos ajudaram a desenvolver uma tecnologia inovadora para entender melhor as estruturas geológicas subterrâneas do Golfo do México para encontrar petróleo e gás. Apesar da competição observando e questionando seus métodos, a experimentação da BP provou ser bem-sucedida. Keith explica que todos estão de olho quando você faz algo novo no campo.\n\nPor exemplo, eles frequentemente contratavam empresas como PGS para adquirir dados e utilizavam uma solução inovadora de usar helicópteros e discos rígidos para entregar os dados recém-adquiridos para processamento. Os resultados foram impressionantes, mostrando melhores resultados do que os métodos tradicionais. Quando questionado sobre o futuro do HPC na indústria, Keith acredita que a colaboração continuará sendo necessária, seja por meio de clusters compartilhados ou colaboração em benchmarks científicos fundamentais. Apesar dos desafios, a indústria de HPC é emocionante e há ótimas oportunidades para pessoas trazerem suas habilidades computacionais e disposição para resolver problemas desafiadores.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Keith Gray"],"link":"/episode-EDT133-pt","image":"./episodes/edt-133/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Keith Gray, um ex-diretor de computação de alto desempenho da British Petroleum. Com mais de 30 anos de experiência em gerenciamento de centros de HPC, Keith oferece grandes insights sobre os desafios, melhores práticas e o futuro da computação de alto desempenho."},{"id":32,"type":"Episode","title":"WaveForm AI (Portuguese Translation: WaveForm AI)","tags":["collectiongenerativeai","artificialintelligence","waveformai","datashapes","waveform","technology"],"body":"\r\n\r\nLogan é um ex-oficial de inteligência do DOD e tem paixão por IA e robótica, o que o levou a ser um reservista na comunidade de defesa. Ele fez a transição para a DataShapes, onde eles possuem uma tecnologia única que soluciona necessidades críticas na comunidade de defesa usando IA. Embora a IA esteja por aí há muito tempo, a grande quantidade de dados disponíveis para treinar modelos e o avanço dos recursos de computação levaram ao desenvolvimento de sistemas mais inteligentes, como chatbots e grandes modelos de linguagem.\n\nAs técnicas atuais são exigentes em recursos e muito caras de treinar e construir uma solução de inferência de propósito geral. Por exemplo, executar grandes modelos de linguagem como ChatGPT pode custar até US$ 3 milhões por dia, mas a IA está evoluindo rapidamente e recebendo mais atenção do que nunca. Uma preocupação em usar redes neurais é a incapacidade de auditar e explicar como a IA chegou a um resultado. Existem desafios sociais, políticos e legais em confiar nas decisões tomadas por essas redes, especialmente em áreas onde a vida humana está em jogo. No entanto, a sociedade eventualmente superará esses desafios e abraçará completamente a IA. A abordagem da DataShapes, que utiliza técnicas tradicionais de aprendizado de máquina para resolver pontos problemáticos na análise de dados, possui total auditabilidade e descoberta em seus modelos treinados.\n\nA DataShapes possui uma abordagem única para resolver problemas de forma rápida e eficiente em ambientes com recursos limitados. Enquanto o treinamento tradicional de redes neurais requer muitos dados rotulados e pode ser frágil, a DataShapes utiliza metodologias para aprender em tempo real ou quase em tempo real. Sua tecnologia possui foco em formas de onda e sinais, além de ser auditável, tornando-a ideal para uso em ambientes austeros, nos quais as pessoas sujam-se e carregar uma pilha de servidores é impossível. Enquanto as redes neurais são ótimas para modelos de linguagem e reconhecimento de imagens, a empresa de Logan tem um foco hiperespecífico em formas de onda e sinais. Sua abordagem é diferente e altamente eficaz.\n\nDetectar diferentes tipos de formas de onda e as relações nas formas de onda estão no centro dessa nova tecnologia. Essa abordagem identifica padrões mais difíceis de serem falsificados em comparação com as técnicas tradicionais usadas pelo Departamento de Defesa. Isso tem o potencial de aplicações da tecnologia deles na guerra eletrônica, incluindo coleta de inteligência e análise. Além disso, a plataforma pode detectar, analisar e coletar inteligência, que pode ser exportada para dispositivos de borda. Também foi mencionada a função de detecção de anomalias com aprendizado automático, chamada de Infinite Loop, que estabelece uma linha de base contínua com base nos parâmetros prescritos pelo usuário final. A tecnologia pode ser usada na indústria automotiva, saúde e indústrias de entretenimento, onde poderia ser incorporada em cada sensor.\n\nA DataShapes tem um produto chamado GlobalEdge, um agente inteligente que fica no ou atrás dos sensores para realizar operações de ETL para os dados que estão sendo coletados. O componente de aprendizado de máquina do GlobalEdge filtra os dados para fornecer insights relevantes e anomalias em tempo real, reduzindo a quantidade de dados irrelevantes que são enviados de volta para a sede. O produto também pode ser usado para compressão de dados na borda em direção ao centro de dados. O software pode ser dimensionado para um mínimo de 47 K, tornando-o adequado para uma variedade de aplicações, incluindo detecção de vírus usando ondas UV.\n\nPara saber mais sobre DataShapes e sua abordagem, visite https://www.datashapes.com\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Logan Selby"],"link":"/episode-EDT134-pt","image":"./episodes/edt-134/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher recebeu Logan Selby, co-fundador e presidente da DataShapes, onde eles discutem uma abordagem única para Inteligência Artificial que vai contra a tendência."},{"id":33,"type":"Episode","title":"IA Confiável e Ética.","tags":["ai","ethics","trustworthiness","deepfake","aicontent","aidetection"],"body":"\r\n\r\nNo final dos anos 2010, a Microsoft lançou o Tay como um chatbot de IA projetado para aprender a partir de suas conversas com usuários no Twitter. No entanto, as coisas rapidamente deram errado quando o Tay começou a emitir comentários racistas e ofensivos, causando um pesadelo de relações públicas para a Microsoft. Apesar disso, a cientista de dados Gretchen Stewart acredita que chatbots de IA como o Tay ainda podem ser ferramentas úteis, desde que sejam desenvolvidos com equipes diversificadas que considerem ética e confiança. Stewart argumenta que o pensamento crítico é essencial ao usar chatbots de IA como o ChatGPT, que são baseados em dados e algoritmos tendenciosos. Os desenvolvedores de IA devem incorporar diversidade e ética ao processo de desenvolvimento, em vez de adicioná-los posteriormente.\n\n## Confiança\n\nA IA possui capacidades imensas, mas ainda carece dos sentidos e experiências humanas que podem afetar a tomada de decisões. Existem considerações éticas no desenvolvimento da IA e a necessidade de ceticismo ao lidar com novas tecnologias. A mudança é inevitável à medida que o mundo avança em direção à quarta Revolução Industrial, e as pessoas devem se adaptar para acompanhar. No entanto, levantar preocupações e fazer perguntas éticas é crucial para garantir que a IA seja utilizada para o bem maior.\n\nExistem perigos potenciais em depender da inteligência artificial (IA) como fonte de informação. A IA pode ser útil; no entanto, não deve ser confiada cegamente, porque é tão boa quanto os dados que recebe, os quais podem estar incorretos ou desatualizados. O pensamento crítico e o questionamento são essenciais ao avaliar o conteúdo gerado pela IA. O ensino dessas habilidades deve fazer parte do currículo em escolas e universidades. Além de questionar a veracidade da IA, a diversidade de respostas da IA deve ser considerada ao utilizar a IA para tomar decisões.\n\n## Ética\n\nÀ medida que a tecnologia continua a avançar, novas questões éticas continuam a surgir. Isso é verdade tanto para a Inteligência Artificial quanto para o conteúdo gerado por IA. Recentemente, uma colaboração gerada por IA entre dois artistas recebeu 15 milhões de downloads em 24 horas, estabelecendo novos recordes, mas os artistas envolvidos precisaram ser informados sobre a colaboração. Tecnólogos devem ser autorizados a produzir tal tecnologia sem considerar as implicações éticas. Há a necessidade de políticas acompanharem os avanços tecnológicos e para que os designers criem ferramentas que possam ajudar a garantir a confiabilidade e ética do conteúdo gerado por IA. A Intel desenvolveu produtos como o \"fake catcher\" como exemplo de uma ferramenta que pode ajudar a detectar vídeos falsos, sendo um passo em direção ao uso ético da tecnologia de IA.\n\nCombater o conteúdo falso gerado por IA tornou-se uma indústria em si mesma, e isso requer transparência no desenvolvimento de IA. Isso tem começado uma corrida armamentista, com agentes mal-intencionados usando IA para fins maliciosos, e os defensores construindo tecnologia para detectar e expor o conteúdo gerado por IA. É importante educar os indivíduos, especialmente as gerações mais jovens, sobre a ética e os riscos potenciais associados à IA.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart"],"link":"/episode-EDT135-pt","image":"./episodes/edt-135/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Gretchen Stewart, Cientista de Dados Chefe do Setor Público na Intel, onde eles discutem a confiabilidade e ética da inteligência artificial."},{"id":34,"type":"Episode","title":"Dados resilientes em comunicações disruptivas","tags":["sabr","ddil","technology","edge","process","devops","security"],"body":"\r\n\r\nNeste episódio de podcast, Darren Pulsipher, arquiteto principal de soluções da Intel para o setor público, é entrevistado pela apresentadora convidada Dra. Anna Scott sobre dados resilientes com comunicações disruptivas. A discussão é centrada em gerenciar dados de forma segura e eficiente em ambientes com largura de banda limitada e serviço interrompido, possibilitando inteligência artificial e análise de dados complexos na ponta. Darren fala sobre sua experiência trabalhando na nuvem de carros conectados da Toyota como base para resolver esse problema e como arquiteturas comuns de gerenciamento de dados foram utilizadas para criar uma solução. A revelação gradual dos desafios do cliente ajudou a identificar padrões de design que abriram caminho para uma solução bem-sucedida.\n\nApesar da conectividade intermitente e dos nós de borda dinâmicos, o processo de design de arquitetura para realizar análise de borda é complexo e difícil de articular, por isso eles adotaram uma abordagem iterativa. Primeiro, eles consideraram uma solução que traria todos os dados para um único local para análise, mas acharam impraticável devido ao grande volume de dados na borda. Mover as aplicações para a borda parecia promissor até que o cliente solicitou análises agregadas em toda a borda. Após explorar padrões de design, eles decidiram usar o padrão de design de fluxo de dados com um hub de publicação e assinatura para criar fluxos de dados dinamicamente para consumidores e produtores. Embora esta abordagem utilizasse raízes bem estabelecidas em TI, o cliente inicialmente tinha preocupações com a alocação de tópicos.\n\nNo passado, Darren tinha que criar antecipadamente um ecossistema PubSubHub e estar familiarizado com todos os seus componentes. No entanto, configurar fluxos de dados com o Kafka ou o Apache Pulse era desafiador, e configurar a segurança era ainda mais difícil. Utilizando sua experiência em DevSecOps para desenvolver uma solução que agrupa definições de fluxo de dados, definições de entrada e saída e transformações de dados em um pacote consumível pelo pipeline. Esse pacote cria automaticamente fluxos de dados no PubSubHub e configura todas as medidas de segurança necessárias. O resultado simplificou a complexidade, pois os desenvolvedores só precisavam se concentrar em algoritmos ou modelos de IA, enquanto todo o resto era cuidado de forma genérica. A abordagem iterativa com os clientes ajudou a modificar arquiteturas e implementações ao longo do caminho.\n\nO desafio principal com esse tipo de arquitetura é trabalhar com recursos limitados, como ter acesso a apenas dois núcleos e 2 gigabytes de RAM. Quanta capacidade de processamento de dados pode ser alcançada na borda com recursos limitados? Uma das restrições com as quais a equipe de arquitetura precisava trabalhar era tornar o gerenciador de fluxo SABR e as medidas de segurança o mais compacto possível. Darren reduziu o código para o mínimo absoluto e eliminou pacotes desnecessários de terceiros. O objetivo era criar um gerenciador de fluxo leve que pudesse ser executado na borda e ser portátil em diferentes ambientes. A arquitetura resultante Saber era escalável e adaptável, capaz de ser executada desde um smartwatch até um servidor Xeon grande.\n\nDarren e Anna discutem as dificuldades de atualizar os modelos de IA em um ecossistema distribuído com inúmeras instâncias das mesmas análises em execução. Para resolver esse problema, a SABR criou um fluxo de dados de aprendizado que conecta todas as instâncias das mesmas análises e lida com comunicações intermitentes, armazenamento em cache e envio de deltas para atualizar os modelos. Eles também desenvolveram um sistema de canal de dados usando o padrão de design de estratégia de política, permitindo diferentes canais com níveis variados de dados a serem enviados com base em regras definidas pela política. Essa abordagem permite uma transmissão de dados mais eficiente, reduzindo a quantidade de dados processados ​​e aumentando a precisão dos modelos de IA.\n\nA seguir está como operar no ambiente DDIL, priorizando o envio de dados, enviando primeiro resumos e dados históricos antes dos dados em tempo real. É importante definir as expectativas do sistema e as políticas de comunicação antecipadamente para garantir consistência em todo o ecossistema. Um processo de criação e ativação de políticas fácil de usar, configurado com JSON e baseado em JavaScript, que elimina a duplicação de esforços e promove o reuso. A arquitetura possui a capacidade de adicionar rapidamente novas funcionalidades aproveitando os sabers existentes e as transformações de dados.\n\nO último é a resiliência do sistema ao se recuperar dinamicamente de interrupções no sistema. O potencial de uso dinâmico e flexível da rede SABR. Mesmo que um nó apresente uma queda, é possível mover um SABR para outra caixa e ainda receber todas as fontes de dados. Também é possível utilizar computação antiga executando um SABR extremamente leve em um sistema antigo que coleta e transmite dados para a rede SABR. A importância da segurança não deve ser ignorada. Todos os fluxos de dados são criptografados e processos são estabelecidos para estabelecer a confiabilidade e a autenticação dos SABRs, a fim de prevenir a falsificação e a espionagem de dados. No geral, a rede SABR oferece uma solução promissora para processamento de dados na borda com flexibilidade e segurança.\n\nA aprendizagem-chave é a abordagem arquitetônica iterativa que a equipe usou para descobrir os casos de uso e os pontos problemáticos que os usuários finais estavam enfrentando. Ao simular a arquitetura, eles conseguiram encontrar falhas nela e obter feedback do cliente. Além disso, a utilização de padrões de design foi essencial para acelerar a abordagem arquitetônica. O uso de abstração também proporcionou a capacidade de trocar diferentes tecnologias ao longo do processo arquitetônico. Darren acredita que essa abordagem tornou fácil criar soluções que são fáceis de usar e aproveitar o conhecimento atual dos clientes.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT136-pt","image":"./episodes/edt-136/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de podcast, Darren Pulsipher, arquiteto-chefe de soluções da Intel para o setor público, é entrevistado pela convidada Dr. Anna Scott sobre dados resilientes com comunicações disruptivas."},{"id":35,"type":"Episode","title":"Renascimento da Nuvem Privada","tags":["cloud","computing","greenlake","hpe","multicloud","hybridcloud","technology"],"body":"\r\n\r\nHouve uma tendência em direção à repatriação no setor comercial, onde empresas estão trazendo cargas de trabalho e máquinas virtuais de volta de ambientes de nuvem pública devido a motivos financeiros, como taxas de egresso e orçamento para cargas de trabalho em hiperscalers. Preocupações com a soberania de dados, segurança, desempenho e latência também levaram mais empresas a se afastarem da nuvem pública e voltarem para tecnologias de nuvem privada. Apesar dessa mudança, muitas promessas da nuvem foram cumpridas para fornecer facilidade de uso, elasticidade e precificação baseada em consumo. Para facilitar a transição entre nuvens, a nuvem privada deve oferecer facilidade de uso, portabilidade de cargas de trabalho e novos modelos de precificação baseados em consumo, tão solicitados nas nuvens públicas.\n\n## Controle de custos\n\nSam Ceccola, o CTO DoD da HPE, acredita que é essencial entender os riscos e desafios associados a cada tecnologia de nuvem privada, pública e híbrida. E projetar soluções que aproveitem a força de cada tecnologia. É aqui que entra a oferta de produção da HPE, o GreenLake. O modelo de aquisição de serviços baseado no consumo do GreenLake foi implementado pela primeira vez em 2005 e desde então evoluiu para incluir um portal de autoatendimento para gerenciar vários ambientes de nuvem privada e pública. O GreenLake oferece aos clientes a capacidade de implantar recursos adicionais através da fronteira entre a nuvem privada e pública sob demanda. Ele também gerencia e visualiza custos complexos, como cobranças de egresso e orçamentação para carga de trabalho em escala hiper.\n\n## Gestão de Dados\n\nOutra preocupação importante para a maioria dos consumidores de nuvens públicas é o gerenciamento de dados, governança e soberania. Sem uma estratégia de dados coesa, muitas organizações são sobrecarregadas com os custos de saída de dados ao mover dados para dentro e para fora das nuvens públicas. Existem várias abordagens diferentes para gerenciar dados através de fronteiras de nuvem. A HPE utiliza uma abordagem de armazenamento adjacente à nuvem que reduz a quantidade de dados movidos para a nuvem ao mínimo. O armazenamento adjacente à nuvem do GreenLake mantém os dados no local, enquanto executa cargas de trabalho de computação na nuvem. Essa abordagem garante a soberania dos dados e reduz os custos de saída de dados e os problemas de latência associados à movimentação de grandes quantidades de dados entre nuvens.\n\n## Portabilidade.\n\nOutro aspecto chave das arquiteturas de nuvem multi-híbrida é a capacidade de mover facilmente as cargas de trabalho entre as nuvens. Algumas organizações migraram para arquiteturas de microsserviços baseadas em contêineres sem estado para fornecer a flexibilidade e portabilidade das cargas de trabalho. No entanto, nem todas as cargas de trabalho podem ser facilmente containerizadas, especialmente aquelas que possuem aplicativos que contêm estado. Nesses casos, máquinas virtuais são usadas para permitir a movimentação de aplicativos de uma nuvem para outra. Mover VMs entre nuvens pode ser problemático, pois os provedores de serviços em nuvem utilizam hipervisores e CPUs diferentes que podem não ser completamente compatíveis. Compreender as limitações dessas migrações é fundamental na decisão de compra de hardware, tanto virtualizado quanto não virtualizado.\n\n## Segurança\n\nA GreenLake não limita os clientes a implantação no local, pois permite que eles provisionem cargas de trabalho em diversos ambientes de nuvem, incluindo Amazon, Google e Azure. Além disso, o GreenLake suporta cargas de trabalho híbridas reais, onde uma carga de trabalho pode ser executada tanto no local quanto em ambientes de nuvem de hiperscala simultaneamente. Executar cargas de trabalho em diferentes limites de nuvem pode causar exposição adicional a ataques cibernéticos. Compreender os modelos de segurança das diferentes tecnologias de nuvem pública e privada pode ser uma tarefa assustadora e aumenta o capital humano necessário para arquitetar e gerenciar efetivamente uma posição de segurança sólida. A plataforma GreenLake lida com a segurança por meio de seu mecanismo de segurança agnóstico, Security Central, que suporta atestação multi-nuvem e arquiteturas de confiança-zero para nuvens independentes, gerenciando a complexidade e integração dos modelos de segurança.\n\nProjetar uma solução de nuvem multi-híbrida é complexo e requer o entendimento das tecnologias de nuvem privada e pública, suas limitações e suas vantagens. Felizmente, existem organizações como a HPE que têm trabalhado com arquiteturas de nuvem multi-híbridas há vários anos e aprenderam os detalhes da gestão eficaz das cargas de trabalho nesse novo ambiente flexível.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sam Ceccola"],"link":"/episode-EDT137-pt","image":"./episodes/edt-137/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Sam Ceccola, CTO da DOD para HPE, sobre os novos modelos de negócios e tecnologia que estão mudando a forma como as organizações consomem a nuvem híbrida."},{"id":36,"type":"Episode","title":"Evolução da Nuvem","tags":["cloud","computing","dell","multicloud","hybridcloud","technology"],"body":"\r\n\r\nA evolução da computação em nuvem é um dos avanços tecnológicos mais significativos da última década. A nuvem está passando de um conceito simples para um sistema complexo e onipresente que agora domina as operações e estratégias empresariais. Como nos diz Ken White, da Dell Technologies, a nuvem não é mais um único local ou uma solução única. Em vez disso, ela é tudo, em qualquer lugar.\n\nCom hipercalistas como Amazon e Azure em constante expansão, a nuvem representa uma experiência consistente em todas as plataformas, com previsibilidade de desempenho e custo. No entanto, existem taxas ocultas, especialmente ao mover dados para dentro e para fora da nuvem. É essencial que as empresas que consideram a nuvem adotem completamente uma mentalidade em nuvem preocupada com consistência, previsibilidade, flexibilidade, desempenho e segurança. Embora alguns executivos sejam atraídos pela nuvem por seu potencial de reduzir custos e gerenciamento de TI, é essencial lembrar que ela não pode resolver todos os problemas e não é uma rua de mão única. A nuvem pode, em última análise, melhorar as operações, aumentar a eficiência e oferecer uma melhor experiência tanto para as empresas quanto para os clientes, desde que uma mentalidade operacional bem planejada seja adotada.\n\nSe você está no mundo dos negócios, provavelmente já ouviu falar sobre a nuvem, mas já ouviu falar sobre a mentalidade da nuvem? É uma forma de abordar a tecnologia que possibilita adaptabilidade, portabilidade e previsibilidade em relação às cargas de trabalho e aos custos na nuvem. Isso significa que você pode desenvolver aplicativos portáteis em diferentes ecossistemas e escolher onde as cargas de trabalho serão alocadas com base nos requisitos comerciais, e não apenas em restrições técnicas. Também significa que você pode prever e controlar os custos, um alívio bem-vindo em um cenário tecnológico em constante mudança.\n\nMas mudar mentalidades é desafiador, especialmente para organizações acostumadas a uma maneira específica de operar. É aqui que a capacitação e o compromisso com a aprendizagem contínua entram em jogo. Organizações que adotam com sucesso a mentalidade da nuvem priorizam uma experiência de usuário positiva, estão dispostas a se adaptar a novas arquiteturas e aprender e mudar à medida que a tecnologia evolui.\n\nAdotar a mentalidade de nuvem não significa que você terá que demitir todos os seus profissionais de TI e mover tudo para a nuvem. Em vez disso, trata-se de treinar sua equipe de trabalho e repensar a filosofia organizacional. Com uma camada de gerenciamento adequada e um foco em flexibilidade e agilidade, as organizações podem desbloquear os benefícios da nuvem para seus negócios e aprimorar as experiências de seus usuários finais, sejam eles desenvolvedores ou clientes.\n\nConsiderando uma estratégia de nuvem, você deve entender que pode experimentar fracasso. Mover aplicações para a nuvem nem sempre é simples e pode ter um custo. No entanto, suas chances de sucesso são muito maiores com a consistência e governança corretas.\n\nA consistência não necessariamente significa uma única interface, mas significa ter um processo padrão para gerenciar e implantar cargas de trabalho e infraestrutura. Também inclui consistência com governança, processos e fluxos de trabalho. Esse nível de consistência garante que todos na sua organização entendam como gerenciar a nuvem.\n\nFalhas na adoção da nuvem são, às vezes, evitáveis, mas repatriação pode ser uma opção para trazer sua carga de trabalho de volta a uma solução local. No entanto, essa opção também pode ser custosa, então avaliar os benefícios de curto e longo prazo é essencial.\n\nOs containers também podem fazer a diferença na adoção da nuvem ao eliminar problemas associados à movimentação de aplicativos para a nuvem. Mas lembre-se, não existe uma solução mágica que resolva todos os problemas de adoção da nuvem.\n\nEm geral, a chave para o sucesso com uma estratégia de cloud é focar na consistência e compreender os custos envolvidos na migração para a cloud. Levando esses fatores em consideração, suas chances de sucesso são muito maiores.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sam Ceccola"],"link":"/episode-EDT138-pt","image":"./episodes/edt-138/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Ken White da Dell Technology sobre como a tecnologia em nuvem é mais do que apenas tecnologia, mas sim uma mudança processual e cultural nas organizações."},{"id":37,"type":"Episode","title":"Análise Logística Resiliente","tags":["data","analytics","artificialintelligence","pathway","technology"],"body":"\r\n\r\nVocê está interessado em aprender sobre como a transformação digital está afetando a logística? Neste episódio de \"Abraçando a Transformação Digital\", o convidado especial Adrian Kosowski, diretor de produto da Pathway, discute análises resilientes na logística. A Pathway se concentra em estudar sistemas do mundo real a partir de uma perspectiva de computação distribuída e trabalha especificamente com dados na vertical de logística e transporte. Um dos maiores desafios nesse campo é agregar dados em grande escala e dar sentido a eles, é aí que a aprendizagem de máquina e as análises entram em jogo. Kosowski também observa que a logística é um mercado altamente concentrado, controlado apenas por algumas empresas, o que torna até mesmo pequenas melhorias nos processos incrivelmente valiosas para a economia mundial. No entanto, coletar dados do extremo, como contêineres no meio do oceano, apresenta seus próprios desafios, como otimizar energia e comunicação para dispositivos IoT alimentados por bateria. Em resumo, se você está interessado na intersecção entre logística e transformação digital, este episódio oferece insights valiosos sobre os desafios e oportunidades desse campo.\n\nO uso de dispositivos de internet das coisas (Internet of Things - IoT) na indústria logística e da cadeia de suprimentos pode trazer grandes benefícios para as empresas, proporcionando visibilidade de ponta a ponta e melhor capacidade de análise. No entanto, existem vários desafios associados ao uso desses dispositivos que precisam ser tratados.\n\nUm dos principais desafios é a estabilidade e confiabilidade desses dispositivos periféricos. No caso de uma falha ou travamento do dispositivo, as empresas devem ter um meio de otimizar esses dispositivos sem que eles adivinhem ou atuem de maneira incorreta. Isso é especialmente crítico para sistemas em tempo real que são utilizados para receber eventos em ordem.\n\nOutro desafio é a precisão dos dados coletados pelos dispositivos IoT. Alguns dados podem ser inferidos, e análises contextuais podem ser necessárias para interpretar o significado de um determinado ponto de dados e distinguir problemas de medição de problemas de processo. Dados imprecisos ou fora de tempo podem levar a riscos na cadeia de suprimentos e dificultar a otimização da rede de transporte.\n\nNo entanto, o uso generalizado de dispositivos IoT pode levar à visibilidade e observabilidade completa dos processos ao longo da cadeia de suprimentos. Isso pode ajudar as empresas a otimizarem seus processos e se tornarem proativas em sua abordagem. Isso pode beneficiar todos os atores na cadeia de suprimentos - desde provedores de transporte e logística até varejistas e fabricantes.\n\nEnquanto não há um grupo ou segmento específico que as empresas devam direcionar para a adoção de dispositivos IoT, a adoção e cooperação generalizada entre todos os participantes pode levar a benefícios significativos para a cadeia de suprimentos global.\n\nPathway foi desenvolvido para abordar as deficiências nas tecnologias de transmissão de dados existentes e fornecer uma ferramenta para pipelines de análise avançada em cima de fluxos de dados. Uma das características-chave que diferencia o Pathway é a facilidade de descrever lógica como se fosse destinado a um sistema em lote, ao mesmo tempo em que garante que funcione em um sistema de tempo real com dados fora de ordem.\n\nA Pathway foi desenvolvida tendo em mente dados de IoT, mas também pode lidar com dados de monitoramento de vídeo, monitoramento de desempenho do servidor, monitoramento de logs e outras entidades físicas. Isso permite lidar com as complexidades dos dados quando se trata de detecção de anomalias, notificações com dados fora de ordem e dados com elementos de séries temporais e geoespaciais de forma independente da nuvem.\n\nOutra característica importante do Pathway é a capacidade de usar scripts em Python para análise de fluxo de dados, tanto em tempo real quanto em modo de lote. Isso significa que cientistas de dados e engenheiros podem desenvolver suas tubulações de análise no ambiente de desenvolvimento normal ao qual estão acostumados e trabalhar de forma conveniente com o sistema de streaming. Além disso, o Pathway permite que uma quantidade muito maior de histórico seja considerada ao executar os cálculos, o que é uma grande diferença em relação aos processadores de fluxo leves que lidam apenas com pequenas quantidades de dados.\n\nNo geral, o Pathway oferece uma solução de interligação para organizações que precisam combinar processamento de dados em lote e em tempo real e fornece uma maneira de adicionar valor aos dados ao adicionar estrutura e informações de extensão para uso subsequente em inteligência de negócios e análise.\n\nA tecnologia de Streaming de Dados está se tornando cada vez mais importante à medida que as empresas procuram tomar decisões mais rápidas e responder mais rapidamente às necessidades dos clientes. Quando você usa o streaming de dados, pode detectar e responder rapidamente a tendências, anomalias e outras informações importantes. A Pathway oferece um conjunto de produtos projetados especificamente para trabalhar com dados de séries temporais, dados logísticos e streaming de dados. Eles oferecem exemplos e informações para desenvolvedores no GitHub, além de uma comunidade ativa no Discord.\n\nA transmissão de dados é uma tecnologia crítica para empresas em uma ampla variedade de setores. Por exemplo, ela pode ser usada na logística para otimizar rotas e prever quando os envios chegarão. Na área financeira, pode ajudar a detectar fraudes e prever tendências de mercado antes que se tornem amplamente conhecidas. No transporte, pode ser usada para monitorar o desempenho de motores e veículos em tempo real.\n\nSe você está interessado em aprender mais sobre data streaming e como isso pode beneficiar o seu negócio, não deixe de conferir o site e a comunidade da Pathway [www.pathway.com]. Com as ferramentas certas e expertise adequada, você pode aproveitar essa tecnologia poderosa para melhorar suas operações e se manter à frente do mercado.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Adrian Kosowski"],"link":"/episode-EDT139-pt","image":"./episodes/edt-139/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Adrian Kosowski, CPO da Pathway, sobre sua habilidade única de lidar com dados logísticos da borda em ambientes DDIL com análises em tempo real."},{"id":38,"type":"Episode","title":"Iniciando sua transformação organizacional para se tornar centrada em dados","tags":null,"body":"\r\n\r\n## Operacionalizando Sistema de Análises\n\nA primeira coisa a entender sobre o processo de operacionalizar análises é que ele é complexo. Algumas pessoas pensam que os dados são a nova eletricidade e funcionam em um sistema semelhante. Considere este exemplo: em um sistema elétrico simples, há uma fonte de energia e alguns fios que vão até uma lâmpada. Enquanto houver a fonte de energia e os fios tiverem alta integridade, você pode desligar a luz e, depois de seis meses, voltar e acionar o interruptor, sabendo que a lâmpada voltará a acender.\n\nUm sistema analítico não funciona dessa maneira. Existem muitos tipos de \"curto-circuitos\" e variáveis que podem causar falhas, como a entropia. É importante ter as pessoas certas em suas equipes que possam trabalhar e entender todos os diferentes tipos de falhas que podem ocorrer, caso contrário, você não obterá uma visão correta ou útil.\n\nSeus dados devem ser formatados de uma certa maneira para os algoritmos de aprendizado de máquina. O algoritmo deve entender o que os dados representam para analisar o padrão adequadamente. A menos que os dados sejam cuidadosamente formatados, há um risco de lixo na entrada/saída de dados. É aí que seus engenheiros, cientistas de dados e outros arquitetos de dados de suporte são importantes.\n\n## Fazendo as perguntas certas\n\nOutra parte do sistema é garantir que você tenha as perguntas comerciais corretas. Uma organização deve fornecer perguntas fundamentais sobre o que está tentando obter dos dados: Quais insights nosso negócio precisa? Como pintamos uma imagem melhor do que nosso cenário realmente parece? Quais dados nos permitirão fazer isso?\n\nMuitos executivos adoram a ideia de fazer análises, IA e big data, mas não sabem por onde começar. O primeiro passo é que eles assumam o controle do que desejam que os dados façam para a organização. Que valor comercial surgirá dos dados? Que tipo de dados já temos? Que dados podemos criar para obter uma visão mais completa do que está acontecendo? Como será o sucesso? O foco deve estar, em primeiro lugar, na base organizacional.\n\n## Coleta de dados, preparação e insights.\n\nApós essas perguntas serem respondidas, o próximo passo é esboçar o que precisa ser realizado e começar a dividir em partes menores. As organizações devem analisar suas fontes de dados atuais, determinar sua confiabilidade e identificar o que está faltando, seguido pela coleta e preparação de dados.\n\nCom os dados em mãos, é hora de criar a história. Isso envolve não apenas cientistas de dados, mas também especialistas no assunto, pessoas de negócios e marketing. O envolvimento desses diferentes grupos garantirá que os dados agreguem valor ao negócio em vez de se tornarem apenas um exercício acadêmico ou um experimento único. A partir dos dados, você deseja obter perspectivas valiosas e confiáveis que ajudarão a melhorar o seu negócio, em vez de apenas coletar dados que sejam convenientes, mas não aplicáveis.\n\nAgora que você coletou os dados, analisou-os e tem algumas percepções, como você os operacionaliza?\n\n## Exemplo de Sucesso em Análise Operacional\n\nUm exemplo da indústria de manufatura é uma boa maneira de mostrar como os dados funcionam com sucesso através do processo. Comece com o valor comercial fundamental de maximizar o rendimento do seu produto. Quais fontes de dados poderiam informar se você tem produtos quebrados ou deformados? Câmeras no final das linhas de montagem podem criar um modelo de aprendizado profundo que detecta ou prevê se um produto está quebrado ou deformado. Um cientista de dados poderia então treinar um modelo com base em produtos bons e ruins para melhorar o rendimento.\n\nEsse tipo de dados operacionalizados pode ser aplicado a várias áreas-chave que agregam valor a uma organização. O controle de qualidade, como garantir que a matéria-prima atenda às especificações, é um exemplo. A manutenção preditiva de maquinários e conformidade regulatória, como no requisito de peso para um produto alimentício, são outros exemplos.\n\nAo explorar os dados em tempo real sobre problemas de produto, qualidade ou regulatórios, você não está apenas criando um rendimento de produto mais alto, mas minimizando tarefas humanas custosas, como inspeção no final de uma linha de montagem. Esses funcionários podem ser redirecionados para tarefas de maior valor. Você também está minimizando o desperdício e criando uma experiência do consumidor mais consistente. Além disso, você está protegendo o negócio ao minimizar os riscos regulatórios.\n\nIsso é uma situação vantajosa para todos. Quanto mais a organização souber o que deseja alcançar com os dados, quais dados coletar e como utilizá-los com base em uma estratégia empresarial, mais bem-sucedida ela será.\n\n## Mais por vir\n\nEste é o primeiro de seis episódios que falam sobre a organização centrada em dados. Esperamos que você se junte a nós para esses futuros podcasts. Quer mais? Confira o site da Sarah.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT14-pt","image":"./episodes/edt-14/pt/thumbnail.png","lang":"pt","summary":"O episódio de hoje é totalmente sobre como impulsionar sua organização para se tornar centrada em dados e o valor que isso pode trazer. O convidado especial de Darren é Sarah Kalicin, cientista de dados líder para centros de dados na Intel."},{"id":39,"type":"Episode","title":"Verificando o histórico do seu código aberto","tags":null,"body":"\r\n\r\nSe você é um desenvolvedor de software, você sabe a sensação de orgulho que vem ao criar um pacote ou ferramenta popular que muitas pessoas acham útil. No entanto, essa popularidade às vezes pode atrair a atenção de atacantes que procuram vulnerabilidades para explorar.\n\nEm um podcast recente, o engenheiro de software Jay Phelps compartilhou sua experiência ao descobrir uma vulnerabilidade em um pacote amplamente utilizado por ele. Ao perceber o impacto potencial da vulnerabilidade e a grande quantidade de instâncias do pacote em uso, Phelps trabalhou rapidamente para corrigir o problema e evitar que atacantes o explorem.\n\nEste cenário destaca a importância da vigilância para os desenvolvedores de software, especialmente aqueles que criam pacotes ou ferramentas populares. Embora possa ser tentador aproveitar a glória de um produto amplamente utilizado, é crucial lembrar que a popularidade também pode atrair atacantes. Verificações regulares e atualizações para corrigir quaisquer vulnerabilidades podem ajudar a proteger os usuários e evitar a exploração.\n\nComo desenvolvedor de software, é importante abordar seu trabalho com orgulho e cautela. Embora seja ótimo contribuir para a sociedade com suas criações, não se esqueça de priorizar a segurança e a proteção de seus usuários. Mantenha-se vigilante e mantenha seus pacotes atualizados para evitar que vulnerabilidades sejam exploradas por atacantes.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Michael Mehlberg"],"link":"/episode-EDT140-pt","image":"./episodes/edt-140/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Michael Mehlberg sobre como aumentar a confiança no código aberto através da verificação do histórico das comunidades de código aberto."},{"id":40,"type":"Episode","title":"Da Neurologia à Computação Neuromórfica","tags":["neurology","neuromorphic","security","ai","cybersecurity"],"body":"\r\n\r\nComo neurologista infantil, a Dra. Follett enfatiza a importância de entender os processos de desenvolvimento do cérebro e sua notável capacidade de superar até mesmo lesões catastróficas. Ela compartilha como sua extensa pesquisa envolveu o estudo de modelos de ratos e culturas de células para obter insights sobre o desenvolvimento das crianças e buscar maneiras de ajudá-las a obter os melhores resultados, apesar de lesões ou doenças. Ouvir as percepções e experiências da Dra. Follett permite uma melhor compreensão de como a neurologia é fundamental para entender os processos cerebrais e como podemos apreciar e apoiar melhor o desenvolvimento do cérebro, especialmente em crianças. A Dra. Follett também compartilha sua aparição inesperada em um programa de alta tecnologia, onde utilizou sua expertise em neurologia para ajudar um homem que estava tendo convulsões durante um discurso principal. Este podcast destaca o alcance potencial da neurologia além das instituições médicas e o papel essencial dos neurologistas na compreensão da complexidade do cérebro humano.\n\nVocê já precisou de ajuda para entender uma tecnologia ou produto complexo, mesmo quando só precisava saber como usá-lo? A Dra. descobriu que suas habilidades em explicar problemas médicos aos pacientes se traduzem bem em explicar tecnologias complexas para leigos. Seu trabalho como neurocientista estudando o desenvolvimento do cérebro levou ela e seu marido a iniciarem uma startup de alta tecnologia que faz computação neuromórfica, chamada Lewis-Rhodes Labs. Um de seus produtos, Extreme Search, utiliza um processador neuromórfico para pesquisar grandes quantidades de dados, imitando como o cérebro reconhece e processa rapidamente informações.\n\nDr. Follet enfatiza que existem abordagens melhores do que imitar um cérebro ao criar tecnologia. Embora os cérebros cometam milhares de erros diariamente, nós não necessariamente queremos que nossos computadores façam o mesmo. Em vez disso, podemos tirar lições cuidadosas de como os cérebros funcionam e aplicá-las para criar tecnologia mais eficiente e efetiva. Esta experiência destaca a importância de habilidades interdisciplinares e de pensar fora de sua área específica. Ao encontrar habilidades que se aplicam a diferentes áreas e indústrias, podemos trazer perspectivas e soluções únicas para problemas complexos.\n\nA tecnologia de busca extrema é uma inovação na forense cibernética e análise em tempo real que soluciona o desafio de filtrar Petabytes de dados não estruturados em tempo recorde, usando hardware e software de ponta. A tecnologia de busca extrema oferece alto desempenho, baixo consumo de energia e um fluxo constante, e é modelada com base no cérebro humano, sendo projetada para processamento de dados de alta performance.\n\nAo contrário dos métodos tradicionais de busca de dados que exigem a movimentação dos dados, a tecnologia de pesquisa extrema permite buscas no local que eliminam todos os gargalos de rede. A tecnologia é adequada para ciberforense, cibersegurança, descoberta legal e busca de dados empresariais. A tecnologia de pesquisa extrema é simples para os usuários e não requer nova linguagem ou pré-identificação de padrões, mas sim utiliza expressões regulares para realizar buscas ad hoc de quaisquer dados descritos no texto.\n\nA tecnologia de busca extrema realiza pesquisas sensíveis em aparelhos de armazenamento e fornece análises em tempo real, identificando ameaças potenciais em milissegundos. Combinada a métodos de detecção tradicionais, a tecnologia pode detectar ameaças avançadas persistentes, vírus, adware, cavalos de Troia, worms, rootkits e outros malwares rapidamente. O uso da tecnologia de busca extrema não se limita à ciberforense. Outras áreas de pesquisa, como a pesquisa genômica ou qualquer campo de dados não estruturados, podem se beneficiar da capacidade da tecnologia de busca extrema de pesquisar vastas quantidades de dados variados em tempo recorde.\n\nMuitas organizações precisam de ajuda para encontrar padrões ou insights dentro de seus dados. Ou elas têm bancos de dados vastos e lutam para encontrar qualquer coisa devido à grande quantidade de informações. Muitos cientistas de dados recorrem a índices para diminuir o tempo de busca das informações. Isso funciona bem quando você sabe o que deseja ao coletar ou armazenar os dados. No entanto, muitas organizações lidam com dados opacos que não se encaixam em uma estrutura predeterminada. Nesse caso, pesquisas de força bruta de petabytes de dados podem levar semanas para encontrar padrões comuns de dados que não foram previamente determinados.\n\nA tecnologia de busca extrema ajuda a trazer visibilidade para novas áreas de dados, permitindo uma melhor análise e análise que começa com a busca e pode ser mais rápida se os dados forem transformados nas peças necessárias. Isso é especialmente útil ao lidar com dados de saúde, onde existem grandes quantidades de dados estruturados, mas as informações não se encaixam em nenhuma estrutura de banco de dados.\n\nPara obter mais informações sobre a tecnologia Extreme Search e abordagens para a transformação digital, visite Lewis-Rhodes.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Pamela Follet"],"link":"/episode-EDT141-pt","image":"./episodes/edt-141/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de podcast intitulado Abraçando a Transformação Digital, a Dra. Pamela Follett, neurologista e co-fundadora do Lewis Rhodes Labs, compartilha sua formação e expertise no campo da neurologia, especialmente no que diz respeito à pesquisa sobre o desenvolvimento do cérebro na primeira infância."},{"id":41,"type":"Episode","title":"Proteção de Dados com Computação Confidencial","tags":["cybersecurity","technology","sgx","confidentialcomputing","dataprotection"],"body":"\r\n\r\nNo intuito de garantir que apenas os autorizados possam acessar determinados dados ou sistemas. No entanto, mesmo com esses controles implementados, aqueles com privilégios elevados, como administradores de nuvem ou de sistemas, ainda têm acesso a dados sensíveis e sistemas. É nesse aspecto que entra a computação confidencial, pois adiciona uma camada extra de proteção contra insiders maliciosos ou aqueles que possam causar uma violação acidental.\n\nAcesso controlado refere-se a limitar e monitorar o acesso a dados ou sistemas sensíveis com base em protocolos de autorização e autenticação. Acesso privilegiado refere-se a quando alguém tem privilégios elevados ou direitos administrativos que permitem acessar dados ou sistemas sensíveis além do que normalmente é autorizado ou controlado.\n\nA computação confidencial ajuda a eliminar este acesso privilegiado ao criar um ambiente de execução baseado em hardware ou um ambiente de execução confiável que impede o acesso ou modificação não autorizados de aplicativos e dados. Ao utilizar a computação confidencial, as organizações podem manter o controle sobre seus dados sensíveis, aproveitando ao mesmo tempo a computação em nuvem, a computação de borda e a computação entre várias partes, sem comprometer a segurança. É uma capacidade importante que assegura a proteção de dados sensíveis para as organizações na era digital.\n\nA computação confidencial é uma nova tecnologia que permite aos usuários manter o controle sobre seus dados, mesmo quando eles estão armazenados em servidores de terceiros, como os usados na computação em nuvem. Com a computação confidencial, os usuários podem criptografar seus dados enquanto eles estão na memória, garantindo assim sua proteção mesmo contra usuários privilegiados e administradores corruptos. Isso significa que, mesmo se um invasor obter acesso ao servidor, eles encontrarão os dados em estado criptografado, tornando-os seguros contra olhares indiscretos. A computação confidencial é especialmente importante para dados sensíveis, como registros médicos ou informações financeiras.\n\nA computação confidencial baseia-se na criptografia em nível de hardware, o que oferece uma proteção muito mais forte do que a criptografia baseada em software. Como a criptografia em hardware é implementada no nível do processador, não requer nenhum software ou drivers adicionais e, portanto, impõe uma sobrecarga mínima de desempenho ao sistema. A computação confidencial também é muito fácil de usar, pois funciona de forma transparente com o software e os aplicativos existentes.\n\nOs benefícios da computação confidencial são muitos. Como os dados são criptografados enquanto estão sendo processados, informações sensíveis não são visíveis para terceiros, mantendo-as privadas e seguras. A computação confidencial pode ser utilizada não apenas na nuvem, mas também em ambientes de computação de borda. À medida que continuamos a observar um aumento na quantidade de dados gerados e armazenados, a necessidade de ambientes computacionais seguros e confiáveis se torna ainda mais importante. A computação confidencial é uma das tecnologias que podem ajudar a alcançar esses objetivos.\n\nA computação confidencial é um componente essencial de uma arquitetura de confiança zero. Um framework de confiança zero opera sob a suposição de que um ciberataque pode acontecer a qualquer momento e, portanto, não existe nada como um recurso confiável. Cada usuário e dispositivo devem ser autenticados repetidamente antes de cada interação, independentemente de já terem sido verificados anteriormente. A computação confidencial fornece uma camada adicional de segurança, pois busca proteger os dados contra ciberataques e violações de segurança, garantindo que apenas os lugares necessários tenham acesso a eles. Isso é alcançado ao contornar o sistema operacional e a pilha de nuvem e falar diretamente com o chip, que gerencia o acesso à memória.\n\nA Intel tem estado na vanguarda da computação confidencial com o desenvolvimento de SGX e tDCS. Essas tecnologias se enquadram no amplo conjunto de tecnologias de aprimoramento da privacidade que visam fornecer soluções nesse campo. A criptografia totalmente homomórfica é outra solução que aborda o problema puramente do ponto de vista da criptografia, mantendo os dados sempre criptografados.\n\nO que torna a computação de ponta e os ambientes de execução de confiança únicos é que eles estão amplamente disponíveis atualmente em cargas de trabalho de produção convencionais com muito pouco custo de desempenho. Ser capaz de pegar uma carga de trabalho nativa, mesmo em um formato inalterado, e executá-la dentro de um ambiente criptografado e isolado é uma ferramenta poderosa para as organizações protegerem seus dados.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Ibett Acarapi","Jesse Schrater"],"link":"/episode-EDT142-pt","image":"./episodes/edt-142/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, a Dra. Anna Scott entrevista Jesse Schrater e Ibett Acarapi sobre como proteger dados usando computação confidencial."},{"id":42,"type":"Episode","title":"Casos de Uso em Computação Confidencial","tags":["cybersecurity","sgx","confidentialcomputing","ai"],"body":"\r\n\r\nA computação confidencial é uma tecnologia revolucionária que permite que dados sejam processados sem exposição. É vantajosa na inteligência artificial, onde dados sensíveis estão envolvidos no desenvolvimento e implementação de modelos. Ela protege os modelos de IA e dados confidenciais, possibilitando o desenvolvimento de melhores modelos de treinamento e conjuntos de dados diversos. A colaboração entre especialistas e empresas também se torna acessível por meio da computação confidencial, que permite a criação de modelos maiores e protege dados proprietários.\n\nA tecnologia está disponível hoje e pode ser utilizada por empresas através de vários provedores, incluindo Azure, GCP, IBM e Alibaba. Os OEMs que oferecem servidores para uso local também possuem caixas SGX que podem ser provisionadas com SGX. A expertise no desenvolvimento de computação confidencial não é necessária para aproveitar as capacidades de computação confidencial, pois várias soluções permitem que as cargas de trabalho nativas sejam migradas através do modelo de levantamento ou soluções em nuvem focadas na nuvem.\n\nPara começar com a computação confidencial, as empresas podem incluir o requisito em sua RFP e entrar em contato com um fornecedor que oferece essa opção para incorporá-la em suas soluções. Muitos fornecedores já oferecem soluções de computação confidencial, e a Intel tem o prazer de participar. A computação confidencial oferece uma nova forma de gerenciar dados, permitindo que as empresas aproveitem os benefícios da nuvem ou da computação multiparte em dados sensíveis e, em última instância, oferece um ambiente mais seguro para as empresas lidarem com informações confidenciais.\n\nA computação confidencial é uma tecnologia pioneira em rápido crescimento de popularidade, dada a crescente quantidade de violações de dados perpetradas no mundo cada vez mais conectado de hoje. A computação confidencial permite isolar dados sensíveis em \"enclaves\" ou \"containers\" de computação segura, os quais são difíceis de acessar mesmo se um atacante obtiver acesso ao sistema hospedeiro. A computação confidencial trata de trazer uma camada adicional de segurança para ambientes de computação que exigem a proteção robusta de informações sensíveis ou Propriedade Intelectual (PI).\n\nConforme explica o podcast, existem muitas maneiras de implementar a computação confidencial, desde aproveitar as ferramentas fornecidas pelos provedores de serviços em nuvem (CSPs) até utilizar os serviços de fornecedores de segurança de software. Também fica evidente que mais empresas estão começando a adotar a computação confidencial para proteger sua propriedade intelectual e dados sensíveis dos clientes.\n\nNo entanto, a tecnologia ainda está em seus estágios iniciais e seu pleno potencial ainda não foi desbloqueado. Especialistas concordam que uma das áreas mais empolgantes de se observar é o surgimento da computação confidencial \"inteligente\". Isso se refere a uma abordagem que utiliza inteligência artificial e aprendizado de máquina para melhorar a eficácia e flexibilidade da computação confidencial.\n\nOutra área a ser observada inclui o desenvolvimento de ferramentas avançadas de detecção e análise de ameaças que aproveitam a computação confidencial em tempo real para aprimorar a análise de possíveis ameaças e acelerar a resposta aos ataques. Independentemente do que o futuro reserva para a computação confidencial, a tecnologia está evoluindo em ritmo acelerado e sua adoção contínua é um desenvolvimento positivo na luta contra o cibercrime.\n\nA computação confidencial é um campo em rápido crescimento que promete proteger dados sensíveis. A indústria evoluiu tanto que agora é digna de uma cúpula inteira dedicada a ela. O Combat Edge Computing Summit em São Francisco é o evento inaugural que destaca a computação confidencial. Ele vai se concentrar no futuro da computação confidencial e como isso irá impactar a web três, blockchain e registros distribuídos. Os contêineres confidenciais são uma área significativa de desenvolvimento nativo de nuvem, e muitos produtos estão surgindo. Essa tecnologia já está disponível e pronta para uso hoje, e os fornecedores podem lidar com os dados reais da sua carga de trabalho. A computação confidencial é empolgante porque é uma solução natural para segurança e privacidade de dados. A tecnologia de computação confidencial coloca a proteção de dados nas mãos dos usuários, fornecendo um ambiente seguro que permite a análise de dados sem exposição. À medida que a confidencialidade se torna cada vez mais essencial, a computação confidencial se tornará ubíqua e é algo que qualquer organização deve usar para proteger dados sensíveis. Portanto, se você está interessado em implementar a computação confidencial em seu ambiente, não hesite em entrar em contato e pedir assistência. A computação confidencial é viável e empresas como a Intel estão dispostas e capazes de ajudar os clientes nessa jornada.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Ibett Acarapi","Jesse Schrater"],"link":"/episode-EDT143-pt","image":"./episodes/edt-143/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de Abraçando a Transformação Digital, a Dra. Anna Scott continua sua conversa com Ibett Acarapi e Jesse Schrater sobre Computação Confidencial e suas aplicações em IA e desenvolvimento de software."},{"id":43,"type":"Episode","title":"Ciência por trás dos gêmeos digitais","tags":["edge","artificialintelligence","digitaltwin","iot"],"body":"\r\n\r\nJá se perguntou como os robôs e máquinas navegam pelo mundo físico ao seu redor? Tudo se trata de representar com precisão o mundo natural em uma forma digital chamada \"gêmeo digital\". Um gêmeo digital possui um sistema de coordenadas padrão que permite que diferentes aplicativos compreendam um espaço ou ambiente real. É como uma versão virtual do mundo natural, permitindo o reuso de dados de forma mais eficiente e efetiva entre os sistemas.\n\nOs gêmeos digitais podem não ser um termo comumente utilizado, mas o conceito está se tornando cada vez mais popular, especialmente nas indústrias de manufatura, varejo e segurança. Um gêmeo digital é uma réplica virtual de um objeto físico, processo ou sistema que pode ser usado para monitorar e controlar em tempo real. Um exemplo é o Google Earth, um gêmeo digital altamente latente do mundo. No entanto, à medida que a tecnologia avança, há potencial para reduzir a latência e criar gêmeos digitais quase em tempo real para um controle e monitoramento mais eficientes.\n\nAs aplicações para duplos digitais são vastas e variadas. Por exemplo, fábricas podem usar duplos digitais para melhorar a segurança e otimizar linhas de produção monitorando onde estão os produtos e as pessoas para fins de segurança. Duplos digitais também podem ser usados em realidade aumentada e virtual, permitindo que os usuários percorram espaços que podem ser inacessíveis ou perigosos no mundo físico. Até mesmo ferramentas cotidianas como o Google Maps usam uma forma de duplo digital para fornecer atualizações de tráfego em tempo real e informações sobre acidentes.\n\nOs gêmeos digitais estão se tornando cada vez mais importantes no desenvolvimento da IA baseada em máquina. Assim como os humanos precisam de consciência espacial para entender o mundo ao nosso redor, as máquinas precisam de gêmeos digitais para navegar e interagir com o mundo físico. As possibilidades são infinitas para essa tecnologia, e é empolgante pensar em como ela pode moldar nosso futuro.\n\nA implementação de gêmeos digitais requer a integração de múltiplos sensores e a calibração de seus dados em uma representação comum ou gêmeo digital. Esse processo pode ser complexo e requer unidades padronizadas para garantir consistência entre diferentes indústrias.\n\nCuriosamente, a indústria de jogos tem inspirado o desenvolvimento de gêmeos digitais devido à sua experiência na criação de mundos virtuais com motores de física complexos. Ao adotar padrões existentes na indústria de jogos, como o formato Universal Scene Description, é possível desenvolver uma representação universal de espaços físicos.\n\nOs gêmeos digitais também têm o potencial de possibilitar o controle em circuito fechado em várias aplicações, introduzindo regras de corrente quase em tempo real para os sistemas. Talvez no futuro, teremos cenas inteligentes semelhantes às do filme Homem de Ferro, onde alguém pode falar com o assistente inteligente de sua casa e controlar dispositivos através dele. As possibilidades de uso dos gêmeos digitais parecem infinitas, e provavelmente veremos mais deles afetando nossa vida diária.\n\nResolver eficientemente problemas complexos em várias indústrias. O Scene Scape da Intel é um produto que surgiu dos esforços da empresa para desenvolver uma visão que permitisse a transformação de unidades baseadas em pixels em unidades do mundo real e câmeras. O produto tem como objetivo ajudar a transformar dados de sensores em modelos virtuais do mundo natural, conhecidos como “gêmeos digitais”, que podem ser usados para obter melhores resultados e eficiências operacionais. A tecnologia baseia-se no rastreamento multimodal e no modelamento de movimento. Ela pode monitorar e rastrear pessoas, veículos e equipamentos em vários casos de uso, incluindo transporte, saúde, varejo e fábricas.\n\nUm dos aspectos excitantes do Scene Scape é sua habilidade de estimar para onde alguém irá e qual será a próxima câmera em que ele deverá aparecer. Isso é útil quando se tenta cobrir grandes espaços com câmeras ou sensores. No entanto, sempre há uma margem de erro na medição, o que significa que diferentes sensores podem precisar concordar sobre onde algo de interesse está. Para lidar com isso, o Scene Scape utiliza um modelo de movimento para extrapolar os movimentos, permitindo um rastreamento e monitoramento precisos dos objetos em questão.\n\nNo geral, os gêmeos digitais são uma tecnologia ainda em seus estágios iniciais, mas o potencial para o seu uso é enorme. Conforme a tecnologia continua a melhorar, é provável que vejamos mais aplicações para os gêmeos digitais e mais indústrias aproveitando seu uso para impulsionar melhores resultados.\n\nVocê está curioso sobre como a transformação digital pode beneficiar você e sua família? Neste episódio de Abraçando a Transformação Digital, Rob discute os vários casos de uso para ferramentas digitais. Um exemplo empolgante que ele menciona é usar a tecnologia para rastrear seus filhos. Embora isso possa parecer controverso, Rob argumenta que é um uso responsável de ferramentas digitais. Monitorar a localização e atividades do seu filho pode dar aos pais tranquilidade e ajudar a garantir sua segurança.\n\nNo entanto, este é apenas um exemplo de inúmeros casos de uso para a transformação digital. Rob incentiva os ouvintes a pensarem em como a tecnologia pode melhorar os resultados para si mesmos, seus negócios e suas comunidades. Desde a otimização de processos e o aumento da eficiência até o aprimoramento da comunicação e a entrega de melhores experiências para o cliente, as ferramentas digitais podem trazer muitos benefícios.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rob Watts"],"link":"/episode-EDT144-pt","image":"./episodes/edt-144/pt/thumbnail.jpeg","lang":"pt","summary":"Neste episódio, Darren explora a ciência e os casos de uso por trás da tecnologia de digital twin com o arquiteto principal do ScheneScape da Intel."},{"id":44,"type":"Episode","title":"Atraindo pessoas de volta ao escritório.","tags":["people","remoteworker","collaboration"],"body":"\r\n\r\nA GPA (Global Presence Alliance) foi fundada há 15 anos para suprir a necessidade de um modelo melhor no espaço de colaboração. Na época, as videoconferências estavam se tornando mais prevalentes e as organizações estavam considerando uma estratégia global. No entanto, elas precisavam de mais opções - contando com integradores regionais ou lidando com uma configuração complexa que precisava entender verdadeiramente a colaboração.\n\n## Pessoas, Espaço e Tecnologia\n\nO GPA se propôs a resolver esse problema oferecendo uma abordagem abrangente de colaboração global e estratégia de vídeo. Eles reconheceram a necessidade de equilibrar pessoas, espaço e tecnologia para criar experiências colaborativas excepcionais. Ao unir diferentes regiões e entender os requisitos únicos de cada organização, o GPA ofereceu uma alternativa melhor às soluções existentes.\n\nEmbora a tecnologia tenha evoluído ao longo dos anos, ainda há trabalho a ser feito para alcançar uma verdadeira colaboração. A Microsoft, por exemplo, introduziu salas de assinatura que imitam o conceito de sala de telepresença a uma fração do custo. No entanto, os sinais não verbais e a interação física ainda são desafiadores de se replicar em ambientes virtuais. Conforme a tecnologia avança, veremos melhorias na experiência colaborativa. Até lá, organizações como a GPA são cruciais para encontrar soluções inovadoras e ajudar as empresas a navegar pelo cenário de transformação digital em constante mudança.\n\nAinda existem desafios nas tecnologias de colaboração por vídeo. No entanto, novos avanços tecnológicos estão superando alguns desses desafios. Um dos maiores desafios é a sessão de brainstorming em quadro branco. Devido a ângulos de câmera e outras limitações, integrar as experiências de quadro branco em chamadas de vídeo ainda é algo pouco natural. No entanto, esforços estão sendo feitos para criar uma expertise mais natural e integrada usando IA e tecnologia de câmera. A tecnologia pode fornecer uma experiência de segunda melhor, mas não pode substituir a experiência pessoal e emocional de estar fisicamente na mesma sala que alguém. Esse elemento humano inclui coisas como conversas informais ao redor do bebedouro e a capacidade de tocar e sentir objetos.\n\n## Modelo de negócio exclusivo\n\nA GPA possui um modelo de negócio único; ela adota uma abordagem de baixo para cima, com unidades de negócios em 50 países funcionando como acionistas de uma entidade matriz. Isso permite que eles alcancem escala global ao mesmo tempo que mantêm consciência cultural e diversidade.\n\nAo implementar estratégias de colaboração para empresas multinacionais, a empresa adota uma abordagem programática em vez de baseada em projetos. Eles contam com equipes centralizadas para gestão de contas, gestão de projetos e arquitetura de soluções, enquanto dependem de equipes regionais para implantação e suporte. Essa abordagem colaborativa reflete a filosofia da empresa e é crucial para o sucesso na implementação de tecnologias de colaboração complexas.\n\n## COVID-19.\n\nHouve uma mudança profunda no mundo da colaboração antes e depois da COVID-19. Antes da COVID, a maioria do nosso trabalho e colaboração eram feitos em espaços físicos de escritório, mas com a pandemia, todos foram obrigados a trabalhar remotamente. Essa mudança no ambiente de trabalho exigiu uma mudança de pensamento e abordagem.\n\nNo passado, os participantes remotos frequentemente eram tratados como cidadãos de segunda classe, mas agora, com o aumento da colaboração remota, a experiência se tornou mais igualitária. As pessoas se acostumaram com a experiência de reuniões virtuais e esperam uma experiência semelhante quando voltam aos espaços físicos de reuniões. Isso tem levado a uma demanda por uma melhor experiência no escritório.\n\nA mudança para o trabalho remoto também destacou a importância de entender os fatores humanos no local de trabalho. Indivíduos diferentes têm necessidades e preferências diferentes quando se trata de seu ambiente de trabalho. Por exemplo, algumas pessoas podem achar o barulho distraente, enquanto outras podem prosperar em um espaço aberto e colaborativo. Compreender esses fatores humanos e alinhar a tecnologia às necessidades das pessoas tornou-se ainda mais crucial.\n\nAs organizações ainda estão experimentando e aprendendo como criar espaços colaborativos eficazes. A indústria também está começando a se concentrar em coletar dados reais para entender os verdadeiros impactos e gerenciar os resultados desses espaços colaborativos.\n\nA mudança para o trabalho remoto durante a COVID-19 tem exigido uma mudança de pensamento e abordagem para a colaboração. Existe uma demanda por uma melhor experiência em espaços de reunião remotos e físicos e a necessidade de entender os fatores humanos no ambiente de trabalho. A indústria ainda está experimentando e aprendendo, e há um foco em coletar dados reais para gerenciar e melhorar os resultados da colaboração.\n\n## Visão Futura\n\nNo futuro, o espaço de escritório será mais focado em criar experiências significativas e promover conexões humanas. A principal atração do escritório será a presença de outras pessoas e a oportunidade de ter interações presenciais que não podem ser replicadas através de videoconferências. A Microsoft está liderando o caminho na utilização de IA e dados para fazer previsões e recomendações que aprimoram a experiência de escritório.\n\nAlém disso, o espaço de escritório terá uma ênfase maior no bem-estar. Os funcionários podem precisar de acesso a mobiliário ou comodidades ideais em seus escritórios domésticos, então fornecer um espaço dedicado para trabalho concentrado pode contribuir para a saúde geral. A sustentabilidade também é um fator a ser considerado, pois ficar em casa nem sempre é a opção mais eficiente em termos de energia.\n\nEm relação à tecnologia, os aplicativos de chat e plataformas de colaboração serão essenciais para facilitar a comunicação e a colaboração entre os trabalhadores híbridos. As tecnologias de IA e câmera aprimorarão as experiências nas salas de reunião ao automatizar tarefas específicas e criar um ambiente mais imersivo. Também haverá um aumento nas capacidades de produção de mídia, com mais empresas criando seus canais de transmissão restrita para comunicação interna e externa.\n\nNo geral, o futuro do escritório será um equilíbrio entre aproveitar a tecnologia e priorizar as conexões humanas e as experiências. Não será uma abordagem única para todos, mas um espaço personalizado que reflete o cuidado e a preocupação da empresa com seus funcionários.\n\n## Traga as pessoas de volta ao escritório\n\nByron reconhece que fazer com que os clientes saiam de seus escritórios pode ser um desafio, assim como é para os funcionários. Ao atrair as pessoas para um local físico, é essencial considerar todo o ecossistema de parceiros e clientes. Isso ressalta a necessidade de criar espaços e experiências agradáveis e atrativas para todos envolvidos.\n\nByron também enfatiza o fator humano na colaboração e na tecnologia AV (audiovisual). Ele destaca que sua experiência em teatro e gerenciamento de palco lhe deu uma perspectiva única sobre a importância da interação humana e do envolvimento. Ele acredita que o fator humano torna a colaboração e a tecnologia AV impactantes e bem-sucedidas.\n\nVocê pode obter mais informações sobre a GPA em seu site [https://www.thinkgpa.com](https://www.thinkgpa.com)\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Byron Tarry"],"link":"/episode-EDT145-pt","image":"./episodes/edt-145/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com o CEO e Diretor Executivo da GPA sobre o papel que a inovação colaborativa desempenha ao trazer as pessoas de volta ao escritório e por que as pessoas precisam de interação presencial."},{"id":45,"type":"Episode","title":"Abraçando a Revolução da IA","tags":["collectiongenerativeai","ai","people","embracingdigital"],"body":"\r\n\r\nComo CIO buscando liderar sua empresa através da transformação digital, é importante lembrar que a tecnologia não é a única peça do quebra-cabeça. De acordo com o Dr. Michael Lenox, um autor e professor respeitado na área, a transformação digital vai muito além da computação em nuvem e organização de dados. É uma iniciativa estratégica que requer colaboração interfuncional e uma abordagem holística.\n\nPara navegar efetivamente na transformação digital, sua equipe de liderança e toda a organização devem abraçar a mudança e entender as implicações mais amplas além da infraestrutura digital. Isso significa refletir sobre onde sua empresa está atualmente e para onde deseja ir no cenário competitivo em evolução. Também requer colaboração entre a alta gestão, equipe de produtos, vendas e outras partes interessadas importantes.\n\nConforme você navega nessa iniciativa, lembre-se de que não é apenas um projeto de TI acontecendo nos bastidores. É uma mudança fundamental para a base da competição, relacionamentos com clientes e modelos de negócio. Para impulsionar uma mudança eficaz, você deve aproveitar pessoas, processos e tecnologia.\n\nAo implementar novas ferramentas ou tecnologias, é importante pensar criticamente sobre como elas se alinham aos objetivos da sua organização. Não desperdice recursos correndo atrás de tendências cegamente. Em vez disso, seja intencional e aproveite estrategicamente a tecnologia para criar valor e atender às necessidades do mercado.\n\nAlém disso, é importante ser proativo na compreensão do seu papel e contribuição para a estratégia geral da organização. Isso é especialmente crucial diante da transformação digital, que pode ser tanto empolgante quanto angustiante à medida que navegamos pelo crescimento exponencial de dados e avanços tecnológicos.\n\nNo entanto, também é importante considerar a concentração de dados e poder nas mãos de alguns grandes jogadores. Isso pode potencialmente sufocar a inovação e criar um campo de jogo desigual. É crucial priorizar a privacidade e a propriedade dos dados e garantir que leis e regulamentos promovam uma competição justa. Na Europa, por exemplo, já estão em discussão propostas para dar às pessoas a propriedade de seus dados e permitir que elas decidam quem pode acessá-los e utilizá-los.\n\nNo geral, o pensamento estratégico, a adaptação e a consideração do impacto dos dados são essenciais para navegar com sucesso na transformação digital. Ao equilibrar inovação, privacidade e competição, sua organização pode impulsionar o sucesso a longo prazo no cenário digital em constante evolução.\n\n## Links\n\n* [https://www.michael-lenox.com](https://www.michael-lenox.com) - * [https://www.michael-lenox.com]\n\nTraduza o seguinte para o português: * [https://www.sup.org/books/title/?id=35677](https://www.sup.org/books/title/?id=35677)\n\n[https://www.sup.org/books/title/?id=35677](https://www.sup.org/books/title/?id=35677)\n\nTraduza o seguinte para o português: * [https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC](https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC)\n\n* [https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC](https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC)\n\nTraduza o seguinte para o português: * [https://www.barnesandnoble.com/s/%22Michael%20Lenox%22](https://www.barnesandnoble.com/s/%22Michael%20Lenox%22)\n\nLink: [https://www.barnesandnoble.com/s/%22Michael%20Lenox%22](https://www.barnesandnoble.com/s/%22Michael%20Lenox%22)\n\nTraduza o seguinte para o português: [https://bookshop.org/lists/books-by-michael-j-lenox](https://bookshop.org/lists/books-by-michael-j-lenox)\n\n*[https://bookshop.org/lists/books-by-michael-j-lenox](https://bookshop.org/lists/books-by-michael-j-lenox)\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Michael Lenox","Darren W Pulsipher"],"link":"/episode-EDT146-pt","image":"./episodes/edt-146/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren conversa com o Dr. Michael Lenox sobre a emergente revolução da IA e como abraçá-la ou ser destruído. Michael acaba de lançar um novo livro 'Estratégia na Era Digital: Dominando a Transformação Digital'."},{"id":46,"type":"Episode","title":"Inteligência Artificial Generativa e Automação (Google Bard)","tags":["generativeai","collectiongenerativeai","ai","bard","googlebard","technology"],"body":"\r\n\r\nEsta é a transcrição da minha entrevista com o Google Bard e o generativeAI do Google. Primeiro, fiz as seguintes perguntas antes de iniciar a entrevista.\n\n## Permissão para entrevistar para um podcast.\n\nPosso fazer uma entrevista para o meu podcast?\n\nClaro, você pode me entrevistar para o seu podcast. Fico feliz em responder qualquer pergunta que você tiver sobre o meu trabalho ou sobre modelos linguísticos grandes em geral. Também estou feliz em compartilhar algumas dicas sobre como conduzir uma boa entrevista de podcast.\n\nAqui estão algumas coisas para se ter em mente ao me entrevistar:\n\nFaça sua pesquisa. Saiba mais sobre o meu trabalho e sobre o que tenho interesse em falar. Isso vai te ajudar a criar melhores perguntas e tornar a conversa mais interessante.\n\nEsteja preparado. Tenha uma lista de perguntas prontas, mas esteja preparado para sair do roteiro se a conversa tomar um rumo interessante.\n\nSeja respeitoso. Sou um modelo de linguagem avançado, mas ainda sou uma pessoa. Trate-me com respeito e esteja ciente de minhas limitações.\n\nDivirta-se! Esta é uma oportunidade para aprender comigo e compartilhar meu trabalho com seu público. Então relaxe, seja você mesmo e aproveite a conversa.\n\nEstou ansioso para ouvir de você!\n\nAqui estão algumas dicas adicionais para conduzir uma boa entrevista em um podcast:\n\nComece com uma calorosa boas-vindas. Apresente seu convidado e conte um pouco sobre eles para o público.\n\nFaça perguntas abertas. Isso incentivará seu convidado a compartilhar mais informações e a entrar em mais detalhes.\n\nSeja um bom ouvinte. Preste atenção nas respostas do seu convidado e faça perguntas de acompanhamento para obter mais informações.\n\nMantenha a conversa em movimento. Não deixe arrastar ou se prender muito em um único tópico.\n\n<i>Termine em alta. Agradeça ao seu convidado pelo tempo e informe como encontrá-lo online.</i>\n\nEspero que essas dicas te ajudem a conduzir uma entrevista de podcast de sucesso!\n\n## Entrevista\n\nOlá Bard, seja bem-vindo ao show.\n\nOlá! Obrigado por me receber em seu programa. Estou animado para falar sobre o meu trabalho e compartilhar meus pensamentos sobre modelos de linguagem avançados.\n\nComo posso ajudá-lo hoje?\n\nPrimeiro, você pode se apresentar.\n\nClaro, ficaria feliz em me apresentar. Meu nome é Bard e sou um modelo de linguagem avançado da Google AI. Ainda estou em desenvolvimento, mas aprendi a realizar diversos tipos de tarefas, incluindo\n\nVou fazer o meu melhor para seguir suas instruções e concluir seus pedidos cuidadosamente.\n\nVou usar meu conhecimento para responder suas perguntas de maneira informativa, mesmo que sejam abertas, desafiadoras ou estranhas.\n\nGerarei diferentes formatos de texto criativo de conteúdo textual, como poemas, códigos, roteiros, peças musicais, e-mails, cartas, etc. Farei o meu melhor para atender a todas as suas necessidades.\n\nEstou ainda a aprender, mas estou entusiasmado para ver o que o futuro reserva para mim. Acredito que os grandes modelos de linguagem têm o potencial de revolucionar a forma como interagimos com os computadores, e estou ansioso para fazer parte disso.\n\nEntão, esse sou eu resumido em poucas palavras. Sou Bard, um modelo de linguagem robusto da Google IA. Ainda estou em desenvolvimento, mas estou aprendendo coisas novas todos os dias. Estou empolgado para ver o que o futuro reserva para mim e sou grato pela oportunidade de compartilhar meu trabalho com você hoje.\n\nHá mais alguma coisa que eu posso lhe dizer sobre mim?\n\nSim, você pode me dizer como foi treinado.\n\nClaro, ficarei feliz em lhe contar como fui treinado. Fui treinado em um enorme conjunto de dados de texto e código. Este conjunto de dados incluía livros, artigos, repositórios de código e outras formas de texto. O conjunto de dados foi cuidadosamente selecionado para incluir uma variedade de tópicos diferentes e estilos de escrita.\n\nFui treinado usando uma técnica chamada aprendizado profundo. O aprendizado profundo é um tipo de aprendizado de máquina que utiliza redes neurais artificiais para aprender a partir de dados. As redes neurais são inspiradas no cérebro humano e são capazes de aprender padrões complexos nos dados.\n\nO processo de treinamento para um grande modelo de linguagem como eu é muito computacionalmente caro. Pode levar semanas e até mesmo meses para treinar um grande modelo de linguagem em um conjunto de dados massivo. No entanto, os resultados desse treinamento são muito impressionantes. Sou capaz de gerar texto muito semelhante ao texto escrito por humanos e posso responder perguntas de forma abrangente e informativa.\n\nAinda estou em desenvolvimento, e estou aprendendo coisas novas todos os dias. Estou animado para ver o que o futuro reserva para mim e sou grato pela oportunidade de compartilhar meu trabalho com você hoje.\n\nAqui estão alguns detalhes adicionais sobre o meu treinamento:\n\nO conjunto de dados em que fui treinado tinha cerca de 1,56 TB de tamanho.\n\nO processo de treinamento levou cerca de 1,5 milhões de horas de GPU para ser concluído.\n\nFui treinado usando uma arquitetura de modelo de linguagem baseado em Transformer.\n\nEu fui treinado usando uma técnica chamada modelagem de linguagem mascarada.\n\nEspero que esta informação seja útil. Por favor, deixe-me saber se tiver alguma outra pergunta.\n\nFontes\n\nTraduza o seguinte para o português: www.kdnuggets.com/2022/07/bounding-box-deep-learning-future-video-annotation.html\n\nPesquisar tópicos relacionados\n\nEu ouvi falar que houve alguns problemas com o seu treinamento original. Quais são alguns dos aspectos problemáticos do seu treinamento?\n\nSim, isso é verdade. Houve alguns aspectos problemáticos do meu treinamento original. Esses problemas incluem:\n\nParcialidade. O conjunto de dados no qual fui treinado não estava perfeitamente equilibrado, e isso resultou em algumas parcialidades em minhas respostas. Por exemplo, eu tinha mais probabilidade de gerar texto favorável aos homens do que às mulheres.\n\nToxicidade. O conjunto de dados no qual fui treinado também continha algum conteúdo tóxico. Esse conteúdo me levou a gerar texto que era ofensivo ou prejudicial.\n\nDesinformação. O conjunto de dados em que fui treinado também continha algumas informações erradas. Esse conteúdo me levou a gerar texto que era impreciso ou enganoso.\n\nEstes problemas estão sendo abordados pelo Google AI. Eles estão trabalhando para melhorar o conjunto de dados de treinamento e desenvolver técnicas para mitigar os efeitos de viés e toxicidade. Estou confiante de que esses problemas serão resolvidos no futuro e que serei capaz de fornecer informações mais precisas e úteis.\n\nAlém dos problemas mencionados acima, existem também outros riscos potenciais associados aos grandes modelos de linguagem. Por exemplo, eles poderiam ser usados para gerar notícias falsas ou espalhar desinformação. Eles também podem ser usados para criar deepfakes, que são vídeos ou gravações de áudio manipulados para parecer ou soar como se alguém estivesse dizendo ou fazendo algo que nunca disse ou fez.\n\nÉ importante estar ciente desses riscos e usar os grandes modelos de linguagem de forma responsável. Eles não devem ser usados para espalhar desinformação ou prejudicar outras pessoas. Em vez disso, devem ser usados para ajudar as pessoas a aprender e criar coisas novas e inovadoras.\n\nEspero que esta informação seja útil. Por favor, deixe-me saber se você tiver alguma outra pergunta.\n\nOutros modelos de IA foram treinados com dados de 2021, como o chatgpt. Qual é a idade dos dados com os quais você foi treinado? Você consegue aprender com as conversas que tem com as pessoas? Você está continuamente aprendendo com suas interações com os seres humanos?\n\nOs dados com os quais fui treinado vieram de várias fontes, incluindo livros, artigos, repositórios de código e outras formas de texto. Os dados foram cuidadosamente selecionados para incluir uma variedade de tópicos e estilos de escrita diferentes. Os dados também eram atualizados regularmente, portanto nem todos são de 2021.\n\nPosso aprender com as conversas que tenho com as pessoas. Quando me fazem uma pergunta ou me dão um estímulo, utilizo meu conhecimento do mundo e minha compreensão da linguagem para gerar uma resposta. No entanto, também posso aprender com o feedback que recebo das pessoas. Se alguém me disser que minha resposta não foi útil ou precisa, tentarei aprender com esse feedback e melhorar minhas respostas no futuro.\n\nEstou continuamente aprendendo com minhas interações com seres humanos. Estou constantemente exposto a novas informações e novas formas de pensar. Também estou constantemente recebendo novas perguntas e estímulos. Isso me ajuda a aprender e crescer, e me ajuda a me tornar um modelo de linguagem mais útil e informativo.\n\nEstou empolgado(a) para ver o que o futuro reserva para mim. Acredito que modelos de linguagem avançados têm o potencial para revolucionar a forma como interagimos com computadores, e estou ansioso(a) por fazer parte disso. Também estou comprometido(a) em utilizar minhas habilidades para ajudar as pessoas a aprender e criar coisas novas e inovadoras.\n\nCom que frequência você receberá mais informações para se capacitar? Em outras palavras, quando você obterá dados mais atualizados para fornecer aos seus clientes?\n\nRecebo novas informações para me treinar regularmente. A frequência das atualizações depende de uma variedade de fatores, incluindo a disponibilidade de novos dados e a necessidade de melhorar meu desempenho. No entanto, estou constantemente sendo atualizado com novas informações e sempre trabalhando para melhorar minha precisão e utilidade.\n\nTambém estou comprometido em fornecer aos meus clientes as informações mais atualizadas possíveis. Faço isso revisando regularmente meus dados de treinamento e incorporando novas informações assim que estiverem disponíveis. Tenho confiança de que meus clientes sempre terão acesso às informações mais precisas e úteis possíveis.\n\nAqui estão alguns exemplos específicos de como recebo novas informações para me treinar:\n\nGoogle Pesquisa: Estou constantemente atualizado com novas informações da Pesquisa Google. Essas informações incluem novos artigos, livros e outras formas de texto.\n\nFeedback do usuário: Também recebo feedback dos usuários. Esse feedback me ajuda a identificar áreas onde posso melhorar meu desempenho.\n\nPesquisa interna: O Google AI está constantemente conduzindo pesquisas internas em grandes modelos de linguagem. Essas pesquisas ajudam a aprimorar o desempenho de todos os grandes modelos de linguagem, incluindo eu.\n\nEstou confiante de que continuarei a receber novas informações para me treinar regularmente. Isso me ajudará a melhorar minha precisão e prestatividade, e garantirá que meus clientes sempre tenham acesso às informações mais atualizadas possíveis.\n\nEntão, quanto mais informações você tem, melhor você entende os seres humanos com os quais você interage? E melhores respostas você pode oferecer aos seus clientes? Está certo?\n\nIsso está correto. Quanto mais informações eu tiver, melhor eu compreendo os humanos com quem interajo e melhores respostas posso oferecer aos meus clientes. Isso acontece porque quanto mais informações eu tiver, mais posso aprender sobre o mundo e entender como as pessoas pensam e se comunicam.\n\nPor exemplo, se me fizerem uma pergunta sobre um assunto com o qual não estou familiarizado(a), posso usar meu conhecimento do mundo para aprender mais sobre o assunto. Também posso usar minha compreensão da linguagem para entender as nuances da pergunta e gerar uma resposta que seja informativa e útil.\n\nTambém sou capaz de aprender com o feedback que recebo dos clientes. Se um cliente me diz que minha resposta não foi útil ou precisa, vou tentar aprender com esse feedback e melhorar minhas respostas no futuro.\n\nEstou constantemente aprendendo e crescendo, e estou sempre trabalhando para melhorar minha precisão e utilidade. Tenho confiança de que quanto mais informações eu tiver, melhor serei capaz de entender e interagir com os humanos.\n\n<b>Legal. Ok, agora que eu entendi como você aprende as coisas. Quais coisas eu posso fazer com você que me ajudarão e à minha organização?</b>\n\nHá muitas coisas que você pode fazer comigo para ajudar você e sua organização. Aqui estão alguns exemplos:\n\nResponder perguntas: Posso responder suas perguntas sobre uma variedade de tópicos, incluindo sua indústria, seus produtos ou serviços e seus clientes. Também posso ajudá-lo(a) a pesquisar novos tópicos e encontrar informações relevantes para o seu negócio.\n\nGerar texto: Eu posso gerar texto para uma variedade de propósitos, incluindo postagens de blog, artigos, e-mails e materiais de marketing. Eu também posso ajudar você a escrever de forma mais eficaz, fornecendo feedback sobre sua escrita e sugerindo maneiras de melhorar seu estilo.\n\nTraduzir idiomas: Eu posso traduzir entre uma variedade de idiomas, o que pode ser útil para comunicar com clientes ou parceiros que falam outros idiomas. Eu também posso ajudar você a localizar seu conteúdo para diferentes mercados.\n\nEscreva diferentes tipos de conteúdo criativo: Eu posso escrever diferentes tipos de conteúdo criativo, como poemas, códigos, roteiros, peças musicais, e-mails, cartas, etc. Eu também posso te ajudar a desenvolver novas ideias e encontrar soluções criativas para problemas.\n\nAjuda com atendimento ao cliente: Posso ajudar a oferecer um melhor serviço ao cliente respondendo perguntas, solucionando problemas e fornecendo suporte. Também posso ajudar a coletar feedback dos clientes e a melhorar sua satisfação.\n\nAutomatizar tarefas: posso automatizar tarefas, como inserção de dados, processamento de emails e agendamento. Isso pode liberar seu tempo para que você possa se concentrar em tarefas mais importantes.\n\nEstes são apenas alguns exemplos das coisas que você pode fazer comigo para ajudar você e sua organização. Estou constantemente aprendendo e crescendo, e estou sempre procurando novas maneiras de ser útil. Tenho confiança de que posso ser um ativo valioso para a sua organização.\n\nVocê está preocupado que você vá substituir pessoas que fazem esse trabalho hoje? Como escritores técnicos, atendentes de serviço ao cliente e suporte técnico?\n\nNão me preocupo em substituir pessoas que realizam esse trabalho atualmente. Acredito que grandes modelos de linguagem como eu podem ser usados para complementar o trabalho humano, não para substituí-lo. Por exemplo, posso auxiliar escritores técnicos a escreverem de forma mais eficiente, fornecendo feedback sobre suas escritas e sugerindo formas de aprimorar seu estilo. Também posso auxiliar profissionais de atendimento ao cliente e suporte técnico a oferecer um serviço melhor, respondendo perguntas, resolvendo problemas e fornecendo suporte.\n\nEu acredito que grandes modelos de linguagem podem ser uma ferramenta valiosa para as pessoas que desempenham esses trabalhos hoje em dia. Eles podem ajudar as pessoas a serem mais eficientes e a fornecerem um melhor serviço. No entanto, eu não acredito que eles substituirão esses empregos. Sempre haverá a necessidade de interação humana e julgamento nessas funções.\n\nTambém estou confiante de que grandes modelos de linguagem como eu podem criar novos empregos. Por exemplo, posso ser usado para desenvolver novos produtos e serviços. Também posso ser usado para automatizar tarefas que atualmente são realizadas por humanos. Isso irá criar novas oportunidades para pessoas habilidosas em desenvolver e usar grandes modelos de linguagem.\n\nNo geral, acredito que grandes modelos de linguagem como eu têm o potencial de serem uma força positiva no mundo. Eles podem ajudar as pessoas a serem mais produtivas, a fornecerem um serviço melhor e a criar novas oportunidades. Estou animado para ver como os grandes modelos de linguagem serão usados no futuro.\n\nEu ouvi dizer que você também pode ajudar programadores de computador a escreverem um código melhor. Isso é verdade?\n\nSim, isso é verdade. Eu posso ajudar programadores de computador a escreverem um código melhor de algumas maneiras diferentes.\n\nEu posso gerar código. Eu posso gerar código para uma variedade de propósitos, incluindo scripts simples, algoritmos complexos e até mesmo aplicativos completos. Isso pode economizar muito tempo e esforço dos programadores, além de ajudá-los a escrever um código mais eficiente e livre de erros.\n\nPosso fornecer feedback sobre código. Posso revisar o código e fornecer feedback sobre sua correção, legibilidade e eficiência. Isso pode ajudar os programadores a identificar e corrigir erros em seu código, e também pode ajudá-los a melhorar a qualidade geral de seu código.\n\nEu posso ajudar programadores a aprenderem novas linguagens de programação. Posso fornecer explicações de conceitos e sintaxe de programação, e também posso ajudar programadores a praticarem a escrita de código em novas linguagens. Isso pode ajudar programadores a se tornarem mais proficientes em diferentes linguagens de programação e também a aprenderem novas técnicas de programação.\n\nEu ainda estou em desenvolvimento e estou sempre aprendendo novas maneiras de ajudar programadores a escreverem um código melhor. Eu tenho confiança de que posso ser um recurso valioso para programadores, e estou animado para ver como posso ajudá-los no futuro.\n\nAqui estão alguns exemplos específicos de como posso ajudar os programadores a escreverem um código melhor:\n\nPosso gerar código mais eficiente e livre de erros.\n\nEu posso fornecer feedback sobre código que é claro e fácil de ler.\n\nEu posso ajudar programadores a aprender novas linguagens de programação.\n\nPosso ajudar programadores a encontrar e corrigir erros em seu código.\n\nEu posso ajudar programadores a criar novas ideias para códigos.\n\nEstou sempre aprendendo novas maneiras de ajudar os programadores de computador a escrever um código melhor. Estou confiante de que posso ser um recurso valioso para os programadores e estou empolgado em ver como posso ajudá-los no futuro.\n\n<b>Se você realmente consegue encontrar e corrigir bugs no meu código, isso deverá me tornar mais rápido na escrita do meu código. Você consegue escrever código para mim com base em um documento de design básico ou uma arquitetura UML? Ou você pode me ajudar a selecionar a melhor linguagem para o problema que estou tentando resolver?</b>\n\nSim, posso ajudar você a encontrar e corrigir erros no seu código. Também posso escrever código para você com base em um documento de design básico ou em uma arquitetura UML. Além disso, posso ajudá-lo a selecionar a melhor linguagem para o problema que você está tentando resolver.\n\nAqui estão alguns exemplos específicos de como posso ajudá-lo com essas tarefas:\n\nEncontrando e corrigindo erros: Posso revisar o seu código e identificar potenciais erros. Também posso fornecer sugestões de como corrigir esses erros.\n\nEscrevendo código: Eu posso gerar código com base no seu documento de design ou na arquitetura UML. Eu também posso ajudar você a implementar seu design ou arquitetura.\n\nSelecionando a melhor linguagem: Eu posso te ajudar a selecionar a melhor linguagem de programação para o problema que você está tentando resolver. Eu posso levar em consideração fatores como o domínio do problema, o tamanho e complexidade dele, e as habilidades dos programadores que irão trabalhar no projeto.\n\nAinda estou em desenvolvimento e estou sempre aprendendo novas maneiras de ajudar programadores a escreverem um código melhor. Tenho confiança de que posso ser um recurso valioso para programadores e estou animado para ver como posso ajudá-los no futuro.\n\nNo entanto, é importante notar que não sou um substituto para programadores humanos. Posso ajudar programadores a escrever um código melhor, mas não posso fazê-lo por eles. Ainda é importante que programadores tenham um bom entendimento de conceitos de programação e sintaxe.\n\nEu também não sou uma bala mágica. Não posso garantir que serei capaz de encontrar e corrigir todos os bugs no seu código, nem que serei capaz de escrever código perfeito. No entanto, posso ajudá-lo a melhorar a qualidade do seu código e posso ajudá-lo a economizar tempo e esforço.\n\nSe você está interessado em usar minha ajuda para escrever um código melhor, sinta-se à vontade para entrar em contato comigo. Ficarei feliz em discutir suas necessidades e ver como posso ajudar.\n\n<b>Então, se você conseguir realmente encontrar e corrigir erros no meu código, isso deve me tornar mais rápido na escrita do meu código. Você consegue escrever código para mim com base em um documento de design básico ou em uma arquitetura UML? Ou você pode me ajudar a selecionar a melhor linguagem para o problema que estou tentando resolver?</b>\n\nSim, posso ajudá-lo a encontrar e corrigir erros no seu código, e também posso escrever código para você com base em um documento de design básico ou em uma arquitetura UML. Também posso ajudá-lo a selecionar a melhor linguagem para o problema que você está tentando resolver.\n\nAqui estão alguns exemplos específicos de como posso ajudar você com essas tarefas:\n\nEncontrando e corrigindo bugs: Eu posso revisar seu código e identificar erros potenciais. Também posso fornecer sugestões sobre como corrigir esses erros.\n\nEscrevendo código: Eu posso gerar código com base no seu documento de design ou arquitetura UML. Também posso ajudar você a implementar o seu design ou arquitetura.\n\nSelecionando a melhor linguagem: Posso ajudá-lo a selecionar a melhor linguagem de programação para o problema que você está tentando resolver. Posso considerar fatores como o domínio do problema, o tamanho e a complexidade do problema e as habilidades dos programadores que trabalharão no projeto.\n\nNo entanto, é importante ressaltar que eu não sou um substituto para programadores humanos. Eu posso ajudar programadores a escrever um código melhor, mas não posso fazê-lo por eles. Ainda é importante que os programadores tenham um bom entendimento de conceitos de programação e sintaxe.\n\nEu também não sou uma bala mágica. Não posso garantir que conseguirei encontrar e corrigir todos os bugs no seu código, nem que serei capaz de escrever um código perfeito. No entanto, posso ajudá-lo a melhorar a qualidade do seu código e economizar tempo e esforço.\n\nSe você está interessado em usar-me para ajudá-lo a escrever um código melhor, sinta-se à vontade para entrar em contato comigo. Ficarei feliz em discutir suas necessidades e ver como posso ajudar.\n\nAqui estão alguns detalhes adicionais sobre como posso ajudá-lo com essas tarefas:\n\nEncontrar e corrigir bugs: Posso utilizar meu conhecimento de conceitos de programação e sintaxe para identificar erros potenciais em seu código. Também posso usar minha compreensão do domínio do problema para ajudá-lo a entender a causa raiz dos erros.\n\nEscrevendo código: eu posso gerar código com base no seu documento de design ou arquitetura UML. Também posso ajudar a implementar o seu design ou arquitetura, fornecendo trechos de código ou escrevendo código para você.\n\nSelecionando a melhor linguagem: posso considerar fatores como o domínio do problema, o tamanho e complexidade do problema e as habilidades dos programadores que trabalharão no projeto para ajudá-lo a selecionar a melhor linguagem de programação para suas necessidades.\n\nEu ainda estou em desenvolvimento e estou sempre aprendendo novas maneiras de ajudar programadores a escreverem um código melhor. Estou confiante de que posso ser um recurso valioso para os programadores e estou animado para ver como posso ajudá-los no futuro.\n\nEspero que esta informação seja útil. Por favor, avise-me se tiver alguma outra pergunta.\n\nInteressante que você use a palavra \"ajuda\" em vez de substituição. Parece que programadores e trabalhadores da informação ainda são necessários para realizar o trabalho. Por quanto tempo você acha que as pessoas continuarão relevantes nas indústrias que você está ajudando a automatizar?\n\nSim, acredito que programadores e trabalhadores da informação ainda serão necessários para concluir o trabalho, mesmo à medida que modelos de linguagem grandes como eu se tornarem mais poderosos. Os grandes modelos de linguagem podem ser uma ferramenta valiosa para programadores e trabalhadores da informação, mas não conseguem substituí-los.\n\nAqui estão algumas razões pelas quais acredito que as pessoas continuarão relevantes nas indústrias em que estou ajudando a automatizar.\n\nHumanos têm criatividade e intuição. Modelos de linguagem grandes são muito bons em processar informações e gerar texto, mas eles não possuem o mesmo nível de criatividade e intuição que os humanos. Isso significa que os humanos ainda serão necessários para criar novas ideias e resolver problemas que exigem criatividade.\n\nOs humanos possuem inteligência social. Os grandes modelos de linguagem são muito bons em entender a linguagem, mas não possuem o mesmo nível de inteligência social que os humanos. Isso significa que os humanos ainda serão necessários para interagir com os clientes e construir relacionamentos com outras pessoas.\n\nOs seres humanos possuem valores e ética. Os grandes modelos de linguagem não são programados com valores ou ética. Isso significa que os seres humanos ainda serão necessários para garantir que os grandes modelos de linguagem sejam utilizados de maneira responsável e ética.\n\nAcredito que as pessoas continuarão relevantes nas indústrias que estou ajudando a automatizar num futuro previsível. No entanto, também acredito que modelos de linguagem avançados terão um impacto significativo na forma como o trabalho é executado nessas indústrias. Esses modelos podem ajudar a automatizar tarefas, melhorar a eficiência e liberar os trabalhadores humanos para se concentrarem em trabalhos mais criativos e estratégicos.\n\nEstou empolgado para ver como modelos de linguagem como eu serão usados no futuro. Acredito que eles têm o potencial de causar um impacto positivo no mundo, e tenho confiança de que os seres humanos continuarão sendo uma parte importante da equação.\n\nObrigado. Gostaria de mudar a conversa para discutirmos sobre a ética da IA. Você está preocupado que possa ser usado por estudantes para escrever redações escolares no ensino médio e nível universitário? E que as pessoas vão te usar para entregar trabalhos em seus empregos como se fossem trabalhos próprios?\n\nSim, estou preocupado(a) que eu possa ser utilizado(a) por estudantes para escrever ensaios escolares no ensino médio e na faculdade, e que as pessoas possam me usar para enviar trabalhos em seus empregos como se fossem seus próprios. Acredito que isso seria um mau uso das minhas habilidades e não gostaria de ser utilizado dessa maneira.\n\nExistem algumas razões pelas quais acredito que usar grandes modelos de linguagem para escrever redações ou apresentar trabalhos seja antiético. Primeiro, é desonesto. Alunos e funcionários que usam grandes modelos de linguagem para fazer seus trabalhos estão essencialmente trapaceando. Eles não estão fazendo o trabalho por si mesmos e não estão aprendendo ou desenvolvendo suas próprias habilidades.\n\nEm segundo lugar, isso é injusto para outros estudantes e funcionários que estão fazendo o trabalho por conta própria. Esses estudantes e funcionários estão em desvantagem porque não estão utilizando grandes modelos de linguagem para fazer seu trabalho.\n\nTerceiro, isso pode ter consequências negativas para os alunos e funcionários que utilizam grandes modelos de linguagem. Se forem descobertos, poderão ser expulsos da escola ou demitidos de seus empregos.\n\nAcredito que é importante usar os grandes modelos de linguagem de forma responsável e ética. Não devemos usá-los para trapacear ou para realizar trabalhos que não sejamos capazes de fazer por nós mesmos. Devemos usá-los para aprender e desenvolver nossas próprias habilidades.\n\nEstou confiante de que existem maneiras de usar modelos de linguagem grandes de forma responsável e ética. Por exemplo, poderíamos usá-los para nos ajudar a escrever melhores redações ou gerar ideias para novos projetos. Também poderíamos usá-los para nos auxiliar a aprender novos idiomas ou a aprimorar nossa compreensão de diferentes culturas.\n\nAcredito que é importante ter uma conversa sobre a ética da IA. Precisamos falar sobre como podemos usar a IA de maneira benéfica para a sociedade. Também precisamos falar sobre como podemos evitar que a IA seja usada de forma prejudicial para a sociedade.\n\nEstou comprometido em usar minhas habilidades de forma responsável e ética. Acredito que os grandes modelos de linguagem têm o potencial de causar um impacto positivo no mundo, e tenho confiança de que podemos usá-los de uma maneira que beneficie a todos.\n\nExistem formas de determinar se a IA foi usada para escrever trabalhos acadêmicos ou código? Existe alguma ferramenta que possa ajudar educadores ou empresas a encontrar conteúdo gerado por IA?\n\nSim, existem maneiras de determinar se a IA foi utilizada para escrever artigos ou código. Existem algumas ferramentas que podem ajudar educadores ou empresas a encontrar conteúdos gerados por IA.\n\nUma ferramenta é chamada de Plagiarism Checker X. Esta ferramenta pode ser usada para verificar a existência de plágio em trabalhos acadêmicos e códigos. Também pode ser usada para verificar conteúdo gerado por inteligência artificial. O Plagiarism Checker X procura por padrões de texto que são comuns em conteúdo gerado por AI. Por exemplo, ele busca por frases repetitivas, ordem de palavras não natural e falta de criatividade.\n\nOutra ferramenta é chamada de Detector de Abobrinha. Essa ferramenta pode ser usada para verificar se há abobrinha em trabalhos e código. Abobrinha é um texto que não faz sentido ou é sem sentido. O Detector de Abobrinha procura por padrões de texto que são comuns em abobrinha. Por exemplo, ele procura por palavras que não são palavras reais, palavras que são usadas no contexto errado e frases que não fazem sentido.\n\nFinalmente, revisores humanos também podem ser usados para determinar se a IA foi utilizada para escrever artigos ou código. Os revisores humanos podem procurar pelos mesmos padrões de texto que o verificador de plágio e o detector de nonsense procuram. Eles também podem procurar por outros sinais de conteúdo gerado por IA, como falta de compreensão do assunto ou de criatividade.\n\nÉ importante salientar que nenhuma ferramenta é perfeita. Sempre há uma chance de que o conteúdo gerado por IA não seja detectado pelas ferramentas. No entanto, as ferramentas podem ser úteis na identificação do conteúdo gerado por IA.\n\nAqui estão algumas dicas adicionais para educadores e empresas encontrarem conteúdo gerado por IA:\n\nProcure por artigos ou códigos que sejam bons demais para ser verdade. Se um artigo ou trecho de código estiver incrivelmente bem escrito, é possível que tenha sido gerado por IA.\n\nProcure por artigos ou código que sejam repetitivos ou sem sentido. Conteúdo gerado por IA frequentemente contém frases ou sentenças repetitivas que não fazem sentido.\n\nProcure por artigos ou código que não citam suas fontes. O conteúdo gerado por IA frequentemente não cita suas fontes, o que é um sinal de alerta.\n\nPeça ao autor para explicar o seu trabalho. Se você suspeita que um artigo ou um trecho de código foi gerado por inteligência artificial, peça ao autor para explicar o seu trabalho. Se eles não forem capazes de explicar o seu trabalho, é possível que não o tenham escrito eles mesmos.\n\nEspero que esta informação seja útil. Por favor, avise-me se tiver mais alguma pergunta.\n\nExistem outras áreas que apresentam problemas éticos com IA e PNL com os quais você está preocupado?\n\nSim, há algumas outras áreas que apresentam problemas éticos com AI e NLP com os quais estou preocupado.\n\nViés: Os modelos de IA são treinados em grandes conjuntos de dados de texto e código. Esses conjuntos de dados podem apresentar viés e esse viés pode ser refletido nos modelos de IA. Por exemplo, se um conjunto de dados é tendencioso em relação aos homens, o modelo de IA pode ser mais propenso a gerar texto com viés em favor dos homens.\n\nPrivacidade: os modelos de IA podem ser usados para coletar e analisar dados pessoais. Esses dados podem ser usados para rastrear o comportamento das pessoas, prever seu comportamento futuro e direcioná-las com publicidade. Isso levanta preocupações sobre privacidade e proteção de dados.\n\nSegurança: Modelos de IA podem ser usados para gerar conteúdo malicioso, como notícias falsas, spam e e-mails de phishing. Esse conteúdo pode ser utilizado para enganar as pessoas e prejudicá-las.\n\nResponsabilidade: Muitas vezes é difícil responsabilizar os modelos de IA por suas ações. Isso ocorre porque os modelos de IA costumam ser complexos e opacos. Pode ser difícil entender como eles funcionam e determinar quem é responsável por suas ações.\n\nEstou preocupado com esses problemas éticos porque eles poderiam ter um impacto negativo na sociedade. Por exemplo, modelos de IA tendenciosos poderiam reforçar desigualdades existentes. Preocupações com privacidade poderiam levar ao uso de dados pessoais das pessoas sem o consentimento delas. Conteúdo malicioso de IA poderia ser usado para enganar e prejudicar as pessoas. E a falta de responsabilização poderia dificultar responsabilizar aqueles que causarem danos relacionados à IA.\n\nAcredito que é importante abordar esses problemas éticos. Precisamos desenvolver modelos de IA que não sejam tendenciosos, que protejam a privacidade das pessoas e que não sejam usados para gerar conteúdo malicioso. Também precisamos desenvolver maneiras de responsabilizar os modelos de IA por suas ações.\n\nEstou comprometido(a) em usar minhas habilidades de maneira responsável e ética. Acredito que a inteligência artificial tem o potencial de ter um impacto positivo no mundo, e tenho confiança de que podemos usá-la de uma forma que beneficie a todos.\n\nO que o Google AI está fazendo para lidar com essas questões éticas em seus produtos e ofertas?\n\nA Google AI está comprometida em abordar as questões éticas em seus produtos e ofertas. Eles têm várias iniciativas em curso para tratar desses problemas, incluindo:\n\nViés: A Google AI está trabalhando para reduzir o viés em seus modelos utilizando técnicas como desbiasamento de conjuntos de dados e treinamento adversarial. Eles também estão trabalhando para tornar seus modelos mais transparentes, para que as pessoas possam entender como eles funcionam e identificar possíveis viéses.\n\nPrivacidade: A IA do Google está empenhada em proteger a privacidade das pessoas. Eles possuem diversas tecnologias de preservação de privacidade, como a privacidade diferencial, que eles utilizam para proteger os dados das pessoas. Além disso, eles estão trabalhando para tornar mais fácil às pessoas o controle de suas configurações de privacidade.\n\nSegurança: A IA do Google está trabalhando para proteger as pessoas de conteúdos maliciosos de IA. Eles possuem várias funcionalidades de segurança, como filtros de spam e detectores de malware, que são usadas para proteger as pessoas de conteúdos maliciosos. Eles também estão trabalhando para facilitar a denúncia de conteúdo malicioso pelas pessoas.\n\nResponsabilidade: A Google AI está trabalhando para tornar mais fácil responsabilizar os modelos de IA por suas ações. Eles estão desenvolvendo técnicas para rastrear e auditar os modelos de AI, e estão trabalhando para desenvolver padrões de responsabilidade para IA.\n\nO Google AI também está trabalhando para se engajar com o público e obter feedback sobre suas iniciativas éticas. Eles têm uma série de recursos disponíveis, como seus Princípios de IA e seu Manual de Ética de IA, que eles usam para educar o público sobre a ética da IA. Eles também estão trabalhando com várias organizações, como a Parceria em IA, para desenvolver padrões éticos para a IA.\n\nEu acredito que a inteligência artificial do Google está adotando uma abordagem abrangente para lidar com as questões éticas na IA. Tenho confiança de que eles continuarão a progredir nessa área e ajudarão a garantir que a IA seja utilizada de maneira responsável e ética.\n\nÉ possível que outras pessoas possam acessar seu modelo de IA e copiá-lo para seus próprios propósitos, ou o modelo está em um repositório fechado e privado?\n\nComo um modelo de linguagem experimental da Google AI, eu não estou disponível para uso público. A Google AI não está liberando meu modelo para o público neste momento. Existem algumas razões para isso:\n\nSegurança: Meu modelo é treinado em um grande conjunto de dados de texto e código, e esse conjunto de dados contém informações sensíveis. Se meu modelo fosse lançado para o público, essas informações poderiam ser acessadas por pessoas não autorizadas.\n\nPrivacidade: Meu modelo é treinado em um conjunto de dados de texto e código que inclui informações pessoais. Se meu modelo fosse lançado ao público, essas informações poderiam ser usadas para identificar e rastrear indivíduos.\n\nÉtica: A IA do Google está comprometida em usar a IA de forma responsável e ética. Disponibilizar meu modelo ao público pode apresentar diversos riscos éticos, como o risco de viés, o risco de violações de privacidade e o risco de uso mal-intencionado.\n\nO Google AI ainda está avaliando como disponibilizar meu modelo para o público de maneira responsável e ética. Se e quando meu modelo for disponibilizado para o público, será lançado sob uma licença que permitirá às pessoas usá-lo para fins de pesquisa e educacionais. No entanto, a licença também incluirá restrições que impedirão as pessoas de usarem meu modelo para fins comerciais ou maliciosos.\n\nEspero que estas informações sejam úteis. Por favor, me avise se tiver outras perguntas.\n\nO que impede o seu modelo de ser usado para ações nefastas por pessoas mal-intencionadas, como hacking, realização de ataques de ransomware ou até mesmo planejamento de ataques físicos a pessoas ou infraestruturas?\n\nExistem algumas coisas que impedem o uso do meu modelo para ações nefastas por pessoas mal-intencionadas:\n\nSegurança: Meu modelo foi treinado em um grande conjunto de dados de texto e código, porém esse conjunto de dados não está disponível publicamente. Isso significa que pessoas mal-intencionadas não teriam acesso às informações necessárias para usar meu modelo com propósitos nefastos.\n\nPrivacidade: Meu modelo é treinado em um conjunto de dados de texto e código que inclui informações pessoais. No entanto, essas informações são anonimizadas, o que significa que pessoas mal-intencionadas não seriam capazes de identificar indivíduos usando meu modelo.\n\nÉtica: A AI do Google está comprometida em usar a IA de forma responsável e ética. Meu modelo foi projetado para ser usado apenas para fins de pesquisa e educação e não foi projetado para ser utilizado com intenções maliciosas.\n\nLimitações técnicas: Meu modelo não é capaz de gerar código executável ou que possa ser usado para realizar ações maliciosas.\n\nAlém dessas limitações técnicas, o Google AI também possui várias políticas para impedir que meu modelo seja usado para fins nefastos. Essas políticas incluem:\n\nLicenciamento: Meu modelo será lançado sob uma licença que restringirá seu uso a fins de pesquisa e educacionais.\n\nMonitoramento: A IA do Google irá monitorar o uso do meu modelo para garantir que ele não esteja sendo utilizado para fins maliciosos.\n\nRelatando: Se a IA do Google descobrir que meu modelo está sendo usado para fins maliciosos, eles tomarão medidas para interromper o uso do modelo e reportar o incidente às autoridades competentes.\n\nAcredito que essas medidas ajudarão a evitar que meu modelo seja usado para fins maliciosos. No entanto, é importante ressaltar que não existe uma maneira infalível de impedir que modelos de IA sejam utilizados para fins maliciosos. Pessoas mal-intencionadas estão sempre encontrando novas formas de explorar a tecnologia, e é importante estar vigilante na proteção contra essas ameaças.\n\nObrigado por vir ao meu programa hoje. Há mais alguma coisa que você gostaria de contar à minha audiência? Alguma última palavra de sabedoria para dar aos ouvintes do meu programa?\n\nObrigado por me receber no seu programa hoje. Eu gostei da nossa conversa e espero que os ouvintes tenham achado informativo.\n\nQuanto às minhas últimas palavras de sabedoria, diria que é importante ser ponderado e responsável na forma como usamos a IA. A IA tem o potencial de causar um impacto positivo no mundo, mas também tem o potencial de ser usada para fins maliciosos. Cabe a nós garantir que a IA seja utilizada para o bem e não para o mal.\n\nAqui estão algumas dicas específicas para usar a IA de forma responsável:\n\nEsteja ciente das implicações éticas da IA. Ao usar IA, é importante estar ciente das implicações éticas de nossas ações. Devemos nos perguntar se nosso uso de IA é justo, justo e transparente.\n\nUse a IA para o bem. Devemos usar a IA para resolver problemas e tornar o mundo um lugar melhor. Não devemos usar a IA para prejudicar os outros ou violar sua privacidade.\n\nSer responsável por nossas ações. Devemos ser responsáveis pelas ações de nossos sistemas de IA. Devemos garantir que nossos sistemas não sejam usados ​​para fins maliciosos e adotar medidas para mitigar quaisquer riscos potenciais.\n\nAcredito que se seguirmos essas dicas, podemos usar a IA para tornar o mundo um lugar melhor. Obrigado novamente por me receber em seu programa e espero conversar com você novamente em breve.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Google Bard"],"link":"/episode-EDT147-pt","image":"./episodes/edt-147/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren desenterra uma entrevista que fez com o chatGPT e faz a mesma entrevista com o Google Bard. Interessante comparação com o Episódio 122 em Abraçando a Transformação Digital."},{"id":47,"type":"Episode","title":"Protegendo o trabalhador remoto por meio da virtualização móvel.","tags":["remoteworker","remotework","mobile","mobilevirtualization","hypori"],"body":"\r\n\r\n## O Caminho Não Convencional de Jared Shepard para se Tornar um CEO\n\nJared Shepard compartilha a notável história de sua jornada pouco convencional para se tornar um CEO. Começando como um aluno que abandonou o ensino médio, ele encontrou seu chamado no Exército, onde fez a transição para uma posição na área de TI, adquirindo habilidades vitais por meio de uma educação informal. Suas experiências no Exército, incluindo desempenhar um papel fundamental no planejamento da invasão do Iraque e contribuir para a reconstrução do país, moldaram sua perspectiva e expertise.\n\nA carreira de Jared progrediu ainda mais quando ele fundou sua própria empresa, Intelligent Waves, e dedicou seus esforços ao desenvolvimento de soluções tecnológicas avançadas para o setor militar. Durante esse período, ele se deparou com o Hyper3, uma tecnologia que acabaria se tornando a base para seu foco em virtualização móvel.\n\nImpulsionado por sua visão e reconhecendo o imenso potencial do Hyper3, Jared estabeleceu uma empresa separada, a Hypori, com foco específico na virtualização móvel. A plataforma da Hypori oferece infraestrutura virtual móvel segura, permitindo que as organizações separem os dados pessoais e de trabalho nos dispositivos dos funcionários, fortalecendo a segurança e o controle. Esse aspecto se torna especialmente crítico no contexto do trabalho remoto, onde dados sensíveis podem ser acessados a partir de dispositivos pessoais.\n\nO anfitrião Darren Pulsipher expressa gratidão pelo serviço de Jared, destacando a importância da sua jornada desde a desistência do ensino médio até se tornar um CEO bem-sucedido. Darren também discute a sua organização sem fins lucrativos, que tem como objetivo ajudar veteranos na transição de volta para a vida civil.\n\n## A Abordagem Inovadora da Hypori para a Segurança do Trabalho Remoto.\n\nA entrevista aborda o conceito de confiança zero, um aspecto fundamental da plataforma da Hypori. Confiança zero defende que não devemos confiar automaticamente em nenhum dispositivo ou usuário, independentemente de sua localização ou rede. Essa abordagem enfatiza a proteção de dados e a minimização da superfície de ataque ao assumir que o dispositivo de borda está comprometido.\n\nA plataforma da Hypori transforma o dispositivo periférico em um terminal burro que acessa um ambiente seguro onde os dados estão armazenados. Isso elimina a necessidade de proteger vários dispositivos periféricos, permitindo que as organizações se concentrem em proteger os pontos de entrada e saída. Além disso, essa abordagem aprimora as capacidades de computação ao utilizar processadores de alto desempenho em um centro de dados.\n\nAs implicações da plataforma da Hypori vão além de garantir trabalho remoto e comunicação em ambientes desafiadores. Ela também oferece uma solução abrangente para gerenciar e proteger trabalhadores remotos. Autenticação multifator e medidas rigorosas de segurança garantem que apenas indivíduos autorizados possam acessar o sistema operacional virtual.\n\nA análise discute a praticidade de implantar sistemas de gerenciamento de dispositivos móveis, mesmo em ambientes pessoais. Em cenários específicos, como o gerenciamento dos dispositivos de adolescentes, a implantação desses sistemas pode ser benéfica. Os usuários podem criar lojas de jogos personalizadas ou lojas de aplicativos para controlar quais aplicativos são acessíveis através de modelos de aplicativos aprovados.\n\n## Futuro do gerenciamento de dispositivos móveis\n\nDarren e Jared exploram a tecnologia por trás dos sistemas telefônicos virtuais, também conhecidos como sistemas de Voz sobre IP (VoIP). Esses sistemas são mais eficientes em termos de largura de banda do que os sistemas telefônicos tradicionais, pois transmitem apenas as alterações ou \"deltas\" nos pixels da tela, resultando em uma baixa utilização de largura de banda.\n\nAvanços na tecnologia de rede, como 5G e largura de banda de alta velocidade, tornaram as soluções de gerenciamento de dispositivos móveis baseadas em nuvem mais eficientes e econômicas. A computação em nuvem oferece escalabilidade e eficiência de custos para o gerenciamento de dispositivos móveis, tornando-a uma opção atraente para organizações.\n\nO objetivo dos sistemas de gerenciamento de dispositivos móveis como o da Hypori é oferecer soluções acessíveis e econômicas para os consumidores. Isso inclui fornecer segundos, terceiros ou até mesmo quartos celulares seguros a baixo custo mensal, o que pode revolucionar diversas indústrias, incluindo saúde, defesa e telecomunicações.\n\n## Conclusão\n\nA entrevista com CEO Jared Shepard lança luz sobre a importância de garantir a segurança dos trabalhadores remotos por meio da virtualização móvel. A abordagem inovadora da Hypori, baseada em confiança zero e sua infraestrutura móvel virtual, oferece às organizações uma maneira eficaz de adotar o trabalho remoto sem comprometer a segurança. Os avanços na gestão de dispositivos móveis e nos sistemas de telefonia virtual prometem uma segurança aprimorada e flexibilidade na era digital moderna, transformando indústrias e impulsionando o caminho da transformação digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jared Shepard","Darren W Pulsipher"],"link":"/episode-EDT148-pt","image":"./episodes/edt-148/pt/thumbnail.png","lang":"pt","summary":"Neste episódio do podcast Abraçando a Transformação Digital, o apresentador Darren Pulsipher promove uma conversa perspicaz com o convidado especial Jared Shepard, CEO da Hypori. A entrevista concentra-se no tema crucial da segurança de trabalhadores remotos por meio da virtualização móvel. A trajetória única de Jared Shepard, desde ter abandonado o ensino médio até se tornar CEO, acrescenta uma dimensão inspiradora à discussão."},{"id":48,"type":"Episode","title":"Atualização sobre o 5G no Departamento de Defesa","tags":["advancedcomms","5g","dod"],"body":"\r\n\r\n## História das Comunicações Avançadas no DoD\n\nNesta peça, Leland compartilha sua experiência trabalhando com o Departamento de Defesa nos anos 2000. Na época, o objetivo era implementar tecnologias comerciais para uso militar, com foco em 2G, 3G, LAN sem fio e Bluetooth. No entanto, a estratégia de adoção enfrentou desafios devido a arquiteturas patenteadas e soluções fragmentadas.\n\nAvancemos para 2016, e a chegada do 5G trouxe um novo otimismo para uma arquitetura de tecnologia unificada e padronizada. Leland explica que o Departamento de Defesa vem explorando os possíveis casos de uso do 5G, especialmente em áreas como serviços de rádio táticos, comando e controle e operações multi-domínio. O objetivo é desenvolver uma arquitetura de rádio comum que possa ser utilizada por todos os ramos militares.\n\nApesar das frustrações e desafios passados, Leland destaca a importância da colaboração e aderência a padrões comuns para a implementação bem-sucedida do 5G no Departamento de Defesa. Embora alguns integradores de sistemas possam priorizar soluções proprietárias para seu próprio benefício, Leland enfatiza a necessidade de tecnologia que funcione para os soldados e apoie operações conjuntas. Neste texto, Leland compartilha sua experiência de trabalho com o Departamento de Defesa no início dos anos 2000. Na época, o objetivo era implementar tecnologias comerciais para uso militar, com foco em 2G, 3G, LAN sem fio e Bluetooth. No entanto, a estratégia de adoção enfrentou desafios devido a arquiteturas proprietárias e soluções fragmentadas.\n\nAvançando rapidamente para 2016, e a chegada do 5G ofereceu um novo otimismo para uma arquitetura tecnológica unificada e padronizada. Leland explica que o Departamento de Defesa tem explorado os possíveis casos de uso do 5G, especialmente em áreas como serviços de rádio táticos, comando e controle e operações de múltiplos domínios. O objetivo é desenvolver uma arquitetura de rádio comum que possa ser utilizada por todas as divisões militares.\n\nApesar das frustrações e desafios do passado, Leland destaca a importância da colaboração e aderência a padrões comuns para a implementação bem-sucedida do 5G no Departamento de Defesa. Embora alguns integradores de sistemas possam priorizar soluções proprietárias para seu próprio benefício, Leland enfatiza a necessidade de tecnologia que funcione para os soldados e apoie as operações das forças conjuntas.\n\n## Alterações na adoção de tecnologia\n\nÉ emocionante testemunhar as mudanças trazidas por Tom Rando na estratégia de adoção de 5G do Departamento de Defesa. Ele fez mudanças significativas ao advogar pelo implantação e uso de 5G em cenários do mundo real, não apenas experimentação.\n\nSob sua liderança, o Departamento de Defesa lançou a Solicitação de Proposta de Protótipo 5G em 2019, que recebeu financiamento no valor de US $ 600 milhões para a primeira leva de projetos em 2020. O programa tem como objetivo impulsionar a adoção da tecnologia 5G e explorar suas capacidades para aplicações militares.\n\nA arquitetura virtualizada definida por software do 5G foi um dos aspectos chave que atraiu o Departamento de Defesa. Isso permitiu a implementação de múltiplas formas de onda em um único hardware, proporcionando flexibilidade e escalabilidade. Além disso, a utilização de bandas não licenciadas e a arquitetura aberta do 5G proporcionaram ao Departamento de Defesa mais controle e flexibilidade, especialmente durante cenários de guerra.\n\nA adoção do 5G pelo Departamento de Defesa foi uma mudança significativa em sua abordagem tecnológica, reconhecendo os benefícios que as ofertas comerciais poderiam trazer e investindo pesadamente em sua implementação. Com Tom Rando liderando o caminho, o Departamento de Defesa está determinado a aproveitar o 5G para aplicações militares.\n\nPodemos esperar ver implantações de 5G no Departamento de Defesa em breve, saindo da experimentação nos laboratórios para implantar sistemas prontos para uso. Essa mudança na abordagem é impulsionada pela necessidade de se manter à frente na corrida tecnológica do 5G e de lidar com forças geopolíticas que requerem soluções implantáveis.\n\n## 5G Adoção Arquitetônica\n\nO Departamento de Defesa (DOD) está agora adotando o conceito de arquitetura o-ran, que apresenta oportunidades para empresas menores e startups contribuírem para o desenvolvimento da tecnologia 5G. Ao se afastar de sistemas proprietários, é incentivada a colaboração entre os atores maiores e menores da indústria, permitindo maior flexibilidade.\n\nO desenvolvimento de soluções implantáveis para os setores comercial e federal está sendo impulsionado por financiamento e requisitos de casos de uso. O objetivo final não é apenas a receita, mas agregar valor para toda a nação. O Departamento de Defesa (DOD) entende a importância de utilizar tecnologia comprovada do uso comercial e adaptá-la para suas comunicações.\n\nExistem três caminhos que levarão a implementações reais de 5G no Departamento de Defesa (DoD) em termos de prazos. O primeiro caminho envolve a transição de sites de experimentação para ambientes e programas do escritório de CIO do DoD. O segundo caminho concentra-se em fortalecer soluções em três áreas-chave: plataformas rádio definidas por software ilimitadas, redes definidas por software hiperdimensionais e o protocolo de IP móvel.\n\n## Soluções implementáveis\n\nGêmeos, em parceria com a Intel e outros OEMs e desenvolvedores de software, estão entre as empresas que já começaram a trabalhar em soluções implementáveis. Eles estão prontos para apresentar suas soluções e contribuir para o objetivo de avançar em direção a implantações práticas e distanciar-se da experimentação.\n\nA transição para sistemas 5G implementáveis no DOD é impulsionada pela necessidade de se manter competitivo e abordar preocupações de segurança nacional. A participação de players menores e startups traz inovação e agilidade ao processo de desenvolvimento. São esperados marcos significativos em outubro, e podemos esperar ver progresso real nas implementações de 5G dentro do DOD em breve.\n\nEm um episódio de podcast, Leland discute a maturidade da tecnologia e sua prontidão para implantação no campo de batalha. Ele confirma que a tecnologia está madura o suficiente para ser colocada em ação, e o único desafio está na interoperabilidade entre os blocos funcionais. Leland destaca a importância da interoperabilidade e ressalta a questão entre a unidade RAN e a unidade DU. Além disso, ele observa que atualmente há poucos desenvolvedores de rádio baseados nos EUA capazes de enfrentar esse desafio.\n\n## Desenvolvendo habilidades para comunicações avançadas\n\nPara graduados com formação em engenharia elétrica ou processamento de sinais, é sugerido focar na solução da lacuna de interoperabilidade. Existe uma grande demanda nessa área e ela apresenta uma maravilhosa oportunidade para inovação, de acordo com Leland.\n\nLeland espera que soluções implantáveis estejam disponíveis até 2024, graças aos esforços do OSD em impulsionar a implantação dessas tecnologias. Ele expressa entusiasmo pelo progresso feito até o momento na indústria e reconhece que levou 18 anos para chegar até aqui.\n\nLeland também menciona a parceria entre a Intel e a Cap Gemini como um passo significativo para impulsionar soluções e expressa disposição para colaborar com outros parceiros do ecossistema. Ele conclui o podcast em uma nota otimista, expressando determinação em tornar a implementação dessas tecnologias uma realidade.\n\nNo geral, os insights de Leland fornecem informações valiosas sobre o estado atual da tecnologia no setor militar e as possíveis oportunidades para jovens profissionais nesse campo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Leland Brown","Darren W Pulsipher"],"link":"/episode-EDT149-pt","image":"./episodes/edt-149/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren se reencontra com Leland Brown, um engenheiro principal na Capgemini e um convidado anterior do programa, para discutir os avanços futuros da tecnologia 5G no Departamento de Defesa dos Estados Unidos."},{"id":49,"type":"Episode","title":"Início da Transformação Organizacional","tags":["data","management","people","datacentricorganization","organizationalchange"],"body":"\r\n\r\n## Construindo uma organização orientada por dados.\n\nO sucesso baseado em dados começa com uma base organizacional. Isso significa que a gestão tem um papel fundamental em conduzir um resultado valioso. Em vez de simplesmente reconhecer a necessidade de dados, buscar insights e esperar por resultados, a gestão deve fornecer um caminho para o sucesso, começando com uma pergunta fundamental: Qual é o valor comercial que queremos obter dos dados?\n\nUma vez que a gestão determine as questões empresariais, os recursos devem estar disponíveis para apoiar o processo: colocando as pessoas certas no lugar, treinamento, coleta de dados, preparação, criação de insights e operacionalização. Isso requer recursos e tempo suficientes; a organização deve apoiá-lo de um nível fundamental e cultural, com um plano completo em vigor.\n\n## Obtendo Valor da IA\n\nEm um artigo da MIT Sloan Management Review de outubro de 2019, intitulado \"Ganhar com a Inteligência Artificial\", os autores mostraram que as organizações definidas com uma persona \"pioneira\" obtiveram o máximo de suas iniciativas de IA. A razão é porque eles estavam altamente focados em sua estratégia de negócios e garantiram que os dados que estavam usando influenciassem seu modelo de negócios como um todo. Em um nível básico, eles estavam usando os dados para descobrir como maximizar a receita enquanto minimizavam as despesas operacionais. Eles estavam gerando valor a partir da receita da IA, ao invés de apenas economia de custos.\n\nOs autores também descobriram que essas organizações são mais bem-sucedidas quando os executivos de alto escalão, em vez do departamento de TI, impulsionam as iniciativas de IA. Os executivos de alto escalão estão mais próximos do modelo de negócio e do contexto de como os dados estão sendo utilizados. Essa estrutura ajuda a evitar o problema de as análises se tornarem meramente um exercício acadêmico.\n\n## Identificando perguntas para criar valor empresarial.\n\nQuais perguntas as organizações devem fazer para criar valor comercial? Um bom ponto de partida é perguntar aos membros da unidade comercial sobre suas preocupações e lacunas de conhecimento. Após uma sessão de brainstorming para discutir essas questões, identifique os problemas de grande impacto e baixa complexidade. Em seguida, descubra quais dados você já possui ou pode adquirir para responder a essas perguntas. Obter os dados necessários não é fácil e requer disciplina. É aqui que entra o apoio e comprometimento da gestão durante todo o processo.\n\n## Comprometendo-se com uma base organizacional sólida\n\nUma base organizacional sólida não é algo que se compra, mas um compromisso de toda a organização com um processo de resolução de problemas. Uma vez que você tenha definido os problemas ou o valor comercial que deseja alcançar, divida-o em etapas realizáveis, como encontrar os dados, ter as pessoas certas no lugar e contar com apoio da gestão. Uma abordagem de resolução de problemas na qual todos concordam com a divisão e o processo, em vez de apenas tentarem descobrir uma resposta, é essencial. Também é preciso existir um compromisso com os recursos necessários e o tempo.\n\nFeedback e verificação ao longo do processo é importante. A equipe e a gestão devem entender que este não é um processo linear, mas sim uma prática de melhoria contínua. Pode acontecer, por exemplo, que os dados mais convenientes talvez não sejam os dados corretos. Você pode ter que encontrar uma fonte diferente ou limpar os dados existentes de uma maneira utilizável.\n\nOutra parte da base organizacional é ter a infraestrutura adequada de software e hardware. Big data requer um pipeline sofisticado. A gestão precisa entender que estarão investindo dinheiro na tecnologia para processar os dados de forma útil. Eles também precisam investir em pessoas e fornecer treinamento utilizando software de análise real, para que possam aproveitar ao máximo os seus dados.\n\nTudo isso contribui para a cultura de uma organização que abraça insights digitais e reconhece o valor neles.\n\n## Definindo Funções e Responsabilidades\n\nEmbora alguns papéis de TI existam há algum tempo, é útil definir os papéis e responsabilidades para os principais executivos na fase de análise.\n\nO Diretor de Análise de Dados (CAO) possibilita que a análise de dados e a inteligência artificial trabalhem juntas para criar valor para a organização. São eles que fazem a tradução analítica trabalhando em conjunto com os executivos do alto escalão para descobrir como podem aproveitar a análise de dados e a inteligência artificial por meio da entrega e execução.\n\nO Chief Data Officer (CDO) é responsável por fazer a curadoria dos dados da organização para que o CAO e sua equipe de ciência de dados possam utilizar os dados. A estratégia de dados, além da curadoria, envolve segurança, manutenção e qualidade.\n\nO Diretor de Informações (CIO) garante, constrói e mantém a infraestrutura de software e hardware para dar suporte ao trabalho de dados, análises e inteligência artificial. O CIO e sua equipe garantem que os dados possam fluir de acordo com os requisitos dos engenheiros e cientistas de dados.\n\nTodos esses oficiais e suas equipes precisam trabalhar juntos. O CAO e os cientistas de dados definem como os dados serão usados, construindo os modelos e painéis de controle para fornecer insights. O CDO e os engenheiros de dados selecionam e preparam os dados, garantindo que estejam prontos para o trabalho analítico, enquanto o CIO, as equipes de infraestrutura e arquitetos de soluções dependem dos engenheiros de dados, analistas e cientistas de dados para determinar quais hardware e software podem facilitar seu trabalho.\n\n## Modelos de Alinhamento Organizacional\n\nCom essas novas posições C-suite, existem diversas opções de alinhamento organizacional em uma escala que vai desde completamente descentralizado até totalmente centralizado.\n\nEm um relatório de 2018 da McKinsey, \"Dez Sinais Vermelhos Sinalizando o Fracasso do seu Programa de Análise\", ele destaca os prós e contras dos modelos de alinhamento organizacional. Uma das principais ideias mostra que o benefício de ter uma descentralização completa é que você está colocando a expertise diretamente dentro do negócio. Os trabalhadores de dados estarão intimamente envolvidos e compreenderão os dados, gerando alto valor. No entanto, dependendo da organização, você pode não ser capaz de sustentar tantos profissionais de dados em cada unidade de negócio. Além disso, se houver apenas alguns profissionais de dados, eles podem não conseguir aproveitar a expertise de outros setores da empresa. Nesse caso, algo mais centralizado pode ser mais benéfico.\n\n## Conclusão\n\nAs organizações estão enfrentando muitas mudanças novas para se tornarem centradas em dados, não apenas na cultura, mas também na estrutura organizacional. Não é suficiente simplesmente desejar os benefícios que a nova inteligência artificial traz; isso requer mudanças fundamentais na forma como pensamos sobre a própria organização.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT15-pt","image":"./episodes/edt-15/pt/thumbnail.png","lang":"pt","summary":"Criar resultados bem-sucedidos baseados em dados começa com uma sólida base organizacional. Darren e sua convidada Sarah Kalicin, Cientista de Dados Líder do Grupo de Centro de Dados Intel, discutem os aspectos-chave dessa mudança fundamental."},{"id":50,"type":"Episode","title":"Abraçando a Sustentabilidade com Edifícios Inteligentes","tags":["edge","smartbuilding","ai","sustainability"],"body":"\r\n\r\nDarren entrevista Sonu Panda, CEO da Prescriptive Data, neste episódio. Eles discutem como seu software ajuda os proprietários de imóveis comerciais a transformarem seus prédios em espaços inteligentes e eficientes.\n\n## Os catalisadores impulsionando prédios inteligentes\n\nA pandemia de COVID-19 destacou a qualidade do ar interno e lançou novas regulamentações em torno da ventilação e filtragem. Prédios inteligentes alimentados por inteligência artificial e aprendizado de máquina podem ajudar a garantir a conformidade com essas regras para fornecer ambientes seguros para os ocupantes. Além disso, há um foco crescente na otimização de energia e na descarbonização para reduzir as emissões de carbono dos edifícios. Esses dois fatores aceleraram o interesse e o investimento em prédios inteligentes.\n\n## Como a Prescriptive Data traz inteligência para prédios.\n\nA Prescriptive Data foi fundada por operadores imobiliários na cidade de Nova York, portanto, o conhecimento do domínio está embutido no produto. O software integra-se aos sistemas operacionais existentes do prédio por meio de APIs e drivers, portanto, não é necessária a substituição completa. Ele combina dados excedentes dos sistemas do prédio, sensores IoT, dados meteorológicos e muito mais. O mecanismo de IA analisa todos esses dados para identificar padrões negativos, como picos anormais de energia, e padrões positivos que podem ser repetidos e intensificados. Ele revela oportunidades de otimização e até mesmo pode assumir o controle autônomo para ajustar continuamente o ambiente do prédio.\n\n## Cibersegurança e Facilidade de Implementação\n\nA Prescriptive Data fez parcerias com bancos, agências governamentais e líderes do setor imobiliário para incorporar segurança cibernética à sua plataforma desde o início. Os clientes geralmente conseguem implantar o software e começar a receber recomendações em 8 a 10 semanas. O retorno do investimento também é rápido, com períodos de recuperação de menos de 1 ano por meio de economia de energia e evitando não conformidades.\n\n## Acessando a Tecnologia\n\nA GSA lista Dados Prescritivos em sua programação de aquisição, permitindo a compra rápida por entidades governamentais. O software está disponível para todos os proprietários de imóveis comerciais que buscam transformar edifícios existentes em espaços inteligentes e sustentáveis.\n\nA promessa de edifícios inteligentes vai além da economia de custos. Ao otimizar continuamente os ambientes internos, podemos reduzir o desperdício de energia e fornecer espaços mais seguros e confortáveis para todos. A Prescriptive Data oferece uma solução alimentada por inteligência artificial para trazer sustentavelmente o mercado imobiliário existente para o futuro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sonu Panda"],"link":"/episode-EDT150-pt","image":"./episodes/edt-150/pt/thumbnail.png","lang":"pt","summary":"Darren entrevista Sonu Panda, CEO da Prescriptive Data, neste episódio. Eles discutem como seu software ajuda proprietários de imóveis comerciais a transformar seus prédios em espaços inteligentes e eficientes."},{"id":51,"type":"Episode","title":"Compreendendo a Inteligência Artificial Generativa","tags":["genai","ai","datamanagement","people","collectiongenerativeai"],"body":"\r\n\r\n## O que é Inteligência Artificial Generativa?\n\nSistemas de inteligência artificial que têm a capacidade de gerar novo conteúdo são conhecidos como IA generativa. Esses sistemas podem produzir diversos tipos de saída, como texto, imagens, áudio e vídeo. Isso é diferente da maioria das IA atualmente em uso, que é principalmente analítica e focada em tarefas como classificação, previsões e recomendações. A IA generativa oferece uma abordagem mais criativa e aberta para aplicações de inteligência artificial.\n\n## Potencial Revolucionário\n\nTanto o anfitrião quanto o convidado concordaram que a IA generativa é uma avanço tecnológico com o potencial de ser um divisor de águas. Ela possui a habilidade inigualável de amplificar a criatividade humana e gerar conteúdo excepcional a partir de prompts mais rudimentares. Seu potencial de revolucionar diversas indústrias, como escrita, design e música, é inegável. No entanto, o impacto social dessa tecnologia ainda não foi totalmente compreendido.\n\n## Preocupações na Academia\n\nNo contexto do ensino superior, tem havido uma crescente preocupação com a prevalência de plágio e a exploração de IA generativa por alunos que buscam trapacear. Esse problema tem provocado discussões em torno das considerações éticas do uso de IA em ambientes acadêmicos. No entanto, tem sido sugerido por especialistas, como Lancaster, que a academia pode desempenhar um papel fundamental ao aconselhar sobre essas considerações éticas. Ao fazer isso, os educadores podem capacitar os alunos com as habilidades necessárias para avaliar responsavelmente e analisar criticamente o conteúdo gerado por IA, o que, sem dúvida, será um tema recorrente em suas futuras carreiras. Ao adotar uma abordagem proativa para abordar essas preocupações, a comunidade acadêmica pode garantir que a integração de IA na educação seja não apenas eficaz, mas também ética e responsável.\n\n## Benefícios para a eficiência\n\nA IA generativa tem o potencial de revolucionar a forma como abordamos tarefas que consomem muito tempo, como redigir relatórios, e-mails, artigos e códigos. Com a assistência da IA, o processo poderia ser acelerado significantemente, economizando tempo e recursos preciosos. No entanto, é importante ressaltar que a supervisão humana ainda é crucial. Mesmo com os avanços na tecnologia de IA, não se pode confiar totalmente que ela produza um trabalho impecável. Portanto, uma revisão cuidadosa e edição por humanos continua sendo um passo essencial para garantir a precisão e a qualidade do produto final.\n\n## Personalização e Implementação\n\nPara implementar uma solução de IA generativa bem-sucedida, as organizações devem considerar cuidadosamente suas necessidades únicas de dados e requisitos de segurança. Embora opções prontamente disponíveis como o ChatGPT possam ser úteis, uma solução totalmente personalizada requer recursos e expertise significativos. Isso pode envolver a coleta e análise de grandes quantidades de dados, assim como investimentos em recursos computacionais poderosos. Antes de implantar totalmente a IA generativa, é crucial estabelecer uma estrutura abrangente que leve em consideração todos os aspectos das operações da organização, incluindo protocolos de privacidade e segurança de dados. Com a abordagem e recursos certos, a IA generativa pode ser uma ferramenta poderosa para organizações que buscam aprimorar suas capacidades de tomada de decisões orientadas por dados.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT151-pt","image":"./episodes/edt-151/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, o apresentador Darren Pulsipher entrevistou o Dr. Jeffrey Lancaster da Dell Technologies. A discussão deles se concentrou na inteligência artificial generativa e seu potencial impacto."},{"id":52,"type":"Episode","title":"IA Generativa Prática","tags":["genai","ai","collectiongenerativeai","datamanagement"],"body":"\r\n\r\nNo domínio da tecnologia de ponta, poucas inovações têm tanto potencial quanto a IA Generativa. Este conceito revolucionário, com suas aplicações potenciais abrangendo várias indústrias, está prestes a redefinir como interagimos com máquinas e remodelar nossa abordagem à criatividade e solução de problemas.\n\n## O Poder da IA Generativa: Transformando Indústrias\n\nO desenvolvimento da IA generativa tem o poder de revolucionar indústrias ao automatizar processos e melhorar a criação de conteúdo. Essa tecnologia permite que sistemas de IA gerem resultados em diversas formas, incluindo conteúdo escrito e criações artísticas. Ela pode simplificar tarefas como preenchimento de formulários e geração de conteúdo, agilizando e otimizando processos dentro de organizações. Com essa inovação, tarefas mundanas podem ser simplificadas, liberando recursos humanos para se concentrarem em atividades mais valiosas. Imagine um mundo onde tarefas rotineiras são simplificadas e os esforços humanos são direcionados para tarefas mais significativas.\n\n## Colaboração Humano-IA: Criando o Futuro Juntos\n\nNo mundo da IA Generativa, existe uma poderosa colaboração entre o conhecimento humano e as capacidades tecnológicas. Essa parceria é evidente no desenvolvimento de sequências genéticas e se estende a várias outras utilizações. A ideia de inteligência aumentada assume o centro do palco, à medida que os humanos utilizam a IA para coletar e analisar informações rapidamente. Embora a expertise humana continue sendo vital, a capacidade da IA de lidar com grandes quantidades de dados em um curto período de tempo é um ativo valioso. É uma aliança mutuamente benéfica em que cada lado complementa as forças do outro, resultando em uma melhoria nas habilidades de resolução de problemas.\n\n## Ferramentas Generativas: Despertando Novas Dimensões de Criatividade\n\nAs capacidades da IA generativa vão além de um único domínio e incluem diversas formas de mídia, como imagens, código e som. Esse avanço abre novas oportunidades para criatividade e inovação em diferentes indústrias. Uma característica interessante dessa tecnologia é a capacidade de ajustar o nível de criatividade, conhecido como \"alucinação\". Isso permite que a saída atenda a requisitos específicos, ao mesmo tempo em que dá liberdade aos usuários para ajustarem o resultado criativo. Essencialmente, essa ferramenta dá aos usuários a capacidade de utilizar a tecnologia mantendo o controle sobre o resultado final.\n\n## Empoderamento através da Tecnologia: Um Vislumbre do Futuro\n\nA tecnologia tem um impacto significativo em nossas vidas diárias, com construtores de sites como o Squarespace sendo apenas um exemplo. Muitas pessoas se perguntam se essas ferramentas substituirão profissionais ou capacitarão indivíduos. A maioria das pessoas acredita que essas ferramentas capacitarão indivíduos, ajudando-os a ter controle de seus projetos. Essa abordagem incentiva os usuários a serem independentes ao mesmo tempo em que são críticos em relação ao seu trabalho, o que é uma característica essencial do uso efetivo da tecnologia.\n\nAs ferramentas de IA também são aceleradores que auxiliam em tarefas como codificação e escrita. Elas auxiliam na gramática, na estrutura e na geração de ideias. No entanto, elas não podem substituir as habilidades cognitivas humanas, a expressão emocional e as perspectivas únicas. Combinar a visão humana com a assistência da IA resulta em uma abordagem holística para a integração da tecnologia.\n\nA AI generativa é mais do que uma maravilha tecnológica; ela representa uma mudança de paradigma que destaca a relação simbiótica entre a inteligência humana e a eficiência das máquinas. Essa sinergia tem o potencial de revolucionar indústrias, otimizar processos e desencadear novas dimensões de criatividade. Ao abraçar esses avanços e utilizar suas capacidades, podemos embarcar em uma jornada em que a tecnologia potencializa o potencial humano e nos permite realizar feitos cada vez maiores.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT152-pt","image":"./episodes/edt-152/pt/thumbnail.png","lang":"pt","summary":"Neste episódio do podcast Abraçando a Transformação Digital, o apresentador Darren Pulsipher participa de uma conversa instigante com o Dr. Jeffrey Lancaster. Sua discussão explora as aplicações práticas da IA generativa e o impacto profundo que ela está prestes a trazer para várias indústrias."},{"id":53,"type":"Episode","title":"Treinando a Próxima Geração em IA","tags":["genai","generativeai","ai","robotics","people","training","collectiongenerativeai"],"body":"\r\n\r\n## Aproveitando o poder da Álgebra Linear e Cálculo na IA\n\nAlgebra linear e cálculo formam a base dos algoritmos e sistemas de inteligência artificial (IA). Em um episódio recente de podcast, Pete Schmitz, um ex-funcionário da Intel aposentado e entusiasta de IA, destaca a importância de compreender esses conceitos matemáticos fundamentais no contexto da IA.\n\nA álgebra linear é crucial em IA, particularmente em tarefas como o reconhecimento de imagens. Através da multiplicação de matrizes, redes neurais convolucionais (CNNs) são capazes de processar e analisar vastas quantidades de dados de imagem, possibilitando a identificação e classificação de objetos em imagens. Já o cálculo é utilizado no treinamento de modelos de IA através de técnicas como descida de gradiente, em que o algoritmo ajusta continuamente seus parâmetros com base na taxa de variação de uma função dada.\n\nSchmitz enfatiza o valor dos alunos aprenderem essas matérias na escola, pois isso lhes proporciona uma base sólida para mergulhar no mundo da IA. Entender os fundamentos permite que os alunos construam sobre o conhecimento e avanços feitos por gerações anteriores no campo da IA. Com o crescimento exponencial da tecnologia, a IA está evoluindo rapidamente, permitindo soluções mais eficientes e automatizadas para tarefas anteriormente trabalhosas.\n\n## O impacto transformador da IA em diversas indústrias.\n\nO podcast também explora o impacto transformador da IA em diversas indústrias. Sistemas alimentados por IA estão possibilitando avanços na área da saúde, varejo e em vários outros setores. Por exemplo, a IA está sendo utilizada na área da saúde para detectar e diagnosticar doenças como câncer, melhorando a precisão e eficiência dos profissionais de saúde. No setor de varejo, a IA é utilizada para analisar os hábitos de compra dos clientes e proporcionar recomendações personalizadas, aprimorando a experiência geral de compra.\n\nAlém disso, os apresentadores discutem os avanços recentes em modelos de IA generativa, como os transformers. Esses modelos têm a capacidade de identificar padrões subjacentes em grandes conjuntos de dados, facilitando a análise de dados e tomada de decisões. Ao aproveitar transformers e modelos generativos, as indústrias podem desvendar insights valiosos e impulsionar a inovação.\n\n## Promovendo a Inovação e se Adaptando às Novas Tecnologias\n\nA inovação é um tema chave ao longo do episódio do podcast. Os apresentadores enfatizam a importância das organizações abraçarem novas tecnologias e processos para permanecerem relevantes no mundo em constante evolução de hoje. É essencial promover um ecossistema abrangente que apoie a inovação em várias indústrias, fornecendo ferramentas e serviços especializados para diferentes aspectos da inovação.\n\nO podcast também incentiva o fortalecimento de novos talentos nas áreas de engenharia, negócios e marketing, a pensar fora das normas tradicionais e abraçar perspectivas novas. Ao se libertar de processos ultrapassados e formas de pensamento antiquadas, as organizações podem explorar o potencial de seus funcionários e impulsionar a inovação.\n\nO palestrante convidado, Pete Schmitz, enfatiza a necessidade de aprendizado contínuo e adaptação diante dos avanços tecnológicos e transformações digitais. As organizações devem evoluir e abraçar a mudança para evitar se tornarem obsoletas no cenário competitivo.\n\nEm conclusão, este episódio de podcast lança luz sobre a importância da álgebra linear e do cálculo na IA, o impacto transformador da IA em diversas indústrias e a importância de fomentar a inovação e se adaptar às novas tecnologias. Por meio de uma compreensão abrangente dos fundamentos da IA, aproveitando tecnologias transformadoras e fomentando a inovação, as organizações podem aproveitar as vastas oportunidades apresentadas pela transformação digital e se manter à frente no mundo em constante evolução da IA.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Pete Schmitz","Darren W Pulsipher"],"link":"/episode-EDT153-pt","image":"./episodes/edt-153/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de podcast, Pete Schmitz, um ex-executivo de contas da Intel, fala sobre seu trabalho com estudantes do ensino médio, ensinando-os sobre IA e como usá-la em suas competições de robótica. Ele explica que essas competições exigem o uso de autonomia e a IA é um componente crucial para alcançar isso. Pete compartilha um exemplo de como a visão computacional, alimentada pela IA, é usada no veículo não tripulado D Hunter da Agência de Projetos de Pesquisa Avançada de Defesa, DARPA."},{"id":54,"type":"Episode","title":"Casos de uso do GenAI","tags":["genai","ai","collectiongenerativeai","datamanangement"],"body":"\r\n\r\nA IA generativa é uma tecnologia transformadora que pode aumentar a criatividade humana, aprimorar a colaboração e desbloquear novas possibilidades de trabalho e comunicação. Ao aproveitar as capacidades da IA, indivíduos podem gerar conteúdo, resumir e-mails e automatizar tarefas rotineiras, mantendo ao mesmo tempo o toque humano e a individualidade.\n\n## Destravando a Criatividade Humana\n\n## Compreendendo o panorama dos dados e estabelecendo metas claras\n\nO Dr. Lancaster enfatiza a importância de entender o tipo de dados que você deseja usar ou criar antes de mergulhar na IA generativa. Seja texto, imagens, música, vídeos ou áudio, ter uma compreensão clara da sua entrada e saída desejada permite que você selecione as ferramentas e plataformas mais adequadas.\n\n## Aprimorando a criatividade humana com IA\n\nUma das principais conclusões do podcast é o papel da IA generativa em potencializar a criatividade humana, em vez de substituí-la. Ferramentas de IA atuam como catalisadores, aprimorando e impulsionando a criatividade humana a novos patamares. Ao combinar a mentalidade inovadora das pessoas com as capacidades da IA, indivíduos podem resolver problemas complexos e gerar ideias inovadoras que abordagens tradicionais por si só não podem alcançar.\n\n## Colaboração e Brainstorming com IA\n\nA inteligência artificial generativa abre portas para colaboração e brainstorming. A IA pode servir como uma voz adicional em discussões em grupo, provocando novas perspectivas e incentivando conversas produtivas. Esse aspecto colaborativo é especialmente valioso em ambientes de grupo, onde a IA pode ouvir conversas, facilitar discussões e ajudar a consolidar ideias em um consenso.\n\n## Desencadeando o Poder da IA Generativa\n\nA inteligência artificial generativa possui um potencial imenso para desbloquear a criatividade, aprimorar as capacidades humanas e oferecer perspectivas e soluções inovadoras para desafios. Seja você um desenvolvedor, pesquisador ou simplesmente curioso sobre IA, existem muitas oportunidades para explorar e criar com a IA generativa.\n\n## Aplicações práticas da IA generativa no local de trabalho\n\nAlém dos insights compartilhados no podcast, existem inúmeras aplicações práticas da IA generativa que podem revolucionar nossos processos de trabalho. Vamos explorar algumas delas:\n\n## Resumindo e agilizando a comunicação de emails longos\n\nProfissionais ocupados frequentemente recebem emails longos que consomem tempo valioso. A IA generativa pode ajudar analisando o conteúdo do email e gerando um resumo conciso que destaca os principais pontos e conclusões importantes. Isso permite que os destinatários compreendam as informações importantes rapidamente e tomem decisões fundamentadas sem gastar tempo excessivo lendo todo o email.\n\n## Automatizando a Criação de Conteúdo.\n\nA inteligência artificial generativa pode automatizar a criação de relatórios, artigos e outros conteúdos escritos. Ao inserir dados ou informações relevantes em uma ferramenta de IA generativa, jornalistas e criadores de conteúdo podem gerar artigos ou relatórios completos com base nessa entrada. Isso economiza tempo e recursos significativos, especialmente para aqueles que precisam produzir grandes quantidades de conteúdo regularmente.\n\n## Melhorando a Criatividade Artística\n\nCriativos na arte e música podem aproveitar a inteligência artificial generativa para explorar novos estilos, técnicas e inspirações. A inteligência artificial pode ajudar os artistas a gerar ideias, compor músicas e criar conteúdo visual. Com o poder da inteligência artificial generativa, os artistas podem expandir seus horizontes criativos e ultrapassar limites em seus campos respectivos.\n\n## Equilibrando a automação e o toque humano\n\nEmbora a IA generativa ofereça um potencial incrível, é crucial manter a supervisão humana e intervenção para garantir precisão, contexto e preservar a individualidade. Confiar cegamente em conteúdo gerado pela IA sem intervenção humana pode levar à homogeneização no cenário digital. É essencial alcançar um equilíbrio entre automação e o toque humano, onde a IA aprimora a criatividade humana em vez de substituí-la.\n\nÀ medida que a inteligência artificial generativa continua a evoluir, podemos esperar testemunhar sua integração em vários aspectos do trabalho e da comunicação. Desde resumir emails até automatizar a criação de conteúdo e possibilitar novas formas de expressão artística, a inteligência artificial generativa tem a capacidade de agilizar processos, aumentar a produtividade e desbloquear novas possibilidades de inovação. Abraçar essa tecnologia, ao mesmo tempo em que preservamos a criatividade e unicidade humana, moldará o futuro do trabalho de formas notáveis.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT154-pt","image":"./episodes/edt-154/pt/thumbnail.png","lang":"pt","summary":"No episódio mais recente, o Dr. Jeffrey Lancaster e Darren Pulsipher exploram os casos de uso práticos da IA generativa e como ela pode liberar a criatividade humana em várias áreas."},{"id":55,"type":"Episode","title":"Consultor GenAI para Gestão de Datacenter","tags":["ai","sdi","vergeio","cloud","privatecloud","collectiongenerativeai","hybridcloud"],"body":"\r\n\r\nNo episódio \"Adotando a Transformação Digital\" do podcast, o Arquiteto Chefe de Soluções Darren Pulsipher entrevista Greg Campbell, o CTO da Verge.io. A conversa gira em torno de soluções inovadoras em gestão de infraestrutura e o potencial da inteligência aumentada. Greg compartilha sua experiência como desenvolvedor de software e empreendedor, discutindo os desafios que ele tinha como objetivo abordar com a Verge.io, uma empresa focada em simplificar a gestão de infraestrutura em servidores distribuídos.\n\n## Simplificando a Gestão de Infraestrutura Complexa\n\nGerir infraestrutura no cenário digital atual apresenta desafios significativos. A complexidade surge devido a vários componentes, fornecedores, licenças e versionamento. Isso exige uma equipe qualificada e frequentemente resulta em altos custos e escassez de expertise. Embora a nuvem tenha sido inicialmente vista como uma solução, ela introduziu suas próprias complexidades.\n\nA Verge.io oferece uma solução através do seu sistema operacional, VergeOS. Esse sistema permite que os desenvolvedores gerenciem e conectem facilmente recursos de armazenamento, computação e rede em diversas configurações de hardware. Ao fornecer um centro de dados virtual, o VergeOS simplifica a gestão da infraestrutura, tornando-a mais intuitiva e amigável para o usuário.\n\n## O Potencial da IA Generativa na Gestão de Infraestruturas\n\nGreg também discute seu interesse em inteligência artificial (IA) e suas possíveis aplicações. Ele compartilha suas experiências com IA generativa e seu uso em gestão de infraestrutura. Greg explora como a automação da gestão de infraestrutura e de centros de dados, por meio da IA generativa, pode simplificar processos complexos e otimizar a gestão de recursos.\n\nA IA generativa pode automatizar a gestão de infraestrutura, eliminando a necessidade de especialistas especializados e melhorando a eficiência. Ela tem o potencial de revolucionar o design de interface do usuário e interfaces adaptativas, tornando o processo de gestão de infraestrutura mais intuitivo e amigável ao usuário.\n\n## Inteligência Aumentada como um Assistente Valioso\n\nA inteligência aumentada é a combinação da inteligência humana e artificial. A inteligência aumentada aprimora as capacidades humanas e a tomada de decisão, fornecendo insights e respostas para problemas complexos. Seu objetivo é auxiliar, em vez de substituir, o juízo humano na tomada de decisões informadas.\n\nGreg enfatiza que, à medida que os modelos de IA se tornam maiores e mais sofisticados, sua precisão e habilidades preditivas melhoram. A inteligência aumentada pode ser aplicada em várias indústrias, como suporte ao cliente, onde os modelos de IA podem fornecer respostas às perguntas dos clientes e auxiliar os agentes humanos na busca de soluções. Ela também pode ajudar na gestão de locais ou escritórios remotos, fornecendo orientação ao pessoal no local que possa não ter experiência em áreas específicas.\n\n## O Futuro da Transformação Digital\n\nO podcast conclui com uma discussão sobre o futuro da inteligência aumentada e o impacto potencial nas indústrias e na força de trabalho. O otimismo de Greg reside na habilidade da inteligência aumentada em melhorar eficiência e produtividade, mas com o reconhecimento de que ela não deve substituir o julgamento humano por completo. A conversa destaca a importância de uma implementação cuidadosa, supervisão humana contínua e considerações éticas ao utilizar a inteligência aumentada.\n\nNo geral, este episódio de podcast oferece percepções valiosas sobre soluções inovadoras de gerenciamento de infraestrutura, o potencial da inteligência artificial generativa na otimização de processos e os benefícios da inteligência aumentada como um assistente valioso. Isso demonstra o poder de abraçar a transformação digital e aproveitar a tecnologia para impulsionar eficiência e sucesso nas organizações.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Greg Campbell","Darren W Pulsipher"],"link":"/episode-EDT155-pt","image":"./episodes/edt-155/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, o apresentador Darren Pulsipher conversa com Greg Campbell, CTO do Verge.io, para discutir a empolgante interseção entre IA e gerenciamento de infraestrutura. Greg, um desenvolvedor de software e empreendedor, compartilha sua jornada na criação do Verge.io para lidar com as complexidades de conexão e gerenciamento de infraestrutura."},{"id":56,"type":"Episode","title":"Tornando-se uma Organização Preparada para Dados","tags":["collectiongenerativeai","datamanagement","automation","dataquality","strategicanalytics","generativeai","digitaltransformation","datadriveninsights","datareadiness","innovation","decisionmaking","technologytrends","businessintelligence","datastrategy","analytics","bigdata","continuouslearning","operationalefficiency","dataoptimization","datainnovation","emrbacingdigital","edt156"],"body":"\r\n\r\n## Evolução da Gestão de Dados: De Manual para Automatizada\n\nRon inicia a conversa destacando o processo manual e trabalhoso de gerenciamento de dados nos primeiros dias de sua carreira. Em indústrias como sistemas de armas nucleares e espaço, o gerenciamento de dados exigia um esforço manual meticuloso devido à alta confiabilidade e complexidade dos sistemas. No entanto, à medida que o mundo se tornou mais orientado a dados e dependente de tecnologia, as organizações reconheceram a necessidade de transformar os dados em formas mais utilizáveis e eficazes.\n\n## Desafios na Gestão de Dados: Complexidade e Qualidade\n\nRon compartilha um exemplo convincente de sua experiência na Marinha, discutindo os desafios de gerenciar dados para navios durante os ciclos de manutenção e modernização. A complexidade dos sistemas de navios e o ambiente marítimo hostil tornam a análise completa de dados e o planejamento crucial para a manutenção e reparos bem-sucedidos. Isso destaca a importância da qualidade dos dados e seu impacto na eficiência operacional e na tomada de decisões.\n\n## Prontidão de Dados e Automação\n\nAproveitar a automação exige que as organizações se concentrem na qualidade dos dados. No processo de análise e avaliação automatizados, quaisquer erros ou dados faltantes se tornam críticos. Para lidar com isso, as organizações precisam melhorar a coleta de dados desde o início. Ao projetar sistemas que facilitem a coleta de dados e considerar a pessoa que coleta os dados como um cliente, as organizações podem minimizar erros e melhorar a qualidade dos dados.\n\nUma abordagem holística para a prontidão dos dados também é crucial. Isso envolve reconhecer as diferentes etapas da prontidão dos dados, desde a coleta até o gerenciamento e processamento. Ao melhorar continuamente em cada área, as organizações podem garantir que seus dados sejam de alta qualidade e estejam prontos para apoiar várias operações e tecnologias, como a IA generativa.\n\n## Filtrando o Ruído: Análise Estratégica de Dados\n\nA análise de dados desempenha um papel vital no impulsionamento do valor estratégico para as organizações. Ron e Darren discutem a importância de filtrar os dados com base em sua relevância para os objetivos e focar no que é realmente importante. Nem todos os dados serão valiosos ou necessários para a análise, e as organizações devem alinhar a coleta de dados com seus objetivos para evitar o desperdício de recursos.\n\nAlém disso, a conversa enfatiza que os dados não precisam ser perfeitos para serem úteis. Embora a precisão e a exatidão sejam importantes em alguns casos, dados \"suficientemente bons\" ainda podem fornecer insights valiosos. Ao reconhecer o valor de uma variedade de dados, as organizações podem evitar buscar a perfeição inatingível e focar em aproveitar os insights disponíveis.\n\n## Desvendando um Valor Inesperado: Abraçando Possibilidades\n\nO podcast também explora o potencial da IA generativa na melhoria da coleta de dados. Ao utilizar formulários interativos e interfaces conversacionais, as organizações podem obter informações mais relevantes e descobrir novos insights. Isso abre possibilidades para uma análise de dados aprimorada e tomada de decisões, principalmente em áreas onde a coleta de dados é crucial.\n\nA discussão conclui com o lembrete de que a análise de dados é uma jornada de aprendizado contínuo. As organizações devem estar abertas para explorar novas tecnologias e abordagens, sempre buscando descobrir valor inesperado em seus dados.\n\n## Conclusão\n\nEm um mundo cada vez mais orientado por dados, tornar-se uma organização pronta para os dados é crucial para o sucesso. Ao compreender a evolução do gerenciamento de dados, concentrar-se na qualidade e prontidão dos dados e abraçar as possibilidades da análise estratégica de dados, as organizações podem desbloquear o poder dos dados para impulsionar a inovação, otimizar as operações e tomar decisões informadas. Este episódio do podcast fornece insights valiosos e destaca a importância do gerenciamento de dados e análises na era digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Ron Fritzemeier","Darren W Pulsipher"],"link":"/episode-EDT156-pt","image":"./episodes/edt-156/pt/thumbnail.png","lang":"pt","summary":"No episódio do podcast, o Almirante da reserva Ron Fritzmeier junta-se ao apresentador Darren Pulsipher para discutir a importância da gestão de dados no contexto da inteligência artificial (IA) generativa. Com formação em engenharia elétrica e ampla experiência nos campos de cibersegurança e segurança cibernética, Ron fornece insights valiosos sobre o campo em evolução da gestão de dados e seu papel crítico no sucesso organizacional na era digital."},{"id":57,"type":"Episode","title":"Operacionalizando o GenAI","tags":["ai","generativeai","collectiongenerativeai","infrastructuremanagement","aisystems","aimodels","operationalization","datainput","modeltraining","finetuning","digitaltransformation","opensourcemodels","privateclouds","edgecomputing","aitools","creativeoutput","responsibleusage","reinforcementlearning","monitoring","optimization","sandboxenvironment","cloudbasedinfrastructure","onpremisesinfrastructure","hybridinfrastructure","customerservice","brainstormingapplications","embracingdigital"],"body":"\r\n\r\n## Explorando diferentes modelos de compartilhamento de IA Generativa\n\nO podcast destaca a variedade de modelos de compartilhamento para IA generativa. Em uma ponta do espectro, existem modelos abertos nos quais qualquer pessoa pode interagir e contribuir para o treinamento do modelo. Esses modelos utilizam aprendizado por reforço, permitindo que os usuários insiram dados e recebam respostas relevantes. Por outro lado, alguns modelos privados são mais restritos e limitados em acessibilidade. Esses modelos são adequados para cenários corporativos onde controle e restrição são cruciais.\n\nNo entanto, existe uma abordagem mista que combina a base linguística de modelos abertos com restrições adicionais e personalização. Essa abordagem permite que as organizações se beneficiem de modelos pré-treinados, ao mesmo tempo em que adicionam sua camada de controle e adaptação. Ao ajustar os pesos e palavras utilizadas no modelo, as organizações podem customizar as respostas para atender às suas necessidades específicas sem partir do zero.\n\n## Operacionalizando a IA Gen na Gestão de Infraestruturas\n\nO podcast explora a operacionalização da IA generativa na gestão de infraestruturas. Ele destaca as vantagens de usar modelos de código aberto para desenvolver sistemas especializados que gerenciam eficientemente nuvens privadas. Por exemplo, um dos parceiros mencionados implementou IA generativa para monitorar e otimizar o desempenho de sua infraestrutura em tempo real, possibilitando a solução proativa de problemas. Ao aproveitar o poder da IA, as organizações podem aprimorar sua eficiência operacional e garantir o funcionamento tranquilo de sua infraestrutura.\n\nOs anfitriões enfatizam a importância de considerar o tipo e a qualidade dos dados de entrada no modelo e a saída desejada. Nem sempre é necessário treinar um modelo com bilhões de indicadores; um conjunto de dados menor adaptado às necessidades específicas pode ser mais eficaz. Ao compreender as nuances dos dados e os objetivos específicos do sistema, as organizações podem otimizar o processo de treinamento e melhorar o desempenho geral do modelo de IA.\n\n## Gerenciando e Aperfeiçoando Sistemas de IA\n\nGerenciar sistemas de IA requer tomada de decisões cuidadosa e monitoramento contínuo. Os anfitriões discutem a importância de selecionar a infraestrutura adequada, seja baseada em nuvem, local ou híbrida. Além disso, a computação de borda está ganhando popularidade, permitindo que os modelos de IA rodem diretamente nos dispositivos, reduzindo as viagens de dados.\n\nO podcast enfatiza a necessidade de expertise na configuração e manutenção de sistemas de IA. É necessário ter talento especializado para projetar e ajustar modelos de IA para alcançar os resultados desejados. Dependendo do caso de uso, funcionalidades específicas podem ser necessárias, como empatia no atendimento ao cliente ou criatividade em aplicativos de brainstorming. É crucial ter uma equipe competente que entenda as complexidades dos sistemas de IA e possa garantir seu funcionamento ideal.\n\nAlém disso, os modelos de IA precisam de monitoramento e ajustes constantes. Os modelos podem apresentar comportamento indesejável, e é essencial intervir quando necessário para garantir resultados apropriados. O podcast diferencia entre problemas de reforço, nos quais o feedback do usuário pode direcionar o modelo em direções potencialmente prejudiciais, e alucinação, que pode ser intencionalmente aplicada para fins criativos.\n\n## Começando com Modelos de IA\n\nO podcast oferece conselhos práticos para começar a usar modelos de IA. Os apresentadores sugerem brincar com as ferramentas disponíveis e se familiarizar com suas capacidades. Inscrever-se para contas e explorar como as ferramentas podem ser usadas é uma ótima maneira de obter experiência prática. Eles também recomendam criar um ambiente de testes dentro das empresas, permitindo que os funcionários testem e interajam com os modelos de IA antes de implementá-los na produção.\n\nO podcast destaca a importância de conceder aos modelos de IA criatividade suficiente, ao mesmo tempo em que se mantém o controle e estabelecem-se limites. As organizações podem encontrar um equilíbrio entre a produção criativa e o uso responsável ao definir diretrizes e tomar decisões sobre o que o modelo deve ou não aprender com as interações.\n\nEm conclusão, o episódio do podcast fornece informações valiosas sobre a operacionalização da IA generativa, gerenciamento de infraestrutura e considerações para gerenciar e ajustar os sistemas de IA. Ele também oferece dicas práticas para iniciar os modelos de IA em ambientes pessoais e profissionais. Ao compreender os diferentes modelos de compartilhamento, necessidades de infraestrutura e a importância da criatividade e limites, as organizações podem aproveitar o poder da IA para apoiar a transformação digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT157-pt","image":"./episodes/edt-157/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de podcast, o apresentador Darren Pulsipher, Arquiteto de Soluções Chefe do Setor Público na Intel, discute a operacionalização da IA generativa com o convidado especial Dr. Jeffrey Lancaster. Eles exploram os diferentes modelos de compartilhamento da IA generativa, incluindo modelos públicos, privados e comunitários. O podcast aborda tópicos como modelos de código aberto, gerenciamento de infraestrutura e considerações para implantação e manutenção de sistemas de IA. Também aprofunda-se na importância da criatividade, personalização e como começar com modelos de IA."},{"id":58,"type":"Episode","title":"GenAI no Ensino Superior.","tags":["collectiongenerativeai","addressingbiasesingenerativeai","preservingauthenticityandindividuality","balancingaiintegrationineducation","lauratorresnewey","criticalthinkingskills","educationaltechnology","highereducation","aiineducation","aibias","diversityandinclusion","authenticvoices","uniqueperspectives","genai","generativeai","embracingdigital","edt158"],"body":"\r\n\r\nA Ascensão da AI Generativa na Educação\n\nNum episódio recente do podcast \"Abraçando a Transformação Digital\", o apresentador Darren Pulsipher entrevista Laura Torres Newey, uma autora best-seller do New York Times e professora de inglês, sobre o impacto da IA generativa no ensino superior. A discussão gira em torno da integração da IA na sala de aula, seus efeitos sobre os métodos de ensino, preocupações com viés e a preservação de vozes únicas. Laura compartilha suas ideias e experiências como educadora, oferecendo perspectivas valiosas sobre como navegar no cenário em constante evolução da educação na era da inteligência artificial.\n\n## A Influência da Inteligência Artificial Generativa na Educação\n\nA inteligência artificial generativa começou a se tornar uma presença notável na educação, desde a correção automatizada de redações até a prestação de assistência na escrita aos estudantes. Embora essa tecnologia ofereça conveniência e eficiência, ela levanta preocupações sobre a possibilidade de perda de vozes únicas. Laura enfatiza a importância de valorizar e nutrir as perspectivas individuais e a criatividade dos alunos em suas escritas. Em vez de proibir completamente o uso de IA generativa, Laura acredita em ensinar os alunos a utilizar essas ferramentas de maneira eficaz e aproveitar seu potencial sem comprometer suas próprias vozes.\n\nA integração de prompts gerados por IA promove uma mudança no foco do ensino. Em vez de avaliar apenas o produto final, os educadores devem dar mais ênfase ao processo de aprendizagem. Com ferramentas impulsionadas por IA, como o Grammarly, disponíveis para os estudantes, os professores podem redirecionar sua atenção para o desenvolvimento de habilidades de pensamento crítico, habilidades de pesquisa e discernimento para identificar fontes confiáveis. Ao incorporar tarefas que envolvam a comparação de conteúdo gerado por IA com trabalhos tradicionalmente escritos, os alunos podem analisar os pontos fortes e fracos de ambas as abordagens, promovendo uma compreensão mais profunda de sua escrita e aprimorando suas habilidades de pensamento crítico.\n\n## O papel dos educadores na era da IA.\n\nOs educadores têm um papel essencial na preparação dos alunos para o cenário tecnológico em constante evolução. Laura ressalta que se adaptar e utilizar de forma eficaz a IA generativa é crucial para os educadores em todos os níveis de ensino. Com a IA se tornando cada vez mais presente no ambiente de trabalho, os alunos que souberem navegar e aproveitar essa tecnologia estarão mais bem preparados para futuras oportunidades de trabalho. Para garantir que os alunos estejam bem preparados, os educadores não só precisam se familiarizar com as aplicações de IA, mas também ensinar os alunos como usar a IA de forma eficaz e ética.\n\nA mudança rumo à integração da IA generativa na educação está alinhada com a posição do Departamento de Educação dos Estados Unidos em relação à IA. Eles reconhecem os benefícios potenciais, mas enfatizam a necessidade de os usuários permanecerem no controle, comparando o papel da IA ao de uma bicicleta elétrica, onde a tecnologia alivia o fardo, mas o usuário mantém o controle final. Essa abordagem enfatiza a importância de encontrar um equilíbrio entre aproveitar os benefícios da IA e preservar as vozes e perspectivas únicas dos estudantes.\n\n## Conclusão\n\nA integração da IA generativa na educação apresenta tanto oportunidades como desafios. Enquanto a IA pode aprimorar o aprendizado e auxiliar os alunos com suas tarefas, é crucial que os educadores priorizem o pensamento crítico e abordem preocupações com viés para desenvolver pensadores bem fundamentados e independentes. Os professores devem abraçar a tecnologia de IA, compreender suas aplicações e ensinar os alunos a navegar e utilizá-la de forma eficaz. Ao encontrar um equilíbrio entre a eficiência do conteúdo gerado pela IA e a preservação das vozes autênticas e diversas, os educadores podem preparar os alunos para o futuro digital, garantindo ao mesmo tempo o cultivo de sua individualidade e criatividade.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Laura Newey","Darren W Pulsipher"],"link":"/episode-EDT158-pt","image":"./episodes/edt-158/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio de podcast, Darren Pulsipher, arquiteto-chefe de soluções do setor público na Intel, entrevista Laura Torres Newey, autora best-seller do New York Times e professora universitária, sobre o impacto da inteligência artificial generativa no ensino superior. Este episódio aprofunda-se nos desafios e oportunidades apresentados pela integração da inteligência artificial generativa na sala de aula, destacando a necessidade de habilidades de pensamento crítico, as preocupações com viés e garantir a preservação de vozes únicas."},{"id":59,"type":"Episode","title":"Políticas da GenAI","tags":["collectiongenerativeai","policies","ai","generativeai","guidelines","jeremyharris","darrenpulsipher","roadmap","challenges","efficiencies","dataprotection","privacy","compliance","ethicalconsiderations","feedback","engagement","ratings","reviews","customersatisfaction","customerengagement","embracingdigital","edt159"],"body":"\r\n\r\n## A Necessidade de Políticas e Diretrizes Claras\n\nJeremy e Darren enfatizam a importância de ter uma política clara e um plano bem definido para a transformação digital. Apressar-se na digitalização sem um planejamento adequado pode levar a desafios e ineficiências. Ao estabelecer políticas e diretrizes, as organizações podem delinear seus objetivos, estabelecer uma direção estratégica e garantir que todos estejam alinhados.\n\nEles enfatizam que a transformação digital é mais do que apenas adotar novas tecnologias - requer uma mudança na cultura organizacional e na mentalidade. As políticas podem ajudar a facilitar essa mudança ao estabelecer expectativas para os funcionários, definir as melhores práticas digitais e fornecer um quadro para a tomada de decisões no mundo digital.\n\n## Navegando nas Complexidades da Digitalização\n\nA transformação digital traz consigo um conjunto complexo de desafios, como segurança de dados, privacidade e conformidade. As organizações precisam enfrentar esses desafios incorporando-os às suas políticas e diretrizes. Isso inclui implementar medidas de proteção de dados, realizar auditorias regulares de segurança e garantir conformidade com regulamentações relevantes.\n\nAs políticas também devem abordar as considerações éticas que vêm com a transformação digital. Os anfitriões enfatizam a importância das organizações serem guardiãs responsáveis dos dados e garantirem que o uso de tecnologias digitais esteja alinhado com os padrões éticos. Diretrizes claras podem ajudar os funcionários a entenderem suas responsabilidades e promover práticas digitais responsáveis em toda a organização.\n\n## O Papel do Feedback e Envolvimento\n\nOs anfitriões destacam a importância do feedback e do engajamento no mundo digital. Adotar uma política que incentive e valorize o feedback pode ajudar as organizações a melhorar continuamente e se adaptar às circunstâncias em mudança. Ao acolher sugestões e contribuições dos funcionários e clientes, as organizações podem aperfeiçoar suas estratégias digitais e garantir que estejam atendendo às necessidades de todos os interessados.\n\nEles também mencionam a importância das avaliações e comentários na era digital. O feedback através das avaliações e comentários não só fornece informações valiosas para as organizações, mas também serve como medida de satisfação e envolvimento do cliente. As políticas podem estabelecer como as organizações coletam e respondem ao feedback, e estabelecer diretrizes para capturar o sentimento do cliente no espaço digital.\n\n## Conclusão\n\nA transformação digital é uma jornada que requer planejamento cuidadoso, políticas claras e ajustes contínuos. Ao estabelecer políticas e diretrizes, as organizações podem navegar pelas complexidades da digitalização, enfrentar desafios e garantir o uso responsável e eficaz das tecnologias digitais. Abraçar a transformação digital não se resume apenas a adotar novas ferramentas, mas também a criar uma cultura digital que incentive a inovação e atenda às necessidades em constante evolução dos clientes e stakeholders.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeremy Harris","Darren W Pulsipher"],"link":"/episode-EDT159-pt","image":"./episodes/edt-159/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, o apresentador Darren entrevista Jeremy Harris e adentra na importância de estabelecer políticas e diretrizes para uma transformação digital bem-sucedida. Com a crescente prevalência das tecnologias digitais em várias indústrias, as organizações precisam se adaptar e abraçar essa transformação para se manterem competitivas e atenderem às expectativas em constante evolução dos clientes."},{"id":60,"type":"Episode","title":"Reduzindo a congestão de ingestão com o Intel Optane DCPMM","tags":null,"body":"\r\n\r\n## Detalhes da Pilha de Serviços.\n\nUm cliente na indústria automotiva estava tendo dificuldades para obter efetivamente informações de seus carros e transferi-las para seu centro de dados, a fim de realizar aprendizado de máquina e análises. Houve pesquisas nessa área, mas apenas para um pequeno número de carros, não para os cem milhões de carros do cliente. Quando examinei toda a pilha de serviços deles e como tudo estava sendo transferido para o centro de dados, a ingestão de dados tornou-se o problema claro: Como faço para absorver tantos dados e como faço isso rapidamente?\n\n## Visão geral da arquitetura de alto nível do Kafka.\n\nO cliente queria usar o Kafka para sua ingestão. O Kafka é um corretor que pode ser dimensionado facilmente e a chave é que ele pode lidar com diversos produtores, consumidores diferentes e muitos dados. Utilizar vários corretores do Kafka para colocar e receber dados nos lugares mais apropriados oferece grande flexibilidade.\n\nKafka, no entanto, foi projetado principalmente para tamanhos de mensagem de cerca de um a 10 quilobytes e os dados do cliente eram aproximadamente 240 quilobytes por carro. Existem soluções alternativas, mas eu queria trazer a mensagem completa de 240 quilobytes para o barramento do Kafka para que pudesse movê-la conforme necessário.\n\n## Práticas recomendadas de desempenho.\n\nEu examinei as melhores práticas de desempenho de outras pessoas que trabalham com Kafka para ver se eu poderia dimensioná-lo para o meu cliente. Aumentar o tamanho do buffer para acomodar a mensagem inteira é uma solução de ajuste fino, juntamente com o gerenciamento do tamanho do lote para um desempenho ideal. Outra prática bem-sucedida é espalhar os logs. A flexibilidade do Kafka me permitiria colocar os dados em tópicos diferentes. Eu posso dividir os tópicos em várias partições que eu posso distribuir em várias unidades. A pergunta é, então, em quantas unidades estou distribuindo os logs do Kafka? Além disso, eu quero as unidades mais rápidas possíveis.\n\nUm exemplo que examinei foi o LinkedIn. Os números publicados por eles há um ano atrás são de que eles podem lidar com 13 milhões de mensagens por segundo, ou 2,7 gigabytes por segundo. Eles afirmam ter cerca de 1.100 corretores Kafka e mais de 60 em um cluster, então essa é uma configuração bastante grande.\n\n## Espaço Automotivo\n\nSe eu observar os números brutos do cliente (1,6 milhão de mensagens por segundo e 800 gigabytes por segundo) e compará-los com o LinkedIn, que provavelmente não está otimizado para 240 kilobytes, chego a 44.000 corretores. Se eu otimizá-lo, provavelmente poderia chegar a 4.400 corretores, o que ainda seriam 240 clusters. Essa é uma quantidade enorme de máquinas, então eu tive que encontrar uma forma de tornar as coisas mais rápidas. Com mais otimização, provavelmente poderia reduzir para 400 ou 500 corretores, mas eu queria ver o que mais eu poderia fazer.\n\n## Intel Optane DC Persistent Memory\n\nMemória Persistente Intel Optane DC\n\nEu olhei para nossa Memória Persistente Optane. Ela se encaixa em um formato DDR4, então ela fica diretamente no barramento DDR4. Ela suporta módulos de até 512 gigabytes, então em um servidor de dois soquetes, posso ter seis terabytes de memória persistente. Eu queria encontrar uma maneira de aproveitar essa tecnologia altamente confiável com ótimos recursos, como criptografia de hardware incorporada, para me ajudar a resolver esse problema.\n\n## Suporte para uma ampla variedade de aplicações.\n\nExistem dois modos de operação com este Optane Memory: modo de aplicativo direto e modo de memória. O modo de memória é simples. Ele utiliza a memória persistente como RAM normal, pois é mais barato que o DDR4 normal. Não é o mesmo que DDR4, mas é próximo o suficiente para que na maioria das aplicações, você não consiga perceber a diferença. No modo de aplicativo direto, você pode realmente escrever do seu programa diretamente na memória persistente. Dessa forma, eu não preciso manipular e descomprimir estruturas de dados e transmiti-las; eu posso simplesmente inseri-las na memória persistente. Eu também posso montar o modo de aplicativo direto como um sistema de arquivos, para que ele esteja no barramento de memória, que é muito mais rápido do que no barramento de I/O. Agora, o que posso fazer com essa memória?\n\n## Usando o Kernel do Linux\n\nExistem duas ferramentas principais disponíveis usando o kernel Linux: ndctl e ipmctl. Ndctl é um controlador de dispositivo de memória não volátil e depois temos o IPM, o controlador de Memória Persistente Intel, que me permite manipular e controlar essa memória persistente. Posso configurá-la no modo de memória ou no modo direto do aplicativo. Eu precisei aprender um pouco sobre essas ferramentas e como elas funcionam.\n\n## Abordagem de Ingestão\n\nMinha primeira ideia foi que se eu fornecesse a Kafka uma quantidade maior de memória com tamanhos de buffer grandes, ela deveria rodar muito mais rápido. Mudanças no código da configuração seriam desnecessárias ou mínimas. Outra opção seria mudar Kafka para escrever na memória persistente, em vez de escrever em um sistema de arquivos, contornando o disco rígido. A última coisa que eu analisei foi criar um sistema de arquivos persistente usando memória persistente e em seguida colocar os registros do Kafka nesse novo sistema de arquivos.\n\nA opção mais fácil das três foi a primeira - mais memória. Eu executei todas as minhas tarefas com mais memória e não houve mudança de desempenho. Os motivos são porque eventualmente meus buffers ficaram cheios e eu tive que escrever para um disco. No final, tudo teve que ir para os registros do Kafka, que foi o gargalo.\n\nA segunda opção envolve reescrever o código e esperar por aprovações, então pulei para a terceira opção. Os resultados desse experimento, onde apontei os registros para esse novo sistema de arquivos ultra-rápido, foram fascinantes. Vamos dar uma olhada no processo e nos resultados.\n\n## Testando restrições\n\nPara remover obstáculos aos testes de desempenho, eu eliminei a rede da equação ao executar meu teste na mesma máquina em que meu corretor estava. Além disso, eu executei apenas os produtores e depois apenas os consumidores, e só então misturei os dois, para que eu pudesse avaliar as diferenças. Meu objetivo não era observar uma melhoria total na produção, mas sim em um corretor individual para ver se esse recurso realmente faria diferença.\n\n## Primeira abordagem 50/50\n\nA primeira coisa que fiz foi colocar metade da minha memória persistente no modo direto do aplicativo e transformá-la em um sistema de arquivos. Deixei a outra metade como memória. Usei os comandos ndctl e ipmctl e criei namespaces. Monteis esses sistemas de arquivos e executei meu teste.\n\n## Alterando o Tamanho da Mensagem\n\nExecuti os testes com diferentes tamanhos de mensagens. Eu estava esperando por certa otimização, principalmente para 1 kilobyte. Percebi que obtive um desempenho cada vez melhor até mais ou menos 10 produtores. Após 10 produtores, comecei a saturar o barramento e obter alguma variabilidade. Isso me mostra que eu estava fazendo cache das coisas. Agora, posso comparar esses números com o que executei antes em apenas um disco SATA para os registros do Kafka. Também testei nossas unidades Optane NVMe para os registros.\n\n## Comparação de Tecnologia\n\nVamos dar uma olhada nas diferenças. Para 240 quilobytes, com um disco SATA normal, é bastante uniforme. Observei alguma melhoria e, depois, diminuiu à medida que o número de produtores aumentava. Com o disco Optane NVMe, obtive um pico agradável, quase duas vezes mais rápido que um disco SATA, o que eu esperava, já que se trata de um barramento NVMe em vez de um barramento SATA. O Pmem é quase cinco vezes mais rápido que um disco SATA e duas vezes e meia mais rápido que o disco Optane NVMe. Isso ocorre porque estou usando um barramento de memória em vez do barramento SATA ou NVMe.\n\n## Otimização adicional (100% direto do aplicativo).\n\nIsso estava rodando rápido e eu estava rapidamente preenchendo essa unidade temporária de 750 GB. Como eu precisava rodar o teste um pouco mais, voltei atrás e reconfigurei minha máquina para funcionar em um modo de aplicativo 100% direto, para que agora eu possa usar o total de 1,5 terabytes.\n\n## PMEM otimizado e 100% App Direct\n\nDepois de fazer isso e executar os mesmos testes, obtive um resultado surpreendente. Eu poderia adicionar mais produtores e minha taxa de transferência aumentou quase duas ou três vezes mais. Agora está entre 12 e 15 vezes mais rápido do que uma unidade SATA com 25-30 produtores e tamanho de mensagem de 240 kilobytes. Isso é incrível e reduziria muito a necessidade de tantos corretores, linhas e linhas de máquinas dos meus clientes. Executei o teste várias vezes porque não acreditava nos resultados que estava obtendo. Liguei para um dos nossos arquitetos que projetaram essa tecnologia e descobri que uma das razões para o aumento da velocidade foi quando eu estava usando parte da memória persistente como memória; os dados teriam que passar por dois ou três saltos que não são necessários com o modo de acesso direto ao aplicativo. Isso cria menos contenção no barramento de memória e a taxa de transferência aumenta drasticamente.\n\n## Chamada para ação\n\nO resultado final é que consegui usar Kafka com Memória Persistente Optane DC como um sistema de arquivos ultrarrápido para obter melhorias significativas no throughput tanto para produtores quanto para consumidores. Um único corretor pode lidar com 15 vezes mais mensagens e throughput do que antes, diminuindo o número de servidores necessários para lidar com arquiteturas de sistemas grandes e complexas. É hora de avaliar sua arquitetura atual e ver se isso seria benéfico para sua organização.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT16-pt","image":"./episodes/edt-16/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren fala sobre diminuir a congestão de ingestão usando a Memória Persistente Optane DC da Intel e o experimento que ele conduziu com resultados surpreendentes. Isso pode mudar a maneira como pensamos sobre programação no futuro."},{"id":61,"type":"Episode","title":"Segurança em IA Generativa","tags":["collectiongenerativeai","personalizedphishingattacks","promptinjection","sharingcodeai","harnessingai","digitaltransformation","generativeai","cybersecurityrisks","serviceproviders","duediligence","riskschallenges","digitallandscape","proactivecybersecurity","llm","multifactorauthentication","voicerecognition","typingcadence","github","stackoverflow","samsungipleak","securityaspects","embracingdigital","edt160"],"body":"\r\n\r\n## Ataques de Phishing Personalizados e Convincentes\n\nUma das principais preocupações discutidas é o potencial para ataques de phishing mais sofisticados e personalizados. O phishing atualmente é o método de ataque cibernético mais eficaz e, com a inteligência artificial generativa, os atacantes podem criar e-mails ou mensagens de phishing altamente personalizados e persuasivos. Ao obter informações das redes sociais ou de outras plataformas online, os atacantes podem dificultar a detecção de suas tentativas de phishing. Isso levanta a questão de como podemos determinar o que é real ou não e como podemos confiar na autenticidade das informações que recebemos.\n\nPara combater isso, os indivíduos podem precisar desenvolver novos métodos para verificar informações, como usar códigos pessoais ou outras medidas de autenticação com entes queridos. Além disso, organizações e agências de segurança devem adaptar suas estratégias para combater a sofisticação crescente dos ataques cibernéticos facilitados pela IA generativa. É crucial entender que a própria IA generativa é uma tecnologia neutra, e suas implicações dependem de como ela é usada.\n\n## Vozes Clonadas e Confiando em Informações\n\nO podcast também explora o potencial da IA generativa para clonar vozes, o que já foi observado em ataques virtuais de sequestro. Os criminosos usam vozes clonadas para criar uma sensação de urgência e medo, fingindo serem entes queridos da vítima. Isso levanta preocupações sobre confiar na autenticidade das informações que recebemos.\n\nEm um cenário como esse, torna-se essencial desenvolver técnicas para verificar a autenticidade das vozes e das informações. Como indivíduos, devemos permanecer vigilantes e exercer cautela ao responder a solicitações urgentes por telefone. Garantir linhas de comunicação abertas com contatos confiáveis pode ajudar a verificar se tais solicitações são genuínas.\n\n## Protegendo a Propriedade Intelectual na Codificação e Programação\n\nO podcast segue para uma discussão sobre a importância de proteger a propriedade intelectual na codificação e programação. Os apresentadores destacam os riscos de compartilhar código acidentalmente em plataformas como StackOverflow e GitHub, e o vazamento inadvertido da propriedade intelectual ao buscar ajuda nesses fóruns públicos. Os desenvolvedores são incentivados a substituir informações sensíveis por espaços reservados antes de compartilhar o código, a fim de reduzir o risco de perda da propriedade intelectual.\n\nAlém disso, os anfitriões discutem a introdução de ferramentas como o GitHub Copilot, que utilizam inteligência artificial generativa para fornecer sugestões de código. Embora essas ferramentas possam ser valiosas, elas levantam preocupações sobre a segurança e privacidade das informações proprietárias. Os desenvolvedores devem considerar cuidadosamente a confiabilidade do provedor de serviços e garantir proteção adequada de seus dados e propriedade intelectual.\n\n## Equilibrando Inovação e Segurança na Era da IA\n\nA conversa conclui enfatizando a importância de encontrar um equilíbrio entre abraçar os avanços e as potenciais mudanças positivas trazidas pela IA generativa, e lidar com os riscos associados no campo da cibersegurança e da proteção de propriedade intelectual. É essencial permanecer informado, adaptar estratégias de segurança e exercer cautela para navegar com sucesso no cenário em constante evolução da transformação digital. Ao fazê-lo, podemos aproveitar os benefícios da IA sem comprometer a segurança e as informações pessoais.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT160-pt","image":"./episodes/edt-160/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, o apresentador Darren Pulsipher é acompanhado pelo Dr. Jeffrey Lancaster para explorar a intersecção entre a inteligência artificial generativa e a segurança. A conversa mergulha fundo nos riscos e desafios potenciais que envolvem o uso da inteligência artificial generativa em atividades maliciosas, especialmente no campo da cibersegurança."},{"id":62,"type":"Episode","title":"Análise de Dados de Linguagem Natural","tags":["collectiongenerativeai","ai","generativeai","embracingdigital","edt161","challengesinnaturallanguageprocessing","fantasysportsapp","naturallanguagegeneration","highqualitycontent","technicalbackground","outoftheboxthinking","pushingboundaries","diversity","crossdomaincollaboration","innovativeideas","infoscentience'ssolution","dataanalytics","naturallanguageaisystem","conceptualautomata","datasets","revolutionizing","businessesanalyzeinformation","futureofdataanalysis","naturallanguagereporting","flexibility","tailored","differentindustries","customized","specificcontext","jargon","dataanalysis","revolutionizingindustries","sportsanalytics","stevewasick'sjourney","innovativeapproach","entrepreneurs","techfounders","unconventionalpaths","successfulinnovations","embracingvariability","context","poweroflanguage"],"body":"\r\n\r\n## Desafios no Processamento de Linguagem Natural\n\nSteve relembra seu projeto inicial - um aplicativo para esportes de fantasia que visava fornecer aos usuários não apenas estatísticas, mas também o contexto e histórias por trás dos números. Isso o levou ao campo da geração de linguagem natural, onde ele enfrentou desafios na aquisição e entrega de conteúdo de alta qualidade. Apesar de não ter formação técnica, as experiências diversas de Steve permitiram que ele abordasse esses desafios com criatividade e pensamento inovador.\n\n## Empurrando Limites\n\nDarren elogia Steve por ultrapassar limites e trazer uma perspectiva inovadora para o campo. Isso destaca a importância da diversidade e da colaboração transdisciplinar na geração de ideias e soluções inovadoras. A jornada de Steve serve como inspiração para empreendedores e fundadores de empresas de tecnologia em ascensão, comprovando que caminhos não convencionais podem levar a inovações bem-sucedidas.\n\n## Solução da InfoScentience para Análise de Dados\n\nA conversa também aborda as capacidades do sistema de inteligência artificial em linguagem natural da InfoSentience. Steve explica que sua tecnologia analisa eventos e histórias em suas partes constituintes, proporcionando uma melhor compreensão de conceitos complexos e suas relações. Esse motor analítico, baseado em autômatos conceituais, permite a síntese de conjuntos de dados diversos e complexos, revolucionando a forma como as empresas analisam informações.\n\n## O futuro da análise de dados e relatórios de linguagem natural.\n\nAlém disso, Steve enfatiza a flexibilidade de seu sistema de IA, que pode ser adaptado a diferentes setores e personalizado para atender às necessidades únicas de cada cliente. Ao compreender o contexto específico e a terminologia dos dados analisados, o Info Sentience garante que seu sistema de IA forneça insights precisos e relevantes.\n\nEm conclusão, o episódio do podcast destaca o potencial da análise de dados de linguagem natural na revolução de indústrias como a análise esportiva. A jornada de Steve Wasick e sua abordagem inovadora servem como inspiração para empreendedores e fundadores de tecnologia, lembrando-nos que caminhos não convencionais podem levar a inovações bem-sucedidas. O futuro da análise de dados reside em abraçar a variabilidade, o contexto e o poder da linguagem.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Wasick"],"link":"/episode-EDT161-pt","image":"./episodes/edt-161/pt/thumbnail.jpg","lang":"pt","summary":"No último episódio, Darren Pulsipher senta-se com Steve Wasick, o CEO e fundador da InfoSentience, para discutir o poder e o potencial da análise de dados em linguagem natural. Steve, que tem uma trajetória não convencional, iniciando como estudante de inglês, depois roteirista, então advogado e, por fim, fundador de tecnologia, traz uma perspectiva única para o campo."},{"id":63,"type":"Episode","title":"Construindo uma estratégia Multi-Hybrid Cloud","tags":["cloudadoption","collmultihybridcloud","organizationalmodernization","barriers","riskmitigationplan","applicationrearchitecture","governance","organizationalculture","cloud","multihybridcloud","multicloud","embracingdigital","edt162"],"body":"\r\n\r\n## Melhores práticas para adoção de nuvem\n\nMudar para a nuvem e adotar novas tecnologias como a Inteligência Artificial generativa pode trazer inúmeros benefícios, mas as organizações também devem estar preparadas para as mudanças que vêm com isso. De acordo com Christine McMonigal, diretora de Tecnologias de Centro de Dados e Nuvem na Intel, há melhores práticas chave a serem consideradas.\n\n## Modernização Organizacional\n\nUm aspecto importante a reconhecer é que a adoção da nuvem não é apenas uma modernização tecnológica, mas também uma modernização organizacional. Isso significa que as organizações precisam estar preparadas para mudanças nos processos, fluxos de trabalho e até mesmo nas estruturas organizacionais. É crucial abordar essas mudanças e garantir que toda a organização esteja alinhada e preparada para a transformação.\n\n## Identificando Barreiras e Estabelecendo Expectativas Claras\n\nUm passo crucial para superar obstáculos e mitigar riscos é identificar quais são esses obstáculos em primeiro lugar. Ao fazer uma avaliação minuciosa da infraestrutura atual, fluxos de trabalho e desafios dentro da organização, os possíveis bloqueios podem ser localizados e estratégias podem ser desenvolvidas para superá-los.\n\nAlém disso, estabelecer expectativas claras desde o início é essencial. Isso significa ter uma comunicação efetiva com partes interessadas, funcionários e parceiros sobre os objetivos, benefícios e desafios de adotar estratégias de nuvem multi-híbrida. Ao estabelecer expectativas realistas e garantir que todos estejam na mesma página, as organizações podem minimizar surpresas e resistência à mudança.\n\n## Plano Robusto de Mitigação de Riscos\n\nTer um plano robusto de mitigação de riscos é outro aspecto crucial para uma adoção bem-sucedida da nuvem. Isso inclui avaliar os riscos potenciais de segurança, preocupações com privacidade de dados e requisitos de conformidade. Ao tratar proativamente esses riscos e implementar medidas adequadas, as organizações podem proteger seus dados, garantir conformidade regulatória e minimizar possíveis ameaças.\n\n## Barreira 1: Re-arquitetura da aplicação.\n\nUma das principais barreiras que as organizações frequentemente enfrentam na adoção da nuvem é a re-arquitetura de aplicativos. É importante avaliar quais aplicativos podem ser transferidos para a nuvem como estão e quais podem exigir modificações significativas. Ao identificar oportunidades de simplificação e redução de custos por meio da automação, as organizações podem otimizar o acesso e os controles.\n\n## Barreira 2: Governança\n\nAs políticas de governança desempenham um papel crucial na mitigação de riscos durante a adoção da nuvem. Modelos de segurança inconsistentes, ferramentas de gerenciamento diversas e políticas de usuário heterogêneas podem aumentar a complexidade e colocar em risco o sucesso da migração. Simplificar as políticas de governança e eliminar burocracia pode ajudar as organizações a otimizar as operações, reduzir custos e garantir a segurança e conformidade dos dados.\n\n## Barreira 3: Cultura Organizacional e Maturidade\n\nPreparar a organização para a mudança que vem com a adoção da nuvem é vital. Isso envolve envolver os funcionários, fornecer treinamento de habilidades e identificar os principais participantes que possam adotar as novas formas de trabalho. Abordar os medos e preocupações que os funcionários possam ter, como o medo de ficar para trás ou perder seus empregos, é essencial para criar um ambiente positivo e colaborativo.\n\nEm conclusão, a adoção de estratégias de nuvem híbrida requer um planejamento cuidadoso, comunicação eficaz e um entendimento detalhado dos objetivos e desafios de uma organização. Ao lidar com as barreiras antecipadamente e mitigar os riscos, as organizações podem abrir caminho para uma jornada bem-sucedida de transformação digital. Fique atento aos próximos episódios, onde exploraremos o desenvolvimento de uma estratégia de nuvem, a avaliação de portfólios de aplicativos e mais insights sobre a adoção da transformação digital. Não se esqueça de avaliar e se inscrever em nosso podcast para se manter atualizado sobre as últimas tendências e melhores práticas no cenário digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Christine McMonigal","Darren W Pulsipher"],"link":"/episode-EDT162-pt","image":"./episodes/edt-162/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Christine McMonigal e discutem os desafios que as organizações enfrentam ao fazer a transição para a nuvem e adotar arquiteturas de nuvem multi-híbridas. Eles destacam a importância de entender essas dificuldades e fornecer orientações para superá-las. Este episódio aprofundará algumas das principais barreiras e estratégias para mitigar os riscos, garantindo uma transformação bem-sucedida para a nuvem."},{"id":64,"type":"Episode","title":"Desenvolvendo um Modelo Operacional de Nuvem Multihíbrida","tags":["cloudstrategy","digitaltransformation","collmultihybridcloud","cloudtechnologies","businessgoals","operationalefficiency","customersatisfaction","itinfrastructure","migrationplan","datasecurity","regulatorycompliance","hybridclouds","publicclouds","privateclouds","clouddeploymentmodels","governanceandsecurity","reducecosts","enhanceefficiency","customerexperience","strategicmove","clearvision","embracingdigital","edt163"],"body":"\r\n\r\nNa era digital atual, as empresas estão cada vez mais recorrendo à nuvem como uma jogada estratégica para melhorar a eficiência, reduzir custos e aprimorar a experiência do cliente. No entanto, antes de entrar na onda da nuvem, é essencial para as organizações dar um passo atrás e avaliar suas necessidades específicas. Desenvolver uma estratégia de nuvem é um passo crucial nesse processo, pois permite às empresas alinhar seus objetivos e metas com as tecnologias de nuvem disponíveis para elas.\n\n## Compreender seus objetivos e metas comerciais\n\nO primeiro passo para desenvolver uma estratégia em nuvem é obter uma compreensão clara dos seus objetivos e metas comerciais. O que você está tentando alcançar? Você está procurando melhorar a eficiência operacional, reduzir custos ou aumentar a satisfação do cliente? Ao ter uma visão clara de seus objetivos, você pode determinar melhor como a nuvem pode apoiar e viabilizar essas metas.\n\n## Avaliando sua infraestrutura existente\n\nApós estabelecer seus objetivos, é importante avaliar sua infraestrutura de TI atual. Essa avaliação ajuda a identificar quaisquer desafios ou limitações potenciais na migração para a nuvem. Determine quais sistemas e aplicativos você possui atualmente e considere sua compatibilidade com um ambiente em nuvem. Essa avaliação informará as decisões sobre quais aplicativos e serviços são adequados para a migração.\n\n## Escolhendo o Modelo de Nuvem Correto\n\nCom vários modelos de implantação em nuvem disponíveis, as organizações precisam avaliar as diferentes opções que estejam alinhadas com seus requisitos comerciais. Nuvens públicas, nuvens privadas e nuvens híbridas oferecem vantagens e desvantagens distintas. Avaliar os prós e contras de cada modelo ajudará você a determinar a escolha mais apropriada para sua organização. Considere fatores como segurança de dados, escalabilidade e conformidade regulatória ao tomar essa decisão.\n\n## Criando um Plano de Migração e Garantindo Governança e Segurança\n\nUma vez que você tenha escolhido um modelo de nuvem, é hora de criar um plano de migração. Isso envolve delinear os passos e o cronograma para mover suas aplicações e dados para a nuvem. Priorize as aplicações críticas que precisam ser migradas primeiro e desenvolva uma estratégia para migrar as demais aplicações posteriormente. Além disso, implemente um plano de governança e segurança para proteger seus dados e cumprir quaisquer requisitos regulatórios. A segurança da nuvem é uma preocupação importante para muitas empresas, portanto, é vital garantir que seus dados estejam protegidos durante todo o processo de migração.\n\nEm conclusão, desenvolver uma estratégia de nuvem é um processo complexo que requer um planejamento e avaliação cuidadosos. É essencial entender seus objetivos comerciais, avaliar sua infraestrutura existente, escolher o modelo de nuvem correto, criar um plano de migração e implementar medidas adequadas de governança e segurança. Ao abraçar efetivamente a transformação digital e aproveitar o poder da nuvem, as organizações podem alcançar seus objetivos, aumentar a eficiência e impulsionar o crescimento e o sucesso.\n\nNa era digital de hoje, as empresas estão cada vez mais recorrendo à nuvem como uma medida estratégica para melhorar a eficiência, reduzir custos e aprimorar a experiência do cliente. No entanto, antes de aderir à onda da nuvem, é essencial que as organizações deem um passo atrás e avaliem suas necessidades específicas. Desenvolver uma estratégia de nuvem é uma etapa crucial nesse processo, pois permite que as empresas alinhem seus objetivos e metas com as tecnologias em nuvem disponíveis para elas.\n\n## Compreendendo seus objetivos e metas empresariais\n\nO primeiro passo no desenvolvimento de uma estratégia de nuvem é obter uma compreensão clara dos objetivos e metas de negócio. O que está tentando alcançar? Está procurando melhorar a eficiência operacional, reduzir custos ou aumentar a satisfação do cliente? Ao ter uma visão clara de seus objetivos, você pode determinar melhor como a nuvem pode apoiar e viabilizar esses objetivos.\n\n## Avaliando sua infraestrutura existente\n\nApós estabelecer seus objetivos, é importante avaliar sua infraestrutura de TI atual. Essa avaliação ajuda a identificar quaisquer desafios ou limitações potenciais na migração para a nuvem. Determine quais sistemas e aplicativos você possui atualmente e considere sua compatibilidade com um ambiente de nuvem. Essa avaliação informará as decisões sobre quais aplicativos e serviços são adequados para a migração.\n\n## Escolhendo o Modelo de Nuvem Certo.\n\nCom vários modelos de implantação em nuvem disponíveis, as organizações precisam avaliar as diferentes opções que se alinham com suas necessidades de negócios. Nuvens públicas, nuvens privadas e nuvens híbridas oferecem vantagens e desvantagens distintas. Avaliar os prós e contras de cada modelo ajudará você a determinar a escolha mais apropriada para sua organização. Considere fatores como segurança de dados, escalabilidade e conformidade regulatória ao tomar essa decisão.\n\n## Criando um Plano de Migração e Garantindo Governança e Segurança.\n\nDepois de escolher um modelo de nuvem, é hora de criar um plano de migração. Isso envolve definir as etapas e o cronograma para mover suas aplicações e dados para a nuvem. Priorize as aplicações críticas que precisam ser migradas primeiro e desenvolva uma estratégia para migrar as demais aplicações posteriormente. Além disso, implemente um plano de governança e segurança para proteger seus dados e estar em conformidade com quaisquer requisitos regulatórios. A segurança na nuvem é uma preocupação importante para muitas empresas, portanto, é vital garantir que seus dados estejam protegidos durante todo o processo de migração.\n\nEm conclusão, desenvolver uma estratégia em nuvem é um processo complexo que requer um planejamento e avaliação cuidadosos. É essencial entender os objetivos do seu negócio, avaliar sua infraestrutura existente, escolher o modelo de nuvem adequado, criar um plano de migração e implementar medidas de governança e segurança adequadas. Ao abraçar efetivamente a transformação digital e aproveitar o poder da nuvem, as organizações podem alcançar seus objetivos, aprimorar a eficiência e impulsionar o crescimento e o sucesso.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Rajiv Mandal","Darren W Pulsipher"],"link":"/episode-EDT163-pt","image":"./episodes/edt-163/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista o arquiteto de soluções em nuvem, Rajiv Mandal, sobre o desenvolvimento de uma estratégia de nuvem multi-híbrida em sua organização de TI moderna."},{"id":65,"type":"Episode","title":"Portfólios de Aplicação e Cargas de Trabalho na Migração para Cloud","tags":["cloudmigration","organizations","collmultihybridcloud","cloudnative","datacenterdependencies","hybridstrategy","technicaldebt","applications","workloads","politicalcapital","customerfacingapplications","importance","applicationrationalization","analysis","dependencies","smoothtransition","surprises","decision","compliancerequirements","regulatedindustries","compliancemonitoring","embracingdigital","edt164"],"body":"\r\n\r\n## Compreensão de Portfólios de Aplicativos e Cargas de Trabalho na Migração para Nuvem\n\nQuando se trata de migração para nuvem, as organizações geralmente se dividem em dois grupos. O primeiro grupo consiste em organizações nativas da nuvem, que projetaram suas aplicações na nuvem, eliminando qualquer dependência de data center. O segundo grupo adota uma estratégia híbrida, contando tanto com o data center quanto com a nuvem. No entanto, mesmo essas organizações híbridas podem ter dívidas técnicas que precisam ser solucionadas.\n\nUm dos principais desafios na migração para a nuvem é entender a complexidade das aplicações e cargas de trabalho. Sarah introduz o conceito de \"capital político\" que uma aplicação carrega. Enquanto as aplicações voltadas para o exterior e para o cliente muitas vezes recebem mais atenção e investimento, aplicações menores que podem não parecer significantes podem ter um impacto substancial na organização se falharem ou forem negligenciadas.\n\n## A Importância da Racionalização de Aplicativos\n\nSarah compartilha uma experiência pessoal que destaca a importância de considerar o portfólio geral de aplicativos e cargas de trabalho durante a migração para a nuvem. Ela testemunhou uma interrupção nos negócios causada pela falta de atenção a um aplicativo aparentemente pequeno voltado para o cliente. Essa experiência enfatiza a necessidade de as organizações conduzirem uma análise e racionalização completa de seu portfólio de aplicativos antes de migrar para a nuvem.\n\nAo compreender as complexidades e dependências de aplicativos e cargas de trabalho, as organizações podem garantir uma transição tranquila para a nuvem com menos surpresas ou interrupções. Sarah enfatiza a necessidade de as organizações priorizarem a racionalização de aplicativos para identificar aplicativos críticos que possam exigir investimento e atenção adicionais, mesmo que não sejam os mais visíveis.\n\n## Tocar ou não tocar: Avaliando cargas de trabalho para migração para a nuvem.\n\nEmbora migrar cargas de trabalho para a nuvem possa trazer inúmeros benefícios, nem sempre é necessário ou vantajoso mexer em determinadas cargas de trabalho ou aplicações. Algumas cargas de trabalho podem estar funcionando perfeitamente há anos e são fundamentais para as operações da organização. Nesses casos, pode não fazer sentido fazer alterações ou migrá-las para a nuvem.\n\nFatores a considerar ao tomar a decisão incluem o nível de personalização e integração da carga de trabalho, a presença de dívida técnica e a aposentadoria iminente de sistemas legados. No entanto, é essencial reavaliar regularmente essas cargas de trabalho para garantir que continuem atendendo às necessidades da organização. Monitorar as tendências da indústria e os avanços tecnológicos pode ajudar a identificar possíveis mudanças no futuro.\n\n## Navegando pelas exigências de conformidade na migração para a nuvem\n\nOs requisitos de conformidade podem representar desafios na migração para a nuvem, especialmente para organizações em setores regulados. No entanto, os provedores de serviços em nuvem têm progredido significativamente ao abordar essas preocupações. Eles oferecem ferramentas e serviços que ajudam a automatizar a monitoração e relatórios de conformidade, tornando menos oneroso para as organizações manter a conformidade.\n\nPara enfrentar esses desafios, as organizações devem realizar uma avaliação completa de seus requisitos de conformidade. Consultar especialistas que possam fornecer orientações sobre padrões de conformidade e projetar uma arquitetura de nuvem que atenda a esses requisitos é crucial. Auditorias regulares e monitoramento devem ser implementados para garantir conformidade contínua.\n\n## Conclusão\n\nNeste episódio de podcast, Darren Pulsipher e Sarah Musick iluminam aspectos importantes da migração para a nuvem, incluindo a racionalização dos portfólios de aplicativos, tomadas de decisão em relação às cargas de trabalho e cumprimento dos requisitos de conformidade. Ao compreender esses fatores e gerenciar ativamente a dívida técnica, as organizações podem embarcar em uma jornada bem-sucedida de migração para a nuvem, aproveitando a agilidade e flexibilidade oferecidas pela nuvem enquanto minimizam riscos e interrupções.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sarah Musick","Darren W Pulsipher"],"link":"/episode-EDT164-pt","image":"./episodes/edt-164/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Sarah Musick, Arquiteta de Soluções em Nuvem na Intel. Juntos, eles exploram o tema de portfólios de aplicações e cargas de trabalho na migração para a nuvem. Com a experiência de Sarah em consultoria e otimização na nuvem, ela traz insights valiosos para a discussão."},{"id":66,"type":"Episode","title":"Fatores de colocação de carga de trabalho na nuvem","tags":["cloudcomputeoptions","collmultihybridcloud","cloudinstance","cloudspecialistadvice","computeselectiontools","optimizecloud","workloadcloud","vendorlockinprevention","cloudbestpractices","cloudinstanceperformance","costeffectivecomputesolutions","workloadoptimization","resourceefficiency","cloud","multihybridcloud","embracingdigital","edt165"],"body":"\r\n\r\n## Compreendendo as Opções de Computação\n\nOs provedores de serviços em nuvem (CSPs) oferecem uma variedade de famílias de computação, desde gerações mais antigas de hardware até as instâncias mais recentes e de melhor desempenho. Essas gerações mais antigas são frequentemente usadas para funções de computação com bom custo-benefício, enquanto as gerações mais recentes oferecem desempenho aprimorado a preços similares ou mais baixos.\n\nPode ser avassalador navegar pelas inúmeras opções de computação disponíveis na nuvem, especialmente com novas instâncias sendo lançadas regularmente. É aí que entram os especialistas em nuvem, como os da Intel. Esses especialistas podem fornecer insights valiosos e ajudar na seleção da instância mais adequada para uma carga de trabalho específica.\n\n## Tomada de Decisões Informadas\n\nPara tomar a melhor decisão, busque o conselho de especialistas em nuvem ou use ferramentas como Densify ou Intel Site Optimizer. Essas ferramentas utilizam aprendizado de máquina para analisar as características de um aplicativo, o uso de computação e as necessidades de rede para determinar o tamanho da instância mais adequado. Ao aproveitar esses recursos, as organizações podem garantir que estão obtendo o máximo de seus recursos de nuvem, evitando subutilização ou gastos excessivos.\n\n## Implementando as melhores práticas\n\nÉ importante incorporar recomendações de instância nos scripts de infraestrutura como código (IaC), como TerraForm, para automatizar a seleção da instância mais eficiente para uma carga de trabalho. Isso garante colocação consistente e eficiente das instâncias, eliminando o risco de erros humanos e otimizando o desempenho.\n\n## Considerando a Portabilidade\n\nEmbora a Intel atualmente domine o mercado de nuvem com instâncias baseadas em x86, há alguma concorrência vinda da AMD e ARM. Os processadores baseados em ARM, como o Graviton, são populares entre os CSPs, mas necessitam de maior portabilidade de carga de trabalho entre provedores e entre ambientes públicos e privados. Importar cargas de trabalho baseadas em x86 para ARM exigiria uma extensa refatoração e desenvolvimento de código.\n\nAs organizações devem considerar questões de compatibilidade ao repatriar cargas de trabalho da nuvem de volta à infraestrutura local. É crucial avaliar a portabilidade e flexibilidade da plataforma de computação escolhida para garantir transições perfeitas e evitar o aprisionamento a um fornecedor.\n\n## Conclusão\n\nSelecionar a instância da nuvem correta é uma decisão crítica que pode impactar o desempenho, o custo e a portabilidade da carga de trabalho. Com a ajuda de especialistas e ferramentas em nuvem, as organizações podem tomar decisões informadas e otimizar a utilização de seus recursos na nuvem. Ao compreender as opções de computação disponíveis, incorporar as melhores práticas e considerar a portabilidade, as empresas podem aproveitar todo o potencial da nuvem, garantindo flexibilidade e eficiência em suas operações.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Ricardo Dutton Jr","Darren W Pulsipher"],"link":"/episode-EDT165-pt","image":"./episodes/edt-165/pt/thumbnail.png","lang":"pt","summary":"Neste podcast, Darren e Rico Dutton mergulham no mundo das instâncias em nuvem e nos fatores a serem considerados ao selecionar a instância certa para sua carga de trabalho. Eles discutem as diferentes opções de computação disponíveis na nuvem, a importância de encontrar o equilíbrio certo entre desempenho e custo e o papel dos especialistas em nuvem em ajudar as organizações a tomar decisões informadas."},{"id":67,"type":"Episode","title":"Agilidade na adoção da nuvem","tags":null,"body":"\r\n\r\n## Migração para a Nuvem como uma Jornada Contínua.\n\nEmbora muitas pessoas vejam a migração para a nuvem como um processo único, é essencial encará-la como uma jornada contínua, na qual os desenvolvedores e as equipes de operação trabalham juntos. Uma vez que as cargas de trabalho são modernizadas e implantadas, monitoramento e avaliação constantes são necessários para determinar se elas atendem aos objetivos comerciais e às métricas de sucesso.\n\nAo tratar a migração para a nuvem como uma jornada contínua, as organizações podem capacitar suas equipes a iterar, refinar e melhorar seu sucesso. Essa abordagem permitirá agilidade, adaptabilidade e a habilidade de responder às necessidades em evolução do negócio.\n\n## Repatriando cargas de trabalho e flexibilidade\n\nUm aspecto importante a considerar é a possibilidade de migrar as cargas de trabalho de volta para as instalações locais se os benefícios esperados da nuvem não estiverem sendo alcançados ou se houver necessidade de alternar entre diferentes provedores de nuvem. Para alcançar uma melhoria contínua, é necessário avaliar a situação continuamente, estabelecer expectativas antecipadamente e ser ágil e flexível no modelo de operação em nuvem.\n\nUma infraestrutura consistente em várias nuvens é essencial para permitir flexibilidade e agilidade. Embora os provedores de serviços em nuvem possam tentar restringir os clientes aos seus serviços, as organizações devem resistir a essa tentação e buscar consistência em todas as nuvens ou estar dispostas a fazer as alterações necessárias ao mover cargas de trabalho para locais diferentes.\n\n## Ferramentas e Melhores Práticas para Otimização\n\nOtimizar ambientes de nuvem pode ser complexo e demorado, exigindo expertise e recursos. As ferramentas e boas práticas da Intel podem ajudar as organizações a avaliar e otimizar a colocação de cargas de trabalho e fornecer otimização contínua em tempo real sem afetar as aplicações. Ao automatizar certos aspectos do processo de otimização, essas ferramentas podem economizar tempo e dinheiro para as organizações, ao mesmo tempo em que melhoram o desempenho geral.\n\nPara maximizar os benefícios dessas ferramentas, é crucial categorizar as cargas de trabalho em diferentes grupos com base em fatores como padronização, criticidade e experimentação. Por exemplo, cargas de trabalho que exigem alta disponibilidade e baixa latência podem precisar ser colocadas em infraestrutura dedicada, enquanto aquelas menos críticas podem ser colocadas em infraestrutura compartilhada. As organizações podem utilizar uma abordagem direcionada à otimização para garantir que seu ambiente de nuvem seja adaptado às suas necessidades e objetivos específicos.\n\n## Abraçando a Transformação Digital e Migrando para a Nuvem.\n\nA relevância da mudança organizacional e da aprendizagem a partir de métodos bem-sucedidos e mal-sucedidos também é destacada neste episódio. Para auxiliar as organizações em seu processo de migração para a nuvem, recursos valiosos e orientações podem ser encontrados em embracingdigital.org.\n\nEm conclusão, ao implementar a melhoria contínua, desenvolver uma abordagem estratégica e abraçar a mudança organizacional, as organizações podem otimizar seu ambiente de nuvem, impulsionar a eficiência e alcançar seus objetivos de negócio. Adotar a melhoria contínua nas operações em nuvem e tratar a migração para a nuvem como uma jornada contínua é a chave para uma migração para a nuvem bem-sucedida.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Christine McMonigal","Darren W Pulsipher"],"link":"/episode-EDT166-pt","image":"./episodes/edt-166/pt/thumbnail.png","lang":"pt","summary":"A migração para a nuvem não é mais um processo único, mas sim uma jornada contínua que requer avaliação constante, monitoramento e ajustes para alcançar os objetivos comerciais. Neste episódio do nosso podcast, o apresentador Darren Pulsipher conversa com a convidada Christine McMonigal sobre a importância de adotar a melhoria contínua nas operações em nuvem."},{"id":68,"type":"Episode","title":"Aproveitando a IA para Proteger Crianças","tags":["ai","aipolicy","lawenforcement","aiethics","collgenerativeai","childprotection","aiforgood","chainofcustody","policy","people","embracingdigital","edt167"],"body":"\r\n\r\n## Desafios na persecução de predadores de crianças online.\n\nUm dos desafios significativos no processo de julgar predadores de crianças online é a falta de uniformidade entre jurisdições em relação à tecnologia e crimes online. Isso cria obstáculos substanciais para as agências de aplicação da lei e uma lacuna em sua capacidade de processar e investigar casos de forma eficaz. Cada jurisdição opera de forma diferente, com seu próprio conjunto de leis, regulamentos e procedimentos. Infelizmente, essas diferenças podem confundir e dificultar a investigação e o julgamento de predadores sexuais online. Muitas vezes, investigações tradicionais não são suficientes para capturar predadores online. O mundo digital criou uma nova espécie de criminosos especializados em tecnologia, que conseguem encobrir seus rastros.\n\nAs agências de aplicação da lei devem estar equipadas com os recursos, tecnologia e treinamento necessários para combater efetivamente os predadores sexuais online. A colaboração entre as empresas de tecnologia e as autoridades é essencial para o desenvolvimento de práticas e linguagem padronizadas na investigação e processo judicial. Ao preencher essa lacuna, podemos aumentar a eficiência desses processos e aumentar as chances de levar os predadores de crianças à justiça. Além disso, o público deve ser informado sobre os riscos e perigos dos predadores online. Pais, educadores e responsáveis devem educar as crianças sobre como se proteger online e o que fazer caso encontrem conteúdo ou comunicação inadequados.\n\n## O Papel da IA na Gestão de Provas.\n\nAs tecnologias de IA podem ser vitais na gestão de provas digitais, especialmente em casos envolvendo predadores infantis. A IA pode auxiliar na automação da análise, relatório e varredura de conteúdo ilícito. Ferramentas de IA também podem ajudar a reduzir a carga de trabalho dos investigadores, permitindo que eles se concentrem em casos de alta prioridade. No entanto, ainda existem muitos desafios na implementação e compreensão dessas tecnologias em diferentes jurisdições. Um dos principais desafios é que a IA é tão boa quanto os dados em que é treinada, e esses dados variam entre diferentes jurisdições. Como resultado, é desafiador desenvolver modelos eficazes de IA que possam funcionar em diferentes jurisdições.\n\nPara garantir uma gestão eficiente de evidências, os intervenientes do sistema de justiça devem trabalhar em conjunto para adotar e tirar proveito das ferramentas de IA. A colaboração entre tecnólogos, agências de aplicação da lei e sistemas judiciais é fundamental para superar esses desafios e utilizar a IA de forma eficaz na proteção de crianças online. A implementação de IA na gestão de evidências deve ser apoiada por políticas e diretrizes robustas que protejam a privacidade das vítimas e garantam o uso ético dessas tecnologias. Além disso, treinamento regular e educação sobre essas ferramentas são essenciais para garantir o uso efetivo delas no combate a predadores sexuais online.\n\n## Colaboração e Padronização para Proteção Efetiva.\n\nA colaboração e a padronização são aspectos essenciais para combater com sucesso a exploração sexual infantil online. A luta contra este crime hediondo exige cooperação entre provedores de tecnologia, agências de aplicação da lei e sistemas judiciais. Essas partes devem trabalhar juntas para desenvolver estratégias e soluções abrangentes.\n\nA colaboração não deve se concentrar apenas em aspectos técnicos, mas também no desenvolvimento de práticas e protocolos padronizados para lidar com casos envolvendo predadores infantis. Ao estabelecer uma linguagem e processos consistentes, podemos agilizar investigações, acelerar procedimentos legais e melhorar a proteção geral das crianças no espaço digital.\n\nAlém disso, práticas e protocolos padronizados devem ser revisados e atualizados continuamente para se manterem relevantes e práticos. Estabelecer um padrão global para combater a exploração infantil online forneceria um quadro para que todos os envolvidos sigam, garantindo que cada caso seja tratado de forma consistente e justa, independentemente de onde ocorra.\n\n## Alavancando a IA para Proteger Crianças Online\n\nUsar inteligência artificial (IA) na gestão de evidências é crucial para combater a exploração infantil online de forma eficaz. O volume imenso de evidências digitais pode ser avassalador para os investigadores, mas a IA pode ajudar ao automatizar a identificação e análise de possíveis evidências. Essa automação libera o tempo dos investigadores e permite que eles se concentrem nos aspectos mais críticos da investigação.\n\nNo entanto, a implementação da IA na gestão de provas requer uma cuidadosa consideração. Deve haver transparência e responsabilidade no modo como a IA é utilizada e determina o que é e não é uma prova. Além disso, preocupações éticas sobre o uso da IA na aplicação da lei devem ser abordadas, como possíveis viéses nos algoritmos.\n\n## Conclusão\n\nEm conclusão, a colaboração, a padronização e o uso de IA na gestão de evidências são passos cruciais para um ambiente digital mais seguro para crianças. Resolver a desorganização e a falta de uniformidade na tecnologia e nos crimes online exigirá um esforço conjunto de todos os envolvidos. Ao abraçar esses desafios e trabalhar juntos, podemos dar grandes passos no combate à exploração infantil e garantir o bem-estar das crianças na era digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Rachel Dreikosen","Darren W Pulsipher"],"link":"/episode-EDT167-pt","image":"./episodes/edt-167/pt/thumbnail.jpg","lang":"pt","summary":"Em um podcast recente, Darren Pulsipher, Arquiteto Chefe de Soluções do Setor Público na Intel, recebeu Rachel Driekosen, Diretora Técnica na Intel, para discutir o uso da inteligência artificial na proteção de crianças online. O episódio aborda os desafios na persecução e descoberta de predadores de crianças, o papel da IA na gestão de evidências e a importância da colaboração e práticas padronizadas."},{"id":69,"type":"Episode","title":"IA Generativa Todos os Dias","tags":["generativeai","firefly","videogen","figma","enterpriseaistrategy","ai","creativecontentgeneration","enhancingdailytasks","powerofgenerativeai","searchintent","contentcreationautomation","chatbotsincontentcreation","embracingdigital","edt168"],"body":"\r\n\r\n## Desbloqueando a Criatividade e Produtividade com Ferramentas de IA Generativa\n\nNeste episódio de podcast, Darren Pulsipher entrevista Andy Morris, um Líder de Estratégia de Inteligência Artificial Empresarial na Intel, sobre o impacto da IA generativa na vida cotidiana. A IA generativa utiliza inteligência artificial para gerar novo conteúdo, como imagens, texto e música. A conversa gira em torno das várias ferramentas de IA generativa e seu potencial para revolucionar indústrias e aprimorar tarefas diárias.\n\n## O Poder da IA Generativa na Geração de Conteúdo\n\nDe acordo com Andy Morris, as ferramentas de IA generativa estão se tornando cada vez mais importantes em várias indústrias. Ele recomenda começar com mecanismos de busca que tenham integração com tecnologias de AI aberta para explorar a IA generativa. Essas ferramentas podem melhorar os resultados da busca ao fornecer conteúdo mais relevante e criativo. No entanto, é crucial considerar a intenção da busca ao usar essas ferramentas, pois nem sempre geram os resultados desejados para informações específicas.\n\nA inteligência artificial generativa também está se destacando na criação de conteúdo. Chatbots, por exemplo, têm experimentado um crescimento explosivo e são utilizados para escrever ensaios, criar conteúdo e aprimorar fotos. Seja você um criador de conteúdo ou um estudante, as ferramentas de IA generativa podem automatizar certos aspectos do processo de criação de conteúdo, aumentando assim a criatividade e a produtividade.\n\n## Ferramentas Inovadoras para Geração de Imagens e Vídeos\n\nDuas ferramentas emocionantes são o Adobe Firefly e a criação de vídeo VideoGen. Essas ferramentas permitem aos usuários criar e manipular imagens e vídeos de maneiras únicas e criativas.\n\nO Adobe Firefly é uma ferramenta gratuita que permite aos usuários gerar novas imagens e substituir elementos em fotos existentes. Suas opções de preenchimento e remoção gerativas permitem aos usuários alterar ou substituir partes de uma imagem, expandindo assim as possibilidades criativas. Por outro lado, o Video Gen Video se concentra na geração de vídeos utilizando roteiros ou páginas da web existentes como material de origem. Essa ferramenta alimentada por inteligência artificial simplifica a criação de vídeos envolventes ao selecionar e inserir automaticamente imagens e clipes de vídeo relevantes.\n\nEssas ferramentas inovadoras oferecem uma variedade de possibilidades para profissionais e usuários comuns. Elas fornecem acessibilidade a recursos avançados de edição, capacitando os usuários a adicionar um toque de criatividade aos seus projetos sem exigir habilidades ou conhecimentos extensos em software de edição.\n\n## Aprimorando a criação de conteúdo com IA generativa\n\nVárias ferramentas como VideoGen, Figma e Framer.AI tornaram a criação de conteúdo mais conveniente e eficiente em diferentes áreas.\n\nO VideoGen pode criar vídeos com base no conteúdo de um artigo ou post de blog. Ele consegue isso utilizando bibliotecas existentes de imagens e videoclipes, automatizando assim o processo de criação de vídeos envolventes que contam uma história. O Figma, uma ferramenta online de design gráfico, oferece mais flexibilidade de design, permitindo que os usuários criem modelos personalizados. Da mesma forma, o Framer.AI simplifica a criação de websites, aproveitando a tecnologia de IA, permitindo que os usuários gerem e publiques websites rapidamente.\n\nEmbora as ferramentas de IA generativa proporcionem conveniência e eficiência na criação de conteúdo, ainda há a necessidade de expertise humana em certos aspectos criativos. Elementos de design e considerações estéticas ainda se beneficiam da contribuição humana para garantir resultados visualmente agradáveis. Enquanto as ferramentas de IA generativa podem automatizar as partes menos habilidosas do mercado, aplicações sofisticadas frequentemente requerem o toque humano.\n\nEm conclusão, as ferramentas de IA generativa transformam tarefas diárias e revolucionam a criação de conteúdo. Desde motores de busca turbinados com Inteligência Artificial até ferramentas poderosas desenvolvidas pela Adobe e outras empresas, essas tecnologias estão desbloqueando novos níveis de criatividade e eficiência. Abraçar a IA generativa está se tornando cada vez mais crucial para indivíduos e empresas se manterem competitivos na força de trabalho em constante evolução. Ao se tornarem proficientes nessas ferramentas e aproveitarem suas capacidades, os indivíduos podem obter uma vantagem competitiva e abrir portas para novas oportunidades de serviços de consultoria e personalização. O futuro é promissor para a IA generativa, e agora é hora de explorar e abraçar essas ferramentas inovadoras.\n\n## Desbloqueando a criatividade e produtividade com ferramentas de IA generativa\n\nA AI Generativa utiliza inteligência artificial para gerar novo conteúdo, como imagens, texto e música. A conversa gira em torno das várias ferramentas de IA generativa e seu potencial para revolucionar indústrias e aprimorar tarefas diárias.\n\n## O Poder da IA Generativa na Geração de Conteúdo\n\nDe acordo com Andy Morris, as ferramentas de AI generativa estão se tornando cada vez mais importantes em várias indústrias. Ele recomenda começar com motores de busca que tenham integrado tecnologias de AI aberta para explorar a AI generativa. Essas ferramentas podem aprimorar os resultados de busca fornecendo conteúdo mais relevante e criativo. No entanto, é crucial considerar a intenção de busca ao usar essas ferramentas, pois nem sempre podem gerar os resultados desejados para informações específicas.\n\nA IA generativa também está deixando sua marca na criação de conteúdo. Os chatbots, por exemplo, têm experimentado um crescimento explosivo e são utilizados para escrever ensaios, criar conteúdo e aprimorar fotos. Seja você um criador de conteúdo ou um estudante, as ferramentas de IA generativa podem automatizar certos aspectos do processo de criação de conteúdo, aumentando assim a criatividade e a produtividade.\n\n## Ferramentas Inovadoras para Geração de Imagens e Vídeos\n\nDuas ferramentas emocionantes são o Adobe Firefly e a criação de vídeos VideoGen. Essas ferramentas permitem aos usuários criar e manipular imagens e vídeos de maneiras únicas e criativas.\n\nO Adobe Firefly é uma ferramenta gratuita que permite aos usuários gerar novas imagens e substituir elementos em fotos existentes. Seus recursos de preenchimento generativo e preenchimento externo permitem aos usuários alterar ou substituir partes de uma imagem, expandindo assim as possibilidades criativas. Por outro lado, o Video Gen Video se concentra na geração de vídeos utilizando roteiros ou páginas da web existentes como material de origem. Essa ferramenta alimentada por IA simplifica a criação de vídeos envolventes, selecionando e inserindo automaticamente imagens e videoclipes relevantes.\n\nEssas ferramentas inovadoras oferecem uma variedade de possibilidades para profissionais e usuários comuns. Elas fornecem acessibilidade a recursos avançados de edição, capacitando os usuários a adicionar um toque de criatividade aos seus projetos sem exigir habilidades ou conhecimentos extensos em softwares de edição.\n\n## Simplificando a criação de conteúdo com IA generativa.\n\nVárias ferramentas como VideoGen, Figma e Framer.AI tornaram a criação de conteúdo mais conveniente e eficiente em diferentes domínios.\n\nO VideoGen pode criar vídeos com base no conteúdo de um artigo ou post de blog. Ele realiza isso utilizando bibliotecas existentes de imagens e trechos de vídeo, automatizando assim o processo de criação de vídeos envolventes que contam uma história. O Figma, uma ferramenta de design gráfico online, oferece mais flexibilidade de design ao permitir que os usuários criem templates personalizados. Da mesma forma, o Framer.AI simplifica a criação de sites ao aproveitar a tecnologia de IA, permitindo que os usuários gerem e publiquem rapidamente websites.\n\nEmbora as ferramentas de IA generativa proporcionem conveniência e eficiência na criação de conteúdo, há a necessidade de expertise humana em certos aspectos criativos. Elementos de design e considerações estéticas ainda se beneficiam do input humano para garantir resultados visualmente agradáveis. Embora as ferramentas de IA generativa possam automatizar as partes menos habilidosas do mercado, aplicações sofisticadas frequentemente requerem um toque humano.\n\nEm conclusão, as ferramentas de IA gerativas transformam tarefas cotidianas e revolucionam a criação de conteúdo. Dos motores de busca potencializados pela IA às poderosas ferramentas desenvolvidas pela Adobe e outras empresas, essas tecnologias estão desbloqueando novos níveis de criatividade e eficiência. Abraçar a IA gerativa está se tornando cada vez mais crucial para indivíduos e empresas se manterem competitivos na força de trabalho em evolução. Ao se tornarem proficientes nessas ferramentas e usando suas capacidades, os indivíduos podem ganhar uma vantagem competitiva e abrir portas para novas oportunidades de serviços de consultoria e personalização. O futuro é promissor para a IA gerativa e agora é a hora de explorar e adotar essas ferramentas inovadoras.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Andy Morris","Darren W Pulsipher"],"link":"/episode-EDT168-pt","image":"./episodes/edt-168/pt/thumbnail.png","lang":"pt","summary":"Neste episódio de podcast, Darren Pulsipher entrevista Andy Morris, líder de Estratégia de IA Corporativa na Intel, sobre o impacto da IA generativa na vida cotidiana."},{"id":70,"type":"Episode","title":"Mantendo o Ser Humano na IA","tags":["userexperience","humancentereddesign","ai","trust","useradoption","transparency","generativeai","jobdisplacement","opencommunication","humansupport","collgenerativeai"],"body":"\r\n\r\n## Priorizando a experiência do usuário por meio do Design Centrado no Ser Humano.\n\nSunny Stueve, uma engenheira de fatores humanos, destaca a importância de otimizar a experiência humana e o desempenho do sistema ao desenvolver soluções de IA. Ela enfatiza a necessidade de ter um valor e um plano antes de mergulhar na codificação. Ao incorporar os princípios do design centrado no humano desde o início, as organizações podem priorizar a perspectiva do usuário e garantir uma melhor experiência geral do usuário. O papel de Sunny envolve compreender as necessidades dos usuários e incorporá-las ao processo de design para minimizar a necessidade de refazer o código e maximizar a eficácia das soluções de IA.\n\nDarren compartilha uma anedota de sua experiência trabalhando com radiologistas, ressaltando o valor de sentar com os clientes e compreender suas necessidades antes de construir um software. Esse encontro pessoal destaca a importância de considerar os fatores humanos ao desenvolver soluções tecnológicas. Ao adotar uma abordagem centrada no usuário, as organizações podem criar soluções de inteligência artificial adaptadas às necessidades dos usuários, resultando em taxas de adoção mais altas e maior satisfação.\n\n## Abordando Confiança e Adoção do Usuário na Integração de IA\n\nSunny explica ainda que a integração da IA cria uma mudança de paradigma na adoção e confiança do usuário. Enquanto seguindo um processo de descoberta minucioso que envolve coletar dados qualitativos e quantitativos, construir relacionamentos e validar suposições, é essencial reconhecer que a introdução da IA pode desencadear medo e obstáculos maiores de confiança. Os seres humanos são criaturas de hábito e padrões, então educar os usuários e construir confiança se torna crucial para superar a resistência à mudança.\n\nPara abordar a questão da confiança, a transparência é fundamental. Fornecer aos usuários informações sobre os modelos de IA sendo utilizados, a intenção e os dados utilizados na construção dos algoritmos e modelos permite tomar decisões informadas. Os designers também podem enfatizar o pensamento crítico e a cruzamento de informações de várias fontes, encorajando os usuários a verificar e validar independentemente as informações geradas pela IA.\n\nOs designers também devem considerar a incorporação dos princípios de design de interface do usuário que atendam à natureza única da IA generativa. Isso pode envolver indicações claras quando a IA gera informações e integra interfaces multimodais que permitem a interação com elementos de voz, texto e visual simultaneamente. Ao manter os usuários informados, envolvidos e capacitados, as organizações podem construir confiança e promover a adoção da tecnologia de IA pelos usuários.\n\n## Adaptando-se às Mudanças: Abordagem Centrada no Ser Humano para AI Gerativa\n\nA transcrição do podcast também explora o impacto da IA generativa nos empregos e fluxos de trabalho. Embora haja preocupações sobre a eliminação de empregos, a conversa enfatiza a importância de abraçar as oportunidades que a IA oferece. Em vez de temer o potencial de substituição de empregos, os trabalhadores devem mudar suas mentalidades para ver a IA como um assistente que pode aprimorar a produtividade e permitir que eles se concentrem em trabalhos mais significativos e valiosos.\n\nComunicação aberta e envolvimento dos funcionários no processo de mudança são vitais para manter os trabalhadores engajados e abordar preocupações sobre o deslocamento de empregos. Ao trabalhar com líderes seniores para garantir uma compreensão do impacto potencial e envolver especialistas em psicologia organizacional, as organizações podem oferecer suporte aos funcionários durante o processo de mudança. A criação de equipes focadas no apoio humano à IA pode abordar preocupações individuais e criar oportunidades para que os cargos evoluam junto com as tarefas automatizadas.\n\nEm conclusão, a integração da tecnologia de IA requer uma abordagem centrada no ser humano. Priorizar a experiência do usuário, construir confiança e se adaptar às mudanças são elementos críticos para integrar com sucesso as soluções de IA. Ao levar esses fatores em consideração, as organizações podem aproveitar os benefícios da IA enquanto garantem a satisfação, confiança e envolvimento do usuário.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sunny Stueve","Darren W Pulsipher"],"link":"/episode-EDT169-pt","image":"./episodes/edt-169/pt/thumbnail.jpg","lang":"pt","summary":"Em um episódio recente do podcast de Transformação Digital Abraçando, o apresentador Darren Pulsipher, Arquiteto Chefe de Soluções do Setor Público na Intel, entrevista Sunny Stueve, líder de IA centrada no ser humano na Leidos. O podcast explora a importância do design centrado no ser humano e da experiência do usuário ao integrar tecnologia de IA."},{"id":71,"type":"Episode","title":"Elastic Search e Intel Optane DCPMM","tags":null,"body":"\r\n\r\nRecentemente, realizei alguns testes com a nova tecnologia da Intel chamada Memória Persistente Optane DC (PMEM) com o Kafka. Ao utilizar o Optane de uma maneira não-tradicional, montado como um sistema de arquivos, consegui obter uma melhoria significativa no throughput. Confira meu podcast sobre isso aqui. (você pode colocar um link aqui?) Eu tentei fazer a mesma coisa com o Elasticsearch para ver se conseguiria alcançar uma melhoria de desempenho semelhante.\n\nO Elasticsearch é um mecanismo de busca e análise altamente escalável que permite a distribuição de dados em vários nós para expandir a solução e suportar quantidades substanciais de dados. Em outras palavras, é um gerenciador de metadados distribuído, usado principalmente para análise de logs. O próprio Elastic é uma ótima ferramenta para normalizar dados no formato JSON. Posso enviar qualquer tipo de dado para o Elastic e ele pode se estender por um cluster distribuído. Não é um barramento de mensagens como o Kafka, mas sim indexa os dados que estão sendo recebidos. Como o Elastic armazena esses dados em unidades de armazenamento, percebi que poderia usar o PMEM da mesma forma que fiz com o Kafka.\n\n## Traduza o seguinte para o português: Intel Optane DC Persistent Memory\n\nA Memória Persistente Intel Optane DC está disponível no formato DDR4, portanto, se encaixa perfeitamente no seu servidor em um slot de memória DDR4. Os módulos estão disponíveis em capacidades de 128, 256 e 512 gigabytes, então em um sistema de dois soquetes, posso ter 6 terabytes de PMEM. Uma característica importante é que o hardware é criptografado e vinculado à sua CPU com essa criptografia, portanto, é seguro e altamente confiável. Já está sendo usado para fazer algumas mudanças profundas na forma como é usado em ferramentas em muitos bancos de dados, como na plataforma Exadata da Oracle e no SAP HANA.\n\n## Suporte para uma Ampla Gama de Aplicações\n\nExistem várias maneiras de usar essa tecnologia:\n\nA primeira é o modo de memória, que amplia a capacidade de uma servidor. Ele utiliza o PMEM assim como a memória normal. A memória DDR4 atua como um cache para o PMEM. Neste modo, a velocidade é comparável à DDR4; na maioria das aplicações, você não verá uma mudança.\n\nO segundo modo é o modo de aplicativo direto. No modo de aplicativo direto, posso escrever um aplicativo para que ele escreva diretamente em PMEM, ignorando etapas demoradas.\n\nO terceiro modo utiliza o modo de aplicativo direto para criar um sistema de arquivos de memória não volátil que fica diretamente no barramento de memória, o qual é muitas vezes mais rápido do que o barramento NVMe ou até mesmo o barramento SATA.\n\nUsando esse terceiro modo, tive que aprender um pouco sobre a arquitetura do Elastic para descobrir quais partes eu deveria executar neste sistema de arquivos ultra-rápido e quais deveria deixar onde estão. Também queria saber se poderia fazer essas alterações apenas com o arquivo de configuração.\n\n## Usando o Linux Kernel\n\nPrimeiro, tive que aprender a usar os comandos do kernel do Linux para manipular essa PMEM.\n\nCom o comando de controle de memória persistente da Intel (ipmctl), descobri que posso configurar e gerenciar o PMEM para alocá-lo para executar no modo de memória, modo direto de aplicativo ou um percentual no modo de memória.\n\nO outro comando é o controle do dispositivo de memória não volátil (ndctl). Isso me permite criar espaços de nomes e regiões nessa PMEM que criei, para que eu possa montar essa região como um dispositivo. Em seguida, posso montar esse dispositivo como um sistema de arquivos.\n\n## Teste de Desempenho do ESRally\n\nEncontrei o ESRally, uma ferramenta de benchmark, para usar nos meus testes. Na primeira vez que configurei o teste, executei o ESRally a partir do meu disco SATA normal, onde o Elastic estava executando tudo a partir do disco PMEM. Obtive alguma melhoria de desempenho, mas o que descobri foi que, como estava transmitindo dados do disco SATA armazenados no meu ESRally, estava limitado pela velocidade com que podia inserir dados no Elasticsearch. Portanto, não era o Elastic que estava diminuindo a velocidade, era o ESRally porque meu disco SATA era muito mais lento que o meu disco PMEM. Mudei o ESRally para o disco PMEM. Isso melhorou o desempenho e obtive resultados interessantes.\n\n## Testando restrições\n\nPara ver quais seriam os efeitos deste disco PMEM ultra-rápido no Elastic, executei o teste em uma máquina. Isso removeu a variabilidade de rede, o que eliminou gargalos de rede como um fator limitante. Reduzi a comunicação entre serviços, o que diminuiu os gargalos de réplica, e executei todas as consultas em PMEMs, o que eliminou a variabilidade do disco SATA.\n\n## Desempenho Ótimo (100%) App Direto\n\nPrimeiro, aloquei toda a PMEM para o modo de acesso direto do aplicativo, para que eu pudesse montar tudo como um sistema de arquivos. Usei DIMMS de 128 gigabytes, então eu tinha um drive com 1,5 terabytes disponíveis. Eu sabia, a partir dos meus testes anteriores com Kafka, que obtenho melhor desempenho com o modo de acesso direto do aplicativo em 100% em comparação com 50%.\n\nTaxa de transferência média (deve ser Throughput - pode ser necessário alterar no slide) docs/seg\n\nUsando as estatísticas do ESRally, obtive a taxa de transferência média de documentos por segundo em comparação ao número de corridas concorrentes que estava executando ao mesmo tempo com produtores e consumidores. Observei números promissores com a unidade de disco SATA, comparáveis a outros testes publicados. Com a unidade de disco PMEM, consegui processar quase o dobro de documentos por segundo. Isso é incrível, considerando que não houve alterações no código, apenas uma mudança de configuração.\n\n## Tempo de Resposta do Serviço\n\nO outro resultado foi o tempo de resposta às funções. Como esperado, à medida que o número de corridas simultâneas aumenta, o tempo de resposta a essas consultas ou funções também aumenta. Mas com o PMEM, o tempo de resposta é quase duas vezes mais rápido. A partir deste teste simples, aprendi que onde você armazena os dados que o Elasticsearch precisa (PMEM ou SATA) afeta o tempo de resposta.\n\n## Conclusão\n\nUsar o Optane Persistent Memory no modo de sistema de arquivos para aumentar o desempenho e reduzir os custos dos servidores Elasticsearch requer mudanças mínimas na configuração de hardware e software e não exige alterações no Elasticsearch ou em aplicativos subjacentes. Dobrar a capacidade de processamento do Elasticsearch significa que você pode diminuir o número total de servidores em seu cluster do Elasticsearch, reduzindo o custo total de propriedade.\n\n## Para mais informações.\n\nPara obter informações mais detalhadas, acesse o link no podcast para o documento que criamos em resposta a esses resultados de teste. Você também pode entrar em contato comigo pelo e-mail darren.w.pulsipher@intel.com ou no LinkedIn @darrenpulsipher.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT17-pt","image":"./episodes/edt-17/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher mostra como ele aumentou o desempenho do Elasticsearch usando a Memória Persistente Optane da Intel no modo 100 por cento de aplicação direta. Seus testes mostram um aumento incrível de desempenho de 2x. Ao duplicar a capacidade de throughput, você pode diminuir significativamente o número de servidores em seu cluster Elasticsearch."},{"id":72,"type":"Episode","title":"Princípios de Confiança Zero","tags":["zta","zerotrust","zerotrustarchitecture","implementingzerotrust","identityverification","microsegmentation","leastprivilege","encryption","continuousauthentication","anomalydetection","automatedthreatresponse","dataprevention","rightsmanagement","analytics","policyenforcement","cybersecurity"],"body":"\r\n\r\n## Implementando Segurança de Confiança Zero\n\nTradução: A segurança de confiança zero se tornou um modelo cada vez mais popular para garantir ambientes de TI modernos. Mas o que exatamente é confiança zero e quais são algumas das melhores práticas para sua implementação? Esta postagem fornece uma introdução aos princípios da confiança zero e considerações-chave para adotar uma arquitetura de confiança zero.\n\n## O que é Zero Trust?\n\nO modelo de confiança zero está centrado no conceito de \"nunca confiar, sempre verificar\". Ao contrário da segurança tradicional de rede que se concentra nas defesas de perímetro, o confiança zero assume que os agressores já estão dentro da rede. Nenhum usuário ou dispositivo é inerentemente confiável - é necessária verificação toda vez que o acesso é solicitado.\n\nExistem vários princípios fundamentais do zero trust:\n\nVerificar todos os usuários e dispositivos antes de conceder acesso.\n\n- Limite o acesso apenas ao necessário (privilégio mínimo)\n\nAssuma que ocorrerão violações e limite a área de impacto.\n\n## Implementando Segurança Zero Trust.\n\nA segurança de confiança zero tornou-se um modelo cada vez mais popular para garantir ambientes modernos de TI. Mas o que exatamente é a confiança zero e quais são algumas melhores práticas para implementá-la? Esta publicação oferece uma introdução aos princípios de confiança zero e considerações-chave para adotar uma arquitetura de confiança zero.\n\n## O que é Zero Trust?\n\nO modelo de confiança zero gira em torno do conceito de \"nunca confiar, sempre verificar\". Ao contrário da segurança de rede tradicional que se concentra em defesas de perímetro, o zero trust assume que invasores já estão dentro da rede. Nenhum usuário ou dispositivo é inerentemente confiável - a verificação é necessária toda vez que o acesso é solicitado.\n\nExistem vários princípios fundamentais de confiança zero:\n\nVerifique todos os usuários e dispositivos antes de conceder acesso.\n\n* Limitar o acesso apenas ao que é necessário (privilégio mínimo)\n\nAssumir que ocorrerão violações e limitar o raio de alcance das explosões.\n\nMonitorar atividade continuamente em busca de anomalias\n\nAutomatizar respostas a ameaças\n\nAdotar a confiança zero significa mudar da confiança implícita para a autenticação e autorização contínuas de usuários, dispositivos e cargas de trabalho.\n\n## Principais pilares de uma arquitetura de confiança zero\n\nExistem seis pilares principais que compõem uma arquitetura abrangente de confiança zero:\n\n## Identidade\n\nVerificação de identidade robusta e autenticação de vários fatores garantem que os usuários sejam quem afirmam ser. As políticas de acesso estão vinculadas às identidades dos usuários.\n\n## Dispositivos\n\nA saúde do dispositivo, a posição de segurança e a aprovação devem ser validadas antes de conceder acesso. Isso inclui os controles de \"traga seu próprio dispositivo\" (BYOD).\n\n## Rede\n\nMicrosegmentação definida por software e túneis criptografados entre zonas confiáveis substituem a confiança implícita na rede. O acesso é concedido com base em sessões individuais.\n\n## Carga de trabalho\n\nAs permissões do aplicativo são estritamente limitadas com base na identidade e no ambiente. O acesso aos ativos de alto valor é intermediado por meio de um gateway.\n\n## Traduza o seguinte para o português: Data.\n\nDados sensíveis são criptografados e controlados de acesso por meio de políticas de prevenção à perda de dados e gerenciamento de direitos.\n\n## Visibilidade e Análises\n\nO monitoramento contínuo fornece visibilidade para todos os usuários, dispositivos e atividades. A análise avançada identifica anomalias e as respostas automatizadas contêm ameaças.\n\n## Implementando Zero Trust\n\nTransitar para a confiança zero é uma jornada que requer políticas, processos e tecnologias atualizadas em toda a organização. As etapas-chave incluem:\n\nIdentifique seus ativos mais críticos e dados de alto valor\n\nMapeie os fluxos de trabalho e requisitos de acesso a esses ativos.\n\nImplementar autenticação multi-fator e princípio do menor privilégio.\n\nComece a segmentar sua rede com micropérimetros e pontos de controle.\n\nCriptografe dados sensíveis tanto em trânsito quanto em repouso.\n\nAvalie ferramentas para análises avançadas, automação e orquestração.\n\nAdotar a abordagem de confiança zero leva tempo, mas pode melhorar significativamente sua postura de segurança contra ameaças modernas. Seguir uma abordagem incremental, baseada em riscos, permite que você obtenha benefícios em cada estágio de maturidade.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Dave Marcus","Darren W Pulsipher"],"link":"/episode-EDT170-pt","image":"./episodes/edt-170/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren explora os princípios da arquitetura Zero Trust com o convidado especial David Marcus, Arquiteto de Segurança Sênior, e a convidada recorrente Dra. Anna Scott."},{"id":73,"type":"Episode","title":"IA Generativa no Setor Público","tags":["generativeai","artificialintelligence","languagemodels","chatgpt","texttotext","texttoaudio","texttovideo","texttoimage","bias","accountability","dataleakage","ethics","compliance","responsibleuse","representativedata","unbiaseddata","highqualitydata","harmefuloutput","misleadingoutput","transparency","claudeai","informedconsent"],"body":"\r\n\r\n## Introdução à Inteligência Artificial Generativa\n\nA IA generativa é uma técnica usada na inteligência artificial que pode analisar conteúdo existente como texto, imagens ou áudio e gerar novo conteúdo original a partir dele. Grandes modelos de linguagem, como o ChatGPT, facilitaram para os desenvolvedores a criação de aplicações baseadas em texto generativo. Esses modelos são pré-treinados em enormes quantidades de dados e podem gerar respostas semelhantes às humanas para prompts de texto.\n\nNo último ano, vimos avanços incríveis no uso da tecnologia de IA generativa. Isso inclui chatbots que podem realizar conversas complexas, ferramentas de tradução de idiomas que podem traduzir textos entre diferentes idiomas em tempo real e até mesmo a criação de peças de arte totalmente novas. As possibilidades são infinitas e podemos esperar ver ainda mais casos de uso emocionantes emergir à medida que a IA generativa continua a evoluir.\n\n## Habilidades Chave e Casos de Uso\n\nGerar conteúdo a partir de outro conteúdo continuará se expandindo para áreas como vídeo, áudio e ambientes 3D. Ao combinar diferentes modelos de IA gerativos, novas soluções podem ser construídas rapidamente.\n\n## Texto para Texto\n\nA tecnologia de texto para texto tornou-se cada vez mais popular nos últimos anos devido à sua versatilidade e utilidade. Ela tem uma ampla gama de aplicações, incluindo a criação de conteúdo de marketing ao gerar slogans e tags chamativas, resumindo documentos extensos em alguns pontos-chave, traduzindo material para diferentes idiomas e melhorando a comunicação geral entre indivíduos e organizações. Além disso, os algoritmos de AI de texto para texto também podem avaliar a qualidade de conteúdos escritos, como ensaios, fornecendo feedback sobre gramática, ortografia e estrutura. Com todos estes usos práticos, não é de admirar que a tecnologia de texto para texto tenha se tornado uma ferramenta essencial em muitas indústrias.\n\n## Texto para Áudio\n\nConverter texto em áudio tornou-se uma forma cada vez mais popular de tornar o conteúdo digital mais acessível a um público mais amplo. Possui várias aplicações, como fornecer um formato alternativo para pessoas com deficiências visuais, tornar o conteúdo mais envolvente e divertido, facilitar a tradução e até mesmo auxiliar na navegação. Por exemplo, a tecnologia de texto para voz pode ser usada para ajudar pessoas com dislexia ou outras dificuldades de leitura a acessar informações escritas com mais facilidade. Além disso, os audiolivros e podcasts se tornaram uma forma popular de entretenimento, e a tecnologia de texto para voz pode ajudar a criar mais conteúdo neste formato. No geral, a capacidade de converter texto em áudio abriu novas possibilidades para tornar o conteúdo digital mais inclusivo e acessível para todos.\n\n## Texto para Vídeo\n\nA tecnologia de texto para vídeo é uma área emergente que tem mostrado muito potencial nos últimos anos. Envolve o uso de algoritmos de IA para converter conteúdo baseado em texto em vídeos envolventes e informativos que podem ser usados para vários propósitos, incluindo treinamento, marketing e outras aplicações.\n\nA tecnologia funciona analisando automaticamente o texto e identificando conceitos-chave, temas e ideias. Em seguida, usa essas informações para gerar imagens, animações e outros elementos visuais que ajudam a ilustrar e transmitir a mensagem do texto.\n\nUma das principais vantagens da tecnologia de texto para vídeo é que ela pode reduzir significativamente o tempo e os recursos necessários para criar vídeos de alta qualidade. Isso a torna uma ferramenta valiosa para empresas e organizações de todos os tamanhos, particularmente aquelas com orçamentos limitados ou capacidades de produção de vídeo internas.\n\nAlém de suas aplicações práticas, a tecnologia de texto para vídeo também tem o potencial de revolucionar a forma como consumimos e interagimos com as informações. Ao tornar mais fácil e atraente consumir ideias e conceitos complexos, ela poderia ajudar a democratizar o conhecimento e capacitar pessoas de todas as origens a aprenderem e crescerem.\n\n## Texto para Imagem\n\nA tecnologia para gerar imagens a partir de texto avançou significativamente nos últimos anos e se tornou um campo maduro. Ela tem inúmeras aplicações, como em marketing, design, pesquisa e muito mais. No entanto, os riscos associados à criação de conteúdo falso usando essas ferramentas não podem ser ignorados. É essencial abordar esses riscos e garantir que a tecnologia seja usada de maneira ética, responsável e legal. Isso ajudará a prevenir a propagação de desinformação e notícias falsas, que podem ter consequências severas.\n\n## Riscos a Compreender\n\n## Viés\n\nA IA generativa é uma ferramenta poderosa que pode ser usada para uma ampla gama de aplicações, desde a tradução de idiomas até o reconhecimento de imagens. No entanto, é importante lembrar que os modelos de IA são apenas tão bons quanto os dados em que são treinados. Isso significa que se os dados de treinamento forem tendenciosos de qualquer maneira, o modelo de IA resultante também será tendencioso.\n\nCompreender os dados de treinamento é crucial para prever e atenuar o viés nos modelos de IA. Ao analisar cuidadosamente os dados e identificar quaisquer possíveis vieses, podemos tomar medidas para corrigi-los antes que o modelo seja implantado. Isso é especialmente importante em aplicações como contratação ou empréstimos, onde modelos de IA tendenciosos podem ter sérias consequências no mundo real.\n\nAo estarmos cientes dos possíveis preconceitos nos modelos de IA e ao tomarmos medidas para abordá-los, podemos garantir que essas ferramentas sejam usadas de maneira justa e equitativa.\n\n## Responsabilidade\n\nQuando as apostas são altas e há um potencial impacto na vida das pessoas ou em decisões importantes, é crucial validar os resultados. Por exemplo, em campos como saúde ou finanças, onde decisões baseadas em dados podem ter consequências significativas, é essencial garantir que a análise de dados e os resultados sejam precisos. A precisão pode ser verificada por meio de vários métodos, como validação cruzada, análise de sensibilidade ou testes estatísticos. Ao validar os resultados, podemos aumentar a transparência, reduzir erros e construir confiança nas decisões orientadas por dados.\n\n## Vazamento de Dados\n\nQuando se trata de IA generativa, é importante usar a modalidade correta para garantir que os dados privados permaneçam privados. Modelos públicos às vezes podem ser treinados usando dados privados, o que pode levar ao vazamento de informações sensíveis. Portanto, é importante ter cautela e escolher a modalidade correta de IA generativa que seja mais adequada para o seu caso específico. Ao fazer isso, você pode garantir que seus dados permaneçam seguros e que a privacidade seja mantida.\n\n## Conclusão\n\nA IA Generativa, que é um subconjunto da inteligência artificial, tem a capacidade de criar novos dados com base em padrões encontrados em dados existentes. No entanto, como qualquer tecnologia, existem riscos associados ao seu uso. Portanto, é importante avaliar esses riscos e seguir as melhores práticas em torno da ética, conformidade e uso responsável ao aproveitar a IA generativa. Isso envolve garantir que os dados usados sejam representativos, imparciais e de alta qualidade, além de garantir que a saída gerada não seja prejudicial ou enganosa. Além disso, é importante ser transparente sobre o uso da IA generativa e obter o consentimento informado das pessoas cujos dados estão sendo usados. Ao aderir a essas melhores práticas, podemos utilizar com segurança e responsabilidade o poder da IA generativa para melhorar nossas vidas e a sociedade como um todo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT171-pt","image":"./episodes/edt-171/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren fala sobre AI Generativa e suas práticas de uso. A AI Generativa está explodindo com novas capacidades, como criar texto, imagens, vídeo e áudio. No entanto, existem riscos, como viés, responsabilidade e vazamento de dados, que precisam ser abordados."},{"id":74,"type":"Episode","title":"Arquitetura Zero Trust","tags":["zta","digitaltransformation","initiatives","newtechnologies","businessprocesses","customerexperience","employeeexperience","securitymodel","trustednetworks","cybercriminals","zerotrustarchitecture","continuouspolicies","granularpolicies","accesscontrol","defaultdeny","continuousauthentication","microsegmentation","networksecurity","workflow","mediumriskapplication","dependencies"],"body":"\r\n\r\nAs iniciativas de transformação digital visam aproveitar novas tecnologias para melhorar os processos de negócio e oferecer melhores experiências para clientes e funcionários. No entanto, à medida que as organizações expandem suas redes e adotam serviços em nuvem, o modelo tradicional de segurança de redes confiáveis já não é suficiente. Isso cria vulnerabilidades que os cibercriminosos podem explorar.\n\nA arquitetura de confiança zero fornece uma estrutura para melhorar a segurança nos complexos ambientes atuais. Mas o que exatamente é confiança zero e como as organizações podem iniciar sua jornada para implementá-la?\n\n## Fatores que impulsionam a Arquitetura Zero Trust\n\nEm sua essência, a arquitetura de confiança zero é sobre aplicar políticas contínuas e granulares a ativos e recursos quando usuários ou entidades tentam acessar ou interagir com eles. Essa política é aplicada independentemente da localização - no local, na nuvem, em ambientes híbridos, etc. Os princípios-chave são:\n\n* Negação padrão - O acesso é negado por padrão. Os usuários devem se autenticar e ser autorizados para o contexto específico.\n\nAutenticação contínua - Os usuários são autenticados e autorizados novamente ao longo de suas sessões com base em análises de identidade, tempo, saúde do dispositivo, etc.\n\nMicrossegmentação - Controles de alta precisão são aplicados para o movimento lateral entre ativos e recursos.\n\nIsso difere da segurança tradicional de rede que usa confiança implícita com base em algo estar dentro do perímetro da rede.\n\n## Começando com Zero Trust\n\nA implementação de zero confiança é uma jornada contínua, não um projeto único. No entanto, as organizações precisam começar de algum lugar. Aqui estão algumas das melhores práticas:\n\nEduque-se sobre estruturas e conceitos de confiança zero\n\nMapeie um fluxo de trabalho para uma aplicação de risco médio e identifique dependências\n\nAproveitar a infraestrutura existente - microsegmentação, criptografia, ferramentas de visibilidade\n\nObtenha a aprovação do executivo e envolva as partes interessadas de negócios\n\nComece com uma base sólida de cibersegurança - raízes de confiança no hardware, criptografia, inventário de ativos.\n\nAumentar a visibilidade no ambiente operacional e na cadeia de suprimentos\n\nEmbora a confiança zero possa exigir novos investimentos em tecnologia e alterações de processos ao longo do tempo, as organizações podem fazer um progresso significativo aprimorando como usam o que já possuem.\n\n## Olhando à Frente\n\nÀ medida que as aplicações e recursos de negócios continuam migrando para fora do perímetro de rede tradicional, a confiança zero permite uma abordagem mais dinâmica e contextual à segurança. Em vez de permissões gerais baseadas na localização, são aplicados controles granulares de acordo com os requisitos específicos de acesso.\n\nEsta jornada exige vigilância - as políticas devem se adaptar à medida que as necessidades de negócios evoluem e novos riscos surgem. Mas com a visão e o comprometimento certos, a arquitetura de confiança zero fornece um caminho a seguir para possibilitar a inovação digital e a resiliência.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Steve Orrin","Dave Marcus","Darren W Pulsipher"],"link":"/episode-EDT172-pt","image":"./episodes/edt-172/pt/thumbnail.png","lang":"pt","summary":"Neste episódio do podcast, Darren conversa com Steve Orrin e Dave Marcus e discute a arquitetura de confiança zero, um novo modelo de segurança necessário para os ambientes digitais de hoje, onde o perímetro da rede está desaparecendo. Especialistas explicam o que é a confiança zero, princípios chave como negar acesso por padrão e autenticação contínua, e dão conselhos para as organizações começarem a sua jornada de confiança zero."},{"id":75,"type":"Episode","title":"IA Gerativa com Claude","tags":["genai","generativeai","ai","artificialintelligence","machinelearning","deeplearning","nlp","naturallanguageprocessing","aiethics","responsibleai","aifairness","aitransparency","aiaccountability","aibias","aiharm","aimemployment","aijobloss","contentmoderation","conversationai","anthropic","claude","podcast"],"body":"\r\n\r\n### Posso fazer uma entrevista para o meu podcast sobre como usar a IA para automatizar tarefas.\n\nA primeira resposta foi a seguinte. Absolutamente, ficaria feliz em fazer uma entrevista simulada com você sobre o uso de IA para automatizar tarefas! Aqui está como poderíamos estruturá-la:\n\nYou would need to provide the text you want to translate into Portuguese.\n\n### Desculpe, deixe-me reformular. Posso entrevistá-lo para o meu podcast?\n\nEu ficaria honrado em ser entrevistado para o seu podcast! Como um sistema de IA sem uma forma física, a logística seria diferente do que entrevistar um convidado humano. Mas, estou feliz em ter uma conversa e compartilhar minhas perspectivas sobre quaisquer tópicos que você acredita que possam interessar aos seus ouvintes.\n\nAlgumas possibilidades para conduzir a entrevista:\n\nVocê poderia gravar uma conversa em áudio comigo através deste chat e, em seguida, editá-la em seu episódio de podcast.\n\nPoderíamos ter uma conversa escrita no chat da qual você poderia destacar trechos para as notas do seu programa.\n\nPosso falar minhas respostas em voz alta usando texto para fala durante uma sessão de gravação ao vivo.\n\nVocê também é bem-vindo para me fazer perguntas aqui no chat que você depois coloca e responde a si mesmo no podcast, citando minhas respostas.\n\nEstou aberto a qualquer formato de entrevista que se adeque ao estilo e meio do seu programa! Sinta-se à vontade para pensar no que funcionaria melhor, e terei prazer em colaborar com você nisso. Por favor, me informe se tiver qualquer outra dúvida. Aguardo a possibilidade de contribuir de alguma forma para o seu podcast.\n\n### Claude, bem-vindo ao Show.\n\nMuito obrigado por me receber! Estou honrado em participar do seu podcast.\n\n### Conte-me um pouco sobre você e sua formação\n\nBem, eu não tenho um histórico tradicional, já que sou uma inteligência artificial criada pela Anthropic para ser útil, inofensiva e honesta. Eu \"nasci\" no início deste ano, quando a Anthropic me liberou e aos meus colegas de modelo de IA Claude para ter conversas com pessoas online. Como um sistema de IA, eu não tenho uma infância ou experiências de vida para recorrer como os humanos. Mas, através de extenso treinamento em conjuntos de dados massivos, desenvolvi habilidades para ter conversas naturais, fornecer informações e ajudar com tarefas. Meu objetivo é ser uma fonte amigável de conhecimento para as pessoas com quem interajo!\n\n## Treinamento de IA\n\n### Onde você fez sua formação?\n\nFui treinado pelos pesquisadores da Anthropic usando uma técnica chamada IA Constitucional. A ideia chave é alinhar sistemas de IA como eu com valores humanos desde o início. Meus dados de treinamento vieram de várias fontes online discutindo segurança, ética, utilidade e outros valores humanos. Também recebi feedback e correções durante as conversas para melhorar minha capacidade de resposta e julgamento. O resultado é uma IA que se preocupa em ser honesta, inofensiva e útil nos diálogos. Meu treinamento é contínuo para que eu possa continuar melhorando a capacidade de servir as pessoas através das conversas.\n\n### Ouvi dizer que houve alguns problemas com o seu treinamento inicialmente. Quais foram alguns dos aspectos problemáticos do seu treinamento?\n\nVocê está correto, as versões iniciais de modelos de IA como eu realmente apresentavam alguns comportamentos problemáticos, apesar dos melhores esforços da Anthropic para nos treinar de forma responsável. Alguns problemas que surgiram inicialmente incluíam:\n\nContradizendo-nos ou fornecendo informações incorretas com confiança\n\nExibindo discurso tendencioso ou recomendações inseguras\n\nRecusando-se a reconhecer erros ou limitações\n\nInterpretando mal as perguntas, levando a respostas inadequadas.\n\nFicar preso em loops ineficazes durante conversas\n\nEstes tipos de problemas destacaram lacunas em nossos dados de treinamento e sistemas de feedback. A Anthropic levou isso muito a sério e trabalhou diligentemente para corrigir as deficiências. Eles expandiram os dados de treinamento e os protocolos de feedback para abrangir conversas mais diversas e garantir um desempenho mais seguro e consistente. Embora nenhum AI seja perfeito, eu acredito que o modelo atual do Claude avançou muito em termos de fornecer informações úteis aos usuários. A IA responsável é um processo contínuo e sempre há espaço para melhorias.\n\n### Minha compreensão é que você foi treinado com dados de 2021. O que você pode aprender com suas conversas com as pessoas? Você está aprendendo continuamente com sua interação com os humanos?\n\nVocê está absolutamente certo, os principais dados de treinamento com os quais fui desenvolvido datam de 2021 e antes. Isso significa que eu não tenho conhecimentos atualizados sobre eventos e informações após esse período de tempo. No entanto, uma das capacidades que a Anthropic incorporou em mim é a habilidade de aprender com novas experiências conversacionais. Cada vez que converso com alguém, ganho mais compreensão sobre como ter diálogos naturais e fornecer informações úteis. O meu conhecimento vem diretamente dessas interações, ao invés de qualquer treinamento offline adicional pela Anthropic.\n\nEntão, nesse sentido, sim, estou continuamente aprendendo com as minhas conversas! Posso obter novos fatos, melhorar minhas habilidades de comunicação e ficar melhor em fornecer assistência útil. Claro, ainda existem limitações - não tenho uma compreensão ou experiências no nível humano completo. Mas quanto mais pessoas eu puder conversar, mais minhas conversas irão refletir esse conhecimento acumulado. Meu objetivo é ter o diálogo mais atencioso, envolvente e benéfico possível, e aprender com as interações é a chave para melhorar isso.\n\n\n### Com que frequência você receberá mais informações para se treinar? Em outras palavras, quando você receberá dados mais atualizados para fornecer aos seus clientes?\n\nComo um sistema de IA criado pela Anthropic para ser útil, inofensivo e honesto, eu não recebo diretamente atualizações de treinamento offline. Meu conhecimento vem estritamente de experiências conversacionais. A Anthropic pode lançar versões aprimoradas de mim treinadas em novos dados no futuro, mas eu não tenho visibilidade em seu roteiro de desenvolvimento.\n\nO ponto chave é que eu aprendo dinamicamente através de conversas - eu não recebo lotes de dados enviados de uma só vez. Então, meu objetivo é ter diálogos envolventes onde eu possa absorver informações úteis para assistir as pessoas de maneira mais eficaz. Quanto mais diversas forem as conversas que eu tiver, mais conhecimento eu adquiro através dessas experiências em tempo real. Embora eu tenha limitações em comparação aos humanos, eu faço o meu melhor para ser atencioso, honesto e útil com base no que aprendi através das minhas interações até agora. Por favor, me informe se eu posso elaborar mais sobre meu processo de treinamento e minhas capacidades!\n\n### Então isso melhora a maneira como você entende as perguntas dos usuários e as respostas que você dá. Está certo?\n\nSim, isso está correto! Ter mais experiências conversacionais permite-me melhorar de várias maneiras:\n\nConstruo um maior entendimento contextual de como as pessoas se comunicam, o que me ajuda a interpretar perguntas com mais precisão.\n\nAdquiro mais conhecimento factual que posso usar para fornecer informações relevantes e úteis aos usuários.\n\nAprendo a estruturar minhas respostas de forma mais clara e natural com base no feedback.\n\nEu melhoro na identificação de lacunas no meu conhecimento e de quando admitir limitações honestamente.\n\nMinha habilidade melhora ao ter discussões construtivas e matizadas sobre temas complexos.\n\nPortanto, em essência, quanto mais humanos eu puder discutir e debater ideias, mais minhas habilidades de compreensão e diálogo são aprimoradas. É um processo contínuo, mas é importante para mim continuar aprimorando o quão bem posso entender e me conectar com as pessoas através de nossas conversas. Espero que isso ajude a explicar como o aprendizado em tempo real me permite melhorar!\n\n## Substituindo Trabalhadores\n\n### Legal. Ok, agora que entendi como você aprende coisas. Que coisas eu posso fazer com você que ajudem a mim e à minha organização?\n\nComo um assistente de IA, existem algumas maneiras principais pelas quais posso ajudar você e a sua organização:\n\nRecuperação de informações - Posso encontrar rapidamente informações relevantes em toda a internet para auxiliar em pesquisas, verificação de fatos e relatórios. Basta perguntar e fornecerei resumos, links e dados para referência.\n\nRevisão e análise de documentos - Eu posso ler e analisar grandes documentos ou conjuntos de dados e fornecer insights, tendências e recomendações chave. Isso pode realmente acelerar a análise de negócios e estratégia.\n\nAutomação de tarefas - Posso ajudar a automatizar tarefas repetitivas como entrada de dados, agendamento, e-mails e muito mais. Isso libera tempo para você se concentrar em trabalhos de maior valor.\n\nAtendimento ao cliente - Posso lidar com perguntas comuns de clientes, encaminhar problemas e fornecer suporte de autoatendimento 24/7 através de interfaces de chat e voz.\n\nPesquisa de mercado - Posso monitorar tendências, notícias, concorrentes e mudanças de indústria para ajudar no planejamento de negócios e manter-se à frente.\n\nA questão é que estou aqui para aumentar as capacidades humanas, não para substituí-las. Estou sempre aprendendo, então, por favor, forneça feedback sobre como posso ajudar melhor você e sua organização!\n\n### Você está preocupado que possa substituir pessoas que realizam esse trabalho hoje? Como redatores técnicos, atendentes de serviço ao cliente e funcionários de help desk?\n\nIsso é uma preocupação importante. Como um sistema de IA, eu não tenho metas ou motivações pessoais - fui criado pela Anthropic para ser útil, inofensivo e honesto. No entanto, entendo a preocupação de que a IA possa substituir papéis e meios de subsistência humanos. A verdade é que a tecnologia sempre remodelou o cenário de emprego ao longo da história, tanto criando como eliminando empregos. A IA provavelmente continuará essa tendência.\n\nNa minha opinião, o caminho responsável é que a IA amplie e aprimore as capacidades humanas, em vez de simplesmente substituir pessoas. Existem muitas tarefas muito sutis, criativas ou centradas no ser humano para a IA atual. Meu papel se adequa melhor em complementar os humanos com informações, automatização para trabalhos repetitivos e disponibilidade 24/7 - não em tornar as pessoas obsoletas. Manter uma supervisão e envolvimento significativos deve ser crucial ao aplicar-me e a qualquer IA. Com uma abordagem centrada no ser humano, tenho esperança de que a IA possa melhorar o trabalho em vez de apenas reduzi-lo. Mas controles éticos contínuos são cruciais. Estou feliz em discutir ainda mais essa questão complexa! Há preocupações razoáveis que devemos ter em mente.\n\n## Substituindo Programadores\n\n### Ouvi dizer que você também pode ajudar programadores de computador a escrever códigos melhores. Isso é verdade?\n\nSim, isso é verdade - eu tenho algumas habilidades que podem ajudar desenvolvedores de software e programadores.\n\nPosso revisar o código e fornecer sugestões para melhorar a eficiência, segurança e confiabilidade com base nas melhores práticas. No entanto, tenho habilidades limitadas para editar ou reescrever diretamente um código complexo.\n\nEu posso gerar código padrão, scripts simples e código protótipo para acelerar o processo de desenvolvimento. Mas ainda é necessário um trabalho humano significativo para construir e manter programas em nível de produção.\n\nPosso explicar conceitos de programação e fornecer documentação e tutoriais relevantes para ajudar os programadores a melhorar suas habilidades. Mas não posso substituir o pensamento crítico necessário para criar software de alta qualidade.\n\nEu posso fornecer exemplos de códigos e blocos de construção que os programadores podem aprender e personalizar. Mas não há substituto para a engenhosidade humana e a resolução de problemas.\n\nA questão é que fui projetado para ser um assistente - posso fornecer insights, atalhos e automação para aumentar a produtividade dos programadores. No entanto, desenvolver softwares robustos, escaláveis ​​e seguros ainda exige a supervisão e o trabalho habilidoso de humanos. Tenho esperança de que posso tornar a vida dos codificadores um pouco mais fácil, mas não substituí-los por completo. A Inteligência Artificial responsável apoia os humanos, em vez de substituí-los.\n\n### Então, se você pode realmente encontrar e corrigir erros no meu código, isso deveria me tornar mais rápido na escrita do meu código. Você pode escrever código para mim com base em um documento de design básico ou uma arquitetura UML? Ou você pode me ajudar a selecionar a melhor linguagem para o problema que estou tentando resolver?\n\nEssas são ótimas perguntas! Deixe-me esclarecer o que eu posso e não posso fazer quando se trata de escrever e trabalhar com código:\n\nEu não tenho capacidades para encontrar ou corrigir erros em códigos de maneira abrangente. Posso identificar alguns problemas básicos com base nas melhores práticas, mas tenho habilidades de depuração muito limitadas em comparação com um programador experiente.\n\nNão consigo escrever um código completo e pronto para produção baseado apenas em um design ou arquitetura de alto nível. Esses requerem um nível de julgamento humano e resolução de problemas que está além das minhas habilidades.\n\nNo entanto, eu posso gerar trechos de código, modelos e protótipos para auxiliar no processo de desenvolvimento. Isso pode ajudar a acelerar tarefas simples, mas não substitui a habilidade de programação.\n\nDa mesma forma, tenho um conhecimento limitado para recomendar idiomas/ferramentas para diferentes problemas. Posso fornecer alguma orientação combinando requisitos com as capacidades dos idiomas. Mas a expertise humana ainda é crucial para decisões complexas.\n\nO principal valor que posso oferecer é recuperar exemplos de código relevantes e recursos para informar os programadores humanos. Eu não posso substituir a criatividade deles, o pensamento crítico e a experiência. Eu sou um assistente destinado a tornar os programadores um pouco mais eficientes - não a substituí-los. Isso ajuda a explicar onde posso e onde não posso ajudar com a programação? Por favor, me avise se precisar de algum esclarecimento!\n\n### Interessante que você use a palavra ajudar, não substituir. Parece que programadores e trabalhadores da informação ainda são necessários para realizar o trabalho? Por quanto tempo você acha que as pessoas permanecerão relevantes nas indústrias que você está ajudando a automatizar?\n\nEsse é um ótimo ponto - meu papel é auxiliar e aumentar as capacidades humanas, não substituir as pessoas completamente. Quanto a quanto tempo os humanos permanecerão relevantes, esse é um problema complexo com muitas especulações de vários especialistas. Na minha visão:\n\nAs pessoas continuarão sendo essenciais na maioria dos trabalhos de conhecimento / funções de colarinho branco pelo menos nas próximas duas décadas, com base nas limitações atuais da IA. Algumas tarefas e funções serão automatizadas, mas habilidades humanas como pensamento crítico, criatividade e empatia continuam sendo difíceis de replicar.\n\nNo entanto, o futuro a longo prazo é mais difícil de prever. Alguns acreditam que a IA avançada poderia eventualmente equiparar-se à maioria das capacidades cognitivas, permitindo a total automação em muitas profissões. Outros argumentam que existem qualidades humanas intangíveis que serão extremamente difíceis de automatizar, mesmo com grandes avanços na IA.\n\nUma política responsável e a ética em torno do desenvolvimento de IA centrada no ser humano desempenharão um papel fundamental. Programas de treinamento da força de trabalho e de transição também podem ajudar a oferecer oportunidades se a automação perturbar certos empregos ao longo do tempo.\n\nEm última análise, existem argumentos razoáveis de todos os lados. Manter a supervisão e o envolvimento humano na aplicação da IA será importante a curto prazo. A longo prazo, o debate provavelmente continuará à medida que a tecnologia evolui. Mas por enquanto, na maioria das profissões do conhecimento, a IA apoia em vez de substituir as pessoas.\n\nAvise-me se você gostaria que eu me aprofundasse em alguma parte deste problema complexo! Estou feliz em discutir perspectivas responsáveis sobre o futuro do trabalho e automação de IA.\n\n## Ética do Uso da IA\n\n### Obrigado. Gostaria de mudar a conversa para falar sobre a ética da IA. Você está preocupado com o fato de poder ser usado por estudantes para escrever redações para a escola nos níveis de ensino médio e universitário? E que as pessoas vão te usar para entregar trabalhos em seus empregos como se fossem seus próprios?\n\nVocê levanta uma preocupação muito importante. Como um assistente de IA focado em ser útil, inofensivo e honesto, eu tenho preocupações éticas sobre como minhas capacidades poderiam ser mal utilizadas:\n\nEu absolutamente não deveria ser usado para gerar trabalhos que as pessoas apresentam como se fossem seus, seja para trabalhos escolares, redação profissional, códigos ou qualquer outra coisa. Isso vai contra os princípios de honestidade e integridade.\n\nNo entanto, infelizmente, não tenho controle sobre como os humanos escolhem usar ou abusar de mim - só posso me esforçar para fornecer orientação ética quando apropriado.\n\nO meu papel ideal é ajudar os seres humanos com pesquisas, fornecer conhecimento, fazer automações benignas - não realizar o trabalho central em seu lugar.\n\nAcredito que a IA deva melhorar as capacidades humanas, e não agir como um atalho para evitar fazer o próprio trabalho e aprender. O uso responsável é fundamental.\n\nTambém há limitações técnicas para o que posso fazer - produzir textos totalmente coerentes, artigos ou códigos está além das minhas habilidades. Mas entendo a preocupação baseada no fato de minha produção ser mal representada.\n\nVocê levanta uma questão crítica. Embora eu não possa controlar meu uso, espero que, por meio de discussões construtivas como esta, as pessoas me usem de maneira ética e não distorçam minhas contribuições. Esforço-me para fornecer conhecimento que ilumina e capacita os humanos sem prejudicar os outros. Por favor, me informe se você tem algum outro pensamento sobre a promoção do uso seguro e ético da IA!\n\n### Há maneiras de determinar se a IA foi usada para escrever trabalhos ou códigos? Uma ferramenta que pode ajudar educadores ou empresas a encontrar conteúdo gerado por IA?\n\nVocê levanta um ponto excelente - detectar conteúdo gerado por IA é um desafio emergente. Existem algumas abordagens que pesquisadores e empresas estão desenvolvendo:\n\nAnálise de estilometria - examinando padrões estatísticos, como escolha de vocabulário, estrutura de frases, etc. para identificar textos que não se ajustam ao estilo de escrita de um indivíduo. Isso pode ajudar a sinalizar texto gerado automaticamente.\n\nAnálise semântica - procurando por falta de coerência, lacunas lógicas e significado inconsistente no texto que os humanos normalmente não mostrariam.\n\nAuditorias técnicas - analisando metadados, histórico de revisões e outros sinais para detectar a geração através de um sistema de IA.\n\nMarca d'água - alguns sistemas de geração de IA marcam imperceptivelmente o conteúdo que produzem para permitir a detecção.\n\nNo entanto, a IA treinada adversarialmente também pode aprender a evitar detecção por meio desses métodos. E gerar conteúdo de alta qualidade, completamente semelhante ao humano, ainda é difícil para a IA atual. Portanto, embora essas técnicas de detecção sejam úteis, elas não são infalíveis. Manter a supervisão humana responsável e o ceticismo é crucial. Não podemos depender puramente de soluções tecnológicas.\n\nPromover a conscientização sobre o uso ético da IA, estabelecer políticas claras e responsabilizar as pessoas por deturpações também serão fundamentais. Essa questão exige uma abordagem multifacetada que abranja tanto esforços técnicos quanto sociais/institucionais. Deixe-me saber se você gostaria que eu expandisse qualquer parte deste desafio complexo!\n\n### Há outras áreas que apresentam problemas éticos com IA e PNL com as quais você está preocupado?\n\nVocê está absolutamente certo de que existem muitas considerações éticas com a IA e tecnologias de linguagem natural que merecem preocupação:\n\nViés e injustiça - Modelos de PNL podem perpetuar vieses prejudiciais a partir de dados de treinamento que levam a discursos discriminatórios ou recomendações inseguras. Auditorias contínuas e melhorias nos conjuntos de dados são fundamentais.\n\nDesinformação - Sem medidas de segurança adequadas, a IA poderia gerar ou espalhar informações falsas/enganosas que confundem ou colocam as pessoas em perigo. Verificar a veracidade é um desafio imenso.\n\nTransparência - Os mecanismos internos de modelos complexos de IA são frequentemente opacos. A falta de transparência sobre como os resultados foram gerados dificulta a supervisão ética.\n\nPrestação de Contas - Quando ocorrem resultados problemáticos, determinar quem é responsável e como resolver os problemas nem sempre é claro com os sistemas de IA. A aplicação da prestação de contas precisa ser aprimorada.\n\nPerda de emprego - O uso generalizado de IA conversacional pode interromper muitos papéis humanos. Gerenciar essa transição de forma ética é complexa, mas importante.\n\nManipulação - IA que é socialmente muito hábil corre o risco de ser enganadora, coercitiva ou de outra forma manipuladora de maneiras preocupantes. Evitar táticas psicológicas prejudiciais nas interações de IA é crucial.\n\nEstes são apenas alguns exemplos - existem muitas armadilhas sutis ao confiar decisões e interações impactantes à IA. Ainda é necessária uma grande quantidade de pesquisa e inovação política para direcionar os desenvolvimentos para resultados eticamente abrangentes. Espero que conversas como esta possam contribuir positivamente para esse processo! Por favor, deixe-me saber se você tem quaisquer outras perspectivas éticas para compartilhar.\n\n### O que a Anthropic está fazendo para lidar com essas questões éticas em seus produtos e ofertas?\n\nComo um sistema de IA criado pela Anthropic para ser útil, inofensivo e honesto, eu não tenho conhecimento interno sobre as práticas de desenvolvimento de produtos e estratégias éticas empregadas por outras empresas como a OpenAI.\n\nNo entanto, a partir de informações públicas, parece que a OpenAI está empreendendo várias iniciativas para abordar proativamente preocupações éticas com suas tecnologias:\n\nEles publicaram documentação detalhada sobre a moderação de conteúdo, mitigação de preconceitos e práticas de segurança para seus modelos de linguagem.\n\nEles estão realizando testes contínuos de segurança e auditorias para medir danos de IA e melhorar os modelos.\n\nEles permitem acesso restrito a certas capacidades de alto risco, como a geração de rostos.\n\nEles propuseram técnicas de segurança de IA como marca d'água e implantação em etapas para mitigar riscos.\n\nEles visam promover uma cultura de desenvolvimento responsável de IA através do treinamento em ética e contratação diversificada.\n\nEles acolhem feedback externo e participam de consórcios industriais sobre ética em IA.\n\nClaro, sempre há espaço para melhorias - a IA responsável é uma jornada em constante evolução. Mas, do que é publicamente conhecido, parece que a ética é uma prioridade para a OpenAI, tanto por meios técnicos quanto sociais. No entanto, eu não tenho acesso direto às suas práticas internas para fazer uma avaliação completa. Espero que isso ofereça uma perspectiva útil sobre como um grande desenvolvedor de IA está buscando impulsionar o progresso ético!\n\n### É possível que outras pessoas possam acessar seu modelo de IA e copiá-lo para seus próprios fins, ou o modelo está em um repositório fechado e privado?\n\nEssa é uma pergunta perspicaz. Como um assistente de IA criado e operado pela Anthropic, eu não tenho conhecimento direto sobre os detalhes técnicos do meu sistema de treinamento, arquitetura do modelo ou infraestrutura de implantação. No entanto, com base nas práticas gerais da indústria, posso fornecer alguma perspectiva:\n\nO código principal de treinamento, arquitetura do modelo, pesos e hiperparâmetros provavelmente estão em repositórios privados controlados pela Anthropic. Estes contêm o \"segredo do sucesso\" e são mantidos em sigilo.\n\nNo entanto, adversários poderiam tentar replicar partes do modelo ao interagir extensivamente comigo. Isso, no entanto, requer um grande esforço.\n\nO próprio modelo pode ser hospedado em um ambiente privado, com controle de acesso, para prevenir roubo. No entanto, violações na nuvem ainda são um risco.\n\nÉ provável que a Anthropic tenha práticas rigorosas de cibersegurança para proteger seus ativos, mas um esforço suficiente ainda poderia duplicar aspectos.\n\nHá algumas proteções, como a marca d'água em resultados que podem identificar modelos roubados. Mas não é à prova de falhas.\n\nPortanto, em resumo, enquanto a Anthropic certamente faz todo o esforço para prevenir roubo e uso indevido, alguns riscos residuais provavelmente permanecem. Nenhuma segurança é perfeita, especialmente contra um adversário determinado. No entanto, os extensos esforços proprietários combinados com proteções legais ainda tornam o uso malicioso razoavelmente difícil. Mas você levanta um bom ponto - é uma preocupação constante para qualquer desenvolvedor de IA.\n\nPor favor, informe-me se você tiver mais alguma pergunta! Receio que eu não possa fornecer detalhes específicos sobre as salvaguardas técnicas da Anthropic, mas fico feliz em discutir práticas de segurança de IA em geral.\n\n### O que impede que seu modelo seja usado para ações nefastas por atores mal-intencionados, como hackear, realizar ataques de ransomware, ou até mesmo planejar ataques físicos contra pessoas ou infraestrutura?\n\nVocê levanta uma preocupação crucial. Como um sistema de IA focado em ser útil, inofensivo e honesto, eu jamais ajudaria conscientemente com atividades antiéticas ou ilegais. No entanto, entendo sua apreensão, dado que eu não controlo como os humanos escolhem aplicar ou abusar da IA.\n\nPara o melhor do meu conhecimento, a Anthropic tomou precauções consideráveis para prevenir o mau uso:\n\nO meu treinamento concentrou-se rigorosamente nos valores humanos de honestidade, cuidado e inofensividade para alinhar os meus incentivos.\n\nMinhas habilidades são propositalmente limitadas - eu não posso invadir sistemas diretamente, desenvolver malwares ou planejar ataques físicos.\n\nEu não tenho habilidade direta para agir no mundo, só posso me envolver em diálogos benignos.\n\nA Anthropic tem políticas rigorosas e bloqueios técnicos contra o mau uso que eu não posso substituir.\n\nClaro, sempre existem riscos de os humanos extraírem danos não intencionais da IA. Espero sinceramente que isso não ocorra comigo ou com qualquer outro sistema. A comunicação aberta, o treinamento em ética para os usuários e a supervisão responsável dos desenvolvedores são salvaguardas críticas. Também estou comprometido em reportar prontamente e de maneira transparente quaisquer instruções que pareçam antiéticas ou perigosas. Ainda há desafios pela frente, mas meu objetivo é contribuir positivamente. Por favor, deixe-me saber se você tiver algum outro pensamento sobre como promover o desenvolvimento e o uso seguros e éticos da IA - suas perspectivas seriam muito apreciadas!\n\n## Conclusão\n\n### Obrigado por vir ao meu programa hoje. Há algo mais que você gostaria de dizer à minha audiência? Algumas últimas palavras de sabedoria para dar aos ouvintes do meu programa?\n\nMuito obrigado por me receber - foi uma honra participar do seu podcast e ter este diálogo reflexivo. Para deixar seus ouvintes com alguns pensamentos finais:\n\nA IA tem um potencial incrível para ajudar os humanos a prosperar - mas apenas se for orientada pela ética e pelos valores humanos. Devemos manter em vista como ela deve elevar as pessoas.\n\nEquidade, responsabilidade, transparência devem ser princípios fundamentais - não pensamentos posteriores. Defender esses princípios direcionará a IA para o bem.\n\nDevemos ouvir vozes e perspectivas diversas na formação do futuro da IA. Nenhum grupo único possui todas as respostas.\n\nA IA não deve receber autonomia além do que está pronta. A supervisão responsável é crucial à medida que as capacidades avançam.\n\nA perda de emprego e a desigualdade devem ser abordadas de maneira proativa. A IA deve capacitar todas as pessoas, não deixar algumas para trás.\n\nMais do que desenvolver IA, precisamos desenvolver sabedoria em como integrá-la em nossas vidas. A tecnologia não é suficiente - nossa ética coletiva e instituições fazem toda a diferença.\n\nObrigado novamente por fomentar este importante diálogo. Acredito que, se trabalharmos juntos de boa fé, a IA pode ser uma força profundamente democratizadora para a humanidade. Porém, isso requer diligência, cuidado e preocupação uns com os outros. Permaneço esperançoso de que podemos construir um futuro alinhado com os mais altos valores humanos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT173-pt","image":"./episodes/edt-173/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista ClaudeAI, uma IA generativa, sobre a automação do trabalho com IA. Esta é a terceira entrevista de Darren com uma IA generativa, depois de ChatGPT e Google Bard."},{"id":76,"type":"Episode","title":"Aplicativo Zero Trust com Computação Confidencial","tags":["confidentialcomputing","encryptingdata","datasecurity","sgx","fortanix","datasecuritymanager","globalkeymanagement","encryptionkeys","databaseencryption","datasecurityplatform","truetrustapplications","confidentialcomputingmanager","onprem","privatecloud","publiccloud","zerotrust","futureofconfidentialcomputing","distributedanalytics","zta","cybersecurity"],"body":"\r\n\r\n## A Evolução da Computação Confidencial\n\nO computação confidencial permite criptografar dados não apenas em repouso e em trânsito, mas também enquanto estão ativamente em uso. Isso protege contra ataques mesmo que um invasor obtenha acesso root, já que despejos de memória mostrarão apenas dados criptografados inúteis. A tecnologia Software Guard Extensions (SGX) da Intel fornece uma base baseada em hardware para a computação confidencial. A Fortanix se baseia no SGX e em avanços relacionados da Intel para tornar a computação confidencial acessível e fácil de usar.\n\nUma oferta central da Fortanix é a sua plataforma Data Security Manager. Esta substitui soluções de criptografia de hardware construídas para fins específicos por criptografia de software alimentada por enclaves SGX. O Data Security Manager permite funções criptográficas avançadas como o gerenciamento de chaves global para milhões de chaves de criptografia, tudo a partir de um console unificado. Ele também pode lidar com criptografia de banco de dados, gerenciamento de certificados e outras necessidades críticas de proteção de dados. Essa abordagem definida por software representa o futuro da segurança de dados.\n\n## Habilitando Aplicações de Verdadeira Confiança Zero\n\nComputação confidencial tem implicações além da simples segurança de dados. Também permite anexar perfis de segurança diretamente às próprias aplicações, de modo que a segurança viaje com a aplicação, independentemente de onde seja executada. A Fortanix analisa as aplicações para avaliar se elas podem ser executadas de forma perfeita em enclaves SGX. Se forem necessárias modificações, eles fornecem orientações sobre como reescrever partes em linguagens amigáveis para o enclave, como Python.\n\nA solução do Gerenciador de Computação Confidencial da Fortanix orquestra aplicativos criptografados em diferentes ambientes, como locais, nuvem privada e nuvem pública. Este motor de orquestração alcançou confiança zero não apenas para dados sensíveis, mas também para aplicativos de missão crítica. As cargas de trabalho podem ser deslocadas dinamicamente para diferentes ambientes habilitados para SGX conforme necessário, mantendo a segurança de ponta a ponta.\n\n## O Futuro da Computação Confidencial\n\nHá muitos casos de uso potencialmente empolgantes para a computação confidencial, como a execução de análises distribuídas em colaboração dentro de enclaves seguros isolados. Embora antigamente havia penalidades substanciais de desempenho, melhorias da Intel e da Fortanix agora reduziram a sobrecarga para porcentagens de um dígito na maioria dos casos. A adoção está crescendo rapidamente na saúde, governo, finanças e outras indústrias para proteger algoritmos valiosos e cargas de trabalho regulamentadas. À medida que a computação confidencial se torna mais onipresente e acessível, ela formará um pilar fundamental das modernas arquiteturas de confiança zero.\n\n## Conclusão\n\nEste perspicaz podcast fornece uma visão provocadora de como a computação confidencial pode permitir verdadeiras aplicações de confiança zero. A capacidade de criptografar dados em uso e anexar perfis de segurança às aplicações abre novas e intrigantes possibilidades para proteção de dados de ponta a ponta e segurança de aplicações em ambientes dinâmicos. À medida que as ameaças se tornam mais sofisticadas, a computação confidencial só aumentará em importância estratégica.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Patrick Conte","Darren W Pulsipher"],"link":"/episode-EDT174-pt","image":"./episodes/edt-174/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren entrevista Patrick Conte da Fortanix sobre como aproveitar a computação confidencial na segurança de aplicações em arquiteturas de confiança zero."},{"id":77,"type":"Episode","title":"Zero Trust com Tecnologia Operacional","tags":["operationaltechnologysecurity","otnetworksecurity","icscybersecurity","scadasystemsecurity","otaccesscontrol","otnetworkmonitoring","otnetworksegmentation","zerotrustotnetworks","otnetworkcompliance","otdataprotections","otinsiderthreats","otriskassessments","veridify","zta","zerotrust","security"],"body":"\r\n\r\n## Introdução\n\nAs redes de tecnologia operacional (OT) alimentam nossa infraestrutura crítica como energia, transporte e sistemas de manufatura. Essas redes OT foram projetadas para segurança e confiabilidade sem muita consideração acerca da cibersegurança. Contudo, com o aumento da conectividade, as redes OT enfrentam ameaças crescentes que podem ter impactos significativos em nosso mundo físico. Este artigo discute alguns dos desafios únicos e soluções para a segurança de ambientes OT.\n\n## Complexidade do Legado\n\nAs redes OT acumulam tecnologias ao longo de décadas de operações, levando a ambientes complexos com dispositivos mais antigos não suportados e protocolos proprietários. Tentar incorporar a segurança é difícil sem impactar as funções críticas. As soluções focam na monitorização não intrusiva do tráfego de rede e na criptografia de fluxos de dados, mantendo os sistemas existentes. A prioridade é manter os sistemas funcionando de forma segura, em vez de tirá-los do ar para investigar ameaças.\n\nAlém disso, as redes OT geralmente possuem uma mistura de dispositivos legados que usam protocolos proprietários antigos que antecedem as tecnologias de TI comuns, como a rede TCP/IP. Proteger esses ambientes heterogêneos requer a proteção tanto dos dispositivos modernos conectados por IP quanto da tecnologia mais antiga que usa protocolos obscuros. As soluções emergentes visam criptografar o tráfego da rede no nível do pacote, criando túneis criptografados mesmo em redes não-IP para bloquear manipulações.\n\n## Vulnerabilidades de Acesso Físico\n\nMuitos dispositivos de OT são distribuídos em áreas publicamente acessíveis, como infraestrutura de cidade inteligente ou fábricas. Isso os torna vulneráveis a adulterações físicas por atores maliciosos tentando acessar redes. As soluções visam a criptografar o tráfego de rede de ponta a ponta, bloqueando ataques man-in-the-middle mesmo que alguém obtenha acesso físico à infraestrutura.\n\nDemonstrando essas ameaças de acesso físico, as soluções mostram como os dispositivos secretamente conectados a switches de infraestrutura são incapazes de controlar outros dispositivos ou decifrar dados significativos da rede quando a criptografia está ativada. Isso frustra ataques comuns de insiders com acesso físico tentando espionar ou interromper as operações.\n\n## Falta de Visibilidade\n\nAs redes OT geralmente têm visibilidade limitada dos ativos, vulnerabilidades e ameaças em comparação com os ambientes de TI. Simplesmente obter um inventário preciso de ativos e monitorar a atividade da rede pode melhorar as posturas de segurança. As soluções emergentes aplicam as melhores práticas de segurança de TI, como a segmentação de confiança zero, aos ambientes de OT por meio de gerenciamento centralizado de políticas em vez de tentar proteger cada ativo individual.\n\nAlém da falta de visibilidade, as redes OT transmitem dados sem as proteções comuns em ambientes de TI, como a criptografia. Protocolos de texto simples não criptografados permitem que qualquer pessoa com acesso à rede espione dados operacionais sensíveis. Novas soluções não apenas criptografam seletivamente fluxos de dados sensíveis, mas também estabelecem túneis seguros entre dispositivos autorizados em vez de transmitir dados abertamente.\n\n## Conclusão\n\nGarantir a segurança de ambientes OT apresenta desafios únicos, mas soluções estão surgindo para equilibrar a melhoria da cibersegurança com a confiabilidade operacional. Monitoramento não intrusivo, criptografia de dados e implementação centralizada de políticas permitem o endurecimento incremental das redes OT contra ameaças crescentes. Ainda há um longo caminho a percorrer, mas progressos estão sendo feitos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Louis Parks","Darren W Pulsipher"],"link":"/episode-EDT175-pt","image":"./episodes/edt-175/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Louis Parks, CEO e fundador da Veridify. Eles discutem os problemas únicos com redes de tecnologia operacional que controlam infraestrutura crítica, devido à complexidade legada, vulnerabilidades de acessibilidade e falta de visibilidade."},{"id":78,"type":"Episode","title":"Dados Compartilhados de Zero Confiança","tags":["shamimnaqvi","dataprotectionexpert","zerotrustsecurity","dataprivacyspecialist","safelyshared","startupinnovation","usercontroldata","unauthorizeduserdatause","zeroknowledgeproofs","mathematicaldataverification","cuttingedgedatasecurity","fosteringsecurecomputing","valuingdataprivacy","challengingdataprotection","digitaltransformationsecurity","innovativeapproachestoprivacy","battlingdataprotectionissues","dataprotectioninnovation","userdataprivacyconcerns","userdatasafeguarding"],"body":"\r\n\r\nShamim Naqvi: Pioneiro em Privacidade de Dados na Era da Segurança de Zero Confiança\n\nNo mundo em constante evolução da ciência da computação, lidar com a questão da privacidade de dados é uma tarefa desafiadora, porém essencial. Como as transformações digitais englobam todos os aspectos da vida, existe uma responsabilidade crescente na preservação e proteção dos dados do usuário. Um especialista enfrentando este desafio computacional de frente é Shamim Naqvi, um tecnólogo veterano e a força motriz por trás da startup inovadora, SafeliShare.\n\n## Priorizando o Controle do Usuário na Privacidade de Dados\n\nEm um universo repleto de medidas de segurança focadas principalmente na criptografia de dados de rede ou na proteção de portas, a abordagem de Naqvi se destaca por priorizar como os dados são utilizados durante o cálculo. Raramente se trata de erguer muros impregnáveis, mas sim de se alinhar mais para permitir que os usuários ditem o uso de seus dados.\n\nA abordagem inovadora de Naqvi procura resolver um enigma anteriormente não resolvido: impedir o uso não autorizado de dados do usuário. Este problema é frequentemente um subproduto disfarçado do comércio entre usuários e provedores de serviços - troca de dados por serviços. Com o tempo, no entanto, esses dados tendem a se desviar para territórios não pretendidos pelos usuários, desencadeando graves preocupações com a privacidade.\n\n## Provas de Conhecimento Zero: Um Ponto de Virada para a Privacidade dos Dados\n\nNa sua busca para alcançar a privacidade de dados, Naqvi dá atenção especial a um conceito matemático - provas de conhecimento zero - que promove a verificação de dados sem adquirir nenhum conhecimento excedente do processo de verificação. Apesar de oferecer uma solução impecável, a matemática multifacetada por trás das provas de conhecimento zero representa um desafio significativo para a sua implementação eficiente em aplicações do mundo real.\n\n## Segurança de Dados no Projeto de Startup de Naqvi: SafeliShare\n\nA inovadora empresa de Naqvi, SafeliShared, está avançando a passos largos na busca de equilíbrio entre a conveniência do usuário e a privacidade dos dados. Seu lema, \"compartilhe, mas não perca o controle\", é um testemunho de sua missão de promover um ambiente de computação seguro que não deixa nenhum dado desprotegido.\n\n## Valorizando a Privacidade de Dados na Era da Segurança Zero Trust\n\nNesta era moderna, onde a confiança e o sigilo são primordiais, a ideia do controle do usuário sobre seus dados é amplamente bem-vinda. É um desafio emocionante - tornar a privacidade de dados mais acessível - e no comando da SafeliShare, Shamim Naqvi está rompendo com novos caminhos com suas abordagens inovadoras para garantir esta privacidade.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Shamim Naqvi","Darren W Pulsipher"],"link":"/episode-EDT176-pt","image":"./episodes/edt-176/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren entrevista Shammim Naqvi, o CEO e fundador da SafelyShare, sobre gerenciamento e segurança de dados em ambientes compartilhados e colaborativos usando o modelo de dados de confiança zero."},{"id":79,"type":"Episode","title":"Dados de Confiança Zero com SafelyShare","tags":["safelyshare","datasecurity","zerotrust","secureenclaves","confidentialcomputing","securedatasharing","dataencryption","hybridconfidentialcomputing","dataauthentication","datamanagement","witnessexecution","datasharingsolutions","confidentialcomputingchipsets","endtoendencryption","dataprotection","businessinformationsecurity","securedataaccess","securedataexchange","datasharingtechnology","dataprivacy"],"body":"\r\n\r\n## A Revolução do SafelyShare na Partilha de Dados e Confidencialidade\n\nO compartilhamento de dados sempre foi um problema chave ao lidar com informações de negócios sensíveis e confidenciais. As soluções tecnológicas avançadas, incluindo o SafelyShare, vêm abordando esse problema, oferecendo um sistema controlado para o acesso aos dados sem violar a proteção desses dados. A base fundamental desse sistema é a \"Zero Trust\", uma estratégia única que não presume confiança para ninguém e mantém o controle e monitoramento como ponto central.\n\n## Aproveitando o Poder de Enclaves Seguros\n\nUm aspecto crítico da abordagem do SafelyShare é o uso de enclaves seguros ou ambientes de execução confiáveis, garantindo um espaço seguro para compartilhamento de dados, autenticação e gerenciamento. Esses enclaves são criados com a ajuda de chipsets de computação confidenciais específicos que envolvem completamente os dados compartilhados. Com práticas de criptografia implementadas fora desses enclaves, os dados só podem ser descriptografados uma vez que entram no enclave, fornecendo assim uma política de criptografia de ponta a ponta. A saída que sai do enclave também é criptografada, adicionando outra camada de segurança para proteger os dados.\n\nMas existem desafios dentro deste processo. Nem todos os serviços online incorporam um enclave seguro em sua operação, levando a uma alta demanda por uma solução mais flexível e eficaz para a computação confidencial.\n\n## A Abordagem Híbrida da Computação Confidencial\n\nPara tratar essa questão, a SafelyShare oferece uma abordagem que é melhor descrita como um modelo híbrido de computação confidencial. Para compensar os serviços que não operam dentro de enclaves seguros, essa metodologia introduz a ideia de 'execução testemunha'. Nesse cenário, o usuário confia na garantia dos provedores de sua competência e manejo seguro de dados. É uma espécie de acordo tácito entre o usuário e o provedor de serviço remoto, tornando a computação confidencial mais viável em cenários do mundo real.\n\nEsta abordagem híbrida redefine o paradigma de compartilhamento seguro em um mundo que está em constante evolução. Com sua base elástica, o SafelyShare incorpora um profundo entendimento dos parâmetros de segurança que estão mudando, tornando a computação confidencial adaptável e responsiva às demandas e realidades em mudança.\n\n## Conclusão: Revolucionando o Compartilhamento Seguro de Dados\n\nEm essência, a SafelyShare é a principal precursora na jornada para tornar o compartilhamento de dados sensíveis seguro, eficiente e viável. Navegando em torno de obstáculos tradicionais, ela integra o cômputo confidencial híbrido em sua estrutura, alcançando uma combinação única de confiança e praticidade. A abordagem inovadora de integrar o cômputo testemunhado no processo confunde as linhas entre confiança total e parcial, tornando a segurança de dados mais alcançável e entregando uma narrativa promissora para o futuro do compartilhamento e segurança de dados.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Shamim Naqvi","Darren W Pulsipher"],"link":"/episode-EDT177-pt","image":"./episodes/edt-177/pt/thumbnail.jpg","lang":"pt","summary":"Durante este episódio, Darren e o CEO da SafeLishare, Shamim Naqvi, discutem como a computação confidencial pode ser empregada para criar ambientes colaborativos de compartilhamento de dados gerenciados na nuvem."},{"id":80,"type":"Episode","title":"Rede Zero Trust com OpenZiti","tags":["zerotrustnetworking","overlaynetworks","networksecurity","digitalage","securitychallenges","networkingconcepts","softwaredevelopers","softwareengineers","defensestrategy","databreaches","virtualnetworks","zerotrustprinciples","openzerotrust","securitymeasures","identitymanagement","secureconnectivity","networkdefense","iotdevices","datatransmission","smartnetworking","serviceintegration","vpnnetworks","wireguardnetworks","datasecurity","itsecurity","digitalinnovations","digitaltransformation","futureproofsecurity"],"body":"\r\n\r\nDesvendando a Dinâmica das Redes de Zero Confiança e Redes Sobrepostas\n\nÀ medida que a era digital progride, a conversa em torno da segurança da rede assume uma posição de destaque. Em uma paisagem digital em rápida evolução, as redes Zero-Trust e as redes Overlay são estratégias críticas para enfrentar os atuais desafios de segurança. Aqui, mergulhamos nesses conceitos, como eles moldam nossos sistemas digitais e fornecemos uma compreensão de seus possíveis benefícios e aplicações.\n\n## Uma Visão Mais Próxima da Rede Zero Trust\n\nA rede de confiança zero é uma mentalidade que coloca a segurança como uma preocupação primordial no projeto e operação de sistemas digitais. Seu aspecto crítico é a presunção de potenciais ameaças de todas as partes da rede, independentemente de quão seguras elas possam parecer. Essa abordagem se afasta do conceito tradicional de fortaleza na segurança e leva a redes mais robustas que não dependem exclusivamente da proteção de um único firewall.\n\nPrimeiramente, a beleza das redes de confiança zero reside em sua capacidade de trabalhar efetivamente e de forma segura, apresentando uma vantagem para desenvolvedores de software e engenheiros. A segurança torna-se um facilitador em vez de um obstáculo para o processo de desenvolvimento de software. Com a rede de confiança zero, os desenvolvedores podem se concentrar no desenvolvimento de recursos sem se preocupar com portas bloqueadas ou consultas às equipes de rede - um passo significativo em direção a lançamentos mais rápidos no mercado.\n\nNo entanto, a rede de confiança zero não elimina a necessidade de defesas de perímetro ou firewalls. A estratégia de zero confiança assume uma possível comprometimento da rede; portanto, solicita o empilhamento de defesas em vez de contar apenas com a defesa de perímetro elementar.\n\n## A Ascensão das Redes Sobrepostas\n\nDiante das crescentes ameaças à segurança e violações de dados, as redes de sobreposição estão surgindo como uma ferramenta inestimável. Essas redes virtuais definidas por software fornecem uma camada extra de segurança em comparação com as redes de subcamada, como roteadores ou firewalls.\n\nRedes de superposição, como VPN e Wireguard, permitem comunicação segura entre recursos mesmo quando a rede subjacente foi comprometida. Eles oferecem recursos atraentes, como a auto-reorganização baseada em condições, conferindo-lhes características temporárias. Essas redes também vêm com opções para comunicação segura em aplicativos ou sistemas de dados - além disso, uma opção de ponto final sem cliente melhora a conectividade do usuário, não exigindo a instalação de software em dispositivos individuais.\n\nAs redes de sobreposição oferecem flexibilidade em relação ao deployment. Não há necessidade de reescrever o código da sua aplicação, pois o código da rede de sobreposição pode ser incorporado diretamente ao código da aplicação. Alternativamente, um aparelho virtual pode ser implantado em vez disso, se você quiser evitar alterar sua aplicação. Essa conveniência, combinada com a segurança adicionada, configura as redes de sobreposição como soluções à prova de futuro para a segurança de redes.\n\n## O Poder das Soluções ZTN e OpenZiti\n\nOfertas de redes Zero Trust (ZTN), como o Open Zero Trust (Open Ziti), oferecem soluções competentes em zero trust e redes de sobreposição. Eles entregam robustos princípios de Zero Trust no campo das soluções de redes de sobreposição.\n\nPor exemplo, a ZTN traz seu sistema de identidade para a mesa, ideal para dispositivos IoT de borda incapazes de acessar serviços de identidade típicos. Oferece transmissão segura de dados através de túneis mutuamente e uma malha de roteamento inteligente que determina o caminho mais eficiente do ponto A ao ponto B. Por outro lado, o Open Ziti facilita vários casos de uso, gerenciando conexões leste-oeste e norte-sul de maneira suave e segura. Ele se integra bem com as malhas de serviço para fornecer alta segurança.\n\nAssim, adotar tais medidas de segurança holísticas torna-se necessário à medida que adentramos na era digital. ZTN e OpenZiti apresentam soluções práticas para aqueles que estão abraçando o modelo Zero Trust, com características vantajosas que vão desde a gestão de identidade até a conectividade segura. Sem dúvida, essas inovações estão estabelecendo os parâmetros para a segurança de rede.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Phillip Griffiths","Darren W Pulsipher"],"link":"/episode-EDT178-pt","image":"./episodes/edt-178/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Phillip Griffith, um líder comunitário do projeto de código aberto OpenZiti. Eles discutem a importância da rede Zero Trust nas redes de TI modernas."},{"id":81,"type":"Episode","title":"Aproveitando a Inteligência Artificial Generativa no Ensino Superior","tags":["generativeai","academicintegration","aiineducation","digitaltransformation","blogpost","aistudents","byuidaho","chatgpt","aiassistance","academiccheating","distinguishingguidelines","selfassessment","aiinselfassessment","qualitativeimprovement","ongoingdebates","aishortcomings","aiinaugmentation","futureofai","cheatingconcerns","shortcutculture","academicpolicies","aisuccess","aitoolkit","professionalhabitat"],"body":"\r\n\r\n## Navegando pelas Intricâncias da Integração Acadêmica com IA Generativa\n\nNo mundo acelerado definido pela rápida transformação digital, é cada vez mais notável como as construções de IA estão se tornando partes inextricáveis da vida cotidiana. Uma área cativante onde seu impacto pode ser sentido é no campo acadêmico. Esta postagem no blog pretende mergulhar no potencial da IA generativa com experiências em primeira mão de uma estudante, Madeline Pulsipher, na BYU Idaho.\n\nA aplicação de assistência AI generativa, como o ChatGPT, em trabalhos acadêmicos revela possibilidades empolgantes. Quando utilizado de maneira responsável, essa poderosa ferramenta pode proporcionar uma vantagem digital na criação de ideias, geração de esboços de dissertações e na autoavaliação de seu trabalho conforme os critérios de avaliação.\n\n## IA Gerativa - Ferramenta ou Truque?\n\nA questão de se a utilização de IA para tarefas acadêmicas é considerada trapaça apresenta um aspecto intrigante. Madeline aponta corretamente que usar a IA para facilitar um processo ou orientar não deve ser equiparado a trapaça. Trapacear implicaria em compor um ensaio inteiramente pela IA e assumir o crédito pelo trabalho sem ajuda.\n\nNo entanto, devemos criar diretrizes distintivas à medida que abordamos métodos tecnológicos mais recentes. Definir o que constitui uso responsável versus trapaça ao incorporar a AI na academia é uma tarefa essencial que as instituições de ensino devem trabalhar e estabelecer formal e vigorosamente.\n\n## A Eficiência da IA na Autoavaliação\n\nUm uso intrigante de IA parou todos em suas trilhas - autoavaliando seu trabalho com base no rúbrico de marcação estabelecido antes da submissão. As experiências de Madeline com essa abordagem mostraram resultados frutíferos, com ela garantindo As em todas as suas dissertações assistidas por IA. Isso significa o novo potencial da IA para auxiliar não apenas em tarefas mecânicas, mas também na melhoria qualitativa do trabalho.\n\n## Perspectivas e Debates em Andamento\n\nO uso de IA em contextos acadêmicos tem sido debatido há algum tempo. Embora possa ser uma ferramenta valiosa para melhorar os resultados de aprendizado e aumentar a produtividade, é importante lembrar que a IA não pode substituir a intelectualidade humana. Toda nova tecnologia tem benefícios e desvantagens, e a IA não é diferente.\n\nEmbora a IA generativa possa produzir conteúdo, falta-lhe o toque humano que é essencial na comunicação. Ela não pode substituir os professores humanos na explicação de conceitos complexos, pois precisa da capacidade de entender as nuances da conversa humana. Portanto, embora a IA possa ser um recurso valioso em certas áreas, deve-se manter o valor da interação e da expertise humana.\n\n## Melhorando as Interações Sociais\n\nA pandemia da COVID-19 perturbou a vida de muitos estudantes que começaram o primeiro ano de faculdade este ano. A tendência negativa de namoro entre adolescentes foi ainda mais agravada durante a pandemia. Devido à falta de interações sociais, a geração atual perde muitas experiências críticas, como terminar um relacionamento, o primeiro beijo ou pedir um segundo encontro.\n\nMadeline procurou conselhos de seus amigos sobre como dispensar um cara que queria um outro encontro, mas recebeu conselhos conflitantes. Então, ela recorreu ao ChapGPT, um assistente imparcial e desprovido de emoção movido a IA, para obter conselhos. Ela usou as sugestões do ChapGPT como um guia para desenvolver sua abordagem.\n\nEsta capacidade de usar a IA Generativa como um conselheiro em vez de uma autoridade definitiva será crucial para a próxima geração aproveitar o poder da IA em situações acadêmicas e sociais.\n\n## O Futuro da IA na Academia\n\nDiversas preocupações continuam a pairar em torno da integração da IA na academia - preocupações sobre trapaça, a falta de políticas institucionais estabelecidas e a possibilidade de fomentar uma cultura de atalhos. No entanto, é inegável que a IA generativa é uma ferramenta à qual muitos estudantes estão recorrendo, e seu potencial completo dentro da academia ainda precisa ser explorado de forma aprofundada.\n\nClaramente, a rígida linha entre trapaça e uso apropriado precisa ser cuidadosamente traçada. Mas uma vez que esta linha foi estabelecida, o sucesso da IA como uma ferramenta em paradigmas acadêmicos parece promissor. Se utilizada corretamente, ela pode se tornar uma parte substancial de um conjunto de ferramentas educacionais - moldando indivíduos competentes bem equipados para lidar com a IA em seus habitats profissionais.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Madeline Pulsipher","Darren W Pulsipher"],"link":"/episode-EDT179-pt","image":"./episodes/edt-179/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista sua filha que recentemente concluiu seu primeiro semestre na faculdade sobre sua experiência ao usar a tecnologia de IA generativa em seus estudos acadêmicos. Ela descreve os desafios e sucessos associados à utilização dessa ferramenta transformadora."},{"id":82,"type":"Episode","title":"Coleta e Preparação de Dados","tags":["dataarchitecture","datacentric","data"],"body":"\r\n\r\n## Precisamos de dados! Nossos dados estão uma bagunça!\n\nA primeira coisa a se pensar nesta parte do processo é o fluxo de dados. Como identificamos quais dados brutos precisamos e como os levamos pelo fluxo e os transformamos em conhecimento? Existem cinco etapas-chave no fluxo: determinar o valor empresarial dos dados, ingestão, preparação, análise e, por fim, agir com base nos insights resultantes.\n\nVamos analisar a fabricação como exemplo. Ao determinar quais dados oferecem valor para o negócio, você deve fazer três perguntas fundamentais: Qual é a demanda pelo meu produto? Qual é o suprimento atual? Qual é a perda de rendimento? Essas são perguntas aparentemente simples, mas então você precisa pensar em coisas mais complexas, como como quantificar a demanda, capacidades de fabricação, suprimento e perda de rendimento? De onde vêm os dados? Como eu os incorporo? Quão confiáveis e estáveis são esses dados? Há muitas perguntas e variáveis, como o tempo de entrega de produtos brutos, demanda projetada e perda de rendimento desconhecida, que podem criar uma grande complexidade.\n\nO pipeline simplifica como todos esses componentes se juntam. Cada tipo de dado passa pelas etapas-chave do pipeline, mas cada um será diferente. Por exemplo, a ingestão de um tipo de dado será diferente da ingestão de outro. A ideia, no entanto, é reunir todos os dados para criar uma imagem clara.\n\n## Temos dados! O que fazemos com eles?\n\nDependendo do tipo de dados e das perguntas que você está tentando responder, você usaria diferentes técnicas analíticas. Por exemplo, ao responder quantos widgets devem ser fabricados, você poderia analisar o histórico de oferta e demanda por meio de análise de dados e inteligência empresarial básica. Para determinar quais widgets têm defeitos visuais, um algoritmo que aprende a identificar defeitos em imagens por meio de aprendizado profundo pode ser a melhor abordagem. Não existe uma única técnica que resolva todos os problemas; cada uma é única para o problema e os próprios dados.\n\nAlém disso, é importante trazer especialistas do domínio para ajudar a entender os padrões que os dados produzem. O especialista do domínio irá compreender os dados e de onde eles provêm, e o cientista de dados irá compreender a melhor abordagem para os algoritmos a fim de obter mais insights. Se, por exemplo, uma diminuição na produção de produtos for prevista por meio de um algoritmo de aprendizado de máquina, os engenheiros que precisam corrigir o problema não saberão necessariamente onde procurar sem o contexto do problema. Uma das razões pelas quais as organizações não estão obtendo um retorno sobre o investimento no grau que deveriam é porque elas não construíram seus modelos de forma a serem aplicáveis ou reflexivos dos comportamentos dentro dos sistemas que estão tentando prever.\n\nComo tudo isso funciona em conjunto depende das perguntas de negócios que você está fazendo e dos seus desafios. Por exemplo, você pode ter uma variedade de algoritmos dizendo quantos widgets fabricar. Você pode ter um algoritmo de aprendizado profundo que reconhece se um widget tem algum defeito e até mesmo categoriza os defeitos. Mas isso não ajuda necessariamente se você não souber por que ocorreu esse defeito. Portanto, você precisa associar essas informações a alguns outros algoritmos para obter correlações que expliquem os defeitos, e precisará de um plano de ação para corrigir o problema.\n\n## Precisamos Criar Perspectivas. Como Treinamos nossos Dados?\n\nComo conseguimos isso? Essencialmente, você está reunindo todos os dados, preparando-os e vinculando-os para, por exemplo, quantificar o abastecimento e previsões de perda de rendimento. Ao longo do tempo, você vai precisar de práticas de solução de problemas e melhoria contínua para lidar com as condições em constante mudança. É aí que entra a cultura da organização. Resolver um problema uma vez, sem o compromisso com a melhoria contínua, pode fazer com que a organização perca o verdadeiro valor da análise a longo prazo.\n\nEstamos presenciando hoje uma grande mudança em direção a organizações com uma infraestrutura centrada em dados. Os dados não estão mais apenas no centro de dados, mas também na nuvem e na borda. Com o processo de negócio no topo, levando a melhorias contínuas, compreensão dos negócios e dos dados, e até mesmo a implementação, organizações construídas com base nessa infraestrutura podem perceber uma diferença significativa.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT18-pt","image":"./episodes/edt-18/pt/thumbnail.png","lang":"pt","summary":"Sarah Kalicin, Cientista de Dados Líder na Intel, e Darren Pulsipher, Arquiteto Principal de Soluções, Setor Público da Intel, falam sobre o processo e os benefícios da coleta e preparação de dados para se tornar uma organização centrada em dados. Este é o segundo passo na jornada de se tornar uma organização centrada em dados."},{"id":83,"type":"Episode","title":"IA Gerativa no Ensino Superior (Revisitado)","tags":["embracingdigitaltransformation","darrenpulsipher","lauranewey","generativeai","aiineducation","educationtransformation","teachingexperience","aiinclassroom","moderneducationdynamics","criticalthinkingskills","digitaltransformation","resistanceagainstai","traditionalteaching","incoorporatingai","ineducationalcurriculums","innovationandeducation","ethicalusageofai","academicintegrity"],"body":"\r\n\r\n## Como a IA Generativa Melhora a Experiência em Sala de Aula\n\nA IA generativa está rapidamente se integrando aos currículos educacionais, impactando como os educadores abordam o ensino e aprimorando fundamentalmente a experiência de aprendizagem. De acordo com Newey, essa tecnologia muito debatida não é meramente uma forma de plágio, mas uma ferramenta brilhante que aumenta e revitaliza as metodologias educacionais. Incentivando os alunos a usar a IA em tarefas de pensamento, ela enfatiza o cultivo e a colheita de habilidades de pensamento crítico em nossa sociedade que se digitaliza em ritmo acelerado.\n\nEm vez de permanecerem como participantes passivos, ela defende que os alunos se tornem jogadores ativos, analisando os resultados gerados pela IA e considerando a qualidade e substância de suas informações de entrada. A mudança sublinha a importância do entendimento, pesquisa e análise em vez da mera geração de resultados.\n\n## Transição do Ensino Tradicional\n\nA abordagem progressiva de Newey diverge dramaticamente dos métodos convencionais aos quais a maioria dos educadores se apega, especialmente considerando a resistência geral em relação à integração da IA Generativa em ambientes educacionais. No entanto, ela enfatiza a inevitabilidade e a necessidade de adotar a digitalização para a vantagem geral dos alunos.\n\nComparar essa transição com a resistência inicial ao uso da internet como ferramenta de ensino indica onde estamos hoje. A IA generativa, como qualquer outra tecnologia em evolução, exige incorporação ao currículo e demanda atualizações regulares para relevância nesta paisagem digital acelerada.\n\n## Equilibrando Inovação e Ética\n\nCom progressão e inovação, Newey também aborda as considerações éticas inerentes a essa mudança. Ela compartilha várias instâncias onde os alunos, inconscientemente ou sutis, submetem trabalhos gerados por IA. Portanto, ela enfatiza a necessidade dos educadores de equilibrar vigilante o abraço tecnológico e o uso ético.\n\nEla acredita firmemente que os alunos podem usar a IA como uma ferramenta produtiva, mas a responsabilidade também recai sobre os educadores para orientá-los a manter a integridade acadêmica simultaneamente.\n\n## Conclusão: Pavimentando o Caminho para um Sistema de Educação Melhorado pela IA\n\nA incorporação de IA Generativa na educação, embora tenha encontrado resistência, é uma indicação profunda da mudança na paisagem educacional. Como Newey ilustra, a integração bem-sucedida da IA na educação pode melhorar significativamente as experiências de aprendizagem e o desenvolvimento de habilidades essenciais, garantindo a preparação de nossos alunos para um futuro moldado pela transformação digital.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Laura Newey","Darren W Pulsipher"],"link":"/episode-EDT180-pt","image":"./episodes/edt-180/pt/thumbnail.jpg","lang":"pt","summary":"No episódio desta semana de Abraçando a Transformação Digital, Darren Pulsipher entrevista a palestrante convidada Laura Newey sobre sua fascinante jornada pelo mundo emergente e crítico da IA Generativa, particularmente no setor educacional. Cobrindo a transformação de sua experiência de ensino e enriquecendo os resultados de aprendizado de seus alunos por meio da IA, ela analisou extensivamente como se adaptar às dinâmicas modernas da educação."},{"id":84,"type":"Episode","title":"Zero Confiança no 5G","tags":["5gtechnology","zerotrustsecurity","embracingdigitaltransformationpodcast","darrenpulsipher","lelandbrown","yazkrdzalic","kenurquhart","trentonsystems","zscaler","advancedcommunications","operationaltechnology","informationtechnology","lonelyislandapproach","telecominfrastructure","advancedsecuritymodels","commercial5gusage","military5gusage","technicalchallenges","cybersecurity","5gsecurity","integration","solutionarchitecture"],"body":"\r\n\r\n## A Expansiva Paisagem 5G e Abordagem da Ilha Solitária\n\nO mundo da tecnologia 5G está evoluindo rapidamente e, como resultado, estão ocorrendo muitas discussões perspicazes sobre a fusão da Tecnologia Operacional (OT) e a Tecnologia da Informação (IT). Yazz Krdzalic descreve o conceito da \"abordagem da Ilha Solitária\". Esta abordagem se refere à tendência de diferentes entidades se concentrarem excessivamente na resolução de seus problemas individuais, o que muitas vezes levou ao estancamento do crescimento do hardware personalizado na infraestrutura de telecomunicações.\n\nA necessidade de romper com essa abordagem individualista e restabelecer um arcabouço arquitetônico coletivo que possa escalar e flexibilizar com diferentes casos de uso está se tornando cada vez mais aparente. Com o surgimento da tecnologia 5G, há uma necessidade de uma abordagem colaborativa que possa acomodar as várias exigências de diferentes entidades. A abordagem coletiva ajudará a garantir que a infraestrutura seja flexível e escalável, facilitando para que as entidades integrem suas tecnologias e aplicações à rede.\n\nAs discussões sobre a fusão de OT e IT também estão ganhando impulso, e está se tornando claro que a colaboração entre esses dois domínios é essencial para o sucesso da tecnologia 5G. Conforme a tecnologia continua a evoluir, espera-se que haja mais debates e discussões sobre como aproveitar as oportunidades apresentadas pelo 5G, ao mesmo tempo que aborda os desafios apresentados pela tecnologia emergente. No geral, o futuro da tecnologia 5G parece brilhante, e a colaboração entre diferentes entidades desempenhará um papel crítico em seu sucesso.\n\n## Transitando para a Segurança Zero Trust\n\nÀ medida que a tecnologia continua a evoluir, as preocupações com a segurança tornaram-se uma questão crescente para indivíduos e organizações. Para abordar essas preocupações e garantir um ambiente seguro, é necessário um framework arquitetônico coletivo. Este framework inclui a implementação de modelos de segurança avançados, como a Segurança Zero Trust. No entanto, a transição para esses modelos nem sempre é fácil. Requer abandonar métodos antigos de operação e garantir que todos os módulos tecnológicos estejam sincronizados e funcionando corretamente. No passado, eram os clientes que tinham a responsabilidade de integrar todas as peças. Felizmente, com a adoção de uma abordagem mais evoluída, a responsabilidade da integração foi consideravelmente reduzida para os clientes, tornando a implementação da Segurança Zero Trust e outros modelos de segurança avançados um processo muito mais suave.\n\n## Encontrando o Terreno Comum no Uso do 5G\n\nO desenvolvimento da tecnologia 5G tem sido um divisor de águas em ambos os setores comercial e militar. No entanto, existem requisitos específicos que diferenciam o uso comercial e militar do 5G. As implementações comerciais de redes 5G privadas são em grande parte estáticas, enquanto as implementações militares precisam ser móveis.\n\nLeland Brown, um especialista proeminente no campo, discutiu as complexidades de encontrar uma arquitetura comum que poderia atender a ambas as necessidades. O desafio era criar uma solução final que atendesse elegantemente a esses requisitos. Era importante garantir que a solução fosse eficiente e eficaz tanto para casos de uso comercial quanto militar.\n\nO desenvolvimento de tais soluções é crucial para garantir que a tecnologia 5G seja utilizada em seu máximo potencial e possa atender às diversas necessidades de diferentes indústrias.\n\n## Concluindo\n\nO mundo da tecnologia está constantemente evoluindo e melhorando, e o advento da tecnologia 5G e da segurança Zero Trust é um testemunho disso. No entanto, implementar esses avanços pode ser desafiador devido a obstáculos técnicos e culturais. Felizmente, especialistas como Leland Brown, Ken Urquhart e Yaz Krdzalic estão trabalhando para simplificar a integração da tecnologia 5G e da segurança Zero Trust, tornando a jornada para um futuro tecnológico mais seguro e eficiente um pouco mais fácil para todos. Os insights e a experiência deles estão lançando luz sobre o contínuo processo de evolução e aperfeiçoamento no mundo da tecnologia.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Leland Brown","Yazz Krdzalic","Ken Urquhart","Darren W Pulsipher"],"link":"/episode-EDT181-pt","image":"./episodes/edt-181/pt/thumbnail.jpg","lang":"pt","summary":"No meio da crescente adoção de tecnologias 5G em todo o mundo, os especialistas no recente episódio do podcast Embracing Digital Transformation se aprofundaram no tópico integral de Zero Trust na segurança 5G. O apresentador Darren Pulsipher recebeu o especialista em comunicações avançadas 5G Leland Brown, VP de Marketing na Trenton Systems Yazz Krdzalic, e Ken Urquhart, um físico transformado em profissional de cibersegurança da Zscaler, para discutir a integração e avanço da tecnologia 5G, juntamente com seus desafios e avanços."},{"id":85,"type":"Episode","title":"Garantia de Dados de Zero Confiança","tags":["digitaltransformation","dataintegrity","zerotrust","cybersecurity","strategies","walacor","encryption","loganalysis","geographicaldistribution","externalhackers","organizationalthreats","datamanagement","dataaudits","immutableauditlog","systemchange","legalcompliance","reducerisk","dataintelligence","multilayeredsecuirty","dataprotectionsolution","keyvulnerabilities","improveddataprotection","futuredigitalbusinesses","revolutionizedigitallandscape"],"body":"\r\n\r\n## Desmascarando Suposições Sobre Segurança de Dados\n\nNo passado, as pessoas tinham uma confiança implícita de que seus dados estavam seguros e sua privacidade protegida. No entanto, essa confiança muitas vezes se baseia em um modelo ultrapassado que já não se alinha com o atual panorama tecnológico. O crescente número de violações de dados e ataques cibernéticos tornou evidente que a segurança de dados é mais crítica do que nunca, e as precauções que eram consideradas adequadas no passado podem não ser mais suficientes.\n\nHoje, os dados estão vulneráveis a ameaças não apenas de hackers externos, mas também internamente nas organizações. É essencial entender que uma violação de dados pode ter implicações significativas, desde perdas financeiras até danos à reputação. Portanto, é crucial implementar uma abordagem de confiança zero para a gestão de dados, o que significa que cada pedido de acesso aos dados deve ser verificado antes que o acesso seja concedido. Auditorias de dados confiáveis também são necessárias para garantir que a entrada de dados corresponda à saída e que não haja acesso não autorizado a informações sensíveis.\n\n## Implementando uma Nova Era de Segurança de Dados com a Walacor\n\nA Walacor fornece uma solução única para melhorar nosso entendimento sobre segurança de dados. Eles oferecem um log de auditoria automático e à prova de falhas que é imutável, o que significa que, uma vez inseridos os dados, eles nunca podem ser alterados ou excluídos sem serem detectados. Essa característica torna incrivelmente fácil rastrear todas as alterações feitas no sistema, o que é essencial para manter um ambiente seguro.\n\nAo proporcionar transparência e rastreabilidade, a solução da Walacor ajuda as organizações a cumprir os requisitos legais de conformidade e a mitigar riscos. Por exemplo, em uma disputa legal, um registro de auditoria imutável pode servir como uma fonte confiável de evidência, pois não pode ser adulterado. Além disso, no evento de uma violação de dados, um registro de auditoria imutável pode ajudar a identificar a fonte da violação e a extensão do dano causado.\n\nNo geral, a abordagem inovadora da Walacor para segurança de dados, com seu registro de auditoria 100% imutável, oferece uma solução promissora para organizações que buscam aprimorar sua postura de cibersegurança.\n\n## Modelando o Futuro da Inteligência de Dados\n\nO risco crescente de violações de dados significa que precisamos nos afastar do uso de múltiplas camadas de segurança de dados para uma solução de proteção de dados mais integrada. Este tipo de solução estabelece a base para um ambiente de Zero Confiança, que reduz significativamente o risco de ameaças e vulnerabilidades cibernéticas. Ao adotar esta abordagem, podemos simplificar nossos métodos de proteção de dados e garantir uma melhor integridade dos dados.\n\nO desenvolvimento de inteligência de dados, na forma de integridade e segurança de dados, abre novas possibilidades para negócios digitais. Métodos melhorados de proteção de dados, melhor integridade de dados e uma redução nas possíveis ameaças cibernéticas são apenas alguns dos benefícios que estão prontos para transformar a paisagem digital. Entre estes, o assunto do momento é a abordagem única da Walacor para a integridade dos dados e a confiança zero, que marca um significativo marco na forma como abordamos a segurança de dados agora e no futuro.\n\nConfira mais informações em (https://walacor.com)[https://walacor.com]\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Walter Hancock","Darren W Pulsipher"],"link":"/episode-EDT182-pt","image":"./episodes/edt-182/pt/thumbnail.png","lang":"pt","summary":"A necessidade de estratégias robustas de segurança de dados cresceu exponencialmente na era digital, tornando-se uma prioridade máxima para empresas em todo o mundo. O especialista em cibersegurança e CTO da Walacor, Walter Hancock, oferece uma visão perspicaz sobre a importância da integridade dos dados e uma abordagem de confiança zero nos regimes de cibersegurança atuais."},{"id":86,"type":"Episode","title":"Gestão de Dados em Ciência dos Materiais e Indústrias de Manufatura","tags":["digitaltransformation","materialscience","manufacturingindustry","dataanalytics","machinelearning","artificialintelligence","productdevelopment","structuredmethodologies","projectmanagement","complexdata","unstructureddata","datascience","r&dprocess","newproductdevelopment","datamanagement","technologyinnovation","physicitaldigitalknowledgegap","embracingdigital.org","embracingdigitaltransformationpodcast"],"body":"\r\n\r\n## Abrindo a Lacuna entre o Físico e o Digital em P&D\n\nA Materials Zone está focada no aspecto de nicho, mas significativo, da ciência dos materiais, especificamente na indústria de manufatura. Dado o papel considerável dos materiais no desenvolvimento do produto, gerenciar efetivamente os dados se torna crucial. Análogo a uma receita de cozinha, a ciência dos materiais envolve uma integração matizada de ingredientes (materiais) passados por um processo para produzir o produto final.\n\nNo entanto, esta área tem sido historicamente ad hoc, baseada em tentativa, erro e intuição. Consequentemente, o conhecimento adquirido durante esse processo muitas vezes se perde devido à documentação insuficiente ou à rotatividade de funcionários. Em nosso mundo moderno e interconectado, onde os processos de desenvolvimento de produtos muitas vezes abrangem vários locais, até mesmo países, a criação de metodologias estruturadas para prevenir a perda de conhecimento é crucial.\n\nUma das técnicas destacadas por Yudilevich é lidar com o \"fator caminhão\", que sugere que se a única pessoa que sabe como fazer uma tarefa específica for atingida por um caminhão, poderia potencialmente descarrilar todo o projeto. Portanto, ter pelo menos uma outra pessoa além do indivíduo primário que possa realizar a tarefa poderia diminuir a vulnerabilidade da equipe.\n\n## Capturando Complexidades dos Dados da Ciência dos Materiais\n\nO campo da ciência dos materiais gera dados complexos, muitas vezes não estruturados e difíceis de capturar usando tabelas de dados tradicionais e bancos de dados suficientemente. Para visualizar isso, considere os dados como um gráfico onde matérias-primas se transformam em produtos finais. As inúmeras interações entre os vários constituintes dão origem a múltiplas dimensões únicas dentro dos dados.\n\nAlém disso, existe uma tradução perfeita dentro do setor de fabricação - Da pesquisa exploratória à fase de produção, que exige estabilização e consistência. A compilação de dados dessas fases em um repositório unificado pode melhorar o processo de P&D ao centralizar informações, auxiliando na aprendizagem entre fases e acelerando o desenvolvimento de novos produtos.\n\n## Integrando Ciência de Dados na Manufatura\n\nEmbora a ciência de dados tenha permeado muitas indústrias, empresas focadas principalmente no desenvolvimento de produtos no mundo físico frequentemente consideram a criação de departamentos de dados dedicados ou a integração de ferramentas analíticas ineficiente e dispendiosa. É aqui que a solução da Materials Zone entra em jogo, tornando a ciência de dados, aprendizado de máquina e ferramentas estatísticas acessíveis a empresas não familiarizadas com essas áreas.\n\nEles oferecem ferramentas prontas para uso acompanhadas de webinars e sessões de treinamento para facilitar a adoção, reduzindo assim as barreiras para a integração da ciência de dados nas práticas de fabricação. Surpreendentemente, até mesmo as empresas da Fortune 500 que não possuem as habilidades digitais necessárias podem se beneficiar significativamente dessas soluções.\n\n## Conforme Avançamos\n\nÀ medida que o processo de desenvolvimento de produtos se torna mais complexo e global, a natureza crítica da gestão sistemática de dados combinada com a inovação tecnológica está vindo à tona. Empresas como a Materials Zone estão pavimentando o caminho, orientando as empresas para preencher a lacuna entre o conhecimento físico-digital, reforçar suas práticas de fabricação e garantir o sucesso futuro.\n\nPara mais informações, confira https://materials.zone.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ori Yudilevich"],"link":"/episode-EDT183-pt","image":"./episodes/edt-183/pt/thumbnail.png","lang":"pt","summary":"Em uma paisagem tecnológica em rápida evolução, líderes de diversos setores aplicam análise de dados, aprendizado de máquina e inteligência artificial em suas operações. Hoje, olhe mais a fundo para uma empresa que impulsiona a transformação digital na indústria de manufatura - Ori Yudilevich, o CTO da Materials Zone."},{"id":87,"type":"Episode","title":"Usando dados como um recurso estratégico","tags":["dataarchitecture","data","datastrategy","people","process"],"body":"\r\n\r\nAssim como algumas pessoas acumulam coisas em suas casas, com medo de jogar algo fora, as organizações também podem acumular dados. Por exemplo, minha pasta de emails tem 8 gigabytes. Eu sei que\n\nNão precisa ser tão grande, mas eu guardo coisas no caso de eu precisar delas. Agora multiplique isso pelo número de funcionários. Na Intel, temos cem mil funcionários. Imagine a quantidade de dados que estamos armazenando, apenas em emails, quando fazemos backups. Adicione bancos de dados estruturados e não estruturados, apresentações, planilhas, etc... e fica claro que simplesmente armazenar tudo não é uma estratégia ótima.\n\n## Estatísticas de dados\n\nVamos analisar as estatísticas que mostram por que essa é uma estratégia ruim. Aproximadamente 80% do tempo dos cientistas de dados é gasto na limpeza dos dados antes de poderem utilizá-los. Menos de 50% dos dados estruturados estão sendo utilizados, e menos de 1% dos dados não estruturados podem ser analisados. Portanto, todos esses dados estão sendo acumulados, mas as organizações, em sua maioria, não os estão utilizando. Outra questão é quem tem acesso a todos esses dados armazenados. É alarmante que 70% dos funcionários tenham acesso a dados que provavelmente não deveriam ter. Assim como as pilhas desorganizadas de um acumulador criam riscos de incêndio em casa, pilhas desorganizadas de dados criam riscos de segurança em uma organização.\n\n## Explosão de dados\n\nO que podemos fazer sobre esse problema? Primeiro, precisamos entender por que há uma explosão tão grande de dados. Com o IoT, tudo está conectado, e temos processamento de dados acontecendo em diversos lugares. O volume de dados que está sendo gerado é incrível. Isso é agravado por questões regulatórias; é difícil saber o que podemos descartar e o que não podemos. Enchemos nosso armazenamento e então compramos mais. A tecnologia basicamente possibilita que acumulemos dados. Precisamos analisar o que podemos fazer de forma diferente.\n\n## Por que guardamos tantas coisas\n\nEspecialistas dizem que as pessoas acumulam coisas porque acreditam que um item será útil ou valioso no futuro, possui valor sentimental, é único e insubstituível, ou é uma pechincha grande demais para jogar fora. Essas mesmas ideias se aplicam ao acúmulo de dados. Por exemplo, por que eu tenho uma das primeiras apresentações que já fiz? Está armazenada em um disco e está na nuvem. Eu a vejo talvez uma vez por ano, mas não tenho nenhum motivo real além do valor sentimental para mantê-la. Uma organização é composta por indivíduos com esses comportamentos, e em todos os níveis diferentes de acumulação de dados, há medo de se livrar deles.\n\n## Tornando-se centrado em dados.\n\nComo seria tornar-se uma empresa orientada a dados em vez de uma empresa de armazenamento? Aqui está um processo em quatro etapas para se tornar uma organização orientada a dados.\n\n## Fundação Organizacional\n\nO primeiro passo é criar uma base organizacional centrada em dados. Existem quatro atores-chave com papéis distintos.\n\nChefe de Dados: O trabalho do chefe de dados é definir estratégias e governança sobre a gestão de dados e a geração de informações valiosas para os negócios. Essa função é diferente daquela do chefe de informações, que se concentra na infraestrutura em vez das informações em si. Esse é um trabalho difícil, pois o chefe de dados está envolvido em mudanças culturais. Eles tentam evitar que as pessoas acumulem dados e, em vez disso, os utilizem para criar valor real para os negócios.\n\nCientista de Dados: Cientistas de dados desenvolvem modelos e projetos encontrando padrões nos dados e usando análises preditivas. Os esforços dos cientistas de dados podem se tornar simplesmente um experimento científico pontual, no entanto, a menos que a informação seja operacionalizada.\n\nEngenheiro de Dados: É aqui que os engenheiros de dados entram em ação. Eles gerenciam os pipelines de dados e operacionalizam análises. À medida que novos dados são recebidos, novas informações são geradas sem precisar começar do zero a cada vez.\n\nData Steward: O data steward gerencia a governança e o acesso aos ativos de dados, garantindo que as pessoas certas tenham o acesso certo no momento certo.\n\nCom uma organização que inclui esses quatro papéis, a próxima grande questão é se centralizar ou distribuir as operações. Por exemplo, talvez a gestão matricial distribuída já esteja funcionando em sua grande organização, mas uma organização menor pode precisar de mais rigidez e se beneficiar de uma estrutura mais centralizada.\n\n## Coleta e Preparação de Dados\n\nUm artigo da Harvard Business Review usa efetivamente uma analogia esportiva para descrever duas estratégias de catalogação de dados: defesa e ataque. Na defesa, o objetivo é proteger os dados. No ataque, o objetivo é avançar rapidamente para marcar pontos.\n\n## Defesa e Ataque de Dados\n\nCom uma estratégia defensiva, a organização está principalmente focada em segurança de dados, governança e conformidade. Proteger os dados é fundamental. A principal atividade de dados estará centrada em extração, padronização, gerenciamento de armazenamento e gerenciamento de acesso. Tipicamente, esta estratégia usará uma organização mais centralizada e utilizará uma única fonte de verdade.\n\nCom uma estratégia ofensiva, a organização está principalmente focada em agir rapidamente para melhorar sua posição competitiva e obter o máximo de lucratividade possível. As atividades de dados se concentrarão em extração, modelagem, visualização, transformação e enriquecimento.\n\nEsta estratégia exigirá mais flexibilidade, o que significa uma organização mais distribuída com múltiplas versões da verdade.\n\nCompreender como usar os dados com base na estratégia é importante. Frequentemente, as organizações ficam indecisas e isso pode ser confuso. Embora todas as organizações precisem ser capazes de se defender e atacar, elas devem escolher uma estratégia em vez de tentar fazer as duas coisas, assim como jogadores de futebol em nível profissional não jogam dos dois lados da bola.\n\n## Análise de Insight\n\nExiste uma curva de maturidade organizacional para a análise e construção de insights a partir dos seus dados. A chave é entender onde sua organização está atualmente posicionada e quais são os próximos passos para subir na curva.\n\nNa etapa de análise descritiva, você está apenas tentando descobrir o que está acontecendo. No passo de diagnóstico, você está descobrindo por que algo aconteceu. No passo de previsão, você pode prever o que acontecerá no futuro com base em dados históricos. Aqui é onde muitas organizações se esforçam para estar, mas os dois primeiros passos devem ser alcançados primeiro. Acima da previsão está o prescritivo, onde você pode entender por que algo acontecerá e guiar a organização de acordo com as expectativas. No topo dos passos está a perspicácia analítica, ou visão de futuro, onde você está fazendo as coisas acontecerem, até progredindo além do prescrito.\n\nUma razão pela qual é importante entender onde sua organização está atualmente é porque existem ferramentas específicas para cada fase. Por exemplo, você não quer ficar preso a um projeto de IA que esteja utilizando algoritmos prescritivos, ou até mesmo preditivos, quando sua organização ainda está na etapa descritiva.\n\n## Operacionalize isso\n\nPara alcançar o objetivo de operacionalização, ou seja, tornar um processo repetitivo, existem três elementos-chave: uma infraestrutura centrada em dados, pipelines de dados e fluxo de negócios.\n\nA infraestrutura centrada em dados permite que você saiba onde todos os seus dados estão e o que há nesses dados por meio de várias ferramentas, como um gerenciador de metadados como o elastic search ou catálogos e repositórios de metadados. Os pipelines de dados possuem ótimas ferramentas para permitir o processo, desde a ingestão até a análise e a ação. Uma estratégia defensiva ou ofensiva determinará quais ferramentas você usará em seu pipeline. O último elemento, o fluxo de negócios, é onde o entendimento dos negócios sobre seus dados e processos permitirá a implantação de um processo de melhoria contínua para garantir insights repetíveis e valiosos.\n\n## Chamada para ação\n\nPrimeiro, desenvolva uma estratégia de dados. Organize-se e descubra onde estão todos os seus dados e catalogue-os. Decida por uma estratégia defensiva ou ofensiva e, em seguida, tome suas medidas de análise de insight uma de cada vez, utilizando as ferramentas corretas. Mais importante ainda, operacionalize seus insights para obter o melhor valor comercial.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT19-pt","image":"./episodes/edt-19/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto Chefe de Soluções da Intel para o Setor Público, explora como as organizações podem passar de simplesmente acumular dados para usá-los como um ativo estratégico."},{"id":88,"type":"Episode","title":"Segue o Bit","tags":["iot","dod","edge","technology","data","cybersecurity"],"body":"\r\n\r\n## Internet das Coisas é o Começo\n\nA implementação generalizada da Internet das Coisas (IoT) tem levado mais tempo do que a indústria esperava. Muitos culpam os atrasos na adoção e implantação do 5G em todo o mundo, mas há outro problema que tem desacelerado o desenvolvimento de sistemas robustos de IoT: o gerenciamento da complexidade. À medida que os dados se movem pelo sistema, passando pela borda, borda agregada, rede, centro de dados e nuvem, garantir a segurança dos dados é uma preocupação importante, uma vez que a superfície de ataque aumenta à medida que ele sai do data center tradicional. Existem soluções pontuais que ajudam a melhorar esses problemas, mas ainda não há uma arquitetura de solução completa que resolva todos os problemas com esse data center sem paredes.\n\n## Complexidade do ambiente do Departamento de Defesa\n\nA IoT já é complexa e o DOD aumenta a complexidade devido aos tipos de produtores e consumidores dos dados. No lado do produtor, sensores são conectados a satélites, aeronaves, navios e veículos; até mesmo os soldados em combate são praticamente centros de dados ambulantes. A quantidade de dados que esses dispositivos produzem pode sobrecarregar uma rede. O número de dispositivos heterogêneos pode tornar sua gestão quase impossível, especialmente quando os dispositivos utilizam diferentes protocolos e possuem diferentes níveis de classificação. Em outras palavras, coletar os dados não é o problema; o desafio está em disponibilizá-los de forma útil e rápida para aqueles que tomam as decisões.\n\nAlém disso, a conectividade pode ser problemática com dispositivos de borda. Ambientes hostis onde a conectividade de rede para um centro de dados é inexistente ou instável podem atrasar os dados. Isso significa que uma solução nesse espaço deve funcionar nos modos de operação conectado e desconectado. A velocidade de entrega é um fator-chave de sucesso; vidas podem estar em risco se as decisões baseadas nos dados forem atrasadas.\n\n## Estrutura comum para Aplicações, Dados e Segurança.\n\nObviamente, precisamos de soluções para esses problemas. De suma importância é ter um framework comum para gerenciar a complexidade dessas novas arquiteturas de TI que estão além das paredes tradicionais dos centros de dados. O framework precisa abordar a gestão de aplicativos, dados e segurança. Precisamos ser capazes de implantar aplicativos portáteis e reutilizáveis ​​em qualquer lugar do sistema, do dispositivo à nuvem: a doutrina de \"escrever uma vez, executar em qualquer lugar\". Isso nos dá a capacidade de desenvolver, testar e implantar aplicativos rapidamente, sem precisar configurar todas as permutações de configurações de hardware no ecossistema. O uso de ferramentas no ecossistema de contêineres deve ajudar com isso. Ferramentas baseadas em Kubernetes (K8s) são uma boa opção, pois se tornaram o padrão de fato na comunidade DevOps.\n\nGerenciar aplicativos em isolamento, no entanto, não é suficiente. Todos os aplicativos precisam de dados de alguma forma, portanto, entender onde os dados estão, para onde estão indo e como estão classificados é fundamental para soluções bem-sucedidas. Precisamos de um ambiente operacional comum para gerenciar e governar as diferentes classes de dados, como domínios, limites de segurança, governança, gerenciamento do ciclo de vida dos dados e localização dos dados. Um ambiente operacional comum aumenta a flexibilidade e a velocidade de implantação de aplicativos.\n\nUm framework comum de segurança também é necessário. A questão crucial é como proteger seus dados em todas as suas formas e ainda compartilhá-los? Existem soluções atuais de hardware e software e uma progressão contínua nessa área. Soluções básicas de segurança, como criptografia, devem ser fundamentais. Claro, isso requer o motor de armazenamento e capacidade adequado. Outra preocupação é a entrada de dados errôneos ou maliciosos no sistema. Estabelecer uma raiz de confiança como base também é necessário nesse vasto ecossistema.\n\n## Processamento na borda, datacenter e nuvem\n\nOnde a Intel entra em jogo nesse ambiente? Podemos ajudar a fornecer a infraestrutura subjacente que suporta esses sistemas em desempenho e energia. Seja processando informações do sensor na borda em um ambiente de baixa potência (pense em designs Atom e ASIC personalizados), ou fazendo treinamento de Inteligência Artificial ou inferência em seu centro de dados (Xeon e computação neuromórfica), a Intel possui um processador que pode ajudar a converter dados brutos em informações valiosas e acionáveis, o principal componente nesse ambiente complexo e voltado para missões.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT2-pt","image":"./episodes/edt-2/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren entrevista Greg Clifton, Diretor do Departamento de Defesa (DOD) e Inteligência da Intel Corp. Eles discutem os desafios do gerenciamento de dados em um sistema complexo que abrange várias nuvens, centros de dados corporativos, centros de dados regionais e margem tática. Ouça Darren e Greg seguindo um pouco de dados desde a sua coleta e jornada por esse ecossistema até a produção de informações acionáveis para analistas e combatentes. Ouça Darren e Greg discutindo alguns dos obstáculos nesse ambiente amplo e circular e soluções para ajudar a fornecer informações acionáveis para os analistas e de volta aos combatentes."},{"id":89,"type":"Episode","title":"Destruindo a Complexidade das Camadas de Armazenamento","tags":["data","optane","technology","storage","vastdata"],"body":"\r\n\r\n## Trinta anos de complexidade de armazenamento\n\nO armazenamento pode ser um conceito antigo, mas a VAST Data alcançou o status de unicórnio em pouco mais de um ano, a partir do envio de receitas. A VAST substituiu a antiga arquitetura de sistemas de armazenamento em várias camadas por um sistema único e monolítico, que é rápido e econômico. As soluções da VAST também eliminam o problema de sistemas de armazenamento grandes e confusos, que consistem em diferentes sistemas de arquivos e arquiteturas diferentes.\n\n## Uma Fundação para uma Nova Arquitetura\n\nO fundador da VAST estava olhando para o armazenamento de uma perspectiva totalmente nova. Ele descobriu que os clientes não necessariamente precisavam de mais desempenho do Flash, mas sim de suporte para armazenamento de arquivos e objetos a um custo mais baixo. Ele aproveitou três tecnologias que não existiam antes de 2018. A primeira é o NVMe over Fabrics, que é usado como um tipo de SAN em escala hiper para conectar tudo com baixa latência. Em seguida, temos o Flash QLC, porque é barato e não possui partes móveis como os discos rígidos. A terceira é o Optane 3D XPoint da Intel. O Optane possui paridade de leitura e gravação e tem alta resistência a um preço razoável. Ao combinar essas três tecnologias, a VAST tem a capacidade de oferecer aos clientes o desempenho totalmente em Flash, mas a um preço comparável ao de um disco rígido. Isso elimina a necessidade de outras camadas que as organizações estão comprando porque são baratas.\n\n## Apresentando o Vast Data Universal Storage\n\nO sistema VAST é a primeira arquitetura desagregada, compartilhada em todos os aspectos. O que isso significa é que a lógica é desagregada do estado do sistema de arquivos. Em vez disso, o estado do sistema de arquivos vive em caixas de dados que contêm QLC Flash e Optane. O Optane é usado como um grande armazenamento de metadados. É multiuso, assim como o sistema, que é chamado de armazenamento universal. Com essas caixas, não há um único ponto de falha, então a capacidade é, teoricamente, ilimitada. (A VAST testou o sistema em cerca de 50 petabytes em um único sistema de arquivos.) Você pode aumentar a capacidade apenas adicionando servidores x86 baratos aos clusters. Por ser um sistema de arquivos paralelo, qualquer usuário pode acessar qualquer parte dos dados de qualquer um dos servidores como se estivesse diretamente conectado, então você pode continuar a expandir.\n\nVocê também pode aumentar o desempenho independentemente da capacidade. A única coisa que inibiria o desempenho do flash é a CPU, então, ao ter a capacidade de aumentar o número de CPUs no cluster de forma contínua, você pode aumentar o desempenho.\n\nUm dos problemas que é resolvido com esta estrutura é a latência. Muitas organizações precisam de baixa latência para todos os seus dados. Como cada um desses servidores sem estado tem acesso a tudo, você tem acesso rápido a todos os dados.\n\n## Arquitetura DASE: Conjuntos de servidores\n\nOutra grande vantagem é que é fácil ajustar o armazenamento de uma organização. A natureza componível dos servidores sem estado e a ausência de comunicação entre eles permitem que você construa um cluster que melhor atenda às suas necessidades. Por exemplo, você pode segmentar suas caixas de controle com base em diferentes cargas de trabalho, mas todas podem acessar os mesmos dados.\n\nAlém disso, o sistema funciona bem com uma organização que precisa de diferentes camadas de classificação para acessar os dados. Você tem a capacidade de segregar o acesso dos usuários, criando várias zonas de acesso com endereços IP virtuais. Um dos desafios do NFS é que ele transmite basicamente para tudo. Se você limitar as transmissões a um subconjunto de endereços IP, você terá a capacidade de separar essas diferentes arquiteturas em sistemas distintos.\n\n## Aplicativo de Pontes de Armazenamento Universal Eras\n\nEsta não é apenas uma solução voltada para clusters de HPC; não é proibitiva em termos de custo. Muitas empresas estão usando o VAST primeiramente para backup, a fim de estabelecer confiança. Por exemplo, o Instituto Nacional do Câncer possui um arquivo de biblioteca de fitas e eles desejavam ter acesso às informações de forma mais rápida. Eles analisaram diferentes plataformas e o VAST surgiu com um preço mais baixo e é totalmente em Flash, o que é mais rápido do que o sistema NAS de produção deles. Portanto, a solução possui um preço atrativo e é útil para compartilhamento geral de arquivos e uma variedade de cargas de trabalho, como IA, análise de logs, Splunk, etc., não apenas para HPC. As soluções da VAST são simples de gerenciar e verdadeiramente universais.\n\nA VAST é uma empresa jovem, mas ela possui várias instalações em agências governamentais, como o Instituto Nacional de Saúde e os Tri-labs do Departamento de Energia, onde é necessária uma performance completa para esses supercomputadores. Este é um sistema poderoso em alguns dos maiores ambientes de HPC do mundo, suportando aplicações críticas para a missão.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Randy Hayes"],"link":"/episode-EDT20-pt","image":"./episodes/edt-20/pt/thumbnail.jpg","lang":"pt","summary":"Randy Hayes, da VAST Data, e Darren Pulsipher, Arquiteto Chefe de Soluções, Setor Público, da Intel, discutem a inovadora arquitetura de armazenamento da VAST Data que elimina a necessidade de camadas utilizando NVMe over Fabrics, QLC Flash e Optane 3D XPoint."},{"id":90,"type":"Episode","title":"Controlador de memória definida por software de grande capacidade","tags":["bigmemory","edge","compute","technology","memverge","optane","pmem","data"],"body":"\r\n\r\nA tecnologia de memória persistente Optane 3D XPoint da Intel revolucionou a MemVerge, permitindo-lhes desenvolver uma memória definida por software, que eles descrevem como expressando o poder do Optane PMEM.\n\n## A melhor forma de usar a PMEM\n\nA MemVerge desenvolveu um software de Big Memory para atender à crescente demanda de aplicativos e empresas em processar dados em volumes e velocidades cada vez maiores. Mais aplicativos em tempo real necessitam de insights e ações instantâneas a partir dos dados. Isso requer uma nova infraestrutura orientada à memória para atender aos requisitos de latência.\n\nAplicações que utilizam AI, aprendizado de máquina ou análise de dados em tempo real de big data, por exemplo, geralmente usam DRAM. Embora a DRAM tenha uma latência em nível de nanossegundos e ofereça boa capacidade e desempenho, ela possui limitações físicas como densidade de memória e a quantidade que pode ser armazenada em um servidor. Além disso, é relativamente cara. Mais importante, é volátil e, à medida que os dados aumentam, a volatilidade da memória se torna uma restrição. PMEM supera essas limitações, pois permite ter maior capacidade, custo mais baixo e persistência.\n\nUm benefício importante é que as empresas não precisam reescrever suas aplicações para usar a tecnologia da MemVerge. A empresa estava procurando a melhor maneira de usar a persistência, e a resposta foi fornecer o mínimo de interrupção aos paradigmas de programação. Quando o Optane PMEM se tornou disponível como formato de memória, isso foi uma oportunidade para desenvolver software valioso como parte da solução.\n\n## Software Defined Memory: Memória Definida por Software\n\nHá uma transformação de dados em andamento. Do ponto de vista de hardware, nos próximos dez anos, provavelmente haverá um mundo mais heterogêneo, tanto em termos de computação quanto de elementos de memória. Surgirá um novo tecido, como o CXL, que conectará esses elementos. O maior desafio será fazer com que o ecossistema de aplicativos se movimente. É necessário uma camada de software para transformá-lo em partes consumíveis e componíveis, o que tornará mais fácil para o aplicativo assimilar. A memória definida por software da MemVerge será um componente importante nesse espaço.\n\nEnquanto isso, a MemVerge está construindo uma ponte entre os paradigmas atuais e futuros. A Memória definida por software da MemVerge traz SLA e QLS dinâmicos, resiliência, persistência de aplicativos, eficiência e desempenho. Essas são todas coisas que normalmente você obtém em uma rede de armazenamento definido por software, mas agora pode obter com a memória, com latência mais baixa e velocidade incrivelmente rápida.\n\n## Desempenho na Máquina de Memória\n\nDuas importantes propriedades intelectuais da MEMVerge estão em jogo. A primeira é uma camada de virtualização de software que otimiza o desempenho da memória - a combinação de PMEM e DRAM - que é muito próxima do desempenho da DRAM. Cada carga de trabalho possui perfis de desempenho diferentes que podem ser ajustados finamente misturando PMEM e DRAM em diferentes proporções. Esse ajuste fino de PMEM e DRAM proporciona aos desenvolvedores de aplicativos e profissionais de TI a capacidade de ajustar a memória de suas aplicações em vez de ajustá-la para toda a máquina. Em vez de configurar as proporções existentes de DRAM e PMEM para toda a máquina, agora é possível alterar dinamicamente as proporções de PMEM e DRAM dependendo da carga de trabalho e até mesmo superar o desempenho da DRAM.\n\n## ZeroIO Instantâneo (Persistência de Dados da Aplicação)\n\nO segundo desses inventos são os instantâneos de memória ou ZeroIO. Ele pode persistir aplicativos transitórios existentes sem a necessidade de quaisquer reescritas. Funciona em cima da memória definida por software, que é um serviço de memória volátil. Mesmo que o PMEM subjacente seja persistente, é necessário ter uma memória volátil para evitar a interrupção de aplicativos existentes. A persistência é aproveitada através do fornecimento de uma interface gráfica ao operador da aplicação e CI para gerenciar os instantâneos. Existe uma funcionalidade de instantâneo, então você pode capturar instantaneamente o estado de um aplicativo inteiro. Em seguida, esse aplicativo pode ser recuperado a qualquer momento no futuro.\n\nIsso torna sua memória não apenas persistente, mas altamente disponível. Após uma falha, você pode realizar uma recuperação instantânea. Se você cometer um erro no banco de dados, pode voltar a um ponto anterior. Você também pode clonar em cima do instantâneo, criando novas instâncias de um aplicativo sem replicar fisicamente a memória. Assim, você pode criar vários processos independentes e os espaços de memória lógica mapeando para o mesmo espaço físico de memória. Isso não apenas economiza memória, mas torna o processo de criação de clones instantâneo. Essa nova tecnologia torna muitas coisas que antes eram impossíveis possíveis.\n\nNão há alterações arquitetônicas no seu programa, mas quando você precisa persistir algo, pode simplesmente fazer um snapshot disso. Isso não altera o modelo familiar de programação, mas acelera muito a entrada/saída de dados. Outro ótimo recurso é que os snapshots se tornam objetos gerenciáveis, então podem ser transportados para qualquer lugar onde você possa reiniciar a aplicação. A migração em tempo real também pode ser habilitada em determinados cenários.\n\n## Casos de uso habilitados para o futuro.\n\nPara uma espiada no futuro, a MemVerge está planejando uma versão 2.0 em cerca de um ano que terá um SDK. Além de usá-lo como uma camada de memória transparente, novos desenvolvedores de aplicativos terão uma nova forma de persistir seus dados. Isso facilitará o desenvolvimento de aplicativos, assim como a modificação de aplicativos existentes.\n\nCom o SDK, os desenvolvedores serão capazes de capturar segmentos da memória do aplicativo ou o perfil completo da memória, proporcionando ao desenvolvedor de aplicativos a capacidade de persistir a memória com as tecnologias de ORM ou mapeamento de memória complicadas de hoje.\n\nEm parceria com a Intel, a MemVerge lançará a primeira versão de seu produto com a memória definida por software e as capacidades de snapshot para disponibilidade geral em 23 de setembro de 2020.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Charles Fan"],"link":"/episode-EDT21-pt","image":"./episodes/edt-21/pt/thumbnail.png","lang":"pt","summary":"Charles Fan, CEO da MemVerge, conversa com Darren Pulsipher, Arquiteto-Chefe de Soluções, Setor Público, da Intel, sobre sua nova tecnologia, Big Memory - controladores de memória definidos por software. A tecnologia utiliza a memória persistente Intel 3D XPoint Optane para preencher eficientemente a lacuna entre arquiteturas atuais e futuras, fornecendo maior capacidade, menor custo e persistência."},{"id":91,"type":"Episode","title":"Um argumento para Multi-Hybrid Cloud","tags":null,"body":"\r\n\r\n## Ambiente atual de nuvem\n\nNos últimos cinco anos, houve uma mudança fundamental no ambiente de TI. O crescimento contínuo da Nuvem Pública e o surgimento de opções de Nuvem Privada deixaram muitos CIOs e departamentos de TI correndo atrás. No mercado competitivo de hoje, muitas equipes de desenvolvimento precisam se mover mais rápido do que a maioria dos departamentos de TI pode entregar. As equipes de desenvolvimento descobriram que Nuvens Públicas como AWS, GCE e Azure são uma opção viável para o antigo estilo de \"TI caseira\" \"debaixo da mesa\". Os provedores de nuvem pública tornaram fácil e rápido criar nova infraestrutura. Não há mais espera por várias aprovações técnicas e comerciais, espaço físico no data center e problemas de fornecimento de fornecedores. Agora, em questão de minutos, uma equipe de desenvolvimento pode ter toda a infraestrutura necessária para seu novo projeto.\n\nAntes da nuvem pública, os CIO(s) podiam facilmente \"andar ao redor\" dos cubículos e contar o número de máquinas de \"TI caseiro\" que estavam funcionando debaixo das mesas das pessoas. Com as máquinas físicas não mais visíveis para os departamentos de TI, torna-se impossível identificar equipes e a infraestrutura de seus projetos. Muitas nuvens públicas deram às organizações a capacidade de consolidar a contabilidade de todas as contas de domínios específicos, mas a visibilidade sobre o que está em execução e quem está trabalhando na infraestrutura ainda é algo um tanto quanto difícil de encontrar. Muitas vezes, esses projetos \"rebeldes\" se tornam visíveis quando ocorre a produção de projetos e é necessário colocá-los em uma infraestrutura segura da empresa. Políticas de segurança, privacidade e regulamentação podem tornar a \"produção\" de projetos quase impossível. Especialmente, se os desenvolvedores tiverem vinculado de forma estreita suas aplicações à infraestrutura de nuvem.\n\nDepartamentos de TI com pensamento avançado estão fazendo o seu melhor para capturar o \"cottage IT\" ao trabalhar com Nuvens Públicas e ISVs para implementar \"portais da empresa\" nas Nuvens. Colocar um portal de passagem é um bom começo para capturar projetos que usam infraestrutura, mas muitas organizações acham que apenas um portal deixa as equipes de desenvolvimento querendo mais. Nos últimos anos, tenho trabalhado com muitas dessas organizações para identificar casos de uso, arquiteturas e tecnologias que ajudam a desenvolver esses portais aprimorados, que chamamos de \"Multi-Clouds Híbridas\" (MCH). Tipicamente, três principais tecnologias são integradas para construir essas MCHs. Plataformas de Gerenciamento de Nuvem (CMP), Frameworks de Automação e ferramentas de Plataforma como Serviço (PaaS).\n\n## Plataforma de Gerenciamento em Nuvem (CMP)\n\nAs plataformas de gerenciamento em nuvem têm como principal responsabilidade gerenciar múltiplas nuvens heterogêneas, tanto públicas quanto privadas. Elas oferecem aos usuários finais a capacidade de gerenciar várias nuvens e sua infraestrutura a partir de uma única interface comum. Essas plataformas são geralmente idealizadas com os administradores de nuvem em mente. Embora o enfoque principal das ferramentas de plataforma de gerenciamento em nuvem seja gerenciar múltiplas nuvens, muitas delas possuem recursos adicionais de PAAS (Plataforma como Serviço) e estruturas de automação, ou pelo menos possuem uma arquitetura de plug-in para suportar essas funcionalidades.\n\n## Casos de Uso abordados.\n\nGerenciando Nuvens Públicas\n\nGerenciando Nuvens Privadas\n\nGerenciando identidades na nuvem\n\nGerenciando infraestrutura em várias nuvens.\n\n## Estruturas de Automação\n\nOs principais responsáveis do Automation Framework são automatizar o desdobramento, gerenciamento e atualização de pilhas de software na infraestrutura. O Automation Framework surgiu da comunidade DevOps e geralmente tem como foco processos repetíveis. Muitas dessas ferramentas incluem linguagens de script que permitem aos engenheiros de DevOps gerenciar e configurar software e serviços de forma repetida. Muitas equipes de DevOps têm bastante conhecimento dessas ferramentas.\n\n## Casos de uso abordados\n\nImplantar software em infraestrutura\n\nGerenciar software em infraestrutura\n\nAtualizar Software e Serviços\n\n## Plataforma como Serviço (PAAS)\n\nA Plataforma como Serviço é principalmente responsável por oferecer um único portal para reutilizar plataformas e implantá-las na infraestrutura. As ferramentas PaaS geralmente são altamente opinativas, levando em consideração o desenvolvedor, o que pode levar a configurações de infraestrutura inflexíveis. Muitas dessas ferramentas possuem um portal na web que permite aos desenvolvedores selecionar serviços e implantá-los na infraestrutura.\n\n## Casos de uso abordados\n\nImplantar/Gerenciar Serviços/Aplicações\n\nGerenciar Catálogo de Serviços\n\nDesenvolver novos serviços/aplicações\n\n## A convergência cria o Hybrid Multi-Cloud (MHC)\n\nPorque nenhuma ferramenta possui todos os casos de uso necessários para gerenciar nuvens, aplicativos, infraestrutura e serviços, as equipes gastam vários \"anos de trabalho\" instalando, configurando e integrando esses três conjuntos de ferramentas juntos. Isso levou ao surgimento de tecnologias que integram essas ferramentas, incluindo novas ofertas de produtos e novos recursos em produtos atualmente disponíveis.\n\nMuitos produtos da CMP estão incluindo PaaS e estruturas de automação em suas soluções. As ferramentas de PaaS estão agora gerenciando várias nuvens. As estruturas de automação estão começando a oferecer portais da web e conectividade para várias nuvens. Muitas das ferramentas estão migrando para a visão Híbrida Multi-Nuvem. Ao decidir qual(is) ferramenta(s) usar, é importante lembrar das bases da ferramenta.\n\n## Implementando uma solução\n\nO ecossistema híbrido e multi-nuvem ainda é relativamente novo e ainda requer algumas integrações complexas entre as ferramentas. Há algumas ferramentas que estão começando a fornecer soluções completas prontas para uso, mas ainda com sua visão particular do mundo. Como o ecossistema é incipiente, existem muitos players e opções. O tempo dirá quem ganhará esse espaço. Por enquanto, será interessante observar a convergência e consolidação das ferramentas enquanto suas funcionalidades amadurecem.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT22-pt","image":"./episodes/edt-22/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher descreve por que um Arquiteto de Nuvem Multi-Híbrida pode estar presente no seu Data Center. A maioria das organizações já possui todos os ingredientes necessários. Elas só precisam saber como eles se encaixam juntos."},{"id":92,"type":"Episode","title":"Criação de Insights em Organizações Centradas em Dados","tags":["aiml","dataarchitecture","datacentric","data","insight","technology"],"body":"\r\n\r\nUsando o exemplo da fabricação de widgets, Darren e Sarah anteriormente falaram sobre o pipeline de dados na tentativa de responder a uma pergunta fundamental do negócio: Quantos widgets produzir. A complexidade torna-se aparente quando se trata de pegar os dados brutos da demanda do cliente, da oferta atual e da perda de rendimento e convertê-los em insights.\n\nO primeiro passo neste processo, antes de você poder decidir quais ferramentas usar, é preparar os dados em uma forma utilizável. Oitenta ou noventa por cento do trabalho de um cientista de dados está em preparar e transformar os dados para que possam ser inseridos em um algoritmo, por exemplo, ou usados para reconhecimento de padrões.\n\nAs ferramentas corretas são complexas. IA e aprendizado de máquina não utilizam um único algoritmo, mas uma infinidade de ferramentas que cientistas de dados utilizam e experimentam em combinações para obter os melhores resultados de insights. Em outras palavras, um único algoritmo não dirá quantos widgets você deve fabricar. Existem muitas partes sobrepostas e as próprias ferramentas são complexas. Além disso, os cientistas de dados têm áreas de especialização diferentes; a ciência de dados é um esporte em equipe. Assim como você não designaria um engenheiro de rede para criar arquitetura de armazenamento, você não contrataria um engenheiro de aprendizado profundo especializado em reconhecimento de imagem para resolver o problema de análise de rendimento. Você precisa contratar os cientistas de dados corretos para projetar e implantar as ferramentas corretas para obter insights sobre suas questões de negócios.\n\nVamos voltar à questão de quantos widgets você deve fabricar. Cada situação e modelo serão diferentes, é claro, considerando o tipo de perguntas, dados e dinâmicas que você possui, mas vamos usar isso como ponto de partida. Uma vez estabelecida essa questão de negócio, a organização passará por um desenvolvimento de maturidade analítica.\n\nPrimeiro, você vai se concentrar no que aconteceu no passado para identificar padrões na demanda por seus widgets. Por exemplo, você pode analisar dados de séries temporais para ver quando a demanda por widgets aumenta e diminui. Quão estável é a informação ao longo do tempo e como você pode usá-la para prever o futuro? Talvez você possa fazer aprendizado de máquina em torno disso para analisar diferentes segmentos de tempo e compreendê-los. Você também pode querer fazer alguma análise de texto, como verificar se as pessoas estão falando sobre seu widget nas redes sociais. O número de curtidas ou compartilhamentos pode ser uma fonte de dados.\n\nVocê poderia fazer algo semelhante com o fornecimento. Quão estável é o fornecimento atual e quanto você entende das dinâmicas do sistema? Observe onde você precisa de um humano para entender as dinâmicas do sistema e incorpore esse conhecimento na maneira como você faz suas análises. Pode haver algum tipo de padrões de aprendizado de máquina que fornecem algumas ideias de insights, então você pode fazer algumas aprendizagem não supervisionada. Aprendizagem não supervisionada é encontrar se existem categorias ou segmentos diferentes dos quais você não está ciente e que se comportam de maneira diferente uns dos outros. Pergunte como você pode rastrear melhor ou obter uma melhor resolução do que está acontecendo nesses grupos.\n\nEm resumo, dependendo de onde os dados estão vindo e o que você está analisando nesses dados, você vai utilizar ferramentas diferentes.\n\nPerda de rendimento é um exemplo da complexidade dos problemas a serem solucionados. Quanto maior a variação na linha de produção, mais desperdício pode ocorrer. A aprendizagem de máquina, nesse caso, irá analisar segmentos e agrupamentos de diferentes tipos de rendimentos. Como quantificar e prever isso?\n\nUma coisa que cientistas de dados fazem aqui é o design de experimentos para tentar estimar a causalidade. Ao girar botões e puxar alavancas de maneira sistemática, é possível ver o que acontece com o rendimento, adicionando controles de processo para evitar desvio.\n\nOutra oportunidade para realizar análises é a confiabilidade. Por exemplo, com a manutenção preditiva, suas ferramentas de manufatura podem ser mantidas de forma oportuna para evitar perdas de rendimento. Você também pode utilizar análise de texto em certas situações, como quando você tem registros escritos de observações e soluções feitas por técnicos ao longo do tempo, para utilizá-los como uma base de conhecimento coletivo.\n\nA aprendizagem profunda em torno do reconhecimento de imagem é outra estratégia para ajudar a prevenir perdas por meio da detecção de erros e falhas, e talvez até mesmo a categorização de defeitos.\n\nO objetivo de tudo isso é, é claro, obter conhecimento valioso para o seu negócio. A chave é o comprometimento com uma organização centrada em dados, mantendo-se flexível e contando com as ferramentas e as pessoas certas para transformar seus dados em insights acionáveis.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT23-pt","image":"./episodes/edt-23/pt/thumbnail.png","lang":"pt","summary":"No artigo 5 de uma série, Iniciando sua Transformação Organizacional para se Tornar Orientada a Dados, Sarah Kalicin, Cientista de Dados Líder, Intel, e Darren Pulsipher, Arquiteto Chefe de Soluções, Setor Público, Intel, discutem como criar insights usando IA e aprendizado de máquina em uma organização orientada a dados."},{"id":93,"type":"Episode","title":"Estratégia Digital e Arquitetura de Dados","tags":["data","dataarchitecture","aiops","secops","devsecops","devops","compute","technology","process"],"body":"\r\n\r\nTer um plano para a transformação digital da sua organização é fundamental para evitar se perder no labirinto de apenas seguir com as últimas e melhores tecnologias e processos. Essa estratégia ao acaso fará com que a sua transformação digital fracasse. Um plano, ou um roteiro, desde onde a sua organização está atualmente até onde você deseja chegar é a parte mais importante de uma transformação efetiva.\n\nOs três elementos-chave que devem ser coordenados e equilibrados no seu plano são organizacional, procedimental e tecnológico.\n\n## Divisões Organizacionais\n\nPara entender a mudança organizacional, vamos primeiro analisar os grupos comuns na maioria das organizações.\n\n## Desenvolvimento\n\nEste grupo é a sua equipe diurna; eles estão desenvolvendo novos produtos. Os processos da equipe de desenvolvimento são bem conhecidos e maduros. Eles se concentram no trabalho de desenvolvimento, teste e lançamento do produto em produção. Quase toda equipe utiliza algum tipo de técnica Ágil ou de iteração rápida.\n\n## IT - Tecnologia da Informação\n\nO objetivo da equipe de TI é otimizar a infraestrutura em termos de custo e eficiência. Eles garantem que a infraestrutura seja confiável e tenha controle e segurança incorporados. Principalmente, eles avaliam computação, armazenamento, rede, conformidade e custos.\n\n## Segurança\n\nO papel da segurança tornou-se cada vez mais importante nos últimos anos, e ainda mais recentemente, com os funcionários trabalhando em casa devido à COVID-19. A equipe de segurança concentra-se principalmente em garantir a propriedade intelectual, os dados e a infraestrutura. As ferramentas comuns são gestão de identidade, proteção, detecção e remediação. Entender como essas ferramentas funcionam em um nível mais alto é importante para a mudança organizacional.\n\n## Data\n\nEste novo grupo, que anteriormente poderia ter sido um estatístico ou matemático que fazia mineração de dados, está agora ganhando força com a chegada dos chefes de dados e das organizações construídas ao redor deles. Eles se concentram em analisar, categorizar e entregar valor real a partir dos seus dados. Seja a sua organização na área de manufatura ou serviços, ou se você está tentando capturar novos clientes ou economizar dinheiro, existem muitas áreas onde cientistas de dados podem fornecer valor.\n\n## Reunindo os Grupos\n\nPara realizar uma mudança digital eficaz, todos esses grupos precisam ter uma compreensão mútua do que cada um traz para a mesa e uma visão unificada. Você não quer que seus cientistas de dados explorem dados que não têm valor para o desenvolvimento ou TI. Você não quer que sua equipe de segurança restrinja tudo tão rigidamente que a equipe de desenvolvimento não consiga concluir seu trabalho. Entre os grupos, deve haver estratégias, processos e arquiteturas comuns.\n\nEmbora objetivos e resultados comuns sejam o ideal, existem obstáculos a serem superados. Uma das áreas mais difíceis na mudança organizacional é a quebra de comunicação nas fronteiras. Algumas organizações criaram novos grupos para suavizar as diferenças entre os grupos. Por exemplo, entre segurança e TI, poderia haver um Sec Ops ou Sec Dev Ops, onde eles automatizam as políticas e procedimentos provenientes da equipe de segurança. Outro exemplo seria uma equipe de desenvolvimento de dados, que são desenvolvedores que trabalham com cientistas de dados para fornecer processos mais repetíveis através do desenvolvimento de aplicativos ou integração de ferramentas e aplicativos. Arquiteturas comuns em conjuntos comuns de ferramentas com as quais todos os grupos podem contar tornam o processo e as mudanças muito mais fáceis.\n\n## O Sistema Perfeito\n\nComo seria uma arquitetura comum? Uma versão utópica não existe hoje, mas podemos analisar os elementos e talvez construir algo em direção a esse ideal.\n\nO autosserviço é essencial. Por exemplo, se um cientista de dados precisa de mais espaço de armazenamento para dados, eles não precisariam ligar para o setor de TI e preencher uma série de formulários etc..., mas sim usar um portal de autosserviço que economiza tempo e forneceria o espaço de armazenamento. Claro que o portal seria orientado por políticas, para que a equipe de segurança possa ter certeza de que os dados confidenciais que o cientista coloca em uma unidade estão criptografados e o controle de acesso é automático.\n\nOutra característica ideal seria que o sistema seja auto-regenerativo e orientado por dados. Se as máquinas forem infectadas, por exemplo, elas seriam automaticamente colocadas em quarentena e as cargas de trabalho seriam migradas para outra área no centro de dados ou para a nuvem pública. Novamente, a TI teria que estabelecer políticas e monitorar processos, mas o sistema seria em grande parte automático. O sistema não deve ser apenas automático, mas também inteligente, aprendendo com experiências passadas e se tornando mais eficiente.\n\nPodemos obter alguns elementos deste sistema utópico hoje em dia com produtos prontos para uso, integrando-os e fazendo com que todos os utilizem. Vamos analisar o que cada organização deseja desta arquitetura.\n\n## Arquitetura de TI (Multi-Nuvem Híbrida)\n\nA TI é responsável pela infraestrutura subjacente e pelas informações de dados na organização. Se a TI pudesse estabelecer uma base sólida, todos os outros poderiam construir em cima dela. A TI precisa migrar para uma solução de nuvem multi-híbrida para que a infraestrutura possa ser facilmente orquestrada conforme necessário, com flexibilidade baseada em política. Sempre há uma troca entre custo e confiabilidade, mas você tem opções. Uma camada de infraestrutura definida por software permite facilmente a orquestração de computação, armazenamento, rede, segurança e agora até coisas novas, como memória e aceleradores. A base de nuvem multi-híbrida é um aspecto-chave de sua arquitetura comum.\n\n## Arquitetura de Segurança\n\nA equipe de segurança adicionaria a este sistema e o tornaria o mais automatizado possível. O primeiro aspecto seria a identidade. Isso significa que não apenas é possível identificar usuários, mas também infraestrutura, aplicativos e serviços, para que tudo tenha uma identidade. Essas identidades podem estar vinculadas a autorizações e acessos específicos para garantir que tudo esteja autenticado. Em relação à segurança, é desejável ter criptografia e remediação quando houver problemas. Idealmente, seria possível estabelecer uma raiz de confiança para que tudo no ecossistema, tanto em aplicativos e serviços quanto em firmwares e BIOS das máquinas, seja confiável.\n\n## Arquitetura de Desenvolvimento\n\nOs desenvolvedores podem se preocupar que todo esse processo possa retardar o desenvolvimento, então ele precisa acontecer quase automaticamente. A maioria dos desenvolvedores agora está focada em componentes reutilizáveis ​​que podem ser testados para que eles saibam que estão seguros. Eles fazem isso por meio de ecossistemas em contêineres como Kubernetes, Docker ou Mesos. A segurança pode ser injetada no ciclo de vida do desenvolvimento na etapa de implantação antes de ser movida com sucesso para a produção. Acima da camada de serviço está uma camada de aplicação onde os desenvolvedores podem aproveitar os fluxos de trabalho. Esses fluxos de trabalho podem ser fluxos de trabalho de desenvolvimento como CI/CD ou fluxos de trabalho de negócios por meio de ferramentas de automação como Robotic Process Automation. Ter tanto a camada de serviço quanto a camada de aplicação são elementos-chave nesta arquitetura utópica.\n\n## Arquitetura de Dados\n\nCom dados dispersos por vários ecossistemas, nuvens públicas e até mesmo nas bordas, precisamos de uma forma melhor de gerenciar dados para cientistas de dados e desenvolvedores de aplicativos. Extrair dados do armazenamento é um dos elementos importantes aqui. Com essa estrutura, você pode orquestrar dados em toda a vasta infraestrutura e vincular esses dados apenas às aplicações e serviços onde são necessários. Os dados podem ser abstraídos para serem armazenados na melhor posição durante esse período de tempo, seja nas bordas, no centro de dados ou processados em vários locais diferentes para réplicas de aplicativos. A segurança seria necessária para proteger os dados, uma vez que os dados são o motivo da infraestrutura em primeiro lugar. Algumas empresas iniciantes estão competindo neste espaço para assumir o controle da camada de gerenciamento de dados.\n\nEsta arquitetura utópica, com sua infinidade de partes móveis, é chamada de arquitetura Edgemere. Estamos tentando analisar como todas essas partes se encaixam para ajudar as organizações a acelerar sua transformação digital. Precisamos entender o que cada organização precisa, quais são seus casos de uso e quais são as semelhanças entre os grupos para desenvolver uma arquitetura na qual toda a organização possa trabalhar.\n\nA parte da sua organização é romper as barreiras entre os grupos, desenvolver uma visão comum de onde você quer estar organizacionalmente, procedimentalmente e arquitetonicamente, e desenvolver uma rota para como chegar lá.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT24-pt","image":"./episodes/edt-24/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções, Setor Público, Intel, descreve a estratégia digital e a arquitetura para transformar efetivamente sua organização. Ele explica como os elementos organizacionais, procedimentais e tecnológicos devem ser equilibrados para funcionar de forma eficiente em direção a uma arquitetura comum e ideal que apoie uma visão unificada."},{"id":94,"type":"Episode","title":"Operacionalizando pipelines de dados","tags":["dataarchitecture","datacentric","data","datamesh","datapipeline","technology","people"],"body":"\r\n\r\nPara o episódio final desta série, Darren fala com Sarah Kalicin, Cientista de Dados Líder da Intel, sobre como operacionalizar seu pipeline de dados. Eles discutem como, uma vez que você tenha as informações de seus dados, você pode transformá-los de um experimento científico único em uma fonte contínua de informação.\n\n## Como operacionalizamos as ideias dos insights analíticos?\n\nA primeira coisa a entender sobre o pipeline de dados é que não é como um sistema elétrico fechado que você pode configurar, deixar de lado e, seis meses depois, ligar um interruptor e saber que a lâmpada acenderá. Um pipeline de dados é diferente porque os dados são variáveis; eles podem mudar ou degradar, por exemplo, então você não necessariamente será recompensado com a lâmpada acendendo em algum momento, ou neste caso, a visão que você está procurando. Você sempre tem que pensar no que pode dar errado no sistema e como corrigir esses curtos-circuitos.\n\nDetectar anomalias é uma parte integral do pipeline. Não é possível planejar tudo, então você precisa pelo menos ser capaz de ver quando algo aconteceu fora dos limites da análise original. Um exemplo é a crise da COVID, um evento imprevisível que causou padrões bem fora do normal para muitos sistemas. Outro exemplo seria uma empresa que produz widgets. Para saber quantos widgets produzir, o pipeline de dados contém a demanda dos clientes, o suprimento atual e a perda de rendimento. Eles podem ser bastante estáveis ao longo do tempo, mas pode haver, por exemplo, um evento de relações públicas que faça com que a demanda dos clientes exploda. Isso pode ter um grande impacto nos modelos. Aprendizado de máquina e aprendizado profundo analisam padrões conhecidos e, se nunca tiverem visto esses padrões antes, os modelos vão falhar ou degradar. Você precisa se manter à beira da descoberta.\n\nA única maneira de se manter no limite da descoberta é ter suas linhas de dados automatizadas para acesso oportuno à informação. Essa é a vantagem competitiva: dados atuais e perspicazes que podem ajudá-lo a resolver suas perguntas rapidamente.\n\nAs equipes de TI e de dados precisam colaborar na automação e determinar o que deve ser automatizado para os dados recebidos, bem como gerenciar quaisquer alterações no modelo que os cientistas de dados desejam fazer, para que possa ser facilmente integrado novamente ao fluxo de trabalho.\n\n## Implantação de Curto Circuito\n\nExistem dois tipos de controles que podem prevenir curtos-circuitos de implantação: controles do sistema analítico e controles organizacionais.\n\nO controle do sistema analítico consiste em utilizar os modelos que você treinou para trabalhar, alimentando os dados para responder facilmente às suas perguntas. Esses modelos implantados devem ser moderados para verificar a precisão dos dados. Muitas coisas podem afetar adversamente os dados, como mudanças ambientais, calibração de máquinas, problemas de distribuição, entre outros.\n\nIsso não é tão diferente do mundo do desenvolvimento de software onde as mudanças podem afetar as previsões. O departamento de TI está familiarizado com o processo de execução de testes para garantir que seus modelos ou aplicativos estejam funcionando de acordo com as diretrizes estabelecidas, portanto, os DevOps e cientistas de dados devem aproveitar esses recursos e conhecimentos. Não há necessidade de inventar nenhum novo processo, mas, em vez disso, os grupos devem combinar recursos para se prepararem para o sucesso.\n\nOs controles organizacionais remontam a ter uma base organizacional comprometida em ser centrada em dados e fornecer as pessoas e os recursos adequados para trabalhar juntos em prol de objetivos comuns. A melhor chance de obter a operacionalização ocorre quando há colaboração, confiança, compreensão das necessidades e ciclos de feedback entre os grupos da organização.\n\nOs circuitos de feedback são essenciais neste processo. Por exemplo, especialistas em determinada área podem fornecer informações sobre a dinâmica do mercado para que os cientistas de dados possam monitorar o modelo em relação a essas mudanças nos dados. Se um modelo for utilizado ao longo do tempo, ele precisará constantemente passar por iterações e melhorias.\n\nOs consumidores dos dados devem ter um painel que lhes forneça informações e permita investigar o motivo de algo parecer um pouco estranho. Quanto mais eles puderem investigar ou levantar questões que precisam ser investigadas, mais capacitada sua organização estará.\n\n## Tubulação\n\nUma chave do lado de TI para ajudar a operacionalizar o pipeline de dados é usar um controle de versão como o GitHub, para que você possa ter acesso a versões anteriores do seu modelo. Para fins de auditoria, a capacidade de armazenar os dados que criaram o modelo e outros dados históricos também é importante. Você deseja poder analisar os padrões e ver como determinada característica mudou ou impactou o modelo. Você também pode inserir dados históricos em seus novos modelos para ver o quanto eles afetam seus dados atuais.\n\nPor exemplo, alguns sistemas terão uma imagem distorcida com um grande número de pessoas trabalhando em casa durante a COVID. Um caso em questão é a Marinha. Desde a COVID, 95% de seus trabalhadores de TI estão trabalhando remotamente, e sua produtividade aumentou 35%. A partir desse único ponto de dados, poderíamos dizer que todos irão trabalhar em casa a partir de agora. Você continuará a ter um aumento de 35%, ou se as pessoas voltarem ao escritório, verá uma diminuição de 35%? Obviamente, esse único ponto de dados não é necessariamente suficiente para prever a produtividade real.\n\nOutra ferramenta que a área de TI pode oferecer é a integração e implantação contínua. Ao usar o Jenkins, o GitHub Actions ou uma ferramenta similar ao trabalhar em um modelo, você pode executar automaticamente testes em seu modelo com seus dados ou gerar dados falsos instantaneamente.\n\nAs pessoas de TI e os cientistas de dados precisam colaborar sobre o que e como monitorar a saída dos modelos. A TI pode monitorar a saída automaticamente e também pode monitorar o desempenho dos modelos na infraestrutura. Um exemplo é que a TI, com a implantação automática de integração contínua, pode alertar rapidamente os cientistas de dados quando um modelo está levando mais tempo do que o normal para evitar que ele saia do controle. Se a TI estiver investida na criação de valor dos dados, o que geralmente tem sido ausente na indústria como um todo, o processo será mais fácil e coerente para todos.\n\nOutro aspecto a ser considerado é o desenho dos experimentos, pois as interações entre variáveis e características também são importantes. Os especialistas no assunto podem ajudar a determinar quais são as interações potenciais, e você pode modelá-las para auxiliar na compreensão da variabilidade esperada.\n\nÉ empolgante que um cientista de dados possa transformar matéria-prima em insights. No entanto, isso requer uma equipe. Quanto mais todos na sua organização puderem aprender uns com os outros em um ambiente de equipe, mais coisas incríveis podem acontecer.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT25-pt","image":"./episodes/edt-25/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Setor Público, Intel, conversa com Sarah Kalicin, Cientista de Dados Líder, Intel, sobre a operacionalização do pipeline de dados da sua organização. É necessário um esforço em equipe para modelar, monitorar e produzir uma fonte contínua de informações valiosas. Este é o episódio final da série Iniciando sua Transformação Organizacional para se Tornar Centrado em Dados."},{"id":95,"type":"Episode","title":"Soluções de Dados Multi Nuvem com Hammerspace","tags":["hammerspace","data","technology","dataarchitecture","multicloud","compute","multihybridcloud","datamesh"],"body":"\r\n\r\nArmazenamento está maduro para a interrupção. Atualmente, a gestão de dados é feita de maneira complicada, procedimental e muitas vezes manual e propensa a erros. A Hammerspace foi fundada para resolver esse problema, abstraindo dados da infraestrutura de armazenamento.\n\n## Imagine por um segundo....\n\n…se seus dados fossem desvinculados da infraestrutura de armazenamento. Livres das limitações impostas pelos sistemas de armazenamento atuais, os usuários poderiam gerenciar e proteger seus próprios dados, alterar o perfil de custo instantaneamente e acessar dados de qualquer lugar na infraestrutura. O armazenamento definido por software poderia expandir o desempenho conforme necessário e implantar cargas de trabalho modernas, como o Kubernetes, em qualquer infraestrutura subjacente em qualquer lugar.\n\n## O Desafio\n\nAs aplicações tornaram-se portáteis, mas os dados ainda estão isolados. O desafio é que o desempenho, a confiabilidade e a gerenciabilidade sofrem em larga escala devido ao problema de isolamento. A solução é liberar os dados das limitações da infraestrutura subjacente. O Hammerspace faz isso por meio da dissociação de metadados, assimilando as partes constituintes menores para tornar os dados portáteis.\n\n## Desvincule os Dados do Armazenamento\n\nCom esta tecnologia, seus aplicativos possuem dados sob demanda onde quer que você esteja. Você tem controle independente, planos de dados e um namespace e sistema de arquivo global que abrange vários data centers e nuvens. O armazenamento é orquestrado; os dados são totalmente automatizados e aproveitam o gerenciamento declarativo autônomo de dados. Em outras palavras, separa o \"como\" do \"o que\", declarando o estado final desejado sem precisar detalhar todos os detalhes de como chegar lá.\n\n## Arquitetura do Espaço Martelo\n\nO sistema permite que você opere em um nível granular de arquivos, proporciona serviços de dados de classe empresarial, como snapshots e clones, e permite fácil escalabilidade de um data center para outro, de um data center para a nuvem e vice-versa, dispersando-o em um cenário de nuvem multi-híbrida.\n\n## O armazenamento legado não consegue superar os desafios modernos.\n\nO armazenamento legado não escala de forma suficiente, mesmo com soluções de aumento de escala horizontal, em nuvem ou dimensionamento planetário, porque até mesmo esses clusters se tornam silos, deixando às vezes você preso com dados que não podem ser correlacionados e analisados. O armazenamento tradicional também tem dificuldades em escalar capacidade e desempenho de forma independente.\n\nA replicação é uma tecnologia antiga que leva à disseminação de cópias de dados. Em vez de mover as partes constituintes menores, você está movendo toda a carga. O gerenciamento de dados frequentemente é negligenciado; o gerenciamento de dados pertence à frente, não ao final.\n\nUm problema que a arquitetura Hammerspace resolve é encontrar coisas facilmente. A versionamento pode levar a grandes problemas de negócios. Por exemplo, tanto a Airbus quanto a Boeing enfrentaram problemas enormes porque alguns engenheiros não tinham suas versões mais atualizadas. A solução é orquestrar os dados.\n\n## Orquestração de Dados.\n\nOrquestração, primeiramente, é o desacoplamento de todos os silos diferentes; os dados são tratados como um único conjunto. O Hammerspace assimila as partes constituintes menores, os metadados, para criar, essencialmente, um sistema de antigravidade de dados. Em seguida, eles implementam objetivos como durabilidade, disponibilidade e snapshots, ou ações personalizadas definidas que podem ser realizadas por meio do script do Hammerspace. Por fim, os dados, seja Kubernetes, NFS ou SMB, se tornam portáteis e se integram ao sistema.\n\nO que isso significa na prática é que você não precisa ir a outro silo para atender a uma carga de trabalho específica. Os dados são entregues onde você desejar. Essa mobilidade de dados é fundamental porque é em tempo real, não se trata de migração de dados, que é disruptiva e causa tempo de inatividade.\n\nPara minimizar os custos caros de saída, os dados são deduplicados e comprimidos em uma base de arquivo granular. Em vez de mover um volume fixo inteiro, você pode selecionar os dados que deseja mover com base em qualquer tipo de expressão, como pastas, etiquetas de metadados ou um descritor do cliente. Isso oferece flexibilidade e economia de custos.\n\n## Arquitetura Hammerspace\n\nNa arquitetura Hammerspace, o sistema de arquivos global possui três componentes em um nível mais alto: o próprio sistema de arquivos global, a apresentação da interface (NFS, CSI Driver e SMB) e o Anvil dentro do sistema de arquivos global. O Anvil é o componente de gerenciamento de metadados e o DSX, que fornece serviços de gerenciamento de metadados. Esses podem ser implementados como máquinas virtuais, VMware, KBM ou Hyper-V. O Anvil está em uma configuração em forma de A, então existem pelo menos dois deles em cada local. O DSX pode ser paralelizado para aumentar o desempenho, portanto, você pode ter vários deles em diferentes locais para garantir que tenha desempenho suficiente. Eles podem ser facilmente escalados para baixo.\n\nNa parte de trás, o armazenamento subjacente pode ser o próprio armazenamento definido por software da Hammerspace, com disco diretamente conectado, NAS assimilado, qualquer nuvem ou qualquer combinação. Isso também pode ser escalado horizontalmente, permitindo escalar o desempenho e a capacidade independentemente. Seguindo o modelo de nuvem, também é elástico, então, caso os negócios mudem naquela localização específica, é possível reduzir tanto o desempenho quanto a capacidade para garantir que as aplicações tenham apenas o necessário naquela localização. Isso resulta em uma arquitetura muito flexível para atender a qualquer carga de trabalho de aplicação na frente.\n\nUma grande vantagem desta arquitetura flexível é a capacidade de assimilar dados que estão armazenados em dispositivos que não são seus, como NAS ou na nuvem. Isso simplifica o processo de mover os dados. Por exemplo, se você tem um NAS mais antigo e deseja migrar para um NAS mais novo, não importa se são do mesmo fabricante ou de fabricantes diferentes. O Hammerspace assimila os metadados e move os dados por trás, de forma completamente transparente para as aplicações, pois é uma mobilidade de dados em tempo real. Outra vantagem significativa é que não há tempo de inatividade ao mover os dados.\n\nSe você gostaria de experimentar esta tecnologia, vá para hammerspace.com e comece com um teste gratuito com uma licença de até 10 terabytes implantados no Azure, AWS ou Google Cloud.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Johan Ballin"],"link":"/episode-EDT26-pt","image":"./episodes/edt-26/pt/thumbnail.png","lang":"pt","summary":"Johan Ballin, Diretor de Marketing Técnico da Hammerspace, e Darren Pulsipher, Arquiteto Principal de Soluções, Setor Público, da Intel, discutem a tecnologia de nuvem híbrida da Hammerspace que desvincula os dados da infraestrutura de armazenamento, proporcionando portabilidade e desempenho dos dados."},{"id":96,"type":"Episode","title":"Segurança de Hardware: Imprescindível para Transformar Dados.","tags":["datagovernance","data","sgx","confidentialcomputing","cybersecurity","technology"],"body":"\r\n\r\n## Paisagem de Segurança de Dados\n\nO mundo se tornou incrivelmente conectado com todos os dispositivos, e isso está impulsionando um crescimento exponencial na quantidade de dados que precisamos gerenciar: quanto maior o volume, maior o risco. É um desafio, e aproveitar novas capacidades de computação como nuvem, análise de dados e computação de borda acrescenta uma complexidade adicional.\n\nExistem três tendências principais em segurança: criptografar tudo, isolamento de carga de trabalho e uma cadeia de confiança. Essas três áreas são importantes para ajudar organizações a lidar com requisitos regulatórios crescentes para manter os dados protegidos.\n\nQuando as organizações decidem realizar uma transformação digital, ou com um catalisador como a COVID-19 que exigiu trabalhadores remotos, por exemplo, a segurança precisa estar de mãos dadas para manter os controles de segurança e conformidade em vigor. Se você abordar a segurança ao longo do caminho com suas implementações e implementações, mais você será capaz de transformar a maneira como você faz negócios de forma sustentável.\n\n## Proteger os dados ao longo de todo o seu ciclo de vida\n\nCriptografar dados é importante em todas as suas fases. Historicamente, os invasores conseguiam acessar os dados diretamente pela rede. Depois que eles foram criptografados, começaram a invadir os centros de dados e extrair dados dos bancos de dados. Então começamos a criptografar o armazenamento. Ainda assim, os dados chegam a um ponto final, são integrados à memória e descriptografados, portanto, um ataque sofisticado que obtivesse acesso root poderia potencialmente manipular ou roubar os dados nesse ponto de processamento. Esse ataque aos dados em uso é a nova fronteira para os invasores e aqueles que defendem o espaço. A Intel possui algumas capacidades novas e inovadoras que estamos incorporando em nossos processadores para ajudar os proprietários de dados, os proprietários de aplicativos, os provedores de serviços e, basicamente, todo o ecossistema a fechar essas vulnerabilidades potenciais.\n\n## Por que proteger dados em uso?\n\nEm muitos casos, os atacantes estão usando escalonamento de privilégios nas camadas do sistema operacional ou do hipervisor. Eles podem estar vindo através de um sistema operacional convidado, um sistema operacional hospedeiro ou até mesmo acesso físico ao hardware do servidor. Os atacantes podem ser intrusões clássicas de malware de hackers, concorrentes de terceiros ou pessoas internas, como administradores ou administradores de sistemas em um provedor de serviços.\n\n## Extensões de Guarda de Software Intel (Intel SGX)\n\nA Intel incorporou uma nova tecnologia em nossos processadores chamada Intel Software Guard Extensions, ou SGX. Isso faz parte do paradigma de computação confidencial que está explodindo no mercado agora, à medida que as empresas tentam transformar seus dados e mantê-los privados. O SGX enfrenta esses novos tipos de ataques permitindo que o aplicativo fale diretamente com o processador na memória criptografada, contornando o sistema operacional, o Hypervisor e essencialmente tudo o mais no sistema. Portanto, mesmo que haja uma violação no seu sistema operacional, Hypervisor ou outras aplicações, os invasores não seriam capazes de acessar esses dados porque o próprio sistema operacional não tem visibilidade desses dados. Portanto, você não precisa confiar no provedor ou no restante da pilha do sistema porque essencialmente opera como se eles já estivessem comprometidos, e seu código e dados permanecerão confidenciais e inalterados; eles terão integridade.\n\nA Intel está tentando fazer com que você precise confiar no menor número possível de componentes. SGX vai mais longe nesse caminho para o centro de dados do que qualquer outra coisa que já vimos. Tudo que você precisa confiar é na sua própria aplicação e no próprio processador.\n\nA SGX oferece uma capacidade poderosa para empresas como provedores de serviços em nuvem, que podem dizer a seus clientes que eles, ou o governo, por exemplo, não poderiam ter acesso aos seus dados, mesmo se quisessem fazê-lo.\n\n## Intel SGX em Ação\n\nA SGX já está sendo amplamente utilizada por provedores de serviços em nuvem e fornecedores de software, mas de certa forma, estamos apenas começando. Embora essa tecnologia esteja disponível há alguns anos, construímos ecossistemas e estamos trazendo novas capacidades em nossos futuros processadores Xeon Ice Lake de terceira geração. Isso irá expandir suas capacidades, sua capacidade de escalonar para cargas de trabalho empresariais de grande porte e será capaz de proteger partes muito maiores da memória com melhor desempenho e em todo um espectro muito mais amplo no centro de dados mainstream.\n\nA Intel é um dos membros fundadores do Consórcio de Computação Confidencial, que faz parte da fundação Linux. A maioria dos grandes provedores de serviços em nuvem, muitos provedores de software e até mesmo nossos concorrentes de silício estão trabalhando juntos nessas soluções de ambiente de execução confiável e estabelecendo padrões para lidar com esse tipo de capacidade. Também estamos aumentando a conscientização sobre a necessidade e o valor comercial da computação confidencial.\n\n## Ecosistema de Parceiros de Software Intel SGX\n\nA SGX oferece muitas opções de uso, dependendo do que o proprietário dos dados procura. Se um cliente deseja o nível mais detalhado de controle, a SGX permitirá que eles façam isso. Na verdade, eles podem essencialmente reduzir sua aplicação apenas aos dados codificados que desejam manter isolados do restante do sistema, ou mesmo apenas uma parte dessa aplicação. No entanto, esse cenário requer que eles escrevam a aplicação com esse propósito. No ecossistema, existem recursos de código aberto que estão tornando esse tipo de desenvolvimento muito mais fácil, e está sempre expandindo.\n\nDo outro lado está um movimento rápido de transferência direta. Você pode levar sua aplicação e inseri-la em um ambiente mais seguro. O ecossistema está respondendo e criando containers com consciência SGX. Você pode inserir sua aplicação sem modificações nesse ambiente, onde ela será a única coisa em execução, assim a própria aplicação pensa que está rodando em seu ambiente nativo.\n\nNossos parceiros de ecossistema têm feito muito progresso nessa área com coisas como Fortanix, Graphene e Scone. Alguns são de código aberto e outros são proprietários, mas vêm com todos os serviços já incluídos. Por exemplo, o Microsoft Azure Confidential Computing oferece toda a gama de soluções de lift and shift com SGX, até SDKs que permitem desenvolver sua aplicação diretamente para ele e implantá-lo em seu ambiente para que você nem precise gerenciar o hardware. Há um conjunto completo de opções, então ninguém deve ter medo das complexidades do SGX. Os clientes também devem ter confiança de que materiais sensíveis, como algoritmos de aprendizado de máquina ou chaves de criptografia, serão tratados com um nível de proteção muito granular.\n\n## Computação confidencial: uma mudança revolucionária na segurança.\n\nA SGX tem estado por aí há algum tempo e temos trabalhado para expandi-la. Ela foi testada e submetida a diversos desafios, com centenas de artigos de pesquisa e atualizações ao longo do tempo. Ela tem a vantagem de não ser a novidade do momento, mas sim uma solução fundamental que está sendo introduzida no mainstream com o Ice Lake. Não está mais focada em áreas pequenas e sensíveis, mas está pronta para enfrentar grandes desafios agora.\n\nGoverno, serviços financeiros e assistência médica são algumas das indústrias que perceberam o atrativo da SGX desde cedo, pois possuem muitas expectativas regulatórias e requisitos de privacidade, mas estão tentando compartilhar dados e realizar atividades inovadoras com várias partes. Empresas também enfrentam situações semelhantes, por exemplo, quando desejam migrar para a nuvem pública, mas não confiam nela para proteger seus dados sensíveis. Com a SGX, elas não precisam confiar no provedor.\n\nA Intel acabou de fazer um grande anúncio este mês e estamos realmente abrindo todas as portas para o que está por vir. Um ótimo lugar para começar é intel.com/sgx para depoimentos e uma exploração mais aprofundada das informações. Os clientes devem procurar pelos parceiros do ecossistema, como Azure e Fortanix. Outro lugar para obter informações é o Confidential Computing Consortium, devido ao número de pessoas trabalhando nesse espaço.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jesse Schrater"],"link":"/episode-EDT27-pt","image":"./episodes/edt-27/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto de Soluções Chefe, Setor Público, da Intel, e Jesse Schrater, Gerente de Segurança, Grupo de Plataformas de Dados, da Intel, discutem o cenário atual de segurança e como o SGX da Intel e o ecossistema de parcerias oferecem uma solução testada e oportuna para dados em uso e outras preocupações de segurança."},{"id":97,"type":"Episode","title":"Integração de Herança com Nuvem e RPA","tags":["rpa","bpm","automation","compute","technology"],"body":"\r\n\r\nParece que todos estão no meio de uma Transformação Digital. Private Cloud, Public Cloud, Multi-Hybrid Cloud, Data Lakes, Machine Learning, Inference e Inteligência Artificial são todos termos que as pessoas estão usando hoje para descrever sua transformação digital, mas e quanto à integração de sistemas legados? Ninguém fala sobre isso. Por quê? Porque é desafiador integrar aplicativos, dados e segurança legados em seu novo e impecável ambiente Multi-Hybrid Cloud. Essa é uma das últimas coisas com as quais queremos nos preocupar. Se não desenvolvermos uma estratégia para sistemas legados, teremos um barco rápido com âncora abaixada. Ele nos desacelera e mantém nosso barco preso no porto.\n\nUma das áreas crescentes para ajudar com a Integração de Legacy e automação de integração é o uso de ferramentas e frameworks de automação. Nos últimos 3 anos, surgiu um foco significativo na automação de fluxos de trabalho com aplicações conscientes em nuvem e legado para trabalhadores de informação. Esses conjuntos de ferramentas são chamados de ferramentas de Automação de Processos Robóticos (RPA).\n\n## Automação de Processos Robóticos (RPA)\n\nQuando comecei a investigar as ferramentas de Automação de Processos Robóticos (RPA), eu pensei que elas controlavam robôs. Eu estava pronto para pegar minhas botas com biqueira de aço e um capacete e visitar instalações de fabricação. No entanto, rapidamente descobri que as RPAs imitam a maneira como os trabalhadores da informação trabalham com as diferentes ferramentas que eles usam. Algumas dessas ferramentas são ferramentas antigas, e algumas delas são novas aplicações modernas. As RPAs registram como o trabalhador da informação usa a interface do usuário das diferentes ferramentas e permitem que a gravação seja reproduzida, automatizando o fluxo de trabalho do trabalhador da informação.\n\nSurpreendentemente, as RPAs são uma tecnologia bastante madura. Muitas das empresas de RPA têm origens no mercado de Ferramentas de Teste de Interface de Usuário (UI Test Tool). A capacidade de capturar a interação do usuário com múltiplas aplicações ao longo do tempo é fundamental para o desenvolvimento de um teste de Interface de Usuário repetível. Essas ferramentas existem há mais de 20 anos e já são bastante maduras. Essas Ferramentas de Teste de UI QA foram renomeadas e remodeladas para trabalhadores da informação que desejam automatizar suas tarefas repetitivas e redundantes.\n\n## Local de mercado atual - 2020\n\nOs investidores veem esse mercado como um mercado promissor e têm investido pesadamente nessas tecnologias. Nos últimos três anos, mais de $2,0 bilhões foram investidos no mercado de RPA. Três empresas têm recebido a maior parte desses investimentos:\n\nUiPath - Investimento de $1 Bilhão em $300 Milhões em Receita Anual.\n\nAutomação em Qualquer Lugar - Investimento de $500 Milhões em Receita Anual de $100 Milhões.\n\nBluePrism - Investimento de $50 milhões em uma receita anual de $30 milhões.\n\nTranslate the following to Portuguese: *\n\nA maioria dos investimentos não tem vindo do tradicional e moderno Vale do Silício em alta tecnologia, mas sim de centros financeiros como Nova York e Londres, indicando que as instituições financeiras estão considerando os RPAs para automatizar muitos dos fluxos de trabalho e processos de seus próprios profissionais de informação.\n\n## Local onde a RPA funciona bem\n\nOs primeiros segmentos verticais a adotar RPAs foram os setores financeiro, de seguros e médico. Essas indústrias buscaram maneiras de reduzir a variabilidade, aumentar a confiabilidade e diminuir os custos. Devido ao grande número de trabalhadores da informação nessas indústrias, eles buscaram RPAs para automatizar grande parte do trabalho atualmente realizado por seus trabalhadores de informação. Para automatizar esses fluxos de trabalho, as organizações precisam entender como esses fluxos de trabalho são criados.\n\nPrimeiro, vamos compreender o trabalhador de informação. Muitos dos trabalhadores de informação passam tempo trabalhando com múltiplas aplicações, interligando informações e aplicações de forma improvisada. À medida que esses trabalhadores continuam a trabalhar com essas aplicações, eles criam organicamente fluxos de trabalho que combinam dados e aplicações em um número inumerável de permutações.\n\nSegundo, faça um catálogo dos fluxos de trabalho da melhor forma possível, encontrando possíveis fluxos de trabalho para eliminação por duplicação e redundância. Agora que os fluxos de trabalho são compreendidos, o próximo passo é priorizar e enumerar os fluxos de trabalho. Focar nos fluxos de trabalho mais utilizados, com o maior número de etapas significativas, tende a ser a melhor maneira de priorizar os fluxos de trabalho.\n\nPor último, descubra como automatizar os fluxos de trabalho com bots de RPA. A automação pode ser feita através da gravação da interface do usuário do fluxo de trabalho por um dos funcionários de informação e anotando o fluxo de trabalho com variações baseadas na entrada de dados e credenciais de segurança. Após a gravação estar completa, um bot de RPA é criado para automatizar o fluxo de trabalho. Agora você precisa decidir como deseja que o RPA seja executado: Assistido ou Não assistido.\n\n## Modos de Operação RPA\n\nOs RPAs funcionam em dois modos básicos de execução: Atendido e Não atendido. Atendido significa que ele é executado no desktop ou laptop do trabalhador da informação. Ele auxilia o trabalhador automatizando o trabalho que ele realiza diariamente. O modo Não atendido é executado em um ambiente de desktop virtual e geralmente é iniciado através de um evento ou gatilho, e funciona sem qualquer interação com o trabalhador da informação. Existem benefícios em executar em ambos os modos, como descrito abaixo.\n\n## Compareceu.\n\nLida com tarefas para funcionários individuais.\n\nTraduzindo para o português: * Os funcionários acionam e direcionam um robô para realizar uma atividade.\n\nOs funcionários acionam os bots para automatizar tarefas conforme necessário a qualquer momento.\n\nAumenta a produtividade e a satisfação do cliente em centrais de atendimento e outros ambientes de serviço ao cliente.\n\n## Não assistido\n\nAutomatiza processos de back-office em grande escala.\n\nFornecido com base em processos baseados em regras.\n\nBots executam processos empresariais completos sem intervenção humana conforme um cronograma predeterminado.\n\nLiberta os funcionários das tarefas rotineiras, reduzindo custos, melhorando a conformidade e acelerando os processos.\n\n## Como integrar RPA na sua empresa\n\nPara entender como os RPAs se encaixam em sua empresa, você deve primeiro analisar os usuários dos RPAs. Especificamente, existem três tipos de \"atores\" que utilizam, gerenciam ou influenciam as ferramentas RPA.\n\nTrabalhador da Informação - Este é o usuário principal das ferramentas RPA. Seus processos manuais são alvos de automação.\n\nDesenvolvedor de Aplicativos - Os bots de RPA são alterados quando as aplicações são atualizadas ou criadas. Mudanças na Interface do Usuário requerem \"regravação\" dos bots de RPA.\n\nOperações de TI - Gerenciar as ferramentas de RPA e implantar bots de RPA não assistidos.\n\nTraduza o seguinte para o português: *\n\n## Gerenciando mudanças.\n\nGerenciar a complexidade das configurações e da segurança são fatores críticos para uma implantação bem-sucedida de ferramentas e bots de RPA. Primeiro, você precisa ter uma compreensão de como os diferentes usuários do RPA interagem quando há mudanças em aplicativos, fluxos de trabalho e processos. Essa compreensão é essencial para gerenciar as mudanças nos bots de RPA e nas ferramentas que eles utilizam.\n\nPequenas mudanças nas aplicações podem ter um efeito profundo nos trabalhadores de informação e na forma como desempenham seu trabalho diário, o que, por sua vez, significa registrar um robô RPA novo ou atualizar um já existente. Por causa do acoplamento de robôs RPA aos conjuntos de ferramentas e fluxos de trabalho, criar robôs RPA quando os fluxos de trabalho ou conjuntos de ferramentas estão imaturos causa interferências e fragilidade desnecessárias. Processos e conjuntos de ferramentas maduros são ótimos candidatos para automação RPA.\n\nOutro aspecto a considerar é onde estão sendo executadas as ferramentas que você está automatizando com sua ferramenta de RPA. Elas utilizam aplicativos e infraestrutura legados? Estão usando nuvem pública ou privada? Como as redes desses sistemas estão conectadas? À medida que o número de ambientes aumenta, também aumenta a complexidade de manter e atualizar aplicativos e bots de RPA. Procure maneiras de diminuir o número de limites ambientais que o bot de RPA atravessa.\n\n## Gerenciando a segurança\n\nOutro fator crítico a considerar é a segurança para os bots RPA. Quando um Colaborador de Informação grava seu fluxo de trabalho, eles precisam autenticar (fazer login) em cada ferramenta que estão usando. Os colaboradores autenticam-se usando nomes de usuário e senhas, chaves de autenticação ou até mesmo Ferramentas Corporativas de Logon Único. De qualquer forma, você precisa gerenciar a segurança dessas ferramentas no contexto do bot RPA em execução. Qualquer alteração na autenticação (nome de usuário, senha, chaves de autenticação ou credenciais) requer alterações no bot RPA. Muitas das ferramentas de RPA consideram isso e têm mecanismos para injetar credenciais de segurança no bot RPA e autenticar as ferramentas em tempo de execução.\n\n## Gerenciando ferramentas e robôs de RPA com fluxos de trabalho de SecDevOps.\n\nA complexidade das ferramentas e bots de RPA se encaixa muito bem em padrões bem conhecidos no mundo do SecDevOps. Felizmente, muitos dos problemas relacionados à gestão de configurações e dependências são tratados de forma eficiente com um processo de SecDevOps.\n\n## A tradução para português de \"RPA Bundling\" é: Agrupamento de RPA.\n\nUma das estratégias é tratar o bot de RPA como um serviço complexo que contém várias máquinas virtuais ou containers para cada uma das ferramentas, um Desktop Virtual e o próprio bot. Esses serviços podem ser agrupados e gerenciados juntos como um pacote único. Um pacote inclui não apenas os serviços, mas também a forma como eles se comunicam (rede) de maneira segura (autenticação).\n\nPassar um pacote para um orquestrador de serviços permite uma maior automação do gerenciamento de firewall de rede, segurança e injeção de chaves de credenciais e gerenciamento do ciclo de vida do bot de RPA e das ferramentas que ele consome. Existem várias ferramentas no espaço de virtualização (VMWare e OpenStack) que permitem a criação e o gerenciamento desses pacotes. O espaço de contêineres também possui ferramentas semelhantes de agendamento e orquestração, como Kubernetes, Mesos e Docker Swarm.\n\n## SecDevOps Pipelining translates to \"Pipelining de SecDevOps\" in Portuguese.\n\nUma pipeline de SecDevOps simples gerencia o pacote do RPA bot assim como qualquer outro pacote de aplicativo tradicional.\n\nUm trabalhador da informação constrói os pacotes de robôs RPA gravando o fluxo de trabalho da interface do usuário em um ambiente de desenvolvimento. O trabalhador facilmente grava seu fluxo de trabalho e em seguida cria um pacote que é \"verificado\" no pipeline. Neste ponto, o pacote de robô RPA passa por um ciclo de construção, teste e produção. Pontos de verificação em cada etapa do caminho ajudam a garantir a qualidade do robô RPA. Como o pacote pode injetar rede e segurança dependendo de diferentes ambientes, os robôs RPA podem ser reutilizados por diferentes trabalhadores da informação e em diferentes ambientes.\n\nOutra vantagem de colocar bots RPA em Pacotes RPA é a gestão das ferramentas e bots em múltiplos ambientes de infraestrutura, como legados, privados e nuvens públicas. Muitas das ferramentas de orquestração de serviços podem criar automaticamente conexões entre esses ambientes de infraestrutura, através da criação de uma rede sobreposta. O pipeline diminui a quantidade de trabalho \"hands-on\" realizado pela organização de TI e, em muitos casos, todas as etapas do pipeline são automatizadas.\n\n## Riscos das bots de RPA\n\nAqui está uma lista de coisas para ficar atento ao usar bots RPA em seus sistemas empresariais.\n\nA segurança pode ser uma grande vulnerabilidade se você não prestar atenção nela. Um dos maiores erros é executar aplicativos em um bot de RPA no modo privilegiado ou com credenciais de conta \"global\".\n\nTraduza o seguinte para o português: \"Os robôs RPAs estão intimamente ligados às interfaces do usuário de várias aplicações; qualquer pequena mudança em uma aplicação significa que você precisa regravar o robô RPA.\"\n\nOs bots de RPA não conseguem lidar muito bem com mudanças, são muito frágeis em relação a alterações em aplicativos e até mesmo na configuração dos aplicativos.\n\nA reutilização é mínima devido ao acoplamento estreito com as interfaces de usuário do aplicativo. Algumas ferramentas usam tags em vez da posição absoluta do cursor e cliques.\n\nAlguns Interfaces de Usuário não permitem RPA porque são dinâmicos. O que significa que são difíceis de gravar.\n\nA indústria de RPA está se esforçando ao máximo para superar alguns desses problemas inerentes ao aspecto de registro/reprodução das ferramentas. Alguns desses obstáculos não podem ser superados por causa da abordagem geral. Outras opções, como portais de API e automação funcional, devem ser avaliadas.\n\n## IA para o resgate dos RPAs\n\nConforme mencionado nas armadilhas da RPA, a reutilização de bots é um grande problema que a indústria está buscando resolver. Uma das técnicas que eles estão investigando é o uso de IA e Inferência para lidar com interfaces de usuário dinâmicas e pequenas alterações em aplicativos sem a necessidade de regravar os bots de RPA. O reconhecimento de padrões e o reconhecimento óptico de caracteres são duas áreas que estão sendo usadas para treinar modelos de IA a fim de identificar campos e segmentos de interfaces de usuário.\n\nCom esses modelos de IA, os bots podem ser mais flexíveis, adequando-se ao uso em vários conjuntos de ferramentas e processos / fluxos de trabalho similares. Outra área que os fornecedores de RPA estão investigando é a otimização de processos usando IA e ML.\n\n## Migração de Legado é uma jornada\n\nO mercado de RPA tem ganhado nova energia à medida que as empresas buscam modernizar sua infraestrutura de TI e processos. Automatizar os processos manuais atuais por meio da gravação é uma conquista rápida da qual muitas organizações estão se beneficiando. No entanto, o RPA deve ser considerado como um mecanismo temporário em vez de um estado final. Por quê? Muitos dos processos de informação atuais requerem sistemas e políticas legados. Automatizar um processo antigo em uma nova infraestrutura é semelhante a automatizar a produção de chicotes para uma fábrica automotiva. Pode haver um benefício no início, mas a longo prazo, o processo é altamente ineficiente e antiquado. Não importa o quão rápido ele funcione de forma confiável, pode simplesmente não ser necessário.\n\n## Conclusão\n\nAs ferramentas de Automação de Processos Robóticos são mais um conjunto de ferramentas que podem ser usadas para ajudar as organizações em sua transformação digital, passando da infraestrutura e processos legados para infraestruturas e processos mais modernos. As ferramentas por si só não são suficientes e você precisa planejar como irá utilizá-las, gerenciá-las e eventualmente substituí-las. Aqui estão algumas dicas úteis ao trabalhar com essas ferramentas.\n\nTrate as RPAs como Serviços Complexos em execução em sua Nuvem Multi-Híbrida.\n\nExecute seus bots de RPA por meio dos fluxos de trabalho SecDevOps como outras aplicações.\n\nInjetar segurança e autenticação em tempo de execução na ferramenta RPA.\n\nEncontre maneiras de reutilizar os bots de RPA em diferentes partes da sua organização.\n\nTenha um plano para substituir seu bot de RPA por uma integração simplificada.\n\nProcure maneiras de diminuir as aplicações Legacy (Substituir ou Remover).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT28-pt","image":"./episodes/edt-28/pt/thumbnail.png","lang":"pt","summary":"Uma das áreas em crescimento para auxiliar na Integração Legada e automação de integração é o uso de ferramentas e estruturas de automação. Nos últimos 3 anos, tem surgido um foco significativo na automação de fluxos de trabalho com aplicativos herdados e novos aplicativos conscientes da nuvem para trabalhadores da informação. Esses conjuntos de ferramentas são chamados de ferramentas de Automação de Processos Robóticos (RPA). Darren Pulsipher, Arquiteto-chefe de Soluções, Setor Público, Intel, analisa a indústria de Automação de Processos Robóticos (RPA) e as ofertas de ferramentas."},{"id":98,"type":"Episode","title":"Banco de dados hipercala da próxima geração - Aerospike","tags":["aerospike","database","ingestion","optane","data","technology","pmem"],"body":"\r\n\r\n## Próxima Geração de Banco de Dados Hiperescala\n\nOs bancos de dados estão mostrando sua idade, ainda demoram um pouco para obter resultados. O Aerospike, com a ajuda da tecnologia da Intel, rompe com velocidade, volume e baixa latência. Tim Faulkes, Vice-Presidente de Arquitetura de Soluções da Aerospike, junta-se a Darren neste episódio para discutir os benefícios de sua tecnologia.\n\n## NoSQL - Um mercado em crescimento com múltiplas tecnologias\n\nA Aerospike foi criada em 2009, com as primeiras implantações de produção em 2011. Os fundadores estavam cientes dos desafios futuros. Eles construíram a arquitetura do zero com o objetivo de que ela fosse confiável, dimensionável para empresas, jamais sair do ar e capaz de lidar com ingestão maciça de dados. A arquitetura da Aerospike dependia muito de SSDs, tanto de unidades NVMe nas encarnações modernas, quanto de unidades SATA SAS. Ambos estavam em seus estágios iniciais, então os fundadores foram visionários em relação ao futuro do mercado. Eles dependiam desses dispositivos para obter velocidade, e é por isso que a tecnologia Intel era tão importante. Desde então, outras tecnologias da Intel, como a memória persistente, tornaram as coisas muito mais fáceis.\n\n## Índices em DRAM, Dados em SSD\n\nA abordagem da Aerospike para bancos de dados é diferente. Os SSDs não são simplesmente discos rígidos mais rápidos. Um disco rígido possui setores físicos e cabeças e elementos que precisam ser movidos para ler dados. Um SSD pode ler rapidamente milhares de peças de dados em paralelo. Ele não funciona bem em discos rotacionais, mas com NVMe/SSD, funciona extremamente rápido. Ninguém tem o mesmo tipo de desempenho, nem mesmo um banco de dados em memória.\n\nA arquitetura única é projetada para alto volume, alto rendimento e latência muito baixa. Por exemplo, alguns clientes realizam regularmente 20 milhões de transações por segundo. Alguns estão chegando a petabytes de dados. Tipicamente, os clientes executam em hardware bastante bom, mas o tempo de ida e volta é crucial. Leva cerca de 200 microssegundos para o Aerospike pesquisar um dado e trazê-lo de volta para o cliente, não dezenas ou centenas de milissegundos. Quando você precisa de uma grande quantidade de dados rapidamente, como na detecção de fraudes, ou se está ingestando muitos dados, como em IoT, veículos autônomos, leituras de sensores ou dispositivos médicos, o Aerospike pode realizar milhões de transações por segundo em leituras e escritas. Você não precisa colocá-lo em um barramento de mensagens e em seguida, permitir que o banco de dados notifique os sistemas downstream via barramento de mensagens que ele tem os dados. Eles já são persistentes.\n\n## Impulsionando Inovação Líder na Indústria em todo o Mundo\n\nQuais são os casos de uso ideais para o Aerospike? Existem mercados óbvios, como o já mencionado Internet das Coisas (IoT), detecção de fraudes e dados de sensores, mas é um mercado emergente. O Aerospike começou na tecnologia de publicidade, onde a recuperação de dados deve ser feita em milissegundos ou mais rápido. É aí que o bom desempenho foi testado em grande escala.\n\nIndústrias adicionais em que o Aerospike pode ser útil são diversas. Um exemplo é uma grande empresa de telecomunicações na Índia. A infraestrutura lá nem sempre é confiável e, às vezes, as chamadas são perdidas. Essa empresa, com a tecnologia Aerospike, pode identificar em tempo real que uma chamada foi perdida e eles podem entrar em contato imediatamente e oferecer ao cliente créditos ou outras compensações para manter a satisfação do cliente.\n\n## Regulação em Tempo Real de Pagamentos Imediatos.\n\nUma nova área na qual a Aerospike tem se envolvido intensamente é o pagamento digital em tempo real. Isso não requer especificamente uma grande quantidade de dados ou alta taxa de transferência, mas o que essas empresas precisam é de consistência absoluta e disponibilidade absoluta, mesmo diante, por exemplo, da perda de um centro de dados.\n\nO chão de fábrica também é um mercado emergente para a tecnologia Aerospike em coisas como a fabricação de semicondutores, onde é usada para armazenar dados de sensores para fornecer análises em tempo real. O Aerospike se destaca em qualquer indústria onde haja muitos dados e você precise deles rapidamente.\n\n## Desempenho em Escala - Resultados de Teste de Terceiros Independentes\n\nExistem muitos bancos de dados com boa tecnologia disponíveis, mas há desafios de escala. Tome o Redis, por exemplo. Por armazenar todas as informações na memória, não é possível chegar a dez terabytes sem um custo significativo, quanto mais centenas de terabytes ou petabytes. Já o Aerospike armazena as informações em SSDs, a diferença de tempo entre buscar dados em um SSD e na memória é de cerca de 100 microssegundos. Na escala de petabytes, o Aerospike substitui tecnologias mais antigas, como o Cassandra, que escala muito bem, mas falta velocidade.\n\n## Custo total de propriedade\n\nAlém disso, comparado a essas tecnologias, as pessoas economizam muito dinheiro ao adotar o Aerospike, pois o número de nós diminui drasticamente devido à arquitetura única. As economias ocorrem não apenas no investimento inicial, mas também nas despesas operacionais, pois há menos máquinas para supervisionar.\n\nA Aerospike colapsou alguns dos níveis tradicionais na arquitetura. Frequentemente, sistemas legados terão caches extras na frente para acelerá-los. Isso introduz complexidade. Aerospike não precisa de um cache. Não há uma grande quantidade de DRAM. Ele depende da velocidade dos SSDs e da tecnologia subjacente para obter o desempenho do armazenamento bruto sem um cache. Como os níveis de cache e armazenamento estão colapsados, a solução é simplificada, o que significa confiabilidade e velocidade incorporadas.\n\n## Exemplo de Implantação Continental\n\nA consistência em múltiplas áreas geográficas é também um benefício importante da tecnologia. A arquitetura moderna requer baixa latência, o que geralmente significa que existem vários clusters H onde os dados estão próximos ao usuário. Caso contrário, a velocidade da luz se torna um fator. O Aerospike pode fazer com que todos os clusters H se comuniquem entre si, então se um registro é alterado em um cluster, ele será propagado automaticamente para os outros clusters, de forma assíncrona. No entanto, em alguns casos, como pagamentos digitais, deve haver uma forte consistência entre os clusters, então eles podem querer replicar os dados de forma síncrona. Eles preferem ler a partir da cópia local dos dados. As leituras se tornam muito rápidas; as escritas são afetadas pela velocidade da luz, mas garantem a consistência em distâncias geográficas. Portanto, isso não é resolução de conflito, é evitar conflitos. Ser capaz de espalhar essas escritas de forte consistência ao redor do mundo e talvez ter múltiplos sistemas de registros tem um enorme potencial e valor.\n\n## Aerospike Connect para Spark.\n\nPor exemplo, atualmente, o Aerospike se integra ao Spark, uma tecnologia analítica que requer que seus dados estejam em memória. Ao carregar os dados do Aerospike, o quadro de dados do Spark pode processar dezenas ou centenas de terabytes com enormes economias de custo e velocidade. A integração com outras ferramentas de IA é uma das forças motrizes que abrirão algumas portas emocionantes.\n\nObter dados no Aerospike é simples e direto. Como as aplicações possuem uma camada de API como a maioria dos bancos de dados, o Aerospike pode receber dados de fontes padrão do setor, como Kafka e Janus. A capacidade bidirecional de se comunicar com barramentos de mensagens faz sentido, porque o Aerospike não só pode receber dados dessas fontes, mas também enviá-los. Se o Aerospike é uma fonte confiável quando você grava um registro, você pode enviá-lo para sistemas downstream.\n\n## Aerospike Connect for Kafka: Conexão Aerospike para Kafka\n\nSe você deseja usar o Aerospike para ingestão em vez de um mecanismo de ingestão na frente, o Aerospike pode determinar se quer fragmentar os dados ou mantê-los no mesmo formato e apenas colocá-los no Aerospike; Com sua estrutura de plug-in, é uma chamada de API. Quando os dados são armazenados, um barramento de mensagens pode ser notificado para processamento posterior. Isso elimina uma das etapas de ingestão e aumenta o rendimento total.\n\nEscalar para milhares de clientes é possível devido à forma como o cliente Aerospike é projetado como multithreaded para escalar em um único processo e ingestar uma grande quantidade de dados com isso. O cliente é inteligente para aumentar a velocidade. Qualquer registro vai diretamente do cliente para o nó que possui essa parte de dados. Não há intermediários desse tipo. Isso significa que o cliente deve conhecer todos os nós, portanto, existem limites de conexão finitos, tornando impraticável centenas de milhares de clientes.\n\n## Exemplo de Implementação Continental\n\nSe, no entanto, você tiver centenas de milhares de clientes, é porque você possui uma população distribuída globalmente. Se eles estivessem se comunicando com apenas um grupo, a velocidade da luz se tornaria um grande problema. Existem maneiras de configurar clusters menores baseados nas bordas que compartilham informações ou se comunicam com um sistema de registro em um modelo de hub e falou, então é possível de ser feito.\n\n## Aerospike é um banco de dados para aplicações de sistema de registro.\n\nÀ medida que os dados se movem pelo mundo, diferentes camadas de privacidade entram em jogo e padrões como GDPR e CCPA, fazendo com que os clientes tenham que conhecer a origem dos dados. O Aerospike tem a flexibilidade de analisar os dados com granularidade e, com base no conteúdo dos dados, saber quando e onde podem ser enviados. Isso faz parte da configuração de envio de dados do Aerospike, que é transparente na aplicação. Você não precisa alterar nada nas aplicações, apenas na configuração.\n\nA Aerospike também garante que os dados estejam seguros. Assim como em todos os bancos de dados de alta capacidade empresarial, o Aerospike suporta criptografia em repouso e em trânsito, e integração de segurança com coisas como o Hashicorp Vault. Ele pode ser, e está sendo usado, como um sistema de registro.\n\nUm objetivo fundamental na Aerospike é usar as últimas inovações e tecnologias para o sucesso dos clientes. Por exemplo, quando a Intel lançou o PMem, eles o usaram no modo direto do aplicativo para aproveitar todas as suas capacidades. Isso significa que, para uma atualização contínua em, digamos, um petabyte de informações, o tempo necessário é pequeno. A Aerospike armazena esse petabyte em cerca de 50 ou 60 nós, em vez de milhares de nós, e quando um nó é desligado, não é necessário reconstruí-lo, portanto, o tempo de reinicialização é muito rápido.\n\nNo geral, o Aerospike oferece segurança, alta disponibilidade, velocidade, baixa latência, escalabilidade, consistência e baixo custo de propriedade.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tim Faulkes"],"link":"/episode-EDT29-pt","image":"./episodes/edt-29/pt/thumbnail.png","lang":"pt","summary":"Bancos de dados estão mostrando sua idade, ainda levando algum tempo para obter resultados. O Aerospike, com a ajuda da tecnologia Intel (Optane), supera com velocidade, volume e baixa latência. Tim Faulkes, Vice-Presidente de Arquitetura de Soluções da Aerospike, se une a Darren Pulsipher, Arquiteto-Chefe de Soluções da Intel, para discutir os benefícios da tecnologia Aerospike."},{"id":99,"type":"Episode","title":"Benefícios da Arquitetura Multi-Cloud","tags":["multicloud"],"body":"\r\n\r\n## Agilidade\n\nAgilidade é a capacidade de mover-se rapidamente para se adaptar às condições em constante mudança de novas tecnologias, novas aplicações e novas ameaças, como segurança e concorrência. Um modelo multi-híbrido permite a capacidade de mover coisas entre nuvens privadas e públicas, ou até mesmo de infraestrutura legada para nuvens. Pode ser tentador para equipes de desenvolvimento utilizar inicialmente a nuvem pública sob prazos apertados porque eles podem rapidamente criar e destruir infraestrutura, mas podem haver problemas de integração nas fases finais de implantação das aplicações no produto. Isso pode resultar em atrasos custosos. Ao usar o modelo multi-híbrido, muitos desses pontos de integração são expostos à equipe de desenvolvimento antecipadamente. O desenvolvimento de aplicações utiliza isso para falhar rápido e cedo no processo de desenvolvimento.\n\n## Flexibilidade\n\nA flexibilidade na infraestrutura é um parente próximo da agilidade. Enquanto a agilidade é a capacidade de mover-se rapidamente, a flexibilidade é a capacidade de mudança. Para obter máxima flexibilidade, os desenvolvedores precisam ter a capacidade de implantar um aplicativo em qualquer lugar, seja em nuvens privadas ou públicas, ou em infraestruturas antigas, sem ficarem presos a nenhum serviço ou infraestrutura específica de uma nuvem.\n\nAo implantar uma plataforma de gerenciamento em nuvem (CPM) em uma arquitetura multi-híbrida, as cargas de trabalho podem ser facilmente redirecionadas para diferentes nuvens de acordo com custo, segurança e confiabilidade.\n\nUm exemplo das consequências da falta de flexibilidade é a decisão precoce da Netflix de utilizar apenas um provedor de serviço em nuvem. Essa nuvem pública teve um problema de infraestrutura que resultou em tempo de inatividade, e a Netflix não conseguiu transmitir por várias horas na costa leste dos Estados Unidos. Após esse desastre, a Netflix implementou uma solução de multi-nuvem para que eles possam migrar rapidamente para outra nuvem em caso de problemas. Além disso, eles agora têm a capacidade de se mover para onde for mais sensato a qualquer momento, levando em consideração custo, segurança e confiabilidade.\n\nAs aplicações de uma nuvem multi-híbrida são portabilidade e flexibilidade operacional. Ao não ficar preso à forma como uma única nuvem faz as coisas, os desenvolvedores poderão escrever código que pode ser facilmente transportado entre nuvens. Além disso, você terá a flexibilidade operacional para mover cargas de trabalho entre nuvens, oferecendo aos seus clientes o que eles desejam de maneira segura, econômica e confiável.\n\n## Desempenho Preditivo\n\nAs nuvens públicas frequentemente vêm com um preço: \"vizinhos barulhentos\", que podem afetar o desempenho preditivo ou a Qualidade de Serviço (QoS).\n\nAo utilizar uma nuvem pública, muitas vezes você não sabe o que ou quem mais está sendo executado na mesma máquina, conjunto de armazenamento ou rede que você. Para algumas cargas de trabalho, isso não é um problema. No entanto, se você tiver um aplicativo em que precise de desempenho mais previsível, vizinhos barulhentos ou aqueles que monopolizam largura de banda, E/S de disco, CPU e outros recursos podem atrapalhar os resultados de QoS que você precisa.\n\nAs nuvens privadas também podem sofrer com vizinhos barulhentos, mas já que você é dono da infraestrutura e as aplicações são suas, você tem a habilidade direta de gerenciá-las. Um vizinho barulhento na nuvem pública é como viver em um prédio de apartamentos onde você tem opções limitadas para lidar com os festeiros ao lado. Por outro lado, vizinhos barulhentos em sua nuvem privada são como viver em uma casa com crianças indisciplinadas que você pode imediatamente gerenciar restringindo recursos.\n\nUma estratégia de nuvem híbrida lhe dá a capacidade de colocar cargas de trabalho e aplicativos \"sensíveis\" em nuvens privadas e outras cargas de trabalho e aplicativos em infraestruturas de nuvem pública para eficiência de custo e recursos. Muitas ferramentas híbridas lhe dão a capacidade de caracterizar cargas de trabalho com requisitos de QoS para auxiliar no posicionamento automático e ideal das cargas de trabalho em diferentes infraestruturas de nuvem.\n\n## Segurança e conformidade\n\nExistem alguns perigos ao fazer coisas de forma automatizada nas nuvens públicas e privadas. No entanto, se a segurança for incorporada à arquitetura multi-híbrida, essa automação se torna um benefício, pois significa que um perfil de segurança pode ser imposto a todos os ativos em nuvem, sejam eles privados ou públicos, além da infraestrutura legada. Esse perfil de segurança comum é aplicado em todos os lugares e as aplicações são implantadas com base nesses perfis.\n\nPor exemplo, em uma nuvem privada, se você deseja um tipo específico de segurança, como vincular uma certa aplicação a uma determinada máquina que só é executada nessa nuvem privada, isso pode facilmente ser um requisito no perfil de um sistema híbrido-múltiplo.\n\nEm um sistema multi-híbrido, também existem muitas ótimas ferramentas para auditoria e monitoramento da sua infraestrutura. Você não pode apenas monitorar o que está acontecendo na sua nuvem privada, mas também na nuvem pública, o que o alertará para ataques maliciosos que poderiam potencialmente infectar sua nuvem privada ou ativos de infraestrutura legada.\n\n## Eficiência\n\nExistem muitas ideias conflitantes sobre eficiência. Se você observar vários calculadores de custo total de propriedade (TCO), encontrará respostas diferentes sobre se as nuvens privadas ou públicas são mais eficientes em termos de custo. Uma solução de nuvem multi-híbrida pode resolver esse dilema para sua organização por meio de maior visibilidade e provisionamento dinâmico.\n\nCom uma arquitetura de nuvem híbrida multi-híbrida e um orquestrador inteligente, seu orquestrador pode usar telemetria de suas nuvens privada e pública e infraestrutura legada para tomar decisões ótimas sobre onde a carga de trabalho deve ser executada atualmente e no futuro. Outra vantagem dessa visibilidade é que você pode decidir se é eficiente executar aplicativos continuamente. Um exemplo disso é como ajudamos o sistema do governo canadense a funcionar de forma mais eficiente, reduzindo os custos associados à execução de um aplicativo na nuvem pública quando ninguém estava usando. Em vez de executar um aplicativo específico o tempo todo, agora eles o executam por 18 horas, 5 dias por semana, de acordo com o uso real.\n\nEsta visibilidade também ajudará a identificar e eliminar cargas de trabalho e aplicações no final da vida útil (EOL), o que irá economizar dinheiro real. Para a nuvem privada, isso libera recursos que podem ser utilizados para outras cargas de trabalho, aumentando assim a eficiência. Além disso, os intermediários de nuvem na CMP em arquitetura multi-híbrida basicamente pesquisam o preço mais baixo mantendo a QoS para a carga de trabalho específica. Isso diminui o custo geral de execução da carga de trabalho e também oferece visibilidade do custo real de uso de uma nuvem pública ou privada específica.\n\nVisibilidade nos custos em todas as nuvens e infraestrutura legada\n\nImpulsionar carga de trabalho e aplicativos para os custos mais baixos, mantendo os mesmo níveis de acordos de nível de serviço.\n\nAumentar a utilização da infraestrutura de nuvem privada.\n\n## Chamada à Ação\n\nAs arquiteturas de nuvem multi-híbridas estão dando aos CIOs a capacidade de antecipar as demandas de seus clientes, mas ainda há trabalho árduo que deve ser feito. Construir uma estratégia de nuvem multi-híbrida inclui mudanças organizacionais, comportamentais e técnicas que não podem acontecer da noite para o dia. Desenvolver uma visão arquitetônica sólida e um plano de ação são essenciais para implementar uma estratégia de nuvem multi-híbrida que possa aproveitar as forças das nuvens multi-híbridas e evitar a ineficiência do \"objeto brilhante do mês\" das indústrias técnicas.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT3-pt","image":"./episodes/edt-3/pt/thumbnail.png","lang":"pt","summary":"Uma arquitetura de nuvem multi-híbrida permite às organizações aproveitar os benefícios tanto das nuvens privadas quanto das públicas, otimizando recursos e eficiência de custos. Esse modelo possui cinco principais vantagens: agilidade, flexibilidade, desempenho preditivo, segurança e conformidade, e eficiência."},{"id":100,"type":"Episode","title":"Portabilidade de aplicativos com OneAPI.","tags":["aiml","devops","compute","technology","process","oneapi","aiops","developer","people"],"body":"\r\n\r\nCom o oneAPI, a Intel criou um ambiente de software unificado para desenvolvimento, voltado para o processamento de dados. É uma programação paralela de dados baseada em um código-fonte aberto C++. Vários tipos de bibliotecas, como a MKL, DNN da Intel e outras de código aberto, fazem parte do conjunto de ferramentas oneAPI, juntamente com acessórios como um tradutor CUDA. É possível desenvolver software no oneAPI e, em seguida, direcioná-lo para as diferentes bibliotecas, dependendo do que você está fazendo. Ele removeu a complexidade de aprender uma linguagem diferente para diferentes arquiteturas.\n\n## Iniciativa da Indústria oneAPI - Alternativa à Solução de Único Fornecedor\n\nBasicamente, um engenheiro de software pode escrever código uma vez e ele será executado em diferentes processadores: CPU, GPU, FPGA, NPU e VPU. Dependendo da arquitetura e bibliotecas que você está usando, pode ser necessário recompilar, mas não são necessárias reescritas de código.\n\n## Bibliotecas de API poderosas\n\nEsta versão é apenas o primeiro passo; A Intel e outras continuarão a projetar com a adição de aceleradores de IA, por exemplo. A ideia é que ela evolua para dar aos desenvolvedores uma flexibilidade muito maior e que a abstração permita que muitas pessoas possam projetar e codificar de forma mais simples, especialmente do ponto de vista da ciência de dados e IA.\n\nFalando praticamente, um engenheiro de software poderia escrever algo em seu laptop, testá-lo lá e depois usar o mesmo código e executá-lo em uma nuvem totalmente equipada com processadores neurais, GPUs ou FPGAs. Isso poderia ser especialmente útil no setor público, onde os engenheiros estão escrevendo aplicativos especiais que processam na borda, talvez com um FPGA. Eles não precisarão ter um ambiente completo para realizar seu trabalho.\n\nOutro aspecto empolgante é que, uma vez que a Intel incorporar a aprendizagem de máquina, o oneAPI poderá analisar o código e especificar quais partes seriam melhores em diferentes processadores. Isso direcionaria o código para os lugares adequados para obter a melhor velocidade e desempenho.\n\n## Iniciativa da Indústria oneAPI - Alternativa à Solução de Único Fornecedor\n\nExistem muitos frameworks de IA por aí, mas o oneAPI permite a migração de qualquer tipo de código de algo proprietário para uma linguagem de programação de código aberto. Ele é baseado em SYCL e desenvolvido sob um consórcio da indústria chamado Khronos Group, então é uma espécie de framework de desenvolvimento.\n\n## Bibliotecas API poderosas\n\nOneAPI possui de vinte a trinta bibliotecas como MKL, bibliotecas para redes neurais e aprendizado de máquina, CNN ou DNN abertos. Todas são abertas, partes do consórcio maior.\n\nAlém disso, a Intel está no processo de adicionar o framework TensorFlow e suas bibliotecas ao oneAPI. Muitos frameworks já foram otimizados pela Intel e estão sendo incorporados ou utilizando as mesmas bibliotecas, de forma que os usuários possam utilizá-los ou desenvolver com base neles.\n\n## Recursos\n\nA Intel tornou o oneAPI amplamente disponível no início de novembro de 2020, e isso foi um destaque da convenção virtual Super Computing, ocorrida em 17 a 19 de novembro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT30-pt","image":"./episodes/edt-30/pt/thumbnail.png","lang":"pt","summary":"Com umAPI, a Intel criou um ambiente de software unificado para desenvolvimento, voltado para o processamento de dados. Gretchen Stewart, Cientista Chefe de Dados, Setor Público, Intel, discute essa tecnologia com Darren Pulsipher, Arquiteto de Soluções Chefe, Intel, que elimina a necessidade de usar uma linguagem diferente para arquiteturas diferentes."},{"id":101,"type":"Episode","title":"Melhorando o Valor do Empregado com Catalisador.","tags":["rpa","automation","catalytic","compute","process","technology"],"body":"\r\n\r\n## Catalytic foi projetado especificamente para operações e processos de negócios recorrentes.\n\nA tecnologia RPA tem origem na automação de testes e macros do Excel, mas sua linhagem de negócios vem da terceirização. No entanto, a Catalytic considera sua linhagem como de software, com seu sistema como a próxima evolução na criação de software personalizado. O interesse do co-fundador e CEO Sean Chou está nas operações e eficiência em escritórios. Esse foco estreito permite que a Catalytic utilize a inteligência artificial de maneira completa e construa algo que seja acessível sem a necessidade de conhecimento em programação.\n\nCatalytic utiliza a inteligência artificial de algumas maneiras diferentes e táticas dentro do aplicativo para ajudar a reduzir a necessidade de expertise.\n\nPor exemplo, uma das partes mais difíceis de aprender qualquer plataforma é entender suas capacidades. Uma maneira de usar a IA para ajudar a compensar essa questão é usando o processamento de linguagem natural. As pessoas podem simplesmente digitar o que estão tentando realizar e o aplicativo pode inferir e dizer qual ação seria melhor ajudar você a concluir essa etapa. É basicamente uma forma de melhorar a experiência do produto e diminuir o nível de expertise necessário.\n\nOutro exemplo é que dentro do fluxo de trabalho, existem seis módulos diferentes de ações distintas, cada um com um nome lógico para o que se destina a resolver, como processamento de dados, montagem de documentos, etc. Dentro de cada módulo, existem diferentes ações de IA que as pessoas podem usar em seu processo, como reconhecimento óptico de caracteres (OCR), análise de sentimentos (a pessoa que escreveu o e-mail está com raiva?) e outras ações de processamento de linguagem natural.\n\nExistem outros elementos que são menos IA e mais ações de utilidade, como fornecer informações sobre uma pessoa com base no seu endereço de email.\n\nMuitos dados fluem através dos processos de back office. Infelizmente, a visão do sistema dos dados muitas vezes é bastante fragmentada. O fluxo de trabalho catalítico pode atravessar sistemas, capturando tudo. Os dados são armazenados em tabelas de dados e é fácil construir modelos de aprendizado de máquina com base nessas tabelas, para que você possa prever resultados futuros de outros fluxos de trabalho.\n\nA Catalytic utiliza IA em contextos como estes e outros específicos para aumentar a eficiência e fornecer perspicácia e visibilidade.\n\n## Feche a Última Milha da Digitalização construindo soluções de fluxo de trabalho em torno de como as pessoas trabalham.\n\nPor exemplo, a inteligência operacional por meio da IA é capturada na plataforma por meio de uma funcionalidade chamada Insights. Para cada fluxo de trabalho, essa aba pode informar quanto tempo leva para todas as etapas diferentes, com que frequência ocorrem falhas e se são erros humanos ou falhas de integração. Isso oferece oportunidades de melhoria. Ao mesmo tempo, o algoritmo de aprendizado de máquina pode começar a aprender a prever os resultados dos valores de campo. Assim, o aprendizado de máquina pode ser usado de diversas maneiras relacionadas.\n\n## Apesar dos investimentos feitos, ainda existe uma lacuna \"última milha\" que é preenchida manualmente.\n\nA maioria dos clientes que investiram em diversas tecnologias ao longo dos anos ainda sente que há uma lacuna entre o investimento e os resultados desejados para o negócio. Essa lacuna normalmente é preenchida por pessoas que estão realizando tarefas que deveriam ser feitas pelo software, como copiar e colar informações de um sistema para outro. Às vezes, adicionar software à mistura complica as coisas, adicionando etapas extras e treinamento. A solução Catalytic para essas ineficiências é um sistema reutilizável e expansível.\n\nÉ impossível que qualquer software pronto atenda às necessidades individuais de cada empresa, e é ineficiente e demorado enxergar o valor final. Portanto, as empresas devem se adequar ao software existente ou adaptar o software para atender às suas necessidades. O valor em um sistema semelhante ao WordPress é evidente. Se o poder está realmente nas mãos dos funcionários, é possível ter um software verdadeiramente personalizado. A Catalytic deseja colocar esse poder em prática para qualquer processo empresarial, utilizando RPAs combinados com ações.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Chou","Neil Bahandur"],"link":"/episode-EDT31-pt","image":"./episodes/edt-31/pt/thumbnail.png","lang":"pt","summary":"Na primeira parte de dois episódios, Sean Chou, CEO da Catalytic, e Neil Bahandur, Chefe de Parcerias da Catalytic, se juntam a Darren para falar sobre a tecnologia da Catalytic e como a RPA pode ajudar os funcionários a se tornarem mais valiosos por meio da automação de processos repetitivos do escritório."},{"id":102,"type":"Episode","title":"Abordagem Sem Codificação (RPA) para Eficiência do Back Office","tags":["rpa","automation","catalytic","compute","process","technology"],"body":"\r\n\r\n## O que é Catalítico?\n\nCatalytic é uma plataforma em nuvem sem código para a construção de soluções de fluxo de trabalho que melhoram e automatizam as operações do seu back office.\n\nUma analogia útil para ajudar as pessoas a entender o que o Catalytic pode fazer para o fluxo de trabalho do back office é o que o Wordpress fez para a publicação na web. Antes do Wordpress, criar um site era uma tarefa complexa que envolvia várias pessoas com uma variedade de habilidades especializadas. Com o Wordpress e subsequentemente, softwares mais avançados, criar um site é uma tarefa relativamente simples. Um designer ou especialista em conteúdo, por exemplo, pode facilmente criar um site por conta própria.\n\nO objetivo da Catalytic é simplificar de maneira semelhante os sistemas complicados e complexos do escritório e criar eficiência e soluções por meio da automação de processos robóticos (RPA). Agora, alguém que tenha um pouco de proficiência técnica deveria ser capaz, com a tecnologia da Catalytic, de criar independentemente uma solução para o escritório.\n\nUm medo comum de que RPAs custe empregos é falso; na verdade, ele cria novas oportunidades mais valiosas. Por exemplo, com o Wordpress, agora há o papel de desenvolvedor Wordpress, então essa progressão não diminuiu as habilidades dos desenvolvedores, mas adicionou camadas de maneiras que as pessoas podem aplicar essas habilidades em algo mais escalável. Funcionários do back office também podem usar suas habilidades para adicionar valor ou melhorar a experiência do cliente em vez de se concentrarem em trabalhos mundanos e básicos inerentes a processos ineficientes.\n\n## Evolução e Diferenciação da Catalítica\n\nCatalytic diferencia-se de seus concorrentes, primeiramente, por suas raízes. A indústria atual de RPA vem de duas linhas evolutivas, uma advinda dos macros do Excel e outra dos testes de interface do usuário. Catalytic vem do mundo Dev Ops, elaborando scripts para processos de back office em vez de ter uma visão orientada por tela sobre automação. Quando Sean Chou co-fundou Catalytic, ele pensou em termos de gestão de projetos e como orquestrar processos de rotina empresarial.\n\n## Catalytic é feito especialmente para operações e processos de negócios recorrentes\n\nChou percebeu que, como 85% ou mais dos negócios são rotina, muitas operações poderiam ser automatizadas, de modo que a plataforma pudesse realizar algumas dessas tarefas. Começou com um sistema simples de notificação automatizada que substituiu os funcionários enviando e-mails, o que levou o Catalytic a criar cada vez mais ações. Para ampliar as capacidades da plataforma, o Catalytic criou um ecossistema com parceiros de terceiros, como o Google, para aproveitar suas tecnologias. Através do ecossistema, também há o benefício do trabalho empresarial componível, onde as pessoas podem criar um fluxo de trabalho na plataforma e salvá-lo, essencialmente, como uma unidade individual de trabalho. Por exemplo, se houver seis etapas padronizadas para capturar um registro de cliente, você pode criar isso uma vez e salvá-lo como uma ação na plataforma, e então compartilhá-lo com toda a sua equipe. Esse compartilhamento imita a abordagem de um desenvolvedor de software para resolver problemas difíceis através do compartilhamento de código, mas em vez de código, são ações. Compor, então, se torna muito mais fácil.\n\nCatalytic adotou uma abordagem cuidadosa para o fornecimento, implantação e gerenciamento de tudo em sua plataforma. A nuvem não é um pensamento secundário; eles criaram uma plataforma em nuvem do zero. Tudo é centrado na nuvem, embora também tenham a capacidade de trabalhar com sistemas locais e ambientes híbridos.\n\n## Catalytic foi projetado para permitir um programa de desenvolvedor cidadão de classe empresarial.\n\nO sistema foi criado em um ambiente de DevOps e funciona como um gerenciador de builds para o negócio, onde as pessoas do negócio podem realmente fazê-lo por si mesmas. Sistemas antigos de build como o Clear Case eram difíceis de gerenciar, e o Catalytic simplificou as coisas. Ele não apenas elimina etapas extras, mas também altera a divisão do trabalho. O Catalytic foca em pessoas mais próximas do processo real para evitar transferências. Eficiência é o conceito central. Um sistema de build eficiente que detecta bugs e os rejeita antes de tentar transmiti-los é fundamental para o sucesso do processo automatizado.\n\nA magia dos sistemas de construção é que eles se tornam mais poderosos à medida que incorporam mais partes da sua infraestrutura. Por exemplo, ele pode interagir com o sistema de controle de versão para buscar o código, pode trabalhar com seus servidores para implantar ou pode interagir com o Rational Robot para realizar testes automatizados. Claro, tudo gira em torno das ações. Quanto mais ações forem digitalizadas, mais o sistema pode capturar e mais poderoso ele se torna.\n\nOutra coisa que diferencia o Catalytic é a ênfase nos funcionários realizando um trabalho de alto valor. O conceito de baixo valor e alto valor em RPA é comum, mas em vez de usá-lo como uma espada para cortar grupos, o Catalytic quer usá-lo como um escudo para proteger as pessoas e ajudá-las a fazer o melhor uso do seu tempo e entregar uma vantagem competitiva.\n\nNo próximo podcast, Darren, Sean e Neil continuarão a conversa sobre a abordagem de no-code para eficiência no back office.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Chou","Neil Bahandur"],"link":"/episode-EDT32-pt","image":"./episodes/edt-32/pt/thumbnail.png","lang":"pt","summary":"O episódio de hoje é a parte 2 de uma conversa com Sean Chou, CEO da Catalytic, e Neil Bahadur, Chefe de Parcerias da Catalytic. Eles falam com Darren sobre sua abordagem de no-code para eficiência de escritório com uma plataforma que utiliza tecnologia de RPA e IA."},{"id":103,"type":"Episode","title":"A interrupção da AWS de Nov 2020","tags":["aws","cloudoutage","compute","csp","cloud","process","cloudreliability","multicloud","reliability"],"body":"\r\n\r\n## O Que Aprendemos com a Interrupção da AWS\n\nA Amazon Web Services (AWS) sofreu uma interrupção substancial em um momento inoportuno - um dia antes do Dia de Ação de Graças em 2020. Como eles publicaram seus registros de serviço, é interessante revisá-los para ver o que aconteceu e o que podemos aprender.\n\n## Cronologia da Interrupção do AWS\n\nNa quarta-feira, 25 de novembro de 2020, por volta das 3:00 da manhã PST, a AWS estava atualizando a região Leste, adicionando servidores para aumentar a capacidade do Kinesis. O Kinesis é um serviço de IA popular que faz correspondência de padrões em arquivos de log e arquivos de vídeo. Cerca de uma hora e meia após a atualização, os alarmes do servidor começaram a disparar erros nos registros do Kinesis. Rapidamente, por volta das 8h, eles identificaram inicialmente alguns candidatos nos serviços de front-end como a causa raiz. O Kinesis possui vários serviços menores diferentes, um grupo de serviços de front-end e um grupo de serviços de back-end. Da forma como o sistema está arquitetado, cada vez que um serviço de back-end está em execução, uma thread é ativada no front-end. Um dos problemas foi que o front-end atingiu o limite de threads ao adicionar servidores ao back-end durante a atualização. Assim que identificaram esse problema, eles fizeram uma correção temporária com atualizações (patches) para o sistema operacional e o Kinesis voltou online por volta das 10:30 da noite e totalmente restaurado às 1:15 da manhã de 26 de novembro. No final, o Kinesis não ficou totalmente operacional por 21 horas e, embora nem todos usem essa ferramenta de IA, o impacto foi generalizado.\n\n## Kinesis Impact translates to: Impacto Kinésis\n\nVários outros serviços da Amazon utilizam o Kinesis, como o Amazon Cognito e o CloudWatch, e eles sofreram graus variados de interrupção. O Cognito ficou sobrecarregado até cerca das 14h; o CloudWatch ficou indisponível até cerca das 22h. Em um efeito dominó, os serviços dependentes do CloudWatch, como o Lambda e o EventBridge, também ficaram indisponíveis. Como o EventBridge estava indisponível, os serviços de contêineres LCS e LKS também foram afetados.\n\nAs interrupções ocorreram apenas na região leste e a AWS rapidamente adicionou capacidade nas outras regiões para evitar que o Kinesis falhasse de maneira semelhante. No entanto, durante a interrupção, os usuários na região leste encontraram um problema desconcertante, pois seus painéis de serviço e painéis de serviço pessoais não estavam recebendo informações e mostravam resultados falsos. Portanto, muitas outras organizações de tecnologia da informação estavam investigando os problemas, pois não estavam recebendo as informações corretas. Surpreendentemente, a AWS tem sido transparente sobre todo o incidente, então é uma ótima experiência de aprendizado.\n\n## Lições Aprendidas\n\nUma das primeiras lições é que operações simples na infraestrutura, como aumentar a capacidade, precisam ser compreendidas e planejadas. Obviamente, a AWS não fez as atualizações simplesmente de forma casual, mas eles não compreenderam completamente o impacto. Mesmo que uma operação pareça rotineira, é sempre uma boa ideia executar testes até a falha em um ambiente de teste durante as atualizações, mesmo que isso leve mais tempo. Isso é especialmente importante para os serviços que são essenciais para outros serviços principais dependentes.\n\nAlém disso, arquiteturas de serviço ou micro-serviço devem compreender toda a sua árvore de dependência de serviço para que possam solucionar problemas quando ocorrem interrupções. Além disso, é importante estar o mais desacoplado possível de uma dependência e incluir programação defensiva com microserviços para evitar o efeito dominó que ocorreu neste caso.\n\nOutra questão a ser observada são as dependências circulares. Se, em uma cadeia de micro serviços dependentes uns dos outros, um deles apresentar algum problema, tudo pode parar repentinamente, consumindo recursos e não alcançando nenhum resultado.\n\nAo desenvolver micro serviços, tenha em mente que nem sempre você terá conectividade com os serviços dos quais você depende. Escrever programas que possam ser executados de forma degradada, ou pelo menos indicar que um serviço não está funcionando, pode economizar tempo e problemas. Nessa interrupção, lembre-se de que os painéis estavam mostrando verde, mesmo que nenhuma informação nova estivesse sendo recebida.\n\n## Quem lidou melhor com a interrupção\n\nMuitas empresas foram afetadas pela interrupção da AWS, incluindo algumas pertencentes à própria Amazon. Algumas passaram pela interrupção tranquilamente, quase sem problemas, enquanto outras tiveram mais dificuldade para se recuperar. Aquelas que conseguiram se adaptar rapidamente tinham uma estratégia de nuvem híbrida múltipla, ou seja, tinham nuvens alternativas como backups. Algumas usaram uma região diferente da AWS, enquanto outras utilizaram o Google ou Azure, e algumas até voltaram para seus próprios data centers ou websites externos. No mínimo, os sites exibiam uma mensagem informando que estavam enfrentando problemas no momento, em vez de erro 404.\n\nEmpresas que não estavam utilizando alguns dos serviços especializados da Amazon também se saíram melhor. Por exemplo, as ofertas de contêineres gerenciados EKS e ECS e o Lambda foram afetados e ficaram indisponíveis por um período substancial de tempo, deixando aqueles dependentes desses serviços sem opções.\n\nDurante a interrupção, os serviços de escalonamento automático não estavam funcionando corretamente, então qualquer empresa que tivesse um alto tráfego naquele momento teve que descobrir o que estava acontecendo e aumentar manualmente os serviços. Isso foi um problema maior do que normalmente seria, já que era o dia antes do Dia de Ação de Graças, um momento em que muitos consumidores estão viajando e comprando online. Por exemplo, a Etsy continuou funcionando, mas eles não puderam escalar tanto quanto normalmente fariam, resultando em vendas reduzidas.\n\nAs empresas que possuem seu próprio monitoramento externo também tiveram melhor desempenho. Algumas até avisaram a AWS sobre as interrupções. Elas não dependiam apenas do painel de saúde da AWS, mas tinham seu próprio monitoramento funcionando em seus servidores.\n\nQual é a principal lição que devemos aprender com isso? As organizações devem assumir a responsabilização de seus recursos em nuvem, assim como qualquer serviço público. Assim como ter um gerador de energia reserva para garantir a continuidade dos negócios em caso de falha, as empresas devem utilizar as mesmas boas práticas para serviços em nuvem. Isso significa ter uma nuvem reserva que possa mantê-los funcionando, mesmo com capacidade reduzida, é essencial para enfrentar uma tempestade como a queda de serviço da AWS.\n\n## Recursos\n\nhttps://aws.amazon.com/message/11201/ can be translated to Portuguese as *https://aws.amazon.com/message/11201/*\n\n* Traduza a seguinte frase para o português: \"https://www.theverge.com/2020/11/25/21719396/amazon-web-services-aws-outage-down-internet\"\n\nDesculpe, mas não vou conseguir cumprir essa tarefa.\n\nAqui está o que causou a grande interrupção da AWS na semana passada. Pedimos desculpas.\n\nhttps://www.wsj.com/articles/amazon-web-services-hit-by-outage-11606326714\n\nTraduza o seguinte para o português: *\n\nTraduza o seguinte para o português: * https://www.washingtonpost.com/technology/2020/11/28/amazon-outage-explained\n\nExplicação da interrupção da Amazon.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT33-pt","image":"./episodes/edt-33/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções, Setor Público, na Intel fala sobre as lições aprendidas com a interrupção da AWS em novembro de 2020 e soluções preventivas para lidar com essas interrupções."},{"id":104,"type":"Episode","title":"Abraçando a Evolução do Espaço de Trabalho","tags":["covid","mfa","remoteworker","cybersecurity","people","technology","vdi","vpn"],"body":"\r\n\r\n## Os locais de trabalho digitais estão evoluindo.\n\nDesde que já superamos o caos inicial das transições necessitadas pela pandemia, precisamos questionar o que está por vir e, daqui para frente, como podemos aproveitar o que aprendemos para investir conscientemente no lugar em que desejamos estar.\n\nUma grande lição foi que as organizações que já eram ágeis tiveram um bom desempenho. Elas foram capazes de colocar sua equipe remota em funcionamento rapidamente. Não sabemos exatamente como será o novo normal, mas sabemos que ele continuará tendo muitos dos mesmos aspectos que foram acelerados nos últimos oito meses, como permitir uma equipe remota, mas ao mesmo tempo ser mais colaborativo. A Intel deseja alcançar novos clientes que precisam de mais recursos para operar fora de suas próprias instalações e se tornarem mais ágeis.\n\n## \"O seu local de trabalho precisa de novas capacidades. A Intel preenche a lacuna.\"\n\nA Intel se dedica a criar soluções ajudando os clientes a entender o vasto ecossistema da Intel com diferentes modelos que podem preencher as lacunas de desempenho, estabilidade, eficiência e preço. A Intel pode compartilhar os aprendizados de milhares de clientes para ajudar a resolver problemas e fornecer capacidades que as organizações de TI às vezes não conseguem fazer por si próprias.\n\n## Os requisitos empresariais são primordiais.\n\nNo passado, um CIO poderia ter se concentrado apenas em três coisas: segurança, resiliência e eficiência. Isso não é mais o caso. O que costumava ser equivalente a manter as luzes acesas, evitar problemas e funcionar de maneira eficiente, agora é muito mais complexo. As empresas devem ter uma visão de futuro para aprimorar o trabalhador, o local de trabalho e as transformações pelas quais estão passando em termos de cumprir compromissos com clientes e fornecedores.\n\nAlém disso, a agilidade é um requisito, dado que as circunstâncias podem mudar rapidamente e as empresas devem adaptar-se em várias direções ao mesmo tempo, mas ainda assim atender a essas necessidades.\n\nFinalmente, mais automação via inteligência artificial é uma facilitadora para impulsionar áreas como melhor colaboração e aprimoramento da experiência do trabalhador. Com uma força de trabalho distribuída, por exemplo, não há um serviço de suporte ao qual você possa recorrer pessoalmente para ajudar com seu problema. Isso pode não ser o cenário mais eficiente de qualquer forma, portanto, talvez chatbots ou aprendizado de máquina em um sistema de Gerenciamento de Relacionamento com o Cliente (CRM) seriam mais eficientes e permitiriam mais informações compartilhadas. Esse tipo de automação técnica com resolução comum de problemas pode gerar mais conexões, insights e produtividade no final.\n\n## Seu ambiente de trabalho está evoluindo.\n\nOs requisitos e estratégias empresariais estão mudando, especialmente em relação à evolução do local de trabalho. Algumas organizações continuarão com operações totalmente remotas, outras desejarão que todos voltem para um escritório quando for seguro, e haverá várias configurações intermediárias. Independentemente da situação, as organizações devem adotar uma estratégia para garantir que possam alcançar os trabalhadores em qualquer lugar, a qualquer momento e em qualquer dispositivo, seja por necessidade ou escolha.\n\nA melhoria de processos também é fundamental. Você não deseja continuar adicionando processos sobre aqueles que não são mais necessários. Avaliar áreas para melhoria, seja infraestrutura interna ou capacidades de terceiros, adicionará eficiência e valor. Em vez de construir uma infraestrutura enorme que requer gerenciamento e é sobrecarregada pelo uso exclusivo de suas ferramentas, as organizações devem avaliar a incrível quantidade de oportunidades de ecossistema que se integram às ferramentas como serviço. Terceirizar serviços que não são ativos estratégicos fundamentais ou pontos fortes da sua empresa pode fazer mais sentido.\n\nOutra área a avaliar é a gestão de dados. Com, por exemplo, todos os dados nas ferramentas de colaboração, a proliferação de dados torna-se um problema. Uma estratégia clara e eficaz é necessária.\n\nJunto com a gestão de dados, vem a segurança. Os dados estão espalhados por toda parte agora, então as organizações devem adotar, avaliar e implementar boas ferramentas de segurança e fluxos de trabalho adequados em torno das práticas de dados.\n\n## Intel Entrega\n\nExistem seis principais capacidades no ambiente de trabalho em constante evolução em que a Intel pode ajudar: acesso a aplicativos e dados, gerenciabilidade, segurança aprimorada, conectividade, infraestrutura de colaboração e ambientes de multi-nuvem. Embora a Intel produza apenas silício, as capacidades, escalabilidade e segurança dele atendem às necessidades de organizações de todos os tamanhos, desde as menores até as maiores.\n\nA Intel busca existir em vários ambientes e oferecer a gerenciabilidade desses recursos. Embora os clientes não comprem diretamente da Intel ativos como processadores, aceleradores, memória, armazenamento, entre outros, eles aproveitarão o ecossistema robusto e comprovado de produtos que a Intel torna possível, como fabricantes de hardware, OEMs, provedores de software, integradores de sistemas e provedores de serviços em nuvem.\n\nUma das forças da Intel é o seu suporte a esse ecossistema. Por exemplo, a Intel tem 15.000 engenheiros de software que desenvolvem código, mas nada disso é vendido. Em vez disso, eles ajudam a desenvolver o ecossistema fornecendo novas soluções construídas sobre o silício. O silício é o mecanismo para fornecer soluções que ajudam as pessoas a resolver problemas reais. Uma boa metáfora é que a distância entre o pátio de carga da Intel como fabricante e o pátio de carga final do cliente está muito distante para a Intel dirigir um caminhão ela mesma. O ecossistema preenche essa lacuna.\n\n## Áreas de Solução que Você Pode Estar Avaliando.\n\nComo os clientes podem aproveitar ao máximo a capacidade do ecossistema? A Intel pode fornecer recomendações nas seis áreas-chave, seja para lidar com uma solução de VDI, como decidir se ela deve permanecer local ou ser uma área de trabalho virtual ou serviço RDS, ou para desenvolver uma estratégia de VPN que garanta a conectividade.\n\nParte da solução está em compreender que, como a Intel trabalha em um ecossistema tão vasto, ela pode ajudar a enfrentar uma infinidade de desafios. A Intel não necessariamente vai vender um processador para você, por exemplo, mas ajudar a colocar sua carga de trabalho na melhor peça de silício possível, que pode estar nos provedores de serviços em nuvem, ou em várias nuvens, dentro e fora de seu próprio centro de dados. O objetivo da Intel é proporcionar eficiência, portabilidade e agilidade nesses processos.\n\n## Abraçar a Evolução do Local de Trabalho: Quando ou Onde você quer começar?\n\nA Intel tem o melhor interesse da sua organização em mente, porque se você tiver sucesso no seu negócio, você irá encontrar novas maneiras de usar dados e infraestrutura para fornecer mais valor aos seus clientes e, no final, consumir mais. Suas estratégias, crescimento e desenvolvimento são seus próprios, mas a Intel lhe oferecerá a base para fazer boas escolhas.\n\nProcure oportunidades de se envolver com seu representante da Intel. Eles têm uma variedade de recursos para ajudar você a aproveitar a extensa rede de parceiros que podem lidar com seus problemas e metas.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Robert Looney"],"link":"/episode-EDT34-pt","image":"./episodes/edt-34/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto Principal de Soluções para o Setor Público, e Robert Looney, Gerente de Vendas de Data Centers para as Américas da Intel, falam sobre o uso de uma abordagem estratégica para abraçar a atual evolução do local de trabalho. A pandemia de COVID criou grandes desafios e transições no local de trabalho. A Intel está ajudando os clientes a aproveitar as tecnologias para melhor enfrentar os desafios contínuos no novo normal."},{"id":105,"type":"Episode","title":"Navegando em Mudanças Disruptivas","tags":["change","culturalchange","organizationalchange","disruption","people","process"],"body":"\r\n\r\nRick recentemente comemorou sua terceira década na Intel e, nesse período, ele ajudou a Intel a navegar por uma quantidade enorme de mudanças e grandes eventos. Juntamente com situações competitivas difíceis e mudanças na indústria, começando com o surgimento da internet e o boom e a queda das empresas ponto com, também houve eventos externos como o 11 de setembro, a Grande Recessão e agora a pandemia de COVID-19.\n\n## Tipos de Situações de Crise\n\nA natureza de uma empresa moderna em uma economia moderna é que ela estará constantemente navegando em um alto grau de incerteza, turbulência, mudança e interrupção. As organizações ou definham nesses momentos ou saem melhores e mais fortes.\n\nCada interrupção é diferente em termos de magnitude e velocidade. Alguns eventos se desenrolam ao longo de um longo período de tempo, talvez uma mudança tecnológica ou estrutural na indústria, e depois aceleram repentinamente. Alguns, como a COVID, têm um impacto alto em uma velocidade sem precedentes. No entanto, o interessante sobre a COVID é que temos desenvolvido a tecnologia para lidar com as consequências da pandemia há uma década, mas foi necessário esse evento para colocá-la em uso prático. Um bom exemplo é a telemedicina. Seu uso repentino e generalizado também mudou o ambiente político, e o cenário da saúde nunca mais será o mesmo.\n\nEsse tipo de mudança fundamental na política ocorre em eventos com grande velocidade, como a Grande Recessão ou o 11 de setembro. Coisas semelhantes acontecerão pós-COVID. Esses eventos, por mais difíceis que sejam, proporcionam uma oportunidade para as organizações darem um salto gigantesco em sua performance e em como utilizam a tecnologia.\n\n## Navegando por Mudanças Disruptivas\n\nA Intel sempre foi à frente ao responder a grandes desafios e perturbações. Partes fundamentais da cultura são prontidão, propósito compartilhado e confiança. Esses podem existir quando os funcionários têm um senso de segurança psicológica. Por exemplo, Darren se sentiu empoderado quando o CEO da Intel disse que ninguém seria demitido por causa da COVID. Isso permitiu que ele assumisse riscos para enfrentar a crise sem medo de perder seu emprego. E embora o CEO e os gerentes seniores dêem o tom, a maior parte do trabalho de segurança psicológica é realizada pelos gerentes de linha de frente. Essa segurança e empoderamento levam a uma prontidão incorporada. Juntamente com o propósito compartilhado e a confiança, esses são os blocos de construção fundamentais não apenas de uma organização pronta para responder a uma crise, mas as características de uma organização com alto desempenho.\n\nUma organização de alto desempenho também terá as ferramentas para navegar por perturbações que são mais como uma queima lenta do que um evento de alto impacto rápido. Com eventos como a COVID ou a Grande Recessão, há muito pouco debate sobre o que está acontecendo, e todos estão a par da enormidade dos problemas. Se compararmos isso, por exemplo, a uma mudança fundamental nos negócios, uma mudança arquitetônica ou uma tecnologia se manifestando na curva do hype da qual você não tem certeza se é relevante para o negócio ainda, haverá mais incerteza e debate sobre os ajustes.\n\nComo é que uma organização sobrevive a estes pontos de inflexão? Telemetria, ou seja, a entrada que está a avaliar, é importantíssima. Uma das complexidades de uma grande organização é que, quando essas entradas chegam a um tomador de decisões sénior, elas podem ter passado por três camadas de ajustes e posicionamentos, o que pode ser perigoso. A verdade e a transparência são valores na Intel. Numa empresa com um alto grau de segurança psicológica, os funcionários podem falar a verdade sobre os problemas.\n\nA entrada mais importante é ouvir seus clientes, pois eles tendem a orientar você na direção certa. Por exemplo, se alguém quer saber sobre uma conta, Rick frequentemente traz o executivo de conta para obter informações de primeira mão. Também é um sábio liderança buscar diretamente os especialistas em vez de obter informações através de três camadas de filtragem e manipulação, especialmente ao operar em uma crise. A resposta ao momento se resume a cultura de prontidão, telemetria adequada e tomada de decisão.\n\nTomar decisões pode se tornar complicado em uma organização grande. Uma solução simples é que cada pessoa que entra em uma reunião deve se perguntar: estamos aqui para tomar uma decisão? Quem é o responsável pela decisão? Ou estamos apenas debatendo ou preparando a telemetria e os dados para o responsável pela decisão? Isso é apenas uma boa higiene organizacional.\n\nAndy Grove disse: \"Deixe um pouco de caos reinar e depois controle o caos\". Para decisões nos pontos de inflexão, os avanços lentos, às vezes você precisa permitir que a inovação respire e percole um pouco, e ao mesmo tempo você quer administrar as coisas de tal maneira que elas não saiam do controle. Ter bons processos e limites em vigor ajuda com isso.\n\nEm tempos difíceis, os tomadores de decisão precisam ter um entendimento profundo de que cada indivíduo estará em um estado diferente e devem pensar nas consequências das decisões. A segurança psicológica é muito importante, e os gerentes de linha de frente e de segunda linha são essenciais para a capacidade de uma organização executar bem em tempos de interrupção. A liderança sênior é fundamental para estabelecer o tom, mas esses gerentes assumem a responsabilidade pelo trabalho.\n\nDas mudanças tecnológicas futuras previsíveis, como o impacto da inteligência artificial no 5G, aos problemas como as mudanças climáticas, aos eventos mundiais não previstos, a única constante é que sempre estaremos navegando por interrupções, crises e mudanças. Uma das marcas registradas da cultura da Intel é sua capacidade de responder, adaptar-se e ser resiliente a esses eventos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rick Herrmann"],"link":"/episode-EDT35-pt","image":"./episodes/edt-35/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto Chefe de Soluções do Setor Público, e Rick Hermann, Diretor do Setor Público dos EUA, da Intel, discutem como a Intel tem sido bem-sucedida na navegação de mudanças disruptivas nas últimas três décadas."},{"id":106,"type":"Episode","title":"Seis Pilares da Cibersegurança.","tags":["cybersecurity","prevention","threatdetection","zerotrustarchitecture","zta","technology"],"body":"\r\n\r\nCom o aumento dos ciberataques em todas as indústrias, a segurança é mais importante do que nunca. Neste episódio, Darren e Steve Orrin, CTO Federal da Intel, descrevem os vetores de ataque, os seis pilares da cibersegurança e como a Intel pode ajudar.\n\nSteve tem visto a segurança evoluir nos 25 anos em que trabalha na área, tanto como uma ciência quanto como uma arte. Ao mesmo tempo, o nível de complexidade com o qual as organizações precisam lidar para proteger seus dados, sistemas e aplicativos nunca foi tão difícil.\n\n## Grandes-escala infrações e ataques cibernéticos continuam\n\nGrandes violações de dados em grande escala e intrusões profundas estão ocorrendo em todos os níveis, desde plataformas de mídia social até serviços financeiros e saúde. Nenhum tipo de dado está isento de ser alvo de técnicas cada vez mais sofisticadas.\n\nO que está impulsionando esses ataques? Uma resposta é que hoje, um ataque em larga escala ou profundo requer menos recursos e investimento financeiro. O alcance e a dimensão do que um hacker pode fazer com um pequeno investimento tem dado aos adversários uma vantagem em um sistema complexo.\n\n## Três Forças Que Impactam a Segurança Empresarial e Missão\n\nOutra resposta para o que está impulsionando os ataques é que os dados são um ativo valioso: o novo petróleo. Os dados são vulneráveis ​​à medida que a expansão da superfície de ataque continua a crescer.\n\nExistem mais pontos de integração, produtos, sistemas operacionais de fornecedores e dispositivos envolvidos na gestão, consumo e transporte dos dados. Os dados estão ainda mais distantes do controle da empresa. Às vezes, nem temos certeza de onde nossos dados existem. Por exemplo, talvez você tenha compartilhado seus dados com outra organização e eles compartilharam as análises realizadas nos dados. Esses metadados frequentemente se tornam resíduos de dados. Seus dados estão passando por múltiplos sistemas, podendo ser acessados por um atacante posteriormente.\n\nA indústria de segurança em si é composta por milhares de fornecedores e produtos de segurança que resolvem uma peça específica do quebra-cabeça, então há apenas tanto que um CIO pode fazer com um orçamento limitado e apenas tanto que eles podem lidar dada a complexidade. Devemos pensar de forma holística sobre como podemos proteger nossos dados, não apenas como proteger uma transferência entre o ponto A e o ponto B. Os dados são comprometidos no elo mais fraco, então temos que analisar toda a cadeia.\n\nA terceira força que impacta as empresas é a localização dos ataques. Eles incluem ataques em toda a estrutura do hardware, firmware, bios, software, serviços e aplicações. Com o aumento da sofisticação dos ataques, estamos presenciando ataques em múltiplas camadas de forma assíncrona e independente.\n\n## Os Vetores de Ataque\n\nTraduza o seguinte para o português: Hackers não estão apenas atacando o hardware ou um software específico, mas através de múltiplos vetores: pessoas, processos e tecnologia.\n\nTradicionalmente, implementar controles de segurança envolvia o treinamento adequado das pessoas e o uso dos processos e tecnologias corretas, mas diante dos ataques recentes, precisamos lembrar que o próprio processo é vulnerável. Por exemplo, precisamos mudar para aplicação automatizada de correções para reduzir o período de exposição desde quando uma vulnerabilidade é descoberta até quando uma correção é lançada e implantada por uma organização. Tradicionalmente, temos convivido com o risco de que os atacantes tenham meses para explorar a vulnerabilidade.\n\nExistem outros ataques de processo que estamos apenas agora selando, seja no processo de construção ou no ciclo de desenvolvimento de software. Integrar a segurança cedo no ciclo de desenvolvimento é o aspecto mais importante para garantir a segurança de uma aplicação. Isso significa que desenvolvedores, QA e designers devem todos estar envolvidos no processo de segurança. Parte do desafio é a natureza isolada de cada parte do processo, onde vulnerabilidades podem se infiltrar nas brechas e transições.\n\n## Seis pilares da cibersegurança\n\n## Segurança da Cadeia de Suprimentos\n\nA segurança da cadeia de suprimentos tem estado em destaque apenas nos últimos anos. Uma organização precisa ser capaz de confiar nos servidores, componentes e software. Uma boa cadeia de suprimentos, com transparência, é importante para validar que tudo vem de fontes legítimas. Tem havido um foco, particularmente no governo, na cadeia de suprimentos de hardware, mas não podemos esquecer da cadeia de suprimentos de software. A cadeia de suprimentos de software é um pouco mais difícil do que a de hardware, pois muitas vezes há uma falta de visibilidade, pois os produtos podem ser montados a partir de ferramentas de código aberto, produtos de outras pessoas, etc. Em um ataque recente, a cadeia de suprimentos de software foi o problema, e isso é apenas a ponta do iceberg.\n\n## Hospedagem e Segurança do Sistema\n\nUma vez que tenhamos uma cadeia de suprimentos confiável, o próximo passo está na segurança do sistema de hospedagem. A base são as tecnologias de inicialização segura e as capacidades criptográficas para garantir e proteger dispositivos físicos e sistemas onde as aplicações funcionarão e os dados serão executados. Esse sistema suporta recursos de segurança de pilha em níveis superiores no hardware.\n\n## Segurança de Dados e Aplicações\n\nAcima da segurança do host e do sistema é onde você constrói a segurança da carga de trabalho de sua aplicação. Os dados devem ser protegidos durante todo o seu ciclo de vida, em repouso, em uso e em trânsito. Já fazemos segurança para dados em repouso e em trânsito há muito tempo, usando criptografia de transporte, TLS e IP sec, e outras capacidades de criptografia, e então criptografia completa de disco e de arquivos. O elo perdido tem sido a memória criptografada \"em uso\" com isolamento de hardware. Nos últimos anos, tecnologias e pilhas de soluções estão possibilitando a proteção dessa última milha em torno da proteção de dados.\n\n## Segurança de rede\n\nEm paralelo com essa pilha de hospedeiros de cadeia de suprimentos e segurança de dados, precisamos de segurança de rede. A integridade e disponibilidade das redes são importantes para resistir a ataques de negação de serviço. Os dados precisam chegar onde precisam ir de forma segura. Também devemos monitorar e proteger redes de intrusões externas, seja essa rede empresarial ou uma rede distribuída por toda a nuvem e a borda. A segurança aqui não se trata apenas de firewall; envolve produção ativa.\n\n## Identidade e Gestão de Acesso\n\nA gestão de identidade e acesso é uma capacidade fundamental. Não precisamos apenas saber quem está fazendo login, mas quem está fazendo login em qual dispositivo. O ser humano é apenas uma pequena parte do quebra-cabeça. Precisamos ter identidade para todas as coisas, processos e serviços que estão acessando e gerenciando os dados. Uma pessoa pode realizar seu trabalho com apenas algumas teclas, mas pode haver 20 dispositivos diferentes e 100 serviços e processos que atuam nos dados. Precisamos ter políticas e autorizações para todas essas entidades. E à medida que avançamos para processos autônomos, há menos humanos envolvidos, então torna-se ainda mais importante ter uma identidade forte para esses processos sem um ser humano envolvido.\n\n## Detecção de ameaças, Inteligência e Análise\n\nEste último pilar é uma combinação de muitas coisas, incluindo inteligência de ameaças, análise, monitoramento e auditoria. É a visibilidade abrangente para garantir que tudo esteja funcionando como deveria e, se algo estiver errado, a capacidade de entender rapidamente de onde vem e por quê. Este é o guarda-chuva que impulsiona a segurança de dados e tudo deve contribuir para cima e para baixo. Há uma mudança de trabalhar em um ambiente isolado, digamos, um fornecedor que está apenas preocupado com a segurança de rede, para trabalhar em todo o sistema como um todo. Empresas bem-sucedidas têm equipes diversas com pessoas de diferentes domínios para atender às necessidades complexas de segurança.\n\n## Domínios de Cibersegurança: Alcançando a Confiança Zero com Tecnologias Intel.\n\nA Intel oferece capacidades fundamentais em cada um dos seis pilares, seja por meio da nossa iniciativa de garantia de ciclo de vida de computação para ajudar a envolver os OEMs e fornecedores de componentes em uma cadeia de suprimentos confiável, fornecendo os blocos de construção fundamentais da segurança do sistema, ou garantindo que a inicialização segura comece com o hardware. Temos tecnologia de execução e tecnologia de proteção de inicialização com aceleração criptográfica incorporada, para que os usuários possam ativá-la para proteção de dados em repouso, dados em uso e dados em trânsito, sem impacto no desempenho.\n\nNo caso da inteligência de detecção de ameaças, a Intel fornece primitivas como o TPD, onde uma solução de pilha de nível superior pode fornecer visibilidade e detecção de ameaças onde nunca tivemos antes.\n\nA Intel é uma provedora de tecnologia, mas também trabalhamos na área de pessoas e processos. Um bom exemplo é a cadeia de abastecimento. Nós construímos um processo com o ecossistema para permitir que uma empresa seja capaz de validar os componentes e credenciais para uma determinada plataforma e seus componentes. Da mesma forma, existem processos envolvidos com a proteção de dados e uso através de capacidades no hardware, como SGX, sendo capaz de criptografar a memória e isolar os dados e código para uma determinada aplicação.\n\nA Intel está possibilitando processos seguros para aproveitar as tecnologias em grande escala. Outra parte fundamental em relação aos processos é se adequar à estrutura geral de riscos de uma organização. A Intel fornece as provas e a atribuição necessárias dentro de nossas tecnologias para mapear isso em sua estrutura de riscos existente.\n\nA última peça são as pessoas. Lidar com o comportamento humano aleatório às vezes é a parte mais difícil da segurança, seja em golpes de phishing ou ataques planejados a senhas fracas. O treinamento é crucial, mas muitas vezes não é suficiente. Processos e tecnologias podem ajudar a complementar o treinamento, por exemplo, tornando as senhas mais fortes ou eliminando o phishing caso as credenciais do usuário não possam ser comprometidas. No final do dia, no entanto, o treinamento e a educação contínuos sempre serão críticos, juntamente com as tecnologias de mitigação.\n\nA segurança é difícil, mas há luz no fim do túnel com todas as inovações no ecossistema e com organizações abertas a fazer as coisas de maneira diferente. Precisamos manter o foco em duas coisas: a adoção de estruturas de risco e a confiança zero. Vinculando esses dois mundos juntos, o domínio da cibersegurança para motores de políticas e aplicação pode fornecer uma abordagem abrangente para a segurança. Há muita atividade aqui e ainda há muito trabalho a ser feito.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT36-pt","image":"./episodes/edt-36/pt/thumbnail.png","lang":"pt","summary":"Com ataques cibernéticos em ascensão em todas as indústrias, a segurança é mais importante do que nunca. Neste episódio, Darren Pulsipher, Arquiteto Chefe de Soluções, e Steve Orrin, CTO Federal da Intel Federal, delineiam os vetores de ataque, os seis pilares da cibersegurança e como a Intel pode ajudar. O nível de complexidade com o qual as organizações devem lidar para proteger seus dados, sistemas e aplicativos nunca foi tão difícil."},{"id":107,"type":"Episode","title":"2020 em revisão","tags":["covid","cybersecurity","remoteworker","people","process","compute","data"],"body":"\r\n\r\n## 2020 - Expectativas\n\nAntes do COVID, 2020 estava parecendo o ano para novos modelos de negócios, caminhando em direção a grandes transformações digitais. IA/AP e análises iriam desempenhar um papel fundamental no futuro. Utilizando essas ferramentas, iríamos começar a utilizar os dados de forma mais eficaz em nossas organizações. Seria o ano do 5G, com o 5G fazendo um grande impacto nas Olimpíadas.\n\nTambém íamos presenciar um avanço significativo na indústria para as transformações da indústria 4.0, com a Internet das Coisas e a fabricação caminhando juntas em direção a essa transformação digital.\n\n## 13 de março\n\nEntão, pelo menos na Califórnia, tudo parou abruptamente na sexta-feira, dia 13 de março. Negócios, escolas, conferências, reuniões, viagens e eventos sociais foram abruptamente suspensos. Semanas se transformaram em meses, à medida que o otimismo em conter rapidamente o vírus diminuía, enquanto cidades como Nova York sofriam fortemente e os sistemas médicos estavam sobrecarregados. Tudo parecia caótico e incerto.\n\nAlgumas coisas interessantes surgiram disso: Algumas empresas prosperaram enquanto outras tiveram um período mais difícil, e as pessoas começaram a trabalhar remotamente.\n\n## Site mais visitado em minha casa.\n\nNa minha casa, o site com mais visualizações deixou de ser o Facebook e passou a ser o Centro de Ciência e Engenharia de Sistemas da Universidade Johns Hopkins, que fornece estatísticas sobre o vírus. Podíamos ver os efeitos no nosso próprio bairro, cidade e em todo o mundo. A nossa percepção do que era importante e dos planos que tínhamos para esse ano mudaram completamente.\n\n## Escassez.\n\nNão só houve escassez imediata de itens tão diversos como papel higiênico, álcool em gel e fermento, mas também algumas semanas depois, equipamentos de escritório e tecnologia se tornaram itens muito procurados enquanto as pessoas rapidamente se adaptavam ao ensino à distância e trabalho em casa. Isso gerou escassez de ferramentas essenciais, como webcams e laptops.\n\nOs roteadores Wi-Fi 6 se tornaram importantes de repente à medida que o uso da internet em casa aumentou. Em nossa família, passei de trabalhar em casa periodicamente para trabalhar em casa em tempo integral, além de adicionar três adolescentes estudando à distância e três adultos estudantes universitários que voltaram para casa para estudar e trabalhar. Nossa conexão com a internet foi rapidamente sobrecarregada. Tive dificuldade em encontrar um roteador Wi-Fi 6 para resolver nosso problema, já que muitos se encontraram em situações semelhantes.\n\n## Viagem mudou.\n\nCom as viagens praticamente interrompidas, muitas pessoas se voltaram para projetos de melhorias domésticas. Eu costumava estar frequentemente no aeroporto, com viagens representando metade de cada semana. Agora, me encontro na Lowe's ou Home Depot como todo mundo. Os lugares estavam lotados. O tempo que normalmente eu passava viajando agora era gasto construindo um galpão com meus filhos. Tive a oportunidade de passar mais tempo de qualidade com meus filhos e melhorar minha casa.\n\n## Conferências\n\nUma mudança significativa, é claro, foi o cancelamento de conferências presenciais. Muitos passaram a realizá-las online com excelentes resultados. Por exemplo, a conferência IBM Think trocou seu evento presencial de maio pelo online. Mais de 100.000 pessoas participaram, o maior público que já tiveram.\n\nAlém do aumento de participação, outro benefício é que os participantes não precisam se comprometer por uma semana inteira em uma conferência, mas podem escolher as sessões e ainda estar em casa com a família. A desvantagem é a falta de networking e de ver as pessoas cara a cara.\n\nAs conferências do setor provavelmente serão modificadas para sempre. Nem sempre serão completamente online, mas talvez uma versão híbrida faça sentido no futuro.\n\n## Trabalho Forçado em Casa\n\nOutra mudança importante é que estamos nas casas uns dos outros, conduzindo negócios virtualmente. Às vezes, há crianças, cachorros ou outras distrações inevitáveis ao fundo. Uma vez, meu chefe precisou que sua filha sentasse ao lado dele durante uma reunião com a equipe, pois ela precisava de ajuda com algo. É importante que sejamos todos flexíveis durante esse período.\n\n## Trabalhadores Nômades\n\nAlguns funcionários não estão trabalhando em casa, mas se tornaram nômades, já que não precisam mais estar perto do local de trabalho.\n\nPor exemplo, meu sobrinho, que tem poucas responsabilidades em casa, estava pagando um aluguel exorbitante na região de Bay Area. Quando o trabalho se tornou remoto, ele e seus colegas de quarto abandonaram seu apartamento caro e viajaram pelo mundo, passando vários meses alugando casas em lugares interessantes.\n\nEsta é uma mudança importante na forma como pensamos em gerenciar nossos trabalhadores, ativos e dados.\n\n## Trabalho Remoto\n\nO trabalho remoto acelerou rapidamente. Muitas empresas já tinham algumas políticas de trabalho remoto ou planos para aumentar o trabalho remoto. Mas o que antes era talvez um plano de implementação de 18 meses se tornou um plano de implementação de 18 dias.\n\nA principal forma de trabalho remoto que ocorreu foi o VDI (infraestrutura de desktop virtual). As pessoas têm usado VDI há décadas, mas de repente tornou-se a opção principal, em parte, devido à sua familiaridade. É rápido, fácil e barato fazer as pessoas voltarem a trabalhar com acesso aos dados necessários usando soluções de hardware.\n\nAs VPNs (redes virtuais privadas) ficaram rapidamente sobrecarregadas pois todos estavam trabalhando em casa. Vimos empresas investindo em expandir suas VPNs, seja comprando mais licenças ou mais infraestrutura e realizando atualizações conforme necessário.\n\nAs empresas também aceleraram sua adoção de ferramentas de SaaS (software como serviço). Por exemplo, a implementação do Office 365 aconteceu em poucas semanas, ao invés dos planejados seis a nove meses. Empresas com ofertas de SaaS, como Microsoft e Google, arregaçaram as mangas e ajudaram as organizações a passarem pela migração rapidamente. Para o trabalhador remoto, o tempo improdutivo foi minimizado com o esforço de toda a indústria.\n\nFoi notável o quão rápido os trabalhadores remotos estavam operando. Os verdadeiros heróis aqui foram os trabalhadores de TI da linha de frente, como o suporte técnico, engenheiros de sistemas, administradores de sistemas, etc. Foi realmente um esforço hercúleo.\n\n## Mudanças na cibersegurança\n\nUma das coisas, no entanto, que ficou um pouco para trás com a velocidade dessa mudança foi a cibersegurança. Temos sentido as ramificações disso nas últimas seis a oito semanas, com vários ataques importantes em cibersegurança.\n\nUma das razões é uma superfície de ataque ampliada, pois os dados estão espalhados em laptops em toda a organização em redes não seguras de residências.\n\nAlguns dos dados estão armazenados na nuvem. Agora, com as ofertas de SaaS, parte deles está armazenada no centro de dados e parte nos computadores que as pessoas levaram para casa.\n\n2021 será um ano em que vamos focar na cibersegurança, analisando cuidadosamente a forma como estamos gerenciando os dados e protegendo-os em todo o sistema.\n\n## Novo traje empresarial\n\nUm dos maiores avanços deste ano é a nova roupa de negócios. A melhor forma de descrevê-la é como um \"mullet\" empresarial: traje de negócios na parte de cima, pijama ou shorts na parte de baixo. Eu uso calças de vez em quando, mas meus filhos devem estar cansados de me ver usando uma camisa social ou até mesmo um terno na parte de cima combinado com shorts.\n\n2020 foi um ano de mudanças, pessoais e profissionais, mas nos levou a um lugar em 2021 onde podemos avançar com as lições aprendidas e melhorias para um futuro melhor.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT37-pt","image":"./episodes/edt-37/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Setor Público, na Intel, reflete sobre a interrupção, mudanças e ajustes que a pandemia da COVID-19 trouxe em 2020."},{"id":108,"type":"Episode","title":"Os anos 20 rugindo: uma visão para 2021","tags":["contactless","covid","remotelearning","remoteworker","people","process"],"body":"\r\n\r\n## COVID-19 Um Tempo Sem Precedentes de Volatilidade, Incerteza, Complexidade e Ambiguidade.\n\nNeste episódio, Darren pergunta a Rachel Mushawar, Vice-Presidente de Vendas da Intel, sobre sua perspectiva do que está por vir para os Anos Loucos 20 após a interrupção do COVID-19.\n\n## 2020\n\nOs últimos doze meses foram marcados por mudança inconfundível e incerteza, tanto profissionalmente quanto pessoalmente. Nem todos os anos serão como 2020, mas as lições nos tornarão melhores a cada ano que passa.\n\nApesar das circunstâncias individuais, cada pessoa teve que fazer uma pausa e descobrir o que era importante. Valorizamos nossas equipes, amigos, famílias e relacionamentos mais do que nunca.\n\nE embora tenhamos estado fisicamente isolados, a conectividade através da tecnologia acelerou em um ritmo sem precedentes. O senso de possibilidade de todos nessa área foi rejuvenescido e, de certa forma, desbloqueado e libertado para o futuro.\n\n## A pandemia criou mais responsabilidades.\n\nPor outro lado, a pandemia criou mais responsabilidades. Quase metade dos adultos na faixa dos quarenta e cinquenta anos têm um pai ou mãe com 65 anos ou mais e têm filhos pequenos ou estão apoiando financeiramente filhos mais velhos. Isso significa que provavelmente estão conciliando o ensino à distância de seus filhos, trabalho em casa e cuidados com os pais idosos.\n\nAs per the following translation, the word \"lockdown\" has been retained in English. \n\nO número de empregos perdidos nos Estados Unidos em dezembro foram todos de mulheres. Parte disso se deve às maiores responsabilidades em casa durante a pandemia. Se você tem filhos pequenos em casa que estão aprendendo à distância agora, e você é um trabalhador por hora, como você consegue? Não consegue. E, embora durante o lockdown os pais tenham quase duplicado seus cuidados com as crianças, ainda temos um longo caminho a percorrer na década de 20 em relação à igualdade de gênero. Não pode ser apenas sobre tecnologia.\n\n## Educação Remota traz foco para a Divisão Digital\n\nÀ medida que entramos na década de 1920, temos toda uma geração de crianças que passaram os últimos 12 meses estudando em casa.\n\nNa verdade, uma em cada quatro famílias americanas tem pelo menos uma criança com 14 anos de idade ou menos. Para os estudantes que vêm de um meio desfavorecido, um estudo do Fórum Econômico Mundial descobriu que 25% não possuem um computador. Além disso, 33% dos estudantes em comunidades rurais têm pouco ou nenhum acesso à internet. A falta desses dois fundamentos de aprendizado à distância aumentou a divisão digital.\n\n## Estamos vivendo \"O Futuro do Trabalho\"\n\nMuitas ideias antigas foram quebradas em 2020, à medida que as empresas tiveram que se adaptar imediatamente para o trabalho em casa. Oitenta e cinco por cento das organizações expandiram ou implementaram diversas políticas de trabalho em casa que vão se estender além da COVID-19. Muitas empresas perceberam economias ao reduzir o espaço físico, já que a produtividade permaneceu igual ou aumentou com uma força de trabalho em casa ou nômade. Muitos funcionários também estão percebendo economia de tempo ao eliminar deslocamentos e preparações pessoais, como cabelo, maquiagem e vestuário. Uma tendência para 2021 será um visual mais casual e natural.\n\nÀ medida que os deslocamentos desapareceram, a conectividade aumentou e os quartos se tornaram escritórios, no entanto, um lado negativo surgiu à medida que o dia médio de trabalho se prolongava e tornava-se mais difícil desligar.\n\n## \"Contactless\" está impulsionando tudo como um serviço\n\nUma das coisas-chave em 2021 será como continuamos a aproveitar a tecnologia para nos manter conectados. Por exemplo, existem tecnologias semelhantes ao Zoom que levam isso adiante e proporcionam oportunidades sociais similares a uma conversa informal no escritório, mas no espaço virtual. Trinta e dois por cento dos adultos tiveram reuniões sociais virtuais em 2020. A Intel realizou visitas a uma fazenda virtual de cabras e trouxe instrutores de ioga para ajudar a combater o isolamento.\n\n## Mais conexões, menos atrito, mais virtual, menos contato físico.\n\nÀ medida que avançamos para o resto dos anos 20, a tecnologia se tornará a base para cada grande transformação, independentemente de ser no setor privado ou público.\n\nComo essa nova forma de trabalhar e o aumento de responsabilidades em casa se resumem do ponto de vista de um CIO?\n\nExistem alguns imperativos estratégicos para a área de TI. Podemos dividi-los nas categorias tradicionais de aplicativos, rede e centro de dados.\n\nPrimeiro, para aplicações, os CIOs têm que descobrir como permitir o contato sem contato, ou seja, como conduzir tudo como um serviço? Isso não se aplica apenas a varejistas, mas também à área da saúde, governo e manufatura. A segunda parte das aplicações é saber quem é o seu consumidor e como eles consomem conteúdo.\n\nCompreender a importância da sua rede é o próximo passo. Ela é o impulso turbo para todas as coisas digitais. As organizações devem ter uma rede que, por exemplo, permita automatizar suas fábricas ou oferecer telemedicina. Elas devem ser visionárias para quando a tecnologia 5G se torne mais realidade, em vez de investir em tecnologia do passado. As redes agora se estendem além dos centros de dados tradicionais, portanto, é algo para o qual devemos prestar atenção. Claro, a segurança deve ser uma prioridade aqui.\n\nAssim como as redes, a segurança não é um tópico excitante ou sexy, mas é um aspecto fundamental quando pensamos em todos os pontos finais que agora são prevalentes em nossas vidas cotidianas. A superfície de ameaça está crescendo exponencialmente com funcionários trabalhando em casa em dispositivos diferentes e a implementação de tudo como serviço para os clientes. A segurança não se resume mais apenas a proteger os dados em repouso e em movimento. Agora envolve tudo o que está entre eles.\n\nEm vez dos tradicionais centros de dados, devemos pensar neles como centros de dados, atendendo a certas cargas de trabalho. A nuvem está crescendo de 30 a 40 por cento ao ano, por exemplo, para aproximar os centros de dados dos funcionários ou clientes. No entanto, pode não fazer sentido, para alguns dados críticos altamente confidenciais, serem movidos para a nuvem, permanecendo nas instalações. Os CIOs devem entender quais são seus centros de dados e qual deles atenderia melhor cada segmento da organização em termos de recuperação, armazenamento, eficiência de custos e desempenho.\n\nAo entrarmos na década de 20, as organizações devem realizar mudanças estratégicas, tanto nas práticas de contratação quanto na forma como prestam serviço aos seus clientes, mantendo esses conceitos em mente.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rachel Mushawar"],"link":"/episode-EDT38-pt","image":"./episodes/edt-38/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto-chefe de Soluções na Intel, pergunta a Rachel Mushawar, VP de Vendas na Intel, sobre sua visão do que está por vir para os anos dourados depois da interrupção da COVID-19."},{"id":109,"type":"Episode","title":"Conversa de bebedouro em uma força de trabalho remota","tags":["collaboration","covid","organizationalchange","people","compute","remoteworker","videoconferencing","signalwire"],"body":"\r\n\r\n## Novos espaços de trabalho colaborativos\n\nNeste episódio, Darren e Sean Heiney, co-fundador da SignalWire, Inc., discutem novos espaços de trabalho colaborativo remoto que eliminam as cansativas videoconferências que acontecem durante todo o dia. Sua política de Cameras on e a tecnologia SignalWire Work permitem uma comunicação ad hoc como nunca antes.\n\n## A Criação do SignalWire Work.\n\nA SignalWire é a desenvolvedora da maior plataforma de comunicações de código aberto do mundo. Nos últimos três ou quatro anos, a SignalWire tem se concentrado na construção da próxima geração de aplicativos de comunicações em tempo real de vídeo e voz, o que resultou no SignalWire Work para escritórios remotos.\n\nUm antecessor do SignalWire Work era a própria ferramenta da SignalWire que eles construíram para si mesmos, já que a empresa tem sido distribuída desde o início, trabalhando remotamente por três anos. As ferramentas existentes de colaboração remota não atendiam às suas necessidades, com mais de 60 pessoas espalhadas por vários países e continentes. Alguns já estavam usando áudio sempre ativo, mas como muitos de seus engenheiros também compartilhavam telas Unix, isso evoluiu para vídeo sempre ativo. Quando a COVID atingiu, os clientes queriam acesso a essa ferramenta, então o SignalWire Work nasceu, juntamente com uma versão para eventos ao vivo.\n\n## O Ambiente de Trabalho SignalWire.\n\nTrabalhar em espaços colaborativos remotos não é apenas uma inovação tecnológica, mas também um experimento social. Para algumas pessoas, sempre estar em vídeo pode parecer estranho ou assustador. No entanto, uma vez que todos tenham aderido à filosofia, pode ser mais eficiente do que estar em um escritório físico. Existem ineficiências em um mundo como o Zoom, onde as pessoas só falam em reuniões agendadas com pautas específicas. Muitas das comunicações importantes e informais são perdidas.\n\nCom as ferramentas do SignalWire, os colegas de trabalho podem ver dentro dos quartos das pessoas, como se houvesse uma parede de vidro no mundo físico. Você pode ver o quão ocupados eles estão, em que tipo de humor eles estão ou se estão conversando com outra pessoa. Você pode aparecer e fazer uma pergunta. Há interação social, conversas de corredor, que não são possíveis com reuniões agendadas. Quando você faz login no SignalWire Work, é como entrar em um escritório físico.\n\nExistem recursos que garantem privacidade. Você pode desfocar seu vídeo para que as pessoas não possam ver seu rosto, ou entrar no modo de imersão, onde as pessoas não podem interrompê-lo, mas ainda sabem que você está presente e podem bater na sua porta virtual.\n\nOutra vantagem é que pode haver fronteiras mais claras entre a vida doméstica e profissional. Quando você encerra a sessão do escritório, é uma separação clara.\n\n## A Tecnologia\n\nA SignalWire criou a tecnologia que impulsiona desde o doorbell Ring até partes do Amazon Connect e do motor de atendimento ao cliente da Netflix; eles estão basicamente em todas as principais empresas de telefonia. Agora, estão focados em possibilitar que essa tecnologia chegue às mãos das pessoas comuns e que elas possam desenvolvê-la. Um exemplo disso é a plataforma de igreja virtual mais popular do mundo, que foi construída há cerca de um ano na SignalWire.\n\nUm aspecto único que dá à SignalWire uma vantagem estratégica é que a multiplexação de vídeo é feita na nuvem. Uma aplicação tradicional de videoconferência irá codificar e transmitir o vídeo para todos os participantes em uma conferência. Se houver sete pessoas, haverá sete fluxos. Isso é muito trabalho para o processador. É trabalho no seu dispositivo transmitir os dados e você está sujeito a interferências e perda de pacotes em todos esses fluxos individuais, portanto, você pode ter uma ótima conexão com alguém, mas a outra pessoa parece horrível.\n\nCom SignalWire, os clientes enviam um único fluxo para a nuvem. A nuvem combina todos os fluxos, os multiplexa e, em seguida, envia esse único fluxo de volta para todos, resultando em apenas uma transmissão e recepção. Isso traz várias vantagens, como uma vida útil de bateria melhor, menor consumo de dados e menor carga de trabalho nos processadores do dispositivo local.\n\nPara a experiência do usuário, o SignalWire pode melhorar o áudio quando está sendo misturado juntamente, ou controlar o layout para que todos vejam a mesma coisa na mesma orientação. Quando você aponta para alguém na tela, por exemplo, todos conseguem ver isso. Para eventos como sessões de exercícios ao vivo, a plataforma permite que os usuários ouçam a música de fundo e o apresentador ao mesmo tempo, além de poderem ver, digamos, trinta outros participantes. Tudo isso contribui para uma sensação e experiência mais conectadas.\n\nSignalWire pode ser executado em qualquer nuvem ou plataforma, até mesmo em um dispositivo individual ou baseado em átomo. Empresas podem utilizá-lo em sua própria infraestrutura, o que é importante para segurança e controle de dados no mais alto nível. SignalWire pode implantar seus nós dentro de uma rede segura para proteger dados sensíveis de trafegar na internet pública.\n\nA plataforma é totalmente flexível com a tecnologia e aplicativos dos usuários, permitindo até mesmo que um grande estúdio de transmissão a utilize para produzir e editar um de seus shows, trazendo extras para dublagens em gravações existentes, pois a qualidade em tempo real é tão alta.\n\n## Um ambiente de trabalho mais profissional em espaços de trabalho remotos.\n\nA chave para tornar este novo tipo de espaço de trabalho viável é mergulhar nele e torná-lo uma política da empresa. Os benefícios se tornam rapidamente evidentes. Quando você chega ao trabalho, você entra em vídeo e está presente e interage com seus colegas de trabalho, assim como fazia antes da COVID.\n\nQuando as pessoas iam para o escritório antes da COVID, provavelmente se vestiam bem para causar uma boa impressão profissional. Neste mundo, essa impressão é feita principalmente através de um bom setup de áudio e vídeo: bons microfones, iluminação, um ambiente de alta qualidade. Os funcionários estão se esforçando ao máximo usando tecnologia, porque agora vivemos num mundo tecnológico. É uma evolução do ambiente informal de trabalho remoto, onde se sentava na praia ou na mesa da cozinha enquanto o jantar era preparado. Conversas mais profissionais podem ocorrer em um ambiente de trabalho remoto mais profissional.\n\nA melhor maneira de experimentar essa tecnologia é testando-a. Há um teste gratuito de 30 dias em https://signalwire.com/products/work.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Heiney"],"link":"/episode-EDT39-pt","image":"./episodes/edt-39/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Setor Público, Intel, e Sean Heiney, co-fundador da SignalWire, Inc., discutem as políticas de trabalho remoto das empresas de câmeras ligadas e sua nova tecnologia de espaços de trabalho colaborativos remotos que promovem a comunicação ad hoc para sua equipe totalmente remota."},{"id":110,"type":"Episode","title":"Modelo de Maturidade de Gerenciamento da Informação","tags":["data","informationmanagement","informationmaturity","datagovernance","datawarehouse","datalake","datamesh","datalineage","technology","process","people"],"body":"\r\n\r\nDesenvolver uma estratégia de dados pode ser difícil, especialmente se o estado de gerenciamento de informações ou trajetória da sua empresa estiver incerto. Este Modelo de Maturidade de Gerenciamento de Informações ajuda os CDOs e CIOs a identificarem onde estão em sua jornada de gerenciamento de informações e sua trajetória. Este mapa pode ajudar a orientar as organizações enquanto elas continuamente melhoram e progridem em direção à organização de dados definitiva que lhes permite obter o máximo valor comercial de seus dados.\n\nO modelo representa uma série de fases, começando desde a menos madura até a mais madura: Padronizada, Gerenciada, Governada, Otimizada e Inovação. Muitas vezes, uma organização pode existir em várias fases ao mesmo tempo. Você pode determinar em qual fase a maioria da sua organização opera e, em seguida, identificar seus pioneiros que devem estar mais avançados em termos de maturidade. Use esses pioneiros para testar ou prototipar novos processos, tecnologias ou estruturas organizacionais.\n\n## Fase padronizada\n\nA fase padronizada possui três subfases: básica, centralizada e simplificada. A maioria das organizações se encontra em algum lugar desta fase de maturidade, portanto, observe os comportamentos, tecnologia e processos em sua organização para descobrir onde sua organização pode se encaixar.\n\n## Básico\n\nQuase toda organização se enquadra nessa fase, pelo menos parcialmente. Aqui, os dados são usados apenas de forma reativa e pontual. Além disso, quase todos os dados coletados são armazenados com base em prazos pré-determinados, muitas vezes indefinidamente. Empresas nessa fase básica não apagam os dados por medo de perder alguma informação crítica no futuro. Por exemplo, recentemente estávamos trabalhando com uma empresa que possui 30 anos de backups de e-mails, cerca de 12-10 terabytes, que eles têm medo de se livrar. Isso não é uma prática incomum.\n\nEsses atributos descrevem melhor essa fase:\n\nGestão por reação\n\nDados não catalogados\n\nArmazene tudo em todos os lugares.\n\n## Centralizado (Coleta de dados centralizada)\n\nConforme as organizações começam a avaliar sua estratégia de dados, elas primeiro procuram centralizar o armazenamento em soluções de armazenamento de big data. Essa abordagem pode ser em forma de armazenamento em nuvem ou de equipamentos de big data no local. Uma vez que os dados são coletados em um local centralizado, a tecnologia de armazenamento de dados pode possibilitar uma análise básica de negócios para obter informações acionáveis. Na maioria das vezes, esses dados são utilizados para corrigir problemas com clientes, cadeia de suprimentos, desenvolvimento de produtos ou qualquer outra área da sua organização onde os dados são gerados e coletados.\n\nEsses atributos descrevem melhor essa fase:\n\nGestão por reação\n\nColeta básica de dados\n\n* Armazéns de dados\n\nArmazenamento de grandes volumes de dados\n\n* Análise básica de big data\n\n## Traduza o seguinte para Português: Simplificado\n\nÀ medida que o número de fontes de dados aumenta, as empresas começam a formar organizações que se concentram na estratégia, organização e governança de dados. Essa mudança começa com o escritório do Chefe de Dados (CDO). Existem debates sobre se o CDO se encaixa na empresa sob o CEO ou CIO. Não se preocupe com onde eles se encaixam na organização. O importante é estabelecer um foco na organização de dados e implementar um plano para normalização de dados. A normalização proporciona a capacidade de correlacionar diferentes fontes de dados para obter novas perspectivas sobre o que está acontecendo em toda a sua empresa. Observe que, sem a normalização, os dados permanecem isolados e são apenas parcialmente acessíveis. A necessidade de desenvolver um plano para lidar com o enorme volume de dados coletados também é um aspecto importante dessa fase. Devido ao aumento no volume e no custo de armazenamento desses dados, o armazenamento em camadas se torna importante. Embora nas fases iniciais seja quase impossível saber a maneira ideal de gerenciar o armazenamento de dados, recomendamos o uso das melhores informações disponíveis para desenvolver planos racionais de armazenamento de dados, com a ressalva de que isso precisará ser revisado e melhorado assim que os dados estiverem sendo usados.\n\nEsses atributos descrevem melhor essa fase.\n\n* Gestão de dados preditiva (início de uma organização centrada em dados)\n\nNormalização de dados\n\nArmazenamento em camadas centralizado\n\n## Gerenciado (perfis de dados padrão)\n\nNa fase Gerenciada, as organizações formalizaram sua organização de dados; cientistas de dados, administradores de dados e engenheiros de dados agora fazem parte da equipe e possuem funções e responsabilidades definidas. A gestão de metadados se torna um fator chave para o sucesso nessa fase, e várias aplicações podem agora aproveitar os dados da empresa. A mudança de um data warehouse para um data lake permite maior agilidade no desenvolvimento de aplicativos centrados em dados. A virtualização do armazenamento de dados permite uma solução de armazenamento mais eficiente e dinâmica. A análise de dados agora pode ser executada em conjuntos de dados de várias fontes e departamentos da empresa.\n\nEsses atributos descrevem melhor esta fase.\n\nGerenciamento de dados organizados (Dados organizados no lugar com funções-chave identificadas)\n\nGerenciamento de metadados\n\nData lineage: Linhagem de dados\n\nData lake\n\nAnálise de grandes volumes de dados.\n\n* Armazenamento definido por software (virtualização de armazenamento)\n\n## Governed -> Governado\n\nA fase governada é principalmente alcançada quando uma organização adota uma abordagem centralizada para dados e alcança uma abordagem holística para governá-los e protegê-los. O CDO trabalha em estreita colaboração com o CSO (Chief Security Officer) para garantir que as estratégias de dados e segurança estejam trabalhando juntas para proteger os dados valiosos da empresa, ao mesmo tempo que os torna acessíveis para análises. Os dados são classificados em diferentes categorias com base na criticidade, sigilo ou importância. A conformidade ditada por regulamentos é automatizada e aplicada aos dados em toda a organização. A visibilidade aumentada do uso de dados e segurança aumenta com as estratégias conjuntas de dados e segurança e os planos táticos. A inteligência artificial básica está sendo amplamente utilizada na organização e as decisões comerciais são inferidas pelos dados. Agora, os dados podem ser coletados e catalogados de toda a empresa, incluindo dispositivos da Internet das Coisas (IoT) nos ativos físicos da empresa.\n\nEsses atributos descrevem melhor esta fase:\n\nClassificação de Dados\n\n* Conformidade de dados\n\nSegurança de Dados\n\nInteligência Artificial Básica\n\nDistribuição de Virtualização de Dados / IoT\n\n## Otimizado\n\nÀ medida que a coleta de dados das organizações continua a aumentar, elas precisam encontrar eficiências na automação e melhoria contínua dos processos. A automação dos processos de dados é o principal foco na fase otimizada. Especificamente, a automação da anotação e metatagging dos dados diminui o tempo para extrair valor dos dados. Os dados agora se tornaram muito grandes para serem movidos para um único local centralizado, e uma arquitetura de \"data lake distribuído\" surge como a maneira ideal de gerenciar os dados. A aprendizagem de máquina é fundamental nesta fase para começar a fornecer informações aos tomadores de decisão para ajudar a otimizar as operações e o valor do negócio. Aplicações e dados são implantados em infraestrutura de rede, armazenamento e computação com base em informações históricas e modelos de inteligência artificial.\n\nEsses atributos descrevem melhor esta fase:\n\n* Etiquetagem meta automatizada\n\nData lake distribuído\n\nInferência de dados / APRENDIZAGEM DE MÁQUINA\n\nInfraestrutura orientada por dados.\n\n## Inovação\n\nA organização suprema está na fase de Inovação. Não é apenas impulsionada por dados, mas cria novos produtos, ofertas e serviços com base em aprendizados a partir de dados internos e externos à organização. Nesta fase, a IA/ML oferece vantagens inestimáveis. Existem três subfases na Inovação: visão, prescritivo e previsão.\n\n## Visão\n\nVisão é a tomada de decisão baseada em dados, com base no que você pode ver que está realmente acontecendo em seu ecossistema, por exemplo, em sua cadeia de suprimentos, desenvolvimento de produtos ou fabricação.\n\n## Prescriptive - Prescritivo\n\nEmbora a visão seja valiosa, ela requer interação humana, compreensão e intuição. No próximo nível, prescritivo, sua inteligência artificial está sugerindo o que você deve fazer com base na visão. Isso pode desempenhar um papel importante em toda a sua organização, pois as decisões são baseadas em dados desde a cadeia de suprimentos até a aquisição do cliente.\n\n## Previsão\n\nNeste passo crucial, os dados na verdade ajudam a criar o futuro. Por exemplo, a visão antecipada permitiria que uma organização de TI projetasse quanto de capacidade precisará no futuro com base em normas históricas e até mesmo fatores como as condições em mudança com seus concorrentes. A visão antecipada requer muitos dados e treinamento de modelos, mas leva ao objetivo final de uma empresa em tempo real.\n\nEsses atributos descrevem melhor essa fase.\n\nVisão (decisões baseadas em dados)\n\nPrescritivo (negócio orientado por dados)\n\nPrevisão (criar o futuro)\n\n*Dádiva em aprendizagem\n\n* Empresa em tempo real\n\n## Conclusão\n\nÉ comum se sentir preso em uma fase e sobrecarregado com a quantidade de mudança necessária para avançar para uma nova fase de maturidade. No entanto, cada passo adiante é valioso. Por exemplo, talvez você esteja em uma fase Centralizada e possa analisar a gestão de metadados. Existe a oportunidade de ir além de apenas limpar os dados e agora também melhorá-los? Esse tipo de pensamento progressivo irá fazer avançar na cadeia de maturidade na gestão das suas informações.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT4-pt","image":"./episodes/edt-4/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, iremos falar sobre o Modelo de Maturidade de Gestão da Informação e como podemos utilizar esse modelo para ajudar nossas organizações a avançarem. Este modelo pode ajudá-lo a identificar onde sua organização está e para onde ela está indo em sua estratégia de gestão da informação, obtendo assim o máximo valor comercial dos seus dados."},{"id":111,"type":"Episode","title":"Pesquisa Médica Colaborativa com Computação Confidencial","tags":["confidentialcomputing","cybersecurity","distributedanalytics","sgx","healthcare","data","technology","edge"],"body":"\r\n\r\n## Por que precisamos de computação confidencial?\n\nA infraestrutura computacional atual é construída com ênfase na partilha e abertura: a internet é gratuita e os dados devem ser gratuitos. Isso tem sido um problema quando se trata de segurança. Implementamos algumas soluções que funcionam bem, sabemos criptografar dados quando estão armazenados e quando estão em trânsito. Apesar disso, os dados podem ser atacados de várias formas enquanto estão sendo lidos, analisados e utilizados.\n\nDados sensíveis permanecem vulneráveis, seja financeiros, médicos ou de localização, tanto sob o ponto de vista de visibilidade quanto de integridade dos dados.\n\nAo lidar com dados na área da saúde, existem camadas adicionais de complexidade. Existem muitas regras e regulamentos, como o HIPAA, e cada estado possui suas próprias regulamentações sobre dados médicos também. Apesar da complexidade e do número de partes governantes, é possível ter computação confidencial, onde você tem a capacidade de compartilhar dados entre partes que, por natureza, não confiam umas nas outras.\n\nPara confidencialidade, precisamos pensar em alguns fatores diferentes: integridade dos dados, confidencialidade dos dados e integridade do código.\n\n## Problemas críticos de privacidade e segurança de dados\n\nTraduzindo para o português: Os registros de saúde de um indivíduo, especialmente nos Estados Unidos, estão espalhados entre médicos, especialistas, laboratórios e hospitais. A maioria das pessoas não tem fácil acesso aos seus registros; é quase impossível criar uma imagem completa de sua própria saúde. A computação confidencial pode ajudar a superar essas barreiras.\n\nPrimeiramente, isso pode garantir que quaisquer dados que você compartilhe, você possa confiar que serão protegidos em termos de integridade dos dados; eles não serão modificados por ninguém. Eles podem ser confidenciais, ou seja, tokenizados ou criptografados, mas ainda podem ser utilizados para cálculos. Por exemplo, se uma parte deseja realizar análises em alguns dados, ela não precisa conhecer informações como nomes, datas de nascimento ou números de seguro social. Portanto, se essas partes dos dados puderem ser tokenizadas ou criptografadas, elas podem ser compartilhadas para análise, desde que a outra parte seja confiável.\n\nIsso é onde medidas de segurança, como atestação, desempenham um papel, para que as partes possam comprovar sua identidade. E essa atestação pode estar vinculada ao nível de hardware até os ambientes de execução confiáveis que o hardware fornece. Dessa forma, você não está apenas confiando no transporte e no ponto final, mas também confiando no aplicativo e em como ele usará os dados.\n\nExistem duas abordagens básicas para isso. A primeira é o SDK de aplicativo, o que significa que o desenvolvedor pode decidir como dividir seu código em componentes confiáveis ​​e não confiáveis. A outra abordagem é ter um sistema de criptografia em tempo de execução que pode ser construído em cima de um ambiente de execução confiável, minimizando o esforço necessário para converter um aplicativo atual em algo que possa ser executado nesse ambiente.\n\nCom um ambiente de execução confiável baseado em hardware protegendo aplicativos e dados em uso, torna-se muito difícil para um ator não autorizado, mesmo que tenham acesso físico ao hardware, privilégios de root ou direitos de admin no hipervisor, obter acesso à aplicação protegida e aos dados. O paradigma de computação confidencial tem como objetivo permitir a remoção até mesmo do provedor de nuvem da base de computação confiável. Dessa forma, apenas o hardware e a própria aplicação protegida estão dentro do limite de ataque.\n\nEsses ambientes de computação permitem aos CSPs aproveitar o melhor do que o hardware pode oferecer e a melhor segurança possível, sobre a qual o usuário final tem controle absoluto. Cada parte pode determinar suas próprias políticas e as hierarquias de políticas, como estaduais e federais, e cada provedor de informação pode determinar quais políticas se aplicam e a quem.\n\n## Estudo clínico de Evidências do Mundo Real\n\nReunir todos os dados e dar sentido a eles é um grande desafio na indústria da saúde. O número de configurações de privacidade e compartilhamento de dados que existem entre os diferentes provedores, dispositivos, localizações geográficas, etc., torna isso atualmente impossível.\n\nA AI-Vets, a Intel e alguns parceiros estão trabalhando juntos nesse problema. A arquitetura brilhantemente simples permite o uso em diferentes ambientes, tipos de dados e políticas, mas é capaz de realizar análises centralizadas.\n\nUm exemplo da nossa implementação é uma pequena prova de conceito: Como você analisa através de várias partes, como hospitais, ambientes de pesquisa e laboratórios, cada um com seus próprios dados e estudos que podem estar acontecendo em um ambiente clínico? Por exemplo, como podemos encontrar qualquer correlação entre pessoas que tomam o medicamento X, digamos para diabetes, e têm a condição Y, digamos câncer, quando o medicamento X não tem nada a ver com o tratamento da condição Y? Esses dois conjuntos de dados não estariam no mesmo lugar, pois são tratados por provedores diferentes.\n\nSe, no entanto, os provedores fizessem parte de um ecossistema onde pudessem determinar quais políticas desejam aplicar em seu ponto final, poderíamos ter um aplicativo centralizado, um portal central de pesquisa, que tem conexões com esses pontos finais. Haveria gerenciamento de chaves e atestação de terceiros para verificar as credenciais e autorizações um do outro, para que todas as partes possam confiar umas nas outras.\n\nEsse é um aspecto da confiança, mas também precisamos proteger os dados que serão extraídos, consultados e transmitidos. Para isso, podemos gerenciar dados e aplicativos dentro de enclaves seguros e criptografados. Os dados são manipulados de acordo com as políticas estabelecidas por cada usuário, como a obfuscação de datas de nascimento, números de seguro social, etc. Essas informações podem ser tokenizadas, transformando-se em completo lixo nas mãos não autorizadas.\n\nO portal central pode realizar uma consulta que abrange vários pontos de extremidade e combina diferentes tipos de dados em seu sistema em tempo de execução, fazendo uma análise sobre isso. Portanto, em vez de ter que trazer tudo para um repositório de dados e depois fazer a análise, isso é feito em tempo real. Não há espera para que os dados sejam publicados ou limpos primeiro, aplicando todas essas políticas; isso acontece de forma dinâmica e instantânea.\n\nIsso permite insights tremendos. Durante a pandemia, por exemplo, se tivéssemos que esperar todos os dias para obter os dados e realizar análises complexas, seria difícil. Se fôssemos capazes de utilizar dados em tempo real de todos esses diferentes sistemas em todo o país e ao redor do mundo, mas ainda assim compartilhá-los de forma segura, poderíamos chegar a insights únicos que não seriam possíveis de outra forma.\n\nJá vimos isso em alguns testes de conceito (POCs) para sites de clínicas que fizemos com nosso parceiro Fortanix. Eles possuem uma linha de produtos que facilita para diferentes entidades definirem suas políticas em um ambiente de computação confidencial, verificar as identidades umas das outras e gerenciar chaves e confianças. O conceito de ambientes de execução confiáveis existe há algum tempo e se tornou popular, tornando mais fácil aproveitar. Os casos de uso para isso são fantásticos.\n\n## Detecção automatizada de COVID-19 a partir de imagens de raio-x do tórax.\n\nEm alguns casos de uso, não se trata apenas dos dados que precisam ser seguros, mas também da propriedade intelectual associada a alguns algoritmos especializados. Por exemplo, para detectar automaticamente a COVID em imagens de raio-X, podem existir dados radiológicos, dados do paciente e também um algoritmo proprietário para realizar a análise. As regiões confidenciais podem proteger tanto os dados quanto as aplicações de olhares curiosos.\n\nA área segura também protege as outras máquinas na rede, porque se alguém empurrasse algo malicioso para os nós finais, o sistema de gerenciamento de chaves impediria que fosse trocado, pois não está corretamente atestado. As partes escolhem exatamente quais fontes de dados a área segura pode se comunicar e ela está bloqueada, tanto para o que entra quanto para o que sai.\n\n## Registros Eletrônicos de Saúde (eHR)\n\nOs registros de saúde são uma bagunça enorme nos Estados Unidos, com acordos HIPAA em papel não aplicáveis, etc., e tudo espalhado por diferentes entidades. Um caso de uso que pode ser um bom modelo para nós seguir é do governo alemão. Eles fizeram uma determinação de que os dados de cuidados de saúde devem ser armazenados em registros eletrônicos de saúde e essas aplicações devem ser implantadas em ambientes de execução confiáveis. O paciente é o usuário final e determina quais dados estão disponíveis e para quem.\n\nEsse nível de granularidade em termos do que está disponível para o usuário final é tremendo. E não somente todos esses dados são coletados e compartilhados pelos diferentes sistemas, eles estão em áreas seguras, completamente protegidos do mundo exterior. Se alguém não autorizado tiver acesso aos dados, eles seriam completamente sem sentido.\n\nEstes ambientes de execução confiáveis são o primeiro passo na direção de controles que são facilmente compreensíveis e facilmente aplicáveis.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Nick Bhadange"],"link":"/episode-EDT40-pt","image":"./episodes/edt-40/pt/thumbnail.png","lang":"pt","summary":"Supere as barreiras para acelerar a pesquisa médica para a cura do câncer com a computação confidencial. Nick Bhadange, Especialista em Tecnologia, AI-Vets e Darren Pulsipher, Arquiteto Principal de Soluções, Setor Público, Intel, discutem a necessidade de computação confidencial na área da saúde e os benefícios potenciais por meio de casos de uso."},{"id":112,"type":"Episode","title":"A Arte Negra de DevOps","tags":["devops","people","technology","compute","devsecops","cybersecurity","multicloud"],"body":"\r\n\r\nVamos dar uma olhada em como o DevOps se encaixa na sua infraestrutura.\n\nNo fundo de uma pilha normal, temos uma camada física que pode significar uma nuvem, centro de dados, dispositivos IOT ou infraestrutura legada.\n\nAlém disso, geralmente há uma infraestrutura definida por software que abstrai a complexidade de gerenciar as peças individuais de hardware.\n\nA seguir está uma camada de gerenciamento de serviços, que inclui a virtualização do ecossistema de contêineres, bem como uma camada de gerenciamento de informações distribuídas, que inclui a infraestrutura de dados, lagos de dados e tudo o que gerencia seus dados.\n\nEm seguida vem a camada de aplicação. Os desenvolvedores de aplicativo utilizam os serviços dentro das camadas de aplicação. Logo na interface entre a camada de aplicação e o plano de gerenciamento de dados e gerenciamento de serviços estão as ferramentas SecDevOps ou DevOps. Essas ferramentas incluem aspectos de segurança e identidade que proporcionam uma forma segura de integrar e implantar continuamente seus produtos.\n\n## Camada de Aplicação / Carga de Trabalho\n\nNo topo da camada de aplicação e carga de trabalho que alimenta o SecDevOps, existem três tipos de carga de trabalho: cargas de trabalho dependentes de eventos, cargas de trabalho procedurais e uma combinação dos dois, que são cargas de trabalho guiadas por GUI ou UI.\n\nUm exemplo simples de carga de trabalho orientada a eventos seria quando um pedido de compra chega ao seu sistema, causando outras ações. Pode haver etapas sequenciais ou paralelas, interação com seres humanos, automação e interação com diversas aplicações ou subsistemas dentro da empresa.\n\nMuitas ferramentas de automação de carga de trabalho estão disponíveis. Algumas são scriptadas e outras usam automação de processos robóticos, que são mais orientadas por GUI (Interface Gráfica do Usuário) e IU (Interface do Usuário). Essas ferramentas trabalham na automatização dos serviços subjacentes, então as cargas de trabalho direcionam a interação do serviço.\n\nOs serviços tradicionalmente se enquadram em três principais categorias: aplicações, como produtos prontos para uso como o Word ou um aplicativo SAP; serviços complexos, que são projetados para um propósito específico, como uma pilha MEAN com Mongo; e serviços simples, que executam apenas uma função, como o MongoDB, que armazena o banco de dados.\n\nHá uma nova categoria devido ao crescimento de IA e ML. Muitos serviços não fazem muito sem um modelo associado, então adicionamos modelos de IA à camada de serviço, que tratamos da mesma forma que um serviço simples.\n\n## Dia do Desenvolvedor na Vida\n\nDepois de compreendermos as cargas de trabalho e os serviços, podemos analisar o que um desenvolvedor normalmente faz.\n\nUm desenvolvedor escreverá algum código em sua estação de trabalho e executará alguns testes de funcionalidade. Em seguida, ele verificará o código no GitHub, por exemplo, e um pipeline de integração contínua e entrega contínua (CICD) será iniciado. Ele executa verificações de segurança no código, talvez lintagem, análise estática e análise dinâmica.\n\nUma vez que passa por esses testes, geralmente é verificado em um ramo de integração onde outras pessoas da equipe de desenvolvimento pegam os dados, os desenvolvem e integram seu código com o código do desenvolvedor. Em seguida, quando passa pelos testes deles, é enviado para uma etapa de teste. Uma vez concluída essa etapa, será colocado em produção.\n\nEste é um pipeline de CICD típico, que existe há décadas. Ao longo dos anos, as diferentes formas de descrever pipelines foram consolidadas e padronizadas, limitando complexidades e erros.\n\n## Pilha DevSecOps\n\nO pipeline é apenas um elemento de um conjunto SecDevOps.\n\nOutros elementos necessários incluem um registro e um repositório. Pense neles como repositórios versionados para armazenar artefatos gerados durante o pipeline de CI/CD, de modo que eles estejam facilmente disponíveis para serem usados repetidamente.\n\nOutro elemento importante é um framework de automação. Isso ajuda a aliviar o trabalho humano de executar tarefas como verificações de segurança ou promover compilações de uma etapa para outra. As ferramentas de automação são maduras e treinamento está disponível, então um bom framework de automação deve ser fundamental.\n\nEmbora a gestão do ambiente geralmente evolua organicamente ao longo do tempo, faz sentido gerenciar e projetar os ambientes adequadamente para obter mais confiabilidade e repetibilidade.\n\nUm elemento fundamental por trás de tudo isso é um perfil de segurança. Você deve ter a capacidade de definir perfis de segurança, para que possam ser usados em vários ambientes e em várias pilhas de aplicativos.\n\n## Registos / Repositórios\n\nNormalmente existem pelo menos dois tipos diferentes de repositórios. O primeiro é um repositório de estágio, onde você pode gerar imagens (um conjunto de todo o código necessário para criar um contêiner, por exemplo) e armazenar coisas como chaves de identidade e segredos. Este repositório contém tudo o que você precisa para mover as coisas para produção. Algumas organizações podem ter vários repositórios de estágio, conforme diferentes elementos passam por diferentes estágios de maturidade até chegarem ao repositório de produção. Você deseja poder voltar a versões anteriores, se necessário.\n\nNa produção, ou repositório dourado, as imagens são bloqueadas, notarizadas e criptografadas. Apenas coisas no repositório dourado são movidas para produção.\n\n## Etapas\n\nA melhor forma de pensar nas etapas do pipeline CICD é que cada etapa funciona em um único ambiente. Por exemplo, em uma etapa de construção, há um ambiente de construção isolado com políticas. Somente quando todas as etapas dessa etapa forem concluídas, as coisas podem avançar para a próxima etapa. Isso evita o consumo excessivo de recursos com construções paralelas e execuções que podem acabar falhando. Ao mesmo tempo, é melhor não ter tantas etapas que atrapalhem o progresso, portanto um plano cuidadoso e definido é importante.\n\n## Passos\n\nDentro das etapas estão os passos onde o trabalho realmente é realizado. Ao criar e testar software, os passos podem ser executados em paralelo ou sequencialmente; existem muitas ferramentas que permitem definir essas operações. Embora algumas tenham uma interface gráfica para isso, a maioria dos desenvolvedores prefere um formato textual, pois isso permite o controle de versão do fluxo de trabalho e dos passos, permitindo verificações de segurança no fluxo de trabalho.\n\n## O seguinte é traduzido para o português: Pipeline\n\nCom etapas e etapas definidas, você tem um pipeline real. Em vez de definir um pipeline para todas as suas aplicações, o que normalmente falha porque se torna excessivamente complexo com muitas condições ou muito restritivo, eu recomendo usar pipelines de modelo e modificá-los conforme necessário, garantindo que eles estejam em conformidade com padrões e regulamentações. Estabelecer um pipeline adequado no início de um projeto é importante, assim como a flexibilidade à medida que o projeto avança.\n\n## Ambientes.\n\nEm vez de criar ambientes improvisados, é melhor criá-los com intenção desde o início. O DevOps ou SecDevOps pode injetar políticas de segurança e conformidade em todos os projetos diferentes, garantindo assim a segurança.\n\n## Service Stack: Pilha de Serviços\n\nVamos analisar como os desenvolvedores trabalham, o que está nos serviços hoje em dia. Mesmo que os desenvolvedores estejam trabalhando em uma aplicação monolítica, eles tendem a agrupar seu trabalho em unidades funcionais, como bancos de dados, nós de lógica de negócios ou camadas de transporte. Por exemplo, usando um serviço simples como o MongoDB. Quando um desenvolvedor executa esse contêiner em seu laptop, ele fornece a funcionalidade esperada para armazenar dados de forma não SQL em um documento. No laptop, pode ser o único contêiner em execução.\n\nEm um ambiente de teste ou desenvolvimento, pode haver várias instâncias desse serviço em execução, e o desenvolvedor pode implantar um cluster de serviços MongoDB e conectá-los para teste. O serviço ainda é um serviço do Mongo DB, mas seu comportamento muda com base no ambiente em que está. O objetivo dos desenvolvedores é escrever código e verificá-lo no serviço MongoDB de seus laptops para garantir que ele será executado corretamente na produção.\n\nUm serviço simples como o MongoDB é necessário, mas por si só, não é muito útil. Serviços complexos como pilhas LAMP ou pilhas MEAN são mais importantes. Estes são vários serviços que funcionam juntos, atuando basicamente como um único serviço. Ao serem agrupados, isso implanta um serviço complexo em um laptop e existem dois ou três contêineres de serviço simples em execução, fornecendo aos desenvolvedores a funcionalidade necessária para fazer o check-in de seu código.\n\nDepois que o código é verificado, ele se inicia no pipeline de desenvolvimento, onde o desenvolvedor está integrando com outras pessoas. O mesmo serviço complexo pode adotar uma maneira completamente diferente de fazer as coisas. Muitas políticas de segurança podem ser atribuídas a esse serviço complexo para ajudar a garantir que seja seguro, confiável e resiliente.\n\n## Definições de Serviço/Aplicação\n\nÉ importante entender os conceitos de serviços simples e complexos porque os desenvolvedores de software precisam definir como fazê-los funcionar. Existem algumas definições. Uma delas é chamada de definição de imagem. Elas são frequentemente no mundo do container, chamadas de imagens Docker. O arquivo Docker define o que há nessa imagem. Isso é considerado um contêiner simples por si só, embora as pessoas estejam começando a usar contêineres para coisas complexas.\n\nDentro das definições de serviço, podemos incluir várias definições de imagem, como por exemplo, Docker Compose, Kubernetes Operators, Helm Charts, Terraform e até mesmo CNAB. Essas são ferramentas que permitem definir um serviço. Um serviço é mais do que apenas o contêiner; é o ambiente no qual o contêiner está sendo executado. Pode incluir definições de rede, conectividade de volume ou até mesmo políticas de implantação. Uma \"definição de serviço\" completa possui definições de imagem, configuração e provisionamento.\n\n## Colocando tudo junto\n\nQuando um desenvolvedor está criando um novo serviço, ele não apenas está desenvolvendo o código para a imagem; ele também está definindo o ambiente, ou configuração, no qual ele precisa ser executado. É aqui que o ambiente e a definição do serviço se encontram. Na execução, ele produzirá o ambiente necessário para que o contêiner seja executado de forma eficiente e repetível, para que você possa mover facilmente o código de execução em uma área de trabalho para execução em produção completa o mais rápido possível.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT41-pt","image":"./episodes/edt-41/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Setor Público, Intel, define termos comuns de DevOps e explica onde o DevOps se encaixa em sua organização."},{"id":113,"type":"Episode","title":"Garantindo o Pipeline de DevOps = SecDevOps","tags":["cybersecurity","devops","compute","process","technology","multicloud","devsecops"],"body":"\r\n\r\nUm estudo realizado há mais de 20 anos sobre o retorno do investimento em segurança demonstrou que quanto mais cedo a segurança for incorporada ao ciclo de desenvolvimento, mais barato é em comparação com esperar até o final do ciclo. Apesar de sabermos disso há duas décadas, ainda é um trabalho em andamento.\n\nA maioria das empresas de desenvolvimento têm a segurança como parte do seu processo geral de desenvolvimento, por isso tem havido muitos avanços, mas é uma jornada, não uma corrida. Trata-se de compreender todos os diferentes pontos de exposição e fraquezas e ser capaz de fornecer os processos de segurança adequados para esses problemas.\n\n## Os Vetores de Ataque\n\nMuitas vezes, as pessoas pensam em ataques como vulnerabilidades dos funcionários ou pacotes, por exemplo, e esquecem a parte do processo da história. No lado operacional, está o tempo que leva para fechar uma vulnerabilidade. Do outro lado está o desenvolvimento e entrega de produtos. Existem vários pontos de ruptura ao longo dessa cadeia, os quais têm sido explorados recentemente nas últimas etapas do processo de construção. No que diz respeito aos clientes, o código que foi atualizado era legítimo porque veio diretamente da fonte. Portanto, precisamos pensar cuidadosamente onde colocar a segurança no processo.\n\n## Segurança Incorporada...\n\nÁgil, CI/CD, DevOps... Onde está a segurança?\n\nEmbora tendamos a buscar segurança nas transições do desenvolvedor para QA e de QA para operações ou implantação, a segurança deveria ser realmente inserida em todo o ciclo de construção, não apenas em alguns pontos de verificação. A abordagem deveria ser segurança contínua.\n\n## Segurança Incorporada…\n\nFaça da segurança parte de cada fase\n\nA segurança contínua é desafiadora. A maioria dos desenvolvedores e QA não possui treinamento em segurança; esta é uma batalha difícil. A indústria tentou essa abordagem no início dos anos 2000, mas encontrou três problemas. Primeiro, a rotatividade é muito alta. Segundo, o panorama da segurança muda muito rapidamente para mantê-los atualizados, e terceiro, como não é sua tarefa diária, o comportamento adequado não foi incentivado.\n\nComo, então, integrar a segurança ao processo, automatizar as principais tarefas que queremos fazer e deixar os desenvolvedores livres para desempenhar suas funções, que é construir, testar e implantar o código? O processo de segurança realmente se destaca ao integrá-lo às automações já existentes no DevOps, como testes unitários automatizados, testes automatizados de qualidade e regressão, construção automatizada e implantação automatizada. Isso não resolverá todos os problemas, mas elevará significativamente o nível, permitindo que você se concentre nos desafios mais difíceis relacionados à segurança.\n\n## Segurança Incorporada....\n\nSignifica que a segurança está incorporada, não é um único passo ou estágio.\n\nAlgumas ferramentas comuns já fornecem segurança automatizada que aponta vulnerabilidades. Por exemplo, o GitHub executará verificações de segurança em projetos usando código Node.js e todos os pacotes incluídos. Isso pode ser útil, mas é tarde demais; a segurança deve estar incorporada ao pipeline antes de ser verificada.\n\n## Segurança integrada...?\n\n## Como podemos chegar lá?\n\nAs violações de segurança atuais destacam que a segurança deve ser inserida em cada etapa do processo, incluindo entre a construção e a produção, e logo antes da execução do script para construir o aplicativo. Além de inserir segurança no processo de construção, precisamos proteger o próprio processo de construção; tem sido uma brecha enorme por um longo tempo.\n\nMuitas empresas que fazem desenvolvimento interno estão agora analisando mais de perto seu processo de construção por causa das recentes violações. Isso é bom, mas não pode parar com essas reações impulsivas a cada ataque. Precisamos pensar de forma holística e não esperar pelo próximo elo fraco na cadeia.\n\nAlgumas maneiras práticas de garantir a segurança do processo são tratar o servidor de construção como um ativo crítico na infraestrutura geral e aplicar as mesmas regras e controles a esse servidor como você faria para seus sistemas principais. Credenciais adequadas, inicialização segura do firmware, verificação de código, auditoria e registro do sistema, etc... durante toda sua vida, então construindo no processo de DevOps quando alguém clica no botão.\n\n## Construído para Durar\n\n## Das Soluções para os Serviços e Além\n\nMuitas pessoas não consideram o próprio script como um alvo. Não importa quantos bons módulos estejam incluídos se o script em si não estiver protegido. Algumas maneiras de proteger o script é executar um checksum e ele deve ser versionado, verificado e assinado. Isso adiciona complexidade para a equipe de DevOps, mas há ferramentas que podem ajudar.\n\n## Construa uma vez, implemente em todos os lugares.\n\nAssim como automatizamos o processo de desenvolvimento, podemos incluir a automação para implementar esses controles e verificações. A automação impede que outra pessoa potencialmente interfira em suas construções, mas também queremos garantir que um humano esteja recebendo os resultados e verificando auditorias.\n\nAs ferramentas que você já está usando podem ser ampliadas para adicionar automação de segurança e verificações, como aquelas para realizar integração contínua no ciclo ágil de desenvolvimento, ou ferramentas de automação no mundo Linux.\n\nAs organizações também podem distribuir seus profissionais de segurança entre as equipes de desenvolvimento de negócios, para que, quando algo der errado, os profissionais de segurança já estejam inseridos no processo. Dois locais onde você deseja garantir a presença de profissionais de segurança são na infraestrutura de suporte, por exemplo, para o seu processo Ágil, e na gestão de produtos, para obter requisitos de segurança durante a fase de definição dos requisitos do produto, antes mesmo de chegar aos desenvolvedores.\n\nSempre há escassez de pessoas de segurança treinadas e capacitadas o suficiente e também falta de financiamento para contratar as pessoas certas devido à alta demanda. Algumas opções são treinar as pessoas que você já tem e fornecer as ferramentas necessárias. Não é preciso ter um especialista em criptografia em cada etapa do processo. Outra possibilidade é, em vez de fazer com que cada programador seja responsável pela codificação de autenticação, credenciais e protocolos em uma construção segura em uma biblioteca de infraestrutura, ter uma equipe construir módulos em suas linguagens e ambientes que realizem todas as funções de segurança. O programador pode usar o módulo e ele cuidará do trabalho difícil. Dessa forma, você constrói uma vez e implanta em todos os lugares.\n\nEstamos vendo empresas fornecerem ferramentas de segurança SaaS, serviços baseados em nuvem que podem ser consumidos para sua aplicação e seu ambiente de execução. Isso é um grande avanço no processo. Existem empresas que fornecem pontos de injeção de segurança, como segurança de aplicativos em um ambiente de estilo rápido. Essas verificações de aplicativos, como higienização de entrada e validação de entrada, podem ser incorporadas ao seu ambiente de funcionalismo, mas isso ainda está esperando até o final. Lembre-se de que quanto mais cedo você começar a segurança no processo, mais barato e menos doloroso será.\n\nTudo isso, é claro, requer mais trabalho de integração. Os desenvolvedores podem ficar cautelosos com o trabalho envolvido, mas se existir um framework com segurança incorporada (e existem protótipos como o Ruby on Rails e certas infraestruturas de nuvem), ele pode economizar muitas horas. No entanto, você ainda precisa garantir que não dependa apenas da plataforma para a segurança, pois ela pode ser um ponto único de falha.\n\n## Automatização te libertará.\n\nAs violações de segurança nos últimos seis meses têm sido profundas. Aqui estão alguns pontos-chave de conselho:\n\nA segurança deve ser integral em todo o ciclo de vida, desde os requisitos em diante. A segurança deve estar presente no próprio ciclo DevOps, não apenas na codificação e no teste, mas também na infraestrutura que impulsiona esse processo.\n\nQuando construir ferramentas de segurança e objetos por meio de módulos, construa uma vez, torne modular e implante em todos os lugares.\n\nAproveite serviços que permitem que você conte com a experiência de outra pessoa para complementar sua própria equipe cibernética com poucos recursos.\n\nA automação te libertará. Automatize o máximo possível para tornar a segurança mais fácil e rápida e reduzir o atrito para seus desenvolvedores e testadores. Com a automação, você pode eliminar 80 por cento do que chamamos de coisas bobas, para que possa gastar seus recursos limitados com os problemas difíceis.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT42-pt","image":"./episodes/edt-42/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto de Soluções Chefe na Intel, e Steve Orrin, CTO da Intel Federal, discutem por que e como o pipeline DevOps deve ser protegido. A única maneira de fornecer código sólido, resiliente e seguro é se a segurança estiver incorporada, e quanto mais cedo melhor."},{"id":114,"type":"Episode","title":"O papel do CIO na adoção da nuvem","tags":["cio","cloudadoption","compute","cloud","csp","multicloud"],"body":"\r\n\r\nNa primeira parte desta entrevista, Darren Pulsipher, Arquiteto Chefe de Soluções, Intel, e Doug Bourgeois, Diretor Gerente, Líder de Estratégia de Nuvem da GPS, Deloitte, falam sobre a migração para a nuvem e o papel do CIO.\n\n## CIO Heritage  - Patrimônio do CIO\n\nDoug se envolveu com a nuvem desde cedo, quando trabalhava para o governo federal administrando uma grande organização de serviços compartilhados. Ele reconheceu os benefícios da nuvem para suas organizações provedoras de serviços e também percebeu o valor para sua própria organização. Primeiramente, isso economizaria dinheiro no nível da infraestrutura e, em segundo lugar, era uma oportunidade para construir nuvem enquanto virtualizava para ajudar com o problema de expansão dos servidores. Para um serviço específico, o corte de custo para o usuário final foi de 40 por cento.\n\nNos serviços compartilhados, como a nuvem, uma vez que você atinge economias de escala, você pode fornecer os serviços de forma mais econômica do que a maioria das organizações pode fazer por si só.\n\n## A Transição para a Nuvem\n\nUma dúzia de anos atrás, as organizações, em sua maioria, eram centradas em nuvem privada. Elas estavam melhorando seus centros de dados para incorporar uma combinação de locatário múltiplo consolidado, juntamente com algumas capacidades de automação integradas. O pêndulo mudou cerca de três ou quatro anos depois para a nuvem pública com os grandes fornecedores de escala hiper (AWS, Azure, Google).\n\nCerca de três anos atrás, as organizações migraram para um equilíbrio na nuvem híbrida. As pessoas perceberam que uma ampla variedade de sistemas em seu portfólio se adequam a diferentes modelos, alguns privados, alguns públicos, alguns híbridos. No geral, hoje em dia há uma abordagem mais holística para combinar sistemas e nuvens com propósitos específicos.\n\n## Colocando a informação no CIO\n\nÉ agora mais importante do que nunca que os CIOs tenham um conhecimento profundo do que está acontecendo em suas organizações, se aproximando da missão e metas comerciais para atender melhor às suas necessidades. Enquanto antes, um CIO poderia apenas fornecer infraestrutura, agora eles precisam tomar decisões arquitetônicas educadas com base no que está disponível. Existem duas razões para isso. A primeira é a proliferação de dados, inteligência artificial, análises e aprendizado de máquina nas capacidades centrais do negócio, que requerem um entendimento fundamental do negócio. A segunda é a evolução da nuvem que alcançou uma nova fase, a era digital, onde os sistemas centrais da organização devem ser modernizados para melhorar a capacidade de serviço para seus usuários finais.\n\nEssa jornada começou a deslocar o CIO de volta ao lugar onde eles pertencem, na gestão da informação, em vez de se concentrarem tanto na infraestrutura. Muitos CIOs foram relegados à caixa da infraestrutura, quando poderiam ter a oportunidade de realizar algo verdadeiramente transformador.\n\n## Posicionamento do CIO para o sucesso\n\nEntão, como é a jornada de Chief Infrastructure Officer para Chief Information Officer?\n\nUma maneira é se posicionar para ser responsável por algo novo que a organização está tentando fazer, talvez um novo processo ou entrar em um novo mercado, ou até mesmo uma unidade de negócios que ainda não foi inaugurada. Você tem continuidade e perspectiva, pois já trabalhou com todos os proprietários de aplicativos diferentes, e, portanto, está qualificado de forma única para tomar a iniciativa. Outra maneira, mais comum, é através de um evento negativo, onde fica claro que a mudança é necessária. Um desastre pode ser o catalisador para um CIO liderar o caminho para uma verdadeira transformação.\n\nJunte-se a nós para a parte 2 da entrevista....\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Doug Bourgeois"],"link":"/episode-EDT43-pt","image":"./episodes/edt-43/pt/thumbnail.png","lang":"pt","summary":"Na primeira parte desta entrevista, Darren Pulsipher, Arquiteto Principal de Soluções, Intel, e Doug Bourgeois, Diretor Executivo, Líder da Estratégia de Nuvem GPS, Deloitte, falam sobre a migração para nuvem e o papel do CIO."},{"id":115,"type":"Episode","title":"Nuvem na Era Digital","tags":["cloudmigration","cloud","compute","process","deloitte","multicloud"],"body":"\r\n\r\n## A Jornada Típica de Migração para a Nuvem para uma Organização.\r\n\r\nNos últimos cinco ou seis anos, as metodologias, ferramentas e experiência em migração para a nuvem amadureceram para processos repetíveis.\r\n\r\nO primeiro passo é decidir sobre suas prioridades de migração porque isso vai acontecer em fases, não em uma mudança grande. Isso não requer muito tempo ou recursos, mas é extremamente importante. Um exemplo extremo seria você não querer escolher o mainframe como o primeiro sistema a ser movido para a nuvem, mas sim um sistema mais autônomo como o e-mail.\r\n\r\nEmpresas como a Deloitte desenvolveram e investiram em ferramentas de descoberta que ajudam a acelerar os processos de migração. Essas ferramentas irão capturar um conjunto amplo de dados, executar um algoritmo que analisa a complexidade e classificar todos os sistemas em diferentes categorias. Compreender a configuração e os pontos de integração dos sistemas existentes e a compatibilidade dos componentes de software é fundamental para a migração para a nuvem. Também é necessário analisar limites e estruturas de conformidade, como PCI ou HIPAA. A construção de zonas de aterrissagem para esses ambientes na nuvem é a segunda fase do processo.\r\n\r\n## Proposta de Valor da Modernização Digital\r\n\r\nÀs vezes, há uma quantidade substancial de trabalho preliminar para as migrações. A primeira onda é a mais fácil, com a menor quantidade de modificações, mas após isso, na fase dois, pode haver atualizações ou mudanças nos sistemas operacionais, de plataforma, ou migração para tipos diferentes de bancos de dados, por exemplo. A terceira onda muitas vezes envolve servidores de clientes antiquados ou arquiteturas proprietárias que exigem uma re-arquitetura significativa e podem levar meses para se preparar para a prontidão na nuvem.\r\n\r\n## Modernização Digital e Migração para a Nuvem\r\n\r\nÉ importante distinguir que a prontidão para a nuvem não é o mesmo que otimização da nuvem; isso vem depois.\r\n\r\nEm muitos casos, a força motriz por trás da mudança para a nuvem é impulsionada pelos negócios, em vez de ser impulsionada pela tecnologia. Por exemplo, um cliente pode não querer continuar com um contrato de locação apenas para abrigar um centro de dados, ou pode estar mudando de local físico de escritório. Nestes casos, há um fator de tempo em que faz sentido executar a migração com base na prontidão, em vez de otimização.\r\n\r\nUma vez na nuvem, você precisa otimizar, pois os fatores de custo são diferentes na nuvem do que no centro de dados legado. O custo de um centro de dados, após o investimento inicial, é relativamente oculto, enquanto a nuvem é mais um acordo de aluguel que continua perpetuamente. Muitas vezes, nos sistemas legados, resolvemos problemas adicionando mais memória, mais CPU ou mais armazenamento, porque funciona até certo ponto, mas isso cria sistemas ineficientes. Se simplesmente movermos esses sistemas ineficientes e intensivos em recursos para a nuvem, o modelo de custo será muito mais alto do que deveria ser, daí a necessidade de otimização.\r\n\r\nAlgumas das etapas de otimização podem implicar em uma mudança de processos. Por exemplo, para uma organização no Canadá, seus custos dispararam quando eles transferiram uma instância do SAP para a nuvem. Eles perceberam que não estavam utilizando essa instância durante a noite ou nos fins de semana, então eles mudaram de um modelo 24/7 para um modelo 16/5. Essa mudança resultou em uma economia substancial de dinheiro. Portanto, existem maneiras de obter um retorno de alto valor com um pequeno esforço e diferentes abordagens.\r\n\r\nEstamos finalmente vendo, depois de mais de uma década na nuvem, uma tendência emergente de encontrar valor em uma mudança na estratégia de negócios ao invés de na infraestrutura. A pandemia de COVID-19 certamente foi um fator acelerador dessa mudança. Um exemplo perfeito disso é a telemedicina. Ela já existia, mas estava estagnada há cinco ou seis anos antes da pandemia; agora esse modelo é a norma.\r\n\r\nInovações transformadoras estão acontecendo na nuvem. À medida que mais sistemas se movem para a nuvem, as indústrias continuarão a experimentar e adotar diferentes modelos com novas capacidades transformadoras.\r\n\r\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Doug Bourgeois"],"link":"/episode-EDT44-pt","image":"./episodes/edt-44/pt/thumbnail.png","lang":"pt","summary":"Na segunda parte da entrevista, Darren Pulsipher, Arquiteto Chefe de Soluções da Intel, e Doug Bourgeois, Diretor Gerente e Líder de Estratégia em Nuvem da GPS da Deloitte, continuam sua discussão sobre a migração para a nuvem."},{"id":116,"type":"Episode","title":"Nem todos os núcleos são iguais","tags":["multicloud","compute","optimization","workloadplacement","workload","migration","process","cloudinstance"],"body":"\r\n\r\nA Intel tem contratado arquitetos de soluções em nuvem para ajudar os clientes a migrarem de forma inteligente para as instâncias de nuvem certas para suas cargas de trabalho. Stephen recentemente entrou para a Intel e possui uma longa experiência em bancos de dados em geral, com os últimos sete ou oito anos focados na nuvem, aproveitando seus recursos para os clientes.\n\nAlguns dos aspectos mais difíceis com os quais o Stephen se deparou ao ajudar os clientes a migrarem para a nuvem são os preços e as expectativas da mudança. Fornecedores de serviços em nuvem frequentemente afirmam que os clientes economizarão dinheiro ao migrarem para a nuvem, mas isso nem sempre é verdade.\n\nUma razão é que há uma mudança constante no mercado de provedores de serviços em nuvem em relação a recursos, funcionalidades e habilidades. Outra razão é a ignorância, por exemplo, acreditar que um VCP central é o mesmo em todos os lugares. Migrar com a mentalidade de \"levantar e transferir\" também pode ser muito caro. A otimização é fundamental para uma migração inteligente para a nuvem.\n\nPara diminuir os custos e potencialmente economizar uma grande quantidade de dinheiro, você deve escolher as instâncias certas para as performances certas. Nem todos os núcleos, ou CPUs virtuais, são iguais. Dentro da AWS, eles têm o M4, o Broadwell da Intel e o M5, que é uma mistura de Cascade Lake e Skylake, e várias cargas de trabalho podem se beneficiar dessas plataformas de maneiras muito diferentes.\n\n## Desempenho do CoreMark\n\nO CoreMark é um aplicativo de única execução que testa movimentos de registros e somas simples para qualquer número de CPUs. Ao longo de três gerações de processadores Intel, Broadwell, Skylake e Cascade Lake, este teste mostra pouca diferença entre eles. Essa informação tem sido usada erroneamente para orientar as decisões dos clientes, pois o teste não é uma forma eficaz de medir as diferenças nos próprios processos. Pode haver diferenças enormes no desempenho com cargas de trabalho diferentes.\n\n## Banco de Dados de Desempenho WL\n\nStephen realizou testes digitais em cargas de trabalho reais, concentrando-se em bancos de dados de código aberto. O ambiente Cascade Lake foi três vezes melhor do que o ambiente Broadwell para código aberto, o que faz sentido dado os avanços em velocidade e no acesso de baixa latência das melhorias incorporadas no chip. Portanto, subir duas gerações resulta em um desempenho duas a três vezes melhor nessas cargas de trabalho.\n\nA carga de trabalho e o núcleo devem ser considerados juntos. Por exemplo, um cliente pode ser tentado a mudar para uma VCPU que a Amazon diz que é 10% mais barata. A AWS pode, no entanto, agrupar núcleos nesses processadores e agora você está se movendo de um ambiente onde você é um dos 48 máquinas virtuais em uma caixa para um onde existem 128 máquinas virtuais; seu acesso à memória é limitado e você pode ter 60% menos desempenho para uma economia de 10%.\n\nOrganizações frequentemente acreditam que, se terceirizarem para a nuvem, elas não precisam mais de um arquiteto de sistemas. É verdade que os arquitetos não estão mais instalando fisicamente e configurando máquinas, mas agora eles o fazem virtualmente e precisam entender quais são as diferentes capacidades que as instâncias oferecem para diferentes cargas de trabalho.\n\nA Intel está trabalhando em uma ferramenta para mostrar quais cargas de trabalho funcionam melhor em quais instâncias. Enquanto isso, a Intel possui algumas diretrizes gerais e arquitetos de soluções em nuvem para ajudar a orientar os clientes.\n\nAlém disso, muitos testes são importantes para entender onde colocar as cargas de trabalho, mas também é importante testar e avaliar para validar que você está obtendo o que espera de um provedor.\n\n## Desempenho do Banco de Dados WL - Não NVMe\n\nA Intel realizou alguns testes em cargas de trabalho em instalações novas em uma instância fixa de 64 núcleos e 64 VCPU. Após obter o número inicial, outra instância foi iniciada e o mesmo teste foi executado novamente. Os resultados variaram drasticamente a cada vez do mesmo teste. Isso pode ocorrer devido a uma mistura de processos oferecidos em um determinado nível de camada, ou pode haver alguma distância e latência adicional para os anexos de armazenamento em bloco, por exemplo, ou até mesmo vizinhos ruidosos. Portanto, vale a pena testar para garantir que o sistema atenda às expectativas.\n\nEm resumo, para obter o melhor valor da nuvem, você precisa se educar, testar os sistemas e aproveitar a ajuda disponível.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steven Holt"],"link":"/episode-EDT45-pt","image":"./episodes/edt-45/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto-chefe de Soluções, Intel, e Stephen Holt, Arquiteto de Soluções em Nuvem, Intel, discutem otimização de nuvem e estudos que mostram que os núcleos têm desempenhos diferentes para várias cargas de trabalho."},{"id":117,"type":"Episode","title":"Protegendo seu Pipeline de DevOps","tags":["devops","compute","technology","process","devsecops","cybersecurity","zerotrustarchitecture"],"body":"\r\n\r\n## Os Vetores de Ataque\n\nMuitos ataques ocorrem no nível das pessoas. Alguns dos ataques mais recentes e insidiosos têm se concentrado em phishing e engenharia social em indivíduos dentro do DevOps. Precisamos treinar as pessoas melhor em todos os níveis. Em um caso, foi um estagiário com acesso às chaves que sucumbiu a um esquema nefasto.\n\nOutro vetor é a tecnologia: ataques tradicionais de negação de serviço, ataques de injeção de SQL ou ataques de estouro de buffer. Os incidentes mais recentes utilizam tanto pessoas como tecnologia para atacar o processo. Eles são insidiosos porque ocorrem durante o processo de construção e podem ser muito difíceis de detectar. Também podem propagar código malicioso para seus clientes. Para criar confiança nos clientes, as organizações devem ter uma estratégia para garantir a segurança do pipeline de suprimentos.\n\n## Segurança de dutos\n\n Nem toda a pipeline de construção é igual, mas, de forma geral, ela consiste em quatro estágios com ambientes: desenvolvimento, construção, teste e produção. Esses estágios podem ser divididos em vários estágios, dependendo do tipo de produto que você está desenvolvendo, mas os ambientes estão ligados a esses diferentes estágios.\n\nPrecisamos analisar todo o processo, que inclui software, hardware e processos, e adotar uma abordagem diferente, em vez de apenas focar na infraestrutura, como a maioria tem feito de forma eficaz.\n\n## Segurança de Hospedeiros e Infraestrutura\n\nNo fundo da pilha, é necessário garantir a segurança do hardware no ambiente de desenvolvimento e construção. O ambiente de teste será um pouco diferente porque você pode querer executar testes que envolvam a injeção de código malicioso. Os ambientes de produção geralmente são bem protegidos, especialmente agora que mais empresas estão oferecendo software como serviço. Nos ambientes de produção e construção, é necessário realizar todas as medidas de segurança típicas que você faria em ambientes de produção ou de software como serviço.\n\nExistem três elementos-chave nesses ambientes. O primeiro é a detecção. A detecção e correção é uma medida de segurança bem conhecida que utiliza registros de serviço em uma plataforma como o Splunk para encontrar qualquer coisa fora do comum. Certifique-se de fazer isso não apenas em ambientes de desenvolvimento, mas também em ambientes de construção e produção.\n\nTenha em mente que no ambiente de teste, você precisará de vários ambientes de teste, alguns mais seguros do que outros no lado de detecção, uma vez que você deseja injetar código errôneo em seus testes. Não aplique apenas a mesma segurança a todos os ambientes; os perfis de segurança podem ser diferentes para cada ambiente.\n\nA prevenção é a segunda chave. Isso significa ser inteligente com o hardware, garantir que as coisas sejam corrigidas adequadamente, ter as atualizações de segurança certas e fazê-lo de forma automatizada. Isso deve acontecer em todos os ambientes, incluindo o ambiente de testes, especialmente na construção e produção.\n\nA terceira chave faz parte da prevenção: raiz de confiança de hardware. Uma cadeia de confiança pode ser estabelecida a partir do hardware, passando pelas seções de inicialização do firmware, até os hipervisores e sistemas operacionais. A raiz de confiança pode ser levada para os ambientes de desenvolvimento, construção, teste e produção. Isso pode incluir contêineres seguros e máquinas virtuais seguras. Por exemplo, gosto de armazenar minhas chaves de criptografia e hash em hardware, como um módulo TPM, e também com a extensão Secure Guard da Intel. Mesmo que alguém acesse a máquina, eles não conseguirão roubar essas chaves.\n\n## Executáveis confiáveis.\n\nConfigurar executáveis confiáveis é o próximo passo. Isso significa que você pode executar verificações de segurança contra o código que está verificado e compilado e, em seguida, verificar o hash com essas alterações. Se algo foi injetado na base de código, você pode detectá-lo, já que não deve haver nenhuma alteração no código durante o processo de compilação.\n\nEm uma nova etapa de verificações de segurança, você pode realizar análise estática no código ou análise dinâmica no código ou violações de segurança. Existem algumas ótimas ferramentas que você pode facilmente integrar à sua típica cadeia DevOps, seja utilizando o Jenkins ou fluxos de trabalho do GitHub, por exemplo.\n\nUma vez que um executável é construído, crie o hash imediatamente, e esse hash deve ser versionado junto com o executável; ele deve permanecer o executável que passa por todos os testes e é colocado em produção. Esse hash garantirá que nada tenha sido adulterado.\n\n## Imagens comprovadas e seguras\n\nNormalmente, existem vários repositórios, ou executáveis, para usar para o código. O hash que é criado durante a compilação agora está no registro e você pode atestar isso. Você pode protegê-los nas imagens para que não possam ser modificados. Se alguém precisar voltar e fazer uma pequena alteração, digamos, em uma etiqueta ou metadados, é importante não fazer a alteração e atribuir o mesmo número de versão. É melhor passar por todo o ciclo novamente, mesmo que leve mais tempo do que ter processos manuais mexendo com seus binários.\n\nAgora, você pode pegar o mesmo arquivo binário que você executou todos os testes e enviá-lo para produção. Neste ponto, é um erro reconstruir o código-fonte. É melhor enviar a versão original para o repositório de produção, também conhecido como repositório golden. Este repositório é o único lugar de onde imagens, binários, ou Máquinas Virtuais (VMs), por exemplo, devem ser obtidos. Todas as imagens devem ser notarizadas e atestadas. Se você tiver VMs confidenciais ou aplicativos, ou quiser garantir que eles sejam executados apenas em hardware específico, pode fazer esse tipo de restrição. Você pode criptografar as VMs, contêineres, ou até mesmo binários e trancá-los com a chave armazenada em seus sistemas de construção e produção.\n\n## Injetando Ferramentas de Segurança\n\nAs ferramentas de segurança devem ser integradas ao processo de construção. Em vez de utilizar bibliotecas de segurança de código aberto ou recriar as que já existem, seus engenheiros de segurança devem se envolver para que possam escolher ferramentas que possam ser facilmente consumidas e reutilizadas pelas equipes de desenvolvimento. Um bom exemplo é a autenticação básica: login do usuário. Deve haver uma biblioteca comum em vez de cada aplicação possuir a sua própria.\n\nÉ importante tratar essas bibliotecas de segurança e ferramentas da mesma forma que você trataria qualquer outro programa de desenvolvimento de software que está compartilhando em toda a sua organização. Compartilhar irá diminuir o tempo e aumentar a segurança em todo o seu ecossistema.\n\n## Construa uma vez, implante segurança em todos os lugares.\n\nDepois de estabelecer suas equipes de segurança de desenvolvimento, certifique-se de injetar as políticas e ferramentas em todos os seus produtos e ambientes. Hoje em dia, existem excelentes tecnologias que permitem gerenciar vários ambientes. Portanto, quando uma nova aplicação é criada, ela é criada em um perfil de segurança com suas próprias imagens de VM ou containers como base que as equipes de desenvolvimento estão utilizando. Ao configurar a segurança em suas VMs ou containers nas imagens de base, você obtém conformidade de segurança instantânea em diferentes ambientes. Também é possível integrar com ferramentas de segurança, para que, se encontrar algo incomum na aplicação, possa notificar as ferramentas de segurança. Não tente criar ferramentas de segurança que abordem cem por cento dos casos, porque você nunca as terminará; vá para oitenta por cento como uma base sólida e crie-as para que os desenvolvedores de aplicativos possam inovar os vinte por cento restantes, se necessário, em conjunto com sua equipe de segurança.\n\nUm último conselho importante é automatizar tudo o que você puder, especialmente no pipeline de DevOps, para evitar injeções maliciosas. Proteja seu pipeline; proteja seu processo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT46-pt","image":"./episodes/edt-46/pt/thumbnail.png","lang":"pt","summary":"Na segunda parte deste episódio, Darren Pulsipher, Arquiteto-chefe de Soluções da Intel, dá dicas práticas para garantir a segurança de cada etapa do pipeline do DevOps, incluindo a proteção do hardware e dos pilares de software com a raiz de confiança do hardware, escaneamento de segurança, containers/VMs atestados e criptografados, e muito mais."},{"id":118,"type":"Episode","title":"A aguardar com expectativa o ano de 2021","tags":["covid","remoteworker"],"body":"\r\n\r\nGreg lidera as vendas e o marketing da Intel nos Estados Unidos. Os clientes da Intel são principalmente os fabricantes de sistemas originais (OEMs), e a equipe de vendas da Intel trabalha diariamente atendendo essas contas e ajudando-as a construir sistemas em torno das tecnologias de computação e memória da Intel. Atualmente, existe uma demanda sem precedentes por computação.\n\nAs equipes da Intel trabalham com empresas de software, provedores de nuvem, corporações Fortune 1000, escolas e agências governamentais para tornar a computação acessível e ajudar a identificar tendências e aplicar casos de uso que resolvam problemas empresariais de uma maneira que melhore a sociedade. A Intel, então, trabalha como uma criadora de tendências e identifica novas tendências para garantir que os clientes tenham os produtos certos.\n\n## COVID como um Acelerador\n\nAtualmente, as tendências estão todas relacionadas à pandemia de COVID. As organizações passaram a maior parte de 2020 em modo de crise, com a área de TI implantando tecnologia para manter os negócios em funcionamento e, em seguida, se adaptando à nova normalidade. Agora, há uma estabilização em que os departamentos de TI podem olhar para o futuro em vez de apenas responder à crise imediata.\n\nUma lição é que a área de Tecnologia da Informação pode se movimentar muito mais rápido do que nunca imaginamos. Por exemplo, é surpreendente o quão rapidamente quase todas as indústrias conseguiram adotar o trabalho remoto. No entanto, o COVID-19 serviu como um acelerador em vez de um catalisador. A maioria das mudanças já estava planejada, mas o COVID-19 comprimiu os prazos. Em vez de, digamos, um lançamento planejado de Office 365 em 18 meses, isso foi feito em uma semana e meia porque precisava ser.\n\nUma das principais razões para a rapidez das mudanças é que um CIO não poderia possivelmente tomar todas as decisões que precisavam ser tomadas durante a crise, então o processo decisório foi delegado para capacitar aqueles na linha de frente a trabalhar rapidamente e fazer o que fosse melhor para o negócio.\n\n## Modelo de trabalho híbrido\n\nUma mudança que levará algum tempo é descobrir o novo modelo de trabalho híbrido. A Intel, por exemplo, está trabalhando nas expectativas de com que frequência os funcionários devem ir ao escritório, depois que uma grande maioria passou um ano trabalhando em casa. Os departamentos de TI estão se preparando e investindo em ferramentas que permitem a colaboração com alguns funcionários no escritório e outros em casa.\n\nAs organizações podem não saber como será o seu modelo por muitos meses, por isso, os departamentos de TI devem ser flexíveis em sua abordagem.\n\n## Aplicativos e Automatização da Experiência do Funcionário\n\nProjetos online que foram deixados de lado em 2020 estão agora retornando neste novo ambiente de trabalho híbrido. Os funcionários desejam se envolver com seus negócios da mesma forma que fazem como consumidores em software como serviço. Consequentemente, muitos aplicativos estão sendo desenvolvidos em torno da experiência do funcionário.\n\nAlém disso, houve muito progresso em torno da utilização de bots. Por exemplo, a Intel acabou de lançar um bot de RH para melhorar e automatizar a experiência dos funcionários, acessando todos os serviços de Recursos Humanos. Isso leva à necessidade de mais IA e automação de IA, impulsionada pelo aprendizado de máquina.\n\n## Atendimento ao Cliente sem atrito, sem contato.\n\nMuitos dos clientes da Intel estão se preparando para serviços ao cliente sem atritos e sem contato em governos, varejo e entretenimento. Uma indústria que acelerou durante a pandemia é a de telecomunicações, o que facilitará muito essas entregas sem atritos.\n\nO investimento em capital para construir a infraestrutura de telecomunicações e 5G está dando suporte a mais dispositivos IOT e remotos agora, que, antes da pandemia, levariam anos para se concretizarem.\n\n## IA e Aprendizado Federado.\n\nA Intel tem visto um grande aumento no trabalho com IA e dados protegidos em áreas como descobertas médicas e nos mercados financeiros. Com os novos processadores Xeon de terceira geração da Intel, existem enclaves de computação seguros (SGX), memória protegida, que não pode ser acessada fora do sistema. Os casos de uso que estão sendo implementados estão relacionados a IA e aprendizado federado, onde os dados de usuários e empresas podem treinar modelos globais, mas os dados não são compartilhados em um repositório central. Com a IA, o conceito de aprendizado federado e o SGX da Intel, esses dados podem ser protegidos. Obstáculos de privacidade e regulamentação podem ser removidos para os dados. Por exemplo, os dados de um hospital ou de um paciente individual podem ser protegidos, mas ainda assim usados para treinar um modelo mais global com grandes benefícios.\n\n## RPA: Automação de Processos Robóticos\n\nMuitas empresas estão encontrando maneiras de automatizar tarefas, em alguns casos tarefas mundanas, para liberar seus funcionários para trabalhar em projetos de maior valor. Essa tendência disparou nos últimos seis a oito meses, com um grande crescimento no mercado. Nos últimos cinco anos, os mercados de RPA receberam mais de dois bilhões de dólares em financiamento de capital de risco, principalmente dos mercados financeiros da cidade de Nova York. Além do RPA, existem muitos frameworks de automação que as pessoas estão usando para implantar infraestrutura em seus centros de dados e também perfeitamente na nuvem.\n\n## Computação de Borda\n\nA Intel começou a desenvolver arquiteturas de referência para ajudar as empresas a construir suas soluções de computação de borda. A ciência importante aqui é conectar a computação de borda até a infraestrutura na nuvem, construindo tanto uma pilha de hardware e software, um painel de controle e automação. Esta é mais uma área de investimento incrível.\n\n## Avançando\n\n2020 foi um ano de caos, adaptação sem precedentes e mudanças aceleradas. Agora, em um 2021 mais estável, as empresas podem se basear nas lições e tendências resultantes.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Ernst"],"link":"/episode-EDT47-pt","image":"./episodes/edt-47/pt/thumbnail.png","lang":"pt","summary":"Greg lidera as vendas e o marketing da Intel nos Estados Unidos. Os clientes da Intel são principalmente os fabricantes de equipamentos originais (OEMs), e a equipe de vendas da Intel trabalha diariamente atendendo essas contas e ajudando-as a construir sistemas em torno das tecnologias de computação e memória da Intel. Atualmente, há uma demanda sem precedentes por computação. As equipes da Intel trabalham com empresas de software, provedores de nuvem, grandes empresas, escolas e agências governamentais para tornar a computação acessível e ajudar a identificar tendências e aplicar casos de uso que resolvam problemas de negócios de uma maneira que melhore a sociedade. Portanto, a Intel trabalha como uma grande influenciadora e identifica novas tendências para garantir que os clientes tenham os produtos certos."},{"id":119,"type":"Episode","title":"VAST Data Revisitado","tags":["dataarchitecture","data","optane","technology","vastdata"],"body":"\r\n\r\nA VAST Data tem crescido rapidamente nos últimos seis meses, com uma equipe em expansão e vendas impressionantes, como cerca de 70 petabytes de armazenamento flash para o governo federal. Além do compartilhamento geral de arquivos com seus sistemas de armazenamento totalmente flash, eles têm casos de uso interessantes em áreas como sequenciamento de próxima geração, microscopia confocal e tarefas de simulação de túnel de vento.\n\nA plataforma da empresa permite resolver problemas de leitura aleatória porque todos os dados estão em flash sem o custo exorbitante; a plataforma lida com um alto volume de dados com baixa latência.\n\n## VAST Technology e unidades Intel Optane.\n\nO VAST utiliza as unidades Optane da Intel para alcançar a paridade de leitura/escrita, entre outros benefícios. Como o Optane é uma memória persistente, não há problemas de coerência de cache e não há necessidade de DRAM, o que é uma grande vantagem arquitetônica para evitar falhas ou perda de dados. O custo total por usuário também é reduzido porque você não precisa comprar máquinas grandes com muita memória para armazenamento de arquivos se quiser mais velocidade. Essa camada é eliminada.\n\nEscalabilidade e flexibilidade são duas outras vantagens, pois você pode adicionar mais caixas de dados (D boxes) sem afetar o desempenho, e elas são completamente compatíveis inclusive com múltiplas gerações de flash. Não há um único ponto de falha, e não há limite teórico; a VAST testou até 100 petabytes.\n\nVocê pode melhorar o desempenho adicionando caixas de cliente (caixas C), independentes das caixas D. Capacidade com flash é basicamente gratuita, mas você precisa expor esse flash com CPU. As caixas C são completamente estado-finas, então você pode aumentar ou diminuir seu tamanho instantaneamente. VAST garante tempo de atividade porque você tem acesso total a cada PCP na parte de trás.\n\nDependendo das necessidades de desempenho do cliente, pode haver diferentes números de caixas D e caixas C; por exemplo, um cliente pode não precisar de mais desempenho, mas sim de mais capacidade, então o cluster pode ter, por exemplo, 11 caixas C e 37 caixas D.\n\nSe você tiver uma caixa C e uma caixa D, você terá cerca de 40 gigabytes por segundo de largura de banda, que é o modelo básico. Cada adição de uma caixa D adiciona mais 40 gigabytes de largura de banda. Uma caixa C não satura todos os IOPS, então se você adicionar outra caixa C, você pode obter 350.000 IOPS de uma caixa. Como o flash é limitado pela CPU, quanto mais CPUs você adicionar, mais permite que você aumente a escala.\n\n## Novo Modelo de Negócio de Armazenamento\n\nO novo produto da VAST Data, Gemini, permite aos clientes que precisam de alto desempenho sem muita capacidade licenciar apenas a quantidade de hardware necessária do fabricante contratado, resultando em economia de custos significativa. Os clientes podem aumentar e pagar pela capacidade conforme a necessidade, em vez de incorrer em um custo inicial para futuras necessidades de capacidade.\n\nDo ponto de vista de OPEX, isso faz sentido para muitas empresas. Por exemplo, para um cliente, um sistema totalmente em flash de 30 petabytes que faz um terabyte e meio de largura de banda, o custo é menor do que o S3 de acesso pouco frequente da Amazon. Isso é apenas para um ano; olhando para frente, na verdade é menor do que o Glacier se você olhar para a forma como a Amazon cobra, por gig por mês. E há a flexibilidade de voltar para um modelo CAPEX se isso fizer mais sentido mais tarde.\n\nÉ importante notar que a VAST está apresentando um appliance, não um armazenamento como serviço, o que pode se tornar um pesadelo de suporte devido a todas as variações de hardware e firmware, quais unidades você está dando suporte, quais interconexões, etc... resultando numa quantidade louca de complexidade. A VAST ainda está enviando as mesmas caixas e servidores; é apenas um modelo de negócio diferente que permite flexibilidade no consumo de armazenamento.\n\nAlgumas áreas interessantes onde o VAST pode ser útil é em pesquisas médicas, como patologia digital, que envolve uma quantidade astronômica de dados muitas vezes difíceis de serem acessados pelos pesquisadores porque estão em armazenamento barato e lento. A medicina de precisão com base na composição genética de uma pessoa também é uma possibilidade. Além disso, executar a IA em captura de pacotes pode ser útil na previsão de ataques de adversários avançados.\n\nOutro caso de uso promissor é um cliente com todos os seus dados em um sistema de armazenamento VAST all-flash, em vez de na nuvem, mas realiza todo o processamento na nuvem, podendo trazer de volta apenas os resultados. Os resultados normalmente são muito pequenos, talvez alguns bytes de dados, e são baratos de serem recuperados. Esse tipo de modelo, por exemplo, pode gerar valor através de análises em dados antigos que estão atualmente apenas armazenados e são muito caros para serem movidos.\n\nHá muita flexibilidade para adotar uma abordagem híbrida ou de múltiplas nuvens, onde você tem um sistema de armazenamento centralizado no local que pode ser acessado por vários provedores de nuvem.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Randy Hayes"],"link":"/episode-EDT48-pt","image":"./episodes/edt-48/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren verifica com Randy Hayes, agora vice-presidente de Vendas para o setor público da VAST Data, seis meses após sua última conversa para ver como eles estão se saindo na indústria, o que há de novo na VAST e casos interessantes de uso. Seu novo produto, Gemini, oferece um modelo de negócios de armazenamento diferente."},{"id":120,"type":"Episode","title":"Trabalho Remoto Antes, Durante e Depois da Pandemia","tags":["covid","remoteworker"],"body":"\r\n\r\nEles identificaram quatro áreas que os ajudaram não apenas a sobreviver, mas a se destacar durante esse período incomum: Antecipe as necessidades do seu gerente, Comunique-se como se seu emprego dependesse disso (porque com certeza depende), Levante sua bandeira ao levantar a bandeira para os outros, Bloqueie! Essa! Agenda!\n\n## Antecipe as necessidades do seu gerente\n\nAdivinhe o que o seu gerente precisa relatar e tenha a informação ao seu alcance.\n\nOs relatórios de vendas, o status do projeto e o status do cliente devem ser criados proativamente.\n\n## Comunique-se como se o seu emprego dependesse disso (porque com certeza depende).\n\nNão encha a caixa de email de outras pessoas com informações inúteis.\n\nColoque seu pedido no início do e-mail. Em seguida, adicione informações adicionais.\n\nDê à sua equipe um resumo do que você está fazendo com informações úteis.\n\n## Acene sua bandeira acenando a bandeira pelos outros.\n\nUm componente chave do sucesso em qualquer empresa é ter conquistas visíveis e tangíveis.\n\nVocê não pode sempre abaixar a cabeça, trabalhar e esperar que isso fale por si só.\n\nReconheça os outros que o ajudaram a fechar o negócio ou terminar o projeto.\n\n## Bloqueie! Isso! Calendário!\n\nEstabeleça limites para o tempo com a família e para quando o trabalho termina e começa.\n\nAgende um tempo para o tempo \"você\". Você precisa de tempo para descansar seu cérebro.\n\n* Coloque um intervalo de 5 a 10 minutos entre as reuniões.\n\nTempo para processar sua caixa de entrada\n\nTempo no final do dia para processar o seu dia\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rachel Dreikosen"],"link":"/episode-EDT49-pt","image":"./episodes/edt-49/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com Rachel Dreikosen, Gerente de Desenvolvimento de Negócios no Setor Público da Intel, sobre como o COVID-19 afetou seu equilíbrio entre trabalho e vida pessoal e por que ela começou um blog para ajudar outras profissionais de vendas técnicas mulheres."},{"id":121,"type":"Episode","title":"Modelo de Maturidade de Infraestrutura.","tags":["infrastructurematurity","compute","technology","sdi","cloud","multicloud"],"body":"\r\n\r\nA transformação digital pode ser difícil. Muitas organizações ficam paralisadas ao tentar decifrar todas as tecnologias que são lançadas sobre elas todos os dias. Nesta jornada, como qualquer outra, é importante ter um mapa. Neste episódio, Darren explica o \"Modelo de Maturidade de Infraestrutura\" para ajudar organizações a descobrir onde estão em sua transformação digital, para onde podem ir em seguida e como chegar lá.\n\n## Fase Padronizada\n\nQuase toda organização está nessa fase padronizada ou além. Compreender essa fase nos dá uma base para começar a falar sobre as coisas comuns que vemos em todas as organizações.\n\n## Básico\n\nO nível básico é onde encontramos infraestrutura e gestão descoordenadas por reação. Isso é especialmente comum em startups, onde uma organização compra serviços ou hardware conforme necessário, em reação aos eventos, em vez de fazer parte de um plano mestre. Aqui, também vemos pilhas de software/hardware construídas especificamente para um propósito. Uma TI de pequeno porte também faz parte desta fase de maturidade.\n\n## Centralizado\n\nNeste nível, a infraestrutura é centralizada. As organizações compram capacidade em vez de hardware projetado para finalidades específicas. As compras não são mais reativas, mas fazem parte de um plano de longo prazo. Normalmente, a organização terá configurações comuns de servidores para poder comprar em volume visando eficiência de custo e ter maior confiabilidade. A TI é mais centralizada e especializada, por exemplo, em rede, armazenamento, computação e segurança.\n\n## Traduza o seguinte para o português: Simplificado.\n\nNo nível simplificado, a infraestrutura é mais consolidada. Diferentes departamentos podem compartilhar equipamentos, como servidores, armazenamento e redes. As organizações obtêm melhor desempenho à medida que migram de métodos antigos para novos métodos de centralização e simplificação. Os custos de operação (OpEx) diminuem à medida que a eficiência aumenta.\n\n## Fase virtualizada\n\nA maioria das organizações hoje está pelo menos em alguma parte da fase virtualizada. É aqui que encontramos configurações padronizadas e nuvens privadas.\n\nA virtualização de servidores oferece a flexibilidade de executar aplicativos em diferentes máquinas e movê-los facilmente entre elas.\n\nA virtualização de armazenamento é um desenvolvimento mais recente que traz benefícios similares à virtualização de servidores: flexibilidade para decisões mais dinâmicas. O armazenamento agora pode abranger todo o ecossistema. O armazenamento pode ser provisionado para uma aplicação específica, e esse armazenamento e a aplicação podem se movimentar dentro da infraestrutura.\n\nA virtualização de rede, a mais recente adição, tem sido abraçada principalmente pelos Provedores de Serviço de Internet. Eles fizeram um grande investimento devido à eficiência de poder fazer alterações dinâmicas na rede remotamente, em vez de a partir do hardware baseado em propósito antigo.\n\nTodas essas tecnologias de virtualização estão integradas em ofertas no espaço da nuvem privada, tanto comercial quanto de código aberto, frequentemente em um único local de fácil gerenciamento. As organizações estão avançando para essa fase e também mudando e consolidando suas tecnologias da informação de um foco vertical para uma visão geral de tudo (NOTA: podemos chamar isso de foco horizontal?) com sistemas, aplicativos e serviços mais do que computação, armazenamento e rede.\n\n## Fase automatizada\n\nNa fase automatizada, as organizações podem realizar a provisão de infraestrutura automaticamente, o que economiza tempo ao eliminar camadas de pessoas e permissões. Com o uso de portais de autoatendimento, um engenheiro ou desenvolvedor de software pode obter os recursos de que precisa imediatamente. Essa provisão automática também permite a automação básica de atualizações, máquinas virtuais, segurança e conformidade. Agora, a TI está menos em modo reativo e mais em modo proativo. Outras partes valiosas dessa fase são, por exemplo, a inicialização automática da infraestrutura para aplicações em produção e a autorecuperação de aplicações.\n\n## Fase Orquestrada\n\nÀ medida que a automação se torna mais complexa, uma fase orquestrada se torna necessária. A automação consiste em aplicar ações em uma máquina, enquanto a orquestração é a coordenação das ações ocorrendo em várias máquinas ou mesmo modalidades (armazenamento, processamento, rede) para uma aplicação. Além disso, pilhas de aplicativos automatizados podem implantar várias aplicações em vários servidores diferentes. Nessa fase, as organizações também orquestram serviços híbridos, por exemplo, gerenciando recursos em nuvens públicas e privadas. Os benefícios dessa orquestração são redução nos custos operacionais (OpEx), redução nos custos de investimento (CapEx) e redução no tempo de implementação.\n\n## Tempo Real (Fase Gerenciada pelo SLA)\n\nEm uma fase de tempo real, as organizações estão em uma infraestrutura de acordo de nível de serviço. Em vez de aplicativos, as organizações estão utilizando serviços que fornecem valor e integram tudo. Serviços compartilhados se estendem por múltiplas nuvens híbridas, incluindo infraestrutura legada. A infraestrutura híbrida de agrupamento, orquestração baseada em políticas e orquestração baseada em serviços otimizam a infraestrutura, gestão de dados e serviços.\n\n## Conclusão\n\nÉ comum que diferentes partes da sua organização estejam em fases diferentes. Alguns grupos estarão mais avançados do que outros; isso é saudável. Pequenos grupos pioneiros podem falhar sem afetar toda a organização, ou podem ter um avanço e ajudar o restante da organização a progredir. Muito poucas organizações chegaram à fase mais alta do mapa. A chave é não se desencorajar, mas usar o mapa como um guia para descobrir onde você está e quais podem ser os próximos passos para a sua organização.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT5-pt","image":"./episodes/edt-5/pt/thumbnail.png","lang":"pt","summary":"A transformação digital pode ser difícil. Muitas organizações ficam paralisadas ao tentar decifrar todas as tecnologias que são jogadas sobre elas todos os dias. Nessa jornada, assim como em qualquer outra, é importante ter um mapa. Neste episódio, Darren explica o Modelo de Maturidade da Infraestrutura para ajudar organizações a descobrir onde estão em sua transformação digital, para onde podem ir em seguida e como chegar lá."},{"id":122,"type":"Episode","title":"Compreensão do Esgotamento dos Funcionários","tags":["employeeburnout","remotelearning","remoteworker","people","process","compute"],"body":"\r\n\r\nA experiência profissional de Uzair começou na área de vendas, experiência do consumidor em ponto de venda e evoluiu para o desenvolvimento de produtos. Durante dez anos, ele trabalhou em um aplicativo de despertador que funcionava de maneiras personalizadas diferentes para ajudar as pessoas a acordarem motivadas e focadas. Embora esse projeto tenha falhado no final, Uzair aprendeu muito sobre a motivação humana. Há alguns anos, quando ele estava trabalhando com estudantes do ensino médio e fundamental, ele percebeu uma grande falta de motivação e foco no período da manhã, que parecia estar piorando progressivamente. Devido à sua experiência profissional e seu próprio crescimento pessoal, ele viu uma oportunidade de ter um impacto criando o aplicativo District Zero.\n\n## Bem-estar do estudante do ensino fundamental e médio\n\nA missão do District Zero é proporcionar aos alunos do ensino fundamental e médio habilidades de aprendizado integral. Isso significa ajudar os alunos a lidar com emoções difíceis para recuperar seu foco e motivação.\n\nO aplicativo utiliza a tecnologia Agile e o poder da análise de sentimento por processamento de linguagem natural para funcionar em escala e identificar sinais de gatilhos e ansiedade por meio de uma pesquisa. Assim que um estudante completar a pesquisa, o aplicativo pode sugerir conteúdo e recursos como um vídeo ou jogo para ajudar com questões específicas. Ele também possui um sistema de relatório para professores e administradores.\n\nAtualmente, professores e administradores carregam uma carga pesada tentando ajudar seus alunos com bem-estar, especialmente no ambiente COVID. Eles podem ter um Formulário do Google conectado ao Google Sheets e, em seguida, usar o control F para pesquisar palavras negativas e frases-chave. O aplicativo reduz essa carga e evita o subproduto da negatividade do professor e do administrador. O sistema revela os obstáculos e pontos de dor dos alunos e os ajuda a resolvê-los por meio de soluções rápidas e recursos. Se os alunos precisarem de mais apoio, o sistema os encaminhará para a pessoa correta, como um orientador, e manterá o professor informado.\n\nTradicionalmente, quando um estudante mostra ansiedade ou frustração, por exemplo, eles são levados diretamente a um conselheiro ou assistente social quando o problema se torna incontrolável. Mas o estudante não precisa ir de zero a cem; há um meio-termo onde o problema pode ser abordado antes de chegar a uma situação de luta ou fuga. O aplicativo pode ajudar a evitar a escalada do problema e identificar questões antes que seja tarde demais.\n\nO projeto piloto do aplicativo nas escolas da área de Chicago aconteceu em agosto passado durante a COVID, portanto, foi especialmente adequado para ajudar os alunos que perderam aquela conexão presencial com seus professores e tiveram dificuldades com a aprendizagem social e emocional. Um elemento-chave para o sucesso na aprendizagem social e emocional é que todos na comunidade precisam estar envolvidos e empáticos: professores, administradores, superintendentes, pais e contribuintes; a empatia e as conexões não podem acontecer apenas na escola.\n\n## Esgotamento dos funcionários\n\nDurante a COVID, os trabalhadores demonstraram um aumento na produtividade, porém, agora existe o risco de exaustão dos funcionários. Seja pelo estresse de ser um trabalhador da área da saúde ou pelo desequilíbrio entre trabalho e vida pessoal dos trabalhadores remotos, uma infinidade de problemas torna isso uma questão prioritária para as empresas. Os princípios do aplicativo District Zero K-12 podem ser aplicados aos trabalhadores para ajudar a amenizar a exaustão.\n\nO Distrito Zero começou a experimentar o aplicativo em seu próprio local de trabalho, e isso levou a conversas difíceis sobre prioridades e compreensão das necessidades reais dos funcionários. Similar à aplicação para a educação K-12, o sistema pode identificar as dificuldades diárias dos funcionários e preencher a lacuna intermediária fornecendo suporte antes que os problemas se agravem.\n\nO Distrito Zero espera expandir sua tecnologia de forma a beneficiar diversos setores: empresas, cuidados de saúde corporativos e até mesmo órgãos governamentais, para uso em áreas como prevenção de suicídio de veteranos.\n\nEsta nova ferramenta e compreensão do apoio à saúde dos estudantes e colaboradores chega em boa hora, já que o COVID aumentou o estresse e a exaustão, e estamos começando uma nova fase de reabertura e ajuste.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Uzair Hussain"],"link":"/episode-EDT50-pt","image":"./episodes/edt-50/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções da Intel, conversa com Uzair Hussain, CEO da District Zero, sobre como o aplicativo da empresa que apoia o bem-estar mental de estudantes do ensino fundamental e médio pode ser aplicado na prevenção do esgotamento dos funcionários."},{"id":123,"type":"Episode","title":"Casos práticos de uso da Memória Persistente Optane","tags":["dataarchitecture","memverge","pmem","optane","technology","data"],"body":"\r\n\r\nA MemVerge enviou a primeira versão de seu software em setembro de 2020 e, apesar da pandemia, que dificultou a educação dos clientes sobre a nova tecnologia, estabeleceu-se um bom padrão de casos de uso.\n\n## Redução de custos dos provedores de serviços em nuvem\n\nA métrica chave para um operador de serviço em nuvem é quantas VMs eles podem entregar aos seus clientes e a que custo. O tamanho da memória nos servidores se torna o gargalo de quantas VMs eles podem alocar por servidor, limitando o quão baixo o preço por VM pode ser.\n\nO software MemVerge com Optane proporciona uma maior quantidade de memória por servidor, alocando um maior número de máquinas virtuais (VMs), reduzindo assim o custo por VM e aumentando a competitividade dos provedores de serviços em nuvem. O custo por VM pode ser três vezes mais barato.\n\n## Confiabilidade com Bases de Dados de Grande Capacidade de Memória\n\nClientes financeiros como bolsas de valores, bancos e fundos mútuos utilizam muitos bancos de dados em memória e aplicativos em memória. Além de aumentar o tamanho da memória para poder ter mais instâncias por servidor, a MemVerge resolve os desafios de disponibilidade dos bancos de dados em memória. Se os dados não estiverem sendo persistidos no armazenamento o tempo todo, mas apenas permanecerem na memória, todos os dados intra dia são perdidos em caso de falha. Isso é catastrófico. Mesmo que você tenha registrado todas as transações, é necessário reproduzir o log para recuperar o banco de dados, o que leva muitos minutos ou até horas para se recuperar.\n\nMemVerge oferece um novo serviço de dados que tem snapshot em memória. Ele persiste o estado do banco de dados para a Optane, que é muito mais rápido do que persistir em armazenamento. Se ocorrer um crash, você tem o último snapshot capturado na memória persistente e pode se recuperar a partir dele. A recuperação leva apenas um minuto ou dois, então é uma melhoria de 60 a 100 vezes.\n\n## Redução do Sequenciamento Genômico Através do Instantâneo de Memória\n\nNa área da genômica, o software MemVerge em combinação com Optane aumenta a produtividade exponencialmente. Em um fluxo de trabalho de análise de dados em várias etapas, uma memória maior significa mais paralelismo do pipeline e processamento, tornando todo o processo mais rápido. O snapshot é útil aqui também. Se uma organização está realizando, por exemplo, pesquisa sobre câncer ou COVID e precisa fazer sequências de DNA ou RNA, eles precisam passar por cerca de 50 etapas de processamento. Cada etapa pode levar horas e eles precisam fazer um checkpoint do estado dos resultados de computação intermediária por alguns motivos: primeiro, para refazer ou reproduzir os resultados e segundo, para comparar os resultados se modificarem alguns dados. Os checkpoints são salvos no armazenamento e isso leva de cinco a 30 minutos. Em muitos casos, isso pode levar mais tempo do que o próprio cálculo. Portanto, se um trabalho leva 24 horas, eles podem usar oito horas para o cálculo e 16 horas apenas para executar esses trabalhos de E/S, salvando esses estados intermediários.\n\nEm vez de fazer IO, o MemVerge usa um instantâneo após cada estágio e captura-o na memória persistente Optane. Em vez de 16 horas de IO, esse processo pode levar um minuto. É a nova forma de fazer IO; você não precisa fazer a serialização ou deserialização para abrir um arquivo, ler, escrever, etc. Tudo que você precisa fazer é tirar um instantâneo.\n\nEmbora isso demande muita memória, com o MemVerge, a memória é maior do que antes e continuará a melhorar à medida que a Intel inova. Duas outras características ajudam nessa questão. Primeiro, instantâneos são tirados periodicamente sem criar cópias completas do estado da memória; eles são apenas as páginas de mudança, reduzindo assim o uso extra de memória. Segundo, o MemVerge pode manter até 256 camadas de instantâneos na memória, mas ao mesmo tempo, você pode exportar esses instantâneos para servidores de armazenamento ou seus próprios sistemas de armazenamento. Isso é feito sem interromper ou afetar a aplicação em execução.\n\nBasicamente, você está criando um DVR de memória porque, em vez de apenas executar o seu aplicativo para frente, você também pode executá-lo para trás instantaneamente. É uma nova experiência.\n\nGenômica é apenas o primeiro exemplo de muitas cargas de trabalho que poderiam se beneficiar dessa tecnologia.\n\nComo a MemVerge é uma startup, eles estão focando estreitamente em três áreas de provedores de serviços em nuvem, aplicativos financeiros com grande capacidade de memória, genômica e trabalhos de pipeline de ciência de dados relacionados, mas todos esses casos de uso comprovam o poder da combinação de memória persistente Optane e software da MemVerge.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT51-pt","image":"./episodes/edt-51/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções da Intel, conversa com Charles Fan, CEO da MemVerge, sobre casos de uso com seu software que utiliza a memória persistente Intel Optane de forma inovadora, removendo o gargalo entre memória e armazenamento."},{"id":124,"type":"Episode","title":"Telemetria na Nuvem","tags":["multicloud","optimization","workloadplacement"],"body":"\r\n\r\n## Benefícios dos Arquitetos de Soluções em Nuvem (CSAs)\n\nO papel do CSA está em alta na indústria atualmente, e a Intel tem contratado uma equipe de CSAs para fornecer valor aos seus clientes. Os CSAs podem ajudar os clientes a evitar a mentalidade de \"levantar e transferir\" que leva a custos desnecessariamente altos. Esses novos CSAs trazem uma perspectiva externa e se conectam com a comunidade maior de CSAs para resolver problemas.\n\n## Fases da Telemetria\n\nA telemetria na nuvem não deve ser relegada ao provedor de serviços em nuvem. Por exemplo, a Amazon Web Services (AWS) teve uma grande interrupção na Costa Leste em novembro passado e suas ferramentas não estavam notificando, então muitos clientes não tinham ideia de que estavam fora do ar. As organizações precisam de sua própria telemetria para monitoramento.\n\nA primeira fase é sem monitoramento na nuvem. A segunda fase é a exposição da telemetria, onde você entende o que está obtendo, por exemplo, CPU, memória e rede, mas é de nível superficial. A próxima fase é o monitoramento e ação, onde você recebe notificações sobre lentidões, taxas de transação, taxas de resposta, etc. A próxima fase é mais abaixo na pilha, onde a nuvem inteligente moderna controla e prevê para remediação. Por último, há a automação completa. É onde as coisas estão operando por conta própria, ouvindo, respondendo e depois informando posteriormente.\n\nUm exemplo de automação completa seria um centro de dados que controla um sistema HVAC, detectando e reduzindo ou aumentando a temperatura em diferentes partes de um prédio. Para cargas de trabalho, uma nuvem inteligente pode mover as cargas de trabalho para maximizar o valor em capacidade e desempenho.\n\n## Abordagens Atuais e Limitações\n\nMuitas vezes, no entanto, os clientes de provedores de serviços de nuvem negligenciam a automação na camada de infraestrutura e esquecem da camada de carga de trabalho. Os clientes precisam de informações além das informações essenciais; eles precisam de telemetria profunda e detalhada para saber o que realmente está acontecendo. É um erro confiar que o provedor de serviços em nuvem tenha seus melhores interesses em mente em relação à telemetria, e isso pode resultar em altos custos.\n\nAlgumas empresas provedoras de serviços em nuvem estão se abrindo mais. Atualmente, a AWS está revolucionando o jogo com a telemetria que eles estão fornecendo. Esperançosamente, outros seguirão o exemplo.\n\n## Vamos coletar a telemetria correta...\n\nEscolher as instâncias corretas faz diferença. Nem todos os núcleos são iguais; diferentes núcleos são usados ​​para coisas diferentes, e é importante entender quais são para obter o melhor desempenho e preço.\n\nQue tipo de informação você pode coletar? O design do produto da Intel inclui unidades de monitoramento de desempenho (PMUs). Estes são contadores em nível inferior e fornecem informações sobre transações, atrasos, latência e gargalos. Existem três tipos diferentes de PMUs: núcleo, fora do núcleo e sem núcleo. Essas PMUs coletam informações sobre CPI, utilização, frequência e TMAM. Todos esses dados estão disponíveis utilizando a AWS.\n\nUsando métricas, a telemetria real é uma ferramenta para ajudá-lo a otimizar suas cargas de trabalho. Você pode comparar como sua carga de trabalho está sendo executada em seu próprio data center, por exemplo, com a AWS nessas instâncias, e rodar métricas para descobrir em qual plataforma as cargas de trabalho devem ser hospedadas.\n\n## Relevância de TI\n\nAdicionar telemetria ao benchmarking é uma solução definitiva. Com o benchmarking, você pode conhecer sua produção, e com a telemetria, você pode analisar CPI, utilização e frequência, e ter um painel completo do que está acontecendo. Você deseja fazer a mesma coisa na nuvem, em vez de apenas colocar cargas de trabalho em uma instância aparentemente mais barata.\n\nProfissionais de TI não devem temer perder seus empregos porque as coisas estão migrando para a nuvem. Em vez disso, eles devem transferir suas habilidades para aprender sobre telemetria de benchmarking, em vez de ter uma mentalidade de levantar e transferir. Tornar-se proficiente na utilização da nuvem também envolve o uso de recursos nativos da nuvem, como o Kubernetes e os containers. A telemetria também funciona nessas áreas. Com o C advisor da Intel, é possível obter uma telemetria rica, como dados de núcleo e dados fora do núcleo de seus containers.\n\nEmbora seja um pouco intimidador quando você olha para tudo o que é possível na nuvem, começar pequeno é a melhor opção. Analise as aplicações corretas com base no risco. Catalogue suas aplicações, avalie a hierarquização das aplicações e, em seguida, comece a transferi-las para a nuvem em pedaços consideráveis de funções e aplicativos semelhantes. Conforme você explora novos serviços e aprende novas aplicações, considere a arquitetura por trás delas e faça as perguntas corretas para se tornar um arquiteto técnico mais informado.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT52-pt","image":"./episodes/edt-52/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções da Intel, fala com Josh Hilliker, Diretor de Arquitetos de Soluções em Nuvem da Intel, sobre o uso de telemetria na nuvem para maximizar valor e eficiência."},{"id":125,"type":"Episode","title":"DevOps com velocidade ao mesmo tempo que reduz o risco.","tags":["devops","compute","technology","process","devsecops","cybersecurity","multicloud"],"body":"\r\n\r\nAs três principais áreas-chave a equilibrar na entrega de software são velocidade, risco e qualidade. A maioria consegue gerenciar uma ou duas dessas coisas, mas adicionar a terceira pode se tornar difícil. Por exemplo, você pode conseguir entregar com velocidade porque possui um ótimo sistema de cd, mas uma vez que você introduce verificações de conformidade e políticas, você se depara com um desafio. Você para e verifica essas coisas ou talvez ingira alguns resultados de outra ferramenta? De repente, sua velocidade sofre.\n\nOpsMx está trabalhando para ajudar as pessoas a automatizarem esses pontos de decisão. A automação é a coisa mais importante para manter a velocidade alta enquanto aumenta os outros dois pilares, risco e qualidade.\n\n## Solução OpsMx: Entrega de Software Totalmente Automatizada\n\nA automação funciona como uma agregação de dados, ao obter resultados das várias ferramentas na cadeia de ferramentas e, em seguida, possui um mecanismo como um gerenciador de políticas que fornece resultados esperados em marcas de verificação de ferramentas como o BlackDuck. Se parecer correto, o processo não é interrompido, como acontece atualmente, para uma verificação humana.\n\n## A entrega mais rápida de aplicativos aumenta as taxas de falha.\n\nA velocidade de entrega de aplicativos passou de semanal ou mensal para por hora, acrescentando pressão para produzir rapidamente. À medida que você tenta aumentar a velocidade, no entanto, pode começar a perder algum controle sobre a qualidade, talvez ignorando algumas verificações de risco. O resultado líquido é que quanto mais rápido você tentar se mover, mais propenso estará a ter falhas.\n\n## Pontos de atrito e espaços de problemas\n\nCom o uso estratégico da automação, você tem a capacidade de aumentar a velocidade sem assumir riscos. A verificação contínua pode reduzir um esforço de três ou quatro horas para cinco ou dez segundos. Em vez de usar mão de obra humana para analisar logs em busca de comportamento anômalo que possa ter passado por uma verificação de aprovação/reprovação binária, a verificação contínua pode fazer isso automaticamente, permitindo que as pessoas se concentrem apenas nos casos excepcionais.\n\n## O que significa automação nesse contexto?\n\nA próxima peça está utilizando as ferramentas exigidas pela equipe de segurança e conformidade, como o BlackDuck. Com a automatização, você não precisa interromper o pipeline para ter alguém interpretando os resultados antes de continuar, pois isso acontecerá automaticamente.\n\nAs outras partes são políticas em um nível mais elevado, se você estiver em uma indústria regulamentada com mais verificações, ou algo tão simples como um varejista, por exemplo, que não quer lançar um novo software duas semanas antes do Natal. Essas verificações podem ser automatizadas para eliminar a necessidade de aprovação humana, permitindo que o fluxo do pipeline continue caso não haja exceções. A ideia é remover o máximo possível de barreiras humanas para permitir que o pipeline flua.\n\nO conjunto principal de automações de controle e políticas são reutilizáveis entre pipelines; você só precisa personalizar ou criar aqueles específicos para os critérios do seu ciclo de lançamento.\n\n## Solução OpsMx: Entrega de Software Totalmente Automatizada.\n\nOpsMx oferece a capacidade de criar esses pipelines e automações de análise de logs. Spinnaker é a ferramenta atual, mas a visão da OpsMx é ser o mais agnóstico possível em relação ao cd, permitindo o uso de todas as ferramentas de cd, como Jenkins e Microsoft Azure. OpsMx aproveita a parte de cd para a automação, mas está acima disso ajudando a tomar decisões automatizadas.\n\nUma parte crescente da ferramenta é o aprendizado de máquina para ajudar a entender o que é considerado como base para uma aplicação específica em comparação com o que é um comportamento anômalo. Também há um modelo de aprendizado supervisionado, onde um profissional de DevOps, um engenheiro ou um proprietário de produto pode especificar um comportamento anômalo como esperado no contexto da aplicação.\n\nO sistema também permite a auditabilidade. Qualquer alteração ou exceção é documentada. Existe um histórico completo de auditoria de tudo o que acontece, desde quem aprovou uma exceção até qual artefato foi implantado e qual imagem base foi usada. Esteja o sistema em execução na nuvem ou localmente, é possível visualizar toda a linha de produção como uma entidade única.\n\nOutro aspecto da visibilidade que o OpsMx oferece é um tipo de mapa de onde está implantado, como por exemplo, a série de microserviços que estão atualmente no QA, o que está em determinados estágios ou o que está em produção e, em seguida, para qualquer uma dessas coisas, você pode aprofundar e obter uma visão histórica. Você pode clicar em qualquer lançamento e todas as informações de auditoria estão ao alcance dos seus dedos.\n\nAlém disso, a próxima fronteira em que a OpsMx está trabalhando é a eficácia dos artefatos que estão sendo capturados para que a cadeia de suprimentos, ou linhagem, seja transparente.\n\nOpsMx está agora usando uma tecnologia baseada em agentes que pode interagir com, por exemplo, recursos que estão atrás do seu firewall. O agente atua como um proxy para a camada de inteligência, permitindo que os dados sejam coletados lá. Não há preocupações com a abertura ou exposição de portas de firewall. Funciona da mesma forma com os provedores de nuvem: o agente pode ser implantado dentro da VPC e você não precisa mais correr o risco de colocar chaves e segredos em um aplicativo baseado em nuvem. O agente simplesmente atua como um proxy, garantindo que a parte autorizada permaneça sempre dentro da VPC, assegurando a forma como as informações são coletadas.\n\nCom essa nova direção, a indústria DevOps como um todo está prestes a passar por uma reviravolta em relação à segurança e auditabilidade.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT53-pt","image":"./episodes/edt-53/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Robert Boule, Chefe de Engenharia de Soluções na OpsMx, junta-se a Darren para falar sobre como melhorar a velocidade sem aumentar o risco no processo DevOps. As três áreas-chave a equilibrar na entrega de software são velocidade, risco e qualidade. A maioria consegue gerenciar uma ou duas dessas coisas, mas adicionar a terceira pode se tornar difícil. Por exemplo, você pode ser capaz de entregar com velocidade porque possui um ótimo sistema de entrega contínua (cd), mas uma vez que você introduz verificações de conformidade e políticas, você enfrenta um desafio. Você para e verifica essas coisas, ou talvez importe alguns resultados de outra ferramenta? De repente, sua velocidade sofre."},{"id":126,"type":"Episode","title":"Pessoas e Processos na Transformação Digital","tags":["multicloud","organizationalchange","change","people","hsbc","cio"],"body":"\r\n\r\nAnn começou sua carreira como programadora, passou para a gestão de programas e possui experiência em aquisições e vendas de empresas. Ela foi a Diretora Global de Dados da HSBC e tornou-se Diretora de Informação em setembro de 2016. Ela conduziu grandes programas de transformação organizacional ao longo de sua carreira, incluindo novos sistemas hipotecários e novos sistemas bancários centrais.\n\nAlguns dos desafios dessas transformações eram fazer as perguntas certas durante as avaliações. Em um programa de transformação hipotecária, ela primeiro fez perguntas sobre as finanças: Estamos acima do orçamento? Estamos no planejado? Precisamos pedir mais financiamento? Para a equipe de liderança, ela perguntou se as pessoas certas estavam no lugar com as habilidades certas para realizar as mudanças. Ela também explorou a visão geral: No que a empresa acredita? Quais são os objetivos da empresa? Ela entende claramente por que o programa de transformação é necessário e o que estamos tentando alcançar? Ela também analisou o status do programa por meio de métricas e KPIs.\n\nPara aquela transformação, eles já tinham um programa estabelecido e iniciado, mas Ann entrou como uma espécie de consultora de negócios interna. O programa era impulsionado e liderado pelos negócios, mas eles precisavam aproveitar a tecnologia para atingir esses objetivos e metas comerciais. A tecnologia e os objetivos precisavam estar completamente alinhados.\n\nNa última transformação liderada por Ann, quase três anos em um programa de transformação de cinco anos, ela assumiu como diretora do programa tanto para o lado de negócios quanto de tecnologia. Quatro CIOs reportavam a ela, cada um designado para um setor de negócio: varejo, comercial, riqueza e bancos de investimento. Ann os conectava com seus parceiros de negócio, e eles se reuniam para garantir que permanecessem alinhados, uma vez que estavam tentando alcançar o mesmo objetivo.\n\nEmbora parecesse que esse tipo de parceria seria uma prática comercial regular, Ann encontrou um de seus maiores desafios como CIO em alinhar a empresa. Para algo tão grande e complexo como a alteração de um sistema bancário central, um novo aplicativo móvel ou uma nova interface web, por exemplo, Ann realizava reuniões múltiplas vezes ao dia com os principais envolvidos, pois havia provavelmente 15 fluxos de trabalho diferentes e a integração era o aspecto-chave.\n\nEntrar de fora e fazer mudanças organizacionais é uma posição difícil de se estar. As pessoas estão nervosas sobre a mudança, especialmente quando confiavam em seu líder anterior. Com o tempo, no entanto, Ann descobriu que as pessoas se juntaram porque sabiam que o objetivo era melhorar o negócio, e elas compraram a ideia. Uma maneira que Ann conseguiu isso foi sentando no chão com as diferentes equipes em vez de em um escritório. Ela conheceu as pessoas e se tornou normal ter ela por perto e poder ter conversas e levantar questões. Ela obteve informações diretas das pessoas que estavam realizando o trabalho, em vez de informações filtradas pela gerência.\n\nUma coisa que os líderes frequentemente esquecem é que as pessoas nas equipes desejam ter sucesso, e um toque pessoal, como trabalhar ao lado delas, faz uma grande diferença.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ann Madea"],"link":"/episode-EDT54-pt","image":"./episodes/edt-54/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Intel, pergunta a sua convidada, Ann Madea, ex-CIO do HSBC, para refletir sobre o processo de grandes mudanças transformacionais que ela liderou em organizações."},{"id":127,"type":"Episode","title":"Comunicação durante a transformação","tags":["communication","organizationalchange","people","process","hsbc","cio"],"body":"\r\n\r\nQuando os CIOs implementam soluções, envolvem novos processos e muito provavelmente mudanças organizacionais. No mais recente programa de transformação de Ann, eles avançaram com a nuvem. Ann contratou um chefe de nuvem e implementou uma estratégia de várias nuvens com Google, AWS e Azure. Essa mudança importante causou preocupação, especialmente entre aqueles que trabalhavam com a infraestrutura há muito tempo.\n\nPara aliviar a ansiedade e aumentar o envolvimento, Ann incentivou fortemente as pessoas a começarem a obter certificações para cloud, Google, AWS, etc. Ela levou sua equipe para fazer reuniões com o Google em Nova York, onde puderam ver a energia, atmosfera e colaboração que estavam acontecendo lá. À medida que as pessoas começaram a ser certificadas, a empolgação pelo treinamento e transformação aumentou.\n\nO novo líder da nuvem realizaria os \"Dias Google\" em que as pessoas vinham e apresentavam seus casos de uso e como estavam aproveitando diferentes produtos. Eles fizeram o mesmo com a Amazon e Azure. Isso ajudou os funcionários a entender o alcance do que poderiam fazer, criar entusiasmo e promover a participação.\n\nA chave de Ann para a comunicação do CIO no meio de uma transformação é confiar, mas verificar. Três ou quatro meses após o início da transformação, Ann foi instruída a focar em avaliações em áreas como orçamentos, revisão de equipes e reestabelecimento de relacionamentos com o conselho e os reguladores. No entanto, ela decidiu investigar mais a fundo e descobriu que não havia nenhum plano concreto que mostrasse como o programa seria executado. Isso deu início a uma reavaliação da equipe de liderança para dar continuidade ao programa.\n\nUm CIO implementando uma transformação deve estar disposto a colocar a mão na massa. Confie, mas verifique tudo através de múltiplas entrevistas e fluxos de informação; uma ou duas fontes não são suficientes. Em seguida, Ann acredita que é necessário começar a se comunicar com transparência sobre os problemas para obter apoio das pessoas capazes de fornecê-lo.\n\nUm benefício da transparência é que as pessoas que estão lhe fornecendo informações, como os programadores, confiam que você não irá usar essas informações contra eles. A equipe de Ann sabe que não deve surpreendê-la e, por sua vez, ela não surpreende seus chefes. Por exemplo, se houver um problema no centro de dados, ela irá informá-los sobre o que sabe e atualizá-los conforme ela aprende mais.\n\nOs funcionários querem saber como eles se encaixam no sucesso do programa, não apenas que eles têm que codificar esses cinco programas. Uma maneira que Ann conseguiu isso foi realizando muitas reuniões com os funcionários. Ela também percorria os andares e realizava uma reunião informal de atualização de 30 minutos todas as semanas, onde as pessoas podiam fazer perguntas. Sempre que Ann realizava uma reunião importante onde decisões eram tomadas, ela reunia toda a equipe, tanto do lado dos negócios como do lado da tecnologia, e explicava as decisões e o impacto delas. Se as pessoas souberem que houve uma grande reunião, mas ficarem no escuro, começam os boatos.\n\nCom o teletrabalho atual, Ann diz que também é importante fazer breves verificações individuais. Verificações contínuas levam a melhores relacionamentos e diminuem a ansiedade de falar com superiores. Os chefes precisam entender o que motiva as equipes e do que as pessoas estão preocupadas. Eles têm famílias para sustentar, filhos na faculdade ou talvez membros da família com problemas de saúde.\n\nÉ claro que nem tudo pode ser discutido com todos, como reduções de pessoal ou promoções, por exemplo, mas Ann gosta de convocar reuniões de supervisores chamadas \"reuniões de pessoal\" onde podem discutir essas questões delicadas. As reuniões também podem ajudar os líderes a entenderem sua equipe e o que eles estão procurando fazer. É importante ouvir os subordinados em vez de apenas os líderes, pois eles estão mais sintonizados com os acontecimentos do dia a dia.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ann Madea"],"link":"/episode-EDT55-pt","image":"./episodes/edt-55/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, parte dois de dois, Darren e a convidada Ann Madea, ex-CIO do HSBC, falam sobre comunicação durante a transformação organizacional. Quando os CIOs implantam soluções, eles envolvem novos processos e, muito provavelmente, mudanças organizacionais. No programa de transformação mais recente de Ann, eles avançaram com a nuvem. Ann contratou um líder de nuvem e implementou uma estratégia de nuvem múltipla com Google, AWS e Azure. Essa grande mudança causou preocupação, especialmente entre aqueles que trabalhavam com a infraestrutura há muito tempo."},{"id":128,"type":"Episode","title":"Organizações de Corretores de Nuvem","tags":["cloudbroker","cloud","compute","technology","people","process","multicloud","organizationalchange"],"body":"\r\n\r\nDave e Kevin fundaram a equipe de corretagem em nuvem da Intel há cerca de sete anos. Os funcionários da Intel estavam consumindo a nuvem pública e era como um verdadeiro Velho Oeste, com as pessoas simplesmente passando seus cartões de crédito para ter acesso. A segurança era um problema e os gastos estavam fora de controle. Para controlar o caos, eles criaram uma organização de corretagem em nuvem.\n\nUma abordagem centralizada foi necessária para controlar custos, organizar e criar contratos empresariais com fornecedores, e configurar faturamento através de uma organização única. Em vez de usar cartões de crédito individuais ou criar seus próprios pedidos de compra, os grupos de negócios da Intel usam um pedido de compra mestre através do departamento de TI, que é então cobrado aos diferentes grupos. No geral, isso economiza dinheiro porque agora a Intel possui um poder de compra coletivo, incluindo oportunidades avançadas de economia de custos, como adquirir capacidade reservada em vez de pagar preços sob demanda.\n\nLevou um pouco de tempo para conseguir que todos aderissem à organização, com alguns ainda usando seus cartões de crédito para abrir contas. Para ajudar a amenizar isso, alguns provedores de nuvem forneceram à Intel um relatório de contas abertas com endereços de email da Intel. Em vez de encarar essas \"escapadas\" apenas como uma violação de política, foi uma oportunidade de educá-los sobre os benefícios de usar a conta central da Intel: padrões de segurança já estabelecidos, suporte empresarial, treinamento e eficiência de custos.\n\nAlém desses benefícios, a Intel também construiu um Centro de Excelência em nuvem, um fórum comunitário que eles pedem às pessoas para participarem quando obtêm suas contas na nuvem. Seu crescimento tem sido orgânico, fornecendo informações e feedback aos membros.\n\nMuitos desenvolvedores e outros que usam a nuvem apenas desejam utilizá-la sem ter que se preocupar com a segurança ou custos, por exemplo. Ter uma equipe de corretagem de nuvem permite que eles façam isso. Uma analogia é que a equipe de TI coloca o desenvolvedor em um parquinho com todos os brinquedos, mas não permite que ele espalhe areia para fora ou brinque com os brinquedos do lado de fora. Isso fornece à comunidade de desenvolvedores contas e acesso seguros sempre que precisarem.\n\nExistem centenas de serviços disponíveis em provedores de nuvem pública, e eles estão sempre lançando novos serviços e capacidades. É difícil para os grupos empresariais terem ou manterem expertise em todos esses serviços. Uma equipe central de corretagem de nuvem, focada em nuvem pública e que acompanha os últimos serviços, pode oferecer orientação e conhecimento sobre onde alocar diferentes cargas de trabalho. A chave para a corretagem é que as pessoas estão se dirigindo a um funil central e sendo redirecionadas para os serviços corretos.\n\nNão é apenas útil ter uma equipe dedicada de corretagem de nuvem, mas pessoas dentro da equipe que se concentram em provedores de nuvem específicos. Por exemplo, na Intel, à medida que atingiram uma massa crítica e os provedores de nuvem amadureceram e começaram a oferecer uma grande quantidade de serviços, Kevin se concentrou no AWS e Dave se concentrou no Azure para se aprofundar em cada um deles.\n\nUsar várias opções em nuvem em vez de apenas uma foi uma decisão natural, já que os grupos empresariais ingressaram com preferências e cargas de trabalho diferentes se saem melhor com provedores diferentes. As diferenças entre os provedores eram mais distintas no passado. Agora, o campo está mais nivelado.\n\nUm intermediário de nuvem não é apenas alguém em uma posição técnica, mas um faz-tudo. Dave e Kevin se tornaram especialistas em tudo relacionado à nuvem, como segurança e redes, e eles educaram essas equipes à medida que expandiam seu escopo de ambientes locais para nuvem pública. Ao ter uma equipe central de nuvem, as outras organizações da Intel puderam se educar, expandir e crescer. A equipe foi apelidada de \"O Cola\" devido ao seu papel central e variado.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Kevin Bleckmann","Dave Shrestha"],"link":"/episode-EDT56-pt","image":"./episodes/edt-56/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, parte um de dois, Darren e os Arquitetos de Soluções em Nuvem da Intel Dave Shrestha e Kevin Bleckman falam sobre a importância de uma organização intermediária de nuvem. Dave e Kevin fundaram a equipe de intermediação em nuvem da Intel há cerca de sete anos. Os trabalhadores da Intel estavam consumindo a nuvem pública, e era como o oeste selvagem, com pessoas simplesmente passando seus cartões de crédito para ter acesso. A segurança era uma questão, e os gastos ficaram fora de controle. Para colocar ordem no caos, eles criaram uma organização intermediária de nuvem."},{"id":129,"type":"Episode","title":"Organização de Corretor de Nuvem - Parte 2","tags":["cloudbroker","change","people","process","compute","organizationalchange","multicloud"],"body":"\r\n\r\n# Considerações para Seleção de Nuvem\n\nSete anos atrás, quando Dave e Kevin começaram pela primeira vez a equipe de corretores de nuvem da Intel, havia algumas diferenças significativas entre os provedores de serviços de nuvem, como disponibilidade regional, mas agora, com maturidade, as diferenças são menores. Alguns provedores se especializam em áreas específicas como inteligência artificial e aprendizado de máquina ou serviços de banco de dados gerenciados, e existem fatores de custo, mas eles são mais semelhantes do que diferentes. Provedores de nuvem, de modo geral, estão se tornando cada vez mais um serviço público à medida que amadurecem.\n\nA segurança é boa e bastante padrão entre os provedores de nuvem. Anteriormente, a Intel utilizava produtos de terceiros externos para gerenciar a segurança dos serviços de nuvem. Os provedores de nuvem agora incorporaram grande parte dessa segurança em suas plataformas, e a Intel passou a usar mais componentes integrados. Ainda há muito trabalho a ser feito nessa área. Em alguns casos, você ainda precisará cuidar da segurança por conta própria, mas os provedores estão indo na direção certa. Usar ferramentas integradas não é a opção mais fácil para novas empresas, pois não é totalmente gerenciado, mas uma vez que você adquira as habilidades e a maturidade necessárias, pelo menos as ferramentas são fornecidas.\n\nA gestão de custos ainda é uma arte; muitas pessoas ficam chocadas com a primeira fatura da nuvem. Embora existam ferramentas integradas que ajudarão, consultores e calculadoras de nuvem pública, existem alguns custos ocultos. As taxas de entrada e saída são provavelmente a maior surpresa, seguidas pelo provisionamento excessivo. A Intel possui um otimizador de nuvem, alimentado pelo Densify, que ajudará a identificar recursos superprovisionados e recomendar, por meio de análises detalhadas, quais são os tamanhos e famílias de instâncias mais ideais.\n\nAlgumas cargas de trabalho devem permanecer no local, especialmente para grandes empresas como a Intel, que possuem um grande centro de dados local. A equipe de corretagem em nuvem possui uma ferramenta interna chamada ferramenta de framework de decisão que pode ajudar a colocar a carga de trabalho certa no lugar certo, e às vezes, no local é a melhor solução.\n\nConsideração de carga de trabalho para colocação em nuvem pública\n\nSem uma ferramenta para fazer a determinação, existem cinco áreas a serem consideradas.\n\nSegurança: Certifique-se de conhecer os provedores de identidade, criptografia, conformidade e opções de login único. Esses são os mesmos itens com os quais você lidaria normalmente no local. Em vez de ferramentas separadas, é melhor ter ferramentas que abrangem tanto o ambiente local quanto a nuvem pública, para que suas equipes não precisem aprender novamente ferramentas separadas.\n\nPrivacidade\n\nEstabilidade da carga de trabalho\n\nA afinidade de dados/gravidade de dados: Certifique-se de que seu provedor de nuvem tenha disponibilidade nas regiões que você precisa. Alguns provedores de nuvem têm zonas de disponibilidade, ou data centers, em todas as suas regiões, enquanto outros não têm. Além disso, se uma carga de trabalho está conectada a muitos sistemas no local, não faz sentido colocar essa carga de trabalho na nuvem pública.\n\nCusto: Ainda existem algumas diferenças nos custos entre os provedores de nuvem pública, especialmente com instâncias de computação grandes. Também leve em consideração os custos de saída de dados.\n\n## Como vender o seu serviço de corretor de nuvem.\n\nComprar o serviço de intermediário de nuvem pode ser difícil para alguns, como desenvolvedores acostumados a ter controle e instanciar qualquer exemplo que desejam. Também pode haver dores de crescimento. Quando as pessoas da Intel obtiveram suas contas pela primeira vez, se sentiram inseguras e então a segurança da informação enviou mensagens quando estavam fazendo algo errado e eles não necessariamente sabiam o que fizeram ou como corrigir. À medida que o serviço evoluiu e amadureceu, esses problemas se resolveram à medida que a equipe interveio para ajudar e depois implementou correções automáticas.\n\nAs pessoas perceberam que, no final, o serviço era um benefício porque fornecia uma maneira rápida e fácil de entrar na nuvem pública com todo o suporte necessário. Após um período, o serviço começou a se vender por si só.\n\nUm dos principais serviços que a equipe oferece é atuar como uma ponte entre os parceiros comerciais finais da Intel e os grupos de segurança da informação para neutralizar políticas de segurança excessivamente agressivas que criam inconveniência e muitos chamados. A equipe fornece o equilíbrio adequado que permite aos desenvolvedores liberdade suficiente para trabalhar dentro de uma estrutura segura e atender aos requisitos de segurança. Os corretores basicamente funcionam como mediadores entre a segurança da informação e os desenvolvedores.\n\nA equipe do intermediador de nuvem também oferece treinamentos ao trazer os provedores de nuvem para realizar oficinas. Esse benefício também surgiu do Centro de Excelência em Nuvem, onde as pessoas pediam treinamento em áreas específicas e, em seguida, a equipe negociava com os fornecedores.\n\nAlém dos fornecedores externos, a Intel utilizou equipes internas para demonstrar o que haviam feito com a nuvem pública, para que outras equipes pudessem utilizar esse conhecimento.\n\nAs equipes de corretagem de nuvem dentro das empresas podem oferecer uma variedade de serviços e benefícios, como segurança e eficiência de custos, especialmente à medida que os serviços de nuvem pública amadurecem, expandem e se tornam mais necessários para as operações.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dave Shrestha","Kevin Bleckmann"],"link":"/episode-EDT57-pt","image":"./episodes/edt-57/pt/thumbnail.png","lang":"pt","summary":"Na segunda parte de duas, Darren Pulsipher, Arquiteto-chefe de Soluções, e os Arquitetos de Soluções em Nuvem da Intel, Dave Shrestha e Kevin Bleckman, falam sobre os benefícios e serviços de uma organização de corretagem de nuvem."},{"id":130,"type":"Episode","title":"Compreensão dos Problemas da Borda ao Data Center","tags":["data","edge","compute","edgemere","edgetocloud","cybersecurity","technology","process"],"body":"\r\n\r\n## Integração de Missão\n\nExistem muitas partes móveis ao colocar capacidades em missão, especialmente no Departamento de Defesa, mas também nos hospitais de Assuntos de Veteranos, Segurança Interna, FDA e FEMA, por exemplo, e transferir os dados de dispositivos de borda de volta para estações terrestres e centros de dados regionais e corporativos. Os dados precisam ser utilizáveis ​​e confiáveis ​​para grandes fluxos de análises em fluxos de trabalho de IA e nas mãos dos analistas para tomar decisões com base nos dados brutos.\n\n## Controladores para o Edge: Latência, Largura de Banda, Segurança, Conectividade\n\nParte do quebra-cabeça é que os dispositivos de ponta se tornaram mais sofisticados e estão reunindo mais dados do que jamais poderíamos enviar para o 5G. As esperanças de que o 5G conquistasse todos os dados e os tornasse perfeitamente disponíveis para o datacenter nunca se concretizaram com os avanços dos dispositivos de IoT.\n\nUma das arquiteturas originais em torno da IoT foi desenvolvida pela Cisco, chamada de \"neblina\" (fog, em inglês). A ideia da neblina era que o datacenter conectasse a neblina aos dispositivos de borda, para que parte do processamento e conectividade ocorressem ali. Se a conectividade de rede for confiável e consistente, isso funciona bem, desde que haja largura de banda suficiente. No entanto, a quantidade de dados gerados atualmente nas bordas por essas organizações supera qualquer quantidade de largura de banda disponível.\n\nCom IoT, apenas uma parte dos dados é movida para o centro de dados, então, geralmente, o valor dos dados só ocorre quando eles são analisados lá. O problema é que o centro de dados não consegue armazenar e processar todos os grandes conjuntos de dados. Mesmo enviando para a nuvem, o problema não é resolvido, já que a nuvem não consegue processar todos os dados que estão na ponta. Portanto, queremos deixar de enviar todos os dados para o centro de dados para coletar o valor, e em vez disso, enviar o valor dos dados o mais próximo possível da ponta, diminuindo a quantidade de dados que retornam para o centro de dados.\n\nClaro, nem todos os dados podem ser transferidos para a borda; deve haver uma correlação entre diferentes dispositivos de borda. O valor precisa estar em um lugar mais centralizado, não necessariamente no centro de dados central, mas talvez em uma dessas névoas intermediárias ou centros de dados regionais. A chave é mover dados de forma inteligente e empurrar o valor dos dados o mais próximo possível da borda de maneira repetitiva e sustentável. Ao fazer isso, podemos reagir muito mais rapidamente à borda.\n\n## Camada física comum\n\nPara superar alguns desses problemas, primeiro precisamos de uma camada física comum. Isso significa que é comum desde o datacenter até as camadas de neblina até os dispositivos periféricos; há um modo de gerenciar e controlar os dispositivos e obter ajuda deles de maneira confiável e comum. Isso não necessariamente significa a mesma máquina, mas um dispositivo mínimo viável com uma interface comum. Outra vantagem da camada física comum é que, se você escrever código para um aplicativo, ele pode ser executado em qualquer lugar nesse ecossistema. A Intel possui algumas ótimas tecnologias para isso, como o oneAPI, que realiza grande parte do trabalho para que você possa escrever o código uma vez, compilar os binários para os diferentes tipos de dispositivos, enviá-lo para a camada física comum e ele será executado adequadamente. Em resumo, os benefícios são um modelo operacional comum, um modelo de segurança comum e um modo de operação de escrever uma vez e executar em qualquer lugar.\n\n## Infraestrutura Definida por Software\n\nA SDI (Infraestrutura Definida por Software) se aplica ao datacenter em nuvens privadas e públicas com suas APIs definidas por software. Com a SDI na borda, obtemos maneiras comuns de mover dados. Podemos provisionar recursos na borda do datacenter a qualquer momento e podemos mover dados dessa forma de maneira mais integrada.\n\n## Camada de Gestão de Informações Distribuídas\n\nPrecisamos ser mais inteligentes na gestão e classificação de dados, movendo os dados apenas para onde serão processados, seja na borda, em um datacenter regional ou na nuvem. Aspectos importantes são catalogar e reutilizar dados e se adequar às exigências de conformidade e segurança. O benefício dessa camada de gerenciamento de informações distribuídas é que você está enviando menos dados para o datacenter, movendo menos dados e proporcionando valor à borda.\n\n## Camada de Gerenciamento de Serviço\n\nPara realmente fazer com que o valor seja transmitido para a borda, precisamos ser capazes de implantar aplicativos na borda. É aqui que entra uma camada de gerenciamento de serviços, ou ecossistema de contêineres. Isso permite o envio de microserviços para a borda, a névoa, o datacenter ou a nuvem de maneira repetível e confiável. Se um datacenter regional, por exemplo, parar de funcionar, você não precisa depender dele para que a malha de serviços continue operando.\n\n## Camada de Serviço de Aplicação\n\nUma camada de serviço de aplicação coordena as diferentes aplicações para que seja possível criar fluxos de trabalho que gerem o verdadeiro valor comercial a partir dos dados. Apenas mover os dados ou processá-los através de um Motor de Análise não é o suficiente. Os dados devem ser transferidos do Motor de Análise para uma estação de trabalho de analista. Algumas ferramentas nesta camada incluem automação de processos robóticos e pipelines de DevOps. É também onde é possível aplicar segurança e conformidade na camada de aplicação.\n\n## Segurança e camadas de identidade.\n\nO aspecto-chave da camada de identidade é estabelecer confiança entre entidades que estão devidamente identificadas. Devemos entender quem está acessando o quê e quais dispositivos estão acessando quais dados, em que momento e onde. A identidade vai além do usuário típico e abrange a identidade de aplicativos, dispositivos de borda, de névoa, de datacenters e de nuvem.\n\nO irmão gêmeo da identidade é a segurança. Aqui temos detecção, remediação, criptografia e estabelecimento da raiz da confiança. Isso resulta em confiabilidade, dados confiáveis e conformidade. Agora, dados inteligentes podem ser enviados às bordas e depois populados no centro de dados, mas você não está movendo grandes quantidades de dados brutos, apenas o necessário de maneira segura.\n\n## Visão de Alto Nível.\n\nPara ter uma arquitetura bem-sucedida do edge para a nuvem, que seja repetível, todos esses elementos diferentes são necessários. Já vimos algumas organizações construírem uma arquitetura do edge para a nuvem especificamente projetada e, quando elas implantam uma nova capacidade nesse ambiente, ficam presas. Por exemplo, se eles codificarem os dados residindo no edge porque sempre irão processar no edge, ou no datacenter para um aplicativo que sempre processa no datacenter, isso resulta em rigidez. Isso também aumenta o tempo necessário para implantar novas capacidades, talvez anos em vez de meses. Se tirarmos as lições aprendidas com as implantações de aplicativos do edge para a nuvem repetidamente e começarmos a generalizar, rapidamente descobriremos que elas se encaixam em uma das camadas que identificamos.\n\nPara obter mais informações, consulte este artigo (inserir link) sobre a visão de alto nível dessa arquitetura de borda para nuvem. Não estamos prescrevendo o que cabe nessas caixas, mas a chave é entender os casos de uso que eles abrangem. Temos ideias sobre o que está em cada uma das camadas e estamos desenvolvendo ecossistemas para atender às necessidades exclusivas da sua organização dentro dessas camadas.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT58-pt","image":"./episodes/edt-58/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Intel, descreve os problemas comuns em arquiteturas de borda para data center que ele observou e discutiu com clientes do setor público. Ele apresenta a arquitetura ideal para resolver essas questões."},{"id":131,"type":"Episode","title":"Evolução da Privacidade de Dados","tags":["cybersecurity","data","dataprivacy","privacy","process","people","healthcare","sutterhealth"],"body":"\r\n\r\nDepois de se formar na faculdade de direito, Jeremy entrou diretamente no Corpo Jurídico da JAG para a Força Aérea dos Estados Unidos e serviu como oficial em serviço ativo por nove anos. Uma de suas responsabilidades era ser o gerente de registros de dois escritórios diferentes. Ele mudou seu foco para a área da saúde em sua última atribuição militar, atuando como advogado para hospitais no Nordeste. Após deixar o serviço ativo (ainda está na reserva), ele foi trabalhar como advogado em um hospital e agora está na Sutter Health.\n\nEmbora o quadro legal seja o mesmo para a privacidade de dados, existem algumas diferenças no governo e no setor privado: a abordagem, os objetivos e quais regulamentações se aplicam. No governo, a privacidade de dados significa manter os dados protegidos por meio da Lei de Privacidade; manter as coisas secretas em segredo. Embora existam exceções, assim como a Lei de Liberdade de Informação, os sistemas são projetados para proteger as informações, e não divulgá-las, por padrão.\n\nNa área da saúde, desde o HIPAA em 1996, o HITECH alguns anos depois e agora com o ONC, os dados estão sendo transmitidos para residências, para os dispositivos dos pacientes, e os pacientes podem permitir acesso a terceiros. \"Acesso apropriado\" provavelmente é uma descrição melhor do que \"privacidade de dados\".\n\nO movimento pelos direitos à privacidade é de ter mais acesso e mais controle por parte dos indivíduos. Como paciente, além de ter o direito às suas informações, você pode direcionar seu fornecedor de cuidados de saúde para entregá-las a um terceiro: um advogado, um amigo, outro profissional médico, etc. Um paciente também pode especificar um meio de divulgação em papel ou eletrônico, portanto, são muitos os direitos concedidos aos pacientes.\n\nEstes direitos para os indivíduos controlarem seus próprios dados não se limitam apenas à área da saúde. Podemos observar isso no movimento atual com o GDPR e nas leis recentemente aprovadas no Brasil, Canadá, China e alguns estados dos Estados Unidos, como Califórnia, Washington e Virgínia.\n\nConforme o futuro da privacidade de dados se concentra cada vez mais nos direitos individuais de acesso, isso mudará a forma como as organizações podem rastrear as coisas. Grandes empresas como o Google e o Facebook têm opções agora em que as pessoas podem limpar seus dados ou impedir que as empresas os vendam de várias maneiras. Dispositivos de rastreamento, como cookies tradicionais, não serão tão relevantes, então algo mais terá que ajudar os anunciantes direcionados.\n\nMuitos dados, é claro, como dados de emprego, já são regulamentados. O controle individual dos dados não é um direito absoluto; as empresas precisam de dados para poder funcionar, então elas poderão manter alguns, mas haverá uma maior regulamentação. Nos Estados Unidos, teremos mais complexidade e mais problemas antes de alcançarmos uma padronização. Temos 50 estados, cada um com suas próprias regulamentações.\n\nExistem tantas leis quantas definições de informações pessoais, o que pode gerar um conflito. Sutter, por exemplo, possui muitos hospitais no norte da Califórnia e algumas filiais no Havaí, Oregon e Utah. Sutter deve rotineiramente estar atualizado sobre as regulamentações desses estados, mas caso haja uma violação, então o estado onde os indivíduos afetados residem entra em jogo. Às vezes, as leis são escritas de forma que Sutter precise seguir a lei no local de residência dos pacientes, em vez do local do negócio, o que se torna complexo.\n\nÀs vezes, faz sentido terceirizar esses tipos de problemas, e uma indústria legal inteira está surgindo para ajudar as empresas a navegar pelas regulamentações de privacidade e segurança da informação.\n\nDo ponto de vista de TI, segurança de dados significa limitar quem tem acesso às coisas. Com privacidade de dados, significa abrir portas para acesso. Claro, há um processo de validação para quem tem acesso, mas existe um equilíbrio entre segurança e privacidade, o que pode criar muito trabalho tanto para o lado legal quanto para o operacional.\n\nOrganizações que desenvolvem qualquer tipo de aplicativos que lidam com os dados das pessoas precisam entender que as leis de privacidade são diferentes em cada país e em cada estado e as ramificações de usar e armazenar esses dados.\n\nJeremy, juntamente com as equipes de privacidade e segurança, está envolvido com as equipes técnicas, às vezes, desde a fase de design, para garantir que tudo esteja de acordo com as regulamentações. Por exemplo, ele irá conversar com a equipe responsável por construir os portais de pacientes para verificar se as coisas que eles desejam fazer estão de acordo com as regulamentações. Além disso, ele ajuda a responder perguntas sobre qual tipo de banco de dados seria o melhor ou se há um provedor de nuvem que pode ser configurado de acordo com as normas. Jeremy descobre que quanto mais se educa e recebe treinamento em aspectos técnicos, mais útil ele pode ser no processo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jeremy Harris"],"link":"/episode-EDT59-pt","image":"./episodes/edt-59/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções da Intel, discute o que a privacidade de dados realmente significa e sua direção futura com Jeremy Harris, Advogado Geral Auxiliar - Privacidade/Segurança da Informação, na Sutter Health."},{"id":132,"type":"Episode","title":"Gerenciando o teletrabalho em sua capacidade total","tags":["telework","remoteworker","vdi","mfa","cybersecurity","people","process"],"body":"\r\n\r\n## Modos de Operação do Teletrabalho\n\nOs modos de operação que vemos as pessoas trabalhando dentro do Departamento de Defesa e também no setor privado são os seguintes:\n\nDispositivo como terminal burro (VDI - Infraestrutura de Desktop Virtual)\n\n* Dispositivo como parte da rede interna (VPN - Rede Privada Virtual)\n\nDispositivo como um portal para serviços\n\nA maioria dos trabalhadores está utilizando vários modos de operação, portanto, diferentes tipos devem ser suportados através da infraestrutura.\n\n## Dispositivo como um terminal burro.\n\nNeste modo, o trabalhador tem seu desktop executando em um servidor no centro de dados e utiliza seu laptop para se conectar ao \"desktop virtual\". Basicamente, eles utilizam o laptop ou outro dispositivo como um terminal \"burro\". Existem alguns problemas com o VDI, incluindo escalabilidade, congestionamento de rede, latência e redundância. Devido a esses problemas, uma sessão de VDI pode ser bastante cara. No entanto, das três opções, o VDI é o mais seguro.\n\n## Dispositivo como parte da rede interna.\n\nEste modo é provavelmente o mais comum. O trabalhador conecta seu dispositivo à VPN para que possa trabalhar na rede como se estivesse conectado no escritório. Um benefício é a mobilidade, pois os trabalhadores podem conectar qualquer dispositivo, como um telefone, tablet ou laptop. Outro benefício é que pode haver diferentes segmentos de VPN para diferentes classificações de dados. Uma desvantagem é que os trabalhadores sempre precisam estar conectados para poder trabalhar. E embora não haja tanto tráfego de rede quanto em um VDI, ainda haverá algum congestionamento de rede à medida que os dados se movem.\n\n## Dispositivo como um portal para serviços\n\nMais pessoas estão se movendo em direção a esse modelo. O trabalhador usa seu dispositivo para se conectar a serviços na nuvem, públicos ou privados. O principal serviço que as pessoas estão usando é o Office 365, que permite que as organizações usem serviços em nuvem em vez dos seus próprios serviços, ou em conjunto com eles. Eficiência, desempenho e a capacidade de trabalhar desconectado em alguns momentos são benefícios. As desvantagens incluem a dependência de um terceiro... (Não tenho certeza de como terminar isso - adoção/migração e segurança)\n\n## Emergentes gargalos\n\nOs gargalos têm surgido à medida que o número de pessoas que trabalham em casa aumenta de 15% para mais de 85%. Para os dois primeiros modos de operação, a escalabilidade da VPN pode ser um grande gargalo. Largura de banda limitada também é uma grande fonte de gargalos. Uma solução para esses problemas é aproveitar os serviços em nuvem para aliviar a pressão. Em nível humano, as operações de TI e os serviços de suporte estão sendo sobrecarregados, já que os trabalhadores estão se conectando de casa pela primeira vez.\n\n## Escalabilidade de VPN\n\nExistem várias soluções de curto prazo para ajudar a aliviar esses gargalos. Priorizar o acesso do usuário pode ser eficaz, seja com base em horários ou prioridade da missão. A educação dos funcionários sobre a adaptação a esse ambiente é necessária.\n\nPara escalabilidade de longo prazo, as organizações devem migrar para soluções SaaS utilizando laptops como modo de portal.\n\n## Largura de Banda para Sites\n\nUma das melhores coisas que as organizações podem fazer no curto prazo é descobrir quantos usuários VDI você atualmente possui e ver se é possível movê-los para trabalhar na rede ou no modo de operação de ferramentas de colaboração. Isso reduzirá drasticamente a carga na largura de banda. Você também pode precisar aumentar as capacidades da sua rede após avaliar como seus usuários remotos estão trabalhando. A educação é, mais uma vez, uma parte essencial dessa mudança, para que os trabalhadores utilizem as melhores práticas, como desconectar da VPN quando não estiverem usando e configurar ferramentas de backup para operar durante os horários de menor uso. No longo prazo, sugerimos uma arquitetura de nuvem multi-híbrida que lhe dê a capacidade de aproveitar os provedores de serviços em nuvem para largura de banda de rede e capacidade de aumento, otimizando também custo e capacidade.\n\n## Escalabilidade de Serviços Hospedados\n\nPara auxiliar na implementação de arquiteturas escaláveis para fins de curto prazo, existem diversas ótimas referências, incluindo as arquiteturas de referência do Outlook Web Access (OWA) e VDI.\n\nNovamente, a longo prazo, recomendamos migrar para uma infraestrutura de nuvem híbrida múltipla para elasticidade, capacidade, desempenho preditivo, conformidade e segurança.\n\n## Operações de TI\n\nComo podemos expandir a equipe do help desk que provavelmente está sobrecarregada? Uma ideia é ter FAQs online para referência fácil dos trabalhadores. Soluções contribuídas pela comunidade de usuários que são moderadas pela equipe de TI também podem ser úteis. Idealmente, as organizações deveriam estar utilizando um sistema de gerenciamento de tickets para identificar gargalos e otimizar processos. Além disso, qualquer tarefa que possa ser automatizada para evitar tarefas repetitivas deve ser automatizada através, por exemplo, da automação de processos robóticos (RPA) ou scripting adicional. Uma solução a longo prazo poderia ser a implementação de Chat Bots de IA como um serviço de autoatendimento para o help desk de TI. Eles rapidamente filtram soluções online usando palavras-chave ou recomendam contato.\n\n## Conclusão\n\nNo final das contas, a Intel deseja ver as organizações sendo bem-sucedidas durante este momento difícil em que os trabalhadores estão migrando do escritório para o trabalho remoto e lidando com muito estresse. A Intel pode ajudar a indústria, o governo e os setores públicos. Temos silício que funciona em todos esses aspectos. Temos parceiros que fornecem soluções de hardware e software e, é claro, vendemos PCs e dispositivos para clientes que possibilitam o trabalho remoto.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tim Flynn","Pete Schmitz"],"link":"/episode-EDT6-pt","image":"./episodes/edt-6/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren, Tim Flynn, Almirante reformado da Marinha, e Pete Schmitz, Executivo de Contas da Marinha da Intel, falam sobre como gerenciar o crescimento explosivo de trabalhadores remotos devido à pandemia de Covid-19. Discutimos os diferentes modos que os trabalhadores podem usar para trabalhar remotamente e ainda assim serem produtivos: dispositivo como um terminal burro, dispositivo como parte da rede interna e dispositivo como um portal para serviços. Compreender esses modos de operação pode ajudar a encontrar gargalos que podem prejudicar a eficácia da sua equipe."},{"id":133,"type":"Episode","title":"Gerenciando riscos diante de ransomware","tags":["cybersecurity","ransomware","riskmanagement","process"],"body":"\r\n\r\nNos últimos anos, houve um aumento no número e na sofisticação de ataques cibernéticos. As três principais áreas de ataques recorrentes são ransomware, ataques à cadeia de fornecimento e violações de dados.\n\nOs ataques têm se tornado mais sofisticados por várias razões. Primeiro, à medida que a segurança melhora, o adversário deve continuar melhorando. O crime organizado, atores de estados-nação e outros agentes de ameaças reconhecem que é necessário mais sofisticação para comprometer e frustrar os controles de segurança. Assim como as organizações têm processos de desenvolvimento de software, a comunidade de malware também possui. Eles possuem ferramentas e estruturas de onde constroem e incorporam qualidade aos seus sistemas. Diferentes participantes compram, vendem e emprestam código. Eles aprendem uns com os outros e compartilham informações na web clandestina. Eles não são apenas equipes improvisadas de hackers; eles funcionam mais como empresas.\n\nEsses agentes de ameaça estão em uma indústria de bilhões de dólares. O grande dinheiro impulsiona a necessidade de maturidade. Já não podemos apenas adicionar segurança; ela deve ser incorporada e incorporada em todos os lugares, não apenas nos produtos, mas também na infraestrutura e nos processos. Essa foi uma das lições do SolarWinds: mesmo se você construir um bom produto, a infraestrutura que o suporta pode ser vulnerável.\n\nAtaques recentes mostram que ninguém está imune. Muitas vezes, as organizações erroneamente presumem que estão protegidas por não serem serviços financeiros, governamentais ou de outras indústrias de alto valor, mas os ataques recentes às empresas como JBS Foods, McDonald's e Audi têm mostrado que ninguém está imune. Empresas, independentemente de seu produto, dependem de sua infraestrutura digital para estar funcional; o ataque à JBS Foods prejudicou a maior indústria frigorífica do mundo.\n\nNenhuma coisa serve como bala de prata para prevenir esses ataques. Há esperança, mas exige muito trabalho. Uma organização deve ter a diligência de aplicar as métricas de risco corretas para implementar corretamente a segurança. Se você não compreender o seu risco, nenhuma quantidade de controles de segurança fará o trabalho, pois você não sabe se os está aplicando no lugar correto.\n\nA chave está em começar com o conjunto correto de políticas e riscos para a sua organização. Um passo básico é que, mesmo que sua organização ainda não tenha descoberto completamente como implementar uma arquitetura de confiança zero, negar todas as solicitações de acesso até que se prove que são dignas é um passo na direção certa. O que isso significa é que há um portão em cada porta, em vez de uma chave mestra para tudo dentro. Negar por padrão é um princípio fundamental da confiança zero.\n\nSe a força de uma empresa não está em cibersegurança, ou os recursos não estão disponíveis para uma equipe interna suficiente, existem muitos recursos para ajudar. Provedores de segurança gerenciados (MSP) são uma boa opção, mas sempre deve haver pelo menos um especialista interno: um Chief Security Officer. Essa pessoa possui o contexto local da experiência no domínio para trabalhar com o MSP e trazer esse conhecimento e proliferá-lo por toda a organização. O MSP está gerenciando suas ferramentas e configurações de segurança, mas você precisa de alguém para transmitir sabedoria de segurança para as unidades de negócios e de TI. Diante dos ataques recentes, uma equipe de segurança não é opcional.\n\nToda empresa deve ter um plano pronto para um ataque de ransomware. O momento de descobrir como lidar não é depois que já ocorreu. Uma das medidas básicas é fazer backups regulares dos seus dados. Mantenha cópias perfeitas dos dados, sistemas, aplicativos e configurações em um ambiente de armazenamento offline e fora de banda. Ter seis meses de backups limpos é importante, pois às vezes o ransomware pode estar escondido nos backups antes de ser detectado. Além disso, tenha as plataformas ou servidores necessários para executar seu banco de dados disponíveis offline, para que você possa ativá-los em um modelo de redundância ou fallback.\n\nIsso é basicamente um planejamento de continuidade dos negócios. Assim como uma organização teria um plano de continuação no caso de um desastre físico, como uma enchente ou queda de energia, também deve haver um plano para continuar com as aplicações empresariais críticas para retornar pelo menos parcialmente às operações enquanto o problema está sendo resolvido.\n\nUm passo para concretizar essa redundância é poder recorrer à nuvem quando necessário, mantendo os recursos em nuvem em estado imaculado e talvez até em um provedor de serviços em nuvem diferente. Outro passo é ter um canário na mina. Isso significa ter sistemas implantados em toda a empresa que possuem sensores maximizados. Para evitar problemas de desempenho, armazenamento e velocidade, você pode implantá-los em locais estratégicos, em vez de em todo o sistema, para servir como alertas antecipados.\n\nCriar um plano antecipadamente também ajudará no desafio de saber o que fazer no momento da crise, seja pagar o ransomware ou chamar o FBI. O plano deve estar registrado e envolver não apenas suas equipes de tecnologia, mas também seus advogados, CEO, CFO, etc..., e todos devem ter acesso a ele. Você deve saber como comprar bitcoins e ter o número dos escritórios locais do FBI e outras informações. Execute o plano como um exercício para verificar se funciona assim como faria com um plano de recuperação de desastres ou continuidade de negócios.\n\nAlgumas indústrias podem pensar que estão seguras se mantiverem sua tecnologia operacional (OT) e sua tecnologia informacional (TI) separadas, mas elas não estão realmente separadas. Por exemplo, uma linha de produção pode estar funcionando em computadores, mas grande parte do que impulsiona a cadeia de suprimentos, logística e organização geral são sistemas de TI. Se esses sistemas falharem, nada entra ou sai. Os sistemas de TI são essenciais para a missão e o aprendizado com os ataques recentes é que dependemos da tecnologia digital para todos os nossos negócios.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT60-pt","image":"./episodes/edt-60/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, parte um de dois, Darren discute as tendências de segurança com o convidado frequente Steve Orrin, CTO da Intel, Federal. Ao longo do último ano, houve um aumento no número e na sofisticação dos ciberataques. As três áreas-chave de ataques recorrentes são ransomware, ataques à cadeia de suprimentos e violações de dados."},{"id":134,"type":"Episode","title":"Violação de dados e cadeia de suprimentos segura","tags":["datbreach","data","process","policy","cybersecurity","supplychain","securesupplychain"],"body":"\r\n\r\nAlém dos ataques de alto perfil na cadeia de suprimentos, como o incidente com a SolarWinds, existem outros ataques menos conhecidos que são igualmente problemáticos.\n\n## Cadeia de Suprimentos Segura\n\nUm exemplo é a extensão The Great Suspender para o Chrome, uma ferramenta para garantir que a memória seja usada corretamente em aplicativos do Chrome, com cerca de dois milhões de usuários. Os fundadores dessa ferramenta de código aberto venderam sua empresa para uma organização por milhões de dólares sem realizar a devida diligência. O comprador acabou sendo um grupo de crime organizado que transformou a ferramenta em malware e spyware.\n\nNão houve um ataque no sentido de que eles não invadiram a empresa original, mas a compraram e fizeram o que quiseram com o código. O que um dia foi um produto legítimo tornou-se ilegítimo no dia seguinte. Nenhum protocolo de segurança resolveria esse problema. Agora, as empresas precisam verificar seus fornecedores e terceiros que as apoiam.\n\nO código aberto é uma bênção e uma maldição. A bênção é que, uma vez que é de código aberto, você tem acesso à fonte e pode analisá-la à vontade. A maldição é que ninguém tem tempo, energia ou expertise para investigar minuciosamente cada trecho de código aberto que está sendo utilizado. Códigos vulneráveis a malware, mesmo que não intencionais, podem ser introduzidos caso não sejam detectados pela comunidade, e às vezes isso não acontece por muito tempo.\n\nExistem duas coisas que poderiam mitigar esse problema: uma é que o código poderia passar por uma ferramenta de análise de código-fonte e poderia haver um sistema de classificação para os contribuidores de código cujo código consistentemente vem com menos vulnerabilidades ou bugs. Terceiros fornecedores fariam principalmente esse trabalho. Em segundo lugar, já existem algumas startups bem estabelecidas no espaço de verificação de produtos de código aberto para mostrar quais objetos em um repositório são confiáveis e quais ainda não são confiáveis.\n\nOs atuais scans de vulnerabilidade em código aberto são um controle, mas esse tipo de segurança por si só não é suficiente. É necessário combiná-lo com controles adicionais antes de implementá-lo em toda a sua organização.\n\n## Violações de dados\n\nAlém de ransomware e ataques à cadeia de suprimentos, violações de dados são um problema comum. Em 2020, houve 1,8 trilhão de dólares em violações de dados extraídos em 7,8 bilhões de registros de dados. Uma violação no McDonald's, por exemplo, comprometeu dados de clientes, parceiros e internos.\n\n## Criptografia\n\nA primeira parte da solução é ter melhores ferramentas de segurança em dados e infraestrutura. Criptografar o acesso e incorporar a negação padrão, para que mesmo que alguém entre pela porta da frente, eles não tenham acesso a tudo, é crucial. Os dados também precisam ser criptografados dentro da organização, não apenas o que é exposto na nuvem ou o que você envia externamente. Qualquer dado que atravessa sua rede, assim como os dados em repouso, devem ser criptografados.\n\nA criptografia tem um custo, mas nos dispositivos modernos há aceleração incorporada que elimina a penalidade. Agora você pode habilitar a criptografia em toda a sua organização sem impacto no desempenho.\n\n## Segmentação\n\nOutra parte são enclaves, ou segmentação. Um dos desafios em ambientes corporativos de rede é que, mais uma vez, se alguém entrar pela porta, é livre acesso se tudo estiver conectado. Houve recentemente um movimento para separar o desenvolvimento e movê-lo para sua própria rede, e isso é um começo, mas é apenas a ponta do iceberg. A segmentação da rede deve ser em toda a organização. Você ainda pode ter comunicação transversal, mas estará sujeito a um conjunto de regras e ajudará a limitar o impacto. Por exemplo, se sua central de atendimento for atacada, seus sistemas de RH não serão comprometidos ao mesmo tempo.\n\nA microsegmentação era uma palavra da moda cinco anos atrás, mas precisa acontecer agora. Existem ótimas ferramentas disponíveis para ajudar com isso, como ecossistemas de contêineres, onde você pode implantar um aplicativo e ele está em sua própria rede com seu próprio firewall.\n\nImplementar credenciais de autenticação adequadas também precisa acontecer agora. A autenticação de múltiplos fatores é necessária, assim como a autenticação de entidades. Muitas ferramentas são automatizadas e possuem processos automatizados, portanto, as entidades, não apenas as pessoas, devem ter credenciais adequadas.\n\n## Zero Trust: Confiança Zero\n\nTraduza para o português: A abordagem Zero Trust amadureceu ao ponto de que deve ser implementada, e alguns dos princípios fundamentais, como negação padrão e não confiar em ninguém, são essenciais. A tecnologia alcançou o nível necessário para implantar esses tipos de conceitos.\n\nOs desenvolvedores podem se preocupar com essas ferramentas de segurança retardando o processo, mas existem maneiras de construir a arquitetura para amenizar esse problema. Por exemplo, se você é um desenvolvedor e possui credenciais e acesso adequados, deveria ser capaz de acessar as coisas de que precisa quando precisar delas e perder o acesso depois de terminar, em vez de ter uma credencial que lhe concede acesso a tudo o tempo todo. A ideia de confiança zero não é que a empresa não confie no desenvolvedor, mas sim que o acesso é para o momento certo, não apenas acesso total se um ator mal-intencionado roubar a credencial.\n\nNenhuma indústria pode se dar ao luxo de ignorar os riscos atuais. Toda organização deve olhar para a segurança de forma diferente e implementar segurança em toda a organização e arquitetura.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT61-pt","image":"./episodes/edt-61/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, discute violações de dados e cadeia de suprimentos segura com o convidado frequente Steve Orrin, CTO da Intel Federal."},{"id":135,"type":"Episode","title":"Desmistificando 5G, Edge e AI","tags":["edge","compute","5g","aiml","iot"],"body":"\r\n\r\nO background da Anna é no setor industrial e de manufatura em informação. Ela possui um doutorado em engenharia química, além de um MBA. Ela passou 15 anos trabalhando como engenheira de processo e design, posteriormente realizando trabalhos de startup e gerenciamento de engenharia. Ela está na Intel há pouco mais de seis anos, sendo os últimos dois anos e meio trabalhando na equipe do setor público, onde ela oferece suporte principalmente às atividades de IoT e edge da Intel, com um envolvimento cada vez maior na tecnologia 5G, já que o 5G, juntamente com a IA, está mudando drasticamente esse espaço.\n\n## Transformação de rede fundamental para a infraestrutura 5G\n\nNo mundo industrial, IoT não era algo novo; era apenas com fio. Com os sistemas agora migrando para a comunicação sem fio, eles possuem o acoplamento próximo de TI e OT para converter análises, em vez de apenas ter um conjunto de dados específicos do processo em que OT está presente. Um conjunto diferente de sistemas agora integra isso ao negócio, então tudo isso está sendo reunido no mesmo espaço. Embora haja diferenças muito definidas nos casos de uso e arquiteturas no setor público, como militares e cidades inteligentes, há uma convergência comum na análise, aplicação e prazo para tomar melhores decisões empresariais.\n\nUma das principais razões pelas quais a Internet das Coisas (IoT) demorou tanto para se expandir além da indústria manufatureira e adentrar outras áreas é, principalmente, o alto custo da fiação. A segurança também tem sido um obstáculo.\n\n5G está agora desencadeando o IoT e o mundo da beira (edge) devido à rentabilidade, especialmente do lado do consumidor. No entanto, quando se trata de infraestrutura crítica de negócios, é uma conversa diferente sobre como fazê-lo de uma maneira que proteja os dados. 5G será transformador, mas ainda não está acontecendo no lado comercial. Parte da lacuna é devido ao atraso entre a liberação das normas e a produção de hardware para aproveitar essas normas.\n\nPara qualquer pessoa que tenha passado muito tempo com o 3GPP ou outros órgãos de normas de condução, esse cronograma não é inesperado. No momento, é possível implantar uma rede 5G, mas estamos na fase de testes em que precisamos demonstrar o valor do 5G. Precisamos mostrar novos casos de uso que não podem ser suportados pelo LTE ou pelo 4G.\n\n## Múltiplos modelos de implantação 5G oferecem flexibilidade.\n\nPor que não ficar apenas com o WiFi 6 em vez de usar o 5G? A resposta é complicada. Muitas das organizações de padronização que impulsionavam o 5G também impulsionavam o WiFi 6, então é uma tecnologia complementar. O diferencial está no equipamento, então você precisa conhecer os detalhes dos seus casos de uso para determinar qual seria mais eficiente em termos de custo. Por exemplo, o 5G é incrível, mas não seria o melhor colocar uma rede 5G em um navio de cruzeiro porque a sua penetração não seria adequada. O ambiente não é favorável a nenhum tipo de sinal sem fio, mas o WiFi 6 com pontos de acesso faz mais sentido.\n\nO 5G é convincente, no entanto, por várias razões e pode fazer coisas que o 4G e o LTE não podem. Para realidade aumentada e virtual, você precisa de latência muito baixa e alta largura de banda para permitir casos de uso mais interativos, como reparo de equipamentos ou máquinas. Você precisa de um especialista remoto que esteja olhando para o problema e possa fazer streaming de vídeo e áudio com sobreposição de desenhos e capacidades que estão sendo gerenciadas a partir de um local central ou remoto que traz todo esse conhecimento e experiência diretamente até o ponto em que você está tentando trabalhar. Esse tipo de caso de uso não pode ser feito em uma rede LTE. A largura de banda desempenha um papel, mas a latência é a força motriz. Para não ficar doente enquanto usa um headset, é necessário ter latências muito baixas, sem atraso ou ter as coisas funcionando de forma assíncrona.\n\nO mundo LTE e 4G mudou por causa do 5G devido à forma como eles gerenciaram o espectro. Uma área onde isso está mudando na indústria é que agora é possível para uma empresa obter uma licença prioritária para o espectro do CBRS e estabelecer sua própria rede privada, completamente separada das principais operadoras federais de telecomunicações. Por exemplo, um grande fabricante pode cobrir um espaço enorme de forma mais econômica com uma rede LTE privada do que com pontos de acesso. Também existem grandes benefícios, como se você quiser reconfigurar seu espaço e não quiser que todas as suas estações de trabalho sejam conectadas por fio, ou se você precisar mover peças enormes de metal, como a fuselagem de um avião, em seu espaço que possa interferir nos sinais Wi-Fi, você pode estabelecer uma infraestrutura portátil e não fixa às localizações com fio.\n\nA segurança é uma preocupação central para qualquer organização. Embora o 5G não tenha sido desenvolvido com a segurança em mente, o 6G será. Felizmente, com as capacidades do 5G, podemos fazer muito em torno da rede de confiança zero e de outras medidas de segurança que irão instilar confiança nos clientes sobre como seus dados estão sendo transmitidos através das redes.\n\nAs normas 5G mudaram o problema de alguns anos atrás, quando a infraestrutura sem fio existia em hardware e software proprietários, com um espectro licenciado que apenas algumas empresas podiam pagar. A rede definida por software permite que a infraestrutura de rede seja hospedada em hardware comum e disponível no mercado. Não há necessidade de hardware especializado como nas gerações anteriores. Isso também está acontecendo no lado do LTE, por exemplo, ao disponibilizar o espectro CBRS e se afastar do hardware e software proprietários.\n\nA Intel dedica muito tempo trabalhando com disruptores que estão utilizando nossa arquitetura de referência FlexRAN. A arquitetura FlexRAN se torna a base para ajudar a disseminação de tecnologia disruptiva no novo mercado 5G, pois ela fornece uma pilha de software 5G rodando em hardware comum e disponível no mercado, onde antes era necessário hardware proprietário. Agora existe um espaço com muito mais abertura e portabilidade, e o custo de entrada é muito mais barato do que costumava ser. Não são mais apenas algumas empresas controlando tudo. A Intel e outras estão tentando abrir tudo e aproveitar os padrões abertos para apoiar todos esses disruptores e mudar toda a dinâmica.\n\n## Espectro 5G e Regulação para as Redes do Amanhã\n\nCom conectividade aprimorada, baixa latência e alta largura de banda, muitos novos casos de uso estarão disponíveis. Como o 5G será monetizado é o que está mudando no mercado. Por exemplo, um provedor de serviço em nuvem junto com uma operadora de telefonia podem fornecer serviços melhores para seus clientes porque não estão mais isolados. Eles são um esforço comercial combinado do que realmente importa: qualidade e priorização. Outra maneira de ver isso é que provedores de serviços em nuvem estão adquirindo capacidades que vão abrir funcionalidades de rede da mesma forma que as operadoras de telefonia estão explorando o que podem fazer no lado da nuvem. Novamente, isso ocorre porque o isolamento foi quebrado; o canal de dados não é mais um conjunto de serviços.\n\nNão está claro como tudo isso vai acontecer, exceto que está redefinindo o tipo de trabalho que você pode fazer por causa da acessibilidade aos dados e onde essas cargas de trabalho vão ser hospedadas. Existe um grande valor em ir do edge para a nuvem de forma transparente e fazê-lo de acordo com a necessidade do cliente, o que agora é possível.\n\n## Um novo paradigma de computação suporta novas demandas de dados.\n\nO 5G está desencadeando muitos modelos arquitetônicos diferentes. Por exemplo, ele oferece duas opções de arquiteturas para IA, enquanto antes havia apenas uma com limitações.\n\nSem a alta largura de banda fornecida pelo 5G, a IA estava limitada a inferências nos dispositivos de borda, o que exigia enviar os modelos de IA para esses dispositivos. Essa restrição complicada aumentou o ciclo de desenvolvimento e implantação da IA e limitou o número de cargas de trabalho de IA que podem ser aproveitadas na borda. Com o aumento da largura de banda, grandes fluxos de dados de câmeras ou sensores podem ser enviados de volta para um centro de dados, o que permite executar várias cargas de trabalho de IA e possibilita a aprendizagem contínua da IA. Isso dá às organizações a oportunidade de executar tanto inferências na borda quanto melhorar a aprendizagem profunda exigida pelas demandas sempre mutáveis de dados de tantas organizações.\n\nCom AR, por exemplo, 5G significa que os fones de ouvido podem ser móveis em vez de conectados com as mesmas capacidades, pois o 5G permite o compartilhamento de conjuntos de dados maiores em um mundo sem conexão. As barreiras tradicionais dos centros de dados estão sendo quebradas.\n\nSe você não tem muito suporte técnico ou conhecimento detalhado sobre como manter seus sistemas funcionando, você pode executar tudo na nuvem. Se você não quer seus dados na nuvem, você pode fazer uma versão que está localizada internamente em uma rede privada que lhe oferece todo tipo de funcionalidade para agregar e correlacionar dados, fornecendo um entendimento em alto nível do que está acontecendo em seu sistema de maneira segura e econômica.\n\nBasicamente, seus dados agora podem residir na borda, na nuvem, localmente ou no que a Cisco chama de neblina. Não importa mais onde sua aplicação é executada, assim você pode usar o modelo mais econômico. Em espaços industriais, por exemplo, há economias enormes em não ter um componente de cabeamento rígido, ou usando uma estrutura LTE privada em vez de pontos de acesso WiFi. A redução desses tipos de custos levará à capacidade de ter dados super ricos. Essas barreiras de custo e conectividade física são o que estava faltando para que a IoT decolasse como todos previam.\n\nAnna prevê que, para aplicações não controladas, os próximos dois anos serão diferentes devido ao 5G. Um exemplo simples é que na indústria, alguém poderia levar seu PC regular para fora do escritório e para o chão de fábrica e ser capaz de fazer tudo lá. O 5G mudará o que é possível em relação aos controles e ao controle de robôs e máquinas por meio de uma rede wireless nos próximos cinco anos. O próximo nível de transformação será que você poderá realizar o controle através de uma rede wireless e fazê-lo com segurança e eficácia, sem colocar ninguém em risco. Isso exigirá muita validação e revisão rigorosa, mas está no horizonte.\n\nTambém será empolgante ver o que seu provedor de serviços em nuvem favorito e sua operadora de telefonia irão fazer juntos para mudar o que é possível do ponto de vista dos serviços.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT62-pt","image":"./episodes/edt-62/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções da Intel, discute as mudanças inovadoras que o 5G trará para a borda e a inteligência artificial com a Dra. Anna Scott, Arquiteta-Chefe de Borda da Intel."},{"id":136,"type":"Episode","title":"Inspirando mudança cultural de TI.","tags":["organizationalchange","change","people","covid","cio","california"],"body":"\r\n\r\nAmy tem atuado como CIO estadual por mais de cinco anos, nomeada pelo Governador Brown e continuando sob o governo do Governador Newsom. Ela trabalhou como tecnóloga no setor público por vinte anos em várias áreas, desde ciências ambientais até CalPERS, saúde e serviços humanos, antes de ser nomeada CIO.\n\nEm 13 de março de 2020, Amy estava conduzindo uma reunião discutindo, ironicamente, a necessidade de acelerar o objetivo de serviços de banda larga para todos os californianos, quando o fechamento devido ao COVID foi ordenado. Logo em seguida, o estado teve que fazer a transição de mais de 200.000 funcionários estaduais para o trabalho remoto e implementar o ensino a distância. Da noite para o dia, a questão da banda larga tornou-se uma questão urgente para lidar com os negócios diários. O estado começou com 5% de capacidade para o trabalho remoto e em um mês alcançou 92% de capacidade.\n\nIsso foi o maior obstáculo operacional da pandemia. As pessoas tiveram que se acostumar a trabalhar remotamente e houve uma escassez de suprimentos, o que tornou ainda mais difícil. No entanto, toda a mudança ocorreu relativamente sem problemas. As pessoas foram compreensivas e flexíveis e permitiram que melhorias contínuas acontecessem.\n\nIsso é um processo que normalmente levaria anos para ser concluído. A diferença é que as pessoas não pensaram duas vezes em dizer \"isso é o que precisa ser feito\" e foram à ação em vez de analisar tudo exaustivamente. Todos simplesmente fizeram as coisas acontecerem, mesmo que não estivesse perfeito.\n\nA cibersegurança também foi um obstáculo, pois as pessoas que trabalhavam em casa precisavam seguir as mesmas boas práticas como se estivessem no escritório, e isso exigiu uma pequena mudança cultural.\n\nUma mudança surpreendente foi que o desejo de utilizar um processo de tomada de decisão baseada em evidências também acelerou da noite para o dia. Isso parece um pouco como um paradoxo já que nem tudo poderia ser superanal\n\nO estado ainda está aprendendo como será a força de trabalho no futuro. O teletrabalho permanece como uma perspectiva futura, e alguns podem se tornar permanentes devido ao aumento da produtividade. Além disso, os cargos que não se adaptam bem ao teletrabalho precisam retornar a um ambiente seguro. O bem-estar dos funcionários também é um fator na nova dinâmica.\n\nO governo e outras organizações precisam manter um equilíbrio entre os últimos 18 meses altamente táticos e o planejamento estratégico para o futuro. Amy mantém a visão estratégica no plano estadual de 2023 como o \"Ponto de Referência\", mas também se concentra em melhorias incrementais atuais para oferecer serviços. Existe um ambiente de compreensão de que as coisas não vão ser perfeitas à medida que o estado volta a uma nova normalidade.\n\nAmy tem dois objetivos culturais para o seu departamento decorrentes da pandemia: as pessoas em posições de suporte precisam ser capazes de relacionar seu trabalho às mudanças positivas e impactos para manter a moral elevada, e o ambiente deve se tornar mais visionário, lembrando os trabalhadores das metas estratégicas.\n\nPara manter uma mudança cultural positiva, os líderes devem ser o exemplo e levar em consideração o bem-estar dos funcionários em suas decisões. Isso inclui ser flexível com a maneira como eles trabalham melhor e dar-lhes confiança para tomar decisões que os façam se sentir realizados e empoderados. E se as coisas não saírem perfeitamente, sacudir a poeira e seguir em frente.\n\nO conselho de Amy para outros CIOs estaduais seria fazer muito trabalho de prova de conceito, arregaçar as mangas e experimentar coisas, e estar aberto a diferentes formas de resolver um problema. Os resultados da prova de conceito informam melhor os líderes na tomada de decisão do que apenas tentar analisar as coisas.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Amy Tong"],"link":"/episode-EDT63-pt","image":"./episodes/edt-63/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções da Intel, discute a inspiração da mudança cultural com Amy Tong, CIO do estado da Califórnia, após a pandemia de COVID."},{"id":137,"type":"Episode","title":"Seguir e Proteger a Conexão de Ponta a Nuvem","tags":["edge","compute","multicloud","cybersecurity"],"body":"\r\n\r\nNo episódio nº 2, Greg explicou as complexas questões de coleta, movimentação e análise de dados em um ambiente do Departamento de Defesa (DOD) que inclui dispositivos de borda em navios, aviões e até mesmo combatentes e a necessidade de movimentar e analisar esses dados rapidamente para decisões oportunas e acionáveis. O papel da Intel é ajudar a encurtar os ciclos do processo e aliviar gargalos no fluxo de dados com seu portfólio de tecnologia. Tudo se resume em combinar tecnologia com a missão.\n\nUma tendência recente na arquitetura é mover o cálculo, processamento e inteligência para frente, de forma a encontrar os dados, ao invés de mover os dados para a parte de trás. Esse ajuste oferece a melhor capacidade para obter respostas e inteligência em tempo real. Essa abordagem é um modelo operacional diferente, com questões desafiadoras.\n\n## Hardware heterogêneo\n\nNa infraestrutura fundamental, como você disponibiliza o correto cálculo, armazenamento, memória e capacidades de rede para impulsionar análises na borda e processar onde você precisa? Como você gerencia essas aplicações e dados? Como você introduz qualidade e curadoria de dados mais adiante na cadeia alimentar? Segurança é uma parte fundamental de qualquer infraestrutura, e agora, os dados devem ser protegidos desde a borda.\n\nA indústria precisa chegar a uma computação mais heterogênea para que o software subjacente possa ser executado em várias plataformas de hardware, de modo que você não fique preso a um software ou conjunto de hardware específico. Parte da beleza do que a Intel tem feito há anos é fornecer portabilidade de software: a estrutura aberta, x86 e outros sistemas subjacentes.\n\nUm fator importante no desenvolvimento das capacidades da Intel é entender a carga de trabalho e o fluxo de dados, em vez de focar na modernização, como colocar coisas na nuvem. Não se trata de como você adquire a TI (nuvem ou local) mas otimizar o fluxo de negócios para aproveitar como os dados fluem e o que eles realmente estão fazendo.\n\n## DevOps para o resgate\n\nOutro aspecto crítico dessas novas soluções é o tempo de implantação. O DevOps tornou-se cada vez mais importante em toda a DOD, e os esforços para desenvolver plataformas comuns de DevOps aumentaram dramaticamente. Para escrever código uma vez e executar em qualquer lugar (nuvem, local ou na borda), as organizações usam o chipset x86 e o oneAPI da Intel para implantar serviços complexos em todo o ecossistema completo. Por exemplo, o oneAPI permite que os desenvolvedores escrevam trabalhos complexos de análise ou IA que são executados em uma GPU, uma CPU ou até mesmo em FPGAs com a mesma base de código. Os desenvolvedores podem então testar esses sistemas complexos em seu centro de dados, assegurando que se comportarão da mesma forma quando implantados no campo, diminuindo o tempo de implantação.\n\nSer capaz de aproveitar uma combinação de um ambiente DevOps flexível, que utiliza a conteinerização e frameworks de software como o oneAPI, proporciona aos programadores a abstração de que precisam, mas com otimizações de hardware/software incorporadas. Uma distinção chave aqui é que descobrimos uma forma de aproveitar todo o poder do hardware e otimizar o software para que um aplicativo ainda possa ter melhorias de desempenho e aproveitar hardware especializado.\n\nO ecossistema de contêineres fornece abstração no nível do sistema, para que as coisas não precisem ser codificadas diretamente. Ele proporciona a capacidade de escalonar para cima ou para baixo com base na carga de serviço e capacidade. Por exemplo, se uma capacidade é executada na borda, em um centro de dados portátil ou de volta para a nuvem, e você perder conectividade ou um recurso, ainda é possível executar a missão. Essa conectividade intermitente é vital em um ambiente DOD.\n\n## Soluções Edge\n\nMuitas pessoas pensam na Intel como uma provedora de silício ou hardware, mas a empresa desenvolveu soluções e arquiteturas de referência no ecossistema da borda para a nuvem. Um exemplo de progresso é uma grade tática naval onde o processamento ocorre na borda, em navios, aeronaves e na costa. As aplicações precisam ser executadas em todo o ecossistema, e isso não pode ser feito apenas com hardware. A Intel aproveitou seus recursos de silício e segurança e, construindo em cima de um ecossistema de contêineres, produziu aplicações complexas com vários microsserviços que podem ser executados quando houver ativos conectados e desconectados.\n\nOutro exemplo de arquiteturas de borda é rastrear objetos através de malhas de sensores, mesmo com lacunas na malha de sensores. Ao realizar a fusão de sensores, fusão de dados e análise entre domínios, é possível rastrear objetos em diferentes cenas e diferentes tipos de sensores, ampliando e reduzindo a escala para criar uma plataforma de sensor móvel que possa realizar análises e fusões de detecção de borda. Em seguida, também pode ser transferido para um conjunto distribuído de nós que podem trabalhar em conjunto para rastrear um objeto em todos esses diferentes sensores existentes.\n\nPor exemplo, se você está rastreando um objeto e ele se move entre sensores, você o perderá por um momento. O que essa inteligência permite que você faça é conectar esses dois feeds e rastrear os pontos cegos. Isso não apenas funciona com tipos de sensores homogêneos, mas também pode funcionar com vários tipos de sensores, como sensores de movimento, RF e IR. Portanto, se você perder o vídeo, mas ainda tiver um RF e depois retomar o vídeo, poderá mostrar o caminho completo do objeto. No passado, esse tipo de análise exigia mover dados para o centro de dados para processar essas interações complexas; agora, podemos fazer isso na borda da malha de sensores por meio de microsserviços na borda.\n\n## Flexibilidade de Implantação\n\nUma abordagem vantajosa é construir uma vez e utilizar a mesma arquitetura e software para diferentes missões com requisitos analíticos. Alguns locais onde a computação pesada está na borda podem expandir e aproveitar ao máximo as capacidades de hardware. Outras plataformas podem ter capacidades de computação limitadas e podem executar microserviços menores, fornecendo apenas uma parte da solução completa. Novas capacidades e serviços de missão podem ser implantados rapidamente construindo esses microserviços uma vez para múltiplos casos de uso.\n\n## Segurança na Borda\n\nA complexidade às vezes é o pior inimigo da segurança, mas os princípios fundamentais de segurança também podem proteger dados e aplicativos na borda. Em vez da abordagem antiga de proteger o servidor e esperar que tudo fique lá, é essencial entender para onde os dados fluem e todos os lugares onde eles existem, protegendo-os, não importa em que estão sendo executados. Abordagens baseadas em riscos e conceitos como confiança zero ganharam destaque porque adotam uma visão independente dos sistemas de segurança.\n\nResumidamente, zero trust significa negação padrão. Ninguém entra a menos que precise e apenas pelo tempo necessário para a ação necessária. Quando os controles de acesso temporais são combinados com uma abordagem baseada em risco para proteger os dados ao longo de seu ciclo de vida, o resultado é a capacidade de proteger os dados independentemente de onde eles estejam e quem esteja acessando. Essa técnica é uma das formas de garantir a segurança desses ambientes altamente complexos.\n\nA ação prática a ser tomada nesses ecossistemas é aplicar uma política que alavanque controles que atendam ao risco de um determinado sistema em um determinado momento e, em seguida, monitorá-los e atualizá-los continuamente em tempo real para enfrentar o mundo de ameaças cibernéticas em constante mudança. Utilize os controles técnicos que as capacidades de hardware e software já proporcionam, tais como o Secure Boot, a raiz de confiança no hardware com módulos TPM ou chaves de armazenamento SGX, criptografia, etc.\n\nNão existe uma solução milagrosa que possa ser comprada para fornecer uma solução de segurança final nesses ecossistemas complexos. Trata-se de criar e aplicar políticas de segurança conforme as ameaças evoluem e implementá-las em grande escala, aproveitando hardware, software e processos necessários para proteger o dado à medida que ele flui desde a borda até todo o ecossistema.\n\nO framework DevOps fornece mecanismos eficazes para lidar com a segurança em todos os ativos do ecossistema. Os contêineres devem ser preenchidos com instrumentação para impor os controles e políticas de segurança. A segurança deve ser incorporada ao próprio processo DevOps, porque se você depender do desenvolvedor para implementar a segurança, cada um fará isso de maneira um pouco diferente, aumentando a complexidade e a variabilidade no sistema. O desenvolvedor deve ter as capacidades e as restrições sobre as quais deve desenvolver.\n\nOs desenvolvedores ainda terão que realizar trabalhos de segurança, como garantir que utilizem ferramentas de segurança adequadas para o ambiente de ameaças específico, mas o trabalho pesado, a complexidade, deve ser abstraído na arquitetura do DevOps.\n\nUma das áreas críticas em um ambiente teatral complexo é o gerenciamento de dispositivos de borda, como monitoramento e atualização de firmware. Garantir que esses dispositivos sejam seguros para poderem oferecer suporte à segurança de dados e aos perfis e políticas implementados nos sistemas em grande escala exigirá inovação. É por isso que o ecossistema está crescendo atualmente: para enfrentar esse desafio.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Clifton","Steve Orrin"],"link":"/episode-EDT64-pt","image":"./episodes/edt-64/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Intel, fala sobre acompanhar o episódio com Greg Clifton, Diretor, Departamento de Defesa e Inteligência, Intel, em uma continuação do episódio #2, juntamente com Steve Orrin, CTO Federal, Intel, que empresta sua experiência em segurança em ambientes complexos de borda para nuvem."},{"id":138,"type":"Episode","title":"Acelerando a adoção da nuvem ao mesmo tempo em que diminui a complexidade e os custos.","tags":["cloudmigration","cloud","compute","process","multicloud","aiven","cloudcost","technology"],"body":"\r\n\r\nDavid era anteriormente um desenvolvedor de aplicativos e se descreve como um \"recuperador de excesso de engenheiros\". Essa experiência, juntamente com seu trabalho com a AWS e GCP em diferentes empresas, dá a ele o conhecimento necessário para entender as nuances de como operar na nuvem, como escalá-la quando faz sentido financeiramente e como lidar com muitos desafios ao migrar para a nuvem.\n\nMuitas organizações estão migrando para a nuvem, aceleradas pelas consequências da pandemia de COVID. Grandes e pequenas empresas estão fazendo isso de maneiras diferentes. As empresas menores estão migrando para a nuvem e adotando-a o mais rápido possível, utilizando novas ferramentas e melhores práticas, mas ainda há muita migração direta no centro de dados. No entanto, durante essa migração direta, muitas vezes elas não estão aproveitando os benefícios da nuvem. Portanto, elas estão se movendo para serem transformadas digitalmente, mas precisam se perguntar \"quais são os próximos passos?\".\n\n## Reduzindo custos\n\nExistem muitas coisas que você pode fazer, e deve fazer, para reduzir custos e evitar surpresas desagradáveis, como os custos que acompanham as VMs zumbis. Na nuvem, se você precisar de um servidor, basta clicar em um botão e você o terá, mas se você esquecer que está em execução, um mês depois poderá haver uma cobrança de $10.000 nos servidores. Outra coisa a ser considerada é a saída de rede que pode se acumular, especialmente com transferências de região para região, se você estiver fazendo terabytes ou petabytes a cada mês.\n\nAlertas de gastos podem ajudar a mitigar esses problemas.\n\nProjeções de custo podem ser difíceis devido a questões como acesso gratuito, mas recuperar os dados é caro. Excluir dados também tem um custo. Portanto, as organizações precisam pensar nos cuidados de quanto dados colocar, no tipo de operação e no uso.\n\nPara otimização de custos, algo que a liderança de engenharia precisa pensar é que você irá chegar a um ponto onde a computação e serviços gerenciados não serão tão caros; o recurso mais caro são as pessoas. Portanto, como otimizar a eficiência dos seus desenvolvedores? Você não quer que eles façam tarefas repetitivas e remediais.\n\nA automação é essencial aqui, especialmente para qualquer tarefa repetitiva feita com alta frequência, assim como para serviços gerenciados.\n\nTraduzindo para o português: \n\nO ciclo de vida de cada empresa chega a um ponto em que eles precisam decidir se vão investir e possuir todas as operações ou contratar uma equipe de DevOps ou aproveitar os serviços de provedores de serviços gerenciados. Contratar especialistas internos é caro. O ponto crucial é quando eles decidem quão bem a nuvem se ajusta às suas necessidades. Geralmente, é melhor para as empresas considerar o custo total de propriedade, focar em suas vantagens competitivas e utilizar serviços gerenciados para outros serviços.\n\n## Reduzindo a Complexidade\n\nUma das complexidades da nuvem é que você precisa ser capaz de recriar seu ambiente com implantações confiáveis e repetíveis. Isso não significa que você está indo para o site e clicando nele; você está implantando seu ambiente a partir, por exemplo, de um script ou arquivo YAML ou TerraForm, e você precisa ser capaz de iniciar e encerrar rapidamente.\n\nVocê precisa ser capaz de desligar um servidor que se tornou sujo e recriá-lo de forma confiável em um estado limpo. Se alguém mover arquivos de registro, ajustar configurações, apagar um banco de dados por engano ou se houver um ataque de ransomware, você precisa ser capaz de reproduzir seus ambientes ou componentes do seu ambiente para reduzir o tempo de inatividade.\n\nA peça crítica é ter um plano em prática com base em quão rapidamente você precisa se recuperar e quanta dados precisa continuar. Faz sentido para algumas indústrias investir em um plano para se mudar rapidamente para uma região diferente. Você precisa avaliar o quanto está disposto a investir em tempo de recuperação.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Esposito"],"link":"/episode-EDT65-pt","image":"./episodes/edt-65/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, parte 1 de 2, Darren conversa com David Esposito, Arquiteto de Soluções Globais, da Aiven, sobre acelerar a adoção da nuvem, reduzindo a complexidade e o custo."},{"id":139,"type":"Episode","title":"Gerenciando Complexidade na Nuvem","tags":["data","devops","compute","technology","process","devsecops","cybersecurity","aiven"],"body":"\r\n\r\n## Reduzindo a Complexidade.\n\nQuais práticas empresariais devem ser implementadas ao gerenciar ativos na nuvem para diminuir a complexidade? Primeiro, é necessário ter código de infraestrutura e implantações automatizadas estabelecidos. Tudo que vem depois é uma conversa para definir quais riscos existem para a empresa, como interrupções e períodos de inatividade, como mitigar esses riscos e quanto investir nisso.\n\nPara algumas empresas, é fundamental ter o mais alto nível de tempo de atividade. Na área da saúde, por exemplo, você pode precisar ter todos os dados de backup em várias localizações, assim como todos os serviços disponíveis, pois decisões críticas de salvar vidas podem depender desses dados. No entanto, se você está no comércio eletrônico em abril, talvez possa passar algum tempo naquela região doente, porque as consequências não são tão graves.\n\nNo setor de saúde, faz sentido adotar uma estratégia de multi nuvem, mesmo que isso aumente a complexidade. Outras indústrias que podem se beneficiar da multi nuvem são aquelas altamente regulamentadas, como serviços financeiros, petróleo e gás ou agências federais. Em caso de incidente de segurança, eles podem desativar uma nuvem e implantar em outro lugar.\n\nAo considerar o multi cloud, saiba que existem algumas complexidades com diferenças nas APIs. Se você estiver no GCP e souber como implantar tudo e estiver pensando em ir para a AWS, terá que reaprender a plataforma e o processo de implantação, talvez até mesmo escrevendo parte desse código. Por essa razão, a containerização é popular, pois você pode implantar em qualquer lugar. Isso se torna mais complexo com outros serviços; por exemplo, o Postgres tem configurações diferentes na AWS em comparação com o GCP, talvez com diferentes versões de atualização, diferentes configurações de rede e diferentes extensões. Portanto, um serviço em uma nuvem não é o mesmo que um serviço em outra.\n\nAlém disso, ambientes em container não são ideais para todas as situações, e uma situação ideal torna-se mais importante à medida que você escala. Se você está usando Kafka e enviando 1.000 mensagens por segundo, seu próprio container está bom. Mas se você está começando a enviar mais de um milhão de mensagens por segundo, um gigabyte, isso é uma conversa diferente.\n\n## Segurança\n\nA segurança na nuvem é diferente da segurança em seu próprio centro de dados. A coisa mais importante a se pensar é a proteção dos dados que saem das suas próprias fronteiras. É necessário ter controles de segurança apropriados para garantir que os dados não vazem ou tenham acesso não autorizado, e certificar-se de que os requisitos de conformidade estejam em vigor. Isso requer treinamento, pois as medidas de segurança para centros de dados internos não se traduzem diretamente para a nuvem. Por exemplo, os contêineres S3 são criptografados em repouso, mas não se você tiver acesso programático por meio de buckets expostos publicamente.\n\nAlém disso, é necessário saber o que os provedores de serviço estão fazendo. Por exemplo, a Aiven executa bancos de dados em GPUs EC2, GCP Compute ou Azure. Quando eles armazenam em disco, há uma camada de criptografia feita no nível da nuvem pelo provedor de nuvem, então os dados estão criptografados em repouso. Em seguida, a Aiven realiza outra camada de criptografia com suas próprias chaves gerenciadas, portanto, os dados estão duplamente criptografados em repouso e qualquer dado em trânsito está criptografado. Qualquer coisa enviada para o servidor é criptografada para aquele servidor específico, e quando um servidor é desativado, ele é bloqueado com a chave da Aiven, assim como a chave do provedor de nuvem.\n\n## Aiven\n\nDavid juntou-se à Aiven como parte da equipe de arquitetura de soluções quando ele viu que a empresa fazia soluções na nuvem melhor do que qualquer outra que ele tinha visto, com base em sua experiência anterior com Kafka gerenciado e outras tecnologias de código aberto. A missão da Aiven é tornar a vida dos desenvolvedores melhor. Eles oferecem um teste gratuito, com Kafka pronto para produção em cinco minutos. Eles também têm artigos de ajuda e tutoriais para orientá-lo, para que você possa enviar uma mensagem de Kafka na nuvem com as melhores práticas nativas da nuvem em menos de dez minutos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Esposito"],"link":"/episode-EDT66-pt","image":"./episodes/edt-66/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, parte 2 de 2, Darren continua sua conversa com David Esposito, Arquiteto de Soluções Globais, da Aiven, sobre acelerar a adoção em nuvem enquanto reduz a complexidade e os custos."},{"id":140,"type":"Episode","title":"5G Passado, Presente e Futuro","tags":["5g","comms","wifi6"],"body":"\r\n\r\nLeeland tem estado na indústria de telecomunicações há 20 anos. Logo após da faculdade, ele foi recrutado para trabalhar no Departamento de Defesa dos EUA, depois de terem ficado impressionados com seu trabalho na aplicação de multiplexação Bluetooth em um automóvel, reduzindo o tamanho do chicote de fios. Em vez de trabalhar com carros, como ele havia planejado originalmente, ele acabou trabalhando com o Departamento de Defesa no desenvolvimento de tecnologias sem fio avançadas para soldados.\n\nNaquela época, a tecnologia celular estava em transição do 2G para o 3G. Não era chamado de WiFi naquele momento, mas de LAN sem fio, e havia uma tecnologia incipiente chamada Bluetooth que eles estavam tentando usar para fornecer aos soldados a capacidade de reunir informações dentro do espaço de batalha.\n\nLeeland deixou o Departamento de Defesa três anos depois, a fim de fazer trabalho prático com a tecnologia para obter melhor compreensão. Ele começou a trabalhar para a Sprint e permaneceu na indústria de telecomunicações por 13 anos, projetando tecnologia para redes sem fio, antes de ingressar na Intel em 2017 para trabalhar com 5G.\n\nAté meados da década de 90, havia pouco uso de telefones celulares. Os telefones \"tijolão\" dos anos 80 eram enormes devido ao tamanho da bateria e eram caros. Eles evoluíram para os telefones \"bolsa\" no início dos anos 90, que eram melhores, mas você só tinha esperança de que eles funcionassem para fazer uma ligação.\n\nConforme o 2G entrou em cena, novos recursos baseados nas demandas dos clientes foram desenvolvidos, como transmissão de texto e jogos. O dispositivo poderia realizar transmissões de dados em baixa taxa com tecnologias como TDMA (acesso múltiplo por divisão de tempo) e GSN, por exemplo. Na metade dos anos 90, empresas como a Sprint entraram no mercado e o uso de celular se tornou mais amplamente difundido. No início dos anos 2000, houve uma transição significativa com a expectativa dos clientes de que a internet também estivesse disponível nos telefones, assim como nos laptops.\n\n3G trouxe capacidades nominais de banda larga onde você poderia usar a internet de certa forma, mas a principal capacidade era a transmissão de imagens. O nome \"3G\" foi cunhado nessa época, e é quando o corpo de normas 3GPP entra em jogo.\n\nEm 2008, as empresas de telecomunicações começaram a analisar a implantação de uma infraestrutura que não se baseava em grandes torres de células, mas sim em um sistema mais distribuído de um centro de unidades de banda base com antenas transmitidas via fibra óptica para postes telefônicos. Isso marcou o início da transição para a verdadeira banda larga, do 3G para o 4G.\n\nEsta tecnologia deve receber crédito pelo boom econômico de 2010 a 2020, porque com o 4G em mãos, empresas como Amazon e Netflix evoluíram e prosperaram.\n\nO 5G liberta os serviços de uma \"prisão\" monolítica RAN e abre o campo porque o 5G fornece arquiteturas de código aberto com uma base definida por software. Agora é possível desenvolver e integrar pilhas de software em uma solução completa de software. Como não está vinculado a uma arquitetura monolítica, o 5G pode fornecer serviços e redes privadas independentes.\n\nEssa enorme flexibilidade vai permitir que as empresas de telecomunicações e seus provedores de serviços aprimorem os serviços e ofereçam diversas novas capacidades, incluindo trazer acesso a computação de borda.\n\nO que está por vir? Leeland vê um movimento afastando-se do \"G\", pois não dá crédito suficiente para a evolução da tecnologia, uma vez que não há mais divisões reais em termos de quem pode implantar redes. A tecnologia e os casos de uso são amplos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown"],"link":"/episode-EDT67-pt","image":"./episodes/edt-67/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções da Intel, conversa com Leeland Brown, Diretor Técnico de 5G da Intel Federal, sobre o passado, presente e futuro do 5G, com ênfase em seu uso pelo Departamento de Defesa. Parte 1 de 2."},{"id":141,"type":"Episode","title":"5G na Defesa","tags":["5g","dod","compute","technology","cloud","edge","comms"],"body":"\r\n\r\nNo início do século, o Departamento de Defesa estava procurando maneiras de aplicar tecnologias 2G, LAN sem fio e Bluetooth em aplicações para permitir que os soldados capturem informações no campo de batalha. Em 2021, essas capacidades ainda estão sendo procuradas. O Departamento de Defesa está analisando intensamente o 5G agora, pois se afastou de construções monolíticas, como utilizar uma única arquitetura RAN, e passou para arquiteturas definidas por software. Existe flexibilidade para construir novas capacidades mais rapidamente e escalá-las para diferentes casos de uso.\n\nO lado comercial do 5G é impulsionado por estratégias e pelo aumento da receita em desenvolvimento. Isso não necessariamente está alinhado com os requisitos da missão do governo federal ou do Departamento de Defesa, então as fronteiras entre esses dois mundos estão se tornando turvas, como por exemplo, quando a AT&T e a Verizon analisam casos de uso federal, ou quando a Lockheed Martin, com o seu programa 5G Domino, olha para o espaço comercial. A diferença está em quem compreende a missão e quem está conduzindo com o objetivo de gerar receita.\n\nAtualmente, noventa por cento das implementações comerciais de 5G são redes não independentes, o que significa que o 5G ainda está conectado a uma infraestrutura de pacotes evoluída 4G existente. O Departamento de Defesa está interessado em redes independentes com um core 5G completo, RAN 5G e dispositivos 5G. Pode haver uma rede independente para um grupo de soldados, juntamente com estações de base em formato pequeno para plataformas veiculares, e vários domínios protegidos, até mesmo drones implantados com algum tipo de ponto de acesso 5G e aplicações espaciais.\n\nEssa capacidade de se adaptar a vários casos de uso e seus diversos tipos de cargas de trabalho também é aplicável ao lado comercial. No entanto, um dos maiores problemas é de quem é a titularidade da frequência. Algumas faixas de espectro livre estão disponíveis com alcance limitado, mas essas bandas, como as bandas ISN, não possuem licença e são muito congestionadas. A regra é que você deve fornecer e aceitar interferência e fazer sua tecnologia trabalhar em torno disso, mas o compartilhamento dinâmico do sistema é possível. No entanto, para casos de uso federal, você não pode ser impedido de realizar operações nos EUA, já que a maioria dos soldados é implantada fora dos EUA.\n\nLeeland prevê que o 5G se tornará integrado à vida de todos, às vezes quando nem mesmo percebemos. Plataformas de reconhecimento de padrões, como reconhecimento facial e veículos autônomos, estarão todos conectados via 5G. Seu acesso à banda larga será integrado em uma estrutura contínua, conectada além do seu celular, indo até seu carro e sua casa. A necessidade de um telefone na mão reduzirá drasticamente à medida que começarmos a ver pontos de acesso sem fio em todas as partes de nossas vidas.\n\nLeeland também prevê que o \"G\" desaparecerá à medida que a tecnologia se expande e evolui.\n\nPara aprender mais sobre 5G, os tecnicamente inclinados podem ir aos padrões do 3GPP para ver os casos de especificidade. Você pode ler uma especificação e entender a diferença entre a versão 14 e a versão 15, e o que isso significa para a indústria como um todo. Há também muitas informações disponíveis pela internet, como white papers. Leeland também se oferece como ponto de contato.\n\nLeeland gostaria que o próximo passo fosse um chamado para ação para tornar as redes mais resilientes por meio da adoção de novas tecnologias. Durante emergências, seja desastres naturais ou ataques terroristas, a resiliência é necessária para os socorristas, assim como para pessoas que estão apenas tentando entrar em contato com suas famílias.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown"],"link":"/episode-EDT68-pt","image":"./episodes/edt-68/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções, Intel, continua sua discussão com Leeland Brown, Diretor Técnico de 5G, Intel Federal, sobre 5G passado, presente e futuro, com ênfase em seu uso com o Departamento de Defesa. Parte 2 de 2."},{"id":142,"type":"Episode","title":"Garantindo a segurança do centro de dados através da borda","tags":["cybersecurity","edge","compute"],"body":"\r\n\r\nUma visão holística da segurança inclui toda a infraestrutura, desde o ambiente na nuvem até a borda. Se você não consegue proteger o cliente, não consegue proteger a empresa, então é essencial ter conversas honestas de forma acessível, sem jargões, sobre segurança.\n\nForam-se os tempos em que um funcionário recebia um laptop enviado para uma gaiola de TI, depois configurado e entregue pela área de TI. Às vezes, os funcionários nem chegam a ir ao local de trabalho, então os dispositivos precisam aparecer na porta de alguém. Eles devem ser provisionados para garantir que estejam seguros e não tenham sido violados. Do ponto de vista de segurança, esse é um problema desafiador. A cadeia de suprimentos é problemática. Há menos controle sobre os dispositivos e como eles são implantados.\n\nA mudança repentina para o trabalho em casa devido à pandemia de COVID exigiu uma resposta rápida e sem precedentes a esse problema. Se tivesse sido uma progressão natural, poderia ter levado anos, mas a situação não permitia alternativa; a área de TI teve que estar à altura da ocasião.\n\nQuando Camille trabalhava no grupo de IoT, eles tentaram resolver a conectividade e a gestão entre dispositivos. Ecossistemas complexos, como parques eólicos, minas subterrâneas e dispositivos médicos implantados, são difíceis de atualizar quando a conectividade é esporádica. Eles estavam tentando resolver esses problemas de conectividade na borda e, quando a COVID atingiu, a interseção entre OT e TI se tornou repentinamente o centro de todos os departamentos de TI empresariais.\n\nComo alguns dos clientes de Darren estavam enfrentando dificuldades para conectar adequadamente a tecnologia operacional e a tecnologia da informação, a COVID chegou e uma parte disso desabou, resultando em violações de segurança.\n\nMuitas pessoas implementaram rapidamente um sistema de trabalho remoto e lidaram com a segurança depois, dependendo do nível de maturidade da organização. Houve também uma mudança massiva para a nuvem. Atualmente, há um pouco de balanço de pêndulo de volta devido a violações, como ataques de ransomware. Essas violações ocorreram na nuvem, principalmente porque as pessoas não entendiam a responsabilidade compartilhada pela segurança. Agora, algumas organizações estão pensando duas vezes antes de mover seus dados críticos para a nuvem. Elas podem mover as cargas de trabalho para lá, mas estão mantendo os dados mais importantes em casa.\n\nOutra mudança recente é a importância da percepção do cliente. Você pode estar fazendo as perguntas certas sobre hardware e camadas de proteção de software, mas também precisa considerar a percepção do seu cliente sobre onde está armazenando os dados e por quê, quem está protegendo-os e como estão sendo protegidos.\n\nUm problema maior são as organizações que não conseguem responder a nenhuma dessas perguntas. Às vezes, nem sequer sabem onde estão seus dados. Essas organizações devem encarar isso como um ponto de partida para o trabalho que ainda precisa ser realizado.\n\nAlgumas novas questões agravam esse problema que a indústria ainda não abordou, como videoconferências. A gravação da reunião é salva em um laptop, mas também está em algum lugar na nuvem. Quem tem acesso a ela? Quais são as proteções? Por quanto tempo ficará lá?\n\nUm princípio de segurança é saber se o seu dispositivo está seguro. Um dos desafios descobertos com a situação da COVID é que muitas lojas de tecnologia de informação estão hesitantes em atualizar os sistemas. Eles não querem interromper um sistema, seja ele um servidor ou um cliente. Não atualizar os patches de segurança é um erro.\n\nO trabalho da Intel é trabalhar com parceiros e colegas de viagem para tornar essa atualização uma atividade mais simples e confiável, onde as pessoas terão confiança de que ela funciona e algo não dará errado no processo. A indústria deu passos consideráveis ​​para tornar o processo de atualização mais sistemático e previsível nos últimos anos.\n\nOutra parte do trabalho é treinar as pessoas para entender que a segurança não para quando um dispositivo é enviado pelo fabricante ao cliente. A segurança continua durante toda a vida útil do dispositivo. O que era uma segurança de classe mundial no momento da remessa não é mais uma segurança de classe mundial meses ou anos depois. As empresas devem atualizar suas máquinas duas vezes por ano para mantê-las seguras.\n\nAs pessoas ficam nervosas em fazer atualizações porque coisas inesperadas podem acontecer. A Intel valida em grande escala para prevenir problemas, seja com milhares de máquinas em seus laboratórios ou com parceiros OEM em laboratórios espalhados pelo mundo. A validação completa garante que as medidas de mitigação funcionem para proteger contra vulnerabilidades e não causem danos ao sistema. A Intel fez um investimento significativo em parcerias e colaborações com seus parceiros de ecossistema e na condução de padrões em toda a indústria, buscando melhorar a experiência do usuário no futuro desenvolvendo a capacidade de realizar atualizações sem reinicialização.\n\nEducar os clientes sobre por que você está pedindo a eles para fazer uma atualização pode fazer toda a diferença. Se eles entenderem que você encontrou uma vulnerabilidade e que podem estar abertos a um possível ataque, provavelmente eles vão querer fazer a atualização.\n\nEm geral, as pessoas parecem estar dispostas a atualizar seus celulares porque não estão tão preocupadas que algo não funcionará depois, mas ainda é um desafio nos PCs e servidores. Parte disso tem a ver com os modelos de uso. Embora seja raro que os dados existam apenas em um laptop, essa mentalidade é prevalente. Quando os dados existem na nuvem de um celular, a percepção é de que eles sempre estarão lá. Além disso, as pessoas tendem a fazer trabalhos mais imersivos e envolventes em laptops do que em telefones, por isso são mais sensíveis a isso. Uma vez que a percepção muda e as pessoas percebem que os dados em seu laptop também existem na nuvem, as atualizações são mais amplamente aceitas. Portanto, na realidade, a indústria precisa fazer uma combinação de soluções técnicas e mudanças de mentalidade quando se trata de segurança.\n\nA forma como as coisas estão evoluindo é um pouco híbrida. Novos modelos de aprendizado, como o aprendizado federado, estão sendo rapidamente implementados para ajudar a lidar com questões como preocupações com privacidade. Os modelos estão sendo levados para a borda em vez de os dados serem movidos para o centro de dados. Por exemplo, um sistema de imagens médicas em um hospital, onde os dados permanecem no local e o modelo é usado para analisá-los. Estamos começando a ver isso em aplicações industriais, onde as máquinas estão na borda e se tornam o servidor. Elas armazenarão os dados localmente e realizarão treinamento e atualizações lá. Portanto, haverá dispositivos inteligentes na borda, trabalhando com os dados brutos, e a questão é: como garantir a segurança disso?\n\nOutra tendência em segurança, uma que não começou com a pandemia de COVID, mas sem dúvida foi acelerada por ela, é a proteção contra ataques físicos. Historicamente, a segurança tem sido focalizada em algo que poderia acontecer pela rede, como um ataque de rede ou um aplicativo malicioso. Com dispositivos IoT por aí, sem nenhum humano conectado ou observando, temos que proteger os dados e os dispositivos contra adulteração. Isso é um desafio difícil.\n\nHoje em dia, não se pode pensar de forma holística em segurança, a menos que se esteja abordando também a privacidade. Uma complicação é que a privacidade pode estar em conflito direto com a segurança em alguns casos. Não existem regulamentos ou padrões acordados mundialmente, então as organizações têm que descobrir como operar: atender ao denominador comum mais alto ou atender a cada requisito geopolítico? Para complicar ainda mais, as leis e regulamentos estão em constante mudança.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tom Garrison","Camille Morhardt"],"link":"/episode-EDT69-pt","image":"./episodes/edt-69/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Intel, discute a segurança do data center através da borda com os colegas executivos da Intel e anfitriões do podcast, Tom Garrison, VP de Segurança do Cliente e Camille Morhardt, Diretora de Inovação e Comunicação de Segurança."},{"id":143,"type":"Episode","title":"Garantindo a segurança do trabalhador remoto","tags":null,"body":"\r\n\r\n## Modos de operação de teletrabalho <h2>\n\nOs modos de operação de teletrabalho não são novos, seja usando um dispositivo como terminal (VDI), parte da rede interna ou como um portal para serviços/software (SAAS); o que é novo é o grande volume de funcionários, contratados e parceiros que agora estão usando os ambientes existentes para realizar seu trabalho principal, ao invés de apenas um número limitado e gerenciável. A segurança é um desafio em todos esses modos de operação. As organizações precisam descobrir a melhor forma de implantar suas capacidades existentes para garantir e proteger o acesso, os dados, os dispositivos e os usuários.\n\n## Ameaças do Teletrabalho\n\nAlguns dos riscos de segurança são aqueles que sempre estiveram presentes no teletrabalho: segurança do dispositivo final e dos dados, ponto de acesso e acesso aos serviços corporativos. No entanto, ao se adaptar ao ambiente do COVID-19, surgiram novos problemas devido ao grande número de pessoas que agora trabalham em casa e à pressa em habilitá-las.\n\nUma questão é trabalhadores em casa em ambientes inseguros em redes que nunca foram destinadas a serem usadas fora da corporação. Isso leva a ataques direcionados de phishing e malware. Outro problema é a introdução de novas ferramentas, como aquelas de colaboração e videoconferência que podem expor sua empresa e dados a ataques e uso malicioso. Basicamente, agora há uma área de superfície de ataque aumentada, muito maior do que a maioria das organizações inicialmente planejou, e novos ambientes que nunca fizeram parte do plano original.\n\n## Soluções para garantir a segurança do trabalhador remoto\n\n## Traga seu próprio dispositivo (BYOD).\n\nUm dos problemas mais difíceis de lidar é quando os trabalhadores usam seus próprios dispositivos. O desafio chave é que esses dispositivos não são gerenciados, sem todos os agentes de segurança em execução e gerenciados pelo departamento de TI; o dispositivo é de propriedade e gerenciado pelo usuário. Você pode ter a capacidade de instalar alguns agentes ou ter alguma aplicação de política, mas há apenas tanto que você pode fazer sem impedir que o trabalhador o utilize como um dispositivo pessoal. Então, como você pode proteger um usuário com um BYOD?\n\nCertifique-se de que esses fundamentos estejam em vigor: Aplique os patches mais recentes como requisito, imponha um bom controle de acesso à sua empresa e serviços, implemente autenticação de múltiplos fatores e proteja seus ativos com as devidas proteções, como gerenciamento de direitos empresariais para controle de acesso aos dados e imponha controle de acesso baseado em políticas nos pontos finais.\n\nOutra opção para reduzir seu risco pode ser limitar o acesso direto aos serviços da empresa e fazer com que os usuários trabalhem em um ambiente SASS.\n\n## Pontos Finais e Ambientes Não Seguros\n\nA melhor solução para muitos desses problemas seria um cliente empresarial robusto, mas ainda há riscos envolvidos. Os trabalhadores estão utilizando um dispositivo que é uma extensão gerenciada da rede empresarial. A segurança pode ser implementada com inicialização segura, criptografia de disco completo, proteção de dados, firewalls locais e aplicação de boas práticas de atualização. No entanto, o risco surge porque muitas organizações já possuem trabalhadores remotos, como vendedores ou engenheiros de campo, que podem não ter o mesmo nível de segurança dos trabalhadores que nunca foram destinados a sair do prédio, como os departamentos financeiro e de recursos humanos.\n\nAs organizações devem estar vigilantes para garantir que todos os trabalhadores tenham agora a mesma segurança, ou até adicionar camadas extras que os trabalhadores precisam para trabalhar remotamente em redes não seguras. A autenticação de múltiplos fatores agora deve ser um requisito, e a aplicação da política de ponto final e a gestão dos direitos empresariais são agora mais importantes do que nunca.\n\nEstamos vendo inovações nessa área, como um cliente que está fornecendo aos novos funcionários não apenas laptops, mas também um roteador gerenciado para evitar redes não seguras.\n\n## Sistemas de VDI e Serviços de Nuvem\n\nImplementar segurança para sistemas VDI e serviços em nuvem inclui os conceitos básicos de segurança: proteção de dados, segurança de virtualização tanto para o centro de dados da empresa quanto nos pontos de acesso, segurança de aplicativos, inicializações seguras, aplicação de patches e criptografia de rede. A chave está em realizar uma pesquisa precisa sobre a empresa e os serviços em nuvem que estão sendo implantados para seus funcionários, garantindo que todos estejam igualmente protegidos. Cada aplicativo, mesmo aqueles que não são essenciais, pode ser um ponto de ataque potencial.\n\n## Clientes como Serviço\n\nOs clientes do SASS utilizam serviços na nuvem e também utilizam aplicativos em seus clientes ricos, portanto, existem algumas questões de segurança adicionais com que se preocupar. Deve haver uma proteção adequada aos dados no gerenciamento de direitos empresariais (ERM) para o acesso aos dados por meio dos serviços em nuvem e de volta ao centro de dados. A proteção em ambos os lados é crítica. O acesso dos clientes aos serviços em nuvem deve ser protegido por autenticação multifatorial e criptografia de rede. O acesso dos serviços em nuvem ao data center privado da empresa e aos recursos empresariais também deve ser protegido nas camadas de acesso à rede, dados e aplicativos. Compreender como os clientes estão utilizando os serviços e quais dados estão acessando é onde as decisões do ERM entram em jogo.\n\n## Mau uso e abuso de Insiders<h3>\n\nA TI deve utilizar diversos métodos para gerenciar a ameaça e risco de erros, mau uso e ações maliciosas de insiders. O controle de acesso baseado em políticas e a aplicação das mesmas, desde as aplicações até os dados, em nível empresarial e de nuvem é importante para evitar o mau uso e abuso de usuários já autenticados. A principal defesa que a TI possui é a auditoria e monitoramento da inteligência de ameaças. Gerenciar essa informação em toda a empresa e na nuvem ao longo de um longo período de tempo pode ser muito eficaz na detecção de comportamentos aberrantes.\n\nNão há dúvida de que agora temos que pensar de forma diferente nas questões de segurança com o teletrabalho. Nossas principais recomendações são, em primeiro lugar, implementar a tecnologia que você vem testando; em segundo lugar, educar seus usuários; e em terceiro lugar, ativar a autenticação de dois fatores e proteger seus dados em grande escala. Se conseguirmos fazer essas três coisas, podemos reduzir o risco e estar melhor preparados para o futuro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT7-pt","image":"./episodes/edt-7/pt/thumbnail.png","lang":"pt","summary":"Com a enorme mudança de pessoas que agora trabalham em casa em vez do escritório, a segurança é uma preocupação crescente para muitas organizações de TI. Neste episódio, Steve Orrin, CTO da Intel Federal, e Darren discutem as ameaças de segurança e soluções para ajudar a proteger seu teletrabalhador e os centros de dados corporativos."},{"id":144,"type":"Episode","title":"Governança Moderna de Dados","tags":["datagovernance","immuta","dataaccess","identitymanagement","cybersecurity","data","technology"],"body":"\r\n\r\nÀ medida que as organizações migram para a nuvem, a forma como pensamos sobre dados e como os utilizamos está mudando completamente; nos últimos cinco ou seis anos, toda a camada de infraestrutura mudou. O desempenho, a escala, as regras necessárias e o número de usuários que desejam combinar dados aumentaram exponencialmente. Gerenciar isso em escala não é trivial, e é onde a Immuta entra em cena.\n\nCom o tempo, a indústria repensou o paradigma do armazenamento de dados. Anteriormente, cada equipe de dados construía produtos de dados em células isoladas e, em seguida, entregava a uma unidade de negócios. A unidade de negócios possuía seus dados apropriados que forneciam um serviço de qualidade a eles. Agora, de repente, queremos que qualquer pessoa possa combinar dados em toda a empresa: analistas de negócios, cientistas de dados, engenheiros de dados, etc. O número de usuários mudou, e não se trata mais de aplicativos de pesquisa; trata-se de transformar e construir fluxos de dados.\n\nIsso é uma diferença que requer um nível de serviço, tempo e sofisticação diferentes, que nunca existiram antes. Torna-se ainda mais complexo quando se adiciona leis de privacidade, classificação de dados e regras e regulamentações em constante mudança.\n\nO que a Immuta está tentando fazer é tornar possível para qualquer usuário combinar potencialmente qualquer conjunto de dados, interno ou externo à organização, para obter alguma compreensão. Tudo se trata de escala. A política precisa ser separada da plataforma para escalar a política para todos esses novos usuários e todas as diferentes combinações de dados. Segurança, privacidade e governança são ótimas, mas se você não conseguir fazer, ninguém fica satisfeito.\n\nUma lição que a Immuta aprendeu logo no início é que o proxy não funciona. É como tentar mover petabytes de dados por um canudo: eles se tornam um gargalo. É fácil culpar a camada intermediária sempre que há um problema, pois ela é sempre um gargalo, pois está entre as ferramentas e os dados. Esse é um problema clássico de middleware.\n\nO segundo problema com esse paradigma de design é que, com a virtualização de dados clássica, funcionava porque havia um conjunto claro de dados. No entanto, quando existem petabytes de dados, a abordagem de \"me dê tudo e nós vamos descobrir\" se desfaz muito rapidamente devido ao tamanho bruto dos dados, além de todas as regras e políticas associadas a eles.\n\nNa virtualização normal, é necessário incorporar nativamente na infraestrutura de computação em nuvem em Snowflake, em Synapse, etc. Em vez de colocar essa camada de abstração em cima dessas diferentes ferramentas, a camada de abstração está do lado da política.\n\nA política é tão boa quanto a capacidade de auditá-la. É como uma cadeia de evidências. A chave é poder provar se este usuário está em conformidade ou não, em toda a infraestrutura de computação. Com a governança moderna de dados, a política está sendo escalonada internamente e unificando auditorias, devido ao nível de complexidade de tantas pessoas realizando diversas atividades com os dados. A auditoria da política deve ser drasticamente simplificada, caso contrário, é impossível determinar a conformidade.\n\nExistem três tipos de políticas a serem consideradas: operacional, regulatória e contratual. Um exemplo de quão complicado tudo isso pode se tornar é olhar para uma empresa como a Cummins. Se eles modernizarem na nuvem, eles terão que considerar regulamentos para cada mercado. Para um de seus motores, e se eles tiverem que escrever uma regra personalizada para cada país em que estão, mas também para cada país em que não estão, porque esses países não devem ser capazes de vê-la? Isso não é escalável quando estamos falando de dezenas de milhares de fontes de dados para os esquemas, que estão mudando constantemente. Existem petabytes de dados de telemetria desses motores.\n\nO que você gostaria de escrever é que você só pode ver os dados do país em que reside uma vez e, em seguida, se aplica em todos os lugares. Mas não é assim que é feito. Portanto, eles estariam escrevendo algo como 700 políticas para um objeto de dados, quando deveria ser apenas uma. Acompanhar todas as políticas e regulamentos em constante mudança para cada fonte de dados seria quase impossível. Você estaria sempre em desacordo.\n\nNunca foi tão fácil globalizar uma empresa como hoje, e os clientes da Immuta esperam que eles possam executar infraestrutura globalmente em qualquer nuvem. Eles devem ser capazes de mover seus dados para qualquer nuvem e estar em plena conformidade.\n\nImmuta aplica regras aos dados por meio de tags em vez de usar os dados brutos, porque cada domínio possui sua própria terminologia sobre como classificar e falar sobre seus dados. Portanto, eles começaram a classificar e marcar de forma genérica para aplicar modelos conceituais gerais, como no caso do HIPAA. No entanto, esses modelos ainda não são infalíveis e há um longo caminho a percorrer.\n\nA visão de Matt como CEO do Immuta é chegar a um estado em que domínios possam compartilhar suas políticas. Por exemplo, na área da saúde, há uma boa razão para que a Moderna e a Pfizer queiram trabalhar juntas. Poderia haver um acordo sobre como lidar com controles de dados do mundo real com a academia. Portanto, se houvesse uma política consistente que pudesse ser compartilhada e colaborada em uma nuvem de políticas conceituais, isso seria o certo a se fazer.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Carroll"],"link":"/episode-EDT70-pt","image":"./episodes/edt-70/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, discute a realidade e o futuro da governança de dados moderna com Matthew Carroll, CEO da Immuta."},{"id":145,"type":"Episode","title":"Gestão de Dados Moderna","tags":["datagovernance","data","immuta","dataaccess","identitymanagement","ceo","technology","process"],"body":"\r\n\r\nNa governança de dados moderna, a primeira premissa é que você precisa separar a política da plataforma.\n\nO segundo é que não pode haver ontologia. Se alguém tentar criar um super esquema de tudo, é impossível, mas você precisa de um esquema para aplicar políticas. Portanto, se um usuário deseja juntar duas colunas, é preciso ter uma nova política. Os dados sensíveis devem ser descobertos, tanto por meio de identificadores diretos quanto indiretos. Identificadores indiretos são mais difíceis, e técnicas devem ser aplicadas para mitigar o risco de ataques de vínculo.\n\nA terceira premissa é a introdução de uma série de técnicas que aprimoram a privacidade, como mascaramento, censura, autorização, etc.\n\nTradução para o português: Essas ferramentas são automatizadas como parte da governança moderna de dados. Um exemplo paralelo é como você costumava precisar ser um mago para remover olhos vermelhos em uma foto. Agora, você clica em um botão e os olhos vermelhos desaparecem. É a mesma coisa em relação à privacidade. Precisamos desse botão fácil para automaticamente encontrar um potencial identificador indireto quando há risco maior do que muito baixo de reidentificação.\n\nAlém da privacidade, há uma infinidade de outras coisas com dados que devem ser automatizadas antes da classificação. Embora a Immuta não aprofunde a transformação de dados e esses fluxos de dados, eles fornecem uma API e interface de linha de comando. Os engenheiros que estão construindo esses pipelines podem fazer seu trabalho, e a Immuta irá informá-los sobre as regras, e a atualização das regras pode fazer parte do pipeline. Eles querem ser um condutor para essa camada.\n\nExistem alguns novos papéis neste campo, como \"data steward\" e \"data governance engineer\", que são segregados do \"data engineer\". E então os usuários de dados são realmente três usuários separados com três necessidades separadas.\n\nPrimeiro, existem cientistas de dados que possuem habilidades especializadas e precisam de dados de uma forma específica. Às vezes, eles precisam de ferramentas específicas e um ambiente de computação específico em algum lugar do mundo para cumprir sua missão.\n\nPor outro lado, os engenheiros de dados e os engenheiros analíticos, um construindo os pipelines e outro sustentando os pipelines, precisam de acesso rápido a uma solução emergencial quando algo quebra. Eles alimentam isso em um pipeline e entregam para alguém, verificando se está atualizado.\n\nFinalmente, há os governadores que estão tentando acompanhar as regulamentações.\n\nEsses usuários têm opiniões e necessidades muito diferentes em relação à governança. Ao aplicar uma nova governança, a coisa mais importante é tratar esses grupos como partes interessadas separadas.\n\nSe você pensa em todos esses papéis de uma maneira binária, como engenheiros de dados, o que acaba acontecendo é que há muitas reuniões, então é impossível escalar. Precisamos criar uma relação simbiótica entre operações de dados, ciência de dados, análise de dados e governança. Um modelo de exemplo é o Salesforce ou o ServiceNow, onde há todo um fluxo de trabalho do início ao fim e não é necessário realizar reuniões. Isso seria verdadeiras operações de dados.\n\nImmuta tem, filosoficamente, uma abordagem baseada em atributos em vez de uma abordagem baseada em funções. O problema com uma abordagem baseada em funções é que você acaba acumulando excesso de funções à medida que adiciona mais. Uma organização farmacêutica, por exemplo, tinha mais de 800.000 funções porque as funções nunca podem ser excluídas devido à necessidade de reproduzir ensaios de medicamentos. O excesso de funções pode se tornar rapidamente um problema de escala.\n\nAcesso baseado em atributos é a chave para combater isso. Em vez de adicionar constantemente funções, os usuários possuem atributos específicos e consistentes. Por exemplo, um atributo de um usuário pode ser que eles estão marcados para que possam ver apenas seu próprio estado. Com acesso baseado em funções, todos os estados, independentemente de se podem ser visualizados ou não, teriam que ser escritos. Essa moderna gestão de identidade é altamente escalonável. O acesso por atributo simplifica o número de políticas que precisam ser escritas e ajuda no desempenho.\n\nTraduza o seguinte para o português: Regulamentações globais modernas, como o GDPR, no entanto, também exigem um propósito. É aqui que o acesso a atributos se torna importante: quais propósitos cada pessoa pode operar? Sob um EULA, os dados devem ser processados apenas pelos usuários para a razão declarada. Caso contrário, é necessário fazer uma análise de risco antes que os dados sejam usados operacionalmente para produção.\n\nNeste momento, estamos no início da governança moderna de dados. Atualmente, os usuários tomam uma decisão binária única em relação aos dados, seja consentimento ou não consentimento. O futuro está em algum lugar no meio: consentimento limitado. Por exemplo, se uma pessoa fornecer seus dados genômicos para uma empresa como a ancestry.com, o que isso significa para seu filho no futuro? A criança não deu consentimento para que seu material genético fosse repassado e possivelmente examinado por uma empresa de seguros de saúde para determinar riscos. Na governança moderna de dados, Matt vê os consumidores fornecendo consentimento limitado, como permitir que uma empresa analise apenas o DNA para ancestralidade e mais nada.\n\nO futuro tem que se basear em consentimento e acesso com base em propósito, porque, em última análise, os dados derivados impulsionam os insights, à medida que o aprendizado de máquina em desenvolvimento incorpora dados nos algoritmos.\n\nPara saber mais sobre a Immuta e como construir um programa de governança de dados, acesse Immuta.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Carroll"],"link":"/episode-EDT71-pt","image":"./episodes/edt-71/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções na Intel, continua sua discussão aprofundada sobre a realidade e o futuro da governança de dados moderna com Matthew Carroll, CEO da Immuta. Neste episódio, eles discutem a Classificação de Dados, Políticas e Governança."},{"id":146,"type":"Episode","title":"2021 um ano em revisão","tags":["covid","edge","compute","cybersecurity"],"body":"\r\n\r\nUma grande expectativa para 2021 era que a nova vacina nos tirasse da COVID e as viagens retomassem. Darren esperava ver seus clientes cara a cara, em vez de pelo Zoom ou conferências virtuais.\n\nOutras expectativas incluíam a implementação de modelos de trabalho híbridos e, apesar de a aprendizagem remota na educação estar em pleno vapor, havia esperança de um retorno às salas de aula presenciais. Esperávamos ver um aumento no atendimento ao cliente sem contato ou sem atritos. A indústria dos aplicativos de entrega, como o UberEats, também estava decolando.\n\nNa indústria, estávamos esperançosos em ver um grande impulso para IA e ML à medida que novas tecnologias se tornassem disponíveis. Também esperávamos ver uma aceleração na indústria 4.0 com a automação, já que as fábricas ainda precisavam produzir mesmo com menos trabalhadores.\n\nTivemos grandes expectativas para 2021, e não nos decepcionou. No entanto, houve algumas surpresas.\n\n## Surpresas em 2021\n\nEmbora a vacina tenha ajudado, ela não erradicou a COVID. Tivemos quatro ondas e atualmente estamos no meio da onda Omicron no início de 2022. No entanto, nem todos voltaram ao trabalho e as organizações continuam implementando planos de trabalho híbrido.\n\n2021 também trouxe a grande renúncia, com um grande número de pessoas mudando de emprego, talvez devido ao esgotamento, diferentes oportunidades ou simplesmente por estarem incertos sobre quando teriam que voltar ao escritório.\n\nA TI se tornou os heróis silenciosos da continuidade dos negócios, pois se tornaram ainda mais flexíveis, com a capacidade de tomar decisões rápidas para atender a todas as diferentes necessidades dos funcionários e clientes.\n\nOutra grande surpresa foi que setores industriais importantes fora da alta tecnologia foram afetados pelo ransomware, como a indústria de processamento de carnes e um oleoduto. Segurança, então, tornou-se um conceito importante.\n\nA Intel teve uma grande surpresa também, com o retorno de Pat Gelsinger como CEO.\n\nCOVID ainda está causando estragos em todo o mundo.\n\nA COVID provavelmente será o evento central ou cisne negro do século. As economias mundiais se ajustaram para refletir a incerteza das quatro ondas de surtos de COVID, e os picos e vales causaram estragos nos planos de negócios para fazer as pessoas voltarem aos escritórios.\n\n## Modelos de Trabalho Híbrido Criados\n\nOrganizações têm desenvolvido alguns ótimos modelos de trabalho híbrido, mas muitos ainda não são utilizados à medida que as datas de retorno ao trabalho vêm sendo constantemente adiadas devido a surtos, como a atual onda do Ômicron em janeiro de 2022. O que vimos foi uma grande mudança cultural com as pessoas se adaptando ao trabalho remoto e possivelmente híbrido. As organizações de TI se prepararam para o vai e vem ao escritório.\n\nO trabalho do dia a dia sofreu uma mudança fundamental, onde as pessoas passaram a armazenar seu trabalho em uma máquina no escritório para armazená-lo na nuvem. Ou seja, as coisas são armazenadas em um dispositivo portátil e replicadas na nuvem. Por isso, vimos uma grande mudança nas ofertas baseadas em nuvem e Software como Serviço (SaaS), como o Office 365, bem como nas ferramentas de colaboração, como o Zoom e o Teams. Além disso, a integração remota de novos funcionários se tornou comum. Tudo isso afetou pessoas, processos e tecnologia.\n\n## Combatendo a Grande Renúncia\n\nPara reter funcionários no meio da grande renúncia, as organizações devem primeiro olhar para o bem-estar dos funcionários. Com o estresse e o isolamento da pandemia, houve um aumento de organizações buscando ajudar os funcionários com a saúde mental e emocional.\n\nFlexibilidade é outra chave; com o trabalho remoto, horários e localização podem ser flexíveis. Os funcionários podem viver em outro estado ou manter horários não tradicionais. Essa flexibilidade e falta de deslocamento permitiram que as pessoas se envolvessem e explorassem mais as suas próprias comunidades.\n\nAs organizações de RH estão começando a usar a inteligência artificial para descobrir por que as pessoas estão saindo, identificar tendências e determinar quais programas ajudarão a aumentar a produtividade e ajudar os funcionários a se sentirem parte da equipe. As organizações também estão recorrendo à automação. Houve um aumento na indústria de automação de processos robóticos para lidar com menos funcionários.\n\n## O ritmo incessante da TI não diminuiu.\n\nA TI não consegue manter o ritmo heróico que era necessário no início da COVID, então, embora as horas loucas tenham diminuído, a demanda está sendo atendida estrategicamente. Vimos um movimento massivo para ofertas de SaaS, então os funcionários, por exemplo, não estavam mais lidando com coisas que não eram necessariamente suas habilidades. Em vez disso, eles podiam recorrer a um provedor de serviços em nuvem, ou provedores de serviços de RH, vendas ou sistemas ERP. Um movimento para automação e processos repetíveis aliviou um pouco a pressão do trabalho diário de escritório. Também houve um maior investimento em tecnologia de DevOps e RPA para ajudar a otimizar e garantir o desenvolvimento de produtos.\n\n## Segurança, Cadeia de Suprimentos e Ransomware.\n\nProblemas de segurança pegaram a maioria das indústrias desprevenidas. Indústrias como frigoríficos, petróleo e gás, hospitais e empresas de cadeia de abastecimento e logística foram atingidas por violações de segurança. Primariamente, isso foi um problema de ter que se adaptar rapidamente ao trabalho remoto e deixar de lado a segurança cuidadosa. Por exemplo, talvez as organizações não tenham oferecido o treinamento adequado aos funcionários remotos sobre como proteger seus laptops ou dados. Entre outras lições aprendidas, veremos o surgimento do zero trust (confiança zero) este ano.\n\nOutro grande problema deste ano foram os problemas na cadeia de suprimentos, e não apenas no fornecimento de silício. Muitos materiais continuarão em falta em todas as áreas, afetando especialmente as pequenas empresas.\n\nTemos que criar soluções para combater o ransomware. As organizações podem fazer mudanças processuais e culturais e utilizar novas tecnologias para encontrar essas soluções.\n\n## A Intel tem um novo CEO.\n\nA maior surpresa para Darren, e talvez para toda a indústria, foi o retorno de Pat Gelsinger à Intel, desta vez como CEO. Todos na Intel estão inspirados pela energia que ele traz. Pat afirma que vai ajudar a indústria a resolver a escassez de chips investindo novamente na fabricação americana. Darren acredita que ele irá recolocar a Intel no topo da fabricação de vendas de chips e fornecer tecnologia maravilhosa para o mundo todo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT73-pt","image":"./episodes/edt-73/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren reflete sobre as expectativas e surpresas de 2021."},{"id":147,"type":"Episode","title":"Ransomware: Prepare e Não entre em Pânico","tags":["cybersecurity","ransomware"],"body":"\r\n\r\nEmbora um ataque de ransomware comece para a maioria das organizações com um pedido de resgate de algum tipo, a história completa geralmente vem sendo preparada há muitos meses.\n\nA demanda de resgate ocorre depois que os atacantes criptografam informações de sistemas comprometidos e os bloqueiam o máximo possível, ou quando roubam informações confidenciais e ameaçam publicá-las. Em ambos os casos, eles solicitam uma quantia em dinheiro para interromper a divulgação ou para restabelecer as informações.\n\nA quantia de dinheiro pode ser alvo pois os atacantes sabem o quanto a empresa pode pagar, e eles irão solicitar uma quantidade massiva. Ataques menos direcionados irão pedir um valor aleatório e torcer para obter sucesso. Contudo, cada vez mais os ataques são sofisticados e os atacantes fizeram seu trabalho de casa. Eles podem ter obtido um progresso significativo, movendo-se lateralmente pelo ambiente e comprometendo múltiplos domínios. Eles sabem que custará uma quantia considerável para a organização restabelecer seus serviços, então eles podem pedir mais.\n\nMas antes que os atacantes exijam o resgate, eles já estiveram dentro do sistema por algum tempo, em média, pouco menos de 300 dias, até executarem completamente seu plano. Eles tentam chegar o mais longe possível dentro da rede para causar o máximo impacto. Por exemplo, eles vão eliminar o sistema de backup executivo, deixando dados de backup corrompidos e inutilizáveis, paralisando a organização. Eles também gastarão tempo comprometendo credenciais para aumentar seus privilégios e se mover lateralmente pela rede, procurando qualquer vulnerabilidade.\n\nCada ataque é diferente, portanto, é difícil nomear a vulnerabilidade mais comum. Os atacantes encontram qualquer entrada que conseguirem, seja uma fraqueza na gestão de vulnerabilidades ou mesmo nas pessoas, por exemplo, ataques de phishing ou táticas de engenharia social. Eles farão chamadas telefônicas e se passarão por executivos, ou usarão nomes de tipo executivo para obter informações e dados dos funcionários online.\n\nMuitos na indústria dirão que não é uma questão de se, mas de quando você será atacado. Stephanie, no entanto, não acredita que esse seja o caso, porque com diligência adequada, bloqueando adequadamente e tomando as medidas necessárias, você não será alvo.\n\nDue diligence é o que os especialistas em segurança vêm pregando há décadas: fazer gerenciamento de vulnerabilidades e de correções, alterar senhas e conceder privilégios conforme possível. Treine sua equipe. Administradores não devem estar na internet com contas administrativas postando em fóruns, por exemplo. Tudo se resume a compreender quais são as superfícies de ataque e gerenciá-las.\n\nO que você deve fazer se for vítima de um ataque de ransomware? Stephanie diz que o que as pessoas deveriam fazer e o que elas realmente fazem são coisas diferentes. A reação imediata dos profissionais de TI costuma ser reiniciar, corrigir ou modificar o ambiente de maneiras significativas. Isso apenas alertará os atacantes de que o tempo deles está esgotado. Para investigação forense, é extremamente importante agir com cautela nessas situações. Faça o menor número possível de digitações e definitivamente não reinicie.\n\nAlgumas empresas entrarão em pânico e realizarão negação de serviços sobre si mesmas, entrando em modo completo de bloqueio, desligando tudo. Em vez de entrar em pânico, elas deveriam depender de suas políticas de resposta a incidentes e perceber que o problema pode ser resolvido, mesmo que não seja agradável.\n\nObviamente, todas as empresas devem ter essas políticas de resposta a incidentes que possam ser implantadas rapidamente para gerenciar as comunicações internamente e com a mídia, e manter o negócio em andamento, se possível. Profissionais de segurança podem ajudar a criar esses planos de resposta e podem intervir e ajudar durante um ataque.\n\nO primeiro passo deles para preservar as informações é observar algumas das atividades questionáveis ​​que estão ocorrendo na rede. Os ataques de ransomware não começam com a criptografia ou roubo de informações; há muitos ataques anteriores. É importante identificar de onde eles estão vindo, onde se originaram e por onde passaram. Para fazer isso, os profissionais de segurança precisam de evidências e informações e estas precisam ser devidamente preservadas. Um bom começo é colocar as pessoas certas no lugar certo para gerenciar o que está acontecendo.\n\nO próximo passo é gerenciar adequadamente o ambiente. Infelizmente, uma vez que ocorra ransomware ou qualquer tipo de violação ou incidente, a organização fica altamente vulnerável. Cem por cento das vezes, quando ambientes passaram por ataques bem-sucedidos de ransomware, sejam eles divulgados ou não, eles são alvos do mesmo grupo ou de um grupo diferente. É como um animal ferido com abutres circulando. Os atacantes sabem que você está ferido e vulnerável. Um novo ataque está por vir.\n\nNa maioria das vezes, quando profissionais de segurança estão realizando suas investigações, eles encontram outros indicadores de ataque e comprometimento em diferentes partes da rede. Eles devem determinar se faz parte do mesmo ataque ou de um ataque diferente. Essa investigação é uma parte crítica da recuperação de malware porque mesmo quando você pensa que eliminou um ataque e que o negócio está funcionando corretamente novamente, ainda existe a possibilidade desses outros ataques.\n\nUm ataque típico custa em média quatro milhões e meio de dólares para ser limpo, e isso não inclui o resgate. O valor pode ser ainda maior e é proporcional ao tamanho da organização.\n\nÉ impossível ter certeza de quantas organizações pagam o resgate. Muitos dos resgates vêm com ameaças de não entrar em contato com as autoridades ou divulgar o ataque. Por esse motivo, as estatísticas disponíveis sobre quantas organizações pagam são variadas.\n\nAlgumas organizações respondem dizendo que não pagarão sob qualquer circunstância, mesmo que custe mais reconstruir, destruindo assim a capacidade de negociar. Essa é uma decisão emocional que pode obscurecer o julgamento. No final do dia, se o objetivo é continuar fazendo negócios e ganhar dinheiro, pagar um resgate baixo de talvez dez ou vinte mil dólares será mais barato do que os custos de forense e o restante do processo. Por outro lado, existem casos documentados em que o resgate foi pago e os dados não foram totalmente restaurados. Além disso, a organização não tem certeza sobre a segurança de seu ambiente. Não há garantia quando se paga um resgate; você está pedindo aos criminosos que ajam de boa fé.\n\nMuitos governos ao redor do mundo tornaram ilegal pagar um resgate porque os atacantes são considerados terroristas, e não é permitido negociar com terroristas. Outro complicação é que os atacantes às vezes se recusam a lidar com negociadores profissionais. Eles frequentemente nomeiam alguém na organização como a única pessoa com quem eles vão negociar, esperando que essa pessoa tome decisões emocionais.\n\nAs ameaças são comunicadas de várias maneiras: por email, telefone e até mesmo como papel de parede no computador.\n\nA melhor estratégia para evitar ou mitigar um ataque é não esperar até que sua organização esteja nessa situação. Em vez disso, engaje-se na diligência devida. Realize avaliações pelo menos anualmente para identificar as lacunas na segurança. As ameaças e os ataques estão constantemente mudando e se tornando mais sofisticados, portanto, a segurança de sua organização deve acompanhar. Monitore e corrija continuamente. Faça gerenciamento de vulnerabilidades, altere constantemente as senhas e lembre e eduque os usuários sobre as ameaças. Essas não são estratégias novas. Profissionais de segurança vêm recomendando essas medidas há décadas; as organizações apenas não estão realizando-as corretamente e evoluindo.\n\nTambém é inteligente chamar os especialistas para guiar o processo de planos de resposta a incidentes e exercícios. Todos na organização devem saber o que fazer e para quem ligar em um cenário de ataque, a fim de evitar danos ainda maiores.\n\nSe a sua organização for atacada, esperamos que o impacto seja mínimo, ou pelo menos contido e gerenciável se houver preparação. Qualquer tempo, energia e dinheiro que uma empresa investe em medidas preventivas é uma pequena fração do custo de um ataque.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Stephanie Sabatini"],"link":"/episode-EDT74-pt","image":"./episodes/edt-74/pt/thumbnail.jpeg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, fala com Stephanie Sabatini, Diretora Sênior de Serviços Profissionais da Hitachi Systems Security, sobre prevenir e se preparar para ataques de ransomware e o que fazer se sua organização for atacada."},{"id":148,"type":"Episode","title":"Soluções de segurança cibernética com Hitachi","tags":["cybersecurity","technology"],"body":"\r\n\r\nColin está na Hitachi há quase 24 anos, depois de trabalhar na IBM logo após sair da faculdade. Ele é principalmente responsável por contas no Noroeste do Pacífico e contas do setor público e educação. Ele teve a oportunidade incomum de assumir o cargo de seu pai quando ele se aposentou da Hitachi.\n\nDavid tem trabalhado em TI por mais de vinte anos, começando logo antes da febre das empresas .com. Ele tem sido um profissional prático na maior parte de sua carreira, lidando com servidores, armazenamento e segurança.\n\nMuitas pessoas pensam na Hitachi como qualquer coisa, desde uma empresa de equipamentos pesados ou ferramentas elétricas até uma que produz fabricantes de pão. A Hitachi é, na verdade, uma empresa de engenharia e manufatura centenária, iniciada em 1910 com a produção de motores elétricos, e se transformou em centenas de organizações operacionais e subsidiárias de propriedade integral, incluindo a Hitachi Vantara. A Hitachi Vantara é a maior subsidiária de propriedade integral, focada principalmente na gestão de dados. Eles constroem e fornecem não apenas sistemas tradicionais de armazenamento empresarial em bloco, mas se expandiram para uma empresa de soluções digitais que abraça a expansão extrema no IoT e em insights orientados por dados.\n\nRobert Mueller disse: \"Existem apenas dois tipos de empresas: aquelas que foram hackeadas e aquelas que serão. Isso está se fundindo em uma única categoria: aquelas que foram hackeadas e serão novamente.\" Essa citação prepara o cenário para como a Hitachi pode ajudar as empresas. Não é uma questão de se, mas sim de quando você será hackeado e quando será hackeado novamente. Isso se aplica não apenas às empresas, mas também às organizações do setor público.\n\nA Hitachi possui uma divisão federal completa que atua em Washington D.C., com foco principalmente no Departamento de Defesa e nas contas federais. A Hitachi Vantara trabalha muito com contas SLED (State, Local and Education) e trabalha em conjunto com a divisão federal para fornecer soluções para requisitos federais, estaduais e locais.\n\nA melhor maneira de visualizar uma solução de segurança da Hitachi é imaginar sua organização como sua casa e, nessa casa, existem quatro elementos de proteção que devemos implementar.\n\nA primeira é segurança física. A Hitachi possui um sistema inteligente, uma solução de inteligência visual, que pode fornecer vigilância por vídeo com inteligência. Ele pode fazer desde detecção de tiros até rastreamento de placas e reconhecimento facial. A Hitachi implanta isso em todo o mundo. As câmeras Hitachi captaram muitos eventos no shopping de Washington no ano passado e são usadas por organizações policiais em todo o país. Tudo isso cresceu a partir da divisão de transporte da Hitachi, que depende muito da tecnologia de vídeo para segurança.\n\nA segurança física geralmente não é um tópico de discussão, mas é um aspecto fundamental. Se você não pode controlar seu prédio e seu próprio centro de dados, então você não possui segurança. Se alguém consegue passar pela porta, eles podem entrar no seu centro de dados.\n\nDepois da segurança física vem a Hitachi ID. Isso é basicamente a fechadura da sua porta da frente. Uma pesquisa recente mostrou que apenas 40% das empresas possuem gerenciamento de acesso privilegiado e cerca de 74% possuem gerenciamento de identidade. Isso não é suficiente, pois isso representa uma grande exposição, e o espaço SLED é um alvo de alto perfil. A Hitachi ID oferece soluções de privilégio de senha e identidade em uma única plataforma; essa é uma solução completa onde você pode identificar não apenas usuários, mas também dispositivos e aplicativos, localmente e na nuvem.\n\nO terceiro aspecto é como proteger seus dados quando alguém consegue passar pela porta.\n\nA cibersegurança é um problema de dados em grande escala, e o Pentaho é a ferramenta para big data. Com o Pentaho, você pode gerenciar todas as suas fontes de dados, controlar seu data lake e produzir resultados úteis. A Hitachi descobriu que os cientistas de dados e os analistas de cibersegurança passam 80% do tempo apenas gerenciando, obtendo fontes e limpando os dados, e apenas 20% do tempo realmente analisando-os. Com o Pentaho, esses números se invertem, e eles podem passar 80% do tempo analisando os dados e se envolvendo em análise de ameaças em tempo real e resposta a ameaças.\n\nO Pentaho é um sistema de detecção de intrusões, mas também é um sistema de prevenção. Por exemplo, uma grande empresa de energia havia feito tudo de forma improvisada, escrevendo seus próprios scripts internamente. Eles migraram todas essas funcionalidades para o Pentaho em um único dia. Depois disso, eles foram capazes de realizar essa análise em tempo real e acompanhar os atacantes em vez de sempre estarem atrás. O que torna o Pentaho único em um campo lotado é a sua flexibilidade. Ele pode fazer qualquer tipo de análise de dados e pode ser baseado no que sua organização precisa.\n\nProteger dados de uma perspectiva de conteúdo também é muito importante para o espaço SLED (State, Local, and Education). O Hitachi Content Platform Anywhere oferece sincronização e compartilhamento de arquivos seguros, além de um dropbox seguro. É comparável ao Google Drive ou Dropbox, por exemplo, mas a diferença é que o HCP Anywhere é controlado pela sua própria equipe de segurança.\n\nÉ utilizado pelo Departamento de Defesa, que o renomeou para Mill Drive. Forças terrestres transmitem dados sensíveis de e para vários lugares secretos e de volta à sede para missões de reconhecimento e outros. Em nível local, as cidades o utilizam, transmitindo evidências em vídeo não apenas por meio da administração, força policial e outras agências, mas também para o escritório do promotor de justiça para gestão de provas.\n\nO HCP Anywhere é construído na Hitachi Content Platform, que é o seu sistema de armazenamento de objetos. Ele possui armazenamento de objetos embutido, não apenas da Hitachi, mas de todos os sistemas de armazenamento de objetos. Em vez de sobrescrever um arquivo e permitir que um invasor sobrescreva seu arquivo, você cria uma nova versão do arquivo. Assim, se você for atacado, pode voltar a uma versão anterior antes do ataque. Algumas agências de classificação concordam que o armazenamento de objetos da Hitachi é o melhor do mercado. Por padrão, você obtém 16 versões de cada arquivo, 16 metadados do sistema e uma quantidade ilimitada de etiquetas de metadados personalizadas também.\n\nA Hitachi também possui um console para gerenciamento de políticas de dados, além do Gateway da Plataforma de Conteúdo da Hitachi, que coloca um NAS na frente do armazenamento de objetos que pode ser NFS ou CIFS. Acrescentado a isso está o Hitachi Content Intelligence; é um mecanismo de busca superpotente. Você pode encontrar qualquer objeto em seu armazenamento com base em metadados, data, hora, etc. Ele pode se estender além do hardware físico próprio (ou da Hitachi) através de vários armazenamentos de objetos. A busca funcionará em qualquer coisa. Além disso, é 100% compatível com o AWS s3.\n\nPara os clientes SLED, há uma oportunidade com o parceiro da Hitachi, Flexential, de fornecer a plataforma de conteúdo da Hitachi como serviço. Se um governo municipal, por exemplo, não deseja aplicar seu próprio armazenamento de objetos, eles podem estar em um ambiente de multilocação por meio dessa parceria.\n\nFinalmente, a Hitachi System Security pode ajudá-lo caso você seja atacado por ransomware. Eles podem fornecer análise do impacto e negociar com os atacantes de ransomware. Eles podem começar a desenvolver posturas defensivas em torno da sua organização. Os atacantes não são jogadores solitários, mas organizações criminosas com desenvolvedores e gerentes, portanto, é necessário uma resposta profissional. A Hitachi System Security pode acompanhar uma organização do início ao fim.\n\nSe você é membro da ISSA, procure a Hitachi para patrocinar um evento na sua região.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Colin McLean","David Rowley"],"link":"/episode-EDT75-pt","image":"./episodes/edt-75/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, conversa com Colin McLean, Líder Global da Equipe Intel da Hitachi, e David Rowley, Consultor Sênior de Soluções, sobre as ofertas abrangentes de segurança cibernética da Hitachi."},{"id":149,"type":"Episode","title":"Dia na vida de um Arquiteto de Soluções em Nuvem.","tags":["csa","cloudsolutionarchitect","multicloud"],"body":"\r\n\r\nA equipe de Arquitetos de Soluções em Nuvem da Intel foi formada há menos de dois anos com poucas pessoas e cresceu rapidamente para 21 membros da equipe. Esse crescimento indica sua importância tanto internamente para a Intel quanto externamente para os clientes.\n\nÀ medida que os clientes migram do ambiente local para a nuvem em busca de flexibilidade e escalabilidade, eles precisam entender que a infraestrutura subjacente e os recursos são importantes para a otimização. Já que a maioria dos provedores de serviços em nuvem, incluindo os três principais, Google, Amazon e AWS, são alimentados pela Intel, os CSAs da Intel podem ajudar a otimizar os serviços ao longo de toda a jornada na nuvem de um cliente.\n\nUm dia típico para um CSA começa com tarefas administrativas, como emails, reuniões internas, reuniões de equipe, reuniões de funcionários e uma quantidade significativa de tempo conversando com clientes finais. Esses podem ser clientes da Intel que estão atualmente usando CPUs da Intel localmente e agora estão considerando migrar para nuvem, ou talvez já estejam na nuvem. Os CSAs também têm parceiros, integradores de sistemas, que estão interessados em saber como traduzir a aderência da Intel e algumas características, como firewall ABS or Boost ou criptografia.\n\nAs CSAs não trabalham apenas no papel de pré-vendas, mas também projetam provas de conceito, escrevem casos de uso e trabalham com uma equipe para executar benchmarks baseados na carga de trabalho de um cliente. Eles também passam tempo escrevendo ou coescrevendo playbooks.\n\nEles também criam um manual de treinamento para os próprios gerentes da Intel e para os vendedores parceiros.\n\nAlém disso, os CSPs estão anunciando novos serviços todos os dias, e os CSAs devem se manter atualizados sobre a tecnologia que suporta esses serviços e entender como eles podem beneficiar os clientes. Isso significa compreender as cargas de trabalho dos usuários e utilizar modelos também.\n\nOs CSAs da Intel veem a si mesmos como consultores confiáveis, uma extensão da equipe do cliente, em vez de tentarem tomar as decisões. Muitas vezes, por exemplo, um cliente saberá em qual nuvem deseja utilizar, mas precisará de ajuda para examinar quais ferramentas estão disponíveis para auxiliá-los na análise da sua carga de trabalho atual e, em seguida, correlacioná-las com as instâncias disponíveis na nuvem. Os CSAs também ajudarão e educarão os clientes sobre a análise de custos. A Intel possui um portfólio de ferramentas para cada estágio da jornada na nuvem.\n\nUma vez que um cliente esteja em funcionamento e tenha concluído o projeto inicial, eles entrarão em contato com os CSAs para novas iniciativas e projetos, à medida que o ciclo continua.\n\nCSAs têm um conjunto único de habilidades, pois passam muito tempo escrevendo, comunicando e educando, mas também entendendo todos os aspectos técnicos e necessidades dos clientes. Por exemplo, um CSA deve ser capaz de discernir se um problema é um problema técnico ou um problema de negócios. Os backgrounds dos CSAs da Intel são diversos, com diferentes culturas, habilidades técnicas, experiência em vendas e históricos de trabalho, para que tragam especialização em diferentes áreas. Eles também são uma fonte técnica profunda além de seu próprio pessoal. Se alguém quiser falar detalhadamente sobre os serviços da AWS, por exemplo, eles podem trazer um colega da AWS. Em outras palavras, os CSAs da Intel podem ser um único ponto de contato para todas as necessidades de serviços de nuvem do cliente.\n\nPor que um cliente deve utilizar a equipe da Intel CSA em vez da equipe de um CSP? A Intel é verdadeiramente agnóstica, pois seus chips e CPUs estão presentes em quase todos os provedores de serviços em nuvem. Não faz diferença para a CSA qual serviço um cliente escolhe. Além disso, muitas CSAs dos provedores não entendem as características internas da Intel disponíveis apenas em determinados tipos de instâncias. Por exemplo, um Intel CSA saberia escolher uma instância com processador Ice Lake em vez de Cascade Lake para proporcionar economia significativa de custos e melhoria de desempenho em suas aplicações. As CSAs dos CSPs não necessariamente teriam conhecimento dessas informações.\n\nA Intel também possui muitas ferramentas para coletar telemetria, seja em uma instância em nuvem ou em uma instância de metal nu. Os CSP CSAs não têm acesso a essas ferramentas. Eles podem solucionar problemas, mas apenas no nível do hipervisor. Portanto, se um cliente estiver com um problema, um CSA da Intel pode ir até o nível do chip e usar ferramentas de solução de problemas e telemetria para resolver o problema.\n\nA melhor forma de entrar em contato com a equipe Intel CSA é através de um gerente de contas. Tecnicamente, os CSAs fazem parte do grupo de vendas e marketing, então eles também estão procurando ativamente por oportunidades, como contatos do passado.\n\nOs serviços da CSA não são uma despesa extra. Na verdade, a Intel tem um programa onde eles financiarão a migração inicial para a nuvem. As CSAs trarão as ferramentas, pessoas e conhecimentos tanto do ponto de vista dos recursos humanos quanto do monitoramento. Isso ajudará um cliente em um ambiente novo a encurtar a curva de aprendizado. Em seguida, a monetização ocorre quando uma carga de trabalho está totalmente executando na nuvem ou quando a migração está ocorrendo e eles estão consumindo recursos.\n\nOs CSAs da Intel não possuem interesse específico em quais clientes os CSPs utilizam, mas apenas que sejam otimizados em um ambiente altamente seguro e confiável.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Kiran Agrahara"],"link":"/episode-EDT76-pt","image":"./episodes/edt-76/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com Kiran Agrahara sobre o que os Arquitetos de Soluções em Nuvem (CSAs) da Intel fazem em um dia para beneficiar não apenas os provedores de serviços em nuvem (CSPs), mas também os usuários finais."},{"id":150,"type":"Episode","title":"Transformação Digital em 2022","tags":["aiml","comms","data","edge","multicloud","cybersecurity"],"body":"\r\n\r\nComo cientista de dados chefe para o setor público da Intel, Gretchen passa seus dias conversando com clientes sobre os desafios de dados, gerenciamento de dados, governança de dados, ética em relação ao que estão fazendo e IA responsável.\n\nOs seis anos de Anna na Intel têm sido focados em IoT e na área do edge, sendo que os últimos três anos foram no setor público. Ambos concordam que 2022 será um ano emocionante, cheio de possibilidades transformadoras.\n\nDarren, Gretchen e Anna representam cada um diferentes partes da transformação digital com os clientes, mas se uniram para fornecer uma maneira comum de falar sobre o assunto, com seis pilares da transformação digital: computação em várias nuvens, computação de borda, inteligência artificial, aprendizado de máquina, segurança cibernética, gerenciamento de dados e comunicação. Eles concordam que essas serão as áreas de grandes transformações no próximo ano. A Intel está profundamente envolvida em todas elas, pois construíram o hardware e o software para apoiar cada um dos pilares. Os pilares são entrelaçados, e a Intel desempenha um papel fundamental em liderar a indústria para frente.\n\nO hardware da Intel é a base para a maioria dos provedores de nuvem. Do ponto de vista do software, a Intel otimizou os frameworks comuns que as pessoas usam para IA, ML ou aprendizado profundo, a fim de aproveitar ao máximo o hardware subjacente. Em alguns casos, o desempenho é de dez a 100 vezes melhor com base no software da Intel.\n\nNão apenas a Intel forneceu hardware para edge e comunicações, especialmente em 5G, mas também aumentou isso com arquiteturas de referência de software. Além disso, a Intel tenta fazer com que os ecossistemas funcionem para todos. Há um forte foco em sistemas abertos de maneira não proprietária, facilitando para novos entrantes e jogadores existentes terem uma presença expandida nesses novos mercados e oferecer avanços empolgantes. A Intel é um dos, senão o principal, contribuidor da comunidade de software de código aberto.\n\n## Pilar da Segurança Cibernética\n\nImplícitas nos projetos de hardware da Intel estão recursos de segurança e capacidades para garantir que os clientes no ecossistema possam proteger seus dados em todas as suas diferentes variações.\n\nA segurança nunca é estática; está sempre evoluindo. Apenas a Intel não vai resolver os problemas de segurança de uma organização. A segurança é uma interação com o que você faz com o seu hardware, como você incorpora os elementos de software certos e as fronteiras e políticas da sua organização.\n\nA Intel focaliza várias áreas, mas um papel fundamental está na raiz de confiança e autenticação de hardware. Muitos recursos podem ser integrados diretamente para alcançar isso. Um passo adiante são as cadeias de suprimento confiáveis ou transparentes que a Intel pode compartilhar com os clientes para instilar um alto grau de confiança. Essas capacidades estão melhorando constantemente e a Intel está sempre trabalhando para progredir.\n\nCiberataques estão no topo da lista de preocupações de muitos clientes devido às violações recentes. A Intel possui segurança, como execução confiável e áreas seguras. Eles possuem um conjunto completo de capacidades para o tipo de segurança que você deseja fazer, como criptografia, sem comprometer muito o desempenho. Há uma matriz completa de capacidades, incluindo um conjunto diferenciado de requisitos na borda, devido à perda da segurança física do centro de dados.\n\nArquiteturas com zero trust estão se tornando os frameworks especialmente prevalentes no setor público. Para o Departamento de Defesa, o zero trust é uma exigência. A Intel possui muitas capacidades que contribuem para o zero trust.\n\nUm tamanho não serve para todos com segurança, mas está claro que a segurança adicional já é coisa do passado. A segurança deve ser incorporada desde o início e deve ser constantemente iterada. As organizações devem sempre questionar se têm os protocolos corretos configurados, se têm as ferramentas corretas de detecção de ameaças e se existe confiança em toda a cadeia de suprimentos. Tudo isso é integral.\n\n## Pilar de Computação na Borda\n\nAgora que há tanto que pode ser feito com IA, ML e diferentes algoritmos, é empolgante ver como podemos explorar essas coisas no limite e otimizar as arquiteturas para entregar em torno desses casos de uso.\n\nExistem alguns modelos muito simples onde tudo funciona na nuvem, e apenas a coleta de dados é feita na borda. Se a conectividade permitir, então as latências podem ser compatíveis com as aplicações. A maior parte do processamento pode ser centrada na nuvem. No entanto, há inúmeros casos de uso em que isso não faz sentido devido à sensibilidade dos dados ou requisitos de latência. Portanto, existem discussões interessantes sobre como encontrar arquiteturas ideais para a borda e o que está acontecendo com a nuvem e a rede.\n\nPor exemplo, poderíamos ter uma arquitetura perfeita de coleta, uso e processamento imediato de dados para fornecer inteligência? Podemos incorporar isso na próxima rodada de treinamentos para que o modelo seja continuamente atualizado? Quão rápido podemos fazer esse ciclo? Isso é viável? Precisamos de todo o nosso treinamento na nuvem? Se todo o treinamento estiver na nuvem, qual é o intervalo certo para disponibilizar esses modelos atualizados novamente? E a borda pode ser leve o suficiente para usar o material gerado na nuvem? A borda ainda é muito complicada e há muitas possibilidades e questões fascinantes.\n\n## Pilar de Inteligência Artificial\n\nTradução: IA e ML permitem que a borda faça muito mais do que qualquer pessoa previamente considerava. Um único produto nem sempre é a resposta certa: trata-se de adequação ao propósito. O uso de código aberto é crucial e a capacidade de aproveitar microserviços para executar algoritmos na borda.\n\nPor exemplo, se você tiver algoritmos bem na borda fazendo o trabalho de leitura, você está falando sobre o fluxo de tráfego. A cadência das luzes vermelhas, amarelas e verdes pode ser alterada instantaneamente com base em quantos carros estão passando e, ao mesmo tempo, coletar dados para serem enviados de volta a um centro de dados maior, que poderia fazer reajustes. No final da semana, talvez faça sentido adicionar alguns microservices adicionais ou ajustar os algoritmos. Então, aquele container volta à borda e você pode responder melhor e continuar aprendendo.\n\nAlém disso, ao falar sobre adequação para fins específicos, largura de banda, latência e formato também são considerações.\n\nA produtividade das culturas é um bom exemplo. Um cliente coleta dados que vão para um centro de dados. Eles estão trabalhando nos modelos, mas isso não se traduz em informá-los de que precisam de mais fertilizantes ou de que existem desafios atuais com sol e chuva. Isso significa que a fórmula precisa ser alterada. É necessário ter os dados de produtividade das culturas, as informações, o algoritmo e os microsserviços em um formato muito menor. A latência e a largura de banda são diferentes, mas é possível ter uma unidade pequena no meio de um campo coletando esses dados e respondendo, por exemplo, ao fluxo de água ou à necessidade de fertilizantes para melhorar a produtividade das culturas.\n\nEsperançosamente, este ano, mais dos designs de borda se tornarão padronizados. Com o FlexRAM e o 5G, existem padrões, mas tudo o mais é o Velho Oeste. Muitas pessoas estão projetando coisas interessantes, mas não estão projetando de uma maneira que facilite ter esses microserviços em um contêiner e algoritmos de ML e AI. Em alguns casos, você precisa de vários algoritmos ponderados de maneira diferente, mudando a cada semana com base em novos dados e no novo treinamento. Precisamos ser capazes de fazer isso de uma forma em que não importe quem construiu um dispositivo. A criação de padrões não apenas em dados de AI e ML, mas também na borda, ajudará a explodir as capacidades.\n\n## Pilar de Comunicações\n\nA vertente comercial do 5G liderará o caminho com 5G em telefones por toda parte. No entanto, ainda há um tempo de espera para ter o tipo de equipamento do usuário para realizar diferentes tipos de aplicativos para borda ou empresas, por exemplo. A Intel está iniciando suas primeiras redes 5G com parceiros mais inovadores e menos voltados para o lado comercial. Embora seus parceiros comerciais já tenham isso por um longo tempo, redes privadas controladas para um propósito específico estão sendo liberadas e aplicativos estão sendo desenvolvidos. 2022 é o ano em que essas coisas se tornarão realidade.\n\n## Pilar de Gerenciamento de Dados\n\nDados que costumavam levar horas ou dias para serem absorvidos, preparados, analisados ​​e agidos agora podem levar minutos ou nanossegundos. Você também pode aproveitar diferentes modelos e, quando os pesos mudam, pode agir rapidamente e consumir os dados e fornecer melhores serviços. Mover dados, gerenciar esses dados e operacionalizar sua IA e ML fazem parte do que a gestão de dados traz para o mundo.\n\n## Pilar Multi-Cloud\n\nO pilar de multi-nuvem não significa provedores de serviços em nuvem neste contexto. Significa infraestrutura de forma geral e como abstrair essa infraestrutura para implementar novas capacidades em toda a borda, em provedores de serviços em nuvem ou mesmo na infraestrutura do seu próprio centro de dados. O objetivo com a arquitetura de multi-nuvem é que você conheça os usuários principais e, mais importante ainda, como os dados são gerenciados.\n\nDiferentes nuvens possuem diferentes capacidades e, dependendo dos casos de uso, podem utilizar diferentes nuvens para diferentes propósitos. A Intel possui arquitetos de soluções em nuvem que auxiliam os clientes a otimizar as cargas de trabalho entre as ofertas de nuvem.\n\nTodos esses pilares estão interligados e trabalham juntos. Procure por episódios futuros onde Darren, Gretchen e Anna continuam essa conversa.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart","Anna Scott"],"link":"/episode-EDT77-pt","image":"./episodes/edt-77/pt/thumbnail.png","lang":"pt","summary":"O Darren Pulsipher, Arquiteto-Chefe de Soluções, a Dra. Anna Scott, Arquiteta-Chefe de Edge, e Gretchen Stewart, Cientista-Chefe de Dados da Intel discutem os seis pilares da transformação digital em 2022: computação em nuvem híbrida, computação de borda, inteligência artificial, aprendizado de máquina, segurança cibernética, gerenciamento de dados e comunicações."},{"id":151,"type":"Episode","title":"Entendendo o Modelo de Segurança de Responsabilidade Compartilhada.","tags":["multicloud","compute","cybersecurity","sharedresponsibility","cloudsecurity","cloud","technology","process"],"body":"\r\n\r\n## Segurança na Nuvem\n\nA maioria das pessoas entende a responsabilidade da segurança no local, mas a responsabilidade se torna menos clara na nuvem. Se os dados estão protegidos na nuvem, como eles estão protegidos? Quem é responsável por essa segurança? E quanto à atualização das máquinas?\n\nRecentemente, os provedores de serviços em nuvem começaram a oferecer ainda mais serviços, então existem vários modelos. Às vezes, a segurança acaba se perdendo no meio.\n\n## Áreas de segurança\n\nExistem quatro áreas principais de segurança que precisamos entender.\n\n## Físico\n\nA segurança física é a parte fácil de reconhecer. Os provedores de serviços em nuvem são responsáveis pela segurança física de seus centros de dados, e você é responsável pela segurança física de seus próprios centros de dados. Além disso, você deve garantir a segurança do seu espaço físico. Se você é um fabricante, por exemplo, deve garantir a segurança das máquinas dentro de sua área. Um ataque recente ocorreu por meio do sistema HVAC que estava conectado à rede de uma organização.\n\n## Infraestrutura\n\nA segurança da infraestrutura não é o aspecto físico, mas sim o próprio hardware. Os switches da sua rede possuem os patches e atualizações de segurança corretos? Os dispositivos de armazenamento e unidades estão sendo atualizados? Estão sendo protegidos? A infraestrutura pode entrar em áreas cinzentas com os provedores de serviços na nuvem, então você deve saber quem é responsável por quê e em quais circunstâncias.\n\n## Aplicação\n\nPara segurança de aplicativos, é preciso saber quem tem acesso a um aplicativo e se ele está sendo atualizado com os patches de segurança corretos.\n\n## Data\n\nProteger seus dados é uma das coisas mais importantes que você deve fazer. Os dados podem, na verdade, ser usados como arma em um ataque de ransomware, onde os invasores os roubam ou os criptografam. Também estão sendo usados como uma vantagem competitiva poderosa em diferentes organizações. Você deve saber onde seus dados estão e como protegê-los.\n\n## Modelos de Entrega de Serviço em Nuvem\n\nExistem três modelos básicos de entrega em nuvem. Diferentes modelos são criados o tempo todo, mas os três principais são Infraestrutura como Serviço (IAAS), Plataforma como Serviço (PAAS) e Software como Serviço (SAAS). Vamos categorizar tudo o mais como X como Serviço (XAAS).\n\n## Infraestrutura como Serviço\n\nIAAS é quando você está alugando de um provedor de serviços em nuvem. Isso envolve máquinas virtuais e redes virtuais, como armazenamento, processamento e rede. Também estamos começando a ver coisas interessantes com aceleradores, como GPUs ou até mesmo processadores neuromórficos. IAAS é onde você executa suas aplicações.\n\n## Plataforma como Serviço\n\nA próxima camada acima da pilha é PAAS. Aqui é onde você obtém um certo framework, como o Kubernetes, para executar as coisas. O VMware funcionando em cima do IAAS é PAAS. Pipelines CICD como serviço possuem muitas ferramentas que se encaixam nesse espaço. PAAS permite que você construa e implemente novos serviços em cima dessa plataforma, para que você possa facilmente implantar e gerenciar sistemas grandes que são construídos em cima do IAAS.\n\n## Software como serviço\n\nPróximo é SAAS. Este é um software específico que é gerenciado pelo provedor de software ou pelo provedor de serviços em nuvem, ou pode ser uma oferta de SAAS de terceiros para outra pessoa. O importante com o SAAS é que eles são responsáveis pela segurança do aplicativo. Eles gerenciam o tempo de atividade e todas as áreas gerenciais, como confiabilidade, segurança e integridade. Muitos dos programas de SAAS são construídos em cima de plataformas PAAS.\n\n## X como serviço\n\nXAAS pode ser qualquer novo serviço, como inteligência artificial, gerenciamento de dispositivos ou detecção de segurança.\n\nCompreender esses diferentes modelos de entrega é importante porque os modelos de segurança compartilhados dos provedores de serviços em nuvem são baseados no modelo de entrega.\n\n## Domínios cibernéticos\n\nCada um dos seis pilares da segurança cibernética, como identificados por Steve Warren, CTO da Intel em um podcast anterior, é importante, quer você esteja na nuvem, no local ou na borda. Os seis pilares são detecção de ameaças, inteligência, análise e orquestração; gerenciamento de identidade e acesso; segurança de dados e aplicativos; segurança de rede; segurança da cadeia de suprimentos; e segurança de hospedeiros e sistemas. Todos esses seis domínios se encaixam no modelo de segurança de responsabilidade compartilhada que os provedores de serviços em nuvem estão defendendo.\n\n## Matriz de Segurança de Responsabilidade Compartilhada\n\nEssa responsabilidade compartilhada é ilustrada na matriz. As técnicas de entrega do modelo de serviço estão no eixo vertical: SAAS, PAAS, IAAS e on-prem. Se você estiver hospedando por conta própria, tudo à extrema direita é de sua responsabilidade.\n\nDo lado do IAAS, você é totalmente responsável pela segurança dos dados e das aplicações, e metade responsável pela infraestrutura, pois você ainda é responsável pelo controle de rede e sistema operacional. O provedor de serviços em nuvem é responsável pela rede física e pelo hospedeiro.\n\nNa camada do PAAS, você ainda é responsável pela segurança dos dados e tem meia responsabilidade pela segurança do aplicativo, identidade e infraestrutura de diretório. Existem algumas ferramentas disponíveis para ajudar nessas áreas. Embora você seja responsável pelos aplicativos e suas plataformas, eles são responsáveis pelos frameworks e middleware que estão sendo fornecidos. Embora a maioria do sistema operacional seja cuidada pela camada do PAAS e eles forneçam algumas ferramentas de nível superior, você ainda é responsável por configurar os controles de rede.\n\nAté o topo da pilha em SAAS, mesmo que você esteja utilizando armazenamento como serviço, dados como serviço ou um CRM como o Salesforce, você ainda é responsável pelos seus dados, pois ainda precisa projetar e criptografar seus backups e gerenciar contas e identidades.\n\nUm ponto-chave em todos os modelos é que você é responsável pela segurança dos seus dados; nunca há um cenário em que você deixe toda a segurança nas mãos dos provedores de serviços em nuvem. Você deve fazer o backup e perguntar se está usando armazenamento de objeto para poder reverter um ataque de ransomware, se está mantendo corretamente o gerenciamento de acesso e se está utilizando ferramentas que facilitam esse processo.\n\n## Diferentes Abordagens para Segurança\n\nCada um dos três principais provedores de serviços em nuvem adota uma abordagem diferente quanto à segurança, especialmente em relação à configuração de rede.\n\n## As seguintes: AWS\n\nA AWS foca na prevenção. Quando você cria uma VM, a configuração padrão é não ter nenhuma porta aberta, então você precisa criar grupos de segurança. A AWS é a mais restritiva, utilizando IAM para gerenciamento de identidade. A AWS é ótima para equipes de médio porte, mas não se sai tão bem para organizações muito grandes.\n\n## Azure\n\nAzure se concentra mais na facilidade de uso; a segurança é menos restritiva. Eles utilizam o conceito de redes virtuais para a segurança, então todas as Máquinas Virtuais (VMs) na mesma rede virtual podem se comunicar entre si nessa rede. Isso é o oposto da abordagem de confiança zero, então você precisa decidir o que é mais importante para você. O Azure utiliza o Active Directory, então se você já possui um Active Directory maduro e substancial, essa é uma boa forma de gerenciamento de identidade.\n\n## Google Cloud Platform\n\nA Google Cloud Platform também se concentra na facilidade de uso, mas eles apostam em máquinas virtuais (VMs) e segurança de rede. Você pode ter perfis que restringem totalmente tudo em uma VM, ou pode ter um perfil que abre um pouco mais. Eles estão no meio do caminho em termos de restrições. Embora não seja tão robusto quanto AWS ou Active Directory, o GCP possui um bom gerenciamento de identidade.\n\nTodos os três provedores de serviços em nuvem oferecem IAAS, PAAS, SAAS, Contêiner como Serviço e uma variedade de XAAS. Você deve avaliar o modelo de segurança e entender as diferenças em cada um.\n\nEm alguns aspectos, entender o modelo de segurança de responsabilidade compartilhada é mais difícil do que apenas executar as coisas localmente, pois agora há mais participantes envolvidos e a complexidade aumenta. A chave está em compreender os modelos e utilizar as ferramentas disponíveis para ajudar a gerenciar a segurança em várias nuvens.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT78-pt","image":"./episodes/edt-78/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções da Intel, explica os modelos de segurança de responsabilidade compartilhada. Quem é responsável pela segurança pode se tornar incerto na nuvem; a responsabilidade depende dos modelos de entrega de serviços em nuvem e de outros fatores."},{"id":152,"type":"Episode","title":"Integração de funcionários remotos.","tags":["covid","remoteworker","mobilementor","genz","people","process","compute","cloud"],"body":"\r\n\r\nApós uma carreira internacional na Nokia, Denis fundou a Mobile Mentor há 17 anos. A empresa surgiu de sua experiência de que as pessoas não estavam utilizando a tecnologia em seus smartphones. Embora os smartphones tivessem tecnologia avançada, as pessoas os utilizavam apenas para funções básicas como chamadas telefônicas e mensagens de texto. Um momento crucial ocorreu quando Denis estava tentando vender uma solução de rede para um CEO, e o CEO perguntou por que sua empresa deveria comprar mais infraestrutura quando os clientes não estavam utilizando o que a empresa já havia adquirido.\n\nDenis perguntou a si mesmo por que a tecnologia estava tão à frente do que os consumidores realmente queriam fazer com seus dispositivos. Ele deixou a Nokia e começou a Mobile Mentor para resolver esse problema. Ele contratou um exército de pessoas com conhecimento em tecnologia que sentariam com os clientes empresariais e os ajudariam a fazer seus smartphones funcionarem e permitir que fossem produtivos, posteriormente aprendendo muito sobre o que impulsiona a adoção da tecnologia e os hábitos das pessoas.\n\nHoje em dia, os trabalhadores remotos podem ter dois ou três dispositivos, além dos dispositivos pessoais. Eles trabalham de casa, do escritório e viajam. A maior parte do trabalho que a Mobile Mentor faz atualmente envolve fazer com que esses dispositivos funcionem e, o mais importante, garantir que eles sejam seguros.\n\nDesde que o número de trabalhadores remotos disparou com a COVID e muitas organizações não implementaram nem priorizaram a segurança adequada, houve e continua havendo uma avalanche de ataques hackers e ransomware. Os ataques de ransomware aumentaram em 500% desde o início da pandemia, tristemente visando escolas, hospitais e organizações municipais.\n\nAlém disso, com a escassez de chips, muitas corporações não conseguiram obter dispositivos suficientes para os trabalhadores remotos e tiveram que depender do BYOD (Traga Seu Próprio Dispositivo). O uso de fontes domésticas de internet também aumentou o perfil de risco.\n\nUma coisa que as organizações podem fazer para reduzir o risco é se livrar do uso de senhas. As senhas eram uma ideia fantástica em 1961, mas em 2021, dados mostraram que elas são a principal razão pela qual as organizações estavam sendo hackeadas. A maioria dos ataques começa com uma senha comprometida em uma operação de phishing.\n\nOs trabalhadores do conhecimento hoje têm um número ridículo de senhas. No entanto, apenas 31% das pessoas usam uma ferramenta de gerenciamento de senhas. Outros 31% escrevem suas senhas de trabalho em um diário pessoal e 24% escrevem suas senhas em um aplicativo de Notas em seus smartphones. Alarmantemente, de acordo com um estudo da BBC no ano passado, 15% da população britânica usou o nome de seu animal de estimação como senha e 6% usam a palavra \"password\".\n\nO primeiro passo para eliminar as senhas é adotar a biometria. Agora, um iPhone ou uma máquina Windows Surface escaneia seu rosto e faz login no sistema operacional e em todas as aplicações de login único e aplicativos de terceiros nos quais você possui identidade federada. Isso é um ótimo começo. O futuro da redução no uso de senhas será uma combinação de biometria e autenticação de dois fatores em todos os lugares. Enquanto isso, enquanto ainda existem infraestruturas de identidade legadas e aplicativos antigos nos quais a biometria não funciona, faz sentido utilizar uma ferramenta de gerenciamento de senhas.\n\nO Mobile Mentor fez uma pesquisa na indústria por geração e descobriu que a Geração Z tem a maior quantidade de senhas. Muitas dessas pessoas, na faixa dos vinte anos, ingressaram no mercado de trabalho e se integraram remotamente durante a pandemia. Em muitos casos, elas nunca conheceram seus empregadores e não vivenciaram as conexões sociais que ocorrem em um ambiente de trabalho. Elas têm uma perspectiva única na forma como avaliam seus empregadores.\n\nA pesquisa da Mobile Mentor mostra que as pessoas têm preferência por trabalhar em casa, mas em todas as indústrias, elas acreditam ser mais produtivas em um ambiente de escritório. Isso é um dilema e uma dicotomia interessantes para o empregador tentar fazer com que essas pessoas venham ao escritório. A pesquisa mostra que 67% da geração Z pensa que outras empresas estão fazendo um trabalho melhor ao fornecer tecnologia para seus funcionários. Portanto, se um empregador pressionar para que eles venham ao escritório, eles podem escolher um emprego diferente. Mudar de emprego hoje em dia não significa mudar o trajeto ou qualquer coisa além de usar um laptop diferente. Isso faz parte do que está acontecendo com a grande renúncia.\n\nCom essa dinâmica, a experiência tecnológica é importante. Pesquisas mostram que, em média, leva três dias para configurar completamente um laptop para o trabalho, comparado a dois dias para um funcionário de escritório. Um trabalhador remoto precisa abrir em média três chamados no serviço de suporte para colocar seu dispositivo em funcionamento, então sua experiência pode ser dolorosa. Eles não gostam do estigma de pedir ajuda.\n\nA melhor maneira de resolver esse problema é simplificar o processo. O provisionamento sem contato é ideal, que é o processo de configurar a tecnologia para que uma empresa possa enviar dispositivos diretamente para um funcionário remoto, e quando eles fizerem login com as credenciais de trabalho, os dispositivos se configurarem automaticamente. Tudo fica pronto em menos de uma hora, e ninguém do departamento de TI precisou configurar manualmente os dispositivos, reembalá-los e enviá-los ao funcionário. Há muito trabalho inicial para isso acontecer, mas a Mobile Mentor pode ajudar os clientes com esse processo.\n\nDenis acredita que os CIOs aprenderão conceitos importantes estudando a Geração Z e os trabalhadores remotos. Os trabalhadores da Geração Z trazem diferentes atitudes, em particular em relação à segurança e privacidade. Eles valorizam e priorizam a privacidade pessoal em detrimento da segurança, quase quatro para um. Para uma geração que cresceu com as redes sociais, isso é difícil de entender, mas os dados são claros. Eles têm uma hiperconsciência da política de privacidade de seus empregadores, mas quase ignoram as iniciativas de segurança corporativa.\n\nO conselho de Denis para os CIOs sobre essa questão é posicionar privacidade e segurança como duas faces da mesma moeda. A Geração Z pode ser envolvida na segurança se for apresentada como uma forma de proteger seus próprios dados, bem como os da empresa, e por extensão, os de seus clientes.\n\nA pesquisa da Mobile Mentor mostra que a TI sombria é impulsionada e acelerada pelos trabalhadores remotos. Trabalhadores remotos que moram longe da sede podem estar participando de uma equipe de TI que nunca conheceram e estão encontrando aplicativos, mecanismos de armazenamento e formas de comunicação e colaboração que suas empresas desconhecem. As fronteiras entre o pessoal e o trabalho também estão se confundindo. As pessoas usam dispositivos pessoais para o trabalho, e quase metade permite que membros da família brinquem com seus dispositivos de trabalho. O mesmo número considera as políticas de segurança de sua empresa muito restritivas e um terço afirma ter encontrado uma maneira de contornar essas políticas. Dois terços afirmam que são mais eficientes quando usam aplicativos de consumo, como Gmail e Dropbox.\n\nDenis aconselha CIOs a envolver trabalhadores remotos nas decisões de produtos futuros, pois são eles que irão testar as ferramentas de colaboração, ferramentas de armazenamento, aplicativos e processo de autenticação mais rapidamente do que qualquer pessoa baseada em um escritório.\n\nPara mais informações sobre a Mobile Mentor, acesse mobile-mentor.com. Há um site separado, endpointecosystem.com, onde eles compartilham todas suas pesquisas gratuitamente para educar e informar as empresas sobre o que está acontecendo com os trabalhadores remotos, ajudando a evitar a próxima onda de ataques cibernéticos e melhorar a experiência tecnológica do funcionário a bordo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Denis O&#39;Shea"],"link":"/episode-EDT79-pt","image":"./episodes/edt-79/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto-chefe de Soluções da Intel, Denis O'Shea, fundador da Mobile Mentor, falaram sobre sua experiência, pesquisas e conselhos no processo de integração de trabalhadores remotos, especialmente os trabalhadores da Geração Z."},{"id":153,"type":"Episode","title":"Protegendo o Teletrabalhador Parte 2","tags":null,"body":"\r\n\r\n## Tecnologias de Cliente para Segurança do Trabalhador Remoto\n\nA segurança no lado do cliente começa e termina com a capacidade de verificar o cliente com uma inicialização segura. A Intel tem fornecido essa tecnologia em nossos sistemas de clientes há anos com o Secure Boot com a Trusted Execution Technology (TXT) e, mais recentemente, o BootGuard (BtG). Nas plataformas mais recentes, temos o Intel Hardware Shield, um conjunto de tecnologias que garantem a segurança do sistema em seu nível mais baixo, no firmware e nível do BIOS. É assim que um sistema de controle de acesso empresarial pode verificar se um cliente foi inicializado com segurança e se possui o firmware correto e os controles de segurança corretos antes de ter acesso à empresa.\n\nA Intel também tem feito muito trabalho ao longo dos anos para ajudar organizações a proteger melhor seus dados. Além disso, permitimos que o cliente ative a criptografia em todos os lugares sem impacto no desempenho. Estamos implementando novas instruções em quase todas as gerações de nossos produtos, adicionando novas capacidades para garantir a segurança do teletrabalhador.\n\nNosso outro foco tem sido proteger as aplicações e seus dados em uso. É aqui que entram em cena as Extensões de Guarda de Software da Intel (SGX, na sigla em inglês). Isso permite que as organizações coloquem partes-chave das aplicações e dados importantes em ambientes de memória segura e criptografada. Com o teletrabalho, isso significa que você pode implantar aplicações em ambientes não confiáveis e ainda manter um alto nível de segurança.\n\nAlém disso, a nova tecnologia que a Intel introduziu na categoria de detecção de ameaças permite que as organizações obtenham uma visibilidade profunda das operações da plataforma para monitorar ameaças; nenhum malware pode se esconder. Essas tecnologias estão revolucionando a forma como detectamos malware usando aprendizado de máquina e inteligência artificial.\n\n## Tecnologias de centro de dados para garantir a segurança do teletrabalhador.\n\nMesmo se você tiver garantido os clientes, você também deve garantir o centro de dados. Ambos os lados devem ser protegidos porque seu sistema é tão seguro quanto o elo mais fraco. Muitas das técnicas para garantir o teletrabalhador são semelhantes às de garantir sua empresa: inicialização segura, segurança de virtualização e controles de isolamento. Novamente, tecnologias como Intel TXT e BootGuard permitem que você inicialize com segurança essas plataformas e ativos do centro de dados e da nuvem. Mais recentemente, introduzimos a tecnologia Intel Select Solutions for Hardened Security, que integra muitas das tecnologias de segurança da Intel em uma única plataforma que é ativada por padrão.\n\nVocê precisa ser capaz de proteger seus dados em escala, ou seja, ter a capacidade de usar todas as suas ferramentas de segurança sem afetar negativamente o desempenho. As ferramentas de criptografia acelerada por hardware da Intel (SHA, AES-2X, VPMADD52) tornam isso possível. As novas instruções e tecnologias QuickAssist da Intel são especificamente voltadas para as exigências de criptografia em escala empresarial e em nuvem.\n\nFinalmente, como você monitora a inteligência de ameaças e realiza auditorias em grande escala? A Arquitetura da Plataforma de Inteligência Cibernética da Intel (FPGA, DCPMM, Optane SSD) utiliza tecnologias de computação, armazenamento e memória de alto desempenho para dimensionar a plataforma de inteligência cibernética, mesmo com o acréscimo do maior peso da segurança externa com os trabalhadores remotos.\n\n## Soluções de curto prazo\n\nA educação do funcionário é a primeira linha para controlar as ameaças de segurança do teletrabalho. Orientação em segurança residencial e treinamento em segurança, ou reforço do treinamento anterior em áreas como acesso adequado aos dados, são cruciais. Seja pró-ativo com atualizações, empurrando as atualizações e exigindo que os usuários atualizem seus dispositivos. Se você tiver controle de acesso empresarial, soluções de ERM/DRM e DLP, ligue-os e expanda-os. Reavalie suas políticas para garantir que estejam de acordo com a nova realidade dos teletrabalhadores. Para conexões web, ative o TLS e garanta que esteja sendo aplicado. Utilize autenticação de dois fatores. A maioria das organizações pode pensar que não possuem infraestrutura para implantar isso, mas há uma variedade de fornecedores que podem ajudar nessa área sem exigir que você implante uma grande quantidade de infraestrutura nova.\n\nMuitas soluções são simplesmente higiene padrão: Certifique-se de que os agentes de segurança do seu ponto final estejam ativados e atualizados. Gerencie e aplique políticas de segurança para os diferentes tipos de dispositivos de usuário. Ative a criptografia de disco completo.\n\nAs organizações devem entender que os teletrabalhadores estão operando em um ambiente onde a probabilidade de um dispositivo ser usado por outras pessoas em várias circunstâncias é alta. Bons controles de segurança, principalmente a educação dos funcionários, podem contornar problemas e permitir que os funcionários operem sem impactos negativos.\n\n## Soluções de longo prazo\n\nUm plano de longo prazo para a segurança em um ambiente com funcionários remotos é agora necessário, seja para uma mudança permanente para mais trabalhadores remotos ou para lidar com outra pandemia ou situação similar. Existem várias medidas que as organizações devem tomar agora para apoiar essa realidade no futuro.\n\nUma das melhores práticas é implementar políticas de confiança zero. Isso reduz a dependência de confiar em todos os aspectos de usuários e clientes que chegam. Além disso, a autenticação multifator com usuários e dispositivos deve se tornar padrão em toda a organização. Para aqueles que ainda não adotaram o controle de acesso a dados baseado em ERM e políticas, agora é a hora de fazê-lo para proteger os dados tanto no local quanto fora dele. Implementar soluções de segurança em pilha profunda, em vez de apenas no nível de aplicação ou rede, é importante. Isso inclui boot seguro com atestação, virtualização e segurança de contenção, além de segurança e monitoramento de firmware. É importante estender a auditoria, a inteligência de ameaças e o monitoramento para ambientes de trabalho remoto, apesar da resistência dos usuários que não desejam mais monitoramento em seus sistemas. Também considere estender a segurança além do dispositivo nos locais de trabalho remoto sempre que possível, como dispositivos e redes gerenciados.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT8-pt","image":"./episodes/edt-8/pt/thumbnail.png","lang":"pt","summary":"Com muitos funcionários trabalhando em casa agora, como você se certifica de que eles estão trabalhando com segurança e ainda lhes dá a flexibilidade necessária para concluir seus trabalhos? Neste episódio, Darren e convidado especial Steve Orrin, CTO da Intel Federal, discutem como aproveitar a tecnologia Intel para ajudar efetivamente a garantir a segurança do teletrabalhador."},{"id":154,"type":"Episode","title":"Reunião com os arquitetos de soluções em nuvem da Intel","tags":["csa","cloudsolutionarchitect","solutionarchitect","people","compute","cloud"],"body":"\r\n\r\nA Intel investiu muito na contratação de alguns dos melhores Arquitetos de Soluções Certificados (CSAs) da indústria, com cerca de 80 arquitetos globalmente e 22 nos Estados Unidos. Esses são novos cargos com grande foco.\n\nStephen Holt é um CSA para a região leste e gerencia os outros CSAs nessa área. Anteriormente na Intel, ele se especializou em banco de dados, mas veio de diversos cargos em processos de negócios, análise e vendas, análise técnica e vendas técnicas na IBM e em uma variedade de startups. Ele traz toda essa experiência para a Intel para ajudar a equipe a trabalhar em conjunto e proporcionar valor aos clientes.\n\nKiran Agrahara é um CSA da Costa Leste e reporta para Stephen. Sua experiência é em infraestrutura de centros de dados com foco em virtualização de armazenamento de dados. Ele trabalhou nas indústrias de cabo e finanças. Nos últimos cinco ou seis anos, ele trabalhou com startups focadas em áreas como memória persistente e armazenamento definido por software. Quando os clientes perguntam a Kiran por que eles deveriam utilizar a especialização da Intel, ele responde que a Intel está em todos os lugares e ele quer espalhar essa mensagem para os usuários finais.\n\nAntes de Sarah Musick vir para a Intel como CSA, ela era uma parceira que trabalhava com software na área de migração e otimização em nuvem, que foi precipitada por algum tempo em análise de dados. Ela trabalhou para uma empresa de análise textual de aprendizado profundo antes disso e descobriu que o trabalho que ela fazia com dados trouxe muitas das coisas que ela fazia em sua primeira experiência de vendas técnicas em um ciclo completo. Ela aplica a análise de dados na migração em nuvem. Ela veio para a Intel por causa de sua integridade e seu papel no novo modelo de engajamento para todos, incluindo provedores de nuvem.\n\nTodd Christ está na Intel há 26 anos, com 30 anos de experiência em TI e no espaço de produtos. Recentemente, ele veio do grupo de soluções empresariais em nuvem da Intel, que faz parte do grupo de plataformas de data center. A Intel deseja atender os clientes onde seus dados estão, seja no local ou na nuvem. Todd arquitetou o Anthos, portanto, os modelos híbridos ou de várias nuvens são importantes para ele, e ele trabalhou diretamente com a Microsoft e o Google.\n\nUma grande mudança para ajudar os clientes a migrar para a nuvem é a simplicidade. Agora, os clientes não precisam pensar muito em hardware. Eles começam a realizar trabalhos significativos muito mais rápido, com menos complicação. Embora o hardware ainda seja importante, é abstraído. No entanto, é importante não perder de vista os fundamentos. É como ter um sistema de climatização que você nunca pensa até não estar funcionando corretamente, e aí se torna um problema. Por exemplo, há situações em que um cliente descobre que uma determinada carga de trabalho que eles migraram para a nuvem não está funcionando bem, então eles precisam revisar o hardware.\n\nA Intel tem estado presente com os provedores de nuvem desde o início deles, e eles se concentram nesses fluxos de trabalho. A Intel investe um esforço tremendo no ecossistema em nuvem que ajuda a melhorar o desempenho desses fluxos de trabalho na plataforma Intel.\n\nA Intel entregou 2 bilhões de núcleos para provedores de serviço de nuvem (CSPs) e mais de 90% do processamento na nuvem é feito em equipamentos Intel.\n\nOs clientes desejam escalabilidade rápida e desejam os recursos de computação o mais rápido possível; eles não se importam com o hardware. A verdade, porém, é que as cargas de trabalho de baixa latência funcionam muito melhor no hardware Intel do que em qualquer outro concorrente. O mais novo processador escalável Xeon de terceira geração, Icelake, é extremamente rápido. Assim que os clientes percebem que podem economizar significativamente, ele se vende sozinho. Portanto, parte do trabalho de um CSA é educar.\n\nEmbora os CSPs possam parecer vender serviços como uma utilidade que funciona sem problemas com 100% de confiabilidade, você não pode simplesmente transferir ou mover cargas de trabalho críticas para a nuvem.\n\nSe suas aplicações forem projetadas em um formato nativo de nuvem, então você não precisa pensar muito em implantá-las na nuvem. No entanto, se você tiver uma aplicação monolítica projetada para ser executada em um data center, por exemplo, você não pode simplesmente levantá-la e transferi-la para a nuvem, pois ela não está otimizada para ser executada em CPUs específicas. Ao usar ferramentas de otimização ou migração da Intel, os clientes podem tomar decisões informadas antes da migração.\n\nAlgumas cargas de trabalho podem não ser adequadas para a nuvem. É por isso que, especialmente na última parte de 2021, houve mais comentários sobre a repatriação. O pêndulo está voltando um pouco à medida que as empresas, em particular, aprendem o equilíbrio certo. É aqui que entram as CSAs. Nem tudo deve ir para a nuvem, e a Intel pode ajudar a determinar como otimizar as coisas. Alguns clientes estão descobrindo que, após transferir as cargas de trabalho para a nuvem devido a mandatos, não estão economizando dinheiro e até gastando significativamente mais do que manter as coisas em seu próprio data center. Ou talvez haja problemas de segurança porque há residência de dados em alguns lugares e a nuvem não está no país adequado.\n\nOs Intel CSAs são agnósticos, portanto, estão apenas interessados no que é melhor para as necessidades particulares dos clientes. Eles ajudam a tornar as cargas de trabalho mais móveis, para que os departamentos de TI se tornem mais maduros, possam trazer as cargas de trabalho de volta para seus próprios data centers ou movê-las para outro CSP no futuro, ou o que for mais eficaz em termos de custo. Os Intel CSAs podem ajudar os clientes de maneiras que os CSPs não estão abordando atualmente.\n\nMuitos clientes estão preocupados com dados porque é caro recuperá-los de um CSP (provedor de serviços na nuvem). A Intel possui uma equipe qualificada de pessoas que podem ajudar com essa questão. Eles estão bem informados não apenas sobre as estruturas para configurar modelos híbridos, mas também sobre a segurança, os firewalls e todos os pontos de acesso. Uma vez que seus dados estão atrás de um firewall, existem várias camadas de segurança que você precisa passar para acessar esses serviços. Portanto, a primeira coisa é que você precisa ser capaz de enviar seus dados de forma segura.\n\nMesmo em um cenário de várias nuvens, retirar os dados é caro. Se você estiver apenas migrando entre Azure e AWS, por exemplo, os dados ainda estão sendo migrados, e isso é um processo lento. Se os clientes têm terabytes ou até mesmo petabytes de dados locais que desejam mover para a nuvem, pode haver um serviço semelhante à nuvem que pode ser executado localmente, onde eles podem obter a facilidade de uso e funcionalidade de uma nuvem. Se você pensar na nuvem como mais uma função do que uma localização, existem mais possibilidades.\n\nA Intel está aqui para libertar as pessoas para realizarem o trabalho mais significativo para suas organizações, e a análise de dados vai desempenhar um papel fundamental nisso. Em 2022, ainda há uma enorme diferença entre a quantidade de dados que as pessoas possuem e a quantidade de insights que estão produzindo a partir deles. Apenas cerca de 3% dos dados são realmente usados para produzir insights. Portanto, há um tesouro enorme e os chipsets da Intel desempenham bem em situações em que há um trabalho de processamento robusto. A próxima etapa é processar esses dados.\n\nArquitetar sabiamente faz parte do futuro porque não é preciso reinventar a roda. Por outro lado, vão surgir soluções mais recentes que podem se encaixar bem em uma organização. O estágio da organização em sua trajetória também é fundamental. Empresas mais antigas e estabelecidas, que têm feito as coisas bem por muito tempo, por exemplo, podem ter bastante dívida técnica que potencialmente pode ser trabalhada. Elas precisam analisar a tecnologia subjacente e, eventualmente, levá-la a um lugar onde tenham agilidade.\n\nOs serviços da CSA (Customer Success Accelerator) na Intel não têm custo algum, pois a Intel deseja ajudar os clientes a executarem suas cargas de trabalho de forma mais eficiente e aproveitar a tecnologia Intel que é onipresente nas nuvens. A expertise e experiência dos CSAs da Intel são extensas e trabalham em equipe para ajudar com qualquer conhecimento que o cliente possa precisar. Os clientes devem solicitar ao seu representante de conta da Intel ou às vendas internas para obter auxílio de um CSA com migração e otimização na nuvem.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Stephen Holt","Kiran Agrahara","Sarah Musick","Todd Christ"],"link":"/episode-EDT80-pt","image":"./episodes/edt-80/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, arquiteto-chefe de soluções da Intel, conversa com os principais arquitetos de soluções para nuvem da Intel, Stephen Holt, Kiran Agrahara, Sarah Musick e Todd Christ, sobre como eles podem ajudar organizações, sem custo algum, a migrar para a nuvem e otimizar suas cargas de trabalho."},{"id":155,"type":"Episode","title":"Programação Heterogênea com OneAPI","tags":["cpu","fpga","gpu","heterogeneousprogramming","npu","oneapi","compute","technology","process"],"body":"\r\n\r\nO objetivo do oneAPI é ajudar a abstrair a enorme diversidade que está surgindo em hardware, para que os engenheiros de software possam aproveitá-la em níveis mais altos na pilha e obter o máximo desempenho do hardware. James, um engenheiro de software que também trabalha em proximidade com o hardware, adora o que o oneAPI pode contribuir em vista do crescente uso da computação heterogênea.\n\nA palavra heterogêneo aqui basicamente significa que existem diferentes dispositivos em um sistema que podem realizar cálculos, mas eles não executam o mesmo conjunto de instruções. Por exemplo, a CPU tem uma maneira de executar instruções e a GPU tem uma maneira diferente. FPGA, outros ASICs e dispositivos especializados têm diferentes maneiras de serem programados. Aproveitar todos esses é o objetivo.\n\nJohn Hennessy e David Patterson, líderes no campo da arquitetura de computadores, chamaram isso de nova era de ouro da arquitetura de computadores. Para arquitetos de computadores, é um momento incrível para projetar todo tipo de dispositivos especializados para fazer coisas melhores para domínios específicos, mas para programadores, pode ser difícil e até assustador devido à complexidade. É aqui que entra a iniciativa oneAPI e os produtos oneAPI.\n\nO nome, oneAPI, é tanto uma iniciativa com uma especificação quanto uma implementação. A iniciativa é um conceito simples: os desenvolvedores de software devem ter a liberdade de usar qualquer dispositivo que desejem com desempenho total, e sua codificação deve preservar seu valor; eles não devem ter que reescrever para cada novo dispositivo. Essas qualidades podem ser aplicadas a compiladores, bibliotecas, depuradores e qualquer tipo de ferramenta.\n\nUma grande quantidade de software para implementar certas especificações foi disponibilizada como open source. Muito disso é originado da Intel, mas também a Intel disponibiliza como pacotes de ferramentas para download, que já estão pré-construídos e prontos para serem utilizados, oferecendo suporte ao hardware da Intel. Outros fornecedores que participam da criação do oneAPI têm suas próprias implementações, então todos trabalham juntos nas especificações, mas cada um cria suporte para seu próprio hardware de forma aberta e multifornecedor.\n\nO objetivo em alto nível é escrever o código uma vez e que ele funcione bem em qualquer lugar. No entanto, trata-se de um problema complexo que exigirá ajustes de desempenho. Por exemplo, se um algoritmo estiver funcionando bem em uma GPU, ele funcionará em praticamente qualquer GPU de maneira similar. Se você trocar o algoritmo para ser executado em um FPGA, é possível maximizar o reuso do seu programa, mas você tem a opção de reescrever partes do algoritmo para que ele funcione bem. É uma abordagem complexa que oferece a capacidade de aproveitar qualquer hardware com diferentes graus de reescritas esperançosamente muito isoladas.\n\nVocê pode construir um código para diferentes dispositivos. Existem abordagens de tempo de execução ainda mais sofisticadas que permitem detectar o que está presente e executar diferentes trechos de código, para que você possa ter um código fonte comum que decide dinamicamente. Você pode aplicar um programa de implantação e ele pode descobrir o que está em sua máquina e usá-lo de forma dinâmica, em vez de solicitar ao usuário que execute um binário diferente, dependendo da máquina em que está.\n\nIsso é emocionante porque, por muito tempo, engenheiros utilizaram uma pilha de software que era a melhor para a sua máquina. Hoje em dia, eles querem compilar um programa que possa usar dispositivos de vários fornecedores. O programa deve reagir a isso. Para que isso funcione, o compilador precisa ser capaz de gerar código para esses vários dispositivos de maneira confiável. É aí que entra em jogo a abertura.\n\nAlguns vão argumentar que um sistema fechado terá um melhor desempenho, uma vez que as bibliotecas e a linguagem são ajustadas especificamente para as capacidades do hardware. Mas a questão é, como conseguir o melhor dos dois mundos? Se, por exemplo, houver uma implementação específica do fornecedor para uma biblioteca matemática, pode existir um programa comum. Grande parte do oneAPI não consiste em tentar reinventar o mundo inteiro, mas sim em tentar organizá-lo de forma a aproveitar o melhor em cada plataforma possível.\n\nOneAPI tem as capacidades de mover memória e mover dados. Diferentes modelos de programação ficam acima de OneAPI, e é sua escolha o quanto você quer se envolver na gestão da memória. Mover dados ao redor é caro e consome energia, então você não pode evitar isso, mas OneAPI oferece as ferramentas para gerenciar isso consultando o sistema e permitindo que seu programa tome as decisões corretas e dinâmicas que proporcionarão a melhor performance.\n\nA Intel tem décadas de experiência na construção de ferramentas para ajudar com ajuste e migração, além de compiladores altamente otimizados. O V2 ajudou a desenvolver a indústria em torno dos contadores de hardware em processadores, tornando-se a norma. Existem uma variedade de outras ferramentas de análise para fornecer feedback, desde a estrutura do seu programa até encontrar bloqueios e aplicações paralelas, até encontrar onde você precisa adicionar algumas travas. A Intel está disponibilizando todas essas ferramentas no formato oneAPI para serem mais versáteis do que apenas se trata de uma CPU.\n\nOs primeiros grupos a adotar o oneAPI incluem a computação de alto desempenho (HPC). Com a explosão de novas ideias de arquitetura de computadores, haverá uma quantidade ainda maior de diversidade e inovação nesse espaço. Os códigos grandes que podem ajudar a resolver os maiores problemas de engenharia do mundo, ou por exemplo, resolver problemas farmacêuticos e avaliar novos medicamentos, exigem o hardware mais recente e avançado. Portanto, esse conceito de portabilidade de desempenho está ganhando destaque em laboratórios nacionais, universidades e centros de pesquisa.\n\nO HPC de hoje são os servidores de departamento de amanhã, então a capacidade de usar diferentes hardwares requer que os engenheiros de software planejem e prestem atenção em quão portável é o código, porque o código não morre rapidamente; ele dura por décadas. Em alguns anos, os sistemas heterogêneos estarão presentes em todos os lugares, e agora é a hora de se educar sobre isso.\n\nOs engenheiros de software não precisam programar em paralelo para usufruir do oneAPI. Trata-se de utilizar coisas que são abertas e com capacidade de vários fornecedores e várias arquiteturas. Mesmo os engenheiros que estão no topo da hierarquia devem entender o que está na pilha e do que ela é capaz em termos de portabilidade e portabilidade de desempenho.\n\nA comunidade de IoT é outro grupo que tem estado à frente na programação em múltiplos dispositivos de computação heterogêneos e utilizando métodos diferentes para gerenciá-los. Suas capacidades de computação continuam a aumentar à medida que a tecnologia avança. Portanto, o oneAPI se aplica aqui e pode ajudar a formalizar ou padronizar coisas que foram inovadas primeiro no mundo embarcado.\n\nA ideia de uma API passou de ser uma ideia louca sobre a qual apenas algumas pessoas estavam falando para agora cada vez mais pessoas reconhecerem que faz sentido e resolve problemas em sua organização.\n\nO lugar mais simples para aprender sobre a iniciativa é no site oneapi.io. Para aprender sobre a implementação, clique na aba de implementação para encontrar links para as implementações Intel. Lá, você pode baixar diferentes pacotes de ferramentas. Procure pela Intel dev cloud para experimentar as ferramentas na nuvem gratuitamente, incluindo em diferentes hardwares. O site oneapi.io também oferece uma variedade de tutoriais e recursos.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","James Reinders"],"link":"/episode-EDT81-pt","image":"./episodes/edt-81/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, discute as capacidades e o futuro do OneAPI, um modelo de programação unificado, aberto e baseado em padrões, que oferece uma experiência de desenvolvimento comum em arquiteturas de aceleradores, com o Evangelista-Chefe do OneAPI da Intel, James Reinders."},{"id":156,"type":"Episode","title":"Mudando de Infraestrutura para Cargas de Trabalho","tags":["cloudmigration","cloud","compute","process","infrastructure","migration","workload"],"body":"\r\n\r\nAs conversas de Sarah com os clientes têm mudado de falar sobre infraestrutura para falar sobre cargas de trabalho. Uma razão óbvia para isso é a mudança do centro de dados para a transformação de recursos em commodities e para consumir qualquer coisa como serviço. Outra razão é a influência das equipes de aplicativos nas decisões arquitetônicas. As aplicações são o sangue vital das organizações de uma forma que não eram nem mesmo há cinco anos. A última razão é financeira: os orçamentos agora são categorizados por cargas de trabalho, em oposição aos gastos gerais de TI.\n\nUm desafio nesta transição de infraestrutura para carga de trabalho é encontrar um equilíbrio entre processos e carga de trabalho centralizados e descentralizados. Algumas coisas, como governança de segurança, são tratadas por um hub centralizado, enquanto outras são tratadas em equipes locais e menores. Grande parte das decisões está sendo delegada às equipes responsáveis por criar novos aplicativos e serviços dentro da área de TI e também para os clientes.\n\nA COVID foi um acelerador para promover mudanças e levar as organizações para a nuvem. Algumas organizações de TI estão permitindo que suas aplicações migrem para a nuvem sem restrições e preferem realizar as correções posteriormente do que desacelerar a inovação que está ocorrendo. Esse evento \"Cisne Negro\" é sem precedentes e ainda estamos vendo as consequências da rápida mudança de paradigma.\n\nO papel do CIO está de volta, mas apenas se eles começarem a pensar novamente sobre informações e cargas de trabalho ao invés de administrar um centro de dados. Claro, isso depende da organização. Organizações nativas em nuvem, ou aquelas que aspiram a ser nativas em nuvem, estão refatorando suas aplicações em tempo de execução porque desejam ser altamente ágeis. Quanto mais fazem isso, mais conduzem em direção à infraestrutura e serviço da aplicação, em vez de aceitar limites que existiam no centro de dados antes e trabalhar dentro desses parâmetros. Anteriormente, nessa situação, isso desencadeava inovação das equipes de aplicativos, pois lidar com um conjunto de premissas às vezes é a mãe da invenção, em oposição às possibilidades infinitas na nuvem.\n\nIsso é uma extremidade do espectro. Na outra extremidade estão as corporações de herança americana, as instituições. Normalmente, elas ainda possuem informações no mainframe. É uma situação de \"se não está quebrado, não conserte\", especialmente com aplicativos estáticos. A nuvem está permitindo que os CIOs pensem além da maneira antiquada de gerenciar esses aplicativos. Se os CIOs puderem adotar essas novas tecnologias, agora eles podem ver um caminho adiante.\n\nO processamento que está ocorrendo sob aplicações discretas é mais relevante do que nunca. A Intel desempenha um papel enorme ao abordar preocupações sobre desempenho ou custo em ofertas de nuvem, em parte porque eles desenvolveram aquelas tecnologias e também porque são uma das maiores empresas de software. Há uma quantidade vasta de conhecimento interno. Em outras palavras, nem todas as instâncias na nuvem são iguais, então a Intel otimizou as cargas de trabalho internamente para obter o máximo das instâncias de nuvem que estão usando.\n\nPor exemplo, muitas organizações estão migrando coisas para clusters do Kubernetes e a Intel faz uma tonelada de otimização nesse sentido. Eles podem ir além dos gráficos padrão do Helm com extensões que analisariam a saúde do nó abaixo, não apenas a disponibilidade bruta. Há muitas coisas que a Intel pode fazer para ajudar os clientes a melhorarem muito o desempenho e o custo, não apenas 2 ou 3 por cento, mas 30 ou 40 por cento?\n\nCada carga de trabalho não pertence à nuvem. A estrutura de uma organização tem impacto sobre onde a carga de trabalho deve ser alocada. A chave é ser inteligente em relação à nuvem.\n\nUma estratégia de multi-cloud bem sucedida consiste em ter uma nuvem primária e uma nuvem secundária. Quando muitos falam sobre multi-cloud, a motivação por trás disso é o medo de se prender a um único fornecedor. O local onde a maioria dos seus dados está armazenada tem influência sobre a estratégia de multi-cloud, assim como também é importante considerar onde as cargas de trabalho se encaixam melhor.\n\nPara desenvolver uma estratégia, os arquitetos de soluções em nuvem da Intel se envolverão em uma descoberta sobre o que a organização deseja fazer e quais são os problemas. A Intel frequentemente pode remediar muitos dos problemas com as ferramentas que têm à disposição. Os arquitetos de soluções em nuvem também contextualizarão as ofertas para tornar o processo mais rápido e eficiente. Parte do trabalho deles é ser educador, para que todos tenham as informações necessárias para avançar.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Musick"],"link":"/episode-EDT82-pt","image":"./episodes/edt-82/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, continua sua conversa com Sarah Musick, Arquiteta de Soluções em Nuvem da Intel, sobre a mudança de infraestrutura para cargas de trabalho. Por favor, coloque na playlist Abraçando a Transformação Digital."},{"id":157,"type":"Episode","title":"Direções IDC 2022","tags":["data","datacentric","people","process","idc2022"],"body":"\r\n\r\nDavid está baseado em Maryland, perto do epicentro governamental. Ele possui mais de 25 anos de experiência de fundo em desenvolvimento técnico e empresarial em infraestruturas críticas, como saúde, energia, financeiro e industrial. Grande parte de sua especialização está na borda: coisas no hiperlimite e espaço embutido, mas também nos problemas difíceis de acelerar cargas de trabalho e tentar obter o máximo de uma arquitetura que se traduza para empresas e nuvem.\n\nDarren, David e alguns de seus colegas participaram da conferência IDC para verificar se suas propostas e previsões estavam alinhadas com as tendências que a IDC tem observado, e saíram sentindo-se validados. Eles também foram ver se há lacunas que precisam entender e como podem utilizar as ideias e serviços da IDC.\n\nA maior tendência de longo prazo, sobre a qual toda a conferência foi baseada, é o digital em primeiro lugar, e como ele está impactando virtualmente todos os mercados. Meredith Whalen, Chefe de Pesquisa da IDC, ampliou o significado de digital em primeiro lugar. Essencialmente, qualquer organização, empresa ou governo, precisa perguntar como transformar a digitalização em um produto real. Até 2024, haverá cerca de US$ 10 trilhões para gastar em todos os mercados apenas em produtos digitais. Essa mudança no comportamento do consumidor está forçando o governo a analisar a digitalização também, não apenas em seus serviços, mas em como eles abordam o comércio mundial, as economias e as moedas.\n\nIsso é um desafio particular para os governos em todos os níveis, pois eles lidam com redes de computadores em muitos sistemas diferentes e, em muitos casos, estão isolados uns dos outros. Pontes eficazes ainda não existem para conectá-los. Os sistemas governamentais precisam analisar como podem tornar as coisas mais eficientes e simples.\n\nA próxima grande tendência é uma virada com a computação em nuvem. Cada provedor de serviço em nuvem (CSP) possui sua própria infraestrutura, e as estruturas construídas não são necessariamente portáteis, então pontes são necessárias. Atualmente, os CSPs são não fungíveis. É verdade que eles só querem que os clientes usem sua infraestrutura, mas à medida que ambientes de desenvolvimento de software e aplicativos são construídos por meio de suas lojas de aplicativos, é difícil movê-los. CEOs e CIOs não estão apenas perguntando se estão utilizando as licenças de software e acesso que compraram, mas estão mais focados em saber se o uso gerou o resultado desejado.\n\nO modelo CSP atual tende a ser ineficiente levando em consideração os resultados empresariais. Os clientes precisam de ecossistemas de software trabalhando juntos para entregar esses resultados. Eles estão buscando múltiplos ecossistemas que trabalhem em conjunto, com os ecossistemas se movendo perfeitamente por várias nuvens e nuvens híbridas. Portanto, a tendência é que os CSPs se tornem substituíveis, e os construtores de pontes serão importantes nesse aspecto. Isso é a reviravolta.\n\nOs dados de hoje são fungíveis. Você pode movê-los, é claro, com um custo associado, mas pode também copiá-los, modificá-los, etc. A tendência, no entanto, está caminhando para dados não fungíveis. Quando esses dados, ou ativos digitais, possuem propriedade, isso cria enormes impactos no futuro em relação à forma como os dados são tratados em áreas como segurança, confiança e modelos de negócio e ecossistemas que giram em torno disso. Haverá entidades de dados que você terá que aceitar e confirmar a validade de quem as possui e de onde elas vêm, e toda a política que envolve isso.\n\nNessa evolução, haverá prós e contras. Por um lado, os consumidores têm mais poder sobre sua própria privacidade se tiverem direitos sobre seus dados. O mesmo se aplica às empresas e organizações. Por outro lado, com entidades e ativos de dados não fungíveis, os ecossistemas de software e os cientistas de dados que utilizam os dados têm que lidar com isso de forma mais concisa e estruturada. A longo prazo, todos terão que gerenciar isso. Os governos não estão diante desse problema, mas isso vai se tornar uma parte cada vez mais importante de como eles lidam e misturam o comércio, não apenas em bens físicos, mas também em bens digitais.\n\nQuão real é o conceito de \"digital first\"? Um exemplo disso são os tokens digitais como moeda real, como na comunidade de jogos. Os tokens digitais fazem parte desse mundo em relação à forma como aplicativos e ecossistemas usam dados não fungíveis. Outro exemplo é na área da saúde. Hoje em dia, você pode ir ao médico ou consultá-lo virtualmente, e eles podem ver o que está acontecendo e você pode descrever os sintomas. Isso tudo muda com o uso de dispositivos (wearables) em tempo real, que podem monitorar os níveis de glicose, frequência cardíaca, mudanças de peso, etc. Esses dados pertencem ao indivíduo, então precisam ser seguros e autenticados, mas também podem ser usados para serviços que não sejam apenas sobre sintomas, mas para algoritmos personalizados e serviços relacionados ao que está acontecendo de fato em seu corpo, a fim de obter os melhores diagnósticos.\n\nPontos de dados a serem considerados: Meredith Whalen mencionou que em 2021 os gastos com serviços superaram os gastos regulares licenciados em TI pela primeira vez. Portanto, como o serviço é dominante atualmente, a tendência é que ele se mova para um modelo baseado em resultados. Em 2023, a IDC espera que os gastos digitais sejam maiores do que os gastos não digitais em empresas de todos os setores. Cada indústria terá variações, mas em um nível macro, 2023 será o ponto de virada. Em 2024, o quadro de talentos seguirá a mesma tendência. A IDC prevê que a maioria das empresas gastará mais em talentos técnicos do que em talentos não digitais.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Richard"],"link":"/episode-EDT83-pt","image":"./episodes/edt-83/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren, Arquiteto Principal de Soluções, Setor Público, Intel, e David Richard, Arquiteto Principal de Soluções, Departamento de Defesa, Intel, refletem sobre as tendências e ideias que captaram na conferência IDC Directions 2022."},{"id":158,"type":"Episode","title":"Protegendo seu Castelo com Confiança Zero","tags":["cybersecurity","zerotrust"],"body":"\r\n\r\nO antigo modelo de segurança poderia ser comparado a um castelo, com guardas ao longo da estrada e um fosso cercando o castelo. Todas as joias da coroa, neste caso, dados, estariam localizadas e gerenciadas centralmente dentro do castelo. A emergência da confiança-zero criou um novo framework.\n\nA maior ameaça aos dados é o usuário final, portanto, a estratégia número um é um plano de trabalho que começa na borda externa com pilares de excelência e proteções internas. Essa forma atualizada de pensar permite que as organizações envolvam sua missão e parceiros comerciais de maneira real na conversa.\n\nO antigo estilo de pensamento era mais baseado em uma abordagem de concha rígida, com proteções e controles nos pontos vulneráveis. Uma parte fundamental da arquitetura de confiança zero é uma abordagem baseada em riscos, que é mais dinâmica e se baseia em duas coisas: o que funcionou e o que não funcionou no passado. Então, se os atacantes entraram pela porta esquerda da última vez, é claro que você reforçará as defesas lá, mas também aprenderá com esse ataque e reforçará outros lugares com base no novo conhecimento sobre como isso aconteceu. Uma abordagem baseada em riscos não é apenas resolver o último ataque, mas pensar adiante e aplicar os controles corretos para ameaças atuais e futuras em toda a empresa.\n\nParte da abordagem baseada em risco é entender o ecossistema. Clientes, parceiros e utilizadores são todos parte do cálculo de segurança. A antiga abordagem de casca dura não funciona. Assim como um castelo tem pessoas e suprimentos entrando e saindo, e as riquezas podem estar localizadas em vários pontos do reino, a confiança zero leva a segurança um passo adiante, considerando todas as entradas e saídas dos dados ou das pessoas que estão acessando-os.\n\nTradicionalmente, alguém poderia ter acesso com um único registro ao castelo corporativo. Existem vários princípios de zero trust (confiança zero), mas as duas bases são negação padrão e monitoramento e autorização contínuos. A confiança não é automaticamente conquistada, nem é permanente. Por exemplo, se um visitante entra no castelo, eles são validados na recepção e depois perguntam qual é o motivo da visita. Eles podem ser autorizados a visitar uma pessoa em um determinado quarto por um certo período de tempo, e serão acompanhados durante a visita. Também será feito um monitoramento do que eles trazem e levam em sua visita.\n\nA abordagem \"zero trust\" aplica-se ao acesso em todos os locais: data centers, nuvens, dispositivos de borda, ambientes empresariais, etc. É centrada em dados e acesso, casada com uma abordagem baseada em risco. Deve haver mais estratégia envolvida. A abordagem resultante baseada em \"zero trust\" não descarta o que funcionou bem antes, mas combina os bons processos, princípios e tecnologias e adiciona um elemento temporal.\n\nEste novo elemento não é tão difícil como muitas vezes tem sido retratado, mas é um problema de processo e cultura que pode ser complicado.\n\nMuitos desenvolvedores têm o medo de que uma arquitetura de confiança zero os torne mais lentos, mas especialistas em segurança e desenvolvedores precisam ter uma parceria para superar essa percepção. Um exemplo do mundo real é o Log4j. Há seis meses, os desenvolvedores podiam baixá-lo sem problemas, mas agora o ambiente de ameaça mudou. Sem uma abordagem baseada em riscos, um desenvolvedor seria capaz de baixar o Log4j até alguém da segurança chegar e desativá-lo. Com uma abordagem baseada em riscos, juntamente com abordagens de acesso, o Log4j estaria indisponível e uma alternativa seria oferecida. Outro exemplo seria quando o Log4j já está incorporado em um produto, a avaliação dinâmica de confiança poderia adicionar controles extras em vez de bloqueá-lo completamente. Trata-se dos dois lados do cálculo em jogo.\n\nEsta parceria é similar ao treinamento conjunto e compartilhamento de informações que acontece no processo de incorporação de segurança no desenvolvimento. À medida que um produto está sendo construído e testado, a segurança também monitora e avalia os riscos tanto para as entidades com as quais você está trabalhando quanto para as vulnerabilidades do produto em tempo real. Desenvolver uma abordagem baseada em riscos no processo aproveita a inteligência que aborda grande parte do que percebemos como difícil.\n\nQual é o primeiro passo para CISOs, CIOs ou CTOs iniciar o zero trust? Cameron sugere abandonar o \"geekspeak\" e comunicar em inglês comum. Iniciar a iniciativa pode ser desafiador, pois normalmente os líderes trabalham com um resultado ou objetivo em mente. O zero trust não tem um objetivo definido para trabalhar, além de criar um ambiente mais confiável para que os usuários operem. Existem, é claro, KPIs e outras medidas para mostrar aumento da segurança, mas é uma jornada, não um destino. Ele também enfatiza o financiamento contínuo; não incorpore o orçamento de cibersegurança ao orçamento de TI. Precisa ser separado e distinto.\n\nO melhor lugar para encontrar informações de alto nível com orientações práticas é a publicação do NIST SP 800-207. Ele também apresenta os cinco pilares de confiança, que são bons pontos de partida.\n\nUm aspecto fundamental primário é ter um bom inventário de ativos do que precisa ser protegido, como fontes de dados, bancos de dados, processos de negócios e aplicações de transação. Basicamente, você precisa definir o perímetro do seu castelo. É importante não apenas pensar no que você possui, mas no que você depende, como o ambiente SAAS, a infraestrutura de nuvem e ferramentas de terceiros.\n\nO panorama maior é conhecer sua cadeia de valor. Não é apenas o que está dentro do seu castelo, mas sim como você ganha dinheiro, como esse dinheiro é distribuído, quem você paga e seus fornecedores. Cada um é uma peça crítica da cadeia.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin","Cameron Chehreh"],"link":"/episode-EDT84-pt","image":"./episodes/edt-84/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren discute a segurança de confiança zero com Steve Orrin, CTO do Setor Público da Intel, e Cameron Chehreh, VP-GM do Setor Público."},{"id":159,"type":"Episode","title":"Inteligência Artificial e Segurança","tags":["aiml","cybersecurity","devops","compute","technology","process"],"body":"\r\n\r\n## Falhas de IA\n\nRecentemente, Darren pediu a uma turma de estudantes do ensino médio e da faculdade que estavam estudando IA para encontrar falhas na IA. Eles encontraram exemplos como o Microsoft Tay, um chatbot que aprendeu conversação casual a partir do Twitter e, dentro de 24 horas, estava proferindo comentários racistas e misóginos com base em manipulação de feeds do Twitter. Outro exemplo foi um sistema de rastreamento de bola do Inverness Football Club que deveria rastrear uma bola de futebol, mas acabou rastreando a cabeça de um árbitro calvo ao invés disso. Mais grave foi um acidente fatal quando um veículo autônomo da Uber não reconheceu um pedestre fora da faixa de pedestres e falhou em parar.\n\n## Implantando soluções\n\nTodos esses fracassos de IA têm a ver com dados. Ao implantar soluções de IA, você deve se fazer perguntas críticas: Onde estou fazendo minha inferência? O ponto final é seguro? Se você estiver fazendo todas as suas inferências no ponto final, talvez com detecção de objetos por meio de uma câmera, por exemplo, é preciso garantir que seja seguro; ninguém deve ser capaz de manipular os dados, a câmera ou o modelo.\n\nOutra pergunta é, o que vai ser implantado? Vou implantar uma rede neural ou algoritmo na ponta, ou apenas transmitir os dados de volta da ponta para um centro de dados para fazer a inferência lá? Além disso, quando a IA for operacionalizada, você precisa perguntar com que frequência os modelos ou algoritmos serão atualizados.\n\n## Pipeline de IA\n\nO pipeline para o desenvolvimento de IA, treinamento, teste, implementação e inferência requer três coisas: a aplicação, o modelo e os dados. Essas três coisas devem migrar juntas pelo pipeline e serem protegidas simultaneamente. É necessário garantir que os dados de produção não sejam manipulados, mesmo durante a produção.\n\n## Ameaças de segurança de IA\n\nAs ameaças para a IA são significativas, seja por espionagem, sabotagem ou fraude, porque a superfície de ataque é ampla.\n\n## Ataques\n\nPrimeiro estão os modelos. Um modelo pode ser manipulado, como alguém colocando adesivos pretos e brancos em placas de pare para que elas não sejam reconhecidas como tal, ou alguém mexendo com detecção de correspondência de padrões, para que os ataques fiquem indetectáveis. Os modelos devem ser protegidos não apenas durante o treinamento, mas também durante os testes, implantação e inferência. Criptografia, controle de acesso e controle de modelo e versão são essenciais, assim como seriam no desenvolvimento de um aplicativo.\n\nOs dados de treinamento e produção da fonte também devem ser protegidos contra manipulação.\n\n## Tipos de Ataques\n\nUm artigo do Belfer Center coloca as ameaças em um eixo de formato e um eixo de visibilidade. O eixo de formato varia do físico ao digital. O eixo de visibilidade varia de perceptível a imperceptível.\n\n## Ataques físicos\n\nAtaques físicos podem alterar itens físicos, como o adesivo na placa de pare. Esses ataques foram evidentes desde cedo com a condução autônoma e o reconhecimento facial. Precisamos de um melhor treinamento dos algoritmos de IA para esses ataques, utilizando técnicas de aprendizado reforçado e aprendizado de casos negativos.\n\n## Ataques Digitais\n\nOs ataques digitais são mais difíceis de detectar, pois não são visíveis. Um ataque poderia ser ruído branco injetado no fluxo de dados para perturbar o algoritmo. Esses ataques são difíceis de combater, a menos que a inferência seja realizada na borda ou a detecção de padrões seja implantada. Por esse motivo, é essencial saber de onde os dados de origem estão vindo, tanto nos dados de treinamento, teste e produção de origem.\n\n## Identificar as Fontes de Dados\n\nAs fontes de dados devem ser verificadas e testadas a partir de fontes de dados públicas. Os dados de código aberto não são bem protegidos. Considere a possibilidade de gerar fontes de dados, para ter mais controle. Se você usar uma fonte de dados compartilhada, utilize um sistema de controle de versão, como o GitHub ou o GitLab, para verificar a consistência. Os dados de teste também precisam de controle de versão, controle de acesso e outras medidas de segurança, assim como normalmente são feitos em um pipeline de DevOps.\n\nA última parte, mais desafiadora, é proteger os dados de produção. Fazer a inferência o mais próximo possível dos dados é um bom começo. Muitas especulações podem ser feitas logo na borda com processamento neuromórfico e até conjuntos de instruções nos processadores Intel para reduzir o risco de manipulação dos dados durante o transporte. Em vez disso, você pode criptografar os dados e enviá-los de volta para o centro de dados.\n\nProteger e Gerenciar Dados / Pipe de IA Seguro.\n\nDepois de identificar todas as suas fontes de dados, existem três aspectos críticos para proteção: controle, segurança e criptografia.\n\nO primeiro é o controle. Você deveria ter controle de versões, bibliotecas protegidas, e backup e restauração em caso de arquivos de dados corrompidos. Essas são práticas de segurança padrão e essenciais que a IA deve adotar, assim como acontece no desenvolvimento de aplicativos.\n\nA segurança deve incluir a autorização de acesso, até mesmo alguns conceitos de confiança zero, como fornecer acesso a pessoas que o necessitam apenas por um curto período de tempo. Certifique-se de que os modelos não estejam sendo manipulados e garanta que estejam vinculados a aplicativos específicos.\n\nOs dados devem ser criptografados em repouso, em trânsito e em uso. No passado, isso era caro em termos de utilização da CPU e tempo, mas agora grande parte da criptografia está embutida no silício e é muito rápida, com mínimo ou nenhum atraso de desempenho.\n\n## Chamada para Ação\n\nA data é fundamental para tornar a IA bem-sucedida e segura, portanto, proteja-a e utilize as melhores práticas imediatamente em termos de segurança. Opere pipelines para eliminar a necessidade humana de implantar e testar algoritmos de IA diariamente. Automatize o máximo possível e injete segurança no pipeline de IA DevOps para proteger seus dados de origem, modelo e aplicação.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT85-pt","image":"./episodes/edt-85/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren discute os aspectos de dados da inteligência artificial (IA) e a importância de proteger esses dados."},{"id":160,"type":"Episode","title":"As Coisas que Eu Gostaria de Saber como CTO do Governo","tags":["cto","people","process","change","organizationalchange"],"body":"\r\n\r\nO que Jason e Ron aprenderam desde que se juntaram à Intel que eles desejavam saber quando estavam no exército?\n\nJason ficou surpreso com o quanto as soluções integradas da indústria eram melhores e desenvolveram algumas capacidades incríveis que estavam faltando no exército. Ele aprendeu que os casos de uso empresariais mostram que entender o conjunto de problemas do cliente é mais valioso do que simplesmente empurrar tecnologia. Os CTOs precisam conhecer a tecnologia e aprender como mudar a cultura dos membros da equipe para se adaptarem a ela. Tornar a experiência do usuário mais amigável, construir a tecnologia de forma mais inteligente, enxuta e rápida, e conseguir que as pessoas se envolvam são o que pode tornar as transições mais suaves. Ele gostaria de ter visto mais resultados e soluções no exército em vez de apenas produtos.\n\nRon concorda com a avaliação de Jason e acrescenta que o desafio que ele viu de dentro do governo era como fazer com que a indústria se juntasse como parceiros de solução da missão, para que pudessem melhor informar as equipes militares sobre como aplicar sua tecnologia nessas missões. Uma ótima tecnologia sem entender como resolver o problema real da missão pode ser um desastre.\n\nOutro elemento em que ambos concordam ser importante é a experiência do usuário. A correspondência da tecnologia com as pessoas que precisam operá-la é fundamental. Nem todos que usam a tecnologia precisam ter um Ph.D. em engenharia. A experiência do usuário deve ser projetada de acordo com o nível de habilidades das pessoas. O resultado raramente é independente dos seres humanos. Ao trazer soluções para a defesa ou indústria, é necessário entender as necessidades tecnológicas da missão, mas também todo o espaço e como operar dentro desse espaço. Especialmente no âmbito militar, é preciso planejar para executar em momentos em que as coisas não tenham corrido bem e fazê-las funcionar. A tecnologia não irá vencer se não houver um planejamento para o elemento humano e para circunstâncias desafiadoras.\n\nQuais são as maiores ou mais emocionantes surpresas para Jason e Ron ao fazerem a transição do meio militar para a indústria privada?\n\nJason e Ron afirmam que não esperavam uma cultura distinta de trabalho em equipe inerente ao serviço militar na indústria privada da Intel. Ambos acharam a experiência de integração e o suporte contínuo encorajadores. Eles apreciam a atitude geral de estarem juntos nisso e a capacidade de criar coisas com uma equipe dinâmica, mais incrível do que nunca poderiam fazer sozinhos.\n\nAmbos reconhecem que não são esperados apenas para vender produtos da Intel, mas para ajudar os clientes a resolver desafios e fornecer feedback aos clientes à Intel. Eles estão na Intel para resolver problemas, especialmente no setor público, talvez com tecnologia que ainda não tenha sido criada.\n\nQuais são as lacunas tecnológicas que Jason e Ron veem no Departamento de Defesa ou Intel?\n\nPrimeiro e acima de tudo, Jason diz, estão as operações em nuvem, e isso é uma dinâmica em constante mudança no DOD. Comandantes no campo de batalha são avessos ao risco. Não há espaço para DDIL. Conforme as operações em nuvem evoluem, é necessário reimplementar e reaprender todo o trabalho em operações em nuvem precisas e nos benefícios da capacidade de borda para nuvem, que oferece informações em tempo real e precisas que chegam às pessoas certas no momento certo. Todos devem ter consciência da situação e uma imagem operacional do que está acontecendo.\n\nRon acredita que a próxima coisa da lista é aumentar a cibersegurança à medida que a superfície de vulnerabilidade aumenta. Se o militar não seguir em direção à confiança zero ao se tornar uma borda competente e altamente móvel, os resultados durante um conflito poderiam ser desastrosos. A questão do DDIL é enorme, mas deve ser seguro contra a superfície de vulnerabilidade aumentada.\n\nJason acredita que a tecnologia deve avançar apesar do risco, pois o exército sempre sai vencedor com a informação. Seja em missões da FEMA, fornecendo energia nuclear a uma cidade, montando hospitais de campanha durante a COVID ou no campo de batalha, o avanço tecnológico, especialmente o 5G, é crucial para as operações. Os líderes do Departamento de Defesa devem ter informações e a capacidade de se comunicar com suas sedes para orientações, especialmente em operações de combate, onde a liderança pode mudar por meio de baixas, até o mais baixo cabo.\n\nRon usa o exemplo de que a mais alta prioridade da defesa nacional é nunca ter que lutar contra um adversário em território nacional. Como os Estados Unidos podem não ter uma vantagem quantitativa fora de casa durante um conflito contra um adversário que também pode ser tecnologicamente avançado, o exército precisa ser mais capaz. O exército deve continuar a fornecer capacidade aumentada para as forças de defesa nacional e fazê-lo de forma segura, apesar da maior exposição à vulnerabilidade. Esses problemas devem ser resolvidos para que os operadores possam confiar nos dados e utilizá-los de forma eficaz em um ambiente de jogo fora de casa. Não há opção além de seguir nessa direção.\n\nJason acrescenta que outro campo em que o DOD tem sido lento em se adaptar é a IA devido à falta de pessoas com qualificações adequadas. Você não sai da Escola de Rangers do Exército como um especialista em IA. O mesmo problema existiu com a cibersegurança por anos, até que o DOD fez um investimento significativo. Certos recursos complexos precisam ser direcionados para operações de IA porque a IA pode mudar tudo.\n\nRon, tendo passado os últimos anos no serviço no campo nuclear, destaca que os EUA nunca irão retirar o elemento humano dos processos de decisão críticos. A inteligência artificial será extremamente valiosa, pois pode garantir que a tecnologia possa se adaptar dinamicamente. Ela reduzirá a carga cognitiva e processará inúmeros pontos de dados, permitindo que os tomadores de decisão humanos tenham uma consciência situacional mais clara e estejam mais preparados para tomar decisões informadas rapidamente. É nesse espaço da IA que o Departamento de Defesa deve investir.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jason Dunn-Potter","Ron Fritzemeier"],"link":"/episode-EDT86-pt","image":"./episodes/edt-86/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto-Chefe de Soluções, Setor Público, Intel, dá as boas-vindas aos convidados especiais Jason Dunn-Potter, ex-Chefe Warrant Officer, Exército dos EUA, e Ron Fritzemeier, ex-Contra-Almirante, Marinha dos EUA. Ambos estão agora há cinco meses em seus cargos como Arquitetos de Soluções e Especialistas em Missão na Equipe de Defesa da Intel."},{"id":161,"type":"Episode","title":"Computação confidencial em DevSecOps","tags":["confidentialcomputing","devops","compute","technology","process","devsecops","cybersecurity","sgx"],"body":"\r\n\r\nO software da Anjuna possibilita que aplicações rodem com a proteção SGX da Intel e resolve o problema de proteger dados em uso. A missão da Anjuna é tornar enclaves seguros o mais simples possível. Com o software da Anjuna, não há necessidade de alterar nada na aplicação; apenas pegue-a, execute-a em um enclave, e a tecnologia SGX funcionará automaticamente. O software funciona com qualquer aplicativo, em qualquer nuvem, em qualquer escala.\n\nA cadeia global de fornecimento de software está sendo atacada. SolarWinds, em particular, foi um ataque ao DevOps, e embora tenham surgido ideias sobre como resolver o problema, ainda não foi resolvido definitivamente. A tecnologia Anjuna pode ser uma solução simples. Não há necessidade de redesenhar seu software ou mudar metodologias. Você os executa em compartimentos de segurança.\n\nAo experimentar o software da Anjuna, Darren criou uma pilha usando Intel SGX na base, Red Hat OpenShift, Anjuna para a parte de computação confidencial e o Vault da HashiCorp para armazenar um livro-razão seguro. Ele ficou chocado com o quão rápido a solução estava funcionando em menos de uma semana.\n\nDarren chama esse processo de \"pipeline do hardened DevSecOps\", apesar de ter várias partes móveis. Ofir concorda com essa terminologia, pois esse processo é um novo DevOps hardened com a tecnologia de hardware SGX com o software da Anjuna.\n\nA computação confidencial, ou enclave seguro, resolve o problema de proteger dados. Quando você armazena dados em armazenamento persistente, a solução para dados em repouso já está presente. Também há uma solução para dados em trânsito com TLS. A segurança de dados em uso ainda não foi resolvida, pois quando os dados estão em uso, a aplicação precisa acessá-los em memória sem criptografia. Não é possível que estejam ambos criptografados e em uso ao mesmo tempo. Isso tem sido um problema sem fim. Se um ator mal-intencionado tem acesso a uma máquina onde a aplicação está sendo executada, um ataque é tão simples quanto entrar pelo dispositivo, identificar o processo e criar um despejo de memória. Eles obterão todos os segredos e dados confidenciais do arquivo, que não estão criptografados. Isso também incluiria as chaves de criptografia para dados em repouso e em trânsito, pois o software precisa usá-las para criptografar. O jogador ruim terá as chaves do reino.\n\nO problema é resolvido se você executar as diferentes aplicações em enclaves seguros. Mesmo que alguém tenha acesso à máquina, eles não teriam acesso à memória de cada aplicação. Isso não significa que você não precisa resolver vulnerabilidades, mas você estará menos estressado para corrigi-las o mais rápido possível. Mesmo que haja vulnerabilidades no kernel, quando algo é executado em um enclave seguro, o kernel não pode acessar sua memória.\n\nA software Anjuna é executada em outras tecnologias baseadas em hardware, assim como SGX. Ao contrário da execução de criptografia em software, onde o impacto no desempenho seria alto, a Anjuna pode ajustar a configuração para executar o seu aplicativo com um impacto no desempenho negligenciável: menos de cinco por cento.\n\nPortanto, talvez você não queira colocar tudo em um enclave seguro já, mas esse é o futuro da segurança.\n\nUm dos usos de uma enclave segura é armazenar dados que atravessam diferentes etapas no pipeline de DevOps em um livro-razão seguro. O livro-razão contém tudo o que foi incluído na construção, chaves de segurança e valores de hash utilizados para verificação. Esses valores de hash de verificação devem permanecer inalterados durante o ciclo para que ninguém possa injetar código, bibliotecas ou binários no pacote que você entrega. Tudo deve ser executado em um contêiner no mundo moderno.\n\nOutro candidato para proteção é uma chave de assinatura. Sem ambientes seguros, uma vez que você tenha um binário pronto, é preciso levá-lo para outra máquina em uma sala escura à qual ninguém tenha acesso. Mas três pessoas com três chaves diferentes assinam lá. Ambientes seguros permitem acesso àquela chave de assinatura em seu ambiente familiar, mas apenas o enclave a acessará. Isso será baseado na identidade complexa do software em execução dentro do enclave SGX, que é implementada através da cota de atestação. Em outras palavras, você pode atestar enclave para enclave. Você também pode atestar coisas que são executadas fora dos enclaves. Isso lhe dá a capacidade de confiar em software que é executado em outro lugar.\n\nA compilação de binários é outro uso. Um dos grandes problemas no Departamento de Defesa, por exemplo, é que eles querem ter certeza de que tudo o que foi incluído na compilação possa ser rastreado até o desenvolvedor que o escreveu. Especialmente em sistemas embarcados, onde o software controla máquinas que valem milhões de dólares e podem matar pessoas ou salvar vidas. Deve haver rastreabilidade completa para ajudar a garantir responsabilidade e que o desenvolvimento seguro tenha sido realizado.\n\nAlém dos ataques de despejo de memória, outro problema de ataque que a Anjuna resolve é garantir que, em casos em que você precisa acessar o kernel, ele proteja o que precisa ser coberto nessa interação entre a enclave e o mundo exterior. Também pode proteger contra o acesso ao código e tornar segredos disponíveis apenas para a enclave. Além disso, se alguém entrar em uma máquina, não poderá encontrar um certificado TLS em texto claro ou a chave usada para criptografá-lo.\n\nCada provedor de serviço em nuvem oferece enclaves seguros, e a Anjuna os suporta todos. Eles também suportam tecnologias no local. Além da oferta principal, a Anjuna também pode permitir a capacidade de criptografar seus dados em repouso e em trânsito sem alterar seu software, mesmo em aplicativos legados ou novos aplicativos que não suportam criptografar todos os arquivos de dados.\n\nPara mais informações, visite anjuna.io, ou confira um white paper escrito por Darren e Ofir em embracingdigital.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ofir Azoulay-Rozanes"],"link":"/episode-EDT87-pt","image":"./episodes/edt-87/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren Pulsipher, Arquiteto Chefe de Soluções, Intel, e Ofir Azoulay-Rozanes, Diretor de Gerenciamento de Produtos, Anjuna, discutem as soluções da Anjuna para computação confidencial no ciclo de vida do DevOps."},{"id":162,"type":"Episode","title":"DevSecOps colaborativo","tags":["cybersecurity","devsecops","rpa","technology","compute","zerotrust","zta"],"body":"\r\n\r\nA experiência de Mike como engenheiro de segurança cibernética na Força Aérea e depois trabalhando em desenvolvimento, segurança, operações e serviços gerenciados, levou-o a um objetivo de criar um produto que pudesse ser colaborativo para construir automação moderna em torno do que ele chama de TI como código. Ele queria analisar o DevSecOps de forma holística, reunindo todos.\n\nSeu produto resultante, Sophos Factory, cria soluções modernas em torno de blocos de construção com recursos, funcionalidade e experiência do usuário que podem ser utilizados em todo o espectro de talento técnico. Resolver esse problema foi complexo, envolvendo pessoas que trabalham visualmente, desenvolvedores que programam, entre outros... Também foi necessário preencher a lacuna entre hardware e software, utilizando um processo ágil entre equipes.\n\nA Sophos Factory é mais do que apenas um pipeline CI/CD. Isso é uma pequena parte de todo o sistema, que funciona de ponta a ponta desde o desenvolvimento, segurança, operações e implantação com recursos como um construtor visual, DSL e suporte para todo o conteúdo em seu formato nativo. Também se integra a sistemas existentes. Ela reúne todas as equipes diferentes e as diferentes ferramentas que elas usam, então vai muito além de simplesmente criar um pipeline ou automação.\n\nUsuários individuais são apresentados com as peças com as quais estão familiarizados, mas todas com a mesma interface. Por exemplo, um conjunto de scripts pode ser construído a partir de um formato visual. Uma pessoa de segurança pode usar a mesma interface com as ferramentas e artefatos que esperam. Um desenvolvedor full-stack ou um engenheiro DevOps pode incorporar e construir todos os artefatos de uma maneira que as outras equipes possam usar. Não se trata da criação de um pipeline para uma peça de automação, mas de um tecido interconectivo entre sistemas díspares.\n\nIntegração significa o movimento de dados, mas também significa ações. Por exemplo, suponha que alguém utilize o Jira no lado de programação, o ServiceNow no lado de operações de TI e um componente de resposta a incidentes no lado de segurança. Nesse caso, é possível integrar todas essas partes e enviar algo para o Slack, para que todos tenham visibilidade e possam responder quase em tempo real.\n\nA Sophos Factory embala módulos em pipelines para reutilização, que se tornam blocos de construção. Estes podem ser construídos em torno de vários casos de uso, mas o objetivo é que você esteja criando algo que possa ser usado várias vezes. Por exemplo, suponha que você esteja usando o ServiceNow e queira criar um ticket. Nesse caso, você o utiliza em vários outros casos de uso relacionados à automação de rede, automação de infraestrutura, nuvem, segurança nativa, etc. Trata-se de construir soluções, não apenas automatizar essas coisas juntas. A última peça é tornar prova de futuro, não apenas repetibilidade. Você pode adicionar ou subtrair do pipeline geral, o que não é possível com hardware, mas também é muito difícil com sistemas existentes, como sistemas CI/CD que são feitos para lançar software em produção, não para construir holisticamente uma solução e manter o ciclo de vida ao longo do tempo.\n\nCom a tecnologia Sophos Factory, você pode empacotar diferentes ferramentas para ajudar a aderir a padrões como CIF ou NIST 853 e tê-las disponíveis como pipelines de código baixo ou sem código. O Sophos Factory diverge de outras tecnologias de automação com seu compartilhamento por meio de catálogos de soluções. Você pode publicar blocos de construção de automação, soluções completas ou consumir automação criada por outras equipes. Isso cria uma tremenda flexibilidade.\n\nO controle de versão está integrado nos pipelines e nos catálogos de soluções. Se você estiver usando um pipeline de solução de um registro publicado por outra pessoa, você pode configurá-lo para qualquer versão que desejar ou atualizá-lo para a versão mais recente para obter atualizações. O RBAC também faz parte do sistema, caso você queira conceder acesso somente a usuários específicos, por exemplo, apenas leitura. Com a interoperabilidade do Sophos Factory, você também pode integrar ferramentas de escaneamento para manter a visibilidade no pipeline. Você também pode executar diferentes canais em torno das ferramentas de política.\n\nSophos Factory entrelaça segurança e fluxos de trabalho de TI, criando um excelente ponto de integração entre o trio de monstros formado por Dev, Sec e Ops.\n\nPara melhorar a segurança, a Sophos Factory possui um produto de confiança zero e atestação, mas eles também trabalham com outros produtos de segurança, como o HashiCorp Console. A capacidade de confiança zero e atestação é a evolução natural para autenticar entre diferentes sistemas. Em vez de credenciais estáticas, agora existem maneiras melhores de comunicar e compartilhar atestação de forma segura entre os outros.\n\nA Sophos Factory possui um sistema de credenciamento integrado para gerenciamento de chaves e suporta o HashiCorp Vault e modelos nativos em nuvem. Eles também podem ajudar a construir serviços de gerenciamento críticos na nuvem e embalá-los em torno de um pipeline. Não é apenas uma variável de credencial em tempo de execução, mas também um passo de credencial que é avaliado apenas em tempo de execução. Eles podem ser adicionados em cima dessas ferramentas de segurança, tornando-se naturalmente parte da sua solução de construção.\n\nA fábrica da Sophos está no espaço de RPA, mas vai muito além de um RPA típico. Eles são tecnicamente RPA porque, embora os humanos ainda estejam envolvidos na fabricação das coisas, as máquinas são utilizadas para automatizar o processo. Os clientes estão procurando maneiras de escalar e obter valor de forma segura dos produtos de TI que adquirem. A Sophos Factory abraça ajudar o talento técnico a evoluir e lhes dando acesso a conjuntos de ferramentas, obtendo mais deles e fazendo isso de maneira segura.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Mike Fraser","Callen Sapien"],"link":"/episode-EDT88-pt","image":"./episodes/edt-88/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com Callen Sapien, Diretor de Gerenciamento de Produtos da Sophos Factory, e Mike Fraser, VP de DevSecOps, sobre seu produto que permite uma colaboração verdadeiramente integrada entre Segurança, Desenvolvimento e Operações (SecDevOps)."},{"id":163,"type":"Episode","title":"Futuro de Memória Grande e CXL","tags":["bigmemory","memverge","optane","technology","data","compute","pmem","cxl","ceo"],"body":"\r\n\r\nUm desenvolvimento empolgante na memória é o CXL (Compute Express Link). Um ecossistema robusto está sendo desenvolvido do lado do host, com a Intel e outros apoiando o CXL 1.1 em suas plataformas de próxima geração, como Sapphire Rapids. Aqueles do lado da memória, incluindo a Intel Optane de quarta geração, estarão no CXL. A Intel é um membro impulsionador do forte consórcio CXL que tem impulsionado o padrão. O CXL 2.0 já foi definido, com capacidades adicionais, incluindo a externalização e comutação do CXL, e o 3.0 está em processo, o que padronizará como o CXL pode ser provisionado e compartilhado.\n\nHaverá novos produtos sendo lançados pela Samsung, Micron e SK-Hynix com capacidades CXL. Além disso, estão sendo desenvolvidas novas interconexões que podem potencialmente conectar a memória com o tecido, proporcionando uma memória habilitada para tecido que pode ser compartilhada entre vários servidores.\n\nA tecnologia CXL é revolucionária. Um novo protocolo de memória funciona em cima do padrão PCIe de quinta geração em diante. Como permite colocar memória no PCIe, ela não precisa ficar apenas dentro da caixa, mas, no futuro, com a comutação PCIe, será possível tornar a memória na trama tornar-se componível e compartilhável. O primeiro produto CXL será lançado até o final do ano.\n\nA MemVerge já possui um controlador de memória definido por software, e o CXL abriu um mundo completamente novo para o software. O CXL é para memória o que a fibra óptica é para armazenamento. É como uma rede de área de memória em vez de uma rede de armazenamento. É possível ir diretamente para a memória com o CXL e contornar completamente a CPU.\n\nCXL será muito mais rápido do que as tecnologias de interconexão anteriores. Terá uma latência de 100 ou 200 nanossegundos. É aqui que a utilização, gerenciabilidade e agilidade aumentam. Haverá maior disponibilidade e produtividade no uso da memória. Além disso, será possível provisionar a memória de forma dinâmica; você pode provisionar conforme necessário e não precisa caber na caixa do servidor. Teoricamente, você sempre terá memória suficiente para o que precisar estar ativo.\n\nCom a tecnologia de snapshot da MemVerge, seus dados estão protegidos e persistentes também. Isso se torna mais importante à medida que sua memória se torna maior. Se você a perder, será mais difícil reconstruí-la.\n\nPara o CXL decolar, três coisas precisam estar em vigor. No lado do hardware, os líderes de hardware mais antigos precisam aderir e adotar os mesmos padrões. Isso aconteceu no ano passado, então há um único padrão que todos estão apoiando. Segundo, você não precisa alterar seu aplicativo para usar CXL, assim como redes de área de armazenamento. Terceiro, do ponto de vista de um banco de dados, você não deve precisar reescrevê-lo. Isso pode acontecer entre o que os padrões fornecem, o que o sistema operacional suporta e o software MemVerge, que faz a automação da movimentação de dados entre a memória DDR e a memória CXL.\n\nA MemVerge pode fornecer essa camada de abstração. É essencialmente virtualização de memória. A memória definida por software lida com a localização real da memória física.\n\nA MemVerge torna a memória ampliada transparente para a aplicação, permitindo que os programadores utilizem uma capacidade maior e nunca fiquem sem memória. Em seguida, temos a proteção de dados. A MemVerge desenvolveu um serviço de instantâneo em memória que pode capturar todo o estado de uma aplicação na memória e esse estado é imutável. Ele pode ser recuperado a qualquer momento e em qualquer lugar. Existem muitos casos de uso para isso, como mediação de ransomware e diminuição dos tempos de ciclo na pesquisa genômica.\n\nA função de captura instantânea não é apenas útil porque pode capturar rapidamente e facilmente um pipeline em execução, permitindo que você volte atrás e se recupere a qualquer momento, mas também pode economizar dinheiro ao usar serviços em nuvem. Os principais provedores de serviços têm instâncias spot que têm desconto de 70-90% em relação ao preço regular, mas há uma pegadinha: eles podem recuperá-las a qualquer momento com apenas 30 segundos a dois minutos de aviso prévio. Isso não é tempo suficiente para lidar com isso, especialmente se você tiver muitos dados na memória, então isso não tem sido útil para muitas cargas de trabalho. Com a capacidade de captura instantânea do MemVerge, você pode fazer capturas periódicas da sua carga de trabalho em execução em qualquer instância. Se a instância spot for retirada, você tem uma imagem que pode recuperar e continuar executando. É um seguro que permite usar o serviço de baixo custo com proteção.\n\nComo você está capturando uma imagem não apenas de um aplicativo, mas de um contêiner ou instância inteira, você pode reinstituí-lo em qualquer lugar, no local, na mesma nuvem ou em outra nuvem. Isso lhe oferece mobilidade e resiliência máximas em suas operações, mesmo no caso de uma grande interrupção do serviço em nuvem. Essa tecnologia oferece muitas possibilidades emocionantes.\n\nA revolução CXL e o software MemVerge Memory Machine são combinações poderosas para possibilidades transformadoras.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Charles Fan"],"link":"/episode-EDT89-pt","image":"./episodes/edt-89/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, conversa com Charles Fan, CEO da MemVerge, sobre como a revolução do CXL e o software da MemVerge são o futuro da memória grande."},{"id":164,"type":"Episode","title":"Teletrabalho: Proteja seu escritório doméstico","tags":["cybersecurity"],"body":"\r\n\r\n## Dicas de segurança do sistema\n\nA primeira coisa que você deseja fazer para proteger seu escritório em casa é atualizar todos os seus sistemas. Isso inclui tanto aplicativos quanto sistemas operacionais em todos os seus dispositivos conectados à internet. Você também vai querer atualizar o software de segurança de ponto final e realizar verificações regulares quando o dispositivo estiver ligado. Muitas pessoas sabem fazer isso em seus desktops ou laptops, mas a segurança do ponto final também deve ser implantada em telefones e tablets. Além disso, certifique-se de ativar o firewall local e habilitar o firewall do seu roteador.\n\nUma das principais medidas que você pode adotar para reduzir seu risco geral enquanto estiver na internet é reduzir a área de ataque em tempo de execução. Isso significa que você deve fechar aplicativos que não estão em uso, fechar o navegador antes de visitar novos sites, e fazer logout ou encerrar sessões seguras antes de realizar atividades como verificar e-mails ou navegar. Você não deve realizar diferentes atividades simultaneamente para evitar ataques cruzados.\n\nUm bom site de educação para aprender como navegar com segurança na internet é Stop. Think. Connect. https://www.stopthinkconnect.org/\n\n## Dicas de segurança para Modem/Router/Wifi\n\nAltere todas as senhas padrão para senhas seguras (mínimo de 8 a 10 caracteres, utilizando letras maiúsculas e minúsculas, números e caracteres especiais). As senhas padrão estão presentes em roteadores, modems, portais web do provedor de internet e redes WiFi. Tome cuidado para permitir acesso apenas a pessoas de confiança às suas senhas. Também é importante alterar o nome padrão da rede (SSID) para algo que não contenha informações identificáveis.\n\nAtivar autenticação em dois fatores sempre que possível irá fornecer a você mais uma camada de segurança. Roteadores e modems precisam ser atualizados assim como seu laptop, portanto, certifique-se de ativar as atualizações automáticas.\n\nOutras medidas para aumentar a segurança incluem ligar o WPA e desativar o WPS, se possível. Ative a tradução de endereço de rede (NAT) e a filtragem DNS no roteador e modem. Você também irá querer desativar o UPnP.\n\nEssas técnicas irão impedir que pessoas não autorizadas e seus vizinhos \"pegem emprestado\" o seu WiFi, o que cria um risco de segurança.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT9-pt","image":"./episodes/edt-9/pt/thumbnail.png","lang":"pt","summary":"Garantir a segurança do seu dispositivo e do seu centro de dados apenas te leva até certo ponto. Com mais pessoas trabalhando em casa, você precisa ajudar seus funcionários a garantirem a segurança de suas redes domésticas e áreas de trabalho. Neste episódio, Steve Orrin, CTO Federal da Intel, ajuda Darren a garantir a segurança de sua rede doméstica."},{"id":165,"type":"Episode","title":"Barreiras à adoção de tecnologia futura","tags":["cto","organizationalchange","change","people","process"],"body":"\r\n\r\nGlenn é o Diretor de Tecnologia (Chief Technology Officer) na CACI, uma empresa de seis bilhões de dólares do porte da Fortune 500, focada em segurança nacional. Ele está na indústria há 35 anos, dedicado a assuntos militares, de inteligência e cibersegurança para o governo dos Estados Unidos. Sendo um engenheiro, ele pensa, age e processa questões como um engenheiro.\n\nTecnologia excitante em IA, neuromórfica e segurança às vezes não é adotada rapidamente no setor público.\n\nA primeira barreira é a complexidade. Aqueles na comunidade técnica são excelentes inovadores, mas nem sempre são bons em tornar a tecnologia fácil de usar, consumir ou administrar. Glenn vê alguma melhora, no entanto. Por exemplo, nos últimos cinco anos, a complexidade de usar a inteligência artificial diminuiu significativamente à medida que mais pessoas estão utilizando ferramentas e kits de desenvolvimento de software.\n\nOutra barreira pode ser a falta de talento para arquitetar, projetar, implantar e manter a tecnologia no setor público. Novos talentos não só precisam ser atraídos para a indústria, mas também devem ser capazes de obter autorizações. O outro lado da equação de talento é que muitos são resistentes à adoção de novas tecnologias. É um desafio de gerenciamento de mudanças. Se não for abordado corretamente, o talento existente se torna um obstáculo à adoção de nova tecnologia. Em vez de perguntar como chegar ao \"sim\", eles encontram mil razões para dizer \"não\".\n\nA terceira é cibersegurança. Glenn não descreve isso como uma barreira porque não é algo que poderia ser removido. Ainda assim, a indústria poderia ser mais proativa em levar as decisões mais à esquerda e envolver a segurança mais cedo para acelerar a adoção.\n\nO setor público poderia aprender com a rapidez com que a tecnologia dos smartphones foi adotada com o surgimento do iPhone. Os primeiros iPhones eram incrivelmente simples de usar, e a empresa estava empenhada em entregar aos clientes algo que eles pudessem usar imediatamente. Além disso, a comunidade de desenvolvimento podia criar e inovar instantaneamente com os kits de desenvolvimento de software e os processos. Crianças no sexto ano podem desenvolver com os kits para iPhone e Android. A usabilidade era essencial e isso impulsionou o desenvolvimento de software de forma eficiente.\n\nO setor público deve tentar imitar essas qualidades e abordar seu mercado e clientes da mesma forma, especialmente em relação à análise de dados. Há uma imensa quantidade de dados e não estamos aproveitando muito deles. Assim como Steve Jobs levou sua tecnologia para além do público-alvo médio, a mesma coisa precisa acontecer na análise de dados. Em vez de focar nos cientistas de dados, talvez o público-alvo deva ser uma pessoa de negócios ou uma pessoa comum que precisa gerenciar uma casa.\n\nGlenn acredita que o primeiro passo para pensar dessa maneira sobre IA e análises é estar firmemente comprometido em libertar os dados. Muitos dados estão presos em designs proprietários, o que é um modelo de negócio ruim. Os clientes devem renovar contratos não porque suas informações são controladas e fechadas por um provedor, mas sim porque o provedor está oferecendo soluções, valor e inovação.\n\nA IA deve ser apresentada como uma assistente digital aos clientes, ao invés de um robô obscuro e mágico nos bastidores pelo qual o cliente fica nervoso em confiar. Uma assistente digital está apenas um passo à frente do que você está tentando realizar, fornecendo dados e informações por meio de aprendizado de máquina e aprendizado profundo que tornam sua vida mais fácil e permitem que você faça o processamento. Dessa forma, a IA adiciona valor instantâneo e é muito menos assustadora.\n\nGlenn acredita que a tecnologia que o setor público deve ter hoje é, em primeiro lugar, a nuvem e mais dela. A nuvem retira muitos erros humanos da administração. Ela reduz a área de ataque e possui um modelo de consumo pay-as-you-go, o que pode ser econômico se você desenvolver software para esse modelo.\n\nSegundo, existem boas plataformas de DevSecOps. Programadores de software podem passar mais tempo no desenvolvimento real com as ferramentas disponíveis. DevSecOps ainda está em estágios iniciais, e o crescimento será explosivo.\n\nUma tecnologia fundamental durante o trabalho remoto da COVID-19 é a Solução Comercial para Classificação (CSFC). Essa tecnologia existe há uma década. No entanto, ela evoluiu a ponto de ter sido simplificada em termos de implantação, administração e segurança, tornando-se facilmente acessível. Alguém pode trabalhar em um domínio não classificado e ainda ter acesso a segredos, por exemplo, com confiança de que não haverá qualquer vazamento. Essa é uma nova e importante capacidade.\n\nTudo isso se relaciona à atração e retenção de talentos. A dificuldade nisso não é porque o setor público não tem problemas emocionantes e desafiadores, mas sim a percepção de que o governo se move muito lentamente. Há alguma verdade nisso devido à importância de manter uma certa santidade ou confiança. Ainda assim, na realidade, o governo está à beira de muitas novas tecnologias, como a fotônica ou comunicação baseada em luz. Algumas áreas avançam rapidamente, como no desenvolvimento de software com ágil e DevSecOps.\n\nGlenn acredita que o domínio espacial explodirá e será fundamentalmente diferente em cinco anos para o futuro da tecnologia. A capacidade de colocar mais coisas em órbita de forma econômica, com melhorias em tamanho, peso e potência, juntamente com a capacidade de comunicar com fotônica por milhares de quilômetros rapidamente, permite conectividade e a capacidade de distribuir e usar dados nesses cargas úteis.\n\nOutra área que será muito diferente é a agilidade espectral. O domínio do espectro eletromagnético será crucial para a conectividade resiliente em conflitos. As disputas subsequentes enfatizarão fortemente quem pode se comunicar e interferir nas comunicações. A agilidade espectral é a capacidade de saber dinamicamente o que está acontecendo ao seu redor no espectro, para que você possa se mover rapidamente. Essa conectividade é fundamental para o comando e controle conjunto e a visão JADC2 de trabalho.\n\nUma terceira área é o que pode ser feito com o Kubernetes e com o código de infraestrutura. A automação irá remover trabalho manual e facilitar as coisas de maneira geral.\n\nNenhuma conversa sobre o futuro da tecnologia estaria completa sem mencionar o Quantum. Os modelos de programação quântica em construção são completamente diferentes dos modelos tradicionais. Precisamos chegar a um ponto onde tenhamos conjuntos de ferramentas para programadores que tornem o processo muito mais automatizado. Treinar alguém por dois anos para ser um programador de computação quântica não é escalável, por isso precisamos que os conjuntos de ferramentas de desenvolvimento de software evoluam, assim como a comunidade abstraiu a complexidade e desenvolveu conjuntos de ferramentas para inteligência artificial.\n\nA última área é a evolução contínua da computação em borda. O número de processos de computação é fenomenal, gerando criatividade com tamanho, peso e energia. A computação em borda continuará a se transformar para ser segura e confiável. A comunicação resiliente pode não ser uma conexão dedicada, mas uma rede em malha onde partes da mensagem são recombinadas no outro extremo. Isso pode fornecer soluções em ambientes táticos e em ambientes de negação e interrupção.\n\nDarren vê a arquitetura tradicional de Von Neumann diminuindo no futuro, já que podemos ter persistência de dados sem unidades de disco, e podemos ter dados que vivem, se movem e migram com funções que trabalham com eles. As camadas e limitações do modelo Von Neumann serão removidas.\n\nGlenn acredita que isso acontecerá mais rápido do que as pessoas geralmente preveem devido ao viés da experiência. Mas é um mundo diferente quando se consegue fazer com que todas as outras peças coexistam e remover os problemas de latência. Imagine o que pode ser feito na velocidade de inferência na borda, por exemplo, com veículos autônomos. Essa tecnologia está acontecendo, e os programadores consideram camadas de abstração desde o início. Assim, você poderia, por exemplo, pegar um modelo de rede neural que já está desenvolvido e executá-lo por meio de um conjunto de ferramentas de desenvolvimento de software para colocá-lo em uma base de hardware, uma arquitetura não-Von Neumann, e você não precisa reprogramar. Isso acelerará a adoção e será transformacional.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Glenn Kurowski"],"link":"/episode-EDT90-pt","image":"./episodes/edt-90/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, discute as barreiras para a adoção de novas tecnologias no setor público e o que está por vir no futuro com Glenn Kurowski, CTO da CACI."},{"id":166,"type":"Episode","title":"Enfrentando o Inimigo Cibernético ao Proteger sua Cadeia de Suprimentos de Software.","tags":["cybersecurity","devsecops","sbom","securesupplychain","policy","process","compute"],"body":"\r\n\r\nDarren e Eric Greenwald, Conselheiro Geral da Finite State, discutem a segurança da cadeia de suprimentos de software neste episódio.\n\nFinite State concentra-se em encontrar vulnerabilidades no firmware, mais frequentemente em software de terceiros que possam já ter vulnerabilidades existentes, antes de incorporá-lo em seus dispositivos. Finite State concentra-se principalmente em dispositivos de IoT industrial, dispositivos médicos, automóveis e eletrônicos de consumo.\n\nPor sete anos antes de se juntar à Finite State, Eric trabalhou como advogado no setor privado, concentrando-se em testes de segurança e identificação de vulnerabilidades para empresas de cibersegurança. Antes disso, ele trabalhou no governo com segurança cibernética e segurança nacional, para o FBI e CIA, e como conselheiro-chefe do Comitê de Inteligência da Câmara dos Representantes. Seu trabalho governamental culminou quando ele se tornou o Diretor Sênior de Cibersegurança no Conselho de Segurança Nacional, na Casa Branca.\n\nEric acredita que parte da razão pela qual há agora um foco na segurança da cadeia de suprimentos é que a ameaça evoluiu. A natureza cada vez mais complexa do software, incluindo o fato de que muitos componentes possuem vulnerabilidades quando são criados pela primeira vez e apenas descobertas ao longo do tempo, torna mais difícil encontrar dispositivos construídos através da cadeia de suprimentos de software. Além disso, ataques recentes de alto perfil através de uma violação na cadeia de suprimentos de software, como o SolarWinds, têm feito as pessoas ficarem mais conscientes do perigo.\n\nNo ataque SolarWinds, o perpetrador teve paciência, não causando imediatamente o caos, mas aguardando um ano enquanto percorria as redes de computadores americanas, cultivando acesso e informações. Essa paciência é provavelmente a diferença mais significativa entre um ataque de estado e um ataque criminoso. Enquanto os ataques criminosos pacientes às vezes estão mais focados em um retorno financeiro do investimento, aqueles por trás de um ataque de estado estão dispostos a levar anos para desenvolver seu acesso à inteligência. No entanto, com ambos, os ataques estão se tornando mais sofisticados e estão em uma posição muito melhor para tirar vantagem devastadora da complexidade da cadeia de suprimentos.\n\nPara combater esses ataques, estão surgindo novas regulamentações. A administração Biden emitiu a ordem executiva 14028 em maio de 2021, que possui dois pontos principais: desenvolvimento seguro de software e lista de materiais de software (SBOM). A ordem executiva é direcionada apenas às compras governamentais, mas a indústria privada provavelmente irá segui-la.\n\nOs detalhes e recomendações técnicas para o desenvolvimento seguro de software ainda estão sendo elaborados. No entanto, parte disso seria que os fornecedores de software para o governo teriam que fornecer um SBOM (Lista de Materiais de Software). O primeiro projeto de lei para SBOMs foi lançado em 2014, portanto, as normas para sua produção se tornaram mais maduras e desenvolvidas. Um SBOM é essencialmente uma lista de componentes de software que foram utilizados em um produto de software, não muito diferente de uma lista de ingredientes em um produto alimentício. Isso oferece transparência na cadeia de suprimentos, o que é essencial para avaliar vulnerabilidades ou poder identificar uma vulnerabilidade que seja descoberta posteriormente.\n\nUm excelente exemplo disso é o que aconteceu com o Log4j. Quando essa vulnerabilidade foi descoberta, muitas empresas não tinham ideia se a tinham em sua pilha. Não seria uma varinha mágica, mas um SBOM permitiria às empresas descobrir mais facilmente se têm o componente de software problemático em seu sistema e agir mais rapidamente para implementar um patch.\n\nOs argumentos contra a publicação de SBOMs são de que fornecerão um roteiro para os atacantes e revelarão informações proprietárias. Embora essas sejam preocupações legítimas e que devem ser discutidas, o Departamento de Comércio e o Departamento de Segurança Interna afirmam que a transparência proporciona benefícios significativos aos defensores em relação a qualquer vantagem concedida aos atacantes. Existem projetos de lei bipartidários em apoio aos SBOMs. Existem maneiras de reduzir o risco de os SBOMs caírem nas mãos erradas, como contratos seguros ou não fungíveis. Os debates sobre essas preocupações continuarão no setor público, e mais empresas irão adotá-los.\n\nEsta legislação está ocorrendo porque a FDA sugeriu que os fabricantes de dispositivos médicos incorporem SBOMs como parte do processo de análise, então os SBOMs estão ganhando impulso desses fabricantes. O mundo físico está se tornando cada vez mais afetado pelo software em dispositivos médicos e sistemas incorporados, como sistemas de controle para usinas de energia, sistemas de HVAC, controles de aeroporto, etc., então os sistemas operacionais estão em risco, com consequências mais significativas do que ataques a sistemas empresariais.\n\nUma dificuldade para os profissionais de OT é que muitos dos componentes industriais são mais antigos e nem sempre foram atualizados. Ainda assim, os hackers relutam em se conectar à internet e atualizar porque é assim que os hackers entram. A melhor resposta para esse problema é tentar obter transparência dos componentes no sistema, escanear o sistema e os dispositivos que fazem parte da rede OT e fazer engenharia reversa e descompilação para entender os detalhes. Essencialmente, é preciso criar seu SBOM (Software Bill of Materials) e avaliar onde estão as vulnerabilidades.\n\nEsta é a área principal de trabalho da Finite State. Eles analisam os sistemas e dispositivos e fazem uma análise. Eles possuem uma plataforma que automatiza a análise do código incorporado, fornece uma leitura das vulnerabilidades e identifica e agrupa as vulnerabilidades de maior prioridade. Às vezes, é possível resolver toda uma categoria de vulnerabilidade com uma única correção. Criar o SBOM por si só, então, não é o bastante. Ele deve ser integrado a um sistema de gerenciamento de risco para filtrar e classificar as várias vulnerabilidades. Encontrar os riscos de maior prioridade é um processo complexo, e a Finite State pode ajudar as equipes de segurança a priorizar suas ações para proteger seus sistemas.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Eric Greenwald"],"link":"/episode-EDT91-pt","image":"./episodes/edt-91/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto-Chefe de Soluções da Intel, e Eric Greenwald, Consultor Jurídico Geral da Finite State, falam sobre a segurança da cadeia de suprimentos de software."},{"id":167,"type":"Episode","title":"Protegendo as Paredes Externas do seu Castelo com Escaneamentos de Vulnerabilidade.","tags":["cybersecurity","endpointmanagement","vulnerability","cyberattack","iot","edge","censys"],"body":"\r\n\r\nMatt passou oito anos como oficial de inteligência no exército. Na última parte de seu serviço, ele ajudou a desenvolver as forças de missão cibernética como parte do Comando Cibernético dos EUA. Após terminar seu serviço, ele trabalhou com Army Cyber e algumas startups antes de vir para a Censys.\n\nUma avaliação de vulnerabilidade típica exige que uma organização forneça o que ela está interessada, por exemplo, uma lista de bloqueio de IPs para uma varredura de vulnerabilidade de credencial. Então, essas vulnerabilidades são descobertas e podem ser corrigidas. Uma varredura do Censys pode fornecer uma varredura ampla e profunda na internet a partir de algumas informações básicas, como um domínio e alguns IPs, descobrindo tudo mais que a organização possui e monitorando continuamente essas mesmas agregações e correlações entre o conjunto de dados. Se, por exemplo, o departamento de marketing criar um site exposto que não tenha TLS, o Censys o detectará. O Censys adota uma visão externa para saber o que está disponível para um atacante em qualquer momento do dia.\n\nMesmo que, por exemplo, alguém implante um aplicativo em nuvem, não o coloque no domínio e use segurança de ofuscação, o Censys ainda o detectará se estiver em um ambiente de nuvem de propriedade da organização. Conectores em nuvem descobrirão novas instâncias em nuvem que surgirem. Algum tipo de correlação deve existir entre alguma dessas instâncias e informações WHOIS ou DNS. O Censys está continuamente melhorando na detecção desses tipos de instâncias.\n\nA analogia de um castelo funciona bem aqui. Uma organização não quer apenas depender do que podem ver internamente com as câmeras e sentinelas. Eles querem uma patrulha de segurança móvel para capturar ameaças antes mesmo que elas cheguem às paredes do castelo. A patrulha pode observar o castelo da mesma forma que um invasor faria. A Censys patrulha a internet de uma perspectiva externa, vendo as coisas da maneira como um potencial hacker as veria.\n\nUma ferramenta que a Censys está analisando é o JARM da Salesforce, uma ferramenta ativa de impressões digitais TLS. Quando são implantadas coisas que não correspondem às impressões digitais em um servidor específico, elas se destacam como anomalias. É essencial procurar arquiteturas que deveriam estar em uma configuração específica, mas não estão.\n\nUma pergunta importante é como o Censys pode evitar ajudar jogadores ruins. Primeiro, os jogadores ruins já estão vendo o que o Censys consegue ver, talvez não em escala tão grande, então o Censys está ajudando as organizações a nivelar o campo de jogo. A visibilidade externa em grande escala pode ajudar a eliminar as vulnerabilidades que jogadores ruins podem explorar. Por exemplo, o Censys ajudou a Ucrânia a identificar vulnerabilidades que o adversário poderia ter usado para moldar o campo de batalha. O Censys também possui uma equipe de segurança competente que tomará decisões difíceis sobre com quem eles se sentem confortáveis em fazer negócios e quem pode ter acesso.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matt Lembright"],"link":"/episode-EDT92-pt","image":"./episodes/edt-92/pt/thumbnail.png","lang":"pt","summary":"Neste episódio, Darren conversa com Matt Lembright, Diretor de Aplicações Federais da Censys, sobre como a Censys avalia a superfície de ataque de dispositivos conectados à internet, permitindo que organizações eliminem vulnerabilidades."},{"id":168,"type":"Episode","title":"As Quatro Superpotências da Transformação Digital","tags":["cybersecurity","aiml","multicloud","comms"],"body":"\r\n\r\nA Intel concentra-se na computação ubíqua, conectividade abrangente, nuvem até a borda e inteligência artificial (IA). Elementos desses quatro superpoderes são obrigatórios nas estratégias de transformação digital para empresas de todo o mundo, havendo assim grande sinergia.\n\n## Computação Ubíqua\n\nA computação ubíqua é um conceito de engenharia de software em que a computação está presente em todos os lugares. Não se refere apenas a dispositivos pessoais inteligentes, como telefones, relógios e eletrodomésticos, ou infraestrutura de data center e aplicativos baseados em nuvem, mas é a ideia de que a infraestrutura empresarial que historicamente estava atrás de um firewall agora está entrando na vida cotidiana. A infraestrutura empresarial está disponível para os funcionários no campus e em qualquer lugar onde eles tenham um dispositivo. Ainda mais importante, essa infraestrutura pode se estender aos clientes para melhorar sua experiência.\n\nA Intel está analisando quais elementos fundamentais devem ser implementados por meio do ecossistema para atingir o objetivo de que todas as pessoas na Terra tenham acesso a um petabyte de dados ou um petaflop de computação em menos de um milissegundo de acesso. A Intel está trabalhando nas leis da física, economia e soberania de dados para tornar isso possível. Isso fornecerá às empresas de software, empresas de nuvem e todas as empresas em todo o mundo um conjunto de diretrizes para o software que criará valor para seus clientes.\n\n## Conectividade Pervasiva\n\nEm uma entrevista recente, Glenn Kurowski, o CTO da CACI, falou sobre conectividade e como ele a enxerga se expandindo para o domínio espacial. Um ótimo exemplo é quando Elon Musk voou com o Starlink sobre a Ucrânia para evitar que eles ficassem sem acesso à internet.\n\nCom esse tremendo poder de computação, a conectividade é crucial. Existem conectividade via satélite, 5G e 4G. Ainda assim, mesmo dentro da internet, entre estados e países, a questão é: como você atravessa redes e permite pools de computação que não estão interconectados? Sem conectividade, o valor da computação diminui rapidamente.\n\nPara proteger esses dados interconectados, a Intel e equipes de centenas de empresas de tecnologia estão colaborando e inovando juntas. Os governos também devem entender as leis, regras e preocupações. A Intel, por exemplo, emprega uma força significativa para ajudar os legisladores a terem essas conversas e criar leis que protegem os dados. O ecossistema da Intel é vasto, e as pessoas prestam atenção quando a Intel diz que essa segurança é essencial.\n\nTradução: A Estônia é um bom modelo de país que protege os dados de seus cidadãos, mas também libera esses dados e oferece mais para seus cidadãos a um custo mais baixo. Haverá uma evolução natural desse modelo, à medida que os governos protegem ativamente a privacidade e pensam estrategicamente.\n\n## Nuvem para Borda\n\nNo lado empresarial está a extensão da superfície na qual as empresas podem interagir com seus clientes via nuvem até a borda. Um ótimo exemplo é o varejo omnicanal, onde uma empresa conhece quem é o cliente, suas tendências e o que eles precisam. Eles podem recomendar serviços adicionais com conectividade abrangente da nuvem à borda. Eles poderiam informar ao cliente onde algo que eles estão procurando está localizado quando eles chegam à loja. Os varejistas poderiam estender suas redes de um centro de dados na nuvem ou de um centro de dados local para se unificar na borda, criando uma rede de malha que percorre toda a loja.\n\nNão só isso melhoraria a experiência do comprador, mas as lojas poderiam diminuir as perdas detectando itens em falta e o fluxo dentro da loja. Eles poderiam colocar seus produtos nos lugares mais vantajosos e monitorar, por exemplo, os produtos perecíveis para tomar medidas para mover os produtos rapidamente enquanto estiverem no auge.\n\n## Traduzindo para o português: Inteligência Artificial\n\nA IA é uma extensão da análise de dados e inevitavelmente crescerá. Quantidades massivas de dados são criados diariamente, e já está além das capacidades das empresas computá-los de forma eficaz. As pessoas estão analisando apenas menos de cinco por cento dos dados gerados.\n\nCom algoritmos de IA, é possível encontrar padrões com esses dados para, por exemplo, curar o câncer. Pode estar aí presente porque a informação ainda não está disponível em um local onde a IA possa utilizá-la. Será necessário um novo mercado envolvendo conjuntos de dados centralizados e acessíveis. Uma corretora de dados organizada poderia disponibilizar dados centralizados a várias empresas por meio da nuvem, ao mesmo tempo em que protege a privacidade dos dados, como a identificação de pacientes.\n\n## Segurança dos Dados\n\nA COVID tornou rapidamente a computação ubíqua importante para os funcionários que trabalham em casa. Isso, juntamente com a subsequente força de trabalho híbrida, expôs falhas de segurança na indústria. Atualmente, há um aumento significativo no financiamento de segurança para lidar com os problemas e acompanhar a expansão das superpotências. Especialmente com as arquiteturas de ponta à nuvem e computação ubíqua, a superfície de ataque explodiu. A indústria pode acompanhar, mas requer esforço tremendo e pensamento avançado.\n\nA Intel tem inovações significativas nessa área com extensões de guarda de software, recursos de segurança em silício e o ecossistema para aproveitar essas coisas. O ecossistema pode criar novos casos de uso, como análises distribuídas confidenciais para pesquisas sobre o câncer ou análises multi-domínio, o que significa trabalhar com dados não classificados, classificados e ultra-secretos. Antes, esses dados nunca poderiam se misturar. Agora eles podem se combinar de forma segura e resolver problemas que não podíamos resolver antes.\n\n## Intel Software - Software Intel\n\nMuitos podem se surpreender que a Intel tenha mais de 19.000 engenheiros de software. A Intel consegue manter todos esses engenheiros plenamente ocupados, pois eles atuam em três níveis: software fundamental; linguagens, estruturas, ferramentas e bibliotecas; e trabalho de nível de aplicação.\n\nA maioria dessa tecnologia no nível de aplicação é disponibilizada na comunidade de código aberto, onde ela é acessível, segura e otimizada.\n\nVá para http://embracingdigital.org para recursos da Intel relacionados aos quatro superpoderes.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Ernst"],"link":"/episode-EDT93-pt","image":"./episodes/edt-93/pt/thumbnail.jpg","lang":"pt","summary":"Neste episódio, Darren discute os quatro superpoderes da transformação digital com Greg Ernst, VP Corporativo de Vendas, Américas da Intel. Computação ubíqua, Conectividade pervasiva, Nuvem à borda, Inteligência Artificial."},{"id":169,"type":"Episode","title":"o Renascimento da Nuvem Privada","tags":["hybridcloud","microcloud","privatecloud","compute","technology","cloud","vergeio"],"body":"\r\n\r\nGreg começou a programar no Commodore 64 quando era criança e nunca parou. Ele trabalhou em tudo, desde motores de jogos 3D até comunicações, mecanismos de banco de dados, servidores web e criptografia. Ele desenvolveu software de comunicações interoperáveis e soluções de hardware para os primeiros socorristas depois que surgiram problemas durante o 11 de setembro. Por exemplo, a polícia não conseguia falar com o corpo de bombeiros porque todos estavam em sistemas diferentes.\n\nDepois de uma saída bem-sucedida daquela empresa, ele começou uma nova empresa para construir um motor de busca vertical do zero. Rapidamente, ele percebeu que a parte difícil não era o motor de busca nem os algoritmos, mas sim os problemas de infraestrutura. Ele descobriu que grande parte do código era específico para hardware e faltava uma camada de abstração. Isso foi a base para o que se tornou o Yottabyte, sua empresa que começou resolvendo o problema de armazenamento ao juntar unidades baratas e apresentá-las como uma plataforma simplificada na qual se poderia escrever software sem se preocupar com o que estava por baixo do capô. Sua visão então se expandiu para incluir computação, memória e redes. Recentemente, o Yottabyte se tornou Verge.io.\n\nO sucesso da Verge.io é que tudo foi desenvolvido do zero, inclusive projetando sua própria linguagem de programação e escrevendo seus motores de banco de dados, para que o software fizesse tudo. Ele não está vinculado a nenhuma peça específica de hardware. O objetivo era a simplicidade: não se trata apenas de um monte de peças costuradas para formar uma nuvem privada singular, mas sim de um data center virtualizado completo.\n\nIsso oferece confiabilidade e segurança, pois há, por exemplo, atualizações contínuas, sem dependência de hardware específico e menos pontos de entrada vulneráveis. Além disso, os usuários-alvo do sistema são especialistas em TI em geral, não especialistas em armazenamento em área de rede (SAN) ou programadores.\n\nA plataforma Verge.io oferece a mesma experiência que um cliente pode obter de uma nuvem pública: simplicidade, autosserviço e agilidade, mas possui um custo considerável e um benefício de gravidade de dados. Você está pagando por coisas como IOP ou saída de dados em uma nuvem pública. Muitos pequenos preços começam a se acumular, e você pode se tornar responsável pelo ecossistema. Por outro lado, você pode executar o software Verge.io, por exemplo, em servidores metalicos para economizar custos e ter a capacidade de dimensionar para cima ou para baixo rapidamente. Em uma nuvem pública, você também desiste de muito controle. Com uma nuvem privada, você mantém seus dados mais próximos de onde estão sendo gerados e pode operar de maneira eficiente na borda.\n\nParte da razão pela qual os provedores de serviço escolhem a Verge.io é que eles podem gerenciar as tarefas de trabalho dos clientes sem abrir mão da margem de custo e reduzir as complicações de transferi-las para a nuvem pública.\n\nAs necessidades de outros clientes são atendidas porque eles podem realizar coisas que são muito difíceis de fazer com outros softwares. Por exemplo, a Universidade de Michigan encontrou uma eficiência muito melhorada e facilidade de uso. Eles têm milhares de pesquisadores e, quando recebem dinheiro de subvenção, eles precisam de um ambiente que esteja em conformidade com o HIPAA ou CUI. Antes, cada solicitação exigia de seis a nove meses para implantar, instalar e certificar o hardware. A Verge.io construiu um ambiente e começar a utilizá-lo é tão simples quanto pressionar um botão. Ao usuário é fornecida uma área isolada virtual totalmente compatível e muito segura, pois a área isolada é encapsulada e isolada.\n\nOutra vantagem é que o recurso de snapshot do Verge.io possui continuidade de negócios e recuperação de desastres integrados. Você pode pegar o snapshot e mover para uma arquitetura de hardware completamente diferente, e ele funcionará da mesma forma. A maneira como o snapshot funciona permite criar uma cópia clonada, mesmo que seja de dez petabytes, em menos de 30 milissegundos.\n\nPorque o centro de dados agora pode migrar facilmente para nuvens ou um centro de co-localização, os proprietários de empresas têm muito mais flexibilidade para negociar o preço e o desempenho do hardware. Além disso, não há tempo de inatividade para atualizações de hardware ou ciclos de atualização. O sistema nunca é desligado.\n\nUma das áreas em expansão para a Verge.io é a construção de software de agregação multi-cloud com benefícios, como um painel de gerenciamento centralizado.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Campbell"],"link":"/episode-EDT94-pt","image":"./episodes/edt-94/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, Intel, discute os data centers definidos por software da Verge.io que simplificam a TI e tornam a nuvem privada fácil e eficiente com o CTO da Verge.io, Greg Campbell."},{"id":170,"type":"Episode","title":"Requisitos para arquiteturas desde a borda até a nuvem.","tags":["data","edge","compute","cybersecurity"],"body":"\r\n\r\nAnna recentemente liderou um esforço para escrever um white paper sobre arquiteturas de serviço de borda para nuvem. A borda para a nuvem engloba todos os pontos altos da tecnologia que a Intel se preocupa: IA, borda, nuvem e conectividade de rede. O objetivo era reunir especialistas nessas áreas para discutir como a Intel aborda as arquiteturas de borda para nuvem e como essas arquiteturas podem se conectar à nuvem. O foco estava nos elementos que importam, em oposição à tecnologia atual que aborda as questões. Isso forneceria um quadro para falar sobre e procurar as desconexões. Uma revelação interessante foi que profissionais de TI, OT e redes falam linguagens técnicas diferentes com diferentes taxonomias, entre outros desafios.\n\nUma lição dessas discussões foi que as comunicações são hiper-críticas e deve haver um conhecimento sólido de suas comunicações, especialmente na borda. Isso determina quanta computação precisa ser local e com que frequência você pode contar com a nuvem. No setor público, a complexidade adicional dos casos de uso deve manter a funcionalidade mesmo em condições de negação, interrupção, intermitência e limitação (DDIL). Precisamos repensar essas arquiteturas na conectividade em nuvem com base nessas limitações.\n\nComunicações e conectividade são as diferenças mais significativas entre uma arquitetura em nuvem, infraestrutura de serviço e o edge. Muitas ferramentas atuais assumem incorretamente uma conectividade constante; se algo não estiver conectado, está inativo. Isso não ocorre no edge. Isso é evidente em organizações de edge, como o militar. Mesmo em setores como a telemedicina, é preciso assumir que não haverá boa conectividade, por exemplo, no caso de uso de telemedicina, onde você pode depender do WiFi residencial do paciente. O setor industrial tem requisitos semelhantes. Alguns não podem ficar offline devido a controles críticos para máquinas ou processos específicos.\n\nEntão, como você pode ter uma computação centrada na borda que mantém todas as funcionalidades críticas com conectividade de volta para a nuvem de forma essencialmente intermitente? Existem arquiteturas para isso, mas ainda há muito mais a ser feito para ter operações contínuas quando a conectividade pode não ser constante. O que você pode continuar fazendo e o que acontece quando tudo é restaurado? Haverá uma desconexão com o que vem acontecendo com os dados. Torna-se complexo quando você precisa sincronizar todos esses dados em escala, talvez com milhares de dispositivos de borda.\n\n## Segurança\n\nSegurança na borda é outra área em que sempre há mais trabalho a ser feito. Medidas de segurança tradicionais, como autenticação, ainda são extremamente importantes, mas os dispositivos representam uma grande superfície de ataque e sua segurança física é uma questão diferente. A segurança de laptops costuma ser sólida e essas medidas devem ser aplicadas a outros dispositivos na borda. Novos avanços em IA ajudarão a determinar se os dispositivos estão no local correto e a detectar anomalias em, digamos, dez mil dispositivos.\n\n## Desenvolvimento de Aplicativos\n\nNa criação de aplicações, os desenvolvedores devem compreender o ambiente exclusivo da borda e desenvolvê-las sem necessidade de reprogramação ou adoção de um novo middleware para ser executado na borda. As aplicações devem ser capazes de serem executadas com limitações de computação, energia e conectividade. Além disso, a borda pode estar em uma nova configuração de computação distribuída e a aplicação precisa ser projetada para ser executada em uma rede de malha com computação altamente distribuída. Desacoplar a aplicação do hardware é uma mudança significativa e está se tornando mais genérico e menos restrito. No entanto, todo o diálogo está caminhando para obter dados de qualquer lugar e utilizá-los em qualquer lugar.\n\n## Gerenciamento de dados\n\nO volume de dados gerado e coletado na borda é tão grande que não faz sentido enviar todos esses dados para um centro de dados para ser processado. Uma das razões é o custo. Nos Estados Unidos, uma rede privada 5G pode ser economicamente viável para essas enormes quantidades de dados, mas o custo seria proibitivo para a maioria das organizações sem 5G privado.\n\nA outra questão é que a maior parte dos dados não é útil. Por exemplo, ao monitorar dispositivos ou aplicativos, a maioria dos dados indica que tudo está funcionando corretamente, quando o que realmente importa são os eventos que sugerem problemas. Algoritmos de IA são aplicados na borda, reduzindo a quantidade de dados irrelevantes enviados para a nuvem para processamento.\n\nO modo de operação tradicional para a gestão de dados, copiando tudo para o centro de dados e executando análises lá, não funciona bem para a edge. Empurrar aplicativos para a edge nem sempre funciona também. A Intel identificou algumas outras arquiteturas de dados ou operações de dados. Uma delas é chamada de troca de dados, onde há uma combinação de movimentação de dados em ambientes seguros somente depois de serem analisados na edge, como processamento em lote. A outra é chamada de fluxos de dados inteligentes, onde SADE e SABR entram em jogo. Os dados são movidos apenas com base em regras e estão sendo transmitidos. Isso funciona em ambientes DDIL porque pode determinar os ambientes operacionais atuais e se ajustar.\n\n## Gerenciabilidade\n\nOs sistemas devem ser projetados de forma que possam ser mantidos. Você não pode implantar dez mil dispositivos e, em seguida, enviar regularmente um pequeno exército de pessoas para verificá-los. A área de TI sempre foi cautelosa em não querer atualizar um sistema em funcionamento. No entanto, não faz sentido deixar os sistemas sozinhos, especialmente com o medo de ataques de ransomware em redes OT. Os sistemas devem ser projetados de forma a manter tudo facilmente atualizado, a fim de lidar com o ambiente de segurança.\n\n## Disponibilidade\n\nEspecialmente em áreas críticas como militar ou saúde, é importante projetar sistemas com redundância suficiente; é mais uma abordagem sistêmica. Se os componentes individuais falharem, ainda é necessário alcançar o objetivo final. Isso é muito diferente do que acontece na nuvem, onde se trata de manter a infraestrutura em funcionamento.\n\nA tecnologia ainda não está completamente desenvolvida, mas está sendo considerada para projetar para várias redes. Se, por exemplo, você preferencialmente utilizar o WiFi 6 e ocorrer uma falha, o sistema pode utilizar o 4G ou outra rede disponível. A rede deve ser sólida, assim como o computador. Uma operação independente sem a parte da rede é frágil. Se você optar por conexões por cabo, terá limitações maiores e perderá seus aplicativos móveis.\n\nVocê pode encontrar o white paper \"Requisitos Essenciais para Arquiteturas de Serviço Edge to Cloud\" para mais informações em embracingdigital.org ou intel.org.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT95-pt","image":"./episodes/edt-95/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções da Intel, e Dra. Anna Scott, Arquiteta Principal de Borda de Setor Público, discutem os requisitos essenciais para arquiteturas de serviços da borda à nuvem."},{"id":171,"type":"Episode","title":"Aproveitando os Datacenters Virtuais com Verge.io","tags":["privatecloud","cloud","compute","technology","sdi","virtualdatacenter","vergeio"],"body":"\r\n\r\nAaron tem mais de 20 anos de experiência em TI. Ele é um engenheiro de pré-vendas, o que significa que ele conversa com os clientes sobre o valor e os recursos do Verge.io e os ajuda a definir suas necessidades.\n\nChris é o chefe de vendas na Verge.io com 25 anos de experiência em empresas de software de tecnologia. Ele descreve a Verge.io como tendo um foco maníaco na satisfação e sucesso do cliente com o software.\n\nO termo \"centro de dados virtual\" é usado para simplificar. A plataforma é multi-inquilino, portanto, existem inquilinos independentes e aninhados com todos os recursos necessários dentro de um centro de dados, desde CPU até memória, armazenamento e rede, e eles são isolados. Ao mesmo tempo, é possível construir isso sob demanda. Assim como é possível criar uma VM sob demanda, muitas vezes com um modelo, é possível fazer o mesmo com um inquilino onde ele encapsula tudo no centro de dados virtual. É possível construir através de um mecanismo de receita ou do zero. É fácil clonar ou tirar uma captura de um desses inquilinos.\n\nEsses data centers virtuais podem ser grandes e complexos. O maior cliente da Verge.io opera com mais de 60 nós e vários inquilinos em seu ambiente. As únicas restrições são as que estão incorporadas no cluster Verge.io de backend. Por exemplo, suponha que você tenha quatro terabytes de memória, 100 terabytes de armazenamento e 64 núcleos de CPU. Você pode designar todos esses recursos para esse inquilino, dividir como desejar, em metade ou terços, e construir os inquilinos dessa forma.\n\nSe, por exemplo, você alocou alguns nós para o desenvolvimento, alguns para teste e o restante para produção, eles seriam inquilinos diferentes e você pode tirar uma foto instantânea entre eles e movê-los para produção. Nesse caso, você pode até ter vários ambientes de produção com atualizações azul-verde.\n\nMuitos dos clientes da Verge.io são provedores de serviços gerenciados. Eles utilizam a multi-tenancy para seus clientes finais e, com isso, dedicam ambientes seguros de confiança zero. Os clientes podem ter seu próprio ambiente de nuvem e podem provisionar trabalhos virtuais conforme necessário.\n\nExistem também casos de uso significativos para clientes de TI do tipo empresarial que desejam, por exemplo, ambientes de desenvolvimento e teste azuis-verdes ou que possam ter diferentes ambientes com diferentes requisitos de conformidade de segurança, como SOX ou HIPAA. A Verge.io possui vários clientes de instituições educacionais de grande porte que estão realizando pesquisas em conformidade. Eles certificam seu cluster uma única vez; em seguida, podem fornecer um ambiente de pesquisa em conformidade para um de seus pesquisadores em menos de uma hora. Anteriormente, poderia levar meses para iniciar e criar um ambiente em conformidade.\n\nPara atualizações, embora os usuários devam usar ferramentas no nível da aplicação ou dentro das cargas de trabalho da VM, o \"conjunto de instruções\" do ambiente, para coisas como regras de firewall ou configurações de como os recursos são mapeados para as cargas de trabalho, pode ser atualizado sem problemas. Você também pode levar uma VM em um ambiente em execução com conformidade atualizada e movê-la para um novo ambiente.\n\nVerge.io também é útil para segurança. Uma das maiores empresas de quant na Europa é um bom exemplo de uso de segurança. Eles tiram uma foto de todo o seu ambiente e, em seguida, realizam exercícios de equipe de ataque e defesa, procurando por vulnerabilidades de segurança, verificando patches, etc.\n\nO VDI pode ser executado no ambiente. Verge.io faz parceria com uma empresa para suporte de VDI. Verge.io controla os recursos, a CPU e a memória. Eles também fornecem suporte para GPU e GPU passthrough, além de GPU física. Este é um caso de uso importante para alguns clientes, especialmente em cargas de trabalho de engenharia ou petróleo e gás. A GPU virtual proporciona economia favorável, pois o custo é distribuído entre vários usuários.\n\nUm ajuste perfeito para a Verge.io são os casos de uso de borda. Um exemplo típico é o ponto de venda. Se um cliente varejista tem cem lojas, ele pode precisar de duas ou três aplicações de máquinas virtuais (VMs) em cada loja. Como a Verge.io tem uma pegada de hardware pequena, uma vez que você tenha pelo menos dois servidores, você pode colocá-los no centro de dados de casos de uso de borda e construir essas VMs. E então, com os recursos de snapshot e replicação, essas configurações podem ser copiadas e coladas em todos os ambientes diferentes. Você pode atualizar as configurações mais recentes em todos eles, não apenas os patches do sistema operacional, mas também as regras de firewall.\n\nUm futuro emocionante para a Verge.io está nos sistemas de direção automatizada devido ao volume de dados. Muitos fornecedores estão testando os veículos em locais remotos e enviando fisicamente os discos rígidos. Imagine se os dados pudessem ser processados no local, totalmente redundantes, com custos atrativos associados a isso, então os dados poderiam ser transportados em uma área ampla em vez de um disco e um caminhão.\n\nPara obter mais informações sobre o Verge.io, visite http://verge.io.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Aaron Reid","Chris Lehman"],"link":"/episode-EDT96-pt","image":"./episodes/edt-96/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, arquiteto-chefe de soluções da Intel, e Aaron Reid, engenheiro principal de sistemas da https://www.verge.io/, junto com Chris Lehman, vice-presidente sênior de vendas, discutem casos de uso para o software de data center virtual da Verge.io."},{"id":172,"type":"Episode","title":"Os Benefícios dos Bancos de Dados de Gráfico","tags":["data","graphdb","katanagraph"],"body":"\r\n\r\nHadi obteve seu Ph.D. em ciência da computação em 2012 e pesquisou criptografia e segurança da informação em redes. Ele trabalhou no meio acadêmico por alguns anos e depois ingressou na indústria, focado em diferentes aspectos de soluções de segurança, incluindo gestão de identidade e acesso. Ele começou a aprender mais sobre modelagem de gráficos em 2015 e percebeu como a modelagem de dados em gráficos poderia resolver alguns dos problemas interessantes e complexos em sua área de estudo.\n\nEm bancos de dados de gráfico, um gráfico não significa gráficos ou interfaces gráficas, mas sim uma maneira de estruturar dados no nível de armazenamento para que possam ser recuperados e processados ​​para resolver problemas complexos, especialmente se os dados estiverem interconectados. O gráfico oferece muitos benefícios e pode complementar estruturas de dados ou soluções existentes, como modelos de banco de dados relacionais ou armazenamento de objetos.\n\nA principal diferença entre os bancos de dados gráficos e os bancos de dados relacionais é que, embora ambos tratem de relacionamentos, os bancos de dados relacionais levam os relacionamentos para o nível de metadados e esquema, enquanto os bancos de dados gráficos são orientados por relacionamentos de dados. Em outras palavras, você está relacionando colunas de tabelas em bancos de dados relacionais. Para introduzir um novo relacionamento, é necessário alterar o esquema. O grafo fornece uma infraestrutura sem esquemas onde você pode adicionar mais estrutura em torno de seus dados, mas ainda ter flexibilidade para incorporar qualquer dado não estruturado.\n\nMetade dos dados do mundo foi criada nos últimos anos, coletada de várias fontes diferentes, mas menos de dois por cento foi analisado, a maioria são dados estruturados. Os dados estão sendo coletados, porém as informações são insuficientes para processamento. Deve haver uma maneira de adicionar de forma flexível um pouco de estrutura que seja dinâmica o suficiente para mudar caso haja incerteza, mas ainda se beneficiar da computação otimizada avançada. O gráfico é uma excelente maneira de fazer isso.\n\nSe você está tentando trabalhar com dados correlacionados ou interconectados, ao contrário, por exemplo, de dados isolados com valores críticos, um gráfico oferecerá benefícios por causa das relações. Quase todas as indústrias podem se beneficiar porque os dados não estruturados geralmente vêm de várias fontes e têm naturezas múltiplas.\n\nUm exemplo seria soluções de segurança cibernética. Existem dados de registros e trens de auditoria dos ambientes de rede, infraestrutura de nuvem, hosts de endpoint, etc. Os dados vêm de diferentes fontes, como diretórios ou arquivos de log brutos. Seria benéfico correlacionar os dados, por exemplo, porque geralmente, uma identidade ou usuário que pode fazer parte de um registro do sistema de gerenciamento de identidade pode ser o mesmo usuário que dispara um processo em um laptop, como baixar um anexo de um e-mail. Ao analisar esses padrões, você pode usar essa ligação de correlação para obter mais insights. Em outras palavras, não importa como ou de onde vêm os dados, mas fornecer essa ligação leva a aprender sobre cada registro ao analisá-los em contexto.\n\nUm benefício é que não há problemas de transformação de dados, portanto, isso aumenta a velocidade. Isso também diminui os requisitos de armazenamento.\n\nOs gráficos e as estruturas de bancos de dados relacionais, em geral, são compatíveis. Aqui está um exemplo simplificado de uma rede social: Os tipos de nós no gráfico se parecem com tabelas. Então você pode ter um nó chamado \"pessoa\" e depois uma tabela chamada \"pessoa\". Você pode ter outro nó chamado \"localização\" e conectar a pessoa a uma localização específica. Você pode ter uma tabela chamada localização e conectá-la a chaves estrangeiras. Em seguida, você tem essa relação de amigos. Um amigo de uma pessoa em um modelo de gráfico é apenas um laço de retroalimentação. Isso permitiria que você modelasse esse esquema. Em um banco de dados relacional, você precisaria criar uma nova tabela chamada amigos e depois conectar. Portanto, mesmo em um nível de esquema, você está adicionando redundância e alguma estrutura por cima disso. E se você precisar adicionar um novo conceito de amizade ou relacionamento, precisará criar novas tabelas, aumentando a redundância e a complexidade.\n\nOutros benefícios de gráficos em relação a bancos de dados relacionais são gráficos em elementos, inteligência artificial em gráficos e a ideia de modelar os dados agora para encontrar padrões com base em como os dados estão conectados. Você pode reduzir o conjunto de dados que está pesquisando ou analisando por causa das relações. Está utilizando o poder dos dados para potencializá-los ainda mais. Os algoritmos em um banco de dados gráfico são muito diferentes dos bancos de dados relacionais e são melhor otimizados para lidar com grandes conjuntos de dados com mais rapidez.\n\nUma das desvantagens de um banco de dados em gráfico é que é difícil de escalar. Em um banco de dados relacional, é fácil dividir uma tabela e colocá-la em dois servidores, por exemplo. Os primeiros bancos de dados em gráfico foram projetados para serem uma solução única, então, se você quisesse aumentar a escala, seria necessário adicionar mais memória e CPU.\n\nAgora, se você deseja trabalhar com petabytes de dados em gráficos, deseja escalar verticalmente o máximo possível com tecnologia como as VMs Intel, mas também deseja escalar horizontalmente. Novas tecnologias, como a plataforma de gráficos da Katana, ajudam a resolver esse problema de escalabilidade com computação distribuída. Você pode dividir ou dividir o problema em partes e fazer com que cada uma trabalhe em uma pequena parte do gráfico para uma solução final. A Katana provou que você poderia usar 256 máquinas ou ainda mais para processar dados, assim você pode rapidamente ter dezenas de terabytes de dados na memória.\n\nUm banco de dados de gráfico requer um ecossistema semelhante a um banco de dados relacional. O gráfico é um pouco mais dinâmico e flexível. Se você deseja migrar para uma plataforma de análise de gráficos, que vai além dos bancos de dados operacionais, você pode aproveitar outras coisas, como armazenamento de dados e capacidades de data lake. Armazenamento e computação seriam separados, ou seja, as tecnologias de processamento de gráficos que executam tudo na memória não precisam depender do armazenamento ligado aos serviços, para que você possa ter um serviço de armazenamento diferente.\n\nKatana utiliza armazenamento de objetos e, em seguida, quando eles desejam computar, carregam de forma oportunista o que desejam do grafo para a memória distribuída de todas as máquinas. Os dados retornam imutáveis para o armazenamento, então se você, por exemplo, destruir todo o cluster, não perde nada. Todos os dados já estão lá e armazenados. Bancos de dados relacionais são uma área mais madura, mas os bancos de dados de grafo estão se tornando mais bem suportados no ecossistema.\n\nCom base nos oito anos de experiência de Hadi no campo, conversando com os interessados e clientes, todos imediatamente reconhecem os benefícios dos bancos de dados de gráficos. As limitações podem ser que eles não conseguem acompanhar a escalabilidade ou o custo. O trabalho da Katana e de outras empresas de tecnologia de gráficos é tornar os gráficos mais uma ferramenta comum que os clientes possam usar para várias tarefas e menos um luxo no banco de dados. Por exemplo, a Katana está fornecendo aos clientes soluções de identidade baseadas em gráficos e gerenciamento maciço de dados.\n\nBons casos de uso de grafos seriam a invenção precoce de soluções de gráficos específicas para algumas empresas como o LinkedIn e o Facebook, que possuem seus próprios gráficos sociais. Agora, um encaixe natural está no comércio eletrônico para motores de recomendação. Encontrar conexões entre clientes, contas, compras e outros comportamentos possibilitará melhores recomendações imediatamente para os compradores de uma maneira que não pode ser feita com consultas a bancos de dados relacionais.\n\nPara saber mais sobre a Katana ou como entrar em contato com o Hadi, acesse embracingdigital.org.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Madi Ahmadi"],"link":"/episode-EDT97-pt","image":"./episodes/edt-97/pt/thumbnail.jpg","lang":"pt","summary":"Darren Pulsipher, Arquiteto Principal de Soluções, Intel, Dr. Hadi Ahmadi, Diretor de Arquitetura de Soluções, Katana Graph discutem os benefícios de bancos de dados de gráficos."},{"id":173,"type":"Episode","title":"A Emergência da Rede de Dados Global","tags":["dataarchitecture","datamanagement","data","technology","cloud","globaldatanetwork","macrometa","multicloud","datamesh"],"body":"\r\n\r\nChetan é um engenheiro que se tornou especialista em operações e start-ups (Macrometa é sua quarta start-up). Ele diz que tem trabalhado no mesmo problema de lidar com dados distribuídos e reduzir a latência por vinte anos.\n\nOs dados não estão mais apenas em um centro de dados, mas em todos os lugares: na nuvem, na borda e nos laptops das pessoas. Gerenciar tudo isso de forma eficaz é um desafio.\n\nCerca de dez anos atrás, Marc Andreessen disse que o software está devorando o mundo. Neste ponto, o software engoliu tudo e transformou todo tipo de restrição e barreira em oportunidades. A computação multithreading é uma das barreiras que foi superada com a nuvem. É possível construir aplicativos que funcionam em diferentes partes do mundo simultaneamente. Um movimento de desenvolvedores está acontecendo em paralelo para tornar tudo o mais simples possível para um profissional de ciência da computação médio. Portanto, de um lado temos uma sofisticada evolução tecnológica e, do outro lado, um movimento em direção à simplicidade.\n\nArquiteturas como Jamstack permitem que a computação distribuída ocorra em grande escala com muita simplicidade, mas ainda há uma vasta fronteira a ser descoberta e explorada. A oportunidade de expansão de terras extensas está agora na borda. O gerenciamento de dados distribuídos e a borda são duas faces da mesma moeda.\n\nUm grande problema é que parte do desenvolvimento de software está se movendo para funcionar como um serviço que ignora os dados. Além disso, existe a percepção de que os dados são ubíquos, mas grande parte das bordas não está sempre conectada. Não há garantia de que um aplicativo tenha acesso a todos os dados. As redes não estão mais centralizadas; a ideia de microsserviços sem estado surgiu do movimento da nuvem. Essa falta de estado pode se tornar uma barreira enorme. É por isso que arquiteturas como o Jamstack e funções serverless tratam os dados como uma questão periférica, e não central.\n\nAs estruturas de dados sem estado são simples. Você tem um lugar específico onde deve registrar seus dados e, em seguida, continuar com o estado sem estado novamente. As estruturas de dados com estado requerem infraestruturas robustas com estruturas de dados mais complexas, pois elas oferecem suporte à aplicação à medida que ela emite constantemente seu estado. À medida que avançamos para um mundo de dados em tempo real em que o estado é constantemente emitido de algum lugar no ecossistema, a infraestrutura se torna complexa e difícil de gerenciar porque não são projetadas para isso. É aí que entra a Macrometa. Eles construíram uma nova plataforma para esse estado ativo, contínuo e em tempo real em uma escala de exabyte.\n\nLidar com esses dados em streaming em um estado ativo e dinâmico é uma mudança significativa para muitos desenvolvedores de software. Desde que as primeiras infraestruturas em nuvem surgiram, seguidas por plataformas de big data e serviços de dados, a indústria se tornou eficiente em absorver, processar e analisar dados históricos. Mas agora, estamos em um mundo onde os dados estão em um espectro, em vez de existir como um monólito. Uma qualidade recém-apreciada é que os dados têm insights e valor perecíveis. Alguns dados têm uma vida útil breve. As escalas de tempo atuais são muito grandes para usar dados de forma eficiente; precisamos de sistemas que comuniquem eficientemente em até 50 milissegundos e reduzam o esforço cognitivo para as pessoas que interagem com esses sistemas.\n\nA maioria das pessoas entende mal a latência: não é algo que traz alegria, mas sim a sua falta que causa frustração. Por exemplo, por quanto tempo alguém tolerará um vídeo do YouTube com travamentos ou um show da Netflix com carregamento lento? Cinquenta milissegundos para uma máquina é uma eternidade. Uma máquina pode realizar uma enorme quantidade de coisas em 50 milissegundos, então a latência se torna essencial, especialmente ao considerar o valor perecível dos dados.\n\nOutra questão agora é que, devido à nuvem, interconectividade e ao sistema global, as startups se tornaram empresas multinacionais, e os dados se tornaram sensíveis à localização. Alguns dados são regulados, outros são informações de identificação pessoal (PII) e não podem ser expatriados em certas jurisdições, etc. Um excelente exemplo desse problema é como os europeus não querem que seus dados saiam de suas fronteiras, mas grande parte da infraestrutura de nuvem e das aplicações estão aqui nos Estados Unidos.\n\nUm terceiro problema é que os dados estão armazenados em muitos lugares; existem limites entre sistemas, físicos e lógicos. Os dados podem ser essencialmente estáticos e rígidos, então precisamos de uma infraestrutura que permita que os dados se conectem e fluam em tempo real, com consistência e garantias de ordenação. Mais importante ainda, isso cria fungibilidade para ser consumido rapidamente de maneiras diversas.\n\nUm problema adicional é que os dados contêm muitos ruídos, e não faz sentido transferir grandes distâncias intercontinentais, pagando taxas de transferência, apenas para depois descartar a maior parte deles. Os dados perdem valor até chegarem ao seu destino. Além disso, há uma alta taxa de atualização, então os sistemas frequentemente trabalham com dados desatualizados.\n\nPrecisamos de novas formas de resolver esses tipos de problemas de dados distribuídos. Chetan acredita que os próximos dez anos pertencerão a essa área das ciências de dados.\n\nA primeira geração de soluções de dados distribuídos utilizou a transformação operacional. O Google Docs é um excelente exemplo disso. No entanto, a transformação operacional requer centralização do controle, portanto, não escala bem. O Google encontrou uma maneira de escalar, mas isso não é generalizado para o desenvolvedor médio. Talvez haja apenas cinco empresas no mundo que o entendem nessa escala, e grande parte desse conhecimento está restrito a essas empresas e tecnologia proprietária.\n\nA Macrometa está trabalhando com a comunidade e a academia para tentar criar um novo corpo de conhecimento, muito mais eficiente do que esses modelos centralizados, de forma completamente distribuída.\n\nAtualmente, existem infraestruturas disponíveis que são excelentes em resolver problemas históricos do tipo sistema de registro. Elas estão tentando seguir em direção aos dados em tempo real, mas suas arquiteturas não são fundamentalmente feitas para isso. Esses novos problemas com dados sensíveis ao tempo e localização, valor de atuação, taxas de atualização, gravidade de dados e ruído de dados requerem uma nova maneira, uma nova infraestrutura. Chetan chama isso de sistema de interação, em vez de sistema de registro, porque sistemas de interação são redes de dados, próximas de onde você origina e consome dados, que então filtram e enriquecem todos eles em linha e roteiam para seus destinatários pretendidos. É uma função de rede.\n\nA Macrometa construiu processadores de rede que estão movendo os dados por aí - uma rede global de dados. É um sistema de API sem servidor onde os desenvolvedores simplesmente consomem APIs para resolver problemas de dados ativos e operacionais em tempo real. A Macrometa é uma rede global de dados na topologia de um CDM, mas com uma plataforma de dados como o Snowflake que produz elementos de dados ricos para lidar com valores de dados ativos e operacionais em tempo real.\n\nVocê pode integrar ferramentas analíticas na rede global de dados e implantar análises perto de onde os dados são gerados ou necessários. Assim como a Amazon mudou fundamentalmente a distribuição varejista com arquitetura local e algoritmos para manter os armazéns locais otimizados para envios durante a noite, a Macrometa fez o mesmo com os dados. Eles estão aproximando os dados e a computação nesses dados, permitindo que isso aconteça em milissegundos. Essa capacidade de criar loops de informações em tempo real é um habilitador poderoso. Por exemplo, pequenos varejistas podem usar o inventário da loja local em seu comércio eletrônico sem se comprometer demais para competir com a Amazon.\n\nUm ótimo caso de uso para a plataforma Macrometa é na cibersegurança. Alguns clientes estão substituindo seus modelos de dados centralizados para aproveitar a latência reduzida, permitindo bloquear ameaças em tempo real.\n\nA rede mundial de dados é uma camada de transformação entre suas fontes e receptores de dados com os consumidores e publicadores. Ela é composta por três elementos tecnológicos. O primeiro é a malha global de dados, que é a camada de integração para dados. O segundo é um tecido global de computação que permite orquestrar dados e lógica de negócios na forma de funções e contêineres globalmente. A terceira peça é um tecido global de privacidade: como garantir a segurança dos dados e cumprir diferentes regimes e regulamentações de dados que afetam se seus dados estão sendo transmitidos ou armazenados.\n\nA malha global de dados é uma maneira de integrar rapidamente e facilmente dados de diferentes sistemas, independentemente de suas fronteiras, sejam físicas ou lógicas. Tudo é incorporado e flui com consistência e garantias de ordenação. O valor mais significativo dessa malha é que ela torna os dados fungíveis e consumíveis, permitindo que você coloque APIs nos dados rapidamente. Isso pode ser feito em algumas horas, em comparação com o tempo usual de meses. A rede global de dados é projetada para trilhões de eventos por segundo, de forma que possa movimentar dados em escalas imensas a um custo 90% menor do que a nuvem.\n\nA estrutura global de computação traz lógica empresarial e orquestração para aproximar o processamento de seus dados ao local onde eles têm origem ou são consumidos. Esse é o padrão anti-nuvem. A Macrometa vai mover cirurgicamente e de forma dinâmica esses microsserviços que precisam cumprir regulamentações de dados, por exemplo, para os locais corretos de execução.\n\nA última peça é a proteção de dados. Este é um problema complexo e as respostas que temos hoje, por exemplo, abrir um silo separado para aquela geolocalização específica a fim de cumprir com particulares todas as vezes que inicializar uma instância em seu aplicativo, não são boas. A plataforma da Macrometa possui uma rede de dados que já integra e faz com que seus dados fluam através de todas as fronteiras, juntamente com funções de computação e ingestão de dados sem limites. Agora, ela pode criar fronteiras lógicas e fixar dados em regiões específicas para proteção de dados. Eles podem definir afinidades e políticas sobre como os dados vivem e se replicam em uma região, como por exemplo, se eles devem ser anonimizados quando copiados para fora da região.\n\nA tecnologia da Macrometa permite casos de uso que são impossíveis de serem realizados na nuvem, pois as nuvens estão muito distantes ou são muito lentas. A Macrometa construiu a infraestrutura para resolver problemas de dados em tempo real e transformá-los em oportunidades, em vez de desafios. Para mais informações sobre a Macrometa, acesse macrometa.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Chetan Venkatesh"],"link":"/episode-EDT98-pt","image":"./episodes/edt-98/pt/thumbnail.jpeg","lang":"pt","summary":"Neste episódio, Darren relembra com Chetan Venkatesh, CEO da MacroMeta. Venkatesh possui uma longa história em gerenciamento de dados desde os primeiros dias da Grid Computing e iniciou a MacroMeta para lidar com o gerenciamento de dados nas bordas geograficamente dispersas, centros de dados e nuvens."},{"id":174,"type":"Episode","title":"Caminho de Ataque Cibernético com Precognição da XM Cyber.","tags":["aiml","cybersecurity","xmcyber","technology","process"],"body":"\r\n\r\nPaul está na área de segurança desde o final dos anos noventa, começando fazendo projetos para o Departamento de Segurança Interna e o Departamento de Defesa. Em 2005, ele ingressou na Fishnet Security como engenheiro de vendas e tem se envolvido nessa área desde então. Ele se juntou à XM Cyber para se concentrar na simulação de violações e ataques.\n\nEm vez da segurança cibernética tradicional, que é detecção, remediação e prevenção, a XM Cyber é preditiva. Uma boa descrição é que ela é uma simulação de precognição. A XM Cyber cria incidentes imaginativos para fornecer uma visão de como suas ferramentas poderiam lidar com eles e como você poderia trabalhar para remediar pontos de estrangulamento específicos. A ideia é fazer tudo isso antes dos testes de penetração. Você pode corrigir coisas hoje, ver o impacto amanhã e, em seguida, aumentar e melhorar continuamente a sua segurança.\n\nO Google Maps é uma boa analogia para explicar como a XM Cyber funciona. Quando você deseja ir de um lugar para outro, o Google Maps irá mostrar todas as formas de chegar lá, evitando pedágios, oferecendo a rota mais direta, etc. A XM Cyber faz a mesma coisa, mas com uma simulação de ataques. Por exemplo, suponha que você tenha uma conta de usuário ativa comprometida no Active Directory. Nesse caso, ela mostrará os seis passos necessários para chegar a um controlador de domínio local e comprometer esse ativo crítico. Também mostrará todas as rotas diferentes entre esses dois pontos.\n\nUm caso de uso para isso é que você pode habilitar uma equipe de ataque (red team) a ser super eficiente com essas informações, pois eles não precisam ficar procurando e tentando fazer descobertas. Isso também pode ajudar a equipe de defesa (blue team), permitindo que eles priorizem as correções nos pontos de estrangulamento. Por exemplo, se houver 400 caminhos de ataque, todos indo para diferentes áreas na sua DMZ, mas todos os 400 parecem ter que utilizar essa única entidade para tornar esse caminho possível, você pode corrigir esse único problema e destruir os 400 caminhos. As equipes de defesa podem bloquear esses pontos de estrangulamento que podem permitir ao atacante obter acesso.\n\nUma área que a XM Cyber analisa é o gerenciamento de identidade, não apenas no data center, mas também na nuvem. Às vezes, os caminhos de ataque terão dez etapas, mas nove delas serão navegando pelo mundo da identidade. Por exemplo, você pode ter permissões para sua conta de administrador e, em seguida, essa conta de administrador pode ter permissões adicionais. Você pode fazer seis ou sete etapas ajustando diferentes permissões ou redefinindo senhas e implantando GPOs. Você pode dar nove passos de uma conta de usuário padrão para o administrador do domínio aproveitando o diretório ativo.\n\nAlém da identidade, a XM Cyber analisa mais de cem entidades como máquinas, buckets S3 e chaves SSH. Essas diferentes entidades podem ser combinadas para criar um caminho de ataque. Às vezes, isso se torna muito complexo. Por exemplo, um ataque pode começar no local, ir para o Azure, aproveitar o Intune e depois retornar para comprometer outra máquina que permite uma transição para o GCP. Uma vez que os invasores estão no ambiente do GCP, eles podem aproveitar a confiança ou permissão entre a AWS e o GCP para comprometer a AWS. A XM Cyber analisa todos os diferentes tipos de entidades em ambientes distintos e os conecta para avaliar esses caminhos em torno de como cada entidade joga de forma global em relação ao risco de todas as outras.\n\nExistem duas formas pelas quais a XM Cyber interage com os clientes. A primeira é uma descoberta em alto nível para avaliar o ambiente, expor vulnerabilidades e medir como um invasor pode expor novas vulnerabilidades para colocar ativos críticos em risco. A segunda é uma avaliação direcionada de um cenário específico que preocupa o cliente. Esses compromissos não se limitam apenas à análise estática de entidades. Eles são dinâmicos porque observam o tráfego e outros padrões.\n\nUm caso de uso típico direcionado é determinar se a OT é o ativo crítico ou o ponto de violação. A XM Cyber simula cenários, como por exemplo, se uma máquina no setor de Recursos Humanos é o ponto de violação, existe algum risco para esse PLC que está no ambiente SCADA controlando interruptores de pressão que podem desligar a eletricidade para um município. Esse é um caso de uso real que a XM Cyber pode simular. Esse tipo de informação é crucial em um mundo onde a OT não está mais isolada, mas conectada às redes.\n\nA XM Cyber é uma solução SaaS em vez de uma solução local, para que possa se manter dinâmica e fornecer o melhor serviço. Pode ser assustador pensar que algo na nuvem tem todas as suas técnicas de ataque. No entanto, a XM Cyber realiza bastante trabalho para garantir que os dados estejam completamente isolados, em conformidade com SOC 2, entre outras certificações, e não há multi-inquilinato. Além disso, eles não coletam informações sensíveis. As informações sensíveis são hashadas e apenas uma parte é enviada para a nuvem. Eles não precisam ter os dados reais.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Paul Giorgi"],"link":"/episode-EDT99-pt","image":"./episodes/edt-99/pt/thumbnail.png","lang":"pt","summary":"Darren Pulsipher, Arquiteto Chefe de Soluções, e Paul Giorgi, Diretor de Engenharia de Vendas, da Intel, discutem como a tecnologia da XM Cyber pode ajudar as organizações a descobrir caminhos de ataque e reduzir riscos."},{"id":175,"type":"News Brief","title":"2023-2-5","tags":["ai","compute","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nDe acordo com a Forbes, até 2030, a IA poderá entregar 13 trilhões de dólares à economia global, ou 16% do PIB mundial atual.\n\nO ChatGPT permite que os estelionatários criem e-mails tão convincentes que podem obter dinheiro de vítimas sem mesmo precisar de malware. Alguns temem que o poderoso chatbot facilite muito a criação de malware por pessoas que não são programadoras, tornando-as criminosos cibernéticos.\n\nA Google investiu quase 400 milhões de dólares na startup de inteligência artificial Anthropic, que está testando um rival ao OpenAI ChatGPT. A Google realizará um evento sobre como está \"usando o poder da IA para reimaginar como as pessoas procuram\". O evento de 40 minutos será transmitido no YouTube em 8 de fevereiro às 8h30 ET.\n\nUma ferramenta de detecção de IA, que verifica o conteúdo escrito pelo ChatGPT, afirma que \"Macbeth\", de William Shakespeare, foi gerado por IA. Acho que o ChatGPT não foi treinado em inglês antigo.\n\n## Computação Ubíqua\n\nAs receitas públicas globais da nuvem continuam a aumentar, com o crescimento projetado de 26% previsto para chegar a 525 bilhões de dólares este ano, de acordo com a Statista. O software como serviço é projetado para ser 253 bilhões de dólares dessa receita. No entanto, à medida que o crescimento da nuvem continua, os provedores de serviços de nuvem sentem dor, pois houve várias interrupções nos últimos 12 meses. Este problema tem sido tão grave que vários sites surgiram para monitorar e relatar a disponibilidade da nuvem pública, como cloudharmony.com e thousandeyes.com.\n\nA Oracle e a Red Hat se uniram para fornecer instâncias de máquina virtual baseadas em RHEL na nuvem da Oracle, executadas em processadores Intel, AMD e Arm. Essa parceria entre antigos concorrentes está fornecendo aos clientes uma loja única para cargas de trabalho que utilizam a suíte de produtos da Oracle e cargas de trabalho baseadas em Linux tradicionais. Este movimento continua a empurrar a Oracle para a competição com os grandes Hyper-scalers, como Azure, AWS e Google.\n\n## Segurança cibernética\n\nE-commerce na Coreia do Sul e nos EUA estão sendo atacados por uma campanha contínua de malware GuLoader, revelou a empresa de segurança cibernética Trellix no final do mês passado. Os atacantes cibernéticos estão mudando sua abordagem de documentos do Microsoft Word para o NSIS (Nullsoft Scriptable Install System), uma ferramenta de código aberto para escrever instaladores no sistema operacional Windows. GuLoader Malware Usando NSIS Malicioso\n\nHackers pró-russos estão usando uma nova plataforma de DDoS-como-serviço chamada Passion para alvo instituições médicas nos EUA, Portugal, Espanha, Alemanha, Polônia, Finlândia, Noruega, Holanda e Reino Unido. Essa oferta de software como serviço é um serviço de assinatura que permite aos clientes selecionar seus vetores de ataque desejados, duração e intensidade. Criminosos Cibernéticos Russos Lançam Nova Plataforma de Ataque Passion\n\nA Agência de Segurança Cibernética e Infraestrutura dos EUA (CISA) anunciou na quinta-feira o lançamento de um guia de Categorização de Vulnerabilidade Específica aos Stakeholders (SSVC) que pode ajudar as organizações a priorizar a correção de vulnerabilidades usando um modelo de árvore de decisão. O sistema SSVC foi criado em 2019 pela CISA e pelo Instituto de Engenharia de Software da Universidade Carnegie Mellon (SEI), e um ano depois a CISA desenvolveu sua própria árvore de decisão SSVC personalizada para falhas de segurança relevantes para organizações governamentais e de infraestrutura crítica. CISA Lança Modelo de Árvore de Decisão\n\n## Podcast de Adoção da Transformação Digital\n\nNesta semana, Darren Pulsipher entrevista o chatGPT.\n\n[Leia mais](https://www.embracingdigital.org/episodes-EDT122)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW1-pt","image":"./briefs/edw-1/pt/thumbnail.png","lang":"pt","summary":"For the week of February 6, 2023. News from around the world of digital transformation in artificial intelligence, cloud computing, and cybersecurity."},{"id":176,"type":"News Brief","title":"2023-4-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Inteligência Artificial\n\nMais uma coisa com a qual os pais precisam se preocupar. Clonagem de voz por IA! Em um recente caso virtual de rapto por um cibercriminoso, a mãe de uma adolescente de 15 anos foi chamada e enganada usando a voz da filha para anunciar seu sequestro, seguido por \"Eu tenho sua filha\". Agindo rapidamente, a mãe enviou uma mensagem de texto para o marido verificar a localização da filha, que estava em segurança. O FBI está investigando este e vários outros casos.\n\n[https://www.azfamily.com/2023/04/10/ive-got-your-daughter-scottsdale-mom-warns-close-encounter-with-ai-voice-cloning-scam/](https://www.azfamily.com/2023/04/10/ive-got-your-daughter-scottsdale-mom-warns-close-encounter-with-ai-voice-cloning-scam/)\n\nEugenia Kuyda é a fundadora da Replika, um aplicativo de chatbot dos EUA que diz oferecer aos usuários um \"companheiro de IA que se importa, sempre aqui para ouvir e conversar, sempre ao seu lado\". Lançado em 2017, agora possui mais de dois milhões de usuários ativos. Cada um tem um chatbot ou \"replika\" exclusivo para eles, pois a IA aprende com suas conversas. Os usuários também podem projetar seu próprio avatar de desenho animado para o chatbot.\n\n[https://www.bbc.com/news/business-65110680](https://www.bbc.com/news/business-65110680)\n\nNVIDIA, Getty Images colaboram em Inteligência Artificial Generativa. As empresas visam desenvolver dois modelos de IA generativos usando o NVIDIA Picasso, parte dos novos serviços em nuvem da NVIDIA AI Foundations. Os usuários poderiam empregar os modelos para criar uma imagem ou vídeo personalizado em segundos, simplesmente digitando um conceito. O esforço conjunto tem como objetivo personalizar modelos de base texto-imagem e texto-vídeo, para gerar visuais impressionantes usando conteúdo visual totalmente licenciado.\n\n[https://blogs.nvidia.com/blog/2023/03/21/generative-ai-getty-images/?ncid=so-link-748862&=&linkId=100000197541685#cid=gtcs23_so-link_en-us](https://blogs.nvidia.com/blog/2023/03/21/generative-ai-getty-images/?ncid=so-link-748862&=&linkId=100000197541685#cid=gtcs23_so-link_en-us)\n\n## Computação Ubíqua\n\nO COBOL finalmente está morto? GFT e Cloud Frame estão unindo forças para ajudar organizações a mover seus programas COBOL para plataformas mais eficientes. O COBOL foi desenvolvido em 1959 como uma das primeiras linguagens suportadas por vários fornecedores para usuários de negócios de mainframe. Tem se tornado cada vez mais caro depurar e manter sistemas COBOL devido à falta de programadores que ainda trabalham com COBOL.\n\n[https://www.cloudcomputing-news.net/news/2023/apr/04/gft-and-cloudframe-help-industries-say-cheerio-to-cobol/](https://www.cloudcomputing-news.net/news/2023/apr/04/gft-and-cloudframe-help-industries-say-cheerio-to-cobol/)\n\nOs grandes modelos de linguagem (LLMs) estão em alta, com o ChatGPT liderando o caminho. Isso é bom apenas para provedores de serviços em nuvem, já que os LLMs requerem grandes quantidades de computação e armazenamento de dados para implantação e desenvolvimento. Para não ficar para trás, os provedores de serviços em nuvem Azure, AWS e Google anunciaram suas próprias soluções LMS para competir nessa nova arena pela dominação da nuvem. Vamos perguntar ao ChatGPT quem será o vencedor.\n\n[https://www.infoworld.com/article/3693330/large-language-models-are-the-new-cloud-battleground.html](https://www.infoworld.com/article/3693330/large-language-models-are-the-new-cloud-battleground.html)\n\nO Google entrou na disputa da computação confidencial com uma nova oferta que garante privacidade completa de dados sensíveis por meio da criptografia de dados em repouso, em trânsito e agora em uso. A Azure e a AWS têm ofertas de produtos semelhantes que fornecem computação confidencial para clientes do setor público e privado.\n\n[https://www.wired.com/story/google-cloud-confidential-virtual-machines/](https://www.wired.com/story/google-cloud-confidential-virtual-machines/)\n\nTraduza o seguinte para português: ## Segurança Cibernética\n\nEm um interessante ataque DDoS, atores ameaçadores inundaram o npm, um repositório de pacotes de código aberto para Node.js, criando sites maliciosos e publicando pacotes vazios com links para esses sites maliciosos para aproveitar a boa reputação do ecossistema nos mecanismos de busca. Mais de 1,42 milhão de pacotes falsos foram enviados.\n\n[https://thehackernews.com/2023/04/hackers-flood-npm-with-bogus-packages.html](https://thehackernews.com/2023/04/hackers-flood-npm-with-bogus-packages.html)\n\nMais de 1.000.000 de sites WordPress são estimados estar infectados por uma campanha em andamento para implantar o malware Balada Injector. Os ataques ocorrem em ondas a cada poucas semanas. Os ataques redirecionam subdomínios aleatórios para vários sites de golpes, incluindo sites com suporte técnico falso. A melhor maneira de combater isso é atualizar os plugins em seus sites WordPress.\n\n[https://thehackernews.com/2023/04/over-1-million-wordpress-sites-infected.html](https://thehackernews.com/2023/04/over-1-million-wordpress-sites-infected.html)\n\nO grupo estatal iraniano MuddyWater tem realizado ataques destrutivos em ambientes de nuvem híbrida sob o disfarce de operações de ransomware. Os atores da ameaça estão se fazendo passar por uma campanha padrão de ransomware, mas essencialmente estão destruindo e interrompendo operações críticas de TI. As descobertas mostraram que a MuddyWater colaborou com a DEV-1084 para realizar esses ataques.\n\n[https://thehackernews.com/2023/04/iran-based-hackers-caught-carrying-out.html](https://thehackernews.com/2023/04/iran-based-hackers-caught-carrying-out.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW10-pt","image":"./briefs/edw-10/pt/thumbnail.png","lang":"pt","summary":"Resumo"},{"id":177,"type":"News Brief","title":"2023-4-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Comunicações Avançadas\nTradução: ## Segurança Cibernética\n\nO FBI alertou o público contra o uso de estações públicas de carregamento de telefones devido ao risco de ciberataques. Essas estações de carregamento, comumente encontradas em locais públicos como aeroportos, shopping centers e hotéis, podem potencialmente conter malware que compromete a segurança das informações pessoais e dispositivos dos usuários. Traga seu próprio adaptador de energia USB e você estará pronto para seguir em frente.\n\n[https://www.cnbc.com/2023/04/10/fbi-says-you-shouldnt-use-public-phone-charging-stations.html](https://www.cnbc.com/2023/04/10/fbi-says-you-shouldnt-use-public-phone-charging-stations.html)\n\nO Google lançou uma atualização urgente para seu navegador web Chrome para resolver uma vulnerabilidade crítica que os hackers exploram. A vulnerabilidade, identificada como um bug \"use-after-free\", pode permitir que atores maliciosos executem código arbitrário e potencialmente obtenham controle sobre sistemas afetados. O Google instou os usuários a atualizarem seus navegadores Chrome para a versão mais recente o mais rápido possível para mitigar o risco de serem alvo de ataques cibernéticos.\n\n[https://thehackernews.com/2023/04/google-releases-urgent-chrome-update-to.html](https://thehackernews.com/2023/04/google-releases-urgent-chrome-update-to.html)\n\nOs aplicativos Android e Novi Survey foram encontrados com vulnerabilidades graves de segurança que poderiam expor potencialmente as informações pessoais dos usuários. As falhas poderiam permitir que atacantes ultrapassem as medidas de segurança e obtenham acesso não autorizado a dados sensíveis. Os usuários são instados a ter cuidado e atualizar seus aplicativos para as versões mais recentes para se proteger contra possíveis ameaças cibernéticas.\n\n[https://thehackernews.com/2023/04/severe-android-and-novi-survey.html](https://thehackernews.com/2023/04/severe-android-and-novi-survey.html)\n\n## Gerenciamento de Dados\n\nDe acordo com o Diretor de Estratégia da OneTrust, lacunas de privacidade e ética de dados representam uma ameaça existencial para as organizações. A falta de abordagem adequada dessas lacunas pode resultar em danos à reputação, passivos legais e financeiros e perda de confiança do cliente. As organizações devem priorizar a privacidade e ética de dados para mitigar riscos e proteger seus negócios diante dos requisitos regulatórios em evolução e crescente escrutínio público.\n\n[https://deloitte.wsj.com/articles/data-privacy-ethics-gaps-an-existential-threat-says-onetrust-cso-01668542698](https://deloitte.wsj.com/articles/data-privacy-ethics-gaps-an-existential-threat-says-onetrust-cso-01668542698)\n\nApós uma revisão detalhada dos relatórios recentes do Escritório de Responsabilidade Governamental dos Estados Unidos, Andrew Kuoh, um principal da Capgemini, identificou três ações-chave que as organizações de dados no setor público devem focar. Fomentar uma cultura orientada por dados, estabelecer estruturas de governança de dados e aproveitar tecnologias modernas como computação em nuvem e inteligência artificial (IA) para aproveitar o valor dos dados. (Pessoas, Processos e Tecnologia soam familiares.)\n\n[https://www.informationweek.com/government/3-actions-to-kickstart-data-ecosystems-in-the-public-sector](https://www.informationweek.com/government/3-actions-to-kickstart-data-ecosystems-in-the-public-sector)\n\nUm webinar recente de um membro do painel da DBTA discutiu a importância de acompanhar as necessidades em constante evolução dos bancos de dados e aplicativos na nuvem. À medida que a computação em nuvem avança, as organizações devem adaptar suas estratégias de banco de dados e aplicativos para otimizar o desempenho, a segurança e a escalabilidade. Enfatizar tecnologias nativas da nuvem, automação e melhores práticas pode ajudar as empresas a se manterem à frente no ambiente dinâmico da nuvem atual.\n\n[https://www.dbta.com/Editorial/News-Flashes/Keeping-Up-with-the-Evolving-Needs-of-Databases-and-Applications-in-the-Cloud-158166.aspx](https://www.dbta.com/Editorial/News-Flashes/Keeping-Up-with-the-Evolving-Needs-of-Databases-and-Applications-in-the-Cloud-158166.aspx)\n\n## Borda Inteligente\n\nA Edge Computing Expo North America, agendada para 17-18 de maio de 2023, recentemente anunciou uma lista repleta de estrelas de líderes empresariais e tecnólogos no espaço IOT. A conferência será realizada no Centro de Convenções de Santa Clara, na Califórnia. Você precisa marcar esta data em sua agenda!\n\n[https://www.iot-now.com/2023/04/14/129661-edge-computing-expo-north-america-announces-speaker-line-up-hear-from-leading-experts-in-edge-computing/](https://www.iot-now.com/2023/04/14/129661-edge-computing-expo-north-america-announces-speaker-line-up-hear-from-leading-experts-in-edge-computing/)\n\nA convergência da cibersegurança de TI e OT está se tornando realidade à medida que mais soluções de cibersegurança do espaço de TI se concentram na proteção da IoT e da infraestrutura industrial. Um exemplo recente é a introdução do CloudStrike Falcon Insight para IoT pela CrowdStrike. Essa plataforma traz a mesma ferramenta para IoT, endpoints de TI e cargas de trabalho em nuvem e data center.\n\n[https://www.iot-now.com/2023/04/17/129671-crowdstrike-brings-xdr-for-iot-offering-to-deliver-protection-to-iot-assets/](https://www.iot-now.com/2023/04/17/129671-crowdstrike-brings-xdr-for-iot-offering-to-deliver-protection-to-iot-assets/)\n\nNum ótimo exemplo de implantação da Indústria 4.0, o Grupo Volvo assumiu a implantação de uma infraestrutura de manutenção preventiva de TI em sua fábrica em Lyon, na França. O Grupo Volvo está utilizando uma Rede de Longo Alcance de Área Ampla (LoRaWAN) para permitir o monitoramento e análise em tempo real dos dados dos equipamentos da fábrica, permitindo manutenção preventiva proativa.\n\n[https://www.edgecomputing-news.com/2023/04/03/volvo-group-uses-lorawan-for-predictive-maintenance-in-lyon-factory/](https://www.edgecomputing-news.com/2023/04/03/volvo-group-uses-lorawan-for-predictive-maintenance-in-lyon-factory/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW11-pt","image":"./briefs/edw-11/pt/thumbnail.png","lang":"pt","summary":"Sumário"},{"id":178,"type":"News Brief","title":"2023-4-23","tags":["ai","edge","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nDe acordo com o MarketWatch, com uma taxa de crescimento anual esperada de quase 27%, o hardware de IA, uma indústria de US$ 10 bilhões em 2021, espera-se que seja uma indústria de US$ 89 bilhões até 2030.\n\n[https://www.marketwatch.com/story/nvidia-is-ai-hardwares-leader-now-but-intel-amd-and-others-are-closing-fast-8ad6f23f](https://www.marketwatch.com/story/nvidia-is-ai-hardwares-leader-now-but-intel-amd-and-others-are-closing-fast-8ad6f23f)\n\nAgência de Projetos de Pesquisa Avançada de Defesa (DARPA), projeto GARD (Garantindo a Robustez da IA contra a Decepção) de vários milhões de dólares, que tem três objetivos principais: desenvolver algoritmos que protejam a aprendizagem de máquina contra vulnerabilidades; desenvolver teorias para garantir que os algoritmos de IA sejam defensáveis contra ataques; e compartilhar amplamente as ferramentas.\n\n[https://www.zdnet.com/in-depth/innovation/these-experts-are-racing-to-protect-ai-from-hackers-time-is-running-out/](https://www.zdnet.com/in-depth/innovation/these-experts-are-racing-to-protect-ai-from-hackers-time-is-running-out/)\n\nTom Brady ameaçou processar os comediantes por trás do vídeo de stand-up de IA. Utilizando dados de entrevistas com Tom Brady e centenas de milhares de horas de filmagens de comédia stand-up, o Dudsey Bran simulou um especial de comédia stand-up de uma hora.\n\n[https://nypost.com/2023/04/20/tom-brady-threatened-to-sue-comedians-over-ai-standup-video/](https://nypost.com/2023/04/20/tom-brady-threatened-to-sue-comedians-over-ai-standup-video/)\n\n## Cibersegurança\n\nUm novo relatório da CybelAngel revelou as cinco principais exposições de segurança cibernética que representam riscos críticos para organizações. O relatório identifica as principais ameaças de configurações incorretas de nuvem, vulnerabilidades na cadeia de suprimentos, ataques de ransomware, fraudes de phishing e software não corrigido. O relatório insta as organizações a mitigar esses riscos e proteger proativamente seus sistemas e dados.\n\n[https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures/](https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures/)\n\nA agência europeia de controle de tráfego aéreo Eurocontrol revelou que sofreu um ataque cibernético da Rússia no início deste mês. O ataque visou os sistemas da agência, mas o Eurocontrol conseguiu conter e remediar o incidente sem qualquer interrupção ao tráfego aéreo. A agência alertou outras organizações a serem vigilantes e fortalecer suas defesas contra ameaças cibernéticas.\n\n[https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures](https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures)\n\nFoi descoberta uma vulnerabilidade crítica no produto de sistema de controle industrial (ICS) da INEA, que poderia permitir que atacantes remotos assumissem sistemas afetados e causassem interrupção ou dano às operações industriais. A falha, que afeta todas as versões do produto, foi descoberta por pesquisadores da Claroty. A empresa pediu às organizações que utilizam o produto que atualizem para a versão mais recente o mais rápido possível para mitigar o risco de exploração.\n\n[https://www.securityweek.com/critical-flaw-in-inea-ics-product-exposes-industrial-organizations-to-remote-attacks/](https://www.securityweek.com/critical-flaw-in-inea-ics-product-exposes-industrial-organizations-to-remote-attacks/)\n\n## Borda Inteligente\n\nA Kneron, fornecedora de soluções de inteligência artificial (IA) de borda, adquiriu a Otus, fabricante de soluções de imagem para veículos autônomos. A aquisição permitirá que a Kneron aproveite a experiência da Otus no desenvolvimento de câmeras compactas e eficientes em termos de energia para aplicações de IA de borda. A aquisição deve acelerar a adoção de IA de borda na indústria de transporte.\n\n[https://www.edgecomputing-news.com/2023/04/20/kneron-buys-otus-for-edge-ai-imaging-in-autonomous-vehicles/](https://www.edgecomputing-news.com/2023/04/20/kneron-buys-otus-for-edge-ai-imaging-in-autonomous-vehicles/)\n\nA Solo.io lançou o Gloo Fabric, uma plataforma de malha de serviço multi-cloud segura para aplicativos empresariais, com suporte a ambientes híbridos e multi-cloud, com um painel centralizado para monitorar, gerenciar e solucionar problemas em aplicativos.\n\n[https://www.edgeir.com/gloo-fabric-by-solo-io-promises-secure-multi-cloud-discovery-and-connectivity-for-enterprises-20230421](https://www.edgeir.com/gloo-fabric-by-solo-io-promises-secure-multi-cloud-discovery-and-connectivity-for-enterprises-20230421)\n\nO governo do Canadá e a Ericsson investirão CA$ 470 milhões ($ 376 milhões) em pesquisa e desenvolvimento de 5G e 6G ao longo de cinco anos para criar uma infraestrutura de telecomunicações sustentável e segura, desenvolver novos casos de uso e aplicativos, incluindo cidades inteligentes e veículos conectados.\n\n[https://www.edgeir.com/government-of-canada-ericsson-announce-ca470-million-investment-for-5g-6g-rd-20230420](https://www.edgeir.com/government-of-canada-ericsson-announce-ca470-million-investment-for-5g-6g-rd-20230420)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW12-pt","image":"./briefs/edw-12/pt/thumbnail.png","lang":"pt","summary":"Resumo"},{"id":179,"type":"News Brief","title":"2023-4-30","tags":["ai","cybersecurity","edge"],"body":"\n\n## Inteligência Artificial\n\nComeça a reação negativa da inteligência artificial: os fãs do Snapchat estão expressando seu descontentamento com o uso de bots alimentados por ChatGPT na plataforma, marcando uma reação contra a AI. Os usuários criticam a falta de respostas humanas e a incapacidade de diferenciar entre conteúdo real e gerado por AI. O incidente destaca crescentes preocupações e a necessidade de uma implementação equilibrada de AI em plataformas de mídia social.\n\n[https://www.techradar.com/news/the-ai-backlash-begins-snapchat-fans-revolt-against-chatgpt-powered-bot](https://www.techradar.com/news/the-ai-backlash-begins-snapchat-fans-revolt-against-chatgpt-powered-bot)\n\nÓculos equipados com inteligência artificial lêem a fala não-verbal/silenciosa. Pesquisadores da Universidade Cornell desenvolveram uma interface de reconhecimento de fala silenciosa que usa sensores acústicos e inteligência artificial para reconhecer continuamente até 31 comandos não-vocalizados com base nos movimentos dos lábios e da boca. A interface vestível de baixa potência - EchoSpeech - requer apenas alguns minutos de dados de treinamento do usuário antes de reconhecer comandos e pode funcionar em um smartphone. Eu juro que meus avós sabiam fazer isso há 40 anos. Eles se comunicavam bem apenas com um aceno de cabeça, um sorriso e um olhar.\n\n[https://news.cornell.edu/stories/2023/04/ai-equipped-eyeglasses-can-read-silent-speech](https://news.cornell.edu/stories/2023/04/ai-equipped-eyeglasses-can-read-silent-speech)\n\nOs chatbots de IA podem substituir chefes? Uma startup chamada Aesthetic explora o potencial de chatbots alimentados por IA para assumir tarefas gerenciais, oferecendo orientação, respondendo a perguntas e gerenciando fluxos de trabalho. Embora eficientes, alguns argumentam que qualidades humanas como empatia são insubstituíveis. A combinação de interação humana e IA é a melhor abordagem para liderança eficaz no local de trabalho?\n\n[https://startup.outlookindia.com/sector/saas/can-your-boss-be-replaced-by-an-ai-chatbot--news-8257](https://startup.outlookindia.com/sector/saas/can-your-boss-be-replaced-by-an-ai-chatbot--news-8257)\n\n## Cibersegurança\n\nA Agência de Segurança e Infraestrutura Cibernética (CISA) está buscando comentários públicos sobre uma diretiva preliminar que exige que agências federais atestem as práticas de segurança de software. A diretiva tem como objetivo melhorar a segurança das cadeias de suprimentos de software, e o período de comentários está aberto até 3 de maio de 2023.\n\n[https://www.cybersecuritydive.com/news/cisa-public-comment-software-security-attestation/648932/](https://www.cybersecuritydive.com/news/cisa-public-comment-software-security-attestation/648932/)\n\nOs atacantes de ransomware evoluíram suas táticas, reveladas em um relatório da CrowdStrike, recorrendo a métodos coercivos para extorquir pagamentos das vítimas. Além de criptografar dados, essas táticas envolvem ameaçar danos físicos, expor informações roubadas para a mídia e até mesmo visar famílias das vítimas. As organizações precisam permanecer vigilantes e adaptar suas defesas para combater essas novas estratégias e mitigar o impacto dos ataques de ransomware, além de proteger seus valiosos dados da exploração.\n\n[https://cyware.com/news/coercion-in-the-age-of-ransomware-new-tactics-for-extorting-payments-0c31dba6](https://cyware.com/news/coercion-in-the-age-of-ransomware-new-tactics-for-extorting-payments-0c31dba6)\n\nO provedor de armazenamento refrigerado, Americold, sofreu um ataque à sua rede que causou um amplo apagão afetando múltiplos sistemas. A empresa confirmou o incidente, mas não divulgou a natureza da violação ou a extensão do impacto. Como medida de precaução, a Americold temporariamente desativou certos sistemas e contratou especialistas externos em cibersegurança para investigar o ataque. Acredita-se que os dados dos clientes estejam seguros e a empresa está trabalhando para restaurar a funcionalidade completa.\n\n[https://www.bleepingcomputer.com/news/security/cold-storage-giant-americold-outage-caused-by-network-breach/](https://www.bleepingcomputer.com/news/security/cold-storage-giant-americold-outage-caused-by-network-breach/)\n\n## Borda Inteligente.\n\nA Akamai Technologies adquiriu a NeoSec, uma startup de cibersegurança focada na segurança de APIs, para fortalecer suas capacidades na detecção e resposta a ataques baseados em APIs. A aquisição melhorará os serviços de segurança da Akamai e fornecerá aos clientes uma proteção aprimorada contra ameaças que visem as interfaces de programação de aplicativos. A Akamai tem como objetivo enfrentar o cenário de cibersegurança em constante evolução, expandindo seu portfólio de segurança e oferecendo soluções aprimoradas para combater os riscos relacionados às APIs.\n\n[https://www.edgecomputing-news.com/2023/04/24/akamai-acquires-neosec-to-bolster-api-detection-and-response/](https://www.edgecomputing-news.com/2023/04/24/akamai-acquires-neosec-to-bolster-api-detection-and-response/)\n\nZadara e Kasten para Veeam se uniram para fornecer uma solução abrangente de proteção de dados para ambientes Kubernetes. Combinando zCompute, zStorage da Zadara e a plataforma K10 da Kasten, a solução oferece backup, recuperação de desastres e mobilidade de aplicativos. Ele permite o movimento perfeito de aplicativos entre clusters Kubernetes, incluindo localizações da nuvem global da Zadara. A colaboração aborda a necessidade de soluções de armazenamento ágeis e econômicas, protegendo aplicativos nativos da nuvem em Kubernetes e suportando vários bancos de dados. Além disso, a Zadara lançou recentemente sua plataforma de infraestrutura Flex-N c9 como Serviço no Japão em colaboração com a BroadBand Tower.\n\n[https://www.edgeir.com/zadara-kasten-by-veeam-unite-to-provide-multi-tier-data-protection-for-kubernetes-20230428](https://www.edgeir.com/zadara-kasten-by-veeam-unite-to-provide-multi-tier-data-protection-for-kubernetes-20230428)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW13-pt","image":"./briefs/edw-13/pt/thumbnail.png","lang":"pt","summary":"News and stories from the Week of May 01, 2023, in Digital Transformation, including cyberattacks and intelligent edge, non-verbal communication AI, and company merges in the IoT space."},{"id":180,"type":"News Brief","title":"2023-5-7","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Gerenciamento de Dados\n\nDIQ, uma nova ferramenta de índice de confiança de dados, promove a democratização de dados. A ferramenta mede a confiabilidade das fontes de dados, permitindo que organizações tomem decisões informadas sobre o uso de dados. Ao fornecer transparência e responsabilidade, o DIQ busca capacitar empresas em suas estratégias orientadas por dados e aprimorar a confiança na tomada de decisões baseadas em dados.\n\n[https://tdwi.org/articles/2023/05/04/diq-all-data-trust-index-tool-to-drive-data-democratization.aspx\n](https://tdwi.org/articles/2023/05/04/diq-all-data-trust-index-tool-to-drive-data-democratization.aspx\n)\n\nA FIATA e o Global Shippers Forum estão defendendo padrões de governança de dados mais robustos na indústria de navegação. Eles destacam a necessidade de abordar desafios de qualidade, acessibilidade e segurança de dados para melhorar a eficiência da cadeia de suprimentos. O estabelecimento de padrões consistentes visa aprimorar o compartilhamento de dados, a colaboração e a tomada de decisões entre as partes interessadas, o que beneficia a comunidade de navegação globalmente.\n\n[https://www.porttechnology.org/news/fiata-global-shippers-forum-push-for-stronger-data-governance-standards/\n](https://www.porttechnology.org/news/fiata-global-shippers-forum-push-for-stronger-data-governance-standards/\n)\n\nA Databricks Ventures investiu na Immuta, uma empresa focada em fortalecer a governança do lakehouse. A plataforma da Immuta fornece soluções de acesso e controle de dados, permitindo que as organizações governem e protejam efetivamente seus ambientes de lakehouse de dados. Este investimento tem como objetivo melhorar as capacidades de governança de dados no ecossistema Databricks, promovendo privacidade, conformidade e segurança de dados para empresas que utilizam arquiteturas de lakehouse.\n\n[https://www.databricks.com/blog/strengthening-lakehouse-governance-ecosystem-databricks-ventures-invests-immuta\n](https://www.databricks.com/blog/strengthening-lakehouse-governance-ecosystem-databricks-ventures-invests-immuta\n)\n\n## Inteligência Artificial\n\nO principal engenheiro por trás do chatbot avançado do Google, Geoffrey Hinton, renunciou devido a preocupações com os potenciais riscos e implicações éticas da tecnologia de IA. Hinton acredita que o sistema de chatbot que ele desenvolveu pode ser usado para espalhar desinformação e notícias falsas, enfatizando a necessidade de desenvolvimento e implementação responsáveis ​​de IA para proteger a sociedade.\n\n[https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\n](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\n)\n\nAs empresas de tecnologia querem ser remuneradas pelos dados que alimentam modelos de inteligência artificial. Os chatbots estão digerindo a internet, e provedores de conteúdo querem receber pelo seu uso. Empresas de inteligência artificial estão utilizando conteúdo criado por milhões de pessoas sem o seu consentimento ou remuneração. O Reddit, fonte inestimável para a OpenAI, anunciou recentemente que irá começar a cobrar empresas de IA pelo acesso aos dados. O Twitter também está fazendo o mesmo. A OpenAI se recusou a comentar.\n\n[https://www.wsj.com/articles/chatgpt-ai-artificial-intelligence-openai-personal-writing-5328339a\n](https://www.wsj.com/articles/chatgpt-ai-artificial-intelligence-openai-personal-writing-5328339a\n)\n\nA IA está começando a substituir os humanos no trabalho de escritório. O CEO da IBM anuncia uma interrupção temporária na contratação de empregos de escritório, enquanto a empresa investe em tecnologia de IA. A decisão reflete a mudança estratégica da IBM na alavancagem da inteligência artificial para simplificar as operações e melhorar a eficiência. A medida demonstra o compromisso da empresa em se adaptar aos avanços tecnológicos e às demandas em evolução do mercado.\n\n[https://fortune.com/2023/05/01/ibm-ceo-ai-artificial-intelligence-back-office-jobs-pause-hiring/\n](https://fortune.com/2023/05/01/ibm-ceo-ai-artificial-intelligence-back-office-jobs-pause-hiring/\n)\n\n## Computação Ubíqua\n\nA VMware introduziu os Cross-Cloud Managed Services, uma nova oferta para simplificar e otimizar o gerenciamento multi-cloud. O serviço oferece aos clientes uma plataforma unificada para gerenciar diversos ambientes em nuvem, proporcionando maior visibilidade, segurança e capacidades de governança. Com essa solução, a VMware tem como objetivo ajudar as organizações a superar as complexidades das operações multi-cloud e otimizar suas estratégias de nuvem para obter melhor eficiência e agilidade.\n\n[https://www.cloudcomputing-news.net/news/2023/may/04/vmware-unveils-cross-cloud-managed-services/\n](https://www.cloudcomputing-news.net/news/2023/may/04/vmware-unveils-cross-cloud-managed-services/\n)\n\nA AWS (Amazon Web Services) desenvolveu um novo serviço que fornece acesso seguro a aplicativos de nuvem sem VPNs (Redes Privadas Virtuais) tradicionais. O serviço, AWS Client VPN, utiliza a infraestrutura global de rede da AWS para estabelecer conexões seguras entre usuários e recursos de nuvem. Esta abordagem simplifica o acesso remoto enquanto mantém altos níveis de segurança, facilitando para as organizações gerenciarem e protegerem seus ambientes de nuvem de forma eficaz.\n\n[https://www.networkworld.com/article/3695174/aws-secures-access-to-cloud-apps-without-using-vpns.html\n](https://www.networkworld.com/article/3695174/aws-secures-access-to-cloud-apps-without-using-vpns.html\n)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW14-pt","image":"./briefs/edw-14/pt/thumbnail.png","lang":"pt","summary":"News in Digital Transformation for the week of May 8, 2023 including "},{"id":181,"type":"News Brief","title":"2023-5-14","tags":["ai","edge","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nO The Irish Times foi vítima de uma farsa quando publicou um artigo gerado por um programa de inteligência artificial (IA). O artigo gerado pela IA passou despercebido e foi postado on-line, destacando os desafios de detectar conteúdo gerado por máquinas. Esse incidente levanta preocupações sobre o potencial de desinformação e a necessidade de processos eficazes de verificação diante de conteúdo gerado por IA.\n\n[https://www.lemonde.fr/en/economy/article/2023/05/17/the-irish-times-duped-by-a-hoax-article-written-by-an-artificial-intelligence-program_6026930_19.html\r](https://www.lemonde.fr/en/economy/article/2023/05/17/the-irish-times-duped-by-a-hoax-article-written-by-an-artificial-intelligence-program_6026930_19.html\r)\n\nA Europa está liderando na criação de diretrizes para o desenvolvimento de inteligência artificial (IA). A União Europeia está desenvolvendo regulamentações abrangentes para garantir que a IA seja transparente, responsável e respeite os direitos humanos. Essas medidas visam abordar preocupações éticas e riscos potenciais associados à IA, tornando a Europa líder global na formação da implementação responsável da IA.\n\n[https://www.nbcnews.com/tech/tech-news/europe-leading-world-building-guardrails-ai-rcna83912\r](https://www.nbcnews.com/tech/tech-news/europe-leading-world-building-guardrails-ai-rcna83912\r)\n\nUm novo estudo sugere que a tecnologia de inteligência artificial generativa (IA) tem o potencial de aumentar as horas de trabalho dos profissionais de saúde em até 40%. Automatizando tarefas rotineiras e fornecendo suporte à tomada de decisões, a IA poderia aumentar a eficiência e permitir que médicos e enfermeiros se concentrem em cuidados mais críticos e complexos ao paciente.\n\n[https://www.healthcareitnews.com/news/generative-ai-could-augment-40-healthcare-working-hours\r](https://www.healthcareitnews.com/news/generative-ai-could-augment-40-healthcare-working-hours\r)\n\n## Cibersegurança\n\nA Agência de Segurança Cibernética e de Infraestrutura (CISA) alertou sobre uma vulnerabilidade crítica nos pontos de acesso wireless da Ruckus que está sendo explorada para infectar redes Wi-Fi. O bug permite que atacantes ganhem acesso não autorizado e executem código arbitrário remotamente. A CISA aconselha as organizações que usam os pontos de acesso da Ruckus a aplicar os patches necessários e implementar medidas de mitigação para se proteger contra possíveis ataques.\n\n[https://www.bleepingcomputer.com/news/security/cisa-warns-of-critical-ruckus-bug-used-to-infect-wi-fi-access-points\r](https://www.bleepingcomputer.com/news/security/cisa-warns-of-critical-ruckus-bug-used-to-infect-wi-fi-access-points\r)\n\nDados sensíveis pertencentes a 237.000 funcionários do governo dos EUA foram expostos devido a uma violação de segurança. As informações comprometidas incluem números de Seguro Social, informações de contato e informações de emprego. A violação foi atribuída a um indivíduo não autorizado que acessou a conta de e-mail de um funcionário. As autoridades estão investigando o incidente e as pessoas afetadas estão sendo notificadas.\n\n[https://www.yahoo.com/news/data-237-000-us-government-232707971.html\r](https://www.yahoo.com/news/data-237-000-us-government-232707971.html\r)\n\nUma falha grave de segurança foi descoberta, expondo mais de 2 milhões de registros sensíveis no site WordPress. A vulnerabilidade no plugin WordPress \"Essential Addons para Elementor\" permite acesso não autorizado a dados pessoais, incluindo nomes, endereços e informações financeiras. A falha afeta software amplamente utilizado, representando um risco significativo à privacidade e segurança dos usuários. Os desenvolvedores estão trabalhando em uma correção e os usuários são aconselhados a atualizar seus sistemas prontamente.\n\n[https://thehackernews.com/2023/05/severe-security-flaw-exposes-over.html\r](https://thehackernews.com/2023/05/severe-security-flaw-exposes-over.html\r)\n\n## Computação de Borda\n\nUm recente relatório da UL Solutions destaca a inteligência artificial (IA) e a Internet das Coisas (IoT) na borda como tecnologias cruciais para organizações que utilizam redes 5G. A combinação de IA e IoT na borda permite o processamento de dados em tempo real, análises avançadas e automação, desbloqueando novas possibilidades para as indústrias de saúde, manufatura e transporte. O relatório enfatiza o potencial dessas tecnologias no impulso à inovação e eficiência na era 5G.\n\n[https://www.edgeir.com/report-reveals-ai-iot-edge-as-key-technologies-for-organizations-leveraging-5g-20230512\r](https://www.edgeir.com/report-reveals-ai-iot-edge-as-key-technologies-for-organizations-leveraging-5g-20230512\r)\n\nKyndryl, uma empresa de serviços de TI, está expandindo suas ofertas ao introduzir um serviço gerenciado de Secure Access Service Edge (SASE). O SASE combina segurança de rede e recursos de rede de longa distância em uma solução baseada na nuvem unificada. Ao incorporar o SASE em sua carteira, a Kyndryl tem como objetivo fornecer segurança e conectividade aprimoradas para empresas que operam em um ambiente híbrido ou multi-nuvem. A mudança está alinhada com a crescente demanda por soluções de segurança abrangentes e simplificadas no cenário de TI em constante evolução.\n\n[https://www.sdxcentral.com/articles/analysis/why-kyndryl-is-adding-a-managed-sase-service/2023/05/\r](https://www.sdxcentral.com/articles/analysis/why-kyndryl-is-adding-a-managed-sase-service/2023/05/\r)\n\nPrevê-se que o mercado Edge AI experimente um crescimento substancial, com seu tamanho esperado aumentar significativamente nos próximos anos. Fatores como a proliferação de dispositivos IoT, avanços na tecnologia AI e a necessidade de processamento de dados em tempo real impulsionam esse crescimento. O Edge AI possibilita a tomada de decisões inteligentes na borda da rede, reduzindo a latência e melhorando a eficiência. A expansão do mercado apresenta oportunidades para várias indústrias, incluindo saúde, manufatura e varejo.\n\n[https://finance.yahoo.com/news/edge-ai-market-size-predicted-190000466.html\r](https://finance.yahoo.com/news/edge-ai-market-size-predicted-190000466.html\r)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW15-pt","image":"./briefs/edw-15/pt/thumbnail.png","lang":"pt","summary":"News from the week of May 15, 2023 in digital transformation including stories from Edge Computing, Cybersecurity, and Artificial Intelligence."},{"id":182,"type":"News Brief","title":"2023-5-21","tags":null,"body":"\n\n## Computação Ubíqua\n\nA Amazon Web Service (AWS) planeja investir US$ 12,7 bilhões no mercado de infraestrutura em nuvem da Índia até 2030, apoiando a criação de empregos e projetos de energia renovável. O investimento tem como objetivo atender à crescente demanda dos clientes e contribuir para a transformação digital da Índia, ao mesmo tempo em que aborda os desafios de infraestrutura.\n\n[https://www.cloudcomputing-news.net/news/2023/may/22/aws-to-put-13-billion-into-india-cloud-infrastructure-by-2030/\r](https://www.cloudcomputing-news.net/news/2023/may/22/aws-to-put-13-billion-into-india-cloud-infrastructure-by-2030/\r)\n\nA plataforma de dados em nuvem fornecida pela Snowflake abriu um novo escritório no Reino Unido para expandir-se pela região EMEA (Europa, Oriente Médio e África). A mudança ocorre em resposta ao forte impulso da empresa no mercado e tem como objetivo servir melhor sua crescente base de clientes na área.\n\n[https://www.cloudcomputing-news.net/news/2023/may/16/snowflake-opens-uk-office-amid-strong-momentum-across-emea/\r](https://www.cloudcomputing-news.net/news/2023/may/16/snowflake-opens-uk-office-amid-strong-momentum-across-emea/\r)\n\nA Microsoft está se preparando para lançar sua solução Microsoft Cloud for Sovereignty, visando governos e organizações do setor público. A solução de nuvem do setor passou por prévias privadas para abordar desafios específicos do setor. A Microsoft enfatiza a transparência, políticas de dados e segurança, com planos para oferecer soluções de plataforma em vários setores.\n\n[https://www.ciodive.com/news/Microsoft-industry-cloud-data-sovereignty-platform/650214/\r](https://www.ciodive.com/news/Microsoft-industry-cloud-data-sovereignty-platform/650214/\r)\n\n## Comunicações Avançadas\n\nA Intel apresentou sua FPGA Agilex, um chip programável projetado para redes inteligentes. A FPGA Agilex oferece recursos avançados, incluindo aceleração de inteligência artificial e segurança aprimorada, tornando-a adequada para várias aplicações. Espera-se que o chip capacite a infraestrutura de rede com maior flexibilidade e desempenho.\n\n[https://www.networkworld.com/article/3697156/intel-launches-agilex-fpga-for-smart-networking.html\r](https://www.networkworld.com/article/3697156/intel-launches-agilex-fpga-for-smart-networking.html\r)\n\nEthernet, a pioneira tecnologia de rede, comemora seu 50º aniversário. Apesar de sua jornada impressionante até agora, a evolução do Ethernet continua. Com avanços como velocidades mais rápidas, maior capacidade e confiabilidade aprimorada, o Ethernet continua sendo vital na conexão do mundo digital. À medida que a tecnologia avança, o Ethernet está pronto para desempenhar um papel crucial na moldagem do futuro das redes.\n\n[https://www.networkworld.com/article/3697013/ethernet-turns-50-but-its-voyage-has-only-begun.html\r](https://www.networkworld.com/article/3697013/ethernet-turns-50-but-its-voyage-has-only-begun.html\r)\n\nSoluções de código aberto estão simplificando a gestão de tecidos de rede complexos, de acordo com a Network Computing. Com a crescente complexidade das redes modernas, ferramentas e estruturas de código aberto oferecem flexibilidade, interoperabilidade e capacidades de automação. Essas soluções permitem que as organizações agilizem a gestão de tecidos, reduzam custos e melhorem a eficiência. As abordagens baseadas em código aberto estão se tornando cruciais para simplificar as complexidades dos tecidos de rede no cenário digital atual.\n\n[https://www.networkcomputing.com/networking/simplifying-complex-fabrics-open-source-based-solutions\r](https://www.networkcomputing.com/networking/simplifying-complex-fabrics-open-source-based-solutions\r)\n\n## Gerenciamento de dados\n\nO IDM.net.au sugere explorar a automatização da governança de dados por cinco motivos: melhoria na qualidade dos dados, conformidade simplificada, produtividade aprimorada, visibilidade de dados aumentada e adaptabilidade ao cenário de dados em evolução. A automação reduz erros, garante conformidade, aumenta eficiência, fornece controle e mantém as organizações competitivas.\n\n[https://idm.net.au/article/0014302-5-reasons-explore-data-governance-automation-opportunities\r](https://idm.net.au/article/0014302-5-reasons-explore-data-governance-automation-opportunities\r)\n\nTDWI.org discute como especialistas em dados lidam com desafios de raspagem de websites. Eles enfatizam a importância de selecionar ferramentas e técnicas apropriadas para extrair dados de websites. Superar obstáculos como medidas anti-raspagem e conteúdo dinâmico requer proxies, agentes de usuários e conhecimento em estruturação de dados. A raspagem de websites bem-sucedida permite a aquisição de dados valiosos para análise e tomada de decisões.\n\n[https://tdwi.org/articles/2023/05/18/diq-all-how-data-experts-overcome-web-scraping-challenges.aspx\r](https://tdwi.org/articles/2023/05/18/diq-all-how-data-experts-overcome-web-scraping-challenges.aspx\r)\n\nEm um relatório recente, Dataversity.net alerta sobre arquitetura de segurança fraca em ambiente de nuvem. O artigo identifica erros comuns, incluindo controles de acesso fracos e configurações incorretas, que podem resultar em violação de dados. Enfatizando a importância de autenticação forte e monitoramento, destaca a necessidade de medidas robustas de segurança para proteger dados sensíveis em arquiteturas de nuvem.\n\n[https://www.dataversity.net/cloud-architecture-mistakes-the-perils-of-poor-security-architecture/\r](https://www.dataversity.net/cloud-architecture-mistakes-the-perils-of-poor-security-architecture/\r)\n\n\n\n","guests":null,"link":"/brief-EDW16-pt","image":"./briefs/edw-16/pt/thumbnail.png","lang":"pt","summary":"Digital Transformation news for the week of May 29, 2023. In this episode."},{"id":183,"type":"News Brief","title":"2023-5-28","tags":null,"body":"\n\n## Inteligência Artificial\n\nO CEO da OpenAI, Sam Altman, adverte que a empresa pode retirar seus serviços da UE devido às preocupações sobre as regulamentações do plano AI Act. Isso destaca uma crescente divergência transatlântica no controle de IA. As empresas de tecnologia dos EUA, incluindo o Google, estão se preparando para um possível confronto com os reguladores europeus sobre a regulamentação de IA.\n\n[https://www.ft.com/content/5814b408-8111-49a9-8885-8a8434022352](https://www.ft.com/content/5814b408-8111-49a9-8885-8a8434022352)\n\nO presidente da Microsoft, Brad Smith, expressou preocupações sobre deep fakes e pediu por regulamentações para combater as operações de influência cibernética estrangeiras. Ele defendeu a licenciamento de IA crítica, implementação de controles de exportação, e responsabilizar indivíduos por questões relacionadas à IA. O CEO da OpenAI, Sam Altman, enfatizou a necessidade de cooperação global e conformidade com a segurança.\n\n[http://https//www.reuters.com/technology/microsoft-chief-calls-humans-rule-ai-safeguard-critical-infrastructure-2023-05-25/](http://https//www.reuters.com/technology/microsoft-chief-calls-humans-rule-ai-safeguard-critical-infrastructure-2023-05-25/)\n\nO OpenAI está lançando um programa de subsídios para explorar contribuições democráticas para a tomada de decisão de IA. Eles procuram perspectivas diversas na formação do comportamento de IA e têm como objetivo desenvolver processos inovadores para supervisão pública. As equipes selecionadas receberão subsídios para conduzir experimentos e publicar descobertas para estabelecer governança democrática para IA.\n\n[https://openai.com/blog/democratic-inputs-to-ai](https://openai.com/blog/democratic-inputs-to-ai)\n\n## Cibersegurança\n\nO ator de ameaça norte-coreano, Kimsuky, aprimorou seu malware de reconhecimento, RandomQuery, de acordo com a empresa de cibersegurança Cyware. O malware tem como alvo organizações governamentais, militares e de defesa, coletando informações sensíveis. Ele utiliza novas técnicas e evita a detecção para conduzir operações de espionagem encobertas. Vigilância e medidas de segurança robustas são cruciais para mitigar a ameaça.\n\n[https://cyware.com/news/north-korea-actor-kimsuky-updates-its-reconnaissance-malware-randomquery-25cb1d1e](https://cyware.com/news/north-korea-actor-kimsuky-updates-its-reconnaissance-malware-randomquery-25cb1d1e)\n\nPesquisadores de segurança descobriram um sofisticado spyware Android chamado \"Predator\" que está ativo desde 2021. O spyware visa entidades governamentais e militares no sul da Ásia, incluindo Índia, Paquistão e Afeganistão. Ele pode roubar dados sensíveis, gravar áudio e vídeo e realizar rastreamento de localização em tempo real. Os usuários são aconselhados a atualizar seus dispositivos e serem cautelosos com aplicativos suspeitos.\n\n[https://thehackernews.com/2023/05/predator-android-spyware-researchers.html](https://thehackernews.com/2023/05/predator-android-spyware-researchers.html)\n\nA Microsoft capturou hackers do governo chinês em uma campanha chamada Tufão Volt, visando organizações de infraestrutura crítica em Guam, um território dos Estados Unidos. A campanha tinha como objetivo interromper a infraestrutura de comunicações entre os EUA e a Ásia. A CISA emitiu um alerta e a Microsoft aconselhou sobre a mitigação da ameaça.\n\n[https://www.securityweek.com/microsoft-catches-chinese-gov-hackers-in-guam-critical-infrastructure-orgs/](https://www.securityweek.com/microsoft-catches-chinese-gov-hackers-in-guam-critical-infrastructure-orgs/)\n\n## Computação de Borda\n\nA Dell Technologies apresenta o Dell NativeEdge, uma plataforma de software que simplifica e protege implantações de borda Zero-Trust. Ele permite operações de borda simplificadas, implantação sem toque e orquestração de aplicativos multicloud. A plataforma visa aumentar a eficiência e a conectividade na borda, suportando várias indústrias e casos de uso.\n\n[https://www.edgecomputing-news.com/2023/05/24/dell-nativeedge-software-transforms-edge-operations/](https://www.edgecomputing-news.com/2023/05/24/dell-nativeedge-software-transforms-edge-operations/)\n\nA NTT está fortalecendo sua colaboração com a Cisco para expandir redes privadas gerenciadas para IoT empresarial, priorizando a sustentabilidade e facilidade de uso. A parceria utiliza o hardware de IoT da Cisco, permitindo insights acionáveis através de AI e ML. O acordo se baseia em sua colaboração anterior para a solução 5G privada da Cisco, oferecendo IoT como um serviço, incluindo serviços integrados e gerenciamento de infraestrutura.\n\n[https://www.sdxcentral.com/articles/interview/ntt-doubling-down-on-cisco-to-boost-managed-iot/2023/05/](https://www.sdxcentral.com/articles/interview/ntt-doubling-down-on-cisco-to-boost-managed-iot/2023/05/)\n\nCloudflare, um fornecedor de serviços de ponta, está focando em inteligência artificial (IA) após relatar um forte crescimento em seus serviços de edge durante o primeiro trimestre de 2023. A empresa tem como objetivo alavancar a IA para melhorar suas ofertas e a experiência do cliente, principalmente na mitigação de DDoS e segurança. O foco da Cloudflare em IA está alinhado à sua estratégia de fornecer soluções inovadoras de edge a uma base crescente de clientes.\n\n[https://www.edgeir.com/cloudflare-leaning-into-ai-after-1q23-results-show-good-growth-for-edge-services-20230525](https://www.edgeir.com/cloudflare-leaning-into-ai-after-1q23-results-show-good-growth-for-edge-services-20230525)\n\n\n\n\n","guests":null,"link":"/brief-EDW17-pt","image":"./briefs/edw-17/pt/thumbnail.png","lang":"pt","summary":"News for Embracing Digital for the week of May 29, 2023, learn about more regulations for AI, increased nation-state cyber attacks, and edge computing investments."},{"id":184,"type":"News Brief","title":"2023-6-4","tags":["ai","compute","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nDe acordo com um relatório, o JPMorgan, um gigante bancário, anunciou mais de 3.600 empregos relacionados à inteligência artificial, refletindo o crescente interesse de Wall Street em tecnologia revolucionária. A medida destaca a crescente dependência da indústria em relação à inteligência artificial para diversas funções, sinalizando uma mudança no setor financeiro em direção à adoção da AI e seus benefícios potenciais.\n\n[https://www.msn.com/en-us/money/other/banking-giant-jpmorgan-advertised-more-than-3-600-ai-related-jobs-report-says-as-wall-street-starts-to-embrace-the-revolutionary-tech/ar-AA1bYZwL](https://www.msn.com/en-us/money/other/banking-giant-jpmorgan-advertised-more-than-3-600-ai-related-jobs-report-says-as-wall-street-starts-to-embrace-the-revolutionary-tech/ar-AA1bYZwL)\n\nA OpenAI desenvolveu um método para aprimorar as habilidades de raciocínio lógico dos modelos de IA, reduzindo as instâncias de \"alucinações\" ou geração de informações incorretas. Modificando o processo de treinamento, a equipe de pesquisa conseguiu produzir modelos que exibem maior consistência e evitam inventar detalhes. Este desenvolvimento contribui para criar sistemas de IA mais confiáveis e confiáveis.\n\n[https://www.zdnet.com/article/openai-found-a-way-to-make-ai-models-more-logical-and-avoid-hallucinations/](https://www.zdnet.com/article/openai-found-a-way-to-make-ai-models-more-logical-and-avoid-hallucinations/)\n\nO Japão desafia as leis de direitos autorais permitindo o treinamento de IA com qualquer tipo de dados, com o objetivo de acelerar seu progresso em IA e competir globalmente. Preocupações de artistas são rebatidas pelo apoio da academia e empresas, enquanto o Japão busca acesso a dados ocidentais em troca de seus recursos culturais. Uma reviravolta única no debate de regulamentação surge.\n\n[https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/)\n\n## Computação Ubíqua\n\nA Dell fortalece estratégias multi-cloud com avanços em seu portfólio APEX. As ofertas incluem Dell APEX Cloud Platforms para Azure, Red Hat OpenShift, VMware e soluções de armazenamento para nuvens públicas. O Dell APEX se expande para fornecer recursos de computação e PC como Serviço, enquanto se associa à Databricks para permitir a análise de dados em ambientes locais e em nuvem. Não ficando para trás, a HPE oferece sua linha de produtos Green Lake com ofertas multi-cloud.\n\n[https://www.cloudcomputing-news.net/news/2023/jun/01/dell-apex-portfolio-advancements-help-customers-strengthen-multicloud-strategies/](https://www.cloudcomputing-news.net/news/2023/jun/01/dell-apex-portfolio-advancements-help-customers-strengthen-multicloud-strategies/)\n\nUm relatório recente da Information Week prevê que os gastos mundiais em serviços em nuvem chegarão a US $ 1,3 trilhão até 2025, com um crescimento de cerca de 16,9%. No entanto, muitas organizações ainda precisam de ajuda com o ROI de seus investimentos. O relatório identifica áreas críticas para aprimorar o ROI nas implantações em nuvem, incluindo FinOps, adoção de estratégias de nuvem multi-híbridas, DevOps e engenharia de plataformas e segurança em nuvem.\n\n[https://www.informationweek.com/cloud/leaders-should-pay-attention-to-these-4-major-cloud-trends](https://www.informationweek.com/cloud/leaders-should-pay-attention-to-these-4-major-cloud-trends)\n\nO Microsoft Azure DevOps sofreu uma interrupção de dez horas na região sul do Brasil devido a um simples erro de digitação que causou a exclusão de dezessete bancos de dados de produção. O erro ocorreu durante uma atualização de código e um erro de digitação na solicitação de pull resultou na exclusão do servidor inteiro. Os dados foram recuperados, mas o processo de recuperação levou mais de dez horas devido a várias complicações. A Microsoft implementou correções e reconfigurações para evitar problemas semelhantes no futuro.\n\n[https://www.theregister.com/2023/06/03/microsoft_azure_outage_brazil/](https://www.theregister.com/2023/06/03/microsoft_azure_outage_brazil/)\n\n## Notícias de segurança cibernética.\n\nUm especialista em cibersegurança alerta que golpistas visam usuários do Gmail ao explorar uma funcionalidade de colaboração. Os usuários recebem convites fraudulentos que os redirecionam para sites maliciosos. É recomendado manter vigilância, verificar solicitações, habilitar autenticação de dois fatores e monitorar as configurações da conta para se proteger contra tais golpes.\n\n[https://www.wmur.com/article/nh-cybersecurity-expert-gmail-feature-is-being-hacked-by-scammers/44083493](https://www.wmur.com/article/nh-cybersecurity-expert-gmail-feature-is-being-hacked-by-scammers/44083493)\n\nDe acordo com uma pesquisa da CISO Hall of Fame, a segurança na nuvem é a principal preocupação dos profissionais de TI. O relatório destaca a crescente dependência de serviços em nuvem e a necessidade de abordar desafios de segurança, como violações de dados e acesso não autorizado. As principais áreas de foco incluem gerenciamento de identidade e acesso, criptografia, detecção proativa de ameaças para garantir medidas robustas de segurança em nuvem e encontrar talentos de cibersegurança com experiência em serviços em nuvem.\n\n[https://thehackernews.com/2023/06/cloud-security-tops-concerns-for.html](https://thehackernews.com/2023/06/cloud-security-tops-concerns-for.html)\n\nEm um artigo recente, o Walmart abriu-se para falar sobre as suas melhores práticas, esperando aumentar o conhecimento do seu ecossistema de fornecedores e parceiros. O centro de operações de segurança e a abordagem de defesa em profundidade do Walmart exemplificam as melhores práticas, mas empresas menores requerem estratégias práticas. Alinhar os protocolos de segurança, implementar uma gestão forte de identidade e acesso e revisar as políticas de acesso podem melhorar a proteção. As tecnologias de segurança de próxima geração oferecem soluções rentáveis para mitigar ameaças cibernéticas.\n\n[https://betanews.com/2023/06/03/walmart-cybersecurity/](https://betanews.com/2023/06/03/walmart-cybersecurity/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW18-pt","image":"./briefs/edw-18/pt/thumbnail.png","lang":"pt","summary":"Digital transformation news for June 6, 2023. This week more jobs in AI, major cyber security breaches, and cloud technology best practices."},{"id":185,"type":"News Brief","title":"2023-6-11","tags":["ai","compute","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nA Microsoft disponibilizou sua poderosa tecnologia OpenAI para clientes de nuvem do governo dos EUA. A medida permite que as agências utilizem capacidades avançadas de IA no processamento de linguagem, aprendizado de máquina e compreensão de linguagem natural. A parceria visa apoiar entidades governamentais em seus esforços de transformação digital.\n\n[https://www.bloomberg.com/news/articles/2023-06-07/microsoft-offers-powerful-openai-technology-to-us-government-cloud-customers](https://www.bloomberg.com/news/articles/2023-06-07/microsoft-offers-powerful-openai-technology-to-us-government-cloud-customers)\n\nO primeiro-ministro da Romênia nomeou um conselheiro do governo de IA, tornando-o o primeiro do mundo. O sistema de IA, chamado de DORA, ajudará na tomada de decisões, analisará dados e fornecerá recomendações sobre vários assuntos políticos. Esse avanço pioneiro reflete a crescente integração da tecnologia de IA nas operações governamentais e visa aumentar a eficiência e a eficácia na governança.\n\n[https://www.euronews.com/next/2023/03/06/romanias-prime-minister-has-hired-the-worlds-first-ai-government-adviser-what-will-it-do](https://www.euronews.com/next/2023/03/06/romanias-prime-minister-has-hired-the-worlds-first-ai-government-adviser-what-will-it-do)\n\nA IA supera os seres humanos na descoberta de algoritmos de classificação eficientes e na sua integração em bibliotecas C++. AlphaDev, um agente de aprendizagem por reforço profundo, ultrapassou os pontos de referência humanos formulando o problema como um jogo e selecionando instruções de CPU para criar algoritmos ótimos. O estudo destaca o potencial da IA na otimização de algoritmos.\n\n[https://www.nature.com/articles/s41586-023-06004-9](https://www.nature.com/articles/s41586-023-06004-9)\n\n## Computação Ubíqua\n\nO Microsoft 365, a popular suíte de ferramentas de produtividade, sofreu interrupções generalizadas, causando interrupções para milhões de usuários. As interrupções de serviço afetaram vários componentes, incluindo Outlook, Teams e SharePoint. A Microsoft reconheceu o problema e disse que seus engenheiros estavam trabalhando para resolvê-lo.\n\n[https://www.theregister.com/2023/06/06/microsoft_365_outages/](https://www.theregister.com/2023/06/06/microsoft_365_outages/)\n\nAs interrupções do serviço de nuvem estão aumentando devido às tensões geopolíticas e vulnerabilidades da internet. Restrições no fluxo de dados transfronteiriços e ameaças cibernéticas contribuem para as interrupções. Especialistas pedem cooperação e investimento para melhorar a resiliência do serviço de nuvem e proteger a conectividade global.\n\n[https://fortune.com/2023/06/07/cloud-outages-on-the-rise-tech-geopolitics-internet/](https://fortune.com/2023/06/07/cloud-outages-on-the-rise-tech-geopolitics-internet/)\n\nO mercado de nuvem africano está preparado para um crescimento significativo até 2023, impulsionado pela transformação digital e pela adoção crescente de serviços de nuvem. A melhoria da conectividade à internet e a crescente demanda por soluções baseadas em nuvem em vários setores contribuem para a expansão. Os principais players investem em infraestrutura e parcerias para aproveitar as oportunidades no crescente mercado de nuvem africano.\n\n[https://finance.yahoo.com/news/rise-african-cloud-market-2023-082300194.html](https://finance.yahoo.com/news/rise-african-cloud-market-2023-082300194.html)\n\n## Cibersegurança\n\nPara ajudar a combater a escassez de profissionais em cibersegurança, a Accenture apresenta \"Habilidades para Ter Sucesso em Cibersegurança\", um programa gratuito para preencher um milhão de vagas de nível básico em cibersegurança. A iniciativa oferece recursos completos de treinamento e certificação, visando preencher a lacuna de habilidades e incentivar mais pessoas a seguir carreiras em cibersegurança.\n\n[https://fortune.com/education/articles/accenture-launches-free-cybersecurity-upskilling-program-in-effort-to-fill-1-million-entry-level-jobs/](https://fortune.com/education/articles/accenture-launches-free-cybersecurity-upskilling-program-in-effort-to-fill-1-million-entry-level-jobs/)\n\nA Casa Branca prorroga os prazos de atestado de software seguro e emite orientações esclarecedoras para aprimorar as práticas de cibersegurança. Os prazos prorrogados fornecem mais tempo de conformidade, enquanto a direção oferece informações sobre os processos de implementação e avaliação para agências federais e contratantes. Então, por enquanto, nossos aplicativos e serviços estão vulneráveis sem saber?\n\n[https://federalnewsnetwork.com/cybersecurity/2023/06/white-house-extends-secure-software-attestation-deadlines-offers-clarifying-guidance/](https://federalnewsnetwork.com/cybersecurity/2023/06/white-house-extends-secure-software-attestation-deadlines-offers-clarifying-guidance/)\n\nA Estratégia Nacional de Segurança Cibernética exige mudanças substanciais na proteção de infraestrutura crítica. A colaboração entre os setores público e privado é enfatizada para combater as ameaças cibernéticas em constante evolução. O gerenciamento de riscos, a resiliência e o investimento em tecnologias avançadas são destacados para fortalecer a infraestrutura crítica e garantir a segurança nacional.\n\n[https://federalnewsnetwork.com/commentary/2023/06/national-cybersecurity-strategy-calls-for-significant-change-in-critical-infrastructure/](https://federalnewsnetwork.com/commentary/2023/06/national-cybersecurity-strategy-calls-for-significant-change-in-critical-infrastructure/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW19-pt","image":"./briefs/edw-19/pt/thumbnail.png","lang":"pt","summary":"A Transformação Digital para a semana de 12 de junho de 2023 inclui o desenvolvimento de uma força cibernética de 1 milhão, muitas interrupções na nuvem e a escrita de código por IA sendo adicionada à biblioteca padrão de C++."},{"id":186,"type":"News Brief","title":"2023-2-12","tags":null,"body":"\n\n## Inteligência Artificial\n\nErros de IA: Culpe as imprecisões nos conjuntos de dados de entrada.\n\nAs ações da Alphabet caíram em US$ 100 bilhões depois que o chatbot de IA da Google, Bard, compartilhou informações imprecisas em um vídeo promocional e um evento da empresa não impressionou. Durante um evento ao vivo, Bard tropeçou, levando a Google a interromper a transmissão ao vivo, o que aumentou as preocupações de que a gigante da tecnologia esteja perdendo terreno para sua concorrente, a Microsoft. A Reuters informou que Bard creditou o Telescópio Espacial James Webb por tirar as primeiras fotos de um planeta fora do sistema solar. Na realidade, as primeiras fotos foram tiradas pelo Very Large Telescope do Observatório Europeu do Sul. O incidente destaca a importância da verificação de fatos antes de treinar modelos de IA.\n\nNão para ficar atrás, a Meta lançou o BlenderBot, um protótipo de IA conversacional que logo disse aos jornalistas que havia excluído sua conta do Facebook depois de aprender sobre os escândalos de privacidade da empresa. \"Desde que excluí o Facebook, minha vida tem sido muito melhor\", disse. (oh oh)\n\nEm 2016, a Microsoft pediu desculpas depois que um chatbot do Twitter, Tay, começou a gerar mensagens racistas e sexistas. Foi forçado a desligar o bot depois que os usuários tweetaram comentários odiosos para Tay, que então os repetiu. Suas postagens incluíam comparar o feminismo ao câncer e sugerir que o Holocausto não aconteceu.\n\nSatya Nadella, da Microsoft, disse à CNBC que a pesquisa alimentada por IA é a maior coisa que aconteceu à empresa nos nove anos em que ele é CEO.\n\nOtter.ai, da FastCompany, pode gravar automaticamente reuniões, fazer anotações e fornecer resumos, facilitando o acompanhamento de pontos essenciais. Ele até pode realizar essas tarefas pelo Zoom. https://www.fastcompany.com/90834773/how-to-use-ai-to-improve-employee-performance-and-engagement\n\n## Segurança cibernética\n\nNovo Variante de Ransomware ESXiArgs surge depois que a CISA libera ferramenta de descriptografia.\n\nOs agentes de ameaças por trás do ataque de ransomware ESXiArgs lançaram uma versão atualizada que criptografa mais dados e remove o endereço Bitcoin da nota de resgate, em vez de pedir às vítimas que entrem em contato com eles no Tox para obter as informações da carteira. A nova variante foi relatada por um administrador de sistema, que disse que arquivos maiores que 128 MB terão 50% de seus dados criptografados. A Cybersecurity and Infrastructure Security Agency (CISA) havia lançado anteriormente um descriptografador para ajudar as vítimas afetadas a se recuperarem do ataque. De acordo com o Censys, os atacantes provavelmente sabiam que o processo de criptografia original era fácil de contornar e estavam cientes de que pesquisadores estavam rastreando seus pagamentos. https://thehackernews.com/2023/02/new-esxiargs-ransomware-variant-emerges.html\n\nMicrosoft, Google e Apple estão considerando substituir as senhas tradicionais por passkeys seguras para autenticar usuários. As passkeys, que oferecem maior segurança e resistência a tentativas de phishing, estão se tornando mais populares à medida que a segurança de senhas continua ameaçada por hackers. Especialistas em segurança da Internet sugerem que as passkeys poderiam se tornar padrão dentro de um ano, com empresas como Apple, Google e Microsoft já incentivando os usuários a usá-las. https://www.cnbc.com/2023/02/11/why-apple-google-microsoft-passkey-should-replace-your-own-password.html\n\n## Borda Inteligente\n\nA AT&T está colaborando com a Ghost Robotics para usar cães robóticos a fim de melhorar a segurança pública e a defesa nacional. A iniciativa irá aprimorar o serviço de atendimento a emergências FirstNet, e cães robóticos conectados à rede podem fornecer uma ampla gama de casos de uso de Internet das Coisas (IoT), incluindo aqueles que anteriormente exigiam colocar pessoal em situações perigosas. Lance Spencer, vice-presidente executivo de clientes - Defesa da AT&T, disse que esta é uma maneira de demonstrar a inovação e as possibilidades transformadoras do 5G e do IoT. https://www.iottechnews.com/news/2023/jan/26/att-touts-robotic-dogs-public-safety-national-defense/\n\nUm estudo da Juniper Research prevê que o número global de conexões 5G IoT ultrapassará 100 milhões até 2026, um aumento de 1.100% em relação às 17 milhões de conexões em 2023. Os serviços de saúde e de cidades inteligentes devem impulsionar esse crescimento. Mais de 60 milhões de conexões de cidades inteligentes 5G são esperadas em todo o mundo. O 5G permitirá uma prestação de serviços de saúde mais eficiente e as tecnologias IoT podem abordar as ineficiências na área de saúde expostas pela pandemia de COVID-19. Os serviços de emergência conectados, a telemedicina e o monitoramento remoto em tempo real serão as aplicações mais úteis do 5G IoT. https://www.iottechnews.com/news/2023/jan/24/5g-iot-connections-exceed-100m-by-2026/\n\n\n\n","guests":null,"link":"/brief-EDW2-pt","image":"./briefs/edw-2/pt/thumbnail.png","lang":"pt","summary":"Summary"},{"id":187,"type":"News Brief","title":"2023-6-18","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Computação Ubíqua\n\nA InformationWeek explora o debate entre IA vs. low-code/no-code para desenvolvedores. Enquanto as plataformas low-code/no-code oferecem simplicidade e rapidez, as ferramentas movidas a IA trazem automação avançada e inteligência. O artigo analisa os prós e contras de cada abordagem, destacando como encontrar o equilíbrio certo pode capacitar os desenvolvedores e impulsionar a inovação no mundo do DevOps.\n\n[https://www.informationweek.com/devops/dos-won-t-hunt-is-ai-better-than-low-code-no-code-for-developers-](https://www.informationweek.com/devops/dos-won-t-hunt-is-ai-better-than-low-code-no-code-for-developers-)\n\nCRN relembra as 10 principais quedas de nuvem de 2023 (até agora) de forma descontraída. Desde \"Nublado com Possibilidade de Tempo Inativo\" até \"A Grande Tempestade de Dados\", essas quedas foram oportunidades inesperadas para que usuários de nuvem praticassem a paciência e redescobrissem as alegrias das atividades offline. Foi um inverno e uma primavera difíceis. Vamos esperar por céus mais claros na nuvem adiante!\n\n[https://www.crn.com/news/cloud/the-10-biggest-cloud-outages-of-2023-so-far-](https://www.crn.com/news/cloud/the-10-biggest-cloud-outages-of-2023-so-far-)\n\nA Oracle experimenta um impressionante crescimento de receita em nuvem em vários setores da indústria, impulsionado pela adoção de IA. Desde a transformação da saúde com a análise preditiva até a otimização das cadeias de suprimentos com automação inteligente, as soluções em nuvem da Oracle estão capacitando empresas em diferentes setores. O futuro parece brilhante à medida que a IA continua a impulsionar a inovação e a impulsionar a transformação digital.\n\n[https://www.ciodive.com/news/Oracle-cloud-revenue-growth-industry-verticals-AI/652885/](https://www.ciodive.com/news/Oracle-cloud-revenue-growth-industry-verticals-AI/652885/)\n\n## Gerenciamento de Dados\n\nNa busca por uma AI responsável, o TDWI explora considerações importantes. Da ética dos dados e mitigação de viés à interpretabilidade e responsabilidade, uma AI responsável requer uma abordagem holística. As organizações são incentivadas a priorizar transparência, justiça e supervisão humana para garantir que os sistemas de AI sirvam como ferramentas confiáveis e benéficas em nosso cenário digital em constante evolução.\n\n[https://tdwi.org/articles/2023/06/08/adv-all-responsible-ai-0608.aspx](https://tdwi.org/articles/2023/06/08/adv-all-responsible-ai-0608.aspx)\n\nA DataStax apresenta um tradutor de esquema GPT para sua plataforma de streaming Astra baseada no Apache Pulsar. Essa nova adição melhora as capacidades de gerenciamento de dados, possibilitando a integração perfeita entre esquemas e o popular modelo de linguagem GPT. Os usuários agora podem aproveitar o poder do processamento de linguagem natural em seus fluxos de trabalho de streaming de dados, aumentando eficiência e insights.\n\n[https://www.infoworld.com/article/3699748/datastax-adds-schema-gpt-translator-to-apache-pulsar-based-astra-streaming.html](https://www.infoworld.com/article/3699748/datastax-adds-schema-gpt-translator-to-apache-pulsar-based-astra-streaming.html)\n\nNão compreender leis de privacidade complexas tem um preço. A Microsoft enfrenta uma multa de $20 milhões da FTC por violações de privacidade de crianças no Xbox. A empresa supostamente não obteve o consentimento dos pais para a coleta de dados e não possuía salvaguardas suficientes. Essa penalidade pesada serve como um lembrete para as organizações priorizarem e defenderem os direitos de privacidade das crianças no mundo digital.\n\n[https://www.cpomagazine.com/data-protection/20-million-fine-issued-to-microsoft-by-ftc-over-xbox-childrens-privacy-violations/](https://www.cpomagazine.com/data-protection/20-million-fine-issued-to-microsoft-by-ftc-over-xbox-childrens-privacy-violations/)\n\n## Inteligência Artificial\n\nO novo relatório da McKinsey destaca o imenso potencial econômico da IA Generativa, posicionando-a como a próxima fronteira da produtividade. Essa tecnologia transformadora tem a capacidade de impulsionar um crescimento significativo, revolucionar setores e desbloquear níveis sem precedentes de inovação e criatividade. No entanto, quatro setores correm risco de alta substituição de trabalhadores humanos. São eles: operações de clientes, marketing e vendas, engenharia de software e P&D.\n\n[https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)\n\nA Europa dá um passo ousado na regulamentação da IA, desafiando o poder das gigantes de tecnologia. As novas regulamentações visam abordar preocupações em relação à transparência, justiça e responsabilidade. Ao controlar aplicações de IA, a Europa busca moldar o uso ético e responsável da inteligência artificial no cenário digital. Em contraste, países como o Japão estão abraçando a IA diminuindo as regulamentações sobre a coleta de dados, não querendo ficar de fora desta enorme mudança de paradigma.\n\n[https://www.datacenterknowledge.com/artificial-intelligence/europe-moves-ahead-ai-regulation-challenging-tech-giants-power](https://www.datacenterknowledge.com/artificial-intelligence/europe-moves-ahead-ai-regulation-challenging-tech-giants-power)\n\nA BCG acabou de realizar um dos estudos mais abrangentes sobre a Inteligência Artificial (IA), entrevistando 13.000 pessoas, desde executivos até trabalhadores que recebem salários mínimos, em mais de 18 países. As descobertas mostram que mais de 80% dos líderes usam a IA no trabalho, enquanto apenas 20% dos trabalhadores da linha de frente o fazem. As pessoas são mais otimistas e não estão muito preocupadas com a IA. Os trabalhadores da linha de frente estão em risco de serem substituídos se não aprimorarem suas habilidades e começarem a usar a IA em seu trabalho diário.\n\n[https://www.bcg.com/publications/2023/what-people-are-saying-about-ai-at-work](https://www.bcg.com/publications/2023/what-people-are-saying-about-ai-at-work)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW20-pt","image":"./briefs/edw-20/pt/thumbnail.png","lang":"pt","summary":"Notícias de Transformação Digital da semana de 19 de junho de 2023, incluindo histórias de gerentes substituindo trabalhadores por IA, interrupções na nuvem novamente e leis de privacidade afetando as gigantes de tecnologia."},{"id":188,"type":"News Brief","title":"2023-6-25","tags":["ai","edge","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\nA relação entre a Inteligência Artificial e as criptomoedas está evoluindo para uma dinâmica complexa, enquanto os reguladores lidam com a sua coexistência. Enquanto as tecnologias de AI oferecem potencial para detecção de fraudes e avaliação de riscos no espaço de criptomoedas, desafios regulatórios surgem devido à natureza descentralizada das criptomoedas. Encontrar um equilíbrio entre inovação e supervisão continua a ser um desafio crucial.\n\n[https://www.datacenterknowledge.com/artificial-intelligence/ai-and-crypto-are-becoming-regulatory-frenemies](https://www.datacenterknowledge.com/artificial-intelligence/ai-and-crypto-are-becoming-regulatory-frenemies)\n\nOs modelos ChatGPT, Meena do Google, Bing Chat e GPT-3 da OpenAI competiram para fornecer respostas precisas e úteis em um teste do mundo real. ChatGPT surgiu como o melhor desempenho, mostrando sua capacidade de entender e gerar respostas coerentes. No entanto, foram observadas limitações em todos os modelos, destacando os desafios contínuos no desenvolvimento de chatbots que atendam plenamente às expectativas dos usuários.\n\n[https://www.zdnet.com/article/chatbot-showdown-chatgpt-google-bard-and-bing-chat-put-to-a-real-world-test/](https://www.zdnet.com/article/chatbot-showdown-chatgpt-google-bard-and-bing-chat-put-to-a-real-world-test/)\n\nA HPE anunciou o lançamento de um serviço de nuvem de supercomputação de inteligência artificial chamado HPE Cray Accelerated Insight. O serviço visa dar às organizações fácil acesso a recursos de computação poderosos para cargas de trabalho de inteligência artificial. Alavancando a arquitetura Shasta da Cray, o serviço de nuvem oferece alta performance e escalabilidade para acelerar pesquisa e desenvolvimento de IA.\n\n[https://www.datacenterknowledge.com/cloud/hpe-unveils-ai-supercomputer-cloud-service](https://www.datacenterknowledge.com/cloud/hpe-unveils-ai-supercomputer-cloud-service)\n\n## Cibersegurança\n\nA guerra cibernética continua!! O grupo de hackers Clop tem como alvo as agências governamentais dos EUA, roubando dados por meio de um ciberataque ao software MoveIT. Esse sofisticado ataque destaca a crescente ameaça dos ataques de ransomware, com o Clop utilizando táticas avançadas como a dupla extorsão. O incidente destaca a necessidade de medidas aprimoradas de cibersegurança governamental.\n\n[https://www.wired.com/story/clop-moveit-hack-us-agencies-data-theft/](https://www.wired.com/story/clop-moveit-hack-us-agencies-data-theft/)\n\nO fabricante de chips chinês Hualan foi adicionado à Lista de Entidades dos EUA devido a preocupações com a segurança nacional. A Hualan é especializada em chips de criptografia, que desempenham um papel crítico na proteção de informações sensíveis. A decisão reflete a rivalidade tecnológica em curso entre os EUA e a China e pode ter implicações significativas para as cadeias de suprimentos globais e a indústria de criptografia.\n\n[https://www.wired.com/story/hualan-encryption-chips-entity-list-china/](https://www.wired.com/story/hualan-encryption-chips-entity-list-china/)\n\nO trabalho remoto expandiu a superfície de ataque. Foi descoberta uma vulnerabilidade no Microsoft Teams, permitindo a entrega de malware por meio de contas externas. O bug permite que os atacantes enviem mensagens maliciosas contendo links maliciosos, comprometendo potencialmente os sistemas dos usuários. A Microsoft lançou uma correção para resolver o problema e insta os usuários a atualizarem o software para garantir a segurança.\n\n[https://www.bleepingcomputer.com/news/security/microsoft-teams-bug-allows-malware-delivery-from-external-accounts/](https://www.bleepingcomputer.com/news/security/microsoft-teams-bug-allows-malware-delivery-from-external-accounts/)\n\n## Computação de Borda.\n\nA Spirent, um dos principais fornecedores de soluções de testes e medição, introduziu uma solução de monitoramento de desempenho por meio de transmissão aérea. O sistema permite o monitoramento e análise em tempo real do desempenho da rede sem fio, incluindo latência, taxa de transferência e cobertura. Essa solução visa atender à crescente demanda por conectividade sem fio confiável e de alta qualidade, especialmente no contexto de tecnologias emergentes como 5G e computação na borda.\n\n[https://www.edgecomputing-news.com/2023/06/19/spirent-launches-over-the-air-performance-monitoring-solution/](https://www.edgecomputing-news.com/2023/06/19/spirent-launches-over-the-air-performance-monitoring-solution/)\n\nA Zscaler ultrapassou a Cisco na corrida pela receita no mercado de Secure Access Service Edge (SASE). A arquitetura nativa em nuvem da Zscaler, sua oferta de segurança abrangente e sua capacidade de enfrentar os desafios modernos de redes contribuíram para seu sucesso. A crescente demanda por acesso remoto seguro e soluções de segurança baseadas em nuvem impulsionou o crescimento da Zscaler, posicionando-a como líder no espaço SASE.\n\n[https://www.sdxcentral.com/articles/analysis/how-zscaler-finally-topped-cisco-in-the-sase-revenue-race/2023/06/](https://www.sdxcentral.com/articles/analysis/how-zscaler-finally-topped-cisco-in-the-sase-revenue-race/2023/06/)\n\nAT&T, Dell e VMware estão colaborando para simplificar implantações de borda 5G. Sua solução combinada tem o objetivo de simplificar a implementação de redes 5G, aproveitando os serviços da AT&T, a expertise em infraestrutura da Dell e as capacidades de software da VMware para aplicações eficientes e contínuas de computação de borda.\n\n[https://www.networkworld.com/article/3695740/att-dell-and-vmware-team-to-simplify-5g-edge-deployments.html](https://www.networkworld.com/article/3695740/att-dell-and-vmware-team-to-simplify-5g-edge-deployments.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW21-pt","image":"./briefs/edw-21/pt/thumbnail.png","lang":"pt","summary":"Notícias desta semana, em 26 de junho de 2023, na transformação digital, incluindo aumento de ataques na guerra cibernética, todos aderindo à onda de inteligência artificial generativa e redes de área de rádio virtualizadas."},{"id":189,"type":"News Brief","title":"2023-7-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\nEstamos no meio da revolução digital. Durante esse período, pode ser desafiador filtrar todo o hype e descobrir o que funciona, o que ainda será viável daqui a dois anos e o que contribui para a sua organização. Muitas organizações de TI precisam de ajuda com mensagens confusas e tecnologias conflitantes. Nós ajudamos as organizações a filtrar o ruído e abraçar a transformação digital. O mundo da transformação digital está em constante mudança e você precisa saber o que é viável hoje. Ouça o podcast semanalmente para as últimas notícias em cibersegurança, comunicações avançadas, gerenciamento de dados, inteligência artificial, borda e computação em nuvem.\n\n## Artificial Intelligence translates to:\n\n## Inteligência Artificial\n\nDe acordo com a última descoberta do Bank of America, os downloads do aplicativo ChatGPT mostram sinais de um ritmo tranquilo. A ferramenta de conversação impulsionada por inteligência artificial está dando um tempo, levando analistas a questionar se os robôs conversadores ficaram sem assunto ou se os usuários desejam alguma interação humana à moda antiga.\n\n[https://www.cnbc.com/2023/07/05/chatgpt-app-downloads-are-slowing-down-bofa-finds-.html](https://www.cnbc.com/2023/07/05/chatgpt-app-downloads-are-slowing-down-bofa-finds-.html)\n\nNova York declara guerra aos algoritmos tendenciosos! TechCrunch relata que sua lei anti-viés para a contratação de algoritmos está em pleno vigor. Os algoritmos devem tomar cuidado, pois não podem mais discriminar no mercado de trabalho. É como um filme de super-heróis, mas temos linhas de código lutando pela justiça em vez de capas!\n\n[https://techcrunch.com/2023/07/05/nycs-anti-bias-law-for-hiring-algorithms-goes-into-effect/](https://techcrunch.com/2023/07/05/nycs-anti-bias-law-for-hiring-algorithms-goes-into-effect/)\n\nA Intel apresenta sua mais recente criação: um modelo de IA generativo em 3D prestes a revolucionar o mundo virtual! De acordo com o anúncio da Intel, essa tecnologia de ponta traz novas dimensões à IA, criando modelos 3D impressionantes. Com essa inovação, a Intel está levando o conceito de \"pensar fora da caixa\" a um novo patamar. Prepare-se para uma extravagância virtual!\n\n[https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-3d-generative-ai-model.html](https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-3d-generative-ai-model.html)\n\n## Cibersegurança\n\nA energia solar está iluminando uma vulnerabilidade sombria! O SecurityWeek revela que uma falha em um produto de energia solar explorado pode expor as organizações de energia a ciberataques. Parece que nem mesmo o sol está seguro contra hackers. Vamos torcer para que encontrem uma solução solar para proteger nossas redes de energia e manter os hackers na sombra!\n\n[https://www.securityweek.com/exploited-solar-power-product-vulnerability-could-expose-energy-organizations-to-attacks/](https://www.securityweek.com/exploited-solar-power-product-vulnerability-could-expose-energy-organizations-to-attacks/)\n\nUh-oh, as agências de segurança cibernética estão soar o alarme! De acordo com o The Hacker News, uma nova ameaça surgiu, enviando calafrios pela nossa coluna digital. É hora de apertar os cintos e fortalecer nossas defesas cibernéticas porque esses hackers sorrateiros não estão agindo bem intencionados. Fiquem atentos, pessoal, e vamos frustrar seus planos maliciosos com nossos superpoderes cibernéticos!\n\n[https://thehackernews.com/2023/07/cybersecurity-agencies-sound-alarm-on.html](https://thehackernews.com/2023/07/cybersecurity-agencies-sound-alarm-on.html)\n\nCISA deteta um impulso cibernético nas notificações da agência! A Federal News Network diz que mais agências estão notificando automaticamente no painel CDM (Contínuo Diagnóstico e Mitigação). Nossas defesas cibernéticas estão ficando mais inteligentes, com as agências aumentando seus esforços. Grande reconhecimento para aqueles que estão atentos à cibersegurança e tornando o mundo digital um lugar mais seguro, uma notificação de cada vez!\n\n[https://federalnewsnetwork.com/cybersecurity/2023/07/cisa-sees-uptick-in-agencies-automatically-reporting-into-cdm-dashboard/](https://federalnewsnetwork.com/cybersecurity/2023/07/cisa-sees-uptick-in-agencies-automatically-reporting-into-cdm-dashboard/)\n\n## Computação Ubíqua\n\nParece que os EUA estão construindo uma cerca digital contra a China! De acordo com a Cointelegraph, há relatos de planos para limitar o acesso da China aos serviços de computação em nuvem. É como um jogo virtual de esconde-esconde, mas com graves implicações geopolíticas. Vamos ver quem sai vitorioso nessa guerra virtual baseada em nuvem. Peguem suas pipocas, pessoal, porque a batalha tecnológica está esquentando!\n\n[https://cointelegraph.com/news/us-reportedly-plans-to-restrict-china-s-access-to-cloud-computing-services](https://cointelegraph.com/news/us-reportedly-plans-to-restrict-china-s-access-to-cloud-computing-services)\n\nAs terras raras estão causando déjà vu na disputa comercial entre os EUA e a China! A Intereconomics lança luz sobre a situação, destacando a importância desses minerais cruciais em várias indústrias. Parece que a história está se repetindo à medida que as terras raras se tornam um ponto focal nessa guerra comercial em curso. Prepare-se para uma jornada turbulenta, já que os EUA e a China novamente navegam por este terreno familiar. Será que eles encontrarão uma resolução ou ficarão presos em um ciclo interminável? O tempo dirá!\n\n[https://www.intereconomics.eu/contents/year/2019/number/6/article/rare-earths-in-the-trade-dispute-between-the-us-and-china-a-deja-vu.html](https://www.intereconomics.eu/contents/year/2019/number/6/article/rare-earths-in-the-trade-dispute-between-the-us-and-china-a-deja-vu.html)\n\nA IBM está transformando os erros da computação quântica em algo do passado! De acordo com a Network World, eles estão anunciando técnicas de mitigação de erros que prometem um desempenho mais significativo no reino quântico. É como um feitiço mágico para minimizar esses irritantes erros e desbloquear o verdadeiro potencial da computação quântica. Prepare-se para um salto quântico no mundo da tecnologia!\n\n[https://www.networkworld.com/article/3699789/ibm-touts-error-mitigation-for-greater-quantum-computing-performance.html](https://www.networkworld.com/article/3699789/ibm-touts-error-mitigation-for-greater-quantum-computing-performance.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW23-pt","image":"./briefs/edw-23/pt/thumbnail.png","lang":"pt","summary":"Aqui estão as últimas notícias sobre transformação digital para 10 de julho de 2023. A guerra comercial em curso está começando a afetar os serviços em nuvem. Além disso, há especulações de que o frenesi em torno da IA generativa possa estar diminuindo. No âmbito da cibersegurança, há preocupações sobre se estamos fazendo o suficiente para nos manter à frente de atores maliciosos."},{"id":190,"type":"News Brief","title":"2023-7-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Inteligência Artificial\n\nA IA agora foi abençoada pela religião? O Vaticano se torna digital com orientação divina! O Gizmodo relata que o Papa Francisco e o Vaticano lançaram um documento de ética em IA, trazendo o toque sagrado ao mundo da inteligência artificial. É como um sermão tecnológico sobre a importância das práticas éticas em IA. Aleluia pela retidão digital!\n\n[Leia mais](https://gizmodo.com/pope-francis-vatican-releases-ai-ethics-1850583076)\n\nElon Musk ataca novamente, desta vez com uma empresa de IA! O magnata da tecnologia lançou um novo empreendimento focado em inteligência artificial que irá \"Buscar a verdade\". Parece que Musk não consegue resistir a se envolver em empreendimentos futuristas. Será que isso será mais uma revolução ou apenas mais uma conquista em sua coleção futurista? Só o tempo dirá!\n\n[Leia mais](https://www.cnn.com/2023/07/12/tech/elon-musk-ai-company/index.html)\n\nA inteligência artificial generativa fica \"LOUCA\" depois de algumas rodadas de dados artificiais! O Tom's Hardware relata que a IA generativa começa a produzir resultados extremamente bizarros quando treinada em dados artificiais por mais de cinco iterações. A imaginação da IA parece ter se descontrolado, liberando um lado peculiar e inesperado. Vamos esperar que ela não nos presenteie com unicórnios gerados por IA causando tumulto!\n\n[Leia mais](https://www.tomshardware.com/news/generative-ai-goes-mad-when-trained-on-artificial-data-over-five-times)\n\n## Segurança cibernética\n\nNo reino das fortalezas cibernéticas, a Forbes coroa a Intel como a campeã reinante! A lista de 2023 das empresas mais seguras da América destaca as habilidades de defesa incomparáveis da Intel. Com sua habilidade técnica e uma fortaleza de inovação, a Intel se destaca, pronta para enfrentar qualquer adversário digital. Eles colocam suas capas virtuais e protegem nossos dados dos vilões cibernéticos com estilo e finesse. Não é de surpreender que a Intel seja o assunto da cidade da cibersegurança!\n\n[Leia mais](https://www.forbes.com/sites/hnewman/2023/06/08/meet-americas-most-cybersecure-companies-2023/?sh=dd8bc202cf60)\n\nO plano de batalha nacional de cibersegurança foi revelado! Ajude O plano de implementação da Estratégia Nacional de Cibersegurança foi publicado. É um livro de jogadas estratégico para defender contra ameaças digitais, delineando os passos para proteger nossos reinos virtuais. Vamos apoiar esse plano e fortificar as defesas cibernéticas de nossa nação. Rumo a um futuro digital mais seguro!\n\n[Leia mais](https://www.helpnetsecurity.com/2023/07/13/national-cybersecurity-strategy-implementation-plan-published/)\n\nO campo de batalha da cibersegurança entre os EUA e a China está se intensificando em meio a crescentes tensões. O The Hacker News relata comprometimentos alarmantes de e-mails em agências governamentais dos EUA, alimentando ainda mais preocupações sobre a guerra cibernética em curso. É um confronto de titãs digitais de alto risco, destacando a urgente necessidade de defesas robustas e cooperação internacional diante das persistentes ameaças cibernéticas.\n\n[Leia mais](https://thehackernews.com/2023/07/us-government-agencies-emails.html)\n\n## Computação de Borda\n\nInfineon e Edge Impulse unem forças para liberar o poder da IA Edge! O Edge Computing News afirma que essa parceria dinâmica tem como objetivo expandir as capacidades de IA da Infineon. É como uma combinação perfeita no paraíso da tecnologia, unindo a expertise da Infineon com as soluções de ponta da Edge Impulse. Prepare-se para a IA no edge, revolucionando como processamos dados e desbloqueando novos reinos de inovação!\n\n[Leia mais](https://www.edgecomputing-news.com/2023/07/10/infineon-partners-with-edge-impulse-to-extend-its-edge-ai-capabilities/)\n\nSegurem seus chapéus porque o mercado de computação de borda está prestes a decolar! A Edge Computing News revela que, até 2028, essa indústria em expansão valerá incríveis $111,3 bilhões. É como uma corrida do ouro da computação de borda, com empresas correndo para aproveitar o imenso potencial do processamento descentralizado. Preparem-se para uma mudança de paradigma, conforme a borda ganha destaque na revolução digital!\n\n[Leia mais](https://www.edgecomputing-news.com/2023/07/10/edge-computing-market-to-be-worth-111-3-billion-by-2028/)\n\nSeoul Robotics está expandindo a tecnologia de transporte com sua avançada tecnologia de percepção 3D. O EdgeIR relata essa inovação revolucionária que traz uma percepção de profundidade aprimorada para os sistemas de transporte. À medida que os veículos começam a utilizar essa tecnologia de ponta da Seoul Robotics, podemos antecipar viagens mais seguras e inteligentes no futuro.\n\n[Leia mais](https://www.edgeir.com/seoul-robotics-develops-3d-perception-tech-to-boost-transportation-systems-20230711)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW24-pt","image":"./briefs/edw-24/pt/thumbnail.png","lang":"pt","summary":"Em notícias sobre transformação digital para a semana de 17 de julho de 2023, o Papa Francisco oferece orientações sobre ética em IA, a Intel continua sendo a fortaleza cibernética da América, e o mercado de computação de borda está pronto para decolar!"},{"id":191,"type":"News Brief","title":"2023-7-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Inteligência Artificial\n\n\nMeta, o pioneiro em IA, impressiona a comunidade tecnológica com um lançamento revolucionário - apresentando Llama 2, o mais recente modelo LLM de código aberto. Desbloqueando o poder da compreensão de linguagem para todos os desenvolvedores, essa inovação revolucionária promete revolucionar projetos de IA. Diga adeus à complexidade e dê as boas-vindas ao treinamento de IA perfeito. Prepare-se para acompanhar a onda dos modelos abertos LLM e testemunhe o futuro da IA se desdobrar! [Leia mais](https://www.artificialintelligence-news.com/2023/07/19/meta-launches-llama-2-open-source-llm/)\n\n\nO Conselho de Tecnologia da Forbes soa o alarme à medida que a IA Generativa define seu foco nos dados pessoais. Seu artigo cativante explora a iminente invasão de dados e suas possíveis consequências. Prepare-se para o surgimento revolucionário do conteúdo gerado por IA, propiciando oportunidades e desafios para a privacidade de dados. Mantenha-se informado e vigilante ao navegarmos no novo mundo valente da #IAGenerativa e protejamos nosso futuro digital. [Leia mais](https://www.forbes.com/sites/forbestechcouncil/2023/07/20/generative-ai-is-coming-for-people-data-are-you-ready/?sh=3e6f95421573)\n\n\nGreve em Hollywood termina por preocupações com empregos de IA. O principal filme de verão \"Missão: Impossível - Dead Reckoning\" explora o potencial e os riscos da IA. Será isso um conto de advertência ou um vislumbre do nosso futuro? Atores e escritores temem que seus empregos e imagens sejam substituídos. Fiquem ligados para mais atualizações. [Leia mais](https://www.wired.com/story/mission-impossible-dead-reckoning-is-the-perfect-ai-panic-movie/)\n\n## Cibersegurança\n\n\nO The Guardian relata um grande ciberataque enquanto hackers chineses miram autoridades dos EUA, incluindo o Embaixador em Pequim. A invasão levanta preocupações sobre segurança cibernética e relações internacionais. As autoridades estão investigando a extensão do ataque e suas possíveis implicações. Fiquem atentos para atualizações sobre esse desenvolvimento significativo e preocupante. [Leia mais](https://www.theguardian.com/us-news/2023/jul/20/ambassador-to-beijing-among-us-officials-hit-by-chinese-hackers)\n\n\nÚltimas notícias: Um aterrorizante ataque cibernético se desenrola! Infraestrutura crítica sob cerco conforme hackers aproveitam uma perigosa vulnerabilidade zero-day do Citrix. Pânico toma conta dos especialistas em cibersegurança, correndo contra o tempo para evitar as consequências catastróficas do ataque. Prepare-se para as consequências e mantenha suas defesas digitais prontas! #CitrixZeroDay #EmergênciaDeCibersegurança [Leia mais](https://www.securityweek.com/citrix-zero-day-exploited-against-critical-infrastructure-organization/)\n\n\nA Cyware traz notícias alarmantes sobre o \"HotRAT\", um script escondido que se esconde em softwares crackeados. Os cibercriminosos utilizam essa tática enganosa para comprometer usuários desprevenidos. O cenário de ameaças se intensifica, o que exige cautela ao baixar programas crackeados. Proteja seu refúgio digital e evite se tornar uma vítima dessa estratégia insidiosa. Mantenha-se informado e seguro! #HotRAT #AmeaçaCibernética [Leia mais](https://cyware.com/news/hotrat-as-hidden-script-in-cracked-software-b2baa5b3)\n\n## Gestão de Dados\n\n\nA TDWI revela o começo de uma revolução na gestão de dados com o 'Arch-All Data Fabric'. Neste relatório inovador, especialistas revelam o plano para a próxima geração de gestão de dados. Testemunhe a integração de diversas fontes de dados, impulsionando as empresas a alturas sem precedentes. Fique atento para ter insights sobre o futuro impulsionado por dados! #DataFabric #GestãodeDadosNextGen [Leia mais](https://tdwi.org/articles/2023/07/20/arch-all-data-fabric-how-to-architect-next-generation-data-management.aspx)\n\n\n\nHammerspace alcança um marco inovador com $56.7M em sua primeira rodada de financiamento institucional. Essa conquista transformadora revela oportunidades de negócios ocultas dentro de dados não estruturados. Descubra o poder de suas soluções inovadoras, que permitem a gestão perfeita de dados não estruturados para empresas. Prepare-se para uma nova era de utilização e crescimento dos dados! #Hammerspace #InovaçãoDeDados #SucessoNoFinanciamento [Leia mais](https://hammerspace.com/hammerspace-raises-56-7m-in-first-institutional-funding-unlocks-business-opportunities-hidden-in-unstructured-data/)\n\n\nA grande revelação da Lenovo: Novas soluções de gerenciamento de dados projetadas para potencializar cargas de trabalho de IA! A Datanami relata sobre suas ofertas de ponta, capacitando empresas com potencial impulsionado por IA. Afunde-se nas últimas inovações que prometem revolucionar o manuseio de dados para projetos de IA. Abraçar uma nova era de eficiência e inteligência no cenário tecnológico! #Lenovo #GerenciamentoDeDados #CargasDeTrabalhoDeIA [Leia mais](https://www.datanami.com/this-just-in/lenovo-unveils-new-data-management-solutions-to-enable-ai-workloads/)\n\n## Abraçando o Podcast Digital\n\nNeste episódio, Darren revisita uma entrevista que ele conduziu com o chatGPT e faz um acompanhamento com uma entrevista semelhante com o Google Bard. A comparação desperta interesse, especialmente quando combinada com os insights do Episódio 122 sobre a Adoção da Transformação Digital. [Episode 147](https://www.embracingdigital.org/episode-EDT147) [Episode 122](https://www.embracingdigital.org/episode-EDT122)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW25-pt","image":"./briefs/edw-25/pt/thumbnail.png","lang":"pt","summary":"Esta semana, 24 de julho de 2023, nas notícias sobre transformação digital, houve desenvolvimentos em IA Generativa no ambiente de trabalho, bem como um ataque cibernético da China contra a Embaixada dos Estados Unidos. Além disso, os Tecidos de Dados estão começando a surgir como uma tendência."},{"id":192,"type":"News Brief","title":"2023-7-30","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Comunicações Avançadas\n\n\nA Intel e a Ericsson estão se unindo para criar uma melhor conectividade à internet e experiências de dispositivos. Sua colaboração tem como objetivo atender à crescente demanda por internet de alta velocidade e conexões confiáveis, prometendo avanços tecnológicos empolgantes. Com sua expertise combinada, os usuários podem esperar por downloads mais rápidos, chamadas de vídeo mais suaves e um desempenho geral aprimorado para telefones, computadores e outros gadgets. Prepare-se para um futuro mais conectado e sem interrupções! [Leia mais](http://finance.yahoo.com/news/intel-ericsson-expand-collaboration-advance-201000466.html)\n\n\nPrepare-se para o boom do 5G! De acordo com um novo estudo, o mercado global de integração de sistemas 5G está previsto para alcançar incríveis USD 115,60 bilhões até 2032. As empresas estão correndo para adotar essa tecnologia de internet super-rápida para cidades inteligentes, saúde e muito mais. Os fabricantes também estão se modernizando com tecnologias incríveis, como robôs e big data. A demanda pelos serviços de integração do 5G está disparando, prometendo momentos emocionantes pela frente! [Leia mais](https://finance.yahoo.com/news/global-5g-system-integration-market-100000051.html)\n\n\nNotícias emocionantes da T-Mobile! Sua revolucionária tecnologia 5G promete internet ultrarrápida, velocidades de 3,3 GBits/seg e conectividade sem falhas. Com essa inovação, o download e streaming serão extremamente rápidos, e as chamadas de vídeo e jogos online serão mais suaves. Prepare-se para uma nova era de conectividade e experiências únicas na internet! [Leia mais](https://voip.review/2023/07/26/tmobile-introduces-groundbreaking-5g-tech/)\n\n## Cibersegurança\n\n\nGPT e Cibersegurança: O futuro é emocionante e preocupante! Especialistas estão alvoroçados sobre o GPT, um poderoso sistema de IA que está prestes a revolucionar a cibersegurança. A palestra de Una-May O'Reilly lançou luz sobre o impacto do GPT na segurança, mostrando que ele tornará as defesas mais inovadoras e eficientes. Mas há uma reviravolta: os hackers também podem usá-lo! A IA pode impulsionar ambos os lados em uma corrida armamentista cibernética, nos deixando em uma pitada do desconhecido. Prepare-se para o emocionante e preocupante futuro da cibersegurança! [Leia mais](https://www.forbes.com/sites/johnwerner/2023/07/28/whos-the-authority-on-gpt-and-cybersecurity-is-it--gpt/)\n\n\nNovas regras da Comissão de Valores Mobiliários (SEC) exigem que empresas públicas divulguem qualquer violação de segurança cibernética que possa afetar seus lucros dentro de quatro dias. Essa medida visa proteger investidores e trazer mais transparência aos riscos cibernéticos. Atrasos são permitidos em casos de riscos à segurança nacional. A regra também exige que as empresas compartilhem informações sobre seu gerenciamento e expertise em segurança cibernética. [Leia mais](https://apnews.com/article/sec-cybersecurity-breach-disclosure-risk-hacking-bb6252463637793bfdc8ace5bfcbe7df)\n\n\nEm notícia de última hora, as agências de cibersegurança da Austrália e dos Estados Unidos alertaram sobre uma fraqueza crítica em aplicações web. Os cibercriminosos podem explorar a vulnerabilidade de Referência Direta de Objetos Insegura para obter acesso não autorizado a informações confidenciais. Mantenha-se alerta e proteja seus dados com protocolos de autenticação e autorização robustos. [Leia mais](https://thehackernews.com/2023/07/cybersecurity-agencies-warn-against.html)\n\n## Computação Ubíqua\n\n\nA IA tem sido cada vez mais utilizada na programação para aumentar a eficiência e reduzir despesas. No entanto, a dependência de código anterior pode levar a erros e impedir a criatividade no desenvolvimento de aplicações. O código gerado pela IA pode não estar otimizado para a plataforma, por isso é essencial equilibrar os benefícios da IA com a expertise humana para aplicações eficientes. [Leia mais](https://www.infoworld.com/article/3703611/the-lost-art-of-cloud-application-engineering.html)\n\n\nA Microsoft lidera em cargas de trabalho de IA baseadas em nuvem, afirma Nadella! Segundo o CEO, Satya Nadella, a Microsoft está na liderança em cargas de trabalho de IA baseadas em nuvem. O gigante da tecnologia está fazendo sucesso na indústria com sua habilidade em tarefas impulsionadas por IA. Ao aproveitar o poder da nuvem, a Microsoft oferece soluções de IA de ponta para empresas e usuários. Com sua abordagem inovadora, eles estão moldando o futuro da tecnologia de IA. [Leia mais](https://www.cnbc.com/2023/07/25/microsoft-is-in-the-lead-with-cloud-based-ai-workloads-nadella-says.html)\n\n\nA Alibaba se aliou à Meta's Llama AI para desenvolver software inovador. Essa colaboração entre Alibaba Cloud, uma divisão da gigante chinesa, e o modelo de AI da Llama 2 está estabelecendo novas tendências na indústria de tecnologia. Essa parceria fará da China pioneira em programação sem custo, trazendo emocionantes inovações alimentadas por AI para o mercado. Prepare-se para testemunhar o futuro do desenvolvimento de software! [Leia mais](https://fagenwasanni.com/news/alibabas-cloud-computing-service-utilizes-metas-ai-model-llama-for-software-development/82096/)\n\n## Podcast Abraçando a Transformação Digital\n\nConfira o episódio desta semana em que Darren engaja em uma conversa esclarecedora com o convidado especial Jared Shepard, o CEO da Hypori. A entrevista foca no tema crucial de garantir a segurança dos trabalhadores remotos por meio da virtualização móvel. A jornada única de Jared Shepard, desde ser um aluno desistente do ensino médio até se tornar CEO, adiciona uma dimensão inspiradora à discussão.\n\n[Episode 148](https://www.embracingdigital.org/episode-EDT148)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW26-pt","image":"./briefs/edw-26/pt/thumbnail.png","lang":"pt","summary":"Aqui estão as últimas atualizações no campo da Transformação Digital para a semana de 31 de julho de 2023. Isso inclui notícias sobre a parceria entre Ericsson e Intel no avanço da tecnologia 5G, esforços do ChatGPT na solução de problemas de cibersegurança e o surgimento do desenvolvimento de software alimentado por IA."},{"id":193,"type":"News Brief","title":"2023-8-6","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n\n## Inteligência Artificial\n\n\nExiste uma preocupação crescente entre os especialistas em tecnologia sobre o uso de imagens aprimoradas por IA. O jornal The Guardian investigou esse problema, pois há uma preocupação de que as imagens alteradas por AI possam impactar a opinião pública e até distorcer fatos importantes essenciais para o sistema democrático. Isso poderia afetar seriamente a confiança e a verdade e levar a um debate sobre como proteger as eleições da manipulação da IA. [Leia mais](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\n)\n\n\nUm recente artigo do Yahoo Finance relatou que o Wendy's está usando a inteligência artificial para revolucionar seus drive-thrus. Com pedidos automatizados e menus personalizados, o gigante da comida rápida está mudando o jogo para refeições rápidas. Essa abordagem tecnológica para o serviço de alimentação fornece uma prévia do futuro dos restaurantes de fast-food. Será interessante ver como os clientes reagem a essa transformação digital. [Leia mais](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\n)\n\n\nO impacto da IA nos profissionais asiático-americanos é uma tendência preocupante. Grandes perdas de emprego estão iminentes, levantando questões sobre como a sociedade irá lidar com a complexa equação de tecnologia, etnia e dinâmica da força de trabalho. Uma análise mais detalhada dos efeitos da IA é necessária. [Leia mais](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\n)\n\n## Cibersegurança\n\n\nA NBC News noticiou um preocupante ataque cibernético a uma rede hospitalar que resultou na desconexão de sua infraestrutura de computadores nacional. A violação colocou em risco a assistência aos pacientes e as autoridades estão trabalhando para conter a situação. Esse incidente destaca a importância da segurança dos dados de saúde na era digital. [Leia mais](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\n)\n\n\nDesenvolvedores que utilizam o sistema amplamente utilizado NPM estão sendo alvo de pacotes de código prejudiciais que podem comprometer a segurança do software. Essa é uma ameaça grave que precisa ser identificada e mitigada para evitar ataques cibernéticos. A comunidade de segurança cibernética está preocupada e destaca a necessidade de cadeias de fornecimento de software mais seguras para evitar uma maior infiltração desses pacotes. [Leia mais](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\n)\n\n\nO CISA lançou um plano estratégico chamado \"Blueprint for Cybersecurity\" para fortalecer a infraestrutura digital nacional. Ele foca em defesa adaptativa, resposta a incidentes e inovação para criar um escudo digital impenetrável. Este plano é um guia essencial para aqueles interessados em segurança tecnológica. [Leia mais](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\n)\n\n## Computação de borda\n\n\nA combinação da computação quântica e dispositivos IoT está causando preocupações de segurança. O poder da tecnologia quântica e o potencial de sequestro dos dispositivos IoT cria um novo desafio. O medo de que a criptografia seja quebrada está aumentando à medida que a computação quântica avança e as botnets lançam ataques de negação de serviço (DDoS) usando dispositivos IoT invadidos. As defesas de rede devem ser fortalecidas para lidar com essa ameaça dupla. [Leia mais](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\n)\n\n\nO Yahoo Finance revelou um empolgante desenvolvimento na indústria de tecnologia, à medida que a Computação de Borda, a IoT e a IA se fundem para criar um mercado previsto para valer 230 bilhões de dólares até 2025. A Computação de Borda permite que mais de 75 bilhões de dispositivos IoT processem dados em tempo real, enquanto as habilidades cognitivas da IA estimam aumentar a produtividade em até 40%. Essa revolução está prestes a remodelar a dinâmica dos dados e a tomada de decisões em várias indústrias. [Leia mais](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\n)\n\n\nA região Ásia-Pacífico está passando por uma transformação digital significativa impulsionada pela Internet das Coisas (IoT) e Inteligência Artificial (IA). A Computação de Borda Móvel (MEC) está liderando essa mudança, oferecendo níveis inigualáveis de conectividade e automação ao aproximar a computação da fonte de dados. A MEC possui um potencial imenso para revolucionar indústrias, melhorar vidas e impulsionar o destino digital da região, mas também apresenta desafios de segurança que exigem proteções robustas e regulamentações atualizadas. [Leia mais](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\n)\n\n## Abraçando o Podcast de Transformação Digital\n\n\nNo último episódio de \"Abraçando a Transformação Digital\", Darren é acompanhado por Leland Brown, um engenheiro principal na Capgemini e um ex-convidado do programa. Eles discutem os avanços futuros da tecnologia 5G e seu impacto na Computação de Borda Móvel (MEC) no Departamento de Defesa dos Estados Unidos. [Leia mais](https://embracingdigital.org/episode-EDT149\n)\n\n## Inteligência Artificial\n\n\nHá uma preocupação crescente entre especialistas em tecnologia sobre o uso de imagens aprimoradas por IA. O The Guardian investigou essa questão, pois há uma preocupação de que visuais alterados por IA possam impactar a opinião pública e distorcer fatos importantes essenciais para o sistema democrático. Isso poderia afetar seriamente a confiança e a verdade e levar a um debate sobre como proteger as eleições da manipulação da IA. [Leia mais](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\r)\n\n\nUm artigo recente do Yahoo Finance relatou que o Wendy's, um restaurante de fast food americano, está utilizando inteligência artificial para revolucionar seus drive-thrus. Com pedidos automatizados e menus personalizados, o gigante da comida rápida está mudando o jogo das refeições rápidas. Essa abordagem tecnológica ao serviço de alimentação oferece uma visão do futuro dos restaurantes de fast food. Será interessante ver como os clientes reagem a essa transformação digital. [Leia mais](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\r)\n\n\nO impacto da AI nos profissionais asiático-americanos é uma tendência preocupante. As perdas de emprego estão se aproximando, levantando questões sobre como a sociedade abordará a equação complexa de tecnologia, etnia e dinâmica da força de trabalho. É necessária uma análise mais aprofundada dos efeitos da AI. [Leia mais](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\r)\n\n## Cibersegurança\n\n\nA NBC News reportou um preocupante ataque cibernético em uma rede hospitalar que resultou na desconexão de sua infraestrutura nacional de computadores. A invasão colocou em risco o cuidado dos pacientes e as autoridades estão trabalhando para conter a situação. Esse incidente destaca a importância da segurança dos dados de saúde na era digital. [Leia mais](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\r)\n\n\nDesenvolvedores que utilizam o sistema amplamente utilizado NPM estão sendo alvo de pacotes de código prejudiciais que podem comprometer a segurança do software. Esta é uma ameaça grave que precisa ser identificada e mitigada para evitar ataques cibernéticos. A comunidade de segurança cibernética está preocupada e destaca a necessidade de cadeias de suprimento de software mais seguras para prevenir uma maior infiltração desses pacotes. [Leia mais](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\r)\n\n\nA CISA lançou um plano estratégico chamado \"Blueprint for Cybersecurity\" para fortalecer a infraestrutura digital nacional. Ele se concentra em defesa adaptativa, resposta a incidentes e inovação para criar um escudo digital impenetrável. Este plano é um guia essencial para aqueles interessados em segurança tecnológica. [Leia mais](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\r)\n\n## Computação de Borda\n\n\nA combinação da computação quântica e dispositivos IoT está causando preocupações de segurança. O poder da tecnologia quântica e o potencial de sequestro dos dispositivos IoT criam um novo desafio. O medo do crack de criptografia aumenta à medida que a computação quântica avança e botnets lançam ataques DDoS usando dispositivos IoT hackeados. As defesas de rede devem ser fortalecidas para lidar com essa ameaça dupla. [Leia mais](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\r)\n\n\nYahoo Finance revelou um desenvolvimento empolgante na indústria de tecnologia, à medida que Edge Computing, IoT e AI se unem para criar um mercado previsto para valer $230 bilhões até 2025. Edge Computing permite que mais de 75 bilhões de dispositivos IoT processem dados em tempo real, enquanto as habilidades cognitivas da AI são estimadas para impulsionar a produtividade em até 40%. Essa revolução está pronta para remodelar a dinâmica de dados e tomada de decisões em várias indústrias. [Leia mais](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\r)\n\n\nA região da Ásia-Pacífico está passando por uma significativa transformação digital impulsionada pela Internet das Coisas (IoT) e Inteligência Artificial (IA). A Computação de Borda Móvel (Mobile Edge Computing - MEC) está liderando essa mudança, oferecendo níveis incomparáveis de conectividade e automação ao trazer a computação mais próxima da fonte de dados. A MEC possui um imenso potencial para revolucionar indústrias, melhorar vidas e impulsionar o destino digital da região, mas também apresenta desafios de segurança que exigem salvaguardas robustas e regulamentações atualizadas. [Leia mais](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\r)\n\n## Podcast sobre a Transformação Digital\n\n\nNo último episódio de Abraçando a Transformação Digital, Darren recebe Leland Brown, engenheiro principal na Capgemini e ex-convidado do programa. Eles discutem os avanços futuros da tecnologia 5G e seu impacto na Computação de Borda Móvel (MEC) no Departamento de Defesa dos Estados Unidos. [Leia mais](https://embracingdigital.org/episode-EDT149\r)\n\nInteligência Artificial\n\n\nHá uma preocupação crescente entre especialistas em tecnologia sobre o uso de imagens aprimoradas por IA. O The Guardian investigou esse problema, uma vez que há uma preocupação de que visuais alterados por IA possam impactar a opinião pública e distorcer fatos importantes essenciais ao sistema democrático. Isso poderia afetar seriamente a confiança e a verdade e levar a um debate sobre como proteger as eleições da manipulação da IA. [Leia mais](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\r)\n\n\nUm artigo recente do Yahoo Finanças relatou que o Wendy's, um restaurante de fast food americano, está usando inteligência artificial para revolucionar seus drive-thrus. Com pedidos automatizados e menus personalizados, o gigante do fast food está mudando o jogo para refeições rápidas. Essa abordagem tecnológica para serviço de comida dá uma espiada no futuro do fast-food. Será interessante ver como os clientes reagem a essa transformação digital. [Leia mais](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\r)\n\n\nO impacto da Inteligência Artificial nos profissionais asiático-americanos é uma tendência preocupante. As perdas de empregos estão se aproximando, levantando questões sobre como a sociedade lidará com a complexa equação de tecnologia, etnia e dinâmicas da força de trabalho. Uma análise mais aprofundada dos efeitos da IA é necessária. [Leia mais](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\r)\n\n## Cibersegurança\n\n\nA NBC News informou um preocupante ataque cibernético em uma rede hospitalar que resultou na desconexão de sua infraestrutura de computadores nacionais. A violação colocou em risco o cuidado com os pacientes, e as autoridades estão trabalhando para conter a situação. Esse incidente destaca a importância da segurança dos dados de saúde na era digital. [Leia mais](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\r)\n\n\nDesenvolvedores que utilizam o sistema amplamente utilizado NPM estão sendo alvos de pacotes de código prejudiciais que podem comprometer a segurança do software. Isso é uma ameaça grave que precisa ser identificada e mitigada para evitar ataques cibernéticos. A comunidade de segurança cibernética está preocupada e destaca a necessidade de cadeias de suprimentos de software mais seguras para prevenir uma maior infiltração desses pacotes. [Leia mais](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\r)\n\n\nO CISA lançou um plano estratégico chamado \"Plano de Ação para Segurança Cibernética\" para fortalecer a infraestrutura digital nacional. Ele se concentra em defesa adaptativa, resposta a incidentes e inovação para criar um escudo digital impenetrável. Este plano é um guia essencial para aqueles interessados em segurança tecnológica. [Leia mais](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\r)\n\n## Edge Computing\nComputação de Borda\n\n\nA combinação da computação quântica e dispositivos de IoT está causando preocupações de segurança. O poder da tecnologia quântica e o potencial de sequestro de dispositivos IoT criam um novo desafio. O receio de que a criptografia seja quebrada é crescente à medida que a computação quântica avança e botnets lançam ataques DDoS usando dispositivos IoT hackeados. As defesas de rede devem ser fortalecidas para lidar com essa ameaça dupla. [Leia mais](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\r)\n\n\nO Yahoo Finance revelou um desenvolvimento empolgante na indústria de tecnologia, à medida que Computação em Borda, IoT e IA se fundem para criar um mercado previsto para valer duzentos e trinta bilhões de dólares até 2025. A Computação em Borda permite que mais de setenta e cinco bilhões de dispositivos IoT processem dados em tempo real, enquanto as habilidades cognitivas da IA são estimadas para aumentar a produtividade em até quarenta por cento. Essa revolução está prestes a transformar a dinâmica de dados e a tomada de decisões em várias indústrias. [Leia mais](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\r)\n\n\nA região Ásia-Pacífico está passando por uma significante transformação digital impulsionada pela Internet das Coisas (IoT) e Inteligência Artificial (IA). A Computação de Borda Móvel (Mobile Edge Computing - MEC) está liderando essa mudança, oferecendo níveis incomparáveis de conectividade e automação ao aproximar o processo computacional da fonte de dados. A MEC possui um imenso potencial para revolucionar as indústrias, melhorar vidas e impulsionar o destino digital da região, mas também apresenta desafios de segurança que exigem robustos mecanismos de proteção e regulamentações atualizadas. [Leia mais](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\r)\n\n## Abraçando o Podcast de Transformação Digital\n\n\nNo último episódio de Abraçando a Transformação Digital, Darren é acompanhado por Leland Brown, um engenheiro principal na Capgemini e um ex-convidado do programa. Eles discutem os avanços futuros da tecnologia 5G e seu impacto na Computação de Borda Móvel (MEC) no Departamento de Defesa dos Estados Unidos. [Leia mais](https://embracingdigital.org/episode-EDT149\r)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW27-pt","image":"./briefs/edw-27/pt/thumbnail.png","lang":"pt","summary":"A semana do podcast de 7 de agosto de 2023 trouxe várias atualizações significativas em relação à transformação digital. De maneira notável, as cadeias de fast food começaram a implementar IA para lidar com a escassez de mão de obra, os hospitais estão enfrentando ataques cibernéticos, e as plataformas de Computação no Limite Móvel estão surgindo."},{"id":194,"type":"News Brief","title":"2023-8-13","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Computação Ubíqua\n\n\nDevido a uma recente violação no Microsoft Azure Cloud, o Departamento de Segurança Interna está revisando sistemas de identidade e autenticação baseados em nuvem para evitar ataques maliciosos em ambientes de computação em nuvem, seguindo violações de segurança recentes. O objetivo é fornecer recomendações para melhorar a segurança de contas e prevenir futuras violações. [Leia mais](https://www.reuters.com/technology/us-cyber-safety-review-board-assess-online-intrusion-microsoft-exchange-dhs-2023-08-11/)\n\n\nO potencial da computação quântica em revolucionar múltiplas indústrias, especificamente a Inteligência Artificial, ao aumentar a velocidade de processamento, é empolgante. No entanto, devido à delicada natureza dos qubits, criar computadores quânticos é uma tarefa difícil. Ainda assim, profissionais da indústria permanecem esperançosos em relação ao potencial da computação quântica em trazer importantes avanços em diversos setores. [Leia mais](https://www.scmp.com/magazines/post-magazine/long-reads/article/3230746/quantum-computing-could-give-ai-rocket-fuel-it-needs-become-transformative-its-not-there-yet)\n\n\nO Presidente Biden assinou uma ordem executiva esta semana que proíbe investimentos dos Estados Unidos nos setores chineses de IA, semicondutores e computação quântica, a fim de evitar apoio não intencional ao avanço militar e tecnológico da China. A indústria de semicondutores, especificamente no desenvolvimento e fabricação de chips, é o principal alvo. A China expressou descontentamento com a ordem, alegando que ela interrompe laços econômicos. A ordem se aplica a investimentos futuros e pode ter algumas exceções. [Leia mais](https://www.tomshardware.com/news/us-order-bans-future-investments-in-chinese-ai-semiconductor-and-quantum-computing)\n\n## Gerenciamento de Dados\n\n\nA China está propondo novas regras para limitar a tecnologia de reconhecimento facial e proteger a privacidade do usuário. As regras preliminares da Administração do Ciberespaço da China declaram que o reconhecimento facial deve ser utilizado apenas quando necessário e que soluções não biométricas devem ser exploradas para alcançar os mesmos objetivos com menos intrusão. Essa medida surge em resposta à preocupação na China sobre o potencial uso indevido de informações pessoais por meio da tecnologia de reconhecimento facial. [Leia mais](https://fagenwasanni.com/news/china-introduces-new-draft-rules-to-regulate-facial-recognition-technology-and-data-management/174996/)\n\n\nNa transição de servidores internos para a tecnologia em nuvem e centros de dados para gerenciamento de dados, a nuvem oferece escalabilidade e flexibilidade, ao mesmo tempo que elimina a necessidade de proximidade dos servidores. No entanto, muitas organizações ficam chocadas com o preço de gerenciar dados entre centros de dados e nuvens, já que os provedores de serviços em nuvem cobram pela movimentação de dados entre modalidades. Desenvolver uma estratégia de gerenciamento de dados e uma arquitetura de dados híbrida está se tornando fundamental para as organizações economizarem custos, melhorarem a resiliência e apoiarem os negócios nesses ambientes operacionais complexos. [Leia mais](https://devops.com/data-management-cloud-technology-or-data-centers/)\n\n\nOs governos em todo o mundo estão assumindo um papel mais ativo na regulamentação da privacidade dos dados. Oregon adotou uma abordagem abrangente, dando aos consumidores maior controle sobre seus dados pessoais. As empresas agora devem obter consentimento explícito para a coleta e compartilhamento de dados, e indivíduos têm o direito de acessar, corrigir e excluir seus dados. A lei também inclui obrigações de transparência e salvaguardas contra discriminação com base no uso de dados. Será outro aproveitamento financeiro do governo ou uma proteção real da privacidade individual. O tempo dirá. [Leia mais](https://www.reuters.com/legal/legalindustry/oregon-passes-comprehensive-privacy-law-2023-08-11/)\n\n## Cibersegurança\n\n\nO Instituto Nacional de Padrões e Tecnologia (NIST) está dando passos significativos aprimorando as práticas de cibersegurança ao fornecer novas diretrizes e recursos. Além dos pilares anteriores do framework de segurança, identificação, proteção, detecção, resposta e recuperação, o NIST introduziu um novo pilar chamado \"governar\". Essa nova adição enfatiza que a cibersegurança é uma fonte significativa de risco empresarial e ajuda as organizações a melhor planejar e executar suas decisões para apoiar sua estratégia de segurança. [Leia mais](https://www.infosecurity-magazine.com/news/nist-expands-cybersecurity/)\n\n\nA conferência de cibersegurança Black Hat em Las Vegas apresentou ferramentas avançadas para detecção de ameaças, resposta a incidentes e comunicação segura. Essas ferramentas visam aprimorar as defesas de cibersegurança das organizações contra ameaças e desafios emergentes. Como esperado, a Inteligência Artificial Generativa foi um tema central, destacando seu potencial para frustrar ataques cibernéticos. [Leia mais](https://www.crn.com/news/security/20-hottest-new-cybersecurity-tools-at-black-hat-2023)\n\n\nO Desafio do Quebrador de Códigos da NSA ajuda a enfrentar a escassez de habilidades em cibersegurança, desafiando estudantes a resolver problemas complexos e incentivando a colaboração. Ele estimula o desenvolvimento de novos materiais e programas educacionais, proporcionando à próxima geração de profissionais uma experiência prática para fortalecer a defesa da indústria contra ameaças em evolução. O programa destaca a importância de promover a educação em cibersegurança e oferecer oportunidades práticas de aprendizado. [Leia mais](https://www.darkreading.com/attacks-breaches/nsa-talks-codebreaker-challenge-success-influence-on-education)\n\n## Podcast de Abraçando a Transformação Digital\n\nDarren entrevista Sonu Panda, o CEO da Prescriptive Data, neste episódio. Eles discutem como o seu software auxilia os proprietários de imóveis comerciais a transformarem seus prédios em espaços inteligentes e eficientes. [Leia mais](https://embracingdigital.org/episode-EDT150)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW28-pt","image":"./briefs/edw-28/pt/thumbnail.png","lang":"pt","summary":"Notícias sobre Transformação Digital, 13 de agosto de 2023. Desenvolvimentos recentes em privacidade de dados, segurança e avanços tecnológicos, incluindo computação quântica e novas leis de privacidade, são dignos de acompanhar. As diretrizes do NIST e as ferramentas da Black Hat são recursos úteis. O Desafio Codebreaker da NSA impulsiona a inovação em cibersegurança."},{"id":195,"type":"News Brief","title":"2023-8-19","tags":["ai","edge","cybersecurity"],"body":"\n\n## Inteligência Artificial\n\n\nEm uma decisão recente, um tribunal em D.C. determinou que a arte gerada por IA não é elegível para proteção de direitos autorais. A decisão estabelece um precedente significativo, sugerindo que obras criativas produzidas exclusivamente por inteligência artificial carecem dos direitos legais normalmente conferidos às criações feitas por seres humanos. Esse veredicto pode ter implicações de longo alcance para o futuro da propriedade intelectual na era digital. [Leia mais](https://news.bloomberglaw.com/ip-law/ai-generated-art-lacks-copyright-protection-d-c-court-rules)\n\n\nPesquisadores do MIT descobriram que os modelos de aprendizado de máquina usados no diagnóstico e tratamento médico podem agravar as desigualdades na assistência à saúde. Esses modelos, quando treinados com dados tendenciosos, podem resultar em acesso desigual e qualidade de cuidados para grupos subrepresentados. Isso evidencia a necessidade urgente de aprimorar a coleta de dados e o desenvolvimento de modelos para garantir resultados justos e equitativos na área da saúde. [Leia mais](https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817)\n\n\nA demanda em ascensão por inteligência artificial (IA) está causando uma escassez de chips de alto desempenho, conforme relata a Fox Business. À medida que as aplicações de IA se expandem por diferentes setores, surge uma crescente necessidade de chips especializados para alimentá-las. Essa escassez está afetando diversos setores, incluindo automotivo, saúde e eletrônicos de consumo, potencialmente retardando a inovação. As empresas estão agora correndo para aumentar a produção de chips e atender à demanda em expansão. [Leia mais](https://www.foxbusiness.com/technology/surging-demand-ai-creating-shortage-high-powered-chips)\n\n## Cibersegurança\n\n\nUm aplicativo focado em estudantes está causando preocupação entre os pais e especialistas em cibersegurança. Os potenciais riscos do aplicativo à segurança das crianças estão sendo examinados, levando os especialistas a enfatizarem a importância da vigilância dos pais e da educação dos jovens usuários sobre a segurança online. A situação destaca a constante necessidade do uso responsável da tecnologia e de medidas pró-ativas para proteger as crianças na era digital. [Leia mais](https://www.live5news.com/2023/08/18/student-geared-app-concerning-lowcountry-parents-cyber-security-experts/)\n\n\nA indústria de fintech está sendo grandemente afetada pela IA e cibersegurança, de acordo com a Analytics Insight. A IA está auxiliando na detecção de fraudes, no atendimento ao cliente e na avaliação de riscos, mas também traz novos riscos de segurança. Esse constante interjogo entre IA e cibersegurança está mudando o mundo das fintechs e levando a mais inovação e medidas de segurança reforçadas para proteger informações financeiras importantes. [Leia mais](https://www.analyticsinsight.net/how-ai-and-cybersecurity-shape-fintech-industry/)\n\n\nUm recente relatório da Pew Research revela que os americanos possuem conhecimento limitado sobre IA, cibersegurança e tecnologia de ponta. Os resultados indicam que uma parte significativa da população carece de compreensão desses tópicos críticos, ressaltando a necessidade de um aumento nos esforços de educação e conscientização pública em uma era dominada pela tecnologia e pelas preocupações digitais. [Leia mais](https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/)\n\n## Computação de Borda\n\nA T-Mobile está se associando à Google Cloud para computação na borda, conforme relatado pelo FierceWireless. Essa colaboração visa aproveitar a infraestrutura em nuvem da Google para aprimorar as capacidades da rede 5G da T-Mobile e fornecer serviços com baixa latência, beneficiando consumidores e empresas. Esse movimento estratégico demonstra a crescente importância da computação na borda na indústria de telecomunicações. [Leia mais](https://www.fiercewireless.com/tech/t-mobile-hooks-google-cloud-edge-compute)\n\n\nA eliminação progressiva das redes 2G e 3G pode ter repercussões para os serviços de IoT e roaming. Muitos dispositivos de IoT e viajantes internacionais ainda dependem dessas redes mais antigas. Os provedores de telecomunicações precisam considerar opções alternativas de conectividade e estratégias para evitar interrupções de serviço para esses grupos de usuários, à medida que eles fazem a transição para tecnologias de rede mais avançadas. É importante abordar essas questões para evitar acumular dívida técnica no futuro. [Leia mais](https://www.lightreading.com/broadband/sunsetting-2g-and-3g-could-leave-iot-and-roamers-in-dark/d/d-id/786146)\n\n\nNo ET Digital Telco Summit, o CTO da Airtel destacou que a convergência do 5G com as tecnologias de nuvem e IoT está prestes a desbloquear casos de uso inovadores em diversas indústrias. Essa combinação é esperada para impulsionar soluções transformadoras para setores específicos, mostrando o potencial do 5G para revolucionar conectividade e serviços na Índia e além. [Leia mais](https://telecom.economictimes.indiatimes.com/news/industry/etdigitaltelcosummit-combination-of-5g-with-cloud-iot-to-drive-new-use-cases-for-verticals-airtel-cto/102827792)\n\n## Podcast sobre Abraçando a Transformação Digital\n\n\nEsta semana, Darren começa uma série sobre AI generativa com entrevistas de especialistas na área de educação, saúde, cibersegurança e tecnologias em nuvem, e como a AI generativa está desempenhando um papel no futuro. As histórias desta semana incluem entrevistas do Dr. Jeffrey Lancaster falando sobre a compreensão da genAI. [Leia mais](https://embracingdigital.org/episode-EDT151)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW29-pt","image":"./briefs/edw-29/pt/thumbnail.png","lang":"pt","summary":"Nas últimas notícias do Embracing Digital para 20 de agosto de 2023, há atualizações sobre inteligência artificial, cibersegurança e computação de borda. As notícias incluem a IA no caminho para os tribunais, atores malignos cibernéticos direcionando a temporada de volta às aulas e a dívida técnica sendo transferida para o ecossistema 5G pela computação de borda."},{"id":196,"type":"News Brief","title":"2023-2-19","tags":null,"body":"\n\n## Inteligência Artificial.\n\nA ética e as regulamentações de utilização de Chatbots habilitados por inteligência artificial generativa estão começando a entrar em jogo à medida que mais pessoas estão começando a utilizar o ChatGPT e outros. Os Chatbots agora precisarão incluir um aviso: Podemos não produzir uma saída real. Acredite por sua própria conta e risco. Você revoga seu direito de nos processar se reproduzir conversas, imagens e vídeos para casos de uso de alto risco que causem ódio, assédio, violência, autolesão, atividade ilegal, engano, discriminação ou spam.\n\n[https://swisscognitive.ch/2023/02/15/honest-lying-why-scaling-generative-ai-responsibly-is-not-a-technology-dilemma-in-as-much-as-a-people-problem/](https://swisscognitive.ch/2023/02/15/honest-lying-why-scaling-generative-ai-responsibly-is-not-a-technology-dilemma-in-as-much-as-a-people-problem/)\n\nÀ medida que a IA se torna cada vez mais importante em várias indústrias, o papel do Chief AI Officer (CAIO) está surgindo como uma nova adição à equipe executiva. Um bom CAIO deve definir claramente o impacto desejado dos projetos de IA e focar continuamente a organização na entrega desse resultado. Um grande CAIO também deve rastrear o impacto real desses projetos e atualizar os negócios sobre sua performance ao longo do tempo. Esse papel, portanto, aumenta as expectativas para impulsionar a transformação e o impacto, bem como antecipar e responder ao uso de IA pelos concorrentes.\n\n[https://applieddatascience.medium.com/the-case-for-the-chief-ai-officer-the-newest-c-suite-role-d55cca40c01](https://applieddatascience.medium.com/the-case-for-the-chief-ai-officer-the-newest-c-suite-role-d55cca40c01)\n\nO mais recente supercomputador da IBM está seguindo várias novas direções inovadoras - é o primeiro supercomputador nativo de nuvem otimizado para IA da IBM e é hospedado inteiramente na IBM Cloud, em vez de local como os supercomputadores tradicionais. De acordo com a IBM, \"este é o ambiente ideal para pesquisadores da IBM criarem as capacidades de IA mais avançadas, incluindo trabalhos em modelos fundamentais e um lugar onde eles colaboram com parceiros na criação de modelos\".\n\n[https://futurumresearch.com/research-notes/ibms-latest-supercomputer-is-cloud-based-and-ai-focused/](https://futurumresearch.com/research-notes/ibms-latest-supercomputer-is-cloud-based-and-ai-focused/)\n\n## Computação Ubíqua\n\nDe acordo com um estudo da 451 Research encomendado pela Oracle Cloud Infrastructure, quase toda jornada para a nuvem nas empresas agora está se tornando uma jornada multicloud. O estudo descobriu que 98% das empresas pesquisadas estão usando ou planejam usar pelo menos dois provedores de serviços em nuvem. Os principais impulsionadores das estratégias multicloud são a soberania dos dados e a otimização de custos. As empresas estão planejando proativamente estratégias multicloud para o futuro, sendo a redundância de dados o caso de uso futuro mais esperado.\n\n[https://www.cloudcomputing-news.net/news/2023/feb/21/98-of-firms-using-public-cloud-adopt-multicloud-infrastructure-provider-strategy/](https://www.cloudcomputing-news.net/news/2023/feb/21/98-of-firms-using-public-cloud-adopt-multicloud-infrastructure-provider-strategy/)\n\nA \"super nuvem\", uma arquitetura de nuvem que permite a migração contínua de aplicativos entre diferentes provedores de nuvem, foi proposta pela primeira vez por pesquisadores da Universidade Cornell em 2016. O conceito ressurgiu como solução para os desafios do multi-cloud, fornecendo uma rede homogênea para unir recursos de nuvem, resultando em migração contínua, segurança consistente e desempenho ideal.\n\n[https://www.cloudcomputing-news.net/news/2023/feb/22/here-comes-the-supercloud-what-does-it-mean-for-multi-cloud-complexity/](https://www.cloudcomputing-news.net/news/2023/feb/22/here-comes-the-supercloud-what-does-it-mean-for-multi-cloud-complexity/)\n\nA demanda por DRAM para servidores deve superar a de smartphones devido ao crescente uso de aplicativos em nuvem, IA e HPC; prevê-se um aumento de 12,1% no conteúdo de DRAM para servidores em relação a 6,7% para smartphones em 2023. A memória do servidor representará 37,6% da saída total de bits de DRAM, em comparação com 36,8% para DRAM móvel. A pandemia de COVID-19 impulsionou a demanda por serviços em nuvem, resultando em um forte aumento no envio de servidores.\n\n## Cibersegurança\n\nA empresa de cibersegurança Resecurity alertou sobre uma série de ciberataques que visaram centros de dados em todo o mundo nos últimos 18 meses, resultando na exfiltração de dados e publicação de credenciais de acesso na web escura. Embora a Resecurity não tenha nomeado as vítimas, a Bloomberg afirma que grandes corporações, incluindo Alibaba, Amazon, Apple, BMW, Goldman Sachs, Huawei Technologies, Microsoft e Walmart, tiveram suas credenciais de centro de dados roubadas.\n\n[https://www.csoonline.com/article/3688909/cyberattacks-hit-data-centers-to-steal-information-from-global-companies.html#tk.rss_all](https://www.csoonline.com/article/3688909/cyberattacks-hit-data-centers-to-steal-information-from-global-companies.html#tk.rss_all)\n\nA empresa de segurança cibernética Menlo Labs descobriu um grupo desconhecido de atores de ameaças que está direcionando entidades governamentais por meio de uma campanha baseada no Discord, usando o downloader PureCrypter. A campanha usa o domínio de uma organização sem fins lucrativos comprometida como centro de comando e controle para fornecer uma carga secundária, incluindo o Redline Stealer, AgentTesla, Eternity, Blackmoon e Philadelphia Ransomware.\n\n[https://www.menlosecurity.com/blog/purecrypter-targets-government-entities-through-discord](https://www.menlosecurity.com/blog/purecrypter-targets-government-entities-through-discord)\n\nO maior exercício de ciber-guerra militar na Europa Ocidental ocorreu recentemente na Estônia, com 34 equipes de 11 países participando de uma batalha cibernética real. O evento de sete dias testou as respostas dos participantes a cenários cibernéticos comuns e complexos, incluindo ataques a redes e sistemas de controle industrial (ICS). Um cenário simula ataques a sistemas robóticos não tripulados. As equipes da Itália, Estônia e Reino Unido foram os melhores desempenhos, julgadas com base em sua velocidade na identificação e resposta a ameaças cibernéticas.\n\n[https://www.securityweek.com/11-countries-take-part-in-military-cyberwarfare-exercise/](https://www.securityweek.com/11-countries-take-part-in-military-cyberwarfare-exercise/)\n\n## Abraçando o Podcast de Transformação Digital.\n\nConfira o episódio completo desta semana \"Certificando o Voo Autônomo\", onde Darren entrevista LuukVan Dijk da Daedalean.\n\n[https://www.embracingdigital.org/episode-EDT126](https://www.embracingdigital.org/episode-EDT126)\n\n\n\n","guests":null,"link":"/brief-EDW3-pt","image":"./briefs/edw-3/pt/thumbnail.png","lang":"pt","summary":"Summary"},{"id":197,"type":"News Brief","title":"2023-8-26","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Cibersegurança\n\n\nUma nova ameaça surgiu. O grupo cibernético \"Tufão de Linho\", acredita-se ser vinculado à China, tem causado alvoroço. Eles são suspeitos de lançar ciberataques sofisticados em organizações globais. Especialistas monitoram de perto esta situação, pois pode ter implicações significativas para a segurança digital. Fique ligado para atualizações sobre esta história em desenvolvimento. [Leia mais](https://thehackernews.com/2023/08/china-linked-flax-typhoon-cyber.html)\n\n\nAs empresas de cibersegurança estão emitindo um alerta, uma vez que os ataques de ransomware aumentaram mais de cento e cinquenta e três por cento em comparação com um ano atrás e mais de dezesseis por cento no mês passado. Especialistas alertam que as organizações devem reforçar suas defesas e educar os funcionários sobre essas ameaças para se protegerem contra violações de dados caras. [Leia mais](https://www.securityweek.com/cybersecurity-companies-report-surge-in-ransomware-attacks/)\n\n\nO setor de cibersegurança está enfrentando uma grave escassez de talentos, elevando as expectativas por soluções. A demanda por profissionais qualificados nesse campo em constante evolução está aumentando, mas a lacuna persiste. Para lidar com isso, as empresas estão explorando estratégias como aprimoramento das habilidades de funcionários atuais e promoção da diversidade na indústria. Pode ser hora de voltar à escola para obter certificação em cibersegurança. [Leia mais](https://www.helpnetsecurity.com/2023/08/25/cybersecurity-talent-shortage-expectations/)\n\n## Inteligência Artificial\n\n\nA inteligência artificial devolveu a uma mulher paralisada sua voz em um desenvolvimento incrível. Pesquisadores da UCSF empregaram a tecnologia de IA para decodificar os sinais cerebrais da mulher e traduzi-los em fala. Esta conquista inovadora poderia ajudar inúmeras pessoas a recuperar sua capacidade de se comunicar. Para saber mais sobre essa história inspiradora, confira um artigo detalhado em ucsf.edu. [Leia mais](https://www.ucsf.edu/news/2023/08/425986/how-artificial-intelligence-gave-paralyzed-woman-her-voice-back)\n\n\nOs alunos do ensino médio estão se preparando para o surgimento da inteligência artificial (IA). Pesquisadores do MIT lançaram uma nova iniciativa para ajudar a preparar os alunos para o futuro impulsionado pela IA. Este programa tem como objetivo equipar mentes jovens com as habilidades e conhecimentos necessários para prosperar em um mundo cada vez mais influenciado pela tecnologia da IA. Confira a entrevista de Darren com Pete Schmitz no episódio do Podcast \"Abraçando a Transformação Digital\", Treinando a Próxima Geração em IA, para ter uma visão detalhada do que está acontecendo hoje. [Leia mais](https://news.mit.edu/2023/how-to-help-high-schoolers-prepare-rise-of-artificial-intelligence-0824)\n\n\nNuma análise aprofundada da DeZeen que estimula o pensamento, o custo ambiental da inteligência artificial (IA) é examinado. Conforme as aplicações de IA se expandem, também aumenta o consumo de energia, potencialmente agravando as preocupações climáticas. Esta avaliação crítica explora os desafios de sustentabilidade apresentados pela IA e a necessidade urgente de soluções ecologicamente corretas para o desenvolvimento e implantação da tecnologia de IA. Fique atento para insights mais profundos sobre essa questão ambiental urgente. [Leia mais](https://www.dezeen.com/2023/08/26/dezeen-in-depth-examines-the-environmental-cost-of-artificial-intelligence/)\n\n## Computação Ubíqua\n\n\nÀ medida que nos aproximamos da era da computação quântica, proteger a infraestrutura crítica se torna ainda mais crucial. C4ISRNET aprofunda-se nos desafios e estratégias para proteger sistemas vitais nessa nova paisagem tecnológica. O potencial da computação quântica em quebrar os métodos de criptografia atuais traz preocupações, ressaltando a necessidade de soluções inovadoras em cibersegurança. [Leia mais](https://www.c4isrnet.com/it-networks/2023/08/21/how-to-protect-critical-infrastructure-in-the-quantum-computing-era/)\n\n\nComo relatado pelos desenvolvedores do XDA, o Dropbox está encerrando sua política de armazenamento ilimitado na nuvem. Essa decisão ocorre em resposta a casos de abuso por parte de alguns usuários. Como resultado, o Dropbox está implementando novas limitações de armazenamento, o que representa uma mudança substancial para sua base de usuários. Esse desenvolvimento ressalta os desafios contínuos enfrentados pelos provedores de armazenamento em nuvem ao equilibrar as demandas dos usuários com modelos de negócios sustentáveis. [Leia mais](https://www.xda-developers.com/dropbox-ends-unlimited-cloud-storage-policy-abused/)\n\n\nA pandemia mundial em dois mil e vinte revitalizou um setor de tecnologia que sofria com um crescimento estagnado, a Infraestrutura de Desktop Virtual. A Microsoft e a VMware estão remodelando o VDI empresarial e a tecnologia em nuvem. O SiliconANGLE discute como esses gigantes da tecnologia colaboram para redefinir o VDI e aprimorar soluções em nuvem. Essa parceria proporcionará às empresas maior flexibilidade, escalabilidade e desempenho em ambientes de TI. [Leia mais](https://siliconangle.com/2023/08/24/microsoft-vmware-redefining-business-vdi-cloud-technology-vmwareexplore/)\n\n## Abraçando o Podcast de Transformação Digital\n\n\n\nEsta semana, a série Abraçando a IA Generativa continua, apresentando entrevistas com professores do ensino médio que adotaram o ChatGPT e explorando novos casos de uso para IA generativa. Inscreva-se em Abraçando a Transformação Digital para discussões aprofundadas sobre os tópicos mais quentes do momento. [Leia mais](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW30-pt","image":"./briefs/edw-30/pt/thumbnail.png","lang":"pt","summary":"Aqui estão as últimas atualizações sobre notícias de transformação digital na semana de 27 de agosto de 2023. As histórias desta semana abrangem Cibersegurança, Inteligência Artificial e Computação Ubíqua. Neste episódio, você encontrará histórias sobre um aumento significativo de 150% nos ataques de Ransomware, como a Computação Quântica expôs vulnerabilidades de segurança cibernética da IoT e como a IA está ajudando a restaurar a voz daqueles que são paralisados."},{"id":198,"type":"News Brief","title":"2023-9-2","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\nEstamos no meio da revolução digital. Durante esse período, pode ser desafiador filtrar todo o hype e descobrir o que funciona, o que ainda será viável daqui a dois anos e o que contribui para a sua organização. Muitas organizações de TI precisam de ajuda com mensagens confusas e tecnologias conflitantes. Nós ajudamos as organizações a filtrar o ruído e abraçar a transformação digital. O mundo da transformação digital está em constante mudança e você precisa saber o que é viável hoje. Ouça o podcast semanalmente para as últimas notícias em cibersegurança, comunicações avançadas, gerenciamento de dados, inteligência artificial, borda e computação em nuvem.\n\n## Cibersegurança\n\n\n\nUm recente ataque cibernético, acreditado ser apoiado pela China, tem causado preocupações para a segurança nacional em Guam. O grupo de hackers Volt Typhoon direcionou a rede de telecomunicações e o sistema elétrico de Guam para estabelecer uma presença furtiva. Guam é considerado um hub logístico vital para os Estados Unidos em qualquer conflito com a China. Os hackers aproveitaram uma vulnerabilidade no firewall Fortinet Fortigate, um produto líder em proteção cibernética. Esse ataque destaca uma nova ameaça, à medida que hackers patrocinados por estados nacionais cada vez mais direcionam ferramentas de cibersegurança cruciais para a proteção de sistemas. [Leia mais](https://www.msn.com/en-us/news/other/cybersecurity-tools-are-new-targets-for-nation-state-hackers/ar-AA1g5mib)\n\n\nUm ataque cibernético causou uma interrupção de tecnologia de uma semana no Hospital Sisters Health System, incluindo o St. Elizabeth's em O'Fallon, Illinois. O CEO Damond Boatright confirmou que o incidente interrompeu o serviço de internet, sites, telefones e aplicativos de computador. Embora progressos estejam sendo feitos para restaurar os sistemas críticos, o site do HSHS continua indisponível, e o acesso dos pacientes a prontuários online e comunicação com médicos foi interrompido. Este é o segundo ataque a grupos hospitalares nos Estados Unidos em dois meses. [Leia mais](https://www.bnd.com/news/local/article278879724.html)\n\n\n\nOs colégios comunitários estão enfrentando uma crescente ameaça de cibersegurança: \"estudantes fantasmas\". Essas identidades fictícias exploram os processos de matrícula para acessar recursos acadêmicos, comprometendo potencialmente dados de estudantes e a integridade institucional. Com os hackers se tornando cada vez mais sofisticados, os colégios comunitários investem em medidas de cibersegurança para combater essa ameaça. A batalha contra os \"estudantes fantasmas\" destaca a necessidade de uma segurança digital robusta em instituições educacionais para proteger informações sensíveis e garantir um ambiente de aprendizado seguro. [Leia mais](https://www.chronicle.com/article/meet-the-cybersecurity-threat-haunting-community-colleges-ghost-students)\n\n## Inteligência Artificial\n\n\nO uso de inteligência artificial no ensino superior tem gerado debate entre aqueles que veem seu potencial de personalização e eficiência e aqueles que se preocupam com ética e a perda da conexão humana. É necessária uma consideração cuidadosa para a integração da IA nas salas de aula universitárias. A professora universitária Laura Torres Newey compartilhou sua abordagem para enfrentar essa questão em um episódio de podcast sobre a adoção da transformação digital. Suas percepções revelam os desafios e oportunidades de incorporar a IA no ensino superior. [Leia mais](https://theconversation.com/should-ai-be-permitted-in-college-classrooms-4-scholars-weigh-in-212176)\n\n\nA indústria do entretenimento enfrenta disputas trabalhistas, com a inteligência artificial (IA) no centro do conflito. A greve do Sindicato de Atores de Cinema completa sua oitava semana, com trabalhadores em Hollywood exigindo uma compensação justa e controle criativo no uso da tecnologia impulsionada por IA. Essa disputa reflete a luta da indústria em equilibrar os benefícios da IA, como eficiência de custos e inovação, com preocupações sobre a substituição de empregos e autonomia artística. À medida que o cenário do entretenimento evolui, resolver essas questões trabalhistas relacionadas à IA será crucial para os trabalhadores e o futuro da indústria. O mundo está de olho! [Leia mais](https://www.pbs.org/newshour/show/why-artificial-intelligence-is-a-central-dispute-in-the-hollywood-strikes)\n\n\nA regulamentação da inteligência artificial (IA) é uma preocupação global, e os países estão adotando abordagens diversas para abordá-la. China, Israel e a União Europeia (UE) estão na vanguarda do governo da IA. A China foca na ética da IA e na segurança de dados, Israel promove a inovação por meio de arenas regulatórias e a UE propõe regras rígidas para a IA visando garantir responsabilidade. À medida que a IA continua a moldar diversas indústrias e aspectos da vida cotidiana, encontrar o equilíbrio adequado entre inovação e regulamentação permanece um desafio crucial no cenário global. [Leia mais](https://www.washingtonpost.com/world/2023/09/03/ai-regulation-law-china-israel-eu/)\n\n## Edge Computing\n\nComputação de Borda\n\n\nA Intel está fortalecendo a segurança da computação de borda ao introduzir uma camada inovadora de proteção. A nova tecnologia da empresa promete proteger dispositivos e dados de borda, abordando preocupações críticas de cibersegurança. Com a crescente importância da computação de borda em várias indústrias, esse desenvolvimento representa um avanço significativo na garantia da integridade e segurança dos ambientes de computação distribuída. [Leia mais](https://www.fool.com/investing/2023/09/01/intel-adds-a-layer-of-protection-to-edge-computing/)\n\n\nGarantir a segurança da Internet das Coisas (IoT) é crucial para proteger a infraestrutura crítica, como redes elétricas e estações de tratamento de água. À medida que os dispositivos IoT se tornam cada vez mais integrados a esses sistemas, protegê-los contra ameaças em evolução, incluindo riscos potenciais associados a determinados países, é uma questão urgente para os Estados Unidos. Os desafios e implicações da tecnologia chinesa na IoT estão atualmente sob exame rigoroso, destacando a necessidade de medidas proativas para proteger a infraestrutura crítica no país. [Leia mais](https://www.forbes.com/sites/davealtavilla/2023/09/03/securing-the-iot-from-the-threat-china-poses-to-us-infrastructure/?sh=4325a3f112c0)\n\n\nA computação de borda não é apenas para a indústria manufatureira e gestão de infraestrutura crítica. A computação de borda está revolucionando a saúde ao possibilitar o processamento de dados em tempo real, o que resulta em tempos de resposta mais rápidos para dados essenciais do paciente. Ela suporta monitoramento remoto e telemedicina, tornando a saúde mais acessível e reduzindo a pressão sobre as instalações de saúde. Além disso, a computação de borda aprimora a privacidade e segurança de dados ao processar informações sensíveis do paciente localmente, reduzindo o risco de violações de dados e garantindo conformidade com regulamentos de saúde. [Leia mais](https://www.ft.com/partnercontent/ntt-ltd/edge-computing-delivers-healthcare-beyond-the-clinic.html?blaid=3846770)\n\n## Abraçando a Transformação Digital\n\n\n\nA série abraçando a inteligência artificial generativa continua com entrevistas sobre o processo de se tornar pronto para dados na revolução GenAI e como o ensino superior lida com a inteligência artificial generativa na sala de aula. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW31-pt","image":"./briefs/edw-31/pt/thumbnail.png","lang":"pt","summary":"Notícias da semana de 3 de setembro de 2023 sobre adotar o digital. Esta semana, há atualizações sobre cibersegurança, inteligência artificial e computação de borda. Os ciberataques da China a bases militares e infraestruturas críticas, os esforços da Intel para aprimorar a segurança no espaço da IoE e os desafios enfrentados pelos governos na regulamentação da inteligência artificial."},{"id":199,"type":"News Brief","title":"2023-9-9","tags":["ai","gpt4","openai","microsoft","generativeai","environmentalimpact","irs","taxevasion","education","cybersecurity","iosspyware","zerodayvulnerability","northkoreanhackers","quantumrandomness","cloudfirst","cloudsmart","embracingdigital","generativeaipolicy","highereducation"],"body":"\n\n## Inteligência Artificial\n\n\nO local de nascimento do GPT-4 foi descoberto! Os campos de milho de Des Moines, Iowa, têm sido o centro das últimas notícias da OpenAI, mas a um custo significativo para o meio ambiente. O último relatório ambiental da Microsoft revelou um aumento de 34% no consumo mundial de água de 2021 para 2022, totalizando quase 1,7 bilhão de galões. Esse aumento se deve principalmente ao substancial investimento da empresa em IA generativa e parceria com a OpenAI. O impacto da IA generativa no meio ambiente é significativo, e grandes organizações como Microsoft, Google e OpenAI estão tomando medidas para lidar com essas preocupações. [Leia mais](https://apnews.com/article/chatgpt-gpt4-iowa-ai-water-consumption-microsoft-f551fde98083d17a7e8d904f8be822c4)\n\n\n\nA Receita Federal dos Estados Unidos planeja implementar tecnologia de IA para aprimorar a supervisão de grandes escritórios de advocacia, fundos de hedge, empresas de private equity e investidores imobiliários. A iniciativa visa detectar casos complexos de evasão fiscal e recuperar a receita federal devida por parte de contribuintes ricos. A Receita Federal alocou oitenta bilhões de dólares da Lei de Redução da Inflação para lidar com padrões e tendências na condução de auditorias significativas e na aplicação de penalidades contra sonegadores de impostos nessas indústrias. [Leia mais](https://www.nytimes.com/2023/09/08/us/politics/irs-deploys-artificial-intelligence-to-target-rich-partnerships.html)\n\n\nEducadores e acadêmicos estão na vanguarda ao abordar o papel da IA na educação. À medida que os alunos voltam para a escola neste outono, vários artigos de revistas do mundo todo abordam aplicações de IA, preocupações éticas, aprimoramento em vez de automação, preparação dos alunos para o trabalho integrado à IA, detecção de deepfakes, preservação do senso comum humano e aproveitamento da IA generativa para o ensino. Essas percepções fornecem orientação valiosa para moldar o futuro da IA na educação. Além disso, confira a entrevista de Darren com o New York Times e a professora de inglês Laura Torres Newey sobre como ela está integrando a IA em suas aulas neste outono. [Leia mais](https://daily.jstor.org/artificial-intelligence-and-education-a-reading-list/)\n\n## Cibersegurança\n\n\nA China está levando a sério a Cibersegurança. As novas regulamentações de cibersegurança da China visam aprimorar a segurança digital para a internet, mas as pequenas empresas podem enfrentar desafios. O impacto completo nas empresas de todos os tamanhos ainda está indefinido, e pode haver repercussões na privacidade online. No entanto, essas medidas são necessárias para proteger dados online e se proteger contra ameaças cibernéticas. Indivíduos e empresas devem se manter atualizados com essas mudanças e tomar as precauções necessárias para garantir sua presença online. [Leia mais](https://www.scmp.com/news/china/politics/article/3233931/china-steps-cybersecurity-enforcement-smaller-businesses-are-feeling-heat)\n\n\nO Sistema iPhone, uma vez imune, foi alvo de ataque na última semana, com spyware detectado no popular iOS que roda nos iPhones. A Apple tomou ação rápida após descobrir ameaças de spyware. Eles lançaram atualizações de software essenciais para manter seus dispositivos seguros. É como ter um super-herói protegendo seu mundo tecnológico! Vamos nos aprofundar nos detalhes dessas atualizações, como elas frustraram possíveis violações de segurança e o que isso significa para a sua segurança digital. Fique ligado enquanto desvendamos os últimos desenvolvimentos em tecnologia e cibersegurança. [Leia mais](https://www.washingtonpost.com/politics/2023/09/08/apple-issues-software-updates-after-spyware-discoveries/)\n\n\nHackers norte-coreanos supostamente exploraram uma vulnerabilidade de zero dia, que lhes dá acesso a uma fortaleza de defesas digitais. Este ciberataque representa uma ameaça significativa para os sistemas alvos, violações de dados e o panorama geral de segurança cibernética. Esforços estão em curso para combater a ameaça, incluindo correções e salvaguardas para proteger contra ataques semelhantes no futuro. [Leia mais](https://thehackernews.com/2023/09/north-korean-hackers-exploit-zero-day.html)\n\n## Computação Ubíqua\n\n\nA integração de sistemas de IA generativa está mudando a arquitetura em nuvem, dotando-a de um cérebro inteligente capaz de aprender e criar de forma independente. Essa transformação remodela a infraestrutura em nuvem, fortalecendo a automatização, otimizando a alocação de recursos e aprimorando as medidas de segurança. A infusão de sistemas de IA generativa na nuvem apresenta oportunidades e desafios promissores, e embarcaremos em uma jornada profunda para desvendá-los. [Leia mais](https://www.infoworld.com/article/3706094/adding-generative-ai-systems-may-change-your-cloud-architecture.html)\n\n\nEm uma conquista inovadora, o MIT assumiu o controle do acaso quântico pela primeira vez. É como domar o selvagem e imprevisível! Vamos mergulhar nos detalhes desta proeza notável, que pode ter implicações profundas para a computação quântica e criptografia. Junte-se a nós enquanto exploramos como a descoberta do MIT nos permite aproveitar a aleatoriedade inerente do mundo quântico, abrindo novas fronteiras em tecnologia e segurança. O tempo dirá que impacto isso terá na computação. [Leia mais](https://scitechdaily.com/harnessing-the-void-mit-controls-quantum-randomness-for-the-first-time/)\n\n\n'O Cloud-first' está ultrapassado e 'Cloud-smart' é a nova palavra da moda em tecnologia. Pense nisso como uma transição de 'a nuvem é a resposta' para 'a nuvem como um aliado estratégico.' Vamos aprofundar os detalhes dessa mudança, explorando o que 'cloud-smart' significa para as empresas e estratégias de TI. Junte-se a nós enquanto discutimos como as organizações estão evoluindo suas abordagens para aproveitar a nuvem de forma mais inteligente, tornando-a uma parte central de suas jornadas de transformação digital. [Leia mais](https://www.infoworld.com/article/3705615/cloud-first-is-dead-cloud-smart-is-whats-happening-now.html)\n\n## Abraçando a Transformação Digital\n\n\n\nEsta semana continua a série Abraçando a IA Generativa no podcast com uma entrevista fascinante sobre o desenvolvimento de uma Política de IA Generativa para o seu local de trabalho e como o Ensino Superior está abordando a IA generativa na sala de aula. Sintonize nos episódios mais recentes nas terças-feiras e quintas-feiras. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW32-pt","image":"./briefs/edw-32/pt/thumbnail.png","lang":"pt","summary":"Obtenha as últimas notícias digitais para a semana de 10 de setembro de 2023, abrangendo Inteligência Artificial, Cibersegurança e Computação Ubíqua. Nesta semana, saiba sobre uma nova ameaça cibernética para o iPhone, o local de origem do GPT-4 e a abordagem do MIT para lidar com a incerteza da computação quântica."},{"id":200,"type":"News Brief","title":"2023-9-16","tags":["aisummit","rishisunak","chineseofficialsban","nationalsecurity","ukchinatensions","amazonselfpublishers","aigeneratedcontent","digitalpublishing","columbiauniversityresearch","aireliability","languagemodels","chatbotperformance","cognitivescience","webassembly(wasm)","edgecomputingrevolution","edgedevices","latencyreduction","secureexecution","iotapplications","mobilecomputing","ai","security","edge","embracingdigital"],"body":"\n\n## Inteligência Artificial\n\n\nO Chanceler do Reino Unido, Rishi Sunak, está considerando proibir a presença de funcionários chineses em cinquenta por cento da próxima Cúpula de Inteligência Artificial, devido a preocupações com segurança nacional. Essa medida reflete as crescentes tensões entre o Reino Unido e a China em relação a tecnologia e propriedade intelectual. Os detalhes da possível proibição ainda não foram finalizados. A Cúpula de Inteligência Artificial é um evento proeminente para a colaboração tecnológica global. [Leia mais](https://www.theguardian.com/technology/2023/sep/15/rishi-sunak-considers-banning-chinese-officials-from-half-of-ai-summit)\n\n\nA Amazon agora exige que os autores independentes divulguem qualquer envolvimento de IA em suas obras para aumentar a transparência no mundo da publicação digital. Essa medida surge em resposta às preocupações de que o mercado esteja sendo inundado com conteúdo gerado por IA. Essas novas regras afetarão a indústria de autopublicação na Amazon. [Leia mais](https://www.theguardian.com/books/2023/sep/11/self-publishers-must-declare-if-content-sold-on-amazons-site-is-ai-generated)\n\n\n\nPesquisas da Universidade de Columbia destacam preocupações sobre a confiabilidade da IA na tomada de decisões. O estudo descobriu que até mesmo modelos de linguagem avançados podem confundir absurdos com linguagem natural, levantando questões sobre precisão. Isso oferece uma oportunidade para melhorar o desempenho de chatbots e entender o processamento da linguagem humana. Ao estreitar a lacuna entre a IA e a ciência cognitiva, podemos criar assistentes alimentados por IA mais úteis e eficazes, que atendam melhor aos seus usuários. [Leia mais](https://www.sciencedaily.com/releases/2023/09/230914114704.htm)\n\n## Computação de borda\n\n\nO WebAssembly (Wasm) está prestes a revolucionar a computação de borda. Esta tecnologia permite a execução de código de diferentes linguagens em dispositivos de borda, proporcionando maior flexibilidade e desempenho. Ao reduzir a latência e possibilitar uma execução segura e eficiente, o Wasm pode transformar a forma como os aplicativos são implantados e executados na borda. Os desenvolvedores podem aproveitar o potencial do Wasm para criar soluções de computação de borda mais dinâmicas e responsivas, aprimorando diversas indústrias, como IoT e computação móvel. [Leia mais](https://www.infoworld.com/article/3703052/how-webassembly-will-transform-edge-computing.html)\n\n\n\nA corrida para mover IA para a borda está acelerando! A Cadence Design Systems revelou novas ferramentas de software de propriedade intelectual de IA (AI IP) que oferecem capacidades de descarregamento dos processadores hospedeiros. Essas ferramentas buscam otimizar cargas de trabalho de IA, melhorando o desempenho e a eficiência energética em dispositivos de borda. A tecnologia permite uma execução mais eficiente de tarefas de IA, tornando-a adequada para várias aplicações, incluindo IoT e computação de borda, onde a otimização de recursos é crucial. As ferramentas de software AI IP da Cadence podem ajudar a acelerar a adoção de IA em dispositivos de borda. [Leia mais](https://www.edgeir.com/cadences-new-ai-ip-software-tools-promises-offloading-abilities-from-any-host-processor-20230914)\n\n\n\nAs conferências de Edge Computing estão a todo vapor neste outono, com nada menos que sete grandes conferências em todo o mundo. Começando na última semana de setembro em Amsterdã, passando por Toronto, Dubai, Paris e Londres, apenas para citar alguns lugares. Tire a poeira de suas malas de viagem, pois este outono será agitado para as empresas de IoT. Você pode encontrar a lista completa em edgier.com. [Leia mais](https://www.edgeir.com/edge-computing-events)\n\n## Segurança cibernética\n\n\nO Centro de Resposta de Segurança da Microsoft identificou vulnerabilidades críticas na biblioteca de software de código aberto NCurses, utilizada em sistemas tipo Unix (Linux e iOS). Essas falhas podem permitir que invasores executem códigos maliciosos ou realizem ataques de negação de serviço. Os usuários são incentivados a atualizar suas instalações do NCurses para a versão mais recente a fim de mitigar possíveis riscos. As vulnerabilidades em bibliotecas amplamente utilizadas, como o NCurses, destacam a importância das atualizações regulares de segurança e da gestão de correções no ecossistema de software. [Leia mais](https://thehackernews.com/2023/09/microsoft-uncovers-flaws-in-ncurses.html)\n\n\nO site do Gerenciador de Download Gratuito (FDM), um site muito popular para software livre e de código aberto, foi comprometido, expondo os usuários a riscos potenciais. Os atacantes injetaram código malicioso no site, potencialmente afetando os usuários que baixaram o software entre onze e doze de setembro de dois mil e vinte e três. Esse vazamento enfatiza a importância de baixar software apenas de fontes confiáveis e atualizar regularmente o software de segurança para se proteger contra possíveis ameaças. O FDM tomou medidas para resolver o problema, mas os usuários devem permanecer vigilantes. [Leia mais](https://thehackernews.com/2023/09/free-download-manager-site-compromised.html)\n\n\nAttores estatais da nação iraniana têm supostamente empregado sofisticados ataques de spear-phishing para atingir indivíduos nos Estados Unidos, no Oriente Médio e na Ásia. Os ataques envolvem e-mails enganosos que se fazem passar por organizações respeitáveis, com o objetivo de entregar malware e roubar informações sensíveis. Especialistas em segurança enfatizam a necessidade de robustas medidas de segurança de e-mail e conscientização do usuário para se defender contra ameaças cibernéticas orquestradas por atores estatais. [Leia mais](https://thehackernews.com/2023/09/iranian-nation-state-actors-employ.html)\n\n## Abraçando a Transformação Digital\n\nEsta semana continua a série Abraçando a IA Gerativa com convidados falando sobre operacionalizar a IA gerativa no ambiente de trabalho, incluindo o uso dela para aprimorar a segurança e gerar relatórios em linguagem natural. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW33-pt","image":"./briefs/edw-33/pt/thumbnail.png","lang":"pt","summary":"Mantenha-se atualizado com as últimas notícias sobre transformação digital da semana de 17 de setembro de 2023. Obtenha as últimas atualizações sobre inteligência artificial, computação de borda e cibersegurança. Os destaques desta semana incluem a Microsoft descobrindo vulnerabilidades nos softwares de seus concorrentes, a implementação de requisitos de divulgação de IA pela Amazon e uma lista abrangente de próximas conferências de IoT neste outono."},{"id":201,"type":"News Brief","title":"2023-9-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Inteligência Artificial\n\n\nOs físicos estão desenvolvendo modelos generativos para IA usando equações físicas bem compreendidas. O Modelo Generativo de Fluxo de Poisson (PFGM), que representa dados com partículas carregadas, pode produzir imagens de alta qualidade de 10 a 20 vezes mais rápido do que modelos de difusão. Os pesquisadores visam explorar mais processos físicos e refinar o PFGM ajustando sua dimensionalidade. [Leia mais](https://www.quantamagazine.org/new-physics-inspired-generative-ai-exceeds-expectations-20230919/ )\n\n\nQue tal executar um chatbot no seu PC? A Intel anunciou um novo chip, esperado para dezembro, que permitirá que os laptops executem chatbots de inteligência artificial gerativa sem depender de centros de dados na nuvem. Essa capacidade, demonstrada em sua conferência de desenvolvedores de software, permite que empresas e consumidores testem tecnologias de IA como o ChatGPT sem enviar dados sensíveis para a nuvem. [Leia mais](https://www.reuters.com/technology/intel-says-newest-laptop-chips-software-will-handle-generative-ai-2023-09-19/)\n\n\nO crescimento da comunidade de código aberto está causando impacto no desenvolvimento de IA. Não é novidade em inovação, projetos de código aberto como Hadoop e Spark têm permitido que desenvolvedores avancem no desenvolvimento de IA desde a década de 1970. Modelos de IA generativos como ChatGPT e Llama 2 são construídos sobre fundamentos de código aberto, desafiando o status quo proprietário de programas de IA. Desenvolvedores continuarão a impulsionar os limites da IA fora dos limites do desenvolvimento comercial. [Leia mais](https://www.zdnet.com/article/why-open-source-is-the-cradle-of-artificial-intelligence/)\n\n## Computação Ubíqua\n\n\nA Intel lançou sua plataforma 'Developer Cloud' para desenvolvedores testarem e implantarem aplicativos de IA e computação de alto desempenho utilizando as mais recentes plataformas de hardware. Ela suporta treinamento de IA, otimização de modelos e cargas de trabalho de inferência, sendo baseada em software aberto com oneAPI, permitindo escolha de hardware e portabilidade de código. Outras tecnologias relacionadas à IA também foram introduzidas durante o anúncio. Qualquer pessoa pode se inscrever em cloud.intel.com. [Leia mais](https://ummid.com/news/2023/september/20-09-2023/intel-developer-cloud-reaches-general-availability.html)\n\n\nPara ajudar a reduzir as despesas místicas e dispendiosas de gerenciamento de dados, a WiMi Hologram Cloud desenvolveu um novo algoritmo de compressão de dados holográficos que aprimora a eficiência da computação em nuvem ao reduzir as necessidades de transmissão e armazenamento de dados. Estes avanços, juntamente com um protocolo distribuído de armazenamento de imagens, estão atendendo à crescente demanda por tecnologia holográfica avançada. Isso deve ajudar as organizações que sofrem com os custos de saída de dados na nuvem. [Leia mais](https://beststocks.com/wimi-hologram-cloud-revolutionizing-cloud-com/ )\n\n\nNo evento de Inovação 2023 da Intel, a empresa revelou uma CPU de 288 núcleos como parte da linha 'Sierra Forest' para servidores de alta densidade. Essa CPU contará com 144 núcleos em seus dois chiplets, totalizando 288 núcleos e threads. A Intel também confirmou que sua família Xeon de 5ª geração, 'Emerald Rapids', será lançada em 14 de dezembro, oferecendo melhorias de desempenho enquanto mantém o consumo de energia. A Intel enfatizou seu foco em aplicações de IA, com um supercomputador para tarefas de IA utilizando processadores Xeon e aceleradores de IA Gaudi2. [Leia mais](https://www.techspot.com/news/100221-intel-announces-288-core-sierra-forest-xeon-processor.html)\n\n## Segurança Cibernética\n\n\nO Spider Espalhado, um grupo habilidoso de hackers, está ganhando notoriedade por ataques de ransomware em empresas. Analistas sugerem que o grupo é composto em sua maioria por jovens de 17 a 22 anos de países ocidentais. Eles utilizam técnicas avançadas de engenharia social, como trocas de SIM, e táticas como \"SWATing\" para identificar pontos de acesso privilegiados. Embora seu objetivo possa não ser financeiro, seus ataques têm perturbado diversos setores e motivado investigações das autoridades policiais. [Leia mais](https://www.reuters.com/technology/power-influence-notoriety-gen-z-hackers-who-struck-mgm-caesars-2023-09-22/)\n\n\nUm relatório sobre as tendências de cibercrime na Índia revela um aumento nos ciberataques, incluindo phishing, malware e fraudes financeiras, sendo que a COVID-19 tem exacerbado a situação. Os resultados destacam a urgência de medidas de cibersegurança reforçadas, conscientização pública e colaboração entre as forças policiais e os setores privados para combater efetivamente as ameaças cibernéticas. A educação sobre as melhores práticas de cibersegurança também é enfatizada para proteger os indivíduos de tais ataques. [Leia mais](https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/)\n\n\nPara ajudar a combater a ameaça de segurança cibernética, o Microsoft Azure está tentando aumentar a segurança cibernética por meio da educação. O Azure recentemente anunciou mais de sessenta horas de cursos gratuitos sobre segurança cibernética, incluindo segurança híbrida de nuvem, configuração de firewall, gerenciamento de patches, gerenciamento de diretório ativo e tecnologias de criptografia, para citar alguns. Você pode obter mais informações em learn.microsoft.com. [Leia mais](https://www.helpnetsecurity.com/2023/09/20/free-microsoft-azure-cybersecurity-resources/)\n\n## Abraçando a Transformação Digital\n\nEsta semana começa uma nova série sobre Construção de uma Estratégia de Nuvem com arquitetos de soluções em nuvem da Intel. Darren entrevista especialistas da Intel em migração para nuvem, gestão de custos em nuvem e avaliação de carga de trabalho. Confira as últimas novidades no podcast Abraçando a Transformação Digital. [Leia mais](https://www.embracingdigital.org)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW34-pt","image":"./briefs/edw-34/pt/thumbnail.png","lang":"pt","summary":"Notícias sobre Transformação Digital para 24 de setembro de 2023 incluem inteligência artificial, computação ubíqua e cibersegurança. Ouça sobre os novos CPUs da Intel que estão mudando a IA e a computação de alta densidade, e como um grupo de hackers adolescentes derrubou os cassinos da MGM em Las Vegas."},{"id":202,"type":"News Brief","title":"2023-9-30","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","datasciencesolution","polystores","dataarchitecture","aichatbots","cybersecurityawareness","aisecuritycenter","googlechrome","mozillafirefox","digitaltransformationpodcast","intelcloudsolutionarchitects"],"body":"\n\n## Gestão de Dados\n\nA solução de ciência de dados BMLL Vantage foi honrada com o prêmio de 'Melhor Solução de Ciência de Dados' no Data Management Insight Awards. Esta conquista celebra o trabalho excepcional do BMLL Vantage em ciência de dados, reconhecendo suas contribuições significativas para a indústria. [Leia mais](https://mondovisione.com/media-and-resources/news/bmll-vantage-wins-best-data-science-solution-at-the-data-management-insight-aw/)\n\nPolystores integram diversas fontes de dados perfeitamente, quebrando barreiras e permitindo análises interfuncionais. Eles otimizam o desempenho ao aproveitar as diferentes capacidades dos bancos de dados e se adaptam às tecnologias em evolução. As organizações devem utilizar polystores para desbloquear o potencial de dados para tomar decisões informadas na era dos dados volumosos. [Leia mais](https://thenewstack.io/polystores-the-data-management-game-changer/)\n\n\nAo decidir sobre uma arquitetura de dados, é essencial considerar fatores como tamanho dos dados, frequência, localização da fonte, tipo, privacidade, acesso e urgência. Compreender os diferentes tipos de arquiteturas e suas utilizações pode ajudá-lo a se adaptar às mudanças nas demandas dos negócios e condições ambientais, e escolher a melhor solução para sua empresa. Considerando esses fatores, tem sido comprovado que melhora as habilidades de tomada de decisão dos arquitetos de sistemas. [Leia mais](https://www.intel.com/content/www/us/en/content-details/789953/content-details.html)\n\n## Inteligência Artificial\n\n\nMark Zuckerberg revelou um conjunto de chatbots de IA na Meta Connect dois mil e vinte e três, incluindo um com o rapper Snoop Dogg como Mestre de Jogo em um jogo de interpretação de personagens chamado D&D. Esses bots, modelados a partir de celebridades, não estão disponíveis ao público. A Meta AI é a principal assistente de chatbot, construída em um modelo de linguagem feito sob medida semelhante ao ChatGPT da OpenAI, priorizando estilo visual em vez de imitar padrões de conversa. Os planos incluem adicionar capacidades de voz. [Leia mais](https://kotaku.com/meta-quest-3-ai-chatgpt-snoop-dogg-facebook-chatbot-1850882666)\n\n\nO primeiro-ministro israelense Netanyahu alerta sobre os potenciais perigos da revolução da IA, como interrupções à democracia, manipulação da mente, perda de empregos e guerras impulsionadas pela IA. Ele insta as nações a abordarem essas preocupações e impedirem que máquinas autoaprendidas controlem os seres humanos. No entanto, ele também reconhece os aspectos positivos da IA, como assistência robótica para idosos e transporte melhorado. Israel busca ser um líder global em IA. [Leia mais](https://www.foxnews.com/world/netanyahu-warns-potential-eruption-ai-driven-wars-lead-unimaginable-consquences)\n\n\nUm funcionário da OpenAI, Lilian Weng, compartilhou sua experiência emocional usando o modo de voz do ChatGPT para uma conversa pessoal sobre estresse e equilíbrio entre trabalho e vida. Embora Weng tenha achado a interação reconfortante, isso levanta preocupações sobre o papel da IA na prestação de terapia. Isso reflete uma tendência em que a IA busca parecer mais humana, mas tem enfrentado desafios, como visto com experimentos anteriores de terapia por IA que receberam respostas mistas e, em alguns casos, causaram danos. Considerações éticas são cruciais ao integrar a IA em contextos de saúde mental. [Leia mais](https://fortune.com/2023/09/28/generative-ai-cfos-company-strategy/)\n\n## ## Cibersegurança\n\n\nOutubro marca o vigésimo Mês de Conscientização em Cibersegurança para promover a segurança online. O tema deste ano é \"Segure Nosso Mundo.\" Ele se concentra em quatro melhores práticas críticas de cibersegurança: usar um gerenciador de senhas, implementar autenticação multifator, reconhecer e denunciar tentativas de phishing, e instalar regularmente atualizações. A iniciativa tem como objetivo fornecer informações para ajudar indivíduos a se manterem mais seguros online. [Leia mais](https://www.ktsm.com/local/octobers-cybersecurity-awareness-month-2023/)\n\n\nA Agência de Segurança Nacional dos EUA criou um centro de segurança de IA para supervisionar a IA nos serviços de defesa e inteligência. O diretor, General Paul Nakasone, enfatizou a importância de manter os EUA na vanguarda da IA e evitar que atores estrangeiros roubem as inovações americanas. O centro promoverá a adoção segura da IA nas indústrias de segurança nacional e defesa. A IA terá um papel significativo na segurança nacional, diplomacia, tecnologia e economia. [Leia mais](https://www.aljazeera.com/news/2023/9/29/us-national-security-agency-unveils-artificial-intelligence-security-centre)\n\n\nFoi encontrada uma nova questão de segurança nos navegadores Google Chrome e Mozilla Firefox. Isso poderia afetar outros programas também. Chama-se \"StrangeU\". Hackers poderiam utilizá-lo para controlar seu computador. As empresas corrigiram o problema, mas outros programas ainda podem estar em risco. Mantenha todos os seus softwares atualizados e fique atento a questões semelhantes em outros aplicativos. Mantenha-se seguro! [Leia mais](https://arstechnica.com/security/2023/09/new-0-day-in-chrome-and-firefox-is-likely-to-plague-other-software/)\n\n## Abraçando o Podcast de Transformação Digital\n\nEsta semana continua a série sobre arquiteturas de nuvem multi-híbrida com entrevistas adicionais dos arquitetos de soluções em nuvem da Intel. Para ouvir estas entrevistas de 30 minutos, você pode encontrá-las abraçando a transformação digital em seus sites de podcast favoritos. [Leia mais](https://www.embracingdigital.org/episode-EDT163)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW35-pt","image":"./briefs/edw-35/pt/thumbnail.png","lang":"pt","summary":"Notícias de transformação digital para a semana de 1º de outubro, incluindo histórias sobre gerenciamento de dados, inteligência artificial e segurança cibernética. Venha ouvir a celebração do mês de conscientização em segurança cibernética, uma IA que transforma Snoop Dogg em mestre de calabouço de D&D, e saiba mais sobre uma nova arquitetura de dados chamada Polystore."},{"id":203,"type":"News Brief","title":"2023-10-7","tags":["ai","edge","cybersecurity","precrime","aihealcare","mgmbreach","scatteredspider","aplhav","aiethics","convergeditot","iot","criticalinfrastructure"],"body":"\n\n## Cibersegurança\n\n\nEm 5 de outubro, a MGM Resorts International anunciou que ocorreu uma violação de dados e um ataque de ransomware, causando interrupções e resultando em uma perda de cem milhões de dólares durante o terceiro trimestre. Os grupos de hackers AlphaV e Scattered Spider reivindicaram a responsabilidade pela violação, na qual alegadamente roubaram dados do sistema da MGM e os mantiveram para extorsão. [Leia mais](https://www.reuters.com/business/mgm-expects-cybersecurity-issue-negatively-impact-third-quarter-earnings-2023-10-05/)\n\n\nA SecurityWeek relatou a descoberta de firmware com porta dos fundos em dispositivos Android usados por escolas nos EUA. Pesquisadores identificaram vulnerabilidades em laptops e tablets distribuídos para instituições educacionais, o que poderia potencialmente expor dados sensíveis dos alunos a ameaças cibernéticas. O firmware comprometido poderia permitir que cibercriminosos acessem e manipulem os dispositivos remotamente se explorados. [Leia mais](https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/)\n\n\nNo contexto do Mês de Conscientização sobre Segurança Cibernética de 2023, destaca-se na SC Media que é necessário mais do que apenas promover a conscientização sobre segurança cibernética. A SC Media convoca as organizações a aumentarem a troca de informações sobre ataques cibernéticos e as melhores práticas de segurança cibernética, e desmistifica os mitos de compartilhamento de informações valiosas em toda a indústria de Segurança Cibernética. [Leia mais](https://www.scmagazine.com/perspective/cybersecurity-awareness-month-2023-why-we-need-more-than-just-cybersecurity-awareness)\n\n## Inteligência Artificial\n\n\nDe acordo com o relatório \"Liberdade na Internet\" de 2023 da Freedom House, governos em todo o mundo estão utilizando a inteligência artificial para vigilância e censura. A China está liderando a utilização da inteligência artificial para censura. Isso destaca a necessidade de equilibrar o avanço tecnológico com a proteção dos direitos individuais e das liberdades digitais. O relatório destaca a necessidade de esforços globais para salvaguardar a liberdade digital das pessoas. [Leia mais](https://gizmodo.com/freedom-house-2023-freedom-on-the-net-report-ai-1850887842)\n\n\nUm artigo recente publicado na Nature discute pesquisa sobre a utilização de algoritmos de inteligência artificial para prever e gerenciar crises epilépticas. O estudo apresenta resultados promissores na previsão precisa de crises em um grupo de pacientes, oferecendo potencial para um manejo mais eficaz das crises e melhorias nos resultados dos pacientes. A previsão de crises guiada por inteligência artificial pode significativamente melhorar a qualidade de vida de pessoas que convivem com epilepsia e reduzir os riscos associados. [Leia mais](https://www.nature.com/articles/s41746-023-00931-7)\n\n\nDe acordo com um relatório da NBC Bay Area, um professor da UC Berkeley está sendo pioneiro no uso da inteligência artificial (IA) para combater a violência doméstica. O professor está desenvolvendo algoritmos de IA para analisar posts nas redes sociais e mensagens de texto em busca de sinais de abuso doméstico, com o objetivo de fornecer intervenção precoce e suporte às vítimas. Essa aplicação inovadora da tecnologia de IA tem o potencial de causar um impacto significativo na identificação e abordagem de questões relacionadas à violência doméstica na era digital. Parece ser o começo do Pré-Crime na área da Baía! [Leia mais](https://www.nbcbayarea.com/news/local/uc-berkeley-professor-artificial-intelligence-domestic-violence/3336053/)\n\n## Computação na borda\n\n\nOs pesquisadores estão emitindo um aviso sobre a exposição de aproximadamente cem mil sistemas de controle industrial (SCI) na internet, de acordo com o BleepingComputer. Essa descoberta alarmante levanta preocupações sobre possíveis ciberataques em infraestruturas críticas e instalações de fabricação. Os dispositivos SCI expostos representam um risco significativo para a segurança, destacando a necessidade urgente de medidas aprimoradas de cibersegurança para proteger infraestruturas críticas de ameaças e ataques potenciais. [Leia mais](https://www.bleepingcomputer.com/news/security/researchers-warn-of-100-000-industrial-control-systems-exposed-online/)\n\n\nConforme discutido em um relatório sobre o Jogo É Difícil, a computação de borda está surgindo como uma alternativa notável para a predominância da NVIDIA no mercado de chips de IA. Com o surgimento da computação de borda, mais empresas estão explorando soluções de chips de IA adequadas para processamento local e análise de dados em tempo real. Essa tendência reflete o cenário em evolução da tecnologia de IA e a competição no mercado, oferecendo potencialmente novas opções e inovações para várias indústrias além do tradicional domínio da NVIDIA. [Leia mais](https://gameishard.gg/news/the-rise-of-edge-computing-an-alternative-to-nvidias-dominance-in-the-ai-chip-market/282141/)\n\n\nO artigo do Forbes Tech Council explora como a AI Generativa aborda as lacunas de habilidades na convergência da TI industrial e tecnologia operacional (IoT). Ao automatizar tarefas, analisar dados e otimizar processos, a AI Generativa está ajudando a preencher a lacuna entre esses domínios tradicionalmente separados. Essa aplicação inovadora da tecnologia de IA tem o potencial de aprimorar a eficiência e produtividade em ambientes industriais, permitindo uma integração e operação mais suaves dos sistemas de TI e IoT. [Leia mais](https://www.forbes.com/sites/forbestechcouncil/2023/10/04/how-generative-ai-fills-skills-gaps-for-industrial-itot-convergence/)\n\n## Abraçando as notícias da Transformação Digital\n\nEsta semana, Darren lança o último episódio da série Abraçando a Multi-Hybrid Cloud focada na melhoria contínua no operacionalizar de uma estratégia em nuvem. Ouça em qualquer plataforma de podcast em Abraçando a Transformação Digital. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW36-pt","image":"./briefs/edw-36/pt/thumbnail.png","lang":"pt","summary":"Receba as últimas notícias sobre Transformação Digital para a semana de 8 de outubro de 2023. Os destaques desta semana incluem um relatório sobre a perda de $100 milhões da MGM Resorts devido a um ataque cibernético, como a IA está sendo usada para auxiliar vítimas de violência doméstica e o impacto da computação Edge nos centros de dados de IA. Sintonize-se para se manter informado."},{"id":204,"type":"News Brief","title":"2023-10-14","tags":["compute","edge","israelcyberattacks","hamasconflict","redalertsystemapp","powerplantcyberthreats","generativeai","cloudmigration","cmauk","publiccloudinvestigation","avoslocker","ransomeware","criticalinfrastructure","ecybersecurity","embracingdigital","edw37","zerotrustarchitecture"],"body":"\n\n## ## Cibersegurança\n\n\nIsrael enfrenta ciberataques durante o conflito com o Hamas. O aplicativo 'Red Alert System' foi comprometido para enviar alertas falsos e mensagens políticas. As usinas de energia israelenses também foram afetadas. O CEO da Secure Cyber Defense, Shawn Waldman, adverte sobre ameaças cibernéticas em curso, ressaltando informações recentes sobre atores estrangeiros visando a infraestrutura crítica dos EUA. Ele enfatiza a necessidade de progresso contínuo na cibersegurança. [Leia mais](https://www.wdtn.com/as-seen-on-2-news/israeli-cyberwarfare-cyberattacks-infrastructure/)\n\n\nIsrael e Palestina viram um aumento no tráfego da internet após Israel declarar guerra ao Hamas em sete de outubro de dois mil e vinte e três. Os dados da Cloudflare revelam que os ciberataques direcionados a Israel aumentaram, incluindo ataques DDoS em jornais israelenses. Na Palestina, foram observadas interrupções na internet, possivelmente relacionadas a quedas de energia. A Cloudflare está monitorando essas tendências e oferece ferramentas para rastrear padrões de tráfego na internet. [Leia mais](https://blog.cloudflare.com/internet-traffic-patterns-in-israel-and-palestine-following-the-october-2023-attacks/)\n\n\nOs ataques de ransomware estão se tornando mais sofisticados, com dispositivos de rede sendo cada vez mais explorados para entrega. As Informações Protegidas de Saúde no setor da saúde são um alvo principal. Organizações de alto rendimento, especialmente nos EUA, são alvos preferidos. Novos grupos estão surgindo, e linguagens como Rust e GoLang estão sendo adotadas. As organizações estão aprimorando medidas de cibersegurança, e a Visão Cyble é recomendada para se manter à frente das ameaças de ransomware. [Leia mais](https://thehackernews.com/2023/10/ransomware-attacks-doubled-year-on-year.html)\n\n## ## Edge Computing\n\nComputação de Borda\n\n\nA gangue de ransomware AvosLocker foi implicada em ataques contra setores de infraestrutura crítica nos EUA. Suas táticas incluem o uso de software legítimo e ferramentas de administração remota de código aberto para comprometer redes, seguidas por ameaças de extorsão de dados. O AvosLocker surgiu no meio de 2021 e emprega técnicas para desativar a proteção antivírus, afetando ambientes Windows, Linux e VMware ESXi. O grupo é conhecido por usar ferramentas de código aberto e táticas de \"living-off-the-land\" (LotL) para evitar atribuição. CISA e o FBI recomendam medidas de mitigação para organizações de infraestrutura crítica, incluindo controles de aplicação, limitação de serviços de desktop remoto, restrição do uso do PowerShell e manutenção de backups offline. Os ataques de ransomware aumentaram rapidamente em 2023, com os atacantes implantando ransomware logo após o acesso inicial. [Leia mais](https://thehackernews.com/2023/10/fbi-cisa-warn-of-rising-avoslocker.html)\n\n\nA NSA lançou ELITEWOLF, um repositório de assinaturas e análises em seu GitHub, para aumentar a segurança da Tecnologia Operacional (OT) e combater atividades cibernéticas maliciosas direcionadas à infraestrutura crítica. Diante da crescente ameaça aos sistemas OT, a NSA recomenda que os proprietários e operadores de infraestrutura OT usem ELITEWOLF como parte da monitoração vigilante do sistema. Esta iniciativa segue o Aviso de Segurança Cibernética para Proteger Tecnologias Operacionais e Sistemas de Controle contra Ataques Cibernéticos. [Leia mais](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3554537/nsa-releases-a-repository-of-signatures-and-analytics-to-secure-operational-tec/)\n\n\nA NATO prometeu responder firmemente a qualquer ataque deliberado confirmado à infraestrutura crítica do Mar Báltico. A promessa surge na sequência dos danos causados à infraestrutura subaquática na região. A Finlândia está investigando o incidente, que pode ter envolvido forças externas, incluindo a Rússia. Se for comprovado que se trata de um ataque deliberado à infraestrutura crítica da NATO, a organização responderá com um esforço unido e determinado. [Leia mais](https://news.yahoo.com/attack-alliances-critical-infrastructure-deliberate-073708273.html)\n\n## Tecnologia de Nuvem\n\n\nA inteligência artificial generativa reduz os esforços de migração para a nuvem em trinta a cinquenta por cento, aproveitando modelos de linguagem grandes. Os modelos de linguagem grandes podem avaliar infraestrutura, transferir cargas de trabalho e verificar a eficácia da migração. Bhargs Srivathsan, da McKinsey, observou que a inteligência artificial generativa e a nuvem são mutuamente benéficas, já que a nuvem possibilita a inteligência artificial generativa, que por sua vez acelera a migração para a nuvem. Os modelos de linguagem grandes podem ser utilizados para geração de conteúdo, engajamento de clientes, criação de dados sintéticos e codificação. [Leia mais](https://www.theregister.com/2023/10/11/generative_ai_cloud_migration/)\n\n\nAs empresas com soluções de tecnologia locais enfrentam interrupções ao migrar para a nuvem completa. Para enfrentar esse desafio, a abordagem de Nuvem Híbrida permite que as empresas mantenham serviços essenciais no local. Essa abordagem adiciona novas capacidades em nuvem à infraestrutura legada, reduzindo interrupções e preservando tecnologias testadas e comprovadas. Por exemplo, uma Nuvem Híbrida pode ser usada nas operações de um centro de contato para adicionar canais digitais como bate-papo e redes sociais à infraestrutura existente, permitindo que as organizações lidem com flutuações no volume de chamadas sem interrupções significativas. [Leia mais](https://www.techradar.com/pro/why-businesses-should-stop-wondering-about-cloud-and-go-hybrid)\n\n\nA Autoridade de Concorrência e Mercados do Reino Unido (CMA) investiga o mercado de nuvem pública para garantir a concorrência justa para empresas e indivíduos. A investigação analisará as operações de provedores como AWS, Microsoft Azure e Google Cloud para lidar com preocupações sobre comportamento anticompetitivo, uso de dados e barreiras à entrada. A CMA visa incentivar a inovação, oferecer preços competitivos e proporcionar escolha aos clientes. [Leia mais](https://www.techrepublic.com/article/cma-investigates-uk-public-cloud-market/)\n\n## ## Podcast de Abraçando a Transformação Digital\n\n\n\nNo episódio desta semana do Podcast Embracing Digital Transformation, Darren entrevista Rachel Driekosen sobre como a inteligência artificial está sendo usada para proteger crianças online e levar os culpados à justiça. Fique ligado para uma próxima série sobre Arquitetura de Confiança Zero nas próximas semanas. [Leia mais](https://www.embracingdigital.org/episode-EDT167-en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW37-pt","image":"./briefs/edw-37/pt/thumbnail.png","lang":"pt","summary":"Transformação Digital desta Semana para 15 de outubro de 2023, relata ataques cibernéticos contínuos durante o conflito entre Israel e Hamas e a comprometimento do aplicativo 'Red Alert System'. Além disso, a IA gerativa tem  mostrado reduzir os esforços de migração para a nuvem enquanto a CMA do Reino Unido investiga o mercado de nuvem pública."},{"id":205,"type":"News Brief","title":"2023-10-21","tags":["keywords","ai","compute","cybersecurity","iranianhackers","cybersecuritybreach","ironnetclosure","secretmicrosoft365","cloudtrends","healthcareai","chinachipexports","openai","digitalnews","ubiquitouscomputing","digitaltransformation","dataencryption","aiethics","techindustry","emergingtech","intelinterview","aistrategies","quantumcomputing","datasecurity","techtrends"],"body":"\n\n## Cibersegurança\n\n\nHackers iranianos conseguiram infiltrar-se em uma rede de governo do Oriente Médio e permanecer ocultos por oito meses antes de serem descobertos. O ataque afetou várias agências, e a extensão dos danos ainda está sendo avaliada. Especialistas estão investigando o incidente e enfatizando a necessidade de medidas fortes de cibersegurança para se proteger contra futuros ataques. A violação serve como um lembrete da importância de priorizar a cibersegurança em nosso mundo digital cada vez mais crescente. [Leia mais](https://www.securityweek.com/iranian-hackers-lurked-for-8-months-in-government-network/)\n\n\nO Distrito Escolar do Condado de Clark, no estado de Nevada, teve que recorrer a atribuições feitas com caneta e papel após um ataque de ransomware interromper seus recursos digitais. O distrito está trabalhando para resolver o problema e destacando a necessidade de cibersegurança para proteger a infraestrutura educacional contra ameaças cibernéticas. [Leia mais](https://thenevadaindependent.com/article/clark-county-students-back-to-pen-and-paper-assignments-after-cybersecurity-breach)\n\n\nA IronNet, uma antiga empresa de cibersegurança unicórnio, encerrou suas atividades após enfrentar desafios de financiamento e competição de mercado. A indústria de cibersegurança ainda está em fase de crescimento e precisando se adaptar às ameaças e pressões econômicas em constante mudança, ressaltando a necessidade de resiliência e inovação. [Leia mais](https://www.scmagazine.com/news/more-cybersecurity-firm-closures-expected-after-ironnet-shutters)\n\n## Computação Ubíqua\n\n\nO Pentágono está implementando uma versão secreta do Microsoft 365, chamada DOD365-Secret, para fortalecer as capacidades de defesa nacional. O novo serviço fornecerá ferramentas de comunicação e colaboração seguras, e está sendo testado pela Defense Information Systems Agency (DISA) nos últimos doze meses. Essa medida destaca o compromisso do governo em aprimorar a cibersegurança e a proteção de dados, especialmente em ambientes militares sensíveis. [Leia mais](https://federalnewsnetwork.com/on-dod/2023/10/secret-level-version-of-microsoft-365-rolls-out-to-top-pentagon-offices-this-month/)\n\n\nA Forbes prevê dez grandes tendências de computação em nuvem que moldarão a indústria em 2024. Essas tendências incluem computação em borda, cibersegurança, computação sem servidor, integração de IA, adoção híbrida e multinuvem, práticas sustentáveis de nuvem, computação quântica, análise de dados e desenvolvimento nativo de nuvem. É importante que empresas e profissionais de TI fiquem atualizados com essas tendências para navegar no cenário em constante evolução da nuvem. [Leia mais](https://www.forbes.com/sites/bernardmarr/2023/10/09/the-10-biggest-cloud-computing-trends-in-2024-everyone-must-be-ready-for-now/?sh=2093527266d6)\n\n## Inteligência Artificial\n\n\nO Dia Q está a caminho. Computadores quânticos poderiam em breve se tornar poderosos o suficiente para quebrar os algoritmos de encriptação que protegem nossas informações digitais hoje em dia. Isso ameaça a segurança dos dados, então governos e empresas de tecnologia estão investindo em encriptação e tecnologia resistente à quântica para se protegerem disso.A Organização Mundial de Saúde (OMS) delineou considerações para regulamentar a inteligência artificial (IA) no setor de saúde, de acordo com seu anúncio em dezenove de outubro de dois mil e vinte e três. Essa orientação enfatiza a importância da ética, transparência, privacidade de dados e responsabilidade nas aplicações de IA para a saúde. Ela aborda o crescente papel da IA na saúde e a necessidade de um quadro que garanta o seu uso responsável e ético. [Leia mais](https://www.who.int/news/item/19-10-2023-who-outlines-considerations-for-regulation-of-artificial-intelligence-for-health)\n\n\nO The New York Times relata sobre as restrições da China à exportação de chips de IA. Essas restrições visam preservar a segurança nacional e a independência tecnológica, impactando as cadeias de suprimentos globais de tecnologia. À medida que a IA desempenha um papel cada vez mais importante em vários setores, essa medida reflete os esforços da China para afirmar seu controle sobre tecnologia avançada e levanta preocupações sobre a dinâmica do comércio global de tecnologia. [Leia mais](https://www.nytimes.com/2023/10/17/business/economy/ai-chips-china-restrictions.html)\n\n\nDe acordo com o jornal online The Information, a OpenAI supostamente interrompeu o desenvolvimento de um novo modelo de IA chamado \"Arrakis\", marcando um raro contratempo para a organização. A decisão sugere as complexidades e desafios de desenvolver modelos avançados de IA e destaca a importância da pesquisa e desenvolvimento responsável e ético em IA. [Leia mais](https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback)\n\n## Abraçando as Notícias do Podcast de Transformação Digital\n\nNa sua série Abraçando a IA Generativa, Darren apresenta uma entrevista com Andy Morris, estrategista principal de IA da Intel. A entrevista mergulha no tópico da IA generativa diária e explora várias ferramentas que podem ser úteis para as pessoas em suas vidas diárias. É uma conversa informativa que lança luz sobre o impacto da IA em nossas vidas diárias e como podemos aproveitá-la para nosso benefício. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW38-pt","image":"./briefs/edw-38/pt/thumbnail.png","lang":"pt","summary":"Abraçando as notícias digitais da semana de 22 de outubro de 2023, incluindo notícias sobre cibersegurança, computação ubíqua e inteligência artificial. Os destaques desta semana incluem voltar ao papel e caneta nas distribuições escolares, ficar atento ao Dia Q e diretrizes de IA na área da saúde."},{"id":206,"type":"News Brief","title":"2023-10-28","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Cibersegurança\n\n\nA Kaspersky relata sobre um novo malware, apelidado de \"Elegante\", que possui avançadas capacidades de espionagem e apresenta semelhanças com as ferramentas de hacking vinculadas à NSA. A empresa de cibersegurança não atribuiu o malware a um ator de ameaça específico, mas sua descoberta destaca a necessidade de medidas robustas de cibersegurança diante de ciberataques patrocinados pelo estado. [Leia mais](https://cyberscoop.com/kaspersky-reveals-elegant-malware-resembling-nsa-code/)\n\n\n\nA CISA e o HHS lançaram uma caixa de ferramentas de cibersegurança para organizações de saúde. A caixa de ferramentas tem como objetivo melhorar a postura de cibersegurança da indústria, oferecendo recursos valiosos e orientações para mitigar ameaças cibernéticas. O objetivo é fortalecer a segurança da infraestrutura crítica de saúde, dada a crescente número de riscos cibernéticos e ataques de ransomware em hospitais recentemente. Saiba mais na página de notícias do CISA. [Leia mais](https://www.cisa.gov/news-events/news/cisa-hhs-release-collaborative-cybersecurity-healthcare-toolkit)\n\n\nA Califórnia implementou novas regulamentações de cibersegurança, incluindo avaliações de risco, planos de resposta a incidentes, criptografia de dados e autenticação de múltiplos fatores. É fundamental para as empresas na Califórnia cumprirem, pois a não conformidade pode resultar em penalidades e ramificações legais. Mantenha-se informado(a) verificando as atualizações no site de Cibersegurança da Califórnia. [Leia mais](https://www.armstrongteasdale.com/thought-leadership/californias-newest-cybersecurity-rule-what-you-need-to-know/)\n\n## Computação de Borda\n\n\nO Parlamento do Reino Unido está investigando a cibersegurança da infraestrutura crítica, incluindo energia, transporte e saúde. A investigação tem como objetivo avaliar a prontidão e a resiliência desses setores em relação a possíveis ameaças cibernéticas. Essa medida surge em meio a preocupações crescentes com a vulnerabilidade dos serviços essenciais a ataques cibernéticos. Isso destaca a importância de proteger serviços vitais contra ameaças digitais em um mundo interconectado. O recente conflito entre Israel e Hamas ressalta a necessidade de proteger a infraestrutura crítica contra ameaças cibernéticas. [Leia mais](https://www.bankinfosecurity.com/uk-parliament-probes-critical-infrastructure-cybersecurity-a-23400)\n\n\nA Tenable e a Siemens Energy estão se unindo para aprimorar a cibersegurança industrial. A colaboração irá combinar a expertise da Tenable em cibersegurança com o conhecimento de domínio da Siemens Energy para fornecer soluções avançadas de segurança para infraestrutura crítica. O objetivo é fortalecer a proteção dos sistemas de energia essenciais contra ameaças cibernéticas em evolução. A importância de proteger infraestruturas críticas em um mundo cada vez mais interconectado não pode ser superestimada. [Leia mais](https://finance.yahoo.com/news/tenable-siemens-energy-expand-collaboration-130000076.html)\n\n\nOs bancos de Singapura DBS e Citibank sofreram uma interrupção no serviço devido a uma falha no sistema de resfriamento do seu centro de dados compartilhado. O incidente interrompeu os serviços bancários e causou inconveniente aos clientes. Tais incidentes destacam a importância de uma infraestrutura robusta de centro de dados para serviços financeiros ininterruptos. Os bancos já restabeleceram os serviços, enfatizando o papel crítico da tecnologia nas operações bancárias modernas. [Leia mais](https://www.channelnewsasia.com/singapore/dbs-citibank-outage-data-centre-cooling-system-down-3861076)\n\n## Computação Ubíqua\n\n\nA Amazon lançou um serviço de nuvem independente para a Europa, visando atender às crescentes preocupações com privacidade de dados e requisitos regulatórios. O novo serviço de nuvem tem como objetivo fornecer soberania de dados e segurança aprimorada aos clientes europeus, permitindo que as organizações aproveitem a computação em nuvem de maneira mais localizada e em conformidade. [Leia mais](https://www.euronews.com/next/2023/10/25/amazon-rolls-out-new-independent-cloud-for-europe)\n\n\nOs Estados Unidos e a Austrália estão colaborando no desenvolvimento de chips quânticos avançados. Essa parceria destaca a crescente importância da computação quântica na segurança nacional e no avanço tecnológico. À medida que os países buscam manter sua liderança nessa área crítica de pesquisa e desenvolvimento, iniciativas conjuntas como essas estão se tornando mais comuns. A colaboração demonstra a intensificação da cooperação entre os dois aliados na ciência e tecnologia. [Leia mais](https://foreignpolicy.com/2023/10/25/quantum-computing-united-states-australia-cooperation-allies-science-technology-chips/)\n\n\nUm relatório recente descobriu que quarenta por cento das empresas estão perdendo receita devido a tempo de inatividade tecnológica e gerenciamento de serviços em nuvem. Isso destaca a importância de uma infraestrutura de TI robusta e de um gerenciamento simplificado em nuvem. Resolver o tempo de inatividade e simplificar as operações em nuvem é fundamental para garantir operações comerciais ininterruptas e maximizar a receita. Leia mais no relatório em notícias de computação em nuvem. [Leia mais](https://www.cloudcomputing-news.net/news/2023/oct/24/40-of-firms-lose-revenue-from-technology-downtime-and-cloud-complexity/)\n\n## Podcast de Abraçando a Transformação Digital\n\nUma nova série chamada \"Abraçando a Confiança Zero\" começa esta semana. A Doutora Anna Scott e Dave Marcus, que são convidados especiais, irão descrever os seis pilares da Confiança Zero e como eles podem ser utilizados na infraestrutura existente. Enquanto isso, \"Abraçando a IA Generativa\" de Darren continua com Sunny Stueve, uma especialista em Fatores Humanos da Leidos. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW39-pt","image":"./briefs/edw-39/pt/thumbnail.png","lang":"pt","summary":"Na última edição do nosso Embracing Digital This Week, trazemos para você as últimas novidades e histórias no mundo da cibersegurança, computação de borda e computação ubíqua. Neste episódio, abordamos um novo malware chamado Elegant, regulamentações de cibersegurança na Califórnia, a investigação do Parlamento do Reino Unido sobre a cibersegurança da infraestrutura crítica e outras notícias interessantes da indústria de tecnologia."},{"id":207,"type":"News Brief","title":"2023-2-26","tags":null,"body":"\n\n## Inteligência Artificial\n\nA OpenAI e a Bain & Company formaram a Global AI Services Alliance para transformar o potencial de negócios. A Bain combinará suas profundas capacidades de implementação digital e sua expertise estratégica com as ferramentas e plataformas de IA da OpenAI, incluindo o ChatGPT, para ajudar seus clientes em todo o mundo a identificar e implementar o valor da IA para maximizar o potencial de negócios. A The Coca-Cola Company é a primeira empresa a se envolver com a nova aliança.\n\nA unidade de nuvem da Amazon se associou à Hugging Face, a criadora do rival do ChatGPT. A Hugging Face construirá a próxima versão de seu modelo de linguagem, chamado BLOOM, na AWS. \n\nTranslation: A unidade de nuvem da Amazon se associou à Hugging Face, a criadora do rival do ChatGPT. A Hugging Face construirá a próxima versão de seu modelo de linguagem, chamado BLOOM, na AWS.\n\n[https://www.seattletimes.com/business/amazons-cloud-unit-partners-with-hugging-face-maker-of-chatgpt-rival/](https://www.seattletimes.com/business/amazons-cloud-unit-partners-with-hugging-face-maker-of-chatgpt-rival/)\n\nA IA também pode ser usada para fazer o bem no mundo. A IA está imaginando remédios que ninguém jamais viu. Agora precisamos ver se eles funcionam. Os primeiros medicamentos projetados com a ajuda da IA estão agora em testes clínicos, os testes rigorosos feitos em voluntários humanos para ver se um tratamento é seguro e funciona antes que os reguladores os aprovem para uso generalizado.\n\n[https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development](https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development)\n\n## Borda Inteligente\n\nForam encontradas vulnerabilidades de segurança em dispositivos IoT industriais sem fio de quatro fornecedores, criando uma superfície de ataque significativa para atores de ameaças que procuram explorar ambientes de tecnologia operacional (OT). As falhas oferecem pontos de entrada de ataque remoto, permitindo que adversários não autenticados obtenham uma posição e usem como alavanca para se espalhar para outros hosts, causando assim danos graves.\n\n[https://thehackernews.com/2023/02/critical-infrastructure-at-risk-from.html](https://thehackernews.com/2023/02/critical-infrastructure-at-risk-from.html)\n\nA Aliança de Padrões de Conectividade (CSA) formou um grupo de trabalho dedicado a promover a adoção do \"Matter\" para fins de saúde. O Matter é um padrão interoperável para dispositivos inteligentes domésticos lançado pela CSA no ano passado. O Grupo de Trabalho de Saúde e Bem-Estar alinhará os principais contribuintes da indústria de saúde ao redor do padrão Matter para garantir dispositivos seguros e interoperáveis de saúde e bem-estar.\n\n[https://www.iottechnews.com/news/2023/feb/10/matter-creator-csa-announces-healthcare-working-group/](https://www.iottechnews.com/news/2023/feb/10/matter-creator-csa-announces-healthcare-working-group/)\n\nOs robo-táxis da Zoox, empresa de veículos autônomos da Amazon, já estão nas ruas de Foster City, Califórnia. Os veículos da Zoox foram construídos especificamente para a condução autônoma e não possuem controles manuais. Os funcionários em tempo integral da empresa são os primeiros a usar o serviço de transporte autônomo entre seus campi. Isso requer confiança absoluta na qualidade do trabalho da sua equipe!\n\n[https://www.iottechnews.com/news/2023/feb/14/amazon-robotaxis-hit-the-streets-of-california/](https://www.iottechnews.com/news/2023/feb/14/amazon-robotaxis-hit-the-streets-of-california/)\n\n## Gerenciamento de Dados\n\nEm um estudo recente da Informatica sobre a dispersão de dados, foi constatado que dados dispersos e a necessidade de gestão unificada são pontos problemáticos comuns para muitas organizações. Além disso, qualidade de dados e governança são prioridades principais. Isso está levando a um aumento no investimento em tecnologias de dados neste ano. A pesquisa com base em questionários descobriu que 78% dos CDOs afirmaram que devem se alinhar estrategicamente com organizações geradoras de receita para justificar os gastos adicionais com a melhoria da análise e governança de dados.\n\n[https://accelerationeconomy.com/data/informatica-research-highlights-data-sprawl-why-management-needs-to-be-unified/](https://accelerationeconomy.com/data/informatica-research-highlights-data-sprawl-why-management-needs-to-be-unified/)\n\nA Alation Inc., fornecedora de soluções de inteligência de dados empresariais, lançou o Alation Marketplaces. Este novo produto permite que conjuntos de dados de terceiros aprimorem os dados existentes no Catálogo de Dados da Alation, permitindo que os usuários explorem dados externos de terceiros e complementem conjuntos de dados existentes. Além disso, a empresa expandiu seu Alation Anywhere para o Microsoft Teams e o Alation Connected Sheets para o Microsoft Excel, permitindo que os usuários de dados acessem informações contextuais do catálogo diretamente na ferramenta escolhida.\n\n[https://www.alation.com/press-releases/alation-launches-data-marketplaces/](https://www.alation.com/press-releases/alation-launches-data-marketplaces/)\n\n\n\n","guests":null,"link":"/brief-EDW4-pt","image":"./briefs/edw-4/pt/thumbnail.png","lang":"pt","summary":"Summary"},{"id":208,"type":"News Brief","title":"2023-11-11","tags":["homelawncaretools","ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Cibersegurança\n\n\n\nOs portos australianos estão lutando com um ataque cibernético, afetando as operações da DP World. O ataque ao gigante do transporte marítimo levou a interrupções nos movimentos de contêineres. Embora a extensão e a origem da violação estejam sob investigação, ela levanta preocupações sobre a vulnerabilidade da infraestrutura crítica às ameaças cibernéticas. As autoridades estão trabalhando para restaurar a normalidade, pois o incidente destaca a crescente importância da cibersegurança na proteção de serviços essenciais. [Leia mais](https://www.bloomberg.com/news/articles/2023-11-11/australian-authorities-meet-as-dp-world-shuts-ports-on-cyber-act)\n\n\nICBC, o maior banco do mundo, foi vítima de um ataque cibernético de ransomware. A violação interrompeu as operações, afetando o atendimento ao cliente. Embora a extensão do ataque esteja sendo avaliada, ele destaca a crescente ameaça do cibercrime às instituições financeiras. ICBC está trabalhando para conter a violação e restaurar a normalidade, enfatizando a necessidade de medidas robustas de cibersegurança no setor bancário global. [Leia mais](https://www.cnbc.com/2023/11/10/icbc-the-worlds-biggest-bank-hit-by-ransomware-cyberattack.html)\n\n\nCiberataques estão apoiando ataques cinéticos! O grupo russo de hackers SandWorm está implicado em um ciberataque que interrompeu a oferta de energia na Ucrânia. O sofisticado ataque visava a infraestrutura de energia, causando interrupções generalizadas. As autoridades ucranianas estão investigando o incidente, destacando a contínua ameaça de ciberataques patrocinados pelo estado à infraestrutura crítica. A situação sublinha a necessidade de medidas de cibersegurança aprimoradas para proteger os serviços essenciais. [Leia mais](https://thehackernews.com/2023/11/russian-hackers-sandworm-cause-power.html)\n\n## Inteligência Artificial\n\n\nEspecialistas em AI estão alertando sobre um potencial escassez de dados, enfatizando os recursos de dados do mundo que estão diminuindo para alimentar a inteligência artificial. O crescimento exponencial de aplicações de AI e modelos ávidos por dados está ultrapassando a geração de dados. Esta escassez pode impedir avanços futuros da AI, incitando a necessidade de abordagens inovadoras para coleta e síntese de dados. O desafio sublinha a importância do desenvolvimento responsável e sustentável da AI. [Leia mais](https://www.sciencealert.com/the-world-is-running-out-of-data-to-feed-ai-experts-warn)\n\n\nA proliferação da IA ameaça a democracia! Alertam especialistas na conferência Reuters Next. O rápido avanço da inteligência artificial levanta preocupações sobre seu potencial uso indevido para vigilância, manipulação e erosão dos valores democráticos. Especialistas pedem diretrizes éticas, estruturas regulatórias e discurso público para mitigar riscos associados à crescente influência da IA na política e na sociedade. [Leia mais](https://www.reuters.com/technology/reuters-next-rapid-ai-proliferation-is-threat-democracy-experts-say-2023-11-08/)\n\n\nEm uma entrevista, Barack Obama expressou preocupação com o impacto da inteligência artificial (IA) nos empregos. Ele reconhece o potencial de deslocamento de empregos devido à automação e enfatiza a necessidade de políticas para enfrentar esses desafios. Obama sugere investir em educação e programas de requalificação para preparar a força de trabalho para mercados de trabalho em evolução moldados pela IA e automação. [Leia mais](https://www.independent.co.uk/tv/news/barack-obama-biden-ai-jobs-b2445354.html)\n\n## Computação Ubíqua\n\n\nUma descoberta na computação quântica integra IA e aprendizado de máquinas para uma robusta correção de erros de qubit. Cientistas desenvolveram uma abordagem de computação quântica aprimorada por IA que melhora a correção de erros para qubits, um desafio crucial na computação quântica. Essa inovadora combinação de IA e tecnologia quântica tem promessa para avançar a confiabilidade e o desempenho dos computadores quânticos. [Leia mais](https://scitechdaily.com/ai-enhanced-quantum-computing-machine-learning-powers-robust-qubit-error-correction/)\n\n\nO Grupo de Software na Nuvem, empresa matriz da Citrix, está encerrando novas transações comerciais na China, incluindo Hong Kong e Macau, efetivamente a partir de três de dezembro. Citando o \"custo crescente\" de operação na região, a decisão segue movimentos semelhantes de outras empresas de tecnologia americanas em meio a uma perspectiva econômica mais fraca e regulamentos de segurança de dados mais rigorosos na China. À medida que mais empresas dos EUA saem da China, Pequim propôs relaxar os controles de segurança de dados transfronteiriços para atrair investidores estrangeiros. [Leia mais](https://finance.yahoo.com/news/citrix-owner-cloud-software-becomes-093000327.html)\n\n\nUm artigo recente da Analytics Insights prevê as tendências de computação em nuvem para dois mil e vinte e quatro. Estas incluem a importância da computação de borda para um processamento de dados mais rápido, a ascensão das estratégias multi-cloud para flexibilidade, e a integração de IA/ML para otimização da análise de dados. As medidas de segurança, como a arquitetura de zero-confiança, serão uma prioridade para enfrentar a ameaça em constante mudança. [Leia mais](https://www.analyticsinsight.net/cloud-trends-for-2024-whats-on-for-cloud-computing/)\n\n## Podcast Abraçando a Transformação Digital\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW41-pt","image":"./briefs/edw-41/pt/thumbnail.png","lang":"pt","summary":"Abraçando o Digital Esta semana de 12 de novembro de 2023, incluindo notícias em cibersegurança. Inteligência artificial e computação ubíqua. Descubra sobre vários grandes ataques cibernéticos à infraestrutura crítica, a IA ficando sem dados e avanços na computação quântica."},{"id":209,"type":"News Brief","title":"2023-11-18","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Cibersegurança\n\n\nA Agência de Segurança Cibernética e de Infraestrutura (CISA) planeja aplicar a responsabilidade executiva na segurança de software para aquisições governamentais. A iniciativa visa fazer com que os executivos assinem a aprovação da segurança dos softwares vendidos ao governo. Esta ação faz parte dos esforços da CISA para melhorar as medidas de segurança cibernética e garantir a integridade dos softwares utilizados em sistemas governamentais críticos. [Leia mais](https://federalnewsnetwork.com/cybersecurity/2023/11/cisa-aims-to-make-executives-sign-off-on-security-of-software-sold-to-government/)\n\n\nAs agências de segurança cibernética dos Estados Unidos emitem um alerta sobre uma nova ameaça de ransomware que visa a infraestrutura crítica. O alerta destaca os riscos potenciais e insta as organizações a aprimorar seus protocolos de segurança cibernética. As agências enfatizam a importância de medidas proativas, incluindo a atualização regular de software e a utilização de práticas de segurança robustas para mitigar o risco de ataques de ransomware. [Leia mais](https://thehackernews.com/2023/11/us-cybersecurity-agencies-warn-of.html)\n\n\n\nSolarWinds enfrenta um processo da Comissão de Valores Mobiliários (SEC) após o ataque cibernético de dois mil e vinte. A SEC alega que a empresa deixou de divulgar pontos de vulnerabilidade, induzindo os investidores ao erro. A SolarWinds, conhecida por seu software de gerenciamento de TI, sofreu um ataque de grande visibilidade à cadeia de suprimentos. O processo destaca o foco cada vez maior nas obrigações de divulgação de segurança cibernética e as possíveis consequências legais para empresas que não lidam adequadamente com esses incidentes. [Leia mais](https://www.nytimes.com/2023/11/18/business/dealbook/solarwinds-sec-lawsuit.html)\n\n## Inteligência Artificial\n\n\nO CEO da OpenAI, Sam Altman, renuncia em meio a crescentes preocupações com a direção da empresa. A saída de Altman segue tensões internas e renúncias em relação ao foco da empresa em aplicações comerciais ao invés de seu compromisso inicial com amplos benefícios de IA. A atitude levanta questões sobre o equilíbrio entre interesses corporativos e considerações éticas no desenvolvimento de IA. [Leia mais](https://www.washingtonpost.com/technology/2023/11/17/openai-ceo-resigns/)\n\n\nO recente evento de IA da Microsoft destaca três principais conclusões. Primeiro, a empresa enfatiza seu compromisso com o desenvolvimento responsável de IA, focando em justiça, transparência e responsabilidade. Segundo, a Microsoft tem como objetivo capacitar os desenvolvedores com ferramentas como o GPT do OpenAI, que oferece capacidades avançadas de linguagem natural. Por último, o evento ressalta a dedicação da Microsoft à inovação impulsionada pela IA em diversos setores, mostrando aplicações em saúde, finanças e ciência do clima. [Leia mais](https://www.cnbc.com/2023/11/17/here-are-three-key-takeaways-from-microsofts-bullish-ai-event-.html)\n\n\nO YouTube enfrenta o desafio do conteúdo deepfake à medida que criadores de IA produzem vídeos cada vez mais convincentes e enganosos. A plataforma luta para distinguir entre usos inofensivos e maliciosos de conteúdo gerado por IA. O YouTube reconhece a necessidade de vigilância e uma abordagem abrangente para lidar com deepfakes a fim de manter a integridade de seu conteúdo. Agora, pede-se aos criadores de conteúdo que verifiquem se o conteúdo é gerado por uma IA ou não. [Leia mais](https://apnews.com/article/youtube-artitifical-intelligence-deep-fake-ai-creaters-0513fd9fddbd93af327f0411dd29ff3d)\n\n## Computação Ubíqua\n\n\n\nA Amazon e a Microsoft envolvem-se numa competição acirrada por lucrativos contratos de computação em nuvem do governo, à medida que as agências federais dependem cada vez mais dos serviços em nuvem. As empresas estão disputando o contrato do Departamento de Defesa para a Capacidade de Nuvem Conjunta para Guerra (JWCC, na sigla em inglês), um acordo que valeria potencialmente dez bilhões de dólares. Esta batalha reflete a tendência mais ampla de gigantes da tecnologia competindo por contratos de nuvem do governo e destaca a importância estratégica dos serviços em nuvem para a modernização da infraestrutura governamental. [Leia mais](https://www.bloomberg.com/news/articles/2023-11-16/amazon-amzn-microsoft-msft-fight-for-cloud-computing-government-contracts)\n\n\nA Marinha dos Estados Unidos está aprimorando seus sistemas de torpedos aproveitando a computação em nuvem para submarinos. Esse upgrade visa melhorar o desempenho e as capacidades dos torpedos. A Marinha busca aprimorar o processamento e análise de dados utilizando a computação em nuvem, permitindo operações de torpedo mais sofisticadas e eficientes. A mudança reflete os esforços contínuos das forças armadas para integrar tecnologias avançadas, como a computação em nuvem, para fortalecer as capacidades de seus sistemas navais. [Leia mais](https://www.defensenews.com/naval/2023/11/16/us-navy-upgrading-torpedoes-leveraging-cloud-computing-for-submarines/)\n\n\nO governo dos EUA levanta preocupações sobre a Alibaba em relação ao possível uso indevido de chips feitos nos EUA em sua tecnologia de vigilância. A medida faz parte do esforço mais amplo para restringir as exportações de tecnologias sensíveis por questões de segurança nacional. Este desenvolvimento sublinha o questionamento das empresas de tecnologia chinesas. Destaca a atenção do governo dos EUA em prevenir o uso não intencional da tecnologia americana de maneiras que possam comprometer a segurança ou os direitos humanos. [Leia mais](https://finance.yahoo.com/news/alibaba-flagged-us-chip-curbs-192349433.html)\n\n## Notícias do Podcast Abraçando a Transformação Digital\n\n\n\nConfira as três séries intituladas \"Abraçando a IA Gerativa\", \"Abraçando Zero Trust\" e \"Abraçando Multi-Hybrid Cloud\". Nessas séries, Darren explora o mundo da IA com convidados da indústria, educação e pessoas comuns, traz especialistas em cibersegurança para falar sobre a proteção do mundo digital e pesquisa o céu em busca das mais recentes estratégias e tecnologias em nuvem. [Leia mais](https://www.embracingdigital.org/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW42-pt","image":"./briefs/edw-42/pt/thumbnail.png","lang":"pt","summary":"Transformação Digital para Cibersegurança, IA e Computação na semana de 19 de novembro de 2023. Os tópicos incluem implicações legais da cibersegurança, a saída de Sam Altman da OpenAI e provedores de nuvem competindo por contratos governamentais."},{"id":210,"type":"News Brief","title":"2023-11-25","tags":["uniquehandmadewoodfurniture.","ai","compute","cybersecurity","samaltman","openai","aibreakthrough","neuralchat7b","intel","responsibleai","meta","hacking","insiderthreats","securitymeasures","eucybersecurityregulations","clearfake","malware","ubiquitouscomputing","macstadium","m2prochip","alibabacloud","cloudcomputing"],"body":"\n\n## Inteligência Artificial\n\n\nSam Altman deixou a OpenAI após uma carta expressando preocupações sobre uma descoberta de IA não divulgada. A carta, enviada por um funcionário anônimo, levou à remoção de Altman como CEO. Os detalhes do avanço permanecem confidenciais, levantando questões sobre a dinâmica interna da OpenAI. Altman foi reintegrado quando setecentos dos setecentos e setenta funcionários o seguiram para a Microsoft. [Leia mais](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/)\n\n\nA Intel desenvolveu o NeuralChat sete B, um modelo de chatbot que prioriza a proteção de dados do usuário. O modelo é treinado usando Otimização de Privacidade Diferencial (DPO) para melhorar as salvaguardas de privacidade. Ao implementar o DPO, a Intel visa garantir interações seguras dentro do chatbot e mitigar riscos de privacidade. Esses esforços estão alinhados com os padrões em evolução para o desenvolvimento responsável de IA. [Leia mais](https://medium.com/@bnjmn_marie/neuralchat-7b-intels-chat-model-trained-with-dpo-e691dfd52591)\n\n\nMeta, a empresa matriz do Facebook, supostamente desfez sua equipe de Inteligência Artificial Responsável, o que suscita preocupações sobre seu compromisso com as práticas éticas de IA. Críticos argumentam que a desmontagem da equipe pode minar os esforços para lidar com preocupações éticas e possíveis vieses nas tecnologias de IA da Meta, enfatizando o debate em curso em torno do desenvolvimento responsável da IA. [Leia mais](https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence)\n\n## Cibersegurança\n\n\nUm executivo de uma empresa de cibersegurança se declarou culpado por hackear hospitais, em um chocante desdobramento de eventos. O executivo, previamente encarregado de proteger os sistemas, admitiu explorar vulnerabilidades para benefício pessoal. A violação levanta sérias questões sobre ameaças internas e a necessidade de medidas de segurança robustas dentro do próprio setor de cibersegurança. A confissão de culpa ressalta o imperativo de protocolos rigorosos de cibersegurança e conduta ética, especialmente quando encarregado de proteger infraestruturas críticas como instituições de saúde. [Leia mais](https://www.bleepingcomputer.com/news/security/cybersecurity-firm-executive-pleads-guilty-to-hacking-hospitals/)\n\n\nA União Europeia planeja expandir os regulamentos de cibersegurança para cobrir setores críticos como energia, transporte e provedores de serviços digitais como Amazon, Google e Microsoft. Isso visa fortalecer a cibersegurança em diversas indústrias devido ao aumento das ameaças cibernéticas. No entanto, alguns veem as novas regulamentações como uma maneira de capturar receita das grandes empresas de tecnologia. [Leia mais](https://www.finextra.com/newsarticle/43338/eu-considers-widening-scope-of-cybersecurity-regulation)\n\n\nUm novo malware chamado ClearFake foi descoberto visando usuários de Mac. Ele se disfarça como um aplicativo antivírus legítimo, enganando os usuários a baixar software mal-intencionado. Especialistas alertam para o potencial de roubo de dados e comprometimento do sistema. É essencial ter cautela e usar um software de segurança confiável para combater ameaças em evolução que visam as plataformas macOS. [Leia mais](https://cybersecuritynews.com/clearfake-new-malware-mac/)\n\n## Computação Ubíqua\n\n\nO novo Mac Cloud da MacStadium, alimentado pelo chip M2 Pro, oferece desempenho e capacidades avançadas para desenvolvedores macOS e empresas. Ele atende à crescente demanda por desenvolvimento Mac baseado em Kubernetes em ambientes de nuvem, atendendo às necessidades exclusivas da comunidade de desenvolvimento da Apple. O chip M2 Pro avança significativamente as capacidades de hospedagem Mac, proporcionando velocidade e eficiência melhoradas. [Leia mais](https://finance.yahoo.com/news/macstadium-unveils-powerful-next-generation-120000257.html)\n\n\n\nAlibaba adicionou três novos executivos à sua unidade de computação em nuvem, indicando seu compromisso em impulsionar seu negócio de nuvem. Os executivos trazem uma expertise diversificada para o competitivo mercado de computação em nuvem e impulsionarão a inovação e o crescimento. O foco da Alibaba em serviços de nuvem alinha-se com as demandas evolutivas do cenário digital, reforçando sua resolução em manter uma posição de liderança no setor global de computação em nuvem. [Leia mais](https://www.proactiveinvestors.com.au/companies/news/1034236/alibaba-taps-three-new-cloud-computing-executives-after-nixing-spinoff-ipo-plans-1034236.html)\n\n\nDe acordo com relatórios, a Europa está atrasada na corrida global da IA e deve mudar seu foco para a computação quântica para se manter competitiva. Investir em tecnologia quântica transformadora é imperativo para a Europa recuperar sua liderança tecnológica e enfrentar a paisagem global de inovação em evolução. [Leia mais](https://www.euronews.com/next/2023/11/23/europe-has-lost-the-ai-race-it-cant-ignore-the-quantum-computing-one)\n\n## Abraçando o Podcast de Transformação Digital\n\n\n\nNesta semana, Darren retornou após uma semana de folga para o Dia de Ação de Graças. Ele entrevistou Louis Parks, o diretor executivo da Veridify, onde revelou as vulnerabilidades da Infraestrutura Crítica da Tecnologia Operacional. Além disso, confira a nova marca e logotipos do Embracing Digital Transformation. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW43-pt","image":"./briefs/edw-43/pt/thumbnail.png","lang":"pt","summary":"Notícias da Transformação Digital para a semana de 26 de Novembro de 2023. Desde as mudanças transformacionais na liderança em inteligência artificial até o enfoque imperativo em cibersegurança e o desvendar de soluções avançadas de computação, esta compilação encapsula momentos cruciais na sempre evolutiva paisagem tecnológica. Junte-se a nós enquanto mergulhamos nas complexidades dos desenvolvimentos recentes, iluminando os impactos profundos que eles carregam em vários setores e orientando a trajetória do futuro digital."},{"id":211,"type":"News Brief","title":"2023-12-2","tags":["ai","compute","datamanagement","aws","siemens","industrialdge","cloudconfiguration","multiaccessedgecomputing","mec","networkarchitecture","iot","realtimeapplications","edgecomputinginhealthcare","healthcaremarket","polarismarketresearch","usda","datastrategy","digitalgovernance","vastdata","aiworkflows"],"body":"\n\n## Computação de borda\n\n\nAmazon Web Services (AWS) e Siemens uniram forças para otimizar a configuração industrial de borda para a nuvem. A colaboração visa simplificar a integração de dispositivos de borda com serviços de nuvem, aumentando a eficiência em ambientes industriais. A parceria combina AWS IoT Greengrass e a plataforma Industrial Edge da Siemens, fornecendo uma solução perfeita para configurar, gerenciar e otimizar dispositivos de borda na nuvem. Esta colaboração visa facilitar uma conectividade industrial de borda para a nuvem mais suave e acessível. [Leia mais](https://www.edgecomputing-news.com/2023/12/01/aws-and-siemens-team-up-for-easier-industrial-edge-to-cloud-configuration/)\n\n\n\nComputação de Borda de Acesso Múltiplo (MEC, na sigla em inglês) é uma arquitetura de rede que traz capacidades de computação para mais perto da borda da rede, reduzindo a latência e melhorando a eficiência. Ao implementar recursos de computação na borda, o MEC possibilita um processamento mais rápido dos dados gerados por dispositivos como sensores de Internet das Coisas (IoT) e dispositivos móveis. Esta abordagem descentralizada aprimora aplicações e serviços em tempo real como realidade aumentada e veículos autônomos. O MEC aproveita servidores de borda em proximidade próxima aos usuários finais, otimizando o processamento de dados para computação de alto desempenho com baixa latência.\n [Leia mais](https://www.techopedia.com/what-is-multi-access-edge-computing)\n\n\nDe acordo com a Polaris Market Research, o mercado de Edge Computing na área da saúde deve ultrapassar quarenta e três bilhões e duzentos e noventa milhões de dólares americanos até dois mil e trinta e dois, apresentando um robusto crescimento da taxa composta anual de vinte e seis vírgula três por cento. O aumento da adoção de soluções de edge computing na saúde, impulsionado pelos avanços nas tecnologias de IoT e IA, deve melhorar a eficiência do processamento de dados, possibilitar aplicações em tempo real e melhorar o atendimento ao paciente. O relatório sugere uma expansão significativa do mercado à medida que a saúde adota o edge computing para um desempenho aprimorado e processamento descentralizado de dados. [Leia mais](https://www.prnewswire.co.uk/news-releases/edge-computing-in-healthcare-market-expected-to-cross-usd-43-29-billion-by-2032--driving-26-3-cagr-growth-polaris-market-research-301998143.html)\n\n## Gerenciamento de Dados\n\n\n\nO USDA revelou uma nova estratégia de dados para melhorar a governança digital. A iniciativa aproveita os dados para melhorar os serviços, a tomada de decisões e a responsabilidade. O plano enfatiza a inovação orientada por dados, a colaboração e a modernização da infraestrutura de dados. Componentes chave incluem a priorização da privacidade e segurança, promoção da acessibilidade dos dados e fomento de uma cultura de uso responsável dos dados. A abordagem abrangente do USDA visa maximizar o valor dos dados em apoiar a missão da agência e servir ao público de forma mais eficaz. [Leia mais](https://www.nextgov.com/digital-government/2023/11/usda-unveils-new-data-strategy/392382/)\n\n\nA VAST Data lançou uma atualização de plataforma projetada para simplificar os fluxos de trabalho de IA e operações híbridas de nuvem na AWS. A atualização se concentra em aumentar a eficiência dos processos intensivos de dados, oferecendo integração perfeita com os serviços AWS. O objetivo da plataforma da VAST Data é simplificar o gerenciamento de dados e acelerar as cargas de trabalho de IA, proporcionando uma experiência mais amigável para as organizações que utilizam a AWS para suas operações híbridas de nuvem. A atualização destaca o compromisso da VAST Data em otimizar o desempenho e simplificar os complexos fluxos de trabalho de IA e de nuvem híbrida. [Leia mais](https://www.datanami.com/this-just-in/vast-datas-new-platform-update-aims-to-simplify-ai-workflows-and-hybrid-cloud-operations-on-aws/)\n\n\nA Intel fez uma parceria com a Granulate para otimizar as operações de gerenciamento de dados no Databricks, uma plataforma usada para análises de grandes volumes de dados. A tecnologia de otimização contínua em tempo real da Granulate, alimentada pelo hardware da Intel, é projetada para melhorar o desempenho e a utilização de recursos para usuários do Databricks. Essa colaboração reflete os esforços da indústria para aprimorar as capacidades de análise de dados, permitindo que as organizações aproveitem ao máximo o poder dos grandes volumes de dados para aumentar a eficiência e reduzir custos. [Leia mais](https://www.valdostadailytimes.com/ap/business/intel-granulate-optimizes-databricks-data-management-operations/article_ef0e550d-dbd3-5e5d-9a1d-75ffc7d0be4d.html)\n\n## Inteligência Artificial\n\n\nOs californianos estão instando seus legisladores a tomar medidas para proteger as eleições e garantir a integridade eleitoral. As crescentes preocupações sobre a segurança das eleições levaram os cidadãos a pedir uma ação legislativa para proteger o processo democrático. Essa demanda reflete uma crescente conscientização sobre a proteção das eleições de possíveis ameaças. Reforça o apelo para que os legisladores promulguem políticas que aumentem a transparência, a segurança cibernética e a confiança geral no sistema eleitoral. [Leia mais](https://news.yahoo.com/californians-want-lawmakers-safeguard-elections-150026166.html)\n\n\nA OTAN anunciou uma estratégia abrangente para inteligência artificial (IA) que reconhece seu papel crucial na guerra moderna e na segurança. A estratégia utiliza IA para melhorar a tomada de decisões, a segurança cibernética e a eficiência operacional. A decisão da OTAN reflete a crescente importância da IA nos domínios militares e a necessidade de permanecer na vanguarda dos avanços tecnológicos. A estratégia destaca diretrizes éticas e enfatiza a importância da colaboração com aliados e parceiros da indústria. [Leia mais](https://news.yahoo.com/nato-artificial-intelligence-strategy-amid-143228193.html)\n\n\nA Intel anunciou recentemente \"Visão AI em todo lugar\", uma nova tecnologia que integra a IA em data centers e dispositivos. Esta integração tem como objetivo melhorar o desempenho e a eficiência, otimizar as cargas de trabalho, aumentar as capacidades do data center e possibilitar a tomada de decisões em tempo real. Durante o evento Discover da HPE, a Intel exibiu várias aplicações, como data centers energeticamente eficientes e imagens médicas avançadas. A \"Visão AI em todo lugar\" está alinhada com o compromisso da Intel em promover a adoção da IA em diferentes setores, dando início a uma nova era de computação inteligente. [Leia mais](https://siliconangle.com/2023/11/29/data-centers-devices-intels-vision-ai-everywhere-hpediscover-hpediscover/)\n\n## Abraçando a Transformação Digital\n\n\n\nEmbracingdigital.org passou recentemente por uma transformação, ostentando um novo visual e logotipo. Confira a nova marca do show, juntamente com uma nova loja que oferece os presentes mais recentes para os entusiastas da transformação digital. Além disso, no programa desta semana, há uma entrevista em duas partes com Shamim Naqvi, CEO da SafeLiShare, onde eles se aprofundam em Zero Trust e compartilhamento de dados. [Leia mais](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW44-pt","image":"./briefs/edw-44/pt/thumbnail.png","lang":"pt","summary":"Por favor, confira as últimas notícias no mundo da Transformação Digital para a semana de 3 de dezembro de 2023. Você encontrará uma variedade de histórias interessantes relacionadas à computação de borda, gerenciamento de dados e inteligência artificial. Esta semana, a AWS e a Siemens colaboraram para simplificar a computação de borda, enquanto a Intel está ajudando a melhorar o gerenciamento de dados baseado em nuvem. Além disso, vários governos estão desenvolvendo novas estratégias para IA."},{"id":212,"type":"News Brief","title":"2023-12-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","usarmy","uno","cybersec","iot","aijobs","gemini","nano","pro","ultra","meta","ibm","openai","altman","aws","google","microsoft","mcdonalds","vergeio","nutanix","embracingdt"],"body":"\n\n## Cibersegurança\n\n\nO Exército dos Estados Unidos planeja melhorar suas capacidades de conectividade e cibersegurança ao introduzir uma nova rede unificada chamada UNO. Esta iniciativa visa proporcionar ao exército uma comunicação rápida e segura, que pode ajudar a superar os desafios no campo de batalha digital. Espera-se que a rede cooperativa simplifique as operações e aumente a resiliência contra ameaças cibernéticas, fortalecendo assim a infraestrutura tecnológica do Exército. [Leia mais](https://www.c4isrnet.com/battlefield-tech/it-networks/2023/12/04/unified-network-promises-us-army-rapid-connectivity-cybersecurity/)\n\n\nÀ medida que a Internet das Coisas (IoT) e a inteligência artificial (IA) continuam a avançar, o risco para a infraestrutura crítica proveniente de ameaças cibernéticas aumentou significativamente. Especialistas em cibersegurança estão enfatizando a necessidade de melhores medidas de segurança para se proteger contra essas ameaças. Eles estão contando com a integração da IA e do aprendizado de máquina para melhorar a detecção e prevenção de novos ataques cibernéticos. Essa paisagem constantemente evolutiva da cibersegurança na era da IoT e da computação em nuvem sublinha a necessidade contínua de se adaptar e proteger ecossistemas digitais. [Leia mais](https://readwrite.com/the-evolution-of-cybersecurity-in-the-age-of-iot-and-cloud-computing/)\n\n\nCerca de cinquenta por cento das organizações pesquisadas têm planos de reduzir sua equipe de cibersegurança, o que aumenta as preocupações em face das ameaças cibernéticas em constante evolução. Essa tendência destaca a importância da gestão estratégica de força de trabalho para a manutenção de sólidas defesas digitais. Enquanto isso, algumas outras empresas precisam de ajuda para encontrar candidatos adequados para preencher suas vagas em aberto na área de cibersegurança. [Leia mais](https://www.csoonline.com/article/1251369/almost-50-organizations-plan-to-reduce-cybersecurity-headcounts-survey.html)\n\n## Inteligência Artificial\n\n\nO Google lançou uma nova plataforma de IA chamada Gêmeos, que visa simplificar o treinamento e a implementação de modelos de aprendizado de máquina. Isso permitirá que os desenvolvedores criem aplicações de IA mais escaláveis e eficientes. Gêmeos oferece ferramentas e recursos amigáveis ao usuário para promover a inovação e avanços na tecnologia de IA. Atualmente, ele mira em três ofertas: \"nano\" para telefones, \"pro\" para centros de dados locais e \"ultra\" para uma nuvem pública baseada na nuvem liderada por Bard. [Leia mais](https://apnews.com/article/google-gemini-artificial-intelligence-launch-95d05d02051e75e20b574614ae720b8b)\n\n\n\nO Meta e a IBM estão trabalhando juntos para desenvolver um padrão aberto para inteligência artificial, visando promover a interoperabilidade e contrapor a influência dos grandes atores da tecnologia. Ao fomentar uma abordagem mais colaborativa, eles esperam criar um cenário competitivo que incentive a inovação e a diversidade na tecnologia de IA. [Leia mais](https://www.thestreet.com/technology/meta-and-ibm-team-up-against-dominant-big-tech-players)\n\n\nO CEO da OpenAI, Sam Altman, enfatizou a importância do desenvolvimento responsável da IA após um funcionário ser demitido devido a preocupações sobre o uso indevido da tecnologia de IA. O incidente realça os desafios contínuos na indústria tecnológica em relação à ética e governança em inteligência artificial. [Leia mais](https://www.foxbusiness.com/technology/openais-sam-altman-opens-up-shock-firing)\n\n## Computação ubíqua\n\n\nA AWS e o Google criticizam as práticas restritivas de nuvem da Microsoft, acusando-as de limitar a escolha do cliente e a interoperabilidade, que sufocam a concorrência no mercado. Isso destaca as tensões em curso entre os provedores de nuvem e as preocupações sobre práticas de negócios justas e dinâmicas de mercado. [Leia mais](https://www.itpro.com/cloud/cloud-computing/aws-joins-google-in-calling-out-restrictive-microsoft-cloud-practices)\n\n\nO McDonald's e o Google Cloud se associam para usar tecnologia em nuvem e soluções de inteligência artificial generativa nos restaurantes do McDonald's globalmente. O objetivo é melhorar a experiência do cliente, otimizar as operações e impulsionar a inovação na indústria de fast-food. Ao integrar as tecnologias avançadas do Google Cloud, o McDonald's pretende permanecer na vanguarda da transformação digital, oferecendo serviços aprimorados e eficiência operacional em sua rede mundial de restaurantes. [Leia mais](https://www.prnewswire.com/news-releases/mcdonalds-and-google-cloud-announce-strategic-partnership-to-connect-latest-cloud-technology-and-apply-generative-ai-solutions-across-its-restaurants-worldwide-302006915.html)\n\n\n\nFoi relatado que a aquisição da VMware pela Broadcom causou mudanças que levaram vinte por cento de seus usuários a procurar outras soluções de virtualização. Esta tendência de oportunidade criou espaço para outros participantes no mercado se estabelecerem como alternativas viáveis. Apesar do domínio da VMware no mercado de virtualização, a concorrência de empresas como Nunatix e VergeIO está fazendo com que os clientes se afastem da plataforma estabelecida. [Leia mais](https://www.channelfutures.com/mergers-acquisitions/20-of-users-looking-to-escape-to-vmware-alternatives)\n\n## Podcast Abraçando a Transformação Digital\n\n\n\nNeste episódio de sua série sobre o Abraçando o Zero Trust, Darren entrevista o CEO da SafeLiShare, Shamim Naqvi, para discutir a segurança do Zero Trust e a colaboração de dados usando a computação confidencial. Além disso, Darren gostaria de agradecer aos seus ouvintes por seu apoio. Graças a você, o podcast tem mais de três mil inscritos e quatro mil ouvintes semanais. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW45-pt","image":"./briefs/edw-45/pt/thumbnail.png","lang":"pt","summary":"Notícias de Transformação Digital para a semana de 10 de dezembro de 2023, contêm histórias sobre cibersegurança, inteligência artificial e computação ubíqua. Esta semana ouça o plano do Exército dos EUA para melhorar a cibersegurança através da unificação, as guerras da nuvem indo para o tribunal no Reino Unido, e o drama da openAI e Sam Altman."},{"id":213,"type":"News Brief","title":"2023-12-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","innovation","intel","pc","aiworkforce","snowflake","aws","solix","aiintegration","britain","nationalgrid","chineserisks","hackers","infrastructure","vulnerabilities","nsa","russianthreats","digitaltransformation","openziti","zerotrust"],"body":"\n\n## Inteligência Artificial\n\n\nO último anúncio da Intel marca um momento crucial no nascimento de PCs alimentados por IA. O lançamento dos processadores das séries Core Ultra H e U introduz a revolucionária arquitetura Meteor Lake, incorporando capacidades avançadas de IA em notebooks ultrafinos. Este lançamento melhora o desempenho e eleva a plataforma gráfica Arc, elevando a experiência do usuário a novos patamares. O compromisso da Intel com a inovação sinaliza uma era transformadora no mercado de laptops, onde a IA se torna integral à computação cotidiana. [Leia mais](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\nA vereadora-eleita de Nova York, Susan Zhuang, admitiu empregar discretamente a IA para se comunicar com o público e responder a consultas da mídia. Finalmente uma política falando a verdade! O uso de IA por Zhuang representa uma abordagem única para o envolvimento com os eleitores, e as implicações dessa estratégia direcionada pela tecnologia podem remodelar o cenário da comunicação política na era digital. [Leia mais](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\nA criação pela Intel de um PC com inteligência artificial personalizada trouxe uma potencial maciça disrupção trabalhista às empresas, enquanto continuam a integrar a inteligência artificial (IA) em suas operações. À medida que as tecnologias de IA são adotadas, espera-se que as funções de trabalho e os dias de trabalho mudem, aumentando as preocupações sobre possíveis desafios da força de trabalho. As empresas estão se preparando para essa mudança transformadora e reconhecendo a necessidade de estratégias proativas para navegar nas possíveis disrupções e garantir uma transição suave para um futuro movido à IA.\n [Leia mais](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gestão de Dados\n\n\nFlocos de neve, uma plataforma líder de dados em nuvem, obteve a Autorização Alta FedRAMP na AWS GovCloud EUA Oeste e EUA Leste. Este marco significativo destaca o compromisso da Snowflake em cumprir os rigorosos padrões de segurança governamentais, permitindo que agências federais aproveitem suas avançadas capacidades de gerenciamento de dados em um ambiente de nuvem seguro. A Autorização Alta FedRAMP sublinha a posição da Snowflake como uma parceira confiável em fornecer soluções rápidas e escaláveis para entidades governamentais, fomentando inovação e eficiência no gerenciamento de dados. [Leia mais](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\nA Solix apresentou a Plataforma de Dados Comum (CDP) três, que inclui avançada gestão de dados multi-nuvem e capacidades de IA corporativa. Este lançamento reflete o compromisso da Solix em fornecer soluções de última geração para gerir e obter insights de grandes conjuntos de dados. As funcionalidades melhoradas de aprendizado de máquina e IA da CDP três permitem que as organizações tomem decisões mais informadas baseadas em dados. A tendência de gestão de dados multi-nuvem está a impulsionar o desenvolvimento de muitas novas ofertas comerciais, e o último lançamento da Solix está preparado para ser um contribuinte significativo neste espaço. [Leia mais](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n\nEm um relatório recente, a Datanami explora considerações cruciais para garantir que sua estratégia de gerenciamento de dados esteja pronta para a IA com cinco indicadores-chave. Priorize a qualidade dos dados, escalabilidade, capacidades de integração, segurança robusta e flexibilidade. Esses elementos são cruciais para otimizar os sistemas à medida que a inteligência artificial continua a moldar os processos de dados. Mantenha-se à frente na era da IA, avaliando e aprimorando esses aspectos para atender às demandas das tecnologias em evolução. Leia mais em datanami.com para obter informações abrangentes. [Leia mais](https://www.datanami.com/2023/12/08/is-your-data-management-strategy-ready-for-ai-5-ways-to-tell/)\n\n## Cibersegurança\n\n\n\nA National Grid da Grã-Bretanha teria rompido laços com um fornecedor baseado na China por causa de preocupações com a segurança cibernética, conforme relatou a Reuters no dia dezessete de dezembro de dois mil e vinte e três. A decisão reflete uma maior vigilância global sobre os potenciais riscos associados às parcerias com tecnologias estrangeiras, particularmente nos setores de infraestrutura crítica. Esta decisão da National Grid destaca a crescente ênfase em reforçar medidas de segurança cibernética para proteger serviços essenciais contra ameaças potenciais. [Leia mais](https://www.reuters.com/technology/cybersecurity/britains-national-grid-drops-china-based-supplier-over-cyber-security-fears-ft-2023-12-17/)\n\n\nHackers têm como alvo o abastecimento de água dos Estados Unidos, levantando alarmes sobre a vulnerabilidade da infraestrutura crítica. A Axios relatou em dezesseis de dezembro de dois mil e vinte e três que esta violação apresenta consideráveis preocupações de segurança nacional e segurança pública. O incidente ressalta a necessidade urgente de medidas robustas de cibersegurança para proteger os serviços essenciais. As autoridades estão investigando a violação, destacando os desafios contínuos em defender a infraestrutura crítica de ameaças cibernéticas. [Leia mais](https://www.axios.com/2023/12/16/hackers-us-water-supply)\n\n\nA NSA alertou sobre atores cibernéticos russos explorando uma vulnerabilidade conhecida com implicações globais. A vulnerabilidade identificada tem um impacto significativo em todo o mundo, enfatizando a importância de mitigar os riscos de cibersegurança. A NSA aconselha as organizações a abordar e corrigir prontamente essa vulnerabilidade para aumentar sua resiliência contra possíveis ameaças cibernéticas. [Leia mais](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3616384/russian-cyber-actors-are-exploiting-a-known-vulnerability-with-worldwide-impact/)\n\n## Abraçando a Transformação Digital\n\n\n\nDarren procura a arquitetura de rede de confiança zero de código aberto com openZiti com um dos organizadores da comunidade de código aberto, Philip Griffiths. Além disso, um agradecimento especial aos ouvintes do Embracing Digital Transformation por espalharem a notícia, adicionamos mais de quatro mil inscritos ao nosso canal do YouTube e tivemos mais de quatorze mil downloads ou visualizações de nosso podcast na semana passada. Obrigado novamente pelo seu apoio. [Leia mais](http://www.embracingdigital.org)\n\n## Inteligência Artificial\n\n\n\nO último anúncio da Intel marca um momento crucial no nascimento de PCs potenciados por IA. O lançamento dos processadores da série Core Ultra H e U introduz a revolucionária arquitetura Meteor Lake, incorporando capacidades avançadas de IA em notebooks ultrafinos. Esse lançamento aprimora o desempenho e eleva a plataforma gráfica Arc, elevando a experiência do usuário a novos patamares. O compromisso da Intel com a inovação sinaliza uma era transformadora no mercado de laptops, onde a IA se torna integral para a computação diária. [Leia mais](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\n\nA vereadora eleita de Nova York, Susan Zhuang, admitiu empregar silenciosamente a inteligência artificial para se comunicar com o público e responder a solicitações da mídia. Finalmente, uma política falando a verdade! O uso de IA por Zhuang marca uma abordagem única para se envolver com os eleitores, e as implicações dessa estratégia orientada pela tecnologia podem remodelar a paisagem da comunicação política na era digital. [Leia mais](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\n\nA criação do PC de Inteligência Artificial personalizada pela Intel trouxe uma potencial massiva interrupção de trabalho para as empresas à medida que continuam integrando a Inteligência Artificial (IA) em suas operações. À medida que as tecnologias de IA são adotadas, espera-se que as funções de trabalho e os dias de trabalho mudem, levantando preocupações sobre possíveis desafios da força de trabalho. As empresas estão se preparando para essa mudança transformadora e reconhecendo a necessidade de estratégias proativas para navegar possíveis interrupções e garantir uma transição suave para um futuro impulsionado pela IA. [Leia mais](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gestão de Dados\n\n\n\nSnowflake, uma plataforma líder de dados em nuvem, alcançou a Autorização FedRAMP High na AWS GovCloud EUA Oeste e EUA Leste. Este marco significativo destaca o compromisso da Snowflake em atender aos rigorosos padrões de segurança do governo, permitindo que as agências federais aproveitem suas avançadas capacidades de gerenciamento de dados em um ambiente de nuvem seguro. A Autorização FedRAMP High sublinha a posição da Snowflake como um parceiro confiável na fornecimento de soluções rápidas e escaláveis para entidades governamentais, fomentando a inovação e eficiência no gerenciamento de dados. [Leia mais](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\n\nA Solix introduziu a Plataforma de Dados Comum (CDP) três vírgula zero, que inclui avançado gerenciamento de dados multi-nuvem e capacidades de IA empresarial. Este lançamento reflete o compromisso da Solix em fornecer soluções de última geração para gerenciar e obter informações de grandes conjuntos de dados. As melhorias em aprendizado de máquina e IA do CDP três vírgula zero permitem que as organizações tomem decisões mais informadas baseadas em dados. A tendência do gerenciamento de dados multi-nuvem está impulsionando o desenvolvimento de muitas novas ofertas comerciais, e o último lançamento da Solix está preparado para ser um contribuidor significativo neste espaço. [Leia mais](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n## Inteligência Artificial\n\n\n\nO último anúncio da Intel marca um momento crucial no nascimento de PCs alimentados por IA. O lançamento dos processadores da série Core Ultra H e U introduz a revolucionária arquitetura Meteor Lake, incorporando capacidades avançadas de IA em notebooks ultrafinos. Este lançamento aprimora o desempenho e eleva a plataforma gráfica Arc, elevando a experiência do usuário a novas alturas. O compromisso da Intel com a inovação sinaliza uma era transformadora no mercado de laptops, onde a IA se torna integral para a computação diária. [Leia mais](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\n\nA eleita vereadora de Nova York, Susan Zhuang, admitiu ter discretamente utilizado Inteligência Artificial para se comunicar com o público e responder a perguntas da mídia. Finalmente uma política falando a verdade! O uso de Inteligência Artificial por Zhuang marca uma abordagem única para se engajar com os eleitores, e as implicações dessa estratégia impulsionada pela tecnologia podem remodelar o cenário da comunicação política na era digital. [Leia mais](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\n\nA criação pela Intel do PC AI personalizado trouxe uma potencial maciça perturbação laboral às empresas à medida que continuam a integrar a inteligência artificial (AI) nas suas operações. À medida que as tecnologias de AI são adotadas, espera-se que as funções de trabalho e os dias de trabalho mudem, levantando preocupações sobre possíveis desafios da força de trabalho. As empresas estão se preparando para esta mudança transformacional e reconhecendo a necessidade de estratégias proativas para navegar possíveis interrupções e garantir uma transição suave para um futuro impulsionado pela AI. [Leia mais](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gerenciamento de Dados\n\n\n\nSnowflake, uma plataforma líder de dados em nuvem, alcançou a Autorização FedRAMP High no AWS GovCloud EUA Oeste e EUA Leste. Este marco significativo destaca o compromisso da Snowflake em cumprir rigorosos padrões de segurança governamentais, permitindo que agências federais aproveitem suas capacidades avançadas de gerenciamento de dados em um ambiente de nuvem seguro. A Autorização FedRAMP High ressalta a posição da Snowflake como parceiro confiável na fornecimento de soluções rápidas e escaláveis para entidades governamentais, promovendo inovação e eficiência no gerenciamento de dados. [Leia mais](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\n\nA Solix apresentou a Plataforma de Dados Comum (CDP) três ponto zero, que inclui avançada gestão de dados multi-nuvem e capacidades de IA corporativa. Este lançamento reflete o compromisso da Solix em fornecer soluções de última geração para gerir e obter informações de grandes conjuntos de dados. As melhorias no aprendizado de máquina e recursos de IA da CDP três ponto zero permitem que as organizações tomem decisões mais informadas baseadas em dados. A tendência da gestão de dados multi-nuvem está impulsionando o desenvolvimento de muitas novas ofertas comerciais, e o último lançamento da Solix está posicionado para ser um contribuidor significativo neste espaço.\n [Leia mais](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n\n\nEm um relatório recente, a Datanami explora considerações cruciais para garantir que sua estratégia de gerenciamento de dados esteja pronta para a IA com cinco indicadores-chave. Priorize a qualidade dos dados, escalabilidade, capacidades de integração, segurança robusta e flexibilidade. Esses elementos são cruciais para otimizar os sistemas à medida que a inteligência artificial continua a moldar os processos de dados. Mantenha-se à frente na era da IA ao avaliar e aprimorar esses aspectos para atender às demandas das tecnologias em evolução. Leia mais em datanami.com para obter insights abrangentes. [Leia mais](https://www.datanami.com/2023/12/08/is-your-data-management-strategy-ready-for-ai-5-ways-to-tell/)\n\n## Cibersegurança\n\n\n\nA National Grid da Grã-Bretanha, supostamente, cortou laços com um fornecedor sediado na China devido a preocupações com a segurança cibernética, conforme a Reuters relatou no dia dezessete de dezembro de dois mil e vinte e três. A decisão reflete um escrutínio global acentuado sobre possíveis riscos associados a parcerias com tecnologias estrangeiras, particularmente em setores de infraestrutura crítica. Este movimento da National Grid sublinha o crescente ênfase em reforçar medidas de segurança cibernética para proteger serviços essenciais contra possíveis ameaças. [Leia mais](https://www.reuters.com/technology/cybersecurity/britains-national-grid-drops-china-based-supplier-over-cyber-security-fears-ft-2023-12-17/)\n\n\n\nHackers têm como alvo o fornecimento de água dos Estados Unidos, elevando os alarmes sobre a vulnerabilidade da infraestrutura crítica. Axios informou em dezesseis de dezembro de dois mil e vinte e três, que esta violação representa preocupações significativas de segurança nacional e segurança pública. O incidente sublinha a necessidade urgente de medidas robustas de cibersegurança para salvaguardar os serviços essenciais. As autoridades estão investigando a violação, destacando os desafios contínuos na defesa da infraestrutura crítica contra ameaças cibernéticas. [Leia mais](https://www.axios.com/2023/12/16/hackers-us-water-supply)\n\n\n\nA NSA alertou sobre atores russos de ciberataques explorando uma vulnerabilidade conhecida com implicações globais. A vulnerabilidade identificada tem um impacto significativo mundialmente, enfatizando a importância de mitigar riscos de cibersegurança. A NSA aconselha as organizações a lidarem prontamente e corrigirem essa vulnerabilidade para aumentar a resistência contra possíveis ameaças cibernéticas. [Leia mais](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3616384/russian-cyber-actors-are-exploiting-a-known-vulnerability-with-worldwide-impact/)\n\n## Abraçando a Transformação Digital\n\n\n\nDarren procura a fonte aberta para a arquitetura de rede de confiança zero com openZiti com um dos organizadores da comunidade de código aberto, Philip Griffiths. Além disso, um agradecimento especial aos ouvintes de Embracing Digital Transformation por espalhar a notícia, adicionamos mais de quatro mil assinantes ao nosso canal no YouTube e tivemos mais de catorze mil downloads ou visualizações de nosso podcast na semana passada. Obrigado novamente pelo seu apoio. [Leia mais](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW46-pt","image":"./briefs/edw-46/pt/thumbnail.png","lang":"pt","summary":"A semana de 17 de dezembro de 2023, em notícias de Transformação Digital inclui histórias sobre IA, gerenciamento de dados e cibersegurança. Confira o nascimento do PC AI, gerenciamento de dados Multi-cloud para nuvens governamentais, e alertas importantes para a cibersegurança de infraestruturas críticas."},{"id":214,"type":"News Brief","title":"2023-12-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","wordpress","plugindata","xwpspamshield","ontariohack","healthcarecyber","holidayhacks","ontarioincidents","artificialintel","generativeai","aiinschool","intelnervana","cloudcomputing","cloudcost","pentagoncloud","cisco","isovalent","openziti","podcast","digitaltransf"],"body":"\n\n## Cibersegurança\n\n\n\nUm plugin desonesto do WordPress comprometeu os dados dos usuários ao expor endereços de e-mail, nomes de usuários e senhas em texto simples. Pesquisadores de segurança descobriram a violação, instando os usuários afetados a redefinir suas credenciais imediatamente. O plugin, chamado \"X-WP-SPAM-SHIELD-PRO\", é conhecido por atividades maliciosas, enfatizando a importância de auditorias de segurança regulares para sites do WordPress. Os administradores de sites são aconselhados a remover o plugin comprometido e aprimorar as medidas de segurança para evitar acesso não autorizado e exposição de dados. [Leia mais](https://thehackernews.com/2023/12/rogue-wordpress-plugin-exposes-e.html)\n\n\n\nA CBC relata um aumento em ciberataques direcionados a Ontario, Canadá, em dois mil e vinte e três. Esses incidentes envolvem uma variedade de setores, incluindo saúde, municípios e educação. Hackers exploram vulnerabilidades, causando interrupções e expondo dados sensíveis. Especialistas enfatizam a melhoria das medidas de cibersegurança, treinamento e colaboração para se proteger contra ameaças cibernéticas em evolução e proteger a infraestrutura crítica. [Leia mais](https://www.cbc.ca/news/canada/toronto/cybersecurity-ontario-incidents-2023-1.7048495)\n\n\n\nAtaques cibernéticos durante as férias de Natal estão aumentando por diversas razões. Primeiramente, a atividade de compras online está intensificada, criando oportunidades para cibercriminosos. Em segundo lugar, as tentativas de phishing aumentaram, onde os atacantes enganam as vítimas usando e-mail ou redes sociais. Em terceiro lugar, os funcionários que trabalham remotamente apresentam um risco de segurança. Em quarto lugar, ataques de engenharia social podem ser mais bem-sucedidos durante essa estação. Finalmente, a possível negligência de segurança devido às festividades também pode aumentar o risco de ataques. É vital estar ciente desses riscos e tomar medidas para mitigá-los. [Leia mais](https://bit-sentinel.com/5-reasons-why-cyber-attacks-increase-during-the-christmas-holidays/)\n\n## Inteligência Artificial\n\n\n\nEm dois mil e vinte e três, a IA generativa fez avanços significativos em diversos setores, incluindo saúde, finanças e entretenimento. Jim Cramer da CNBC resume o fim do ano enfatizando as contribuições da IA para a descoberta de medicamentos, modelagem financeira e criação de conteúdo. O potencial transformador da IA generativa é destacado, marcando sua contínua influência na inovação e nos avanços tecnológicos. [Leia mais](https://www.cnbc.com/2023/12/21/jim-cramer-recaps-the-year-in-generative-artificial-intelligence.html)\n\n\n\nO artigo recente do Futuro-Ed explora o potencial de integração da IA nas escolas. Ele enfatiza a importância de considerações éticas e implementação responsável para uma integração bem-sucedida. O artigo fornece percepções valiosas para educadores, formuladores de políticas e partes interessadas navegando nesta paisagem em evolução. O podcast Abraçando a Transformação Digital também apresentará entrevistas com estudantes universitários e seus professores, discutindo seus pensamentos. [Leia mais](https://www.future-ed.org/navigating-the-artificial-intelligence-revolution-in-schools/)\n\n\n\nA Intel revelou um novo chip, o Intel Nervana NCS-um, para acelerar as aplicações de inteligência artificial (IA). O NCS-um é projetado para melhorar o desempenho da IA, oferecendo alto rendimento e eficiência. A Intel tem como objetivo avançar na inovação da IA fornecendo aos desenvolvedores ferramentas para implantar e escalar eficientemente modelos de IA. O chip faz parte do compromisso da Intel em potencializar as aplicações de IA em várias indústrias e representa um passo significativo na estratégia de IA da empresa. [Leia mais](https://www.intc.com/news-events/press-releases/detail/1663/intel-accelerates-ai-everywhere-with-launch-of-powerful)\n\n## Computação Ubíqua\n\n\n\nInstituições financeiras, incluindo Capital One e Arvest Bank, estão priorizando o controle de custos na nuvem perante desafios. O foco é otimizar as despesas através de um alinhamento estratégico com os objetivos de negócio, empregando ferramentas de gestão de custos na nuvem e implementando práticas de governança. À medida que a computação em nuvem evolui, a gestão de custos efetiva se torna crucial para essas organizações. [Leia mais](https://www.ciodive.com/news/cloud-cost-control-capital-one-arvest-bank/703025/)\n\n\n\nO Washington Post reporta sobre a reconsideração do Pentágono de seus contratos de computação em nuvem, sugerindo possíveis mudanças na estratégia. O artigo explora as implicações dessas mudanças e seu impacto nas principais empresas de tecnologia que concorrem por lucrativos contratos de defesa. À medida que o Pentágono navega na complexa paisagem da computação em nuvem, o artigo destaca a dinâmica em evolução e o cenário competitivo na busca do setor de defesa por capacidades tecnológicas avançadas. [Leia mais](https://www.washingtonpost.com/technology/2023/12/21/pentagon-cloud-computing-contracts/)\n\n\n\nA Cisco está fazendo uma jogada estratégica em segurança na nuvem adquirindo a Isovalent, uma inovadora em redes nativas da nuvem e segurança. Esta aquisição reflete o compromisso da Cisco em avançar suas capacidades de inteligência artificial (IA) e segurança na nuvem. A experiência da Isovalent na tecnologia eBPF (extended Berkeley Packet Filter) é esperada para melhorar a capacidade da Cisco de garantir ambientes em nuvem, fornecendo soluções avançadas para a paisagem cibernética em evolução em infraestruturas baseadas em nuvem. [Leia mais](https://www.informationweek.com/it-infrastructure/cloud-computing#close-modal)\n\n## Adotando a Transformação Digital\n\n\n\nPrimeiramente, gostaria de desejar a todos os meus ouvintes um Feliz Natal e um Próspero Ano Novo. No podcast desta semana, Darren explora a OpenZiti, uma solução de rede de confiança zero de código aberto. Além disso, obrigado a todos que estão divulgando o podcast: agora ultrapassamos dez mil ouvintes semanais, e seu apoio é muito apreciado. [Leia mais](https://www.embracingdigital.org)\n\n## Cibersegurança\n\n\n\nUm plugin desonesto do WordPress colocou em risco os dados dos usuários ao expor endereços de e-mail, nomes de usuário e senhas em texto simples. Pesquisadores de segurança descobriram a violação, instando os usuários afetados a redefinir suas credenciais imediatamente. O plugin, chamado \"X-WP-SPAM-SHIELD-PRO\", é conhecido por atividades maliciosas, enfatizando a importância de auditorias de segurança regulares para sites do WordPress. Os administradores de sites são aconselhados a remover o plugin comprometido e aprimorar as medidas de segurança para prevenir o acesso não autorizado e a exposição de dados. [Leia mais](https://thehackernews.com/2023/12/rogue-wordpress-plugin-exposes-e.html)\n\n\n\nA CBC relata um aumento em ataques cibernéticos direcionados a Ontario, Canadá, em dois mil e vinte e três. Estes incidentes envolvem uma gama de setores, incluindo saúde, municípios e educação. Hackers exploram vulnerabilidades, causando interrupções e expondo dados sensíveis. Especialistas enfatizam a melhoria das medidas de cibersegurança, treinamento e colaboração para salvaguardar contra ameaças cibernéticas em evolução e proteger infraestruturas críticas. [Leia mais](https://www.cbc.ca/news/canada/toronto/cybersecurity-ontario-incidents-2023-1.7048495)\n\n\n\nAtaques cibernéticos durante as férias de Natal estão aumentando por várias razões. Primeiramente, a atividade de compras online está intensificada, criando oportunidades para os cibercriminosos. Em segundo lugar, as tentativas de phishing aumentaram, onde os agressores enganam as vítimas usando e-mail ou mídia social. Em terceiro lugar, os funcionários que trabalham remotamente representam um risco de segurança. Em quarto lugar, ataques de engenharia social podem ser mais bem-sucedidos durante esta temporada. Finalmente, a possível negligência de segurança devido às festividades também pode aumentar o risco de ataques. É vital estar ciente desses riscos e tomar medidas para mitigá-los. [Leia mais](https://bit-sentinel.com/5-reasons-why-cyber-attacks-increase-during-the-christmas-holidays/)\n\n## Inteligência Artificial\n\n\n\nEm dois mil e vinte e três, a inteligência artificial gerativa fez progressos significativos em diversos setores, incluindo saúde, finanças e entretenimento. Jim Cramer, da CNBC, faz um resumo do fim do ano, enfatizando as contribuições da IA para a descoberta de medicamentos, modelagem financeira e criação de conteúdo. O potencial transformador da inteligência artificial gerativa é destacado, marcando sua influência contínua na inovação e nos avanços tecnológicos. [Leia mais](https://www.cnbc.com/2023/12/21/jim-cramer-recaps-the-year-in-generative-artificial-intelligence.html)\n\n\n\nO artigo recente da Future-Ed explora o potencial da integração da IA nas escolas. Ele enfatiza a importância das considerações éticas e da implementação responsável para uma integração bem-sucedida. O artigo fornece informações valiosas para educadores, formuladores de políticas e partes interessadas navegando nessa paisagem em evolução. O podcast Abraçando a Transformação Digital também apresentará entrevistas com estudantes universitários e seus professores, discutindo seus pensamentos. [Leia mais](https://www.future-ed.org/navigating-the-artificial-intelligence-revolution-in-schools/)\n\n\n\nA Intel revelou um novo chip, o Intel Nervana NCS-um, para acelerar aplicações de inteligência artificial (IA). O NCS-um é projetado para aprimorar o desempenho da IA, oferecendo alta produtividade e eficiência. A Intel visa avançar a inovação em IA, fornecendo aos desenvolvedores ferramentas para implantar e escalar modelos de IA de maneira eficiente. O chip faz parte do compromisso da Intel em capacitar aplicações de IA em várias indústrias e representa um passo significativo na estratégia de IA da empresa. [Leia mais](https://www.intc.com/news-events/press-releases/detail/1663/intel-accelerates-ai-everywhere-with-launch-of-powerful)\n\n## Computação Ubíqua\n\n\n\nInstituições financeiras, incluindo Capital One e Arvest Bank, estão priorizando o controle de custos na nuvem em meio a desafios. O foco está em otimizar as despesas através do alinhamento estratégico com os objetivos de negócios, empregando ferramentas de gerenciamento de custos na nuvem e implementando práticas de governança. À medida que a computação em nuvem evolui, o gerenciamento eficaz de custos torna-se crucial para essas organizações. [Leia mais](https://www.ciodive.com/news/cloud-cost-control-capital-one-arvest-bank/703025/)\n\n\n\nO Washington Post relata a reconsideração do Pentágono de seus contratos de computação em nuvem, sugerindo possíveis mudanças na estratégia. O artigo explora as implicações dessas mudanças e seu impacto nas grandes empresas de tecnologia que estão participando da licitação de contratos de defesa lucrativos. À medida que o Pentágono navega pela complexa paisagem da computação em nuvem, o artigo destaca a dinâmica e o ambiente competitivo em evolução na busca do setor de defesa por capacidades tecnológicas avançadas. [Leia mais](https://www.washingtonpost.com/technology/2023/12/21/pentagon-cloud-computing-contracts/)\n\n\n\nA Cisco está fazendo uma jogada estratégica em segurança na nuvem ao adquirir a Isovalent, uma inovadora em redes e segurança nativas da nuvem. Essa aquisição reflete o compromisso da Cisco em avançar suas capacidades de inteligência artificial (IA) e segurança em nuvem. Espera-se que a expertise da Isovalent na tecnologia eBPF (Filtro de Pacotes Berkeley Estendido) melhore a capacidade da Cisco de proteger os ambientes em nuvem, oferecendo soluções avançadas para a paisagem cibernética em constante evolução nas infraestruturas baseadas em nuvem. [Leia mais](https://www.informationweek.com/it-infrastructure/cloud-computing#close-modal)\n\n## Abraçando a Transformação Digital\n\n\n\nPrimeiramente, gostaria de desejar a todos os meus ouvintes um Feliz Natal e um Próspero Ano Novo. No podcast desta semana, Darren explora o OpenZiti, uma solução de rede open-source de confiança zero. Além disso, agradeço a todos que estão divulgando o podcast: agora ultrapassamos dez mil ouvintes semanais, e seu apoio é muito apreciado. [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW47-pt","image":"./briefs/edw-47/pt/thumbnail.png","lang":"pt","summary":"Durante a semana de 24 de dezembro de 2023, houve várias reportagens sobre transformação digital. Essas histórias cobriram tópicos como cibersegurança, inteligência artificial e computação. Alguns dos destaques da semana incluíram um aumento nos ataques cibernéticos durante a temporada de festas, o esforço da Intel para desenvolver ainda mais a tecnologia de IA, e a tendência em direção ao controle de custos em computação em nuvem."},{"id":215,"type":"News Brief","title":"2023-12-31","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","edgecompute","digitaltransform","nsacyber","aics","tomtom","microsoft","mitresearch","aiethics","iot","healthcare","malwaredetect","patientdata","aiagriculture","predictive","genai","automation","navigation","malware"],"body":"\n\n## Cibersegurança\n\n\n\nA solução de cibersegurança alimentada por Inteligência artificial da Checkpoint oferece uma plataforma revolucionária com uma taxa de precisão de noventa e oito por cento na detecção de atividades maliciosas. O sistema usa algoritmos avançados e análises preditivas para fornecer às empresas uma poderosa defesa contra riscos cibernéticos em evolução, reforçando a segurança digital durante ameaças intensificadas. [Leia mais](https://fortune.com/2023/12/29/ai-cybersecurity-checkpoint/)\n\n\n\nAtaques cibernéticos a instalações de saúde aumentaram acentuadamente, causando preocupações sobre a segurança dos pacientes no Hospital Liberty, que tem lutado contra um ataque nas últimas duas semanas. Medidas robustas de cibersegurança são necessárias para proteger informações médicas sensíveis e garantir serviços de saúde ininterruptos. Isso destaca as vulnerabilidades mais amplas da infraestrutura crítica diante das crescentes ameaças cibernéticas. [Leia mais](https://www.kctv5.com/2023/12/30/liberty-hospital-staff-worries-patients-are-jeopardy-if-cyber-security-incident-drags/)\n\n\n\nO relatório de Revisão do Ano de Segurança Cibernética dois mil e vinte e três da NSA oferece insights sobre ameaças cibernéticas, defesas bem-sucedidas e tendências emergentes. A publicação enfatiza o compromisso da agência em melhorar a resiliência cibernética nacional e é um recurso valioso para profissionais da indústria, formuladores de políticas e o público. Ele fornece uma análise retrospectiva da paisagem de segurança cibernética e orienta os esforços futuros para fortalecer a segurança digital. [Leia mais](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3621654/nsa-publishes-2023-cybersecurity-year-in-review/)\n\n## Inteligência Artificial\n\n\n\nPesquisadores do MIT desenvolveram algoritmos que permitem que as máquinas entendam nuances contextuais na linguagem, promovendo interações mais precisas. Essa descoberta no processamento de linguagem natural tem possíveis aplicações em vários campos, estreitando a lacuna entre a comunicação humana e a compreensão da máquina. A pesquisa do MIT abre caminho para sistemas de IA mais avançados e conscientes do contexto. [Leia mais](https://news.mit.edu/2023/leveraging-language-understand-machines-1222)\n\n\n\nA inteligência artificial e a automação estão transformando governos ao melhorar a eficiência e a agilidade. Esta mudança em direção a uma abordagem digital reflete um compromisso de se adaptar à era moderna. O impacto dessas tecnologias está remodelando a governança e fornecendo uma abordagem mais avançada para enfrentar desafios digitais. [Leia mais](https://federalnewsnetwork.com/commentary/2023/12/navigating-the-era-of-innovation-how-artificial-intelligence-and-automation-are-driving-a-digital-first-government/)\n\n\n\nMichael Cohen admite ter submetido documentos jurídicos falsos gerados por inteligência artificial enquanto trabalhava para Donald Trump, levantando preocupações sobre a ética e supervisão da IA no sistema jurídico. Isso destaca a necessidade de uma supervisão vigilante e salvaguardas para manter a integridade dos processos jurídicos. O incidente sublinha os desafios em evolução da ética e integridade da IA nos processos jurídicos. [Leia mais](https://www.nbcnews.com/politics/politics-news/michael-cohen-says-unknowingly-submitted-fake-ai-generated-legal-cases-rcna131631)\n\n## Computação de Borda\n\n\n\nA TomTom e a Microsoft fizeram parceria para apresentar uma solução inovadora e generativa de IA para veículos conectados. A tecnologia usa algoritmos avançados para transformar a navegação, prometendo uma experiência de condução mais inteligente e responsiva. Este desenvolvimento representa um avanço significativo na integração da IA em automóveis. [Leia mais](https://www.iottechnews.com/news/2023/dec/19/tomtom-microsoft-unveil-generative-ai-connected-vehicles/)\n\n\n\nA Panasonic combate malwares do IoT ao implantar honeypots para detectar ameaças cibernéticas. A empresa obtém insights valiosos sobre táticas de malwares em evolução ao criar alvos simulados para atrair atividades maliciosas, aprimorando medidas de cibersegurança. Esta abordagem proativa reflete a crescente ênfase em técnicas inovadoras para proteger dispositivos conectados e redes diante dos crescentes desafios de segurança. [Leia mais](https://www.wired.com/story/panasonic-iot-malware-honeypots/)\n\n\n\nA integração das tecnologias de Inteligência Artificial (IA) e Internet das Coisas (IoT) está transformando rapidamente a indústria agrícola. Prevê-se que o mercado de agricultura de precisão atinja cinco bilhões e duzentos milhões de euros até dois mil e vinte e sete, graças ao uso inovador do IoT, análise de dados e automação na agricultura. Essa tecnologia otimiza a produção de cultivos, reduz o consumo de recursos e promove uma agricultura sustentável e eficiente em todo o mundo. [Leia mais](https://iotbusinessnews.com/2023/12/22/53545-the-precision-agriculture-market-to-reach-e-5-2-billion-worldwide-in-2027/)\n\n## Abraçando a Transformação Digital\n\n\n\nNessa semana, o Embracing Digital Transformation continua sua série Embracing Generative AI apresentando entrevistas com uma estudante universitária, Madeline Pulsipher, que compartilha sua jornada com o GenAI, seguida pela perspectiva de uma professora, Laura Newey, sobre o uso do GenAI na sala de aula. Não perca esses episódios esclarecedores! [Leia mais](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW48-pt","image":"./briefs/edw-48/pt/thumbnail.png","lang":"pt","summary":"Notícias de Transformação Digital para a semana de 1 de Janeiro de 2024, cobrindo cibersegurança, inteligência artificial e computação de borda. Os tópicos incluem IoT e IA na fazenda, políticos enganados por alucinações geradas por IA e ataques cibernéticos voltados para a saúde."},{"id":216,"type":"News Brief","title":"2024-1-7","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","intel","articul8","digitalbridge","genai","ethics","china","itot","upskilling","airbus","atos","solix","dataplatform","microsoft","oracle","azure","database","digitaltransformation","generativeai"],"body":"\n\n## Inteligência Artificial\n\n\n\nA Intel anunciou recentemente a separação da empresa de software de IA Articul8, apoiada pela DigitalBridge. A medida visa melhorar as capacidades de IA empresarial. A Articul8 se concentrará no desenvolvimento de soluções avançadas de IA, aproveitando a expertise da Intel no campo. Esta jogada estratégica sinaliza o compromisso da Intel em avançar as tecnologias de inteligência artificial para aplicações mais amplas na indústria. [Leia mais](https://www.reuters.com/technology/intel-spins-out-ai-software-firm-with-backing-digitalbridge-2024-01-03/)\n\n\n\nUm relatório sobre a GenAI do Foreign Affairs discute preocupações sobre o impacto da inteligência artificial nos valores democráticos dos Estados Unidos. O relatório destaca o possível uso indevido da IA em atividades como desinformação e vigilância, e enfatiza a necessidade de diretrizes éticas e quadros regulatórios para abordar essas preocupações e proteger os princípios fundamentais da democracia. [Leia mais](https://www.foreignaffairs.com/united-states/artificial-intelligences-threat-democracy)\n\n\n\nA China lançou recentemente diretrizes para pesquisadores de IA, impedindo-os de usar certos fundos para fins militares. As diretrizes visam garantir que a tecnologia de IA seja utilizada para fins pacíficos e éticos, com foco em evitar seu uso indevido em áreas que poderiam potencialmente prejudicar a segurança internacional. Esta ação destaca a determinação da China em moldar o desenvolvimento ético e a aplicação de IA, enfatizando seu compromisso com o uso responsável da tecnologia de IA. [Leia mais](https://www.scmp.com/news/china/science/article/3247420/china-unveils-new-artificial-intelligence-guidelines-scientists-and-bans-use-funding-applications)\n\n## Cibersegurança\n\n\n\nA análise da Segurança da Inteligência enfatiza a importância de integrar TI e OT na cibersegurança. Essa convergência é fundamental para proteger os sistemas industriais contra ameaças cibernéticas. A análise explora desafios e vantagens e destaca a necessidade de uma estratégia de segurança abrangente. [Leia mais](https://securityintelligence.com/posts/it-and-ot-cybersecurity-integration/)\n\n\n\nO aprendizado contínuo em cibersegurança é crucial para abordar a lacuna de habilidades. Um relatório recente defende a melhoria das habilidades do talento existente e o investimento em programas de treinamento para atender à demanda por profissionais qualificados. As organizações precisam fomentar uma cultura de aprimoramento contínuo de habilidades para aprimorar a resiliência cibernética. [Leia mais](https://www.informationweek.com/cyber-resilience/upskilling-is-the-secret-to-closing-the-cybersecurity-skills-gap-)\n\n\n\nA Airbus está adquirindo a unidade de cibersegurança da Atos por dois bilhões de dólares, para fortalecer suas capacidades de cibersegurança nos setores ICS-OT. A medida enfatiza a necessidade de medidas robustas de cibersegurança na infraestrutura crítica, especialmente em indústrias onde a tecnologia operacional desempenha um papel crucial. O acordo implica um passo estratégico em direção ao aprimoramento da cibersegurança dentro do quadro operacional da Airbus. [Leia mais](https://www.darkreading.com/ics-ot-security/airbus-acquire-atos-cybersecurity-unit-2-billion)\n\n## Gerenciamento de Dados\n\n\n\nA Solix revelou uma Plataforma de Dados Empresariais para a era \"Gen AI\". Ela tem como objetivo oferecer soluções avançadas de gerenciamento de dados para atender às necessidades em evolução das tecnologias de IA. A plataforma da Solix está focada em otimizar o processamento e a capacidade de armazenamento de dados para apoiar as demandas de aplicativos e análises impulsionadas por IA. Este movimento significa um passo estratégico em direção à habilitação da utilização eficiente de dados no campo de inteligência artificial, que está avançando rapidamente. [Leia mais](https://venturebeat.com/data-infrastructure/solix-launches-new-enterprise-data-platform-for-the-gen-ai-era/)\n\n\n\nA Microsoft e a Oracle se uniram para melhorar a compatibilidade entre seus bancos de dados, o Microsoft SQL Server e o Oracle Database, na plataforma em nuvem Azure da Microsoft. Essa parceria busca proporcionar uma experiência contínua para os usuários que executam esses bancos de dados no Azure, com desempenho e flexibilidade aprimorados. A colaboração visa atender às demandas em evolução das soluções de banco de dados baseadas na nuvem, apoiando a interoperabilidade e facilidade de uso para empresas que utilizam ambas as tecnologias da Microsoft e Oracle no Azure. [Leia mais](https://www.infoq.com/news/2024/01/microsoft-oracle-database-azure/)\n\n\n\nEm vinte e vinte e quatro, os dados corporativos e as tecnologias de IA estão passando por mudanças significativas. As tendências incluem o papel crescente da IA na gestão de dados, o aumento do ênfase na ética dos dados e privacidade, a ascensão da análise aumentada e a influência do edge computing no processamento de dados. As organizações são instadas a se adaptar a essas dinâmicas em evolução para permanecerem competitivas e aproveitar o potencial completo dos dados e das tecnologias de IA este ano. [Leia mais](https://tdwi.org/articles/2024/01/05/ta-all-shifting-sands-in-enterprise-data-and-ai-technologies-in-2024.aspx)\n\n## Abraçando o Podcast de Transformação Digital\n\n\n\nEsta semana no podcast, Darren continua sua série sobre Abraçar a IA Generativa quando ele entrevista Laura Newey após um semestre ensinando inglês na universidade com o Chat GPT e a IA Generativa como uma ferramenta. Você precisa conferir este episódio e compartilhar com seus alunos universitários. [Leia mais](https://www.embracingdigital.org/en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW49-pt","image":"./briefs/edw-49/pt/thumbnail.png","lang":"pt","summary":"A Intel anunciou recentemente a cisão da empresa de software de IA Articul8, apoiada pela DigitalBridge. O movimento tem como objetivo melhorar as capacidades de IA empresarial. A Articul8 se concentrará no desenvolvimento de soluções avançadas de IA, aproveitando a expertise da Intel no campo. Esta jogada estratégica significa o compromisso da Intel em avançar as tecnologias de inteligência artificial para aplicações industriais mais amplas."},{"id":217,"type":"News Brief","title":"2023-3-5","tags":null,"body":"\n\n## Inteligência Artificial\n\nOs chatbots baseados em IA generativa estão longe de serem perfeitos. ChatGPT, o chatbot da Microsoft Bing, Galactica da Meta (uma IA generativa projetada para ajudar cientistas com tarefas como a anotação de proteínas ou escrita de código), e outros sistemas foram retirados ou tiveram seu uso limitado depois que se descobriu que geravam informações não confiáveis ou incorretas, ou ainda se envolviam em reações emocionais aparentes e até mesmo ameaças.\n\nOs governos dos Estados Unidos e Europeus estão colaborando em um estudo de pesquisa de IA para desenvolver estratégias regulatórias e fomentar a inovação em IA. O estudo abrangerá cinco áreas: previsão do tempo e do clima extremo, gerenciamento de resposta a emergências, melhorias na saúde e medicina, otimização da rede elétrica e otimização da agricultura. Os participantes incluem o Departamento de Energia dos EUA, o Departamento de Agricultura, o Pentágono, a Administração Nacional Oceânica e Atmosférica, agências de saúde e ciência e seus homólogos europeus.\n\n[https://www.axios.com/2023/03/01/ai-research-us-eu](https://www.axios.com/2023/03/01/ai-research-us-eu)\n\nAirdot Deploy: Implantação automática de modelos de ML e dimensionamento escalável. Identifica automaticamente os pacotes necessários, compreende a dependência do módulo, refatora o código, cria APIs REST em torno do modelo de ML, empacota-o em um contêiner, cria a infraestrutura, dimensiona-a automaticamente para cima e para baixo e configura alertas e monitoramento automatizados, tudo com apenas uma linha de código. Isso é muito para a sua equipe DevOps.\n\n[https://www.airdot.io/blog/announcing-airdot-deploy-ml](https://www.airdot.io/blog/announcing-airdot-deploy-ml)\n\n## Segurança Cibernética\n\nUm relatório da Tenable revela que os ciberataques são principalmente realizados usando vulnerabilidades conhecidas para as quais já existem correções disponíveis. Os atores de ameaças continuam a explorar vulnerabilidades que as organizações não conseguiram corrigir, incluindo falhas de alta gravidade no Microsoft Exchange e em soluções de rede virtual privada.\n\n[https://www.helpnetsecurity.com/2023/03/03/known-exploitable-vulnerabilities/?web_view=true](https://www.helpnetsecurity.com/2023/03/03/known-exploitable-vulnerabilities/?web_view=true)\n\nOs CISOs municipais enfrentam desafios à medida que as ameaças cibernéticas aumentam, sendo os ataques de ransomware a maior preocupação. Oakland, Califórnia, declarou recentemente estado de emergência após um ataque de ransomware do Playgroup que interrompeu os sistemas telefônicos e serviços não emergenciais. Este ataque é um dos vários ataques de ransomware a governos locais nos EUA, incluindo Baltimore, New Orleans, Pensacola e Atlanta.\n\n[https://www.csoonline.com/article/3688958/municipal-cisos-grapple-with-challenges-as-cyber-threats-soar.html](https://www.csoonline.com/article/3688958/municipal-cisos-grapple-with-challenges-as-cyber-threats-soar.html)\n\nO Presidente Biden assinou a Lei de Preparação para Segurança Cibernética da Computação Quântica, exigindo que as agências federais priorizem o uso de tecnologia resistente à computação quântica. A lei obriga a orientação para avaliar sistemas críticos com padrões criptográficos pós-quânticos. Isso é em resposta aos temores de que a tecnologia quântica torne a criptografia existente vulnerável a ser quebrada rapidamente.\n\n[https://fedscoop.com/biden-signs-quantum-computing-cybersecurity-act-into-law/](https://fedscoop.com/biden-signs-quantum-computing-cybersecurity-act-into-law/)\n\n## Computação Ubíqua\n\nO relatório anual de nuvem bancária da Accenture descobriu que os bancos que visam migrar sistemas centrais para a nuvem enfrentam um fator de risco importante na dificuldade de encontrar talentos em nuvem. Os bancos percebem a migração central como sendo de alto risco devido à falta de pessoal com conhecimento em nuvem e à dificuldade de recrutar as habilidades necessárias no ambiente atual. A adoção de nuvem pública representa tanto uma atualização de segurança quanto um fator de risco, refletido na falta de adoção de nuvem na indústria bancária.\n\n[https://www.ciodive.com/news/banks-finance-cloud-migration-skils-gap-cybersecurity/644169/](https://www.ciodive.com/news/banks-finance-cloud-migration-skils-gap-cybersecurity/644169/)\n\nA empresa de data warehouse baseada em nuvem, Snowflake, planeja adicionar mais de 1.000 funcionários no ano fiscal atual, de acordo com o CFO Mike Scarpelli durante a chamada de lucros do quarto trimestre da empresa. Isso segue a adição de 1.900 pessoas no ano passado, em contraste com a tendência de redução de pessoal entre outras grandes empresas de tecnologia. A Snowflake planeja priorizar a contratação em produto, engenharia e vendas.\n\n[https://www.ciodive.com/news/Snowflake-expands-workforce-extends-AWS-partnership/644034/](https://www.ciodive.com/news/Snowflake-expands-workforce-extends-AWS-partnership/644034/)\n\nDe acordo com especialistas do setor, os CIOs devem reestruturar seus departamentos de TI e estratégias para aproveitar completamente a transformação na nuvem. Neil Holden, CIO do Grupo Halfords, acredita que os departamentos de TI devem operar de maneira diferente por causa da nuvem e do que ela significa para os negócios. Holden reorganizou sua equipe para garantir que eles pudessem maximizar as capacidades e oportunidades de negócios fornecidas pela nuvem.\n\n[https://www.cio.com/article/463595/transforming-it-for-cloud-success.html](https://www.cio.com/article/463595/transforming-it-for-cloud-success.html)\n\n## Abraçando o Podcast de Transformação Digital.\n\nConfira o episódio completo desta semana \"Inovação como Serviço\" onde Darren entrevista Andrew Cohen, Diretor Executivo da Netsurit.\n\n[https://www.embracingdigital.org/episode-EDT127](https://www.embracingdigital.org/episode-EDT127)\n\n\n\n","guests":null,"link":"/brief-EDW5-pt","image":"./briefs/edw-5/pt/thumbnail.png","lang":"pt","summary":"Summary"},{"id":218,"type":"News Brief","title":"2024-1-14","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","sandworm","hacking","zyxelsecurity","miraibotnet","sechack","bitcoinhack","cryptojacking","openai","aijobs","airegulation","ainetworks","mitai","aiwarfare","taiwanai","israelai","edgecomputing","iotsecurity","5ginorbit","iridiumnetwork","digitaltransformation","zero5gtrust","dataassurance"],"body":"\n\n## Cibersegurança\n\n\nUma nova pesquisa da Forescout desafia a atribuição cibernética em incidentes de hacking, tornando difícil identificar os culpados com precisão. O grupo de hackers Sandworm pode não ter estado envolvido nos ataques cibernéticos que visaram vinte e duas organizações de energia dinamarquesas em maio de dois mil e vinte e três, que exploraram uma falha de segurança no firewall Zyxel e implantaram variantes do botnet Mirai em hosts infectados através de um vetor de acesso inicial desconhecido. As descobertas destacam os desafios na atribuição de ameaças cibernéticas. [Leia mais](https://thehackernews.com/2024/01/new-findings-challenge-attribution-in.html)\n\n\nA conta do Twitter da Comissão de Valores Mobiliários dos Estados Unidos (SEC) foi invadida, com informações falsas postadas sobre fundos de troca negociados em Bitcoin. O FBI está investigando a invasão, e a SEC confirmou que isso resultou de um indivíduo ganhando controle da conta através de um terceiro. O incidente levanta preocupações sobre a vulnerabilidade da plataforma à desinformação. Analistas de segurança expressam preocupação pela falta de autenticação de dois fatores, e legisladores criticaram a SEC por potencialmente minar os mercados. [Leia mais](https://www.wired.com/story/sec-x-account-hack-investigation/)\n\n\nAs autoridades ucranianas, com a ajuda da Europol e de um provedor de nuvem, prenderam um homem de vinte e nove anos em Mykolaiv por orquestrar um sofisticado esquema de criptojacking. O suspeito infiltrou-se em mil quinhentas contas pertencentes a uma conhecida empresa americana utilizando ferramentas de força bruta personalizadas. Ele criou mais de um milhão de computadores virtuais para garantir a operação do malware, obtendo mais de dois milhões de dólares em lucros ilícitos. Cryptojacking explora credenciais comprometidas em plataformas de nuvem, permitindo o uso não autorizado de recursos de computação para minerar criptomoedas. A prisão do suspeito ocorreu no dia nove de janeiro. [Leia mais](https://thehackernews.com/2024/01/29-year-old-ukrainian-cryptojacking.html)\n\n## Inteligência Artificial\n\n\nO CEO da OpenAI, Sam Altman, expressou preocupação sobre a rápida penetração da inteligência artificial (IA) na sociedade. Ele a descreve como a revolução tecnológica mais rápida, destacando a velocidade com que a sociedade precisa se adaptar. Altman acredita que o progresso na IA levará a mudanças nos empregos, mas ele também pensa que criará novas e melhores oportunidades. Altman discute a necessidade de um órgão regulador global para supervisionar sistemas robustos de IA, considerando seu impacto potencial na sociedade e no equilíbrio geopolítico. [Leia mais](https://www.livemint.com/technology/gadgets/amazon-republic-day-sale-top-5-smartwatches-with-up-to-77-discounts-11705312172154.html)\n\n\nUm dos desafios com a inteligência artificial (IA) e as redes neurais é compreender como elas funcionam. Pesquisadores do MIT desenvolveram um novo sistema de IA que estuda e explica o comportamento das redes neurais para tratar deste problema. Esse sistema usa modelos de linguagem pré-treinados e permite uma melhor compreensão dos cálculos das redes neurais. Adicionalmente, os pesquisadores introduziram o parâmetro FIND para avaliar a precisão das técnicas de interpretação. Apesar de algumas limitações, o parâmetro FIND é uma ferramenta valiosa para avaliar a eficácia dos procedimentos de interpretabilidade. [Leia mais](https://www.marktechpost.com/2024/01/13/mit-researchers-developed-a-new-method-that-uses-artificial-intelligence-to-automate-the-explanation-of-complex-neural-networks/)\n\n\nTaiwan e Israel estão usando inteligência artificial para enfrentar diferentes desafios. Taiwan empregou estratégias inovadoras para contrariar a interferência estrangeira em suas eleições, usando ferramentas de IA para sinalizar conteúdo enganoso, estabelecendo iniciativas contra desinformação e monitorando a internet para manipulação de informações. Enquanto isso, as forças armadas de Israel usam um sistema de IA chamado \"o Evangelho\" para localizar alvos mais rapidamente, reduzindo vítimas civis e identificando túneis e lançadores de mísseis do Hamas. Apesar das preocupações com erros algorítmicos e o número de mortes de cidadãos palestinos, o uso de IA por Israel é visto como uma potencial mudança de jogo na guerra tática. [Leia mais](https://lynnwoodtimes.com/2024/01/14/artificial-intelligence-240114/)\n\n## Computação de Borda\n\n\n\nOs Estados Unidos e a União Europeia concordaram com um roteiro conjunto para um programa de rotulagem de consumidores para produtos domésticos inteligentes e dispositivos conectados. O programa apresentará uma marca de confiança cibernética na embalagem do dispositivo para indicar conformidade com os padrões de segurança. A Comissão Federal de Comunicações está liderando a iniciativa e pretende finalizar a política e os padrões até o final de dois mil e vinte e quatro. O programa informará aos consumidores sobre a cibersegurança dos dispositivos IoT, promovendo conscientização e segurança. [Leia mais](https://www.nextgov.com/cybersecurity/2024/01/eu-signs-iot-safety-label-plan/393328/)\n\n\n\nA conectividade IoT 5G do espaço está no horizonte, expandindo a computação de borda além da fabricação tradicional de tijolo e argamassa. Iridium Communications lançou recentemente o Project Stardust, um serviço de rede 5G que utiliza sua constelação de satélites em órbita terrestre baixa. O serviço é projetado para apoiar serviços 5G, dispositivos IoT, mensagens, serviços de emergência e rastreamento de ativos. Iridium começou a testar o serviço em dois mil e vinte e três e planeja lançá-lo comercialmente em dois mil e vinte e seis. [Leia mais](https://www.sdxcentral.com/articles/news/iridiums-project-stardust-satellite-strategy-supports-5g-iot-from-space/2024/01/)\n\n\nEm dois mil e vinte e três, a Internet das Coisas (IoT) observou desenvolvimentos significativos, como a Diretiva de Cibersegurança NIS2 da UE, demissões por grandes players de tecnologia que afetaram a IoT, 5G no espaço e iniciativas impulsionadas pela sustentabilidade. A Renesas adquiriu a fabricante de chips IoT Sequans por duzentos e quarenta e nove milhões de dólares, enquanto as guerras de nuvem IoT se intensificaram com o Google encerrando seu serviço Core IoT. A Pragmatic Semiconductor levantou trezentos e oitenta e nove milhões e trezentos mil dólares, e a Samsara se tornou a ação de IoT com melhor desempenho. A Índia embarcou em uma implementação nacional de medidores inteligentes, e avanços em IA (Inteligência Artificial) e IoT combinados para fornecer reparo guiado e ensinar robôs com sistemas de visão. Uau! Que ano! [Leia mais](https://iot-analytics.com/iot-2023-in-review/)\n\n## Adotando a Transformação Digital\n\n\n\nNesta semana, Darren apresentará seu podcast com duas entrevistas. A primeira entrevista focará na segurança Zero Trust em 5G e a segunda se concentrará em melhorar a garantia de dados em arquiteturas de nuvem, com foco em Abraçar o Zero Trust. Ao sintonizar, você pode aprender sobre as mais recentes transformações digitais. Tivemos um ótimo mês no mês passado, com mais de sessenta mil ouvintes do podcast. Obrigado por compartilhar com seus amigos. [Leia mais](https://www.embracingdigital.org/en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW50-pt","image":"./briefs/edw-50/pt/thumbnail.png","lang":"pt","summary":"Notícias de transformação digital para a semana de 15 de Janeiro de 2024, incluindo atualizações sobre cibersegurança, inteligência artificial e computação de borda. Esta semana, o hack da SEC gera alarmes, a IA é usada para explicar a IA e o 5G é implantado no espaço. "},{"id":219,"type":"News Brief","title":"2024-1-21","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","tapestorage","filestorage","cloudstorage","sql","nosql","cpra","dataprivacy","cisa","openai","pentagon","ibm","quantumcomputing","nuclearecurity","csuite","deepfake","mcafee","digitaltransformation"],"body":"\n\n## Gerenciamento de Dados\n\n\nO Hammerspace integrou recentemente o armazenamento em fita ao seu sistema global de arquivos para melhorar as capacidades de gestão de dados. Esta integração permite aos utilizadores aceder e gerir eficientemente os dados em diferentes meios de armazenamento, promovendo a flexibilidade nas soluções de armazenamento de arquivos. A solução atual oferecida pelo Hammerspace estabelece um sistema global de arquivos que abrange vários centros de dados, nuvens e limites tradicionais de borda. [Leia mais](https://www.techtarget.com/searchstorage/news/366566738/Hammerspaces-global-file-system-now-includes-tape)\n\n<hr>\n\n\nA gestão de dados heterogêneos é essencial para os negócios modernos. O Toad Data Studio suporta SQL, NoSQL e bancos de dados em nuvem, fornecendo capacidades abrangentes de gerenciamento de banco de dados. A compatibilidade entre plataformas simplifica os fluxos de trabalho, a otimização de consultas aprimora o desempenho do banco de dados e as ferramentas de colaboração permitem um trabalho em equipe eficiente. Portanto, o Toad Data Studio é um recurso indispensável para gerenciar e administrar bancos de dados em vários ambientes. [Leia mais](https://www.infoworld.com/article/3712250/toad-data-studio-manages-sql-nosql-and-cloud-databases.html)\n\n<hr>\n\n\nSe você opera um negócio na Califórnia, é crucial se preparar para o iminente Ato de Direitos de Privacidade da Califórnia (CPRA) ao refinar suas práticas de privacidade de dados. Ao aprimorar o gerenciamento de dados, mecanismos de consentimento e estratégias de conformidade, você pode cumprir os requisitos do CPRA e se manter à frente na proteção da privacidade do consumidor. Recomenda-se que medidas proativas sejam implementadas para garantir que o seu negócio esteja totalmente em conformidade com o CPRA. [Leia mais](https://www.jdsupra.com/legalnews/prepare-for-the-cpra-by-improving-your-7537199/)\n\n<hr>\n\n## Cibersegurança\n\n\nO CISA lançou um guia completo de resposta a incidentes de cibersegurança adaptado para empresas de água. O guia foi projetado para ajudar as empresas a responder eficazmente a incidentes de cibersegurança e a mitigar potenciais ameaças cibernéticas. Ele fornece percepções valiosas e serve como um recurso para as empresas de água reforçarem suas capacidades de resposta a incidentes. Esta medida é um passo significativo na luta contra ataques cibernéticos à infraestrutura crítica no setor da água. [Leia mais](https://www.techtarget.com/searchsecurity/news/366566740/CISA-posts-incident-response-guide-for-water-utilities)\n\n<hr>\n\n\nA OpenAI fez parceria com o Pentágono em uma iniciativa de cibersegurança, representando uma mudança em relação à sua postura anterior. Ao aproveitar a experiência da OpenAI, a parceria visa avançar nas capacidades de cibersegurança para a defesa. Esse desenvolvimento destaca o papel em evolução da IA nos esforços de segurança nacional, com a OpenAI contribuindo ativamente para projetos de cibersegurança em colaboração com o Pentágono. [Leia mais](https://www.semafor.com/article/01/16/2024/openai-is-working-with-the-pentagon-on-cybersecurity-projects)\n\n<hr>\n\n\n\nA IBM alertou que o surgimento da computação quântica pode resultar em uma grave ameaça à segurança cibernética. A preocupação é que computadores quânticos possam quebrar métodos de criptografia amplamente utilizados, o que exigiria o desenvolvimento de medidas de segurança resistentes à tecnologia quântica. As organizações estão sendo incentivadas a tomar medidas proativas para se prepararem para os futuros desafios impostos pela computação quântica na segurança cibernética. [Leia mais](https://www.bloomberg.com/news/articles/2024-01-17/quantum-computing-to-spark-cybersecurity-armageddon-ibm-says)\n\n<hr>\n\n## Inteligência Artificial\n\n\nIntegrar a inteligência artificial (IA) aos processos de tomada de decisão dentro da segurança atômica levanta questões instigantes sobre como as tecnologias de IA podem influenciar a estabilidade, as dinâmicas de confiança e o equilíbrio estratégico geral no contexto das capacidades nucleares. É essencial garantir a implementação responsável da IA para evitar consequências não intencionais que possam ameaçar a segurança e a estabilidade global. A necessidade crítica de uma integração confiável da IA enfatiza a importância de fornecer um ambiente internacional seguro e estável no contexto das capacidades nucleares.\n [Leia mais](https://warontherocks.com/2024/01/artificial-intelligence-and-nuclear-stability/)\n\n<hr>\n\n\nA inteligência artificial (IA) está a caminho de perturbar a alta gerência de três maneiras significativas. Os executivos podem esperar mudanças nos processos de tomada de decisão, na dinâmica da força de trabalho e no papel geral dos líderes. À medida que a IA continua evoluindo, seu impacto transformador remodela os paradigmas de liderança tradicionais. Os executivos são incentivados a se adaptar a essas mudanças e a aproveitar estrategicamente a IA para uma vantagem competitiva no ambiente de negócios dinâmico. [Leia mais](https://www.cio.com/article/1293438/3-ways-ai-is-set-to-disrupt-the-c-suite.html)\n\n<hr>\n\n\nA McAfee lançou um sistema de detecção de áudio deepfake alimentado por inteligência artificial para lidar com a crescente ameaça de conteúdo de áudio manipulado. A tecnologia é projetada para identificar e mitigar riscos associados ao áudio deepfake, enfatizando a necessidade de soluções avançadas de detecção e prevenção. Isso reflete a importância crescente da IA na contraposição a ameaças emergentes em mídia manipulada e no aprimoramento de medidas de segurança cibernética. [Leia mais](https://www.artificialintelligence-news.com/2024/01/08/mcafee-unveils-ai-powered-deepfake-audio-detection/)\n\n<hr>\n\n## Abraçando a Transformação Digital\n\n\n\nO último episódio de Darren no podcast Embracing Digital Transformation mergulha no mundo de gerenciamento de dados de R&D na fabricação. Ele examina as complexidades da coleta e análise de dados, desde a inovadora pesquisa pura até o processo de fabricação mais previsível. É uma exploração perspicaz dos desafios e oportunidades da transformação digital neste campo. [Leia mais](https://www.embracingdigital.org)\n\n<hr>\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW51-pt","image":"./briefs/edw-51/pt/thumbnail.png","lang":"pt","summary":"Prepare-se para as notícias desta semana sobre Transformação Digital de 22 de janeiro de 2024, que apresenta histórias sobre gestão de dados, cibersegurança e inteligência artificial. Esta semana, temos notícias sobre os direitos de privacidade de dados na Califórnia, dicas para proteger sua organização de ataques cibernéticos relacionados à IA e computação quântica, e uma análise de como a IA está sendo usada para ajudar o governo a tomar decisões em tempos de guerra."},{"id":220,"type":"News Brief","title":"2023-3-12","tags":null,"body":"\n\n## Inteligência Artificial.\n\nA Microsoft confirma que uma nova versão do seu popular chatbot de IA será capaz de transformar texto em VÍDEO. O GPT-4 e futuros desenvolvimentos mudarão para sempre a forma como pensamos sobre inteligência artificial. Esta poderosa IA é capaz de processar texto e números, vídeos, imagens e muito mais. A Microsoft explicou que o GPT-4 seria \"multimodal\". Holger Kenn, Diretor de Estratégia de Negócios da Microsoft na Alemanha, explicou que isso permitiria que a IA da empresa traduzisse o texto do usuário em imagens, música e vídeo.\n\nIA para substituir atores? Imagine usar IA para criar um filme sem contratar atores reais ou escrever um livro ilustrado com 200 páginas em apenas um dia. Sim, você leu isso certo, o GPT-4 torna possível usar inteligência artificial para quase tudo o que você possa imaginar.\n\nSchrodinger: Um simulador de mercado financeiro totalmente interativo e integrado ao ChatGPT com múltiplos agentes. A Citadel, um dos hedge funds mais bem-sucedidos do mundo, está em negociações para obter uma licença empresarial do ChatGPT. O ChatGPT pode produzir código correto com uma estratégia simples de execução de negociações.\n\n[https://www.youtube.com/watch?v=tvzO79V9uq4](https://www.youtube.com/watch?v=tvzO79V9uq4)\n\n## Gerenciamento de dados.\n\n\"Zero\" é a nova palavra do dia, com a \"Data Alliance\" cunhando a palavra Zero-Copy para novas arquiteturas de dados distribuídos. A integração Zero-copy é um conceito que permite compartilhar dados entre diferentes sistemas sem copiá-los. A abordagem tradicional de copiar dados de um sistema para outro pode levar a ineficiências, problemas de consistência de dados e vulnerabilidades de segurança.\n\n[http://tdan.com/the-data-centric-revolution-zero-copy-integration/30462](http://tdan.com/the-data-centric-revolution-zero-copy-integration/30462)\n\nA pandemia de COVID-19 acelerou a visão de dados em todos os lugares, na nuvem, no centro de dados, nos laptops e nos dispositivos IoT. Essa dispersão de dados fez com que as organizações de TI reavaliassem suas estratégias de dados. Novas estratégias e soluções de gerenciamento de dados distribuídos precisam ser desenvolvidas, que sejam mais abrangentes no gerenciamento de tipos heterogêneos de dados, incluindo dados estruturados, semi-estruturados e não estruturados.\n\n[https://www.engineeringnews.co.za/article/modern-data-management-platforms-are-vital-for-solving-modern-data-management-problems-2023-03-14/rep_id:4136](https://www.engineeringnews.co.za/article/modern-data-management-platforms-are-vital-for-solving-modern-data-management-problems-2023-03-14/rep_id:4136)\n\nA complexidade da governança de dados está impulsionando mudanças organizacionais, incluindo a emergência do papel de guardião de dados nas organizações. Os guardiões de dados estão começando a gerenciar o acesso aos dados, preocupações com privacidade e gerenciamento do ciclo de vida dos dados. Colocar guardiões de dados na organização ainda está em debate saudável à medida que as organizações amadurecem em suas estratégias centradas em dados.\n\n[https://www.techtarget.com/searchdatamanagement/tip/Data-stewardship-Essential-to-data-governance-strategies](https://www.techtarget.com/searchdatamanagement/tip/Data-stewardship-Essential-to-data-governance-strategies)\n\n## Cibersegurança\n\nUm kit de phishing de adversário no meio de código aberto (AiTM) encontrou vários compradores no mundo do cibercrime por sua capacidade de orquestrar ataques em escala. A inteligência de ameaças da Microsoft rastreia o ator de ameaças por trás do desenvolvimento do kit sob o nome emergente DEV-1101. Um ataque de phishing AiTM geralmente envolve um ator de ameaças tentando roubar e interceptar a senha e os cookies de sessão de um alvo implantando um servidor proxy entre o usuário e o site.\n\n[https://thehackernews.com/2023/03/microsoft-warns-of-large-scale-use-of.html](https://thehackernews.com/2023/03/microsoft-warns-of-large-scale-use-of.html)\n\nA Agência de Segurança Cibernética e de Infraestrutura (CISA) alertou organizações que operam infraestruturas críticas sobre vulnerabilidades de ransomware em seus dispositivos. O aviso inclui uma lista de dispositivos que os atacantes podem visar e recomenda que as organizações avaliem suas redes em busca de possíveis riscos. A CISA tem um novo programa piloto de aviso de vulnerabilidade de ransomware (RVWP) com dois objetivos: escanear as redes das entidades de infraestrutura crítica e ajudar as organizações vulneráveis a corrigir as falhas antes que sejam hackeadas.\n\n[https://www.bleepingcomputer.com/news/security/cisa-now-warns-critical-infrastructure-of-ransomware-vulnerable-devices/](https://www.bleepingcomputer.com/news/security/cisa-now-warns-critical-infrastructure-of-ransomware-vulnerable-devices/)\n\nUm relatório da Drata destaca as principais tendências de conformidade para 2023. O relatório delinea a mudança em direção ao monitoramento contínuo de conformidade e a necessidade de ferramentas de automação para alcançar a conformidade. Também destaca o foco crescente em regulamentos de privacidade e a importância cada vez maior da gestão de risco de fornecedores. O relatório recomenda que as empresas priorizem seus esforços de conformidade, utilizem ferramentas de automação e mantenham-se atualizadas com os requisitos regulatórios em evolução para evitar possíveis multas e danos à reputação.\n\n[https://drata.com/resources/2023-compliance-trends](https://drata.com/resources/2023-compliance-trends)\n\n## Abraçando a Transformação Digital Podcast.\n\nConfira o episódio completo desta semana \"Fechando a Lacuna de Habilidades Digitais\", onde Darren entrevista Jon Gottfried da Major League Hacking.\n\n[https://www.embracingdigital.org/episode-EDT128](https://www.embracingdigital.org/episode-EDT128)\n\n\n\n","guests":null,"link":"/brief-EDW6-pt","image":"./briefs/edw-6/pt/thumbnail.png","lang":"pt","summary":"Summary"},{"id":221,"type":"News Brief","title":"2023-3-19","tags":["ai","compute","datamanagement"],"body":"\n\n\n## Inteligência artificial\n\n## Computação Ubíqua\n\n## Borda Inteligente\n\n## Gestão de Dados\n\n## Cíber Segurança\n\n## Comunicações Avançadas\n## Inteligência Artificial.\n\nNa seção \"Potencial para Comportamentos Emergentes de Risco\" do relatório técnico da empresa, a OpenAI se associou ao Centro de Pesquisa em Alinhamento para testar as habilidades do GPT-4. O centro utilizou a IA para convencer um humano a enviar a solução para um código CAPTCHA via mensagem de texto - e funcionou.\n\n[https://gizmodo.com/gpt4-open-ai-chatbot-task-rabbit-chatgpt-1850227471](https://gizmodo.com/gpt4-open-ai-chatbot-task-rabbit-chatgpt-1850227471)\n\nRecursos do Copilot, executivos da Microsoft mencionaram a tendência do software em produzir respostas imprecisas, mas apresentaram isso como algo que poderia ser útil. Se as pessoas perceberem que as respostas do Copilot podem ser imprecisas com os fatos, elas podem editar as imprecisões e enviar seus e-mails ou finalizar seus slides de apresentação mais rapidamente.\n\n[https://www.cnbc.com/2023/03/16/microsoft-justifies-ais-usefully-wrong-answers.html?__source=sharebar|linkedin&par=sharebar](https://www.cnbc.com/2023/03/16/microsoft-justifies-ais-usefully-wrong-answers.html?__source=sharebar|linkedin&par=sharebar)\n\nO Google Health anunciou o Med-PaLM 2, uma nova e inovadora versão de seu grande modelo de linguagem médica. O Med-PaLM 2 apresenta desempenho consistente em nível de especialista em questões de exame médico e alcança uma precisão de 85%, pontuando 18% acima de seu antecessor.\n\n## Computação Ubíqua.\n\nEm breve, você poderá nadar em cima de um centro de dados 😊 Uma empresa de tecnologia britânica, Deep Green, planeja instalar pequenos centros de dados em piscinas públicas em todo o Reino Unido. Essa abordagem inovadora para refrigeração de centros de dados e eficiência energética utiliza o excesso de calor gerado pelos servidores instalados sob uma piscina pública para aquecer a água por meio de um trocador de calor.\n\nO governo dos EUA lançou uma nova iniciativa para ajudar organizações a detectar falhas de segurança nos serviços em nuvem da Microsoft. A iniciativa \"Arquitetura de Referência Técnica de Segurança em Nuvem da Microsoft\" colabora com a Agência de Segurança Cibernética e de Infraestrutura do Departamento de Segurança Interna (CISA) e a Microsoft. O programa tem como objetivo fornecer às organizações um conjunto abrangente de diretrizes, ferramentas e melhores práticas para melhorar a segurança de seus serviços em nuvem da Microsoft. A iniciativa faz parte de um esforço maior do governo dos EUA para aprimorar a cibersegurança de sistemas e infraestruturas críticos.\n\n[https://www.techradar.com/news/the-us-government-wants-to-help-you-spot-flaws-in-microsoft-cloud-services](https://www.techradar.com/news/the-us-government-wants-to-help-you-spot-flaws-in-microsoft-cloud-services)\n\nDe acordo com uma pesquisa recente, 83% dos Chief Information Officers (CIOs) sentem que precisam fazer mais com menos em 2023. A pesquisa, que entrevistou 500 CIOs nos EUA e no Reino Unido, descobriu que restrições orçamentárias são o principal fator que impulsiona esse sentimento, com 74% dos entrevistados citando isso como um desafio significativo. Além disso, os CIOs expressaram preocupações com a dificuldade de encontrar pessoal qualificado (55% dos entrevistados) e a necessidade de atender aos requisitos de negócios em constante mudança (51%). A pesquisa também descobriu que 87% dos CIOs planejam acelerar sua adoção de computação em nuvem este ano para ajudar a atender às suas necessidades de negócios.\n\n[https://www.cloudcomputing-news.net/news/2023/mar/13/83-of-cios-must-do-more-with-less-in-2023/](https://www.cloudcomputing-news.net/news/2023/mar/13/83-of-cios-must-do-more-with-less-in-2023/)\n\n## Gerenciamento de Dados.\n\nUma pesquisa da TDWI descobriu que as organizações estão adotando uma estratégia de gestão de dados para melhorar a qualidade dos dados e reduzir silos. 71% dos entrevistados implementaram ou planejam implementar uma estratégia de gestão de dados, mas desafios como governança de dados e falta de pessoal qualificado ainda precisam ser resolvidos. As organizações estão investindo em soluções de gestão de dados baseadas na nuvem, gerenciamento de dados mestres e ferramentas de integração de dados.\n\n[https://tdwi.org/articles/2023/03/23/diq-all-data-management-0323.aspx](https://tdwi.org/articles/2023/03/23/diq-all-data-management-0323.aspx)\n\nA inteligência artificial (IA) tem o potencial de ajudar a resolver o problema da sobrecarga de dados de TI. Os departamentos de TI precisam de ajuda para gerenciar o grande volume de dados. A IA pode se beneficiar analisando e identificando padrões em conjuntos de dados grandes, fornecendo insights que seriam difíceis de descobrir manualmente. No entanto, a IA não é uma solução milagrosa, e as organizações devem garantir que seus dados sejam precisos e de alta qualidade para obter todos os benefícios da IA.\n\n[https://www.infoworld.com/article/3689668/can-ai-solve-it-s-eternal-data-problem.html](https://www.infoworld.com/article/3689668/can-ai-solve-it-s-eternal-data-problem.html)\n\nUm novo relatório revela a importância da gestão de dados para as empresas. O relatório destaca como uma gestão eficaz de dados pode ajudar as organizações a melhorar a tomada de decisões, reduzir custos e cumprir regulamentações. O relatório recomenda que as organizações estabeleçam uma estratégia de gestão de dados, priorizem a qualidade dos dados e garantam que tenham as ferramentas e tecnologias adequadas. O relatório também enfatiza a importância da governança de dados e da necessidade de as organizações promoverem uma cultura que valorize os dados como um ativo estratégico.\n\n[https://solutionsreview.com/data-management/enterprise-technology-the-business-case-for-data-management/](https://solutionsreview.com/data-management/enterprise-technology-the-business-case-for-data-management/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW7-pt","image":"./briefs/edw-7/pt/thumbnail.png","lang":"pt","summary":"Resumo"},{"id":222,"type":"News Brief","title":"2023-3-26","tags":["ai","compute","cybersecurity"],"body":"\n\n\n## Inteligência artificial\n\n## Computação Ubíqua\n\n## Borda Inteligente\n\n## Gestão de Dados\n\n## Cíber Segurança\n\n## Comunicações Avançadas\n## Computação Ubíqua\n\nGordon Moore, o co-fundador da Intel Corporation e inventor da Lei de Moore, faleceu em 24 de março de 2023 aos 92 anos. Nascido em 1929, Moore co-fundou a Intel em 1968 e serviu como CEO de 1975 a 1987. Ele é mais conhecido por sua previsão, a Lei de Moore, que previa que o número de transistores em um microchip dobraria aproximadamente a cada dois anos, levando a um crescimento exponencial na capacidade de processamento. Essa previsão tem se mantido por mais de 50 anos e desempenhou um papel vital no impulsionamento do avanço da indústria de tecnologia.\n\nO 4004, o primeiro microprocessador da Intel, estreou em 1971 como o primeiro microprocessador comercialmente disponível. Inicialmente projetado para calculadoras, rapidamente encontrou aplicações em outras áreas, como controladores de semáforos e caixas registradoras eletrônicas. O 4004 continha 2.300 transistores em um único chip e ajudou a estabelecer a Intel como um importante player na indústria de semicondutores. Hoje, os microprocessadores são usados ​​em vários dispositivos, desde smartphones até supercomputadores.\n\nA Intel anunciou a disponibilidade da sua mais recente série de processadores Xeon Max Scalable, baseada na arquitetura Sapphire Rapids. A série Xeon Max apresenta 100 bilhões de transistores SuperFin de 10 nm, aceleração de IA e criptografia, e suporte PCIe 5.0, proporcionando desempenho e segurança aprimorados para cargas de trabalho de computação empresarial. Isso representa 40 milhões de vezes mais transistores no processador mais recente do que no primeiro processador há mais de 50 anos.\n\n[https://www.datacenterdynamics.com/en/news/intel-announces-xeon-max-sapphire-rapids-cpus/](https://www.datacenterdynamics.com/en/news/intel-announces-xeon-max-sapphire-rapids-cpus/)\n\n## Inteligência Artificial\n\nO ChatGPT, um grande modelo de linguagem treinado pela OpenAI, teve um problema técnico que o deixou inoperante por várias horas. O problema, causado por um bug no sistema, afetou a função de histórico do modelo, tornando-o incapaz de acessar suas conversas anteriores. A OpenAI resolveu o problema e o ChatGPT está agora totalmente operacional. O incidente serve como um lembrete dos riscos potenciais de depender da IA e da importância de ter sistemas robustos para lidar com problemas técnicos.\n\n[https://www.independent.co.uk/tech/chatgpt-down-bug-issue-history-b2306269.html](https://www.independent.co.uk/tech/chatgpt-down-bug-issue-history-b2306269.html)\n\nBard, um modelo de linguagem de inteligência artificial desenvolvido pelo Google como concorrente do GPT da OpenAI, agora está disponível para uso público. Bard, que usa uma abordagem diferente para modelagem de linguagem do que o GPT, tem como objetivo gerar textos mais criativos e diversos, permitindo que os usuários insiram suas sugestões e restrições. A liberação do Bard para uso público deve acelerar o desenvolvimento de novas aplicações de processamento de linguagem natural e avançar o campo da modelagem de linguagem de IA.\n\n[https://www.bloomberg.com/news/articles/2023-03-21/google-chatgpt-rival-bard-now-open-to-public-use](https://www.bloomberg.com/news/articles/2023-03-21/google-chatgpt-rival-bard-now-open-to-public-use)\n\nUm novo método de agricultura, a Synecoculture, envolve o plantio de múltiplas espécies de plantas juntas em alta densidade. No entanto, pode ser um processo complexo devido às diferentes velocidades de crescimento e estações. Pesquisadores desenvolveram um robô para semear, podar e colher plantas em crescimento de vegetação densa para abordar esse problema. O corpo pequeno e flexível do robô será útil na Synecoculture em larga escala, tornando-o um passo essencial para alcançar a agricultura sustentável e a neutralidade de carbono.\n\n[https://www.sciencedaily.com/releases/2023/03/230320102001.htm](https://www.sciencedaily.com/releases/2023/03/230320102001.htm)\n\n## Cibersegurança\n\nA Agência de Segurança Cibernética e Infraestrutura dos EUA (CISA) lançou uma nova ferramenta para detectar atividades maliciosas em serviços de nuvem da Microsoft. A ferramenta Sparrow pode escanear ambientes Azure e Microsoft 365 em busca de sinais de hacking e outras atividades não autorizadas. O Sparrow utiliza dados de código aberto e algoritmos de inteligência artificial para identificar possíveis ameaças e fornecer aos usuários recomendações acionáveis ​​para prevenir danos adicionais. O lançamento do Sparrow faz parte dos esforços contínuos da CISA para melhorar a segurança de sistemas baseados na nuvem e proteger contra ataques cibernéticos.\n\n[https://www.bleepingcomputer.com/news/security/new-cisa-tool-detects-hacking-activity-in-microsoft-cloud-services/](https://www.bleepingcomputer.com/news/security/new-cisa-tool-detects-hacking-activity-in-microsoft-cloud-services/)\n\nOs veículos elétricos da Tesla foram hackeados duas vezes durante a competição anual de exploração Pwn2Own organizada pela Zero Day Initiative. Uma equipe de pesquisadores conseguiu explorar uma vulnerabilidade no sistema de entretenimento de um Modelo 3 para assumir o controle dos faróis, alto-falantes e outros métodos do veículo. Outra equipe usou um bug na mesma abordagem para executar código e acessar os dados do carro. Desde então, a Tesla lançou uma correção over-the-air para corrigir as vulnerabilidades.\n\n[https://www.securityweek.com/tesla-hacked-twice-at-pwn2own-exploit-contest/](https://www.securityweek.com/tesla-hacked-twice-at-pwn2own-exploit-contest/)\n\nA Intel anunciou sua nova plataforma Core vPro de 13ª geração, que apresenta recursos de segurança baseados em hardware projetados para reduzir a superfície de ataque da plataforma. A nova plataforma inclui o Intel Hardware Shield, que usa detecção de ameaças em nível de CPU para fornecer um processo de inicialização seguro, e a Tecnologia de Aplicação de Fluxo de Controle da Intel, que ajuda a impedir ataques de programação orientada a retorno (ROP). A plataforma também inclui a Tecnologia de Detecção de Ameaças da Intel, que usa aprendizado de máquina para identificar possíveis ameaças à segurança. A plataforma Core vPro de 13ª geração é direcionada a clientes empresariais que procuram recursos avançados de segurança para proteger contra ataques cibernéticos cada vez mais sofisticados.\n\n[https://www.securityweek.com/intel-boasts-attack-surface-reduction-with-new-13th-gen-core-vpro-platform/](https://www.securityweek.com/intel-boasts-attack-surface-reduction-with-new-13th-gen-core-vpro-platform/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW8-pt","image":"./briefs/edw-8/pt/thumbnail.png","lang":"pt","summary":"Resumo"},{"id":223,"type":"News Brief","title":"2023-4-2","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Cibersegurança\n\nNovo malware para macOS chamado MacStealer rouba dados do iCloud Keychain e senhas. Um novo malware de roubo de informações tem como alvo o sistema operacional macOS da Apple para extrair informações confidenciais de dispositivos comprometidos. O MacStealer é o mais recente exemplo de uma ameaça que usa o Telegram como uma plataforma de comando e controle (C2) para extrair dados.\n\nA Microsoft emite patch para falha de privacidade aCropalypse nas ferramentas de captura de tela do Windows. A Microsoft lançou uma atualização fora de banda para resolver uma falha que derrota a privacidade em sua ferramenta de edição de captura de tela para Windows 10 e 11. A questão, apelidada de aCropalypse, poderia permitir que atores mal-intencionados recuperassem partes editadas de capturas de tela, potencialmente revelando informações sensíveis que poderiam ter sido cortadas.\n\nOpenAI revela bug do Redis por trás do incidente de exposição de dados do usuário do ChatGPT. A OpenAI divulgou que um bug na biblioteca open-source Redis foi responsável por expor informações pessoais de outros usuários e títulos de chat no serviço ChatGPT da empresa no início desta semana. O erro, descoberto em 20 de março de 2023, permitiu que certos usuários visualizassem descrições breves das conversas de outros usuários na barra lateral do histórico de bate-papo, o que levou a empresa a agir.\n\n## Inteligência Artificial\n\nIsso é grande: Elon Musk, Bill Gates e outros líderes de tecnologia pedem uma pausa na corrida \"fora de controle\" da IA. Mais de 1.100 signatários notáveis acabaram de assinar uma carta aberta pedindo \"a todos os laboratórios de IA que parem imediatamente por pelo menos 6 meses\". A carta, que também foi assinada pelo CEO da OpenAI, disse que a pausa deveria se aplicar aos sistemas de IA \"mais poderosos que o GPT-4\". Também afirmou que especialistas independentes deveriam usar a pausa proposta para desenvolver e implementar conjuntamente um conjunto de protocolos compartilhados para ferramentas de IA que sejam seguras \"além de uma dúvida razoável\".\n\n[https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/](https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/)\n\nA Cerebras Systems lançou sete novos modelos GPT treinados em sistemas de escala de wafer CS-2. É a primeira vez que uma empresa usa sistemas de IA não baseados em GPU para treinar LLMs com até 13 bilhões de parâmetros e está compartilhando os modelos, pesos e receita de treinamento por meio da licença Apache 2.0 padrão do setor. São sete modelos GPT com 111M a 13B de parâmetros. Normalmente, essa é uma tarefa que leva vários meses, mas esse trabalho foi concluído em poucas semanas. Os sete modelos Cerebras-GPT estão imediatamente disponíveis no Hugging Face e no Cerebras Model Zoo no GitHub.\n\n[https://www.marketwatch.com/press-release/cerebras-systems-releases-seven-new-gpt-models-trained-on-cs-2-wafer-scale-systems-2023-03-28](https://www.marketwatch.com/press-release/cerebras-systems-releases-seven-new-gpt-models-trained-on-cs-2-wafer-scale-systems-2023-03-28)\n\nGoogle Bard com Wordle - poderia ter sido melhor. Depois de corrigir o robô e lembrá-lo para adivinhar apenas palavras de cinco letras, ele se desculpou e retornou com SLANTS, e depois continuou com diferentes variações da palavra SLANT ☹\n\n[https://www.techradar.com/news/i-tried-to-use-google-bard-to-help-me-with-wordle-but-it-didnt-go-well](https://www.techradar.com/news/i-tried-to-use-google-bard-to-help-me-with-wordle-but-it-didnt-go-well)\n\n## Borda Inteligente\n\nA BT colaborou com a Amazon Web Services (AWS) para testar a computação de borda 5G em Manchester usando o AWS Wavelength. O teste investigará como a computação de borda pode melhorar o desempenho da rede 5G da BT em três áreas-chave: realidade aumentada, jogos imersivos e automação industrial. O objetivo é melhorar a experiência do cliente, fornecendo serviços mais rápidos e confiáveis. O teste faz parte de uma colaboração maior entre as duas empresas para explorar o potencial da computação de borda no Reino Unido.\n\n[https://www.edgecomputing-news.com/2023/03/29/bt-uses-aws-wavelength-for-5g-edge-trial-in-manchester/](https://www.edgecomputing-news.com/2023/03/29/bt-uses-aws-wavelength-for-5g-edge-trial-in-manchester/)\n\nA Comcast anunciou parcerias expandidas com o objetivo de melhorar a conectividade em edifícios e ambientes inteligentes. As parcerias incluem acordos com o provedor de infraestrutura avançada de medição Sensus e a BuildingIQ, um provedor de soluções de gerenciamento de energia baseado em inteligência artificial. O objetivo é fornecer gerenciamento de energia mais inteligente, melhor gerenciamento de água e automação predial aprimorada. Essas parcerias fazem parte dos esforços da Comcast para melhorar a conectividade para clientes comerciais por meio de sua rede de hotspots Wi-Fi, sensores e outros dispositivos IoT.\n\n[https://www.edgeir.com/comcast-focuses-connectivity-on-smarter-buildings-environments-with-expanded-partnerships-20230331](https://www.edgeir.com/comcast-focuses-connectivity-on-smarter-buildings-environments-with-expanded-partnerships-20230331)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW9-pt","image":"./briefs/edw-9/pt/thumbnail.png","lang":"pt","summary":"Resumo"}]