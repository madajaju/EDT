[{"id":0,"type":"Episode","title":"Storia dell'architettura centrata sui dati","tags":["dataarchitecture","softwaredeveloper","microservice","container","virtualization","technology","compute","data"],"body":"\r\n\r\nIn questo episodio, Darren parla della storia delle applicazioni e di come recenti cambiamenti, principalmente a causa dell'attacco continuo,\n\nd have the systems and processes in place to effectively manage and make sense of all the data being generated. This influx of data is overwhelming traditional data management methods and requires new approaches and technologies to handle it efficiently.\n\nOne significant challenge is the sheer volume of data being produced. With billions of devices connected to the internet, each continuously collecting and transmitting data, the amount of information being generated is unprecedented. Traditional database systems struggle to handle such large quantities of data, leading to issues of scalability, performance, and data quality.\n\nAnother challenge is the variety of data being generated. Internet of Things devices generate data in various formats, including structured, semi-structured, and unstructured data. This diversity makes it difficult to integrate and analyze the data effectively, as traditional database systems are designed to handle structured data only.\n\nFurthermore, the velocity at which data is generated poses a challenge. IoT devices generate and transmit data in real-time, requiring timely processing and analysis to derive meaningful insights. Traditional batch processing methods, commonly used in data-centric architectures, are not sufficient for handling real-time data streams.\n\nTo address these challenges, new technologies and approaches are emerging. For instance, distributed and scalable data processing frameworks like Apache Hadoop and Spark enable the parallel processing of large datasets across multiple nodes, improving scalability and performance. Streaming platforms, such as Apache Kafka, allow real-time processing and analysis of data streams.\n\nAdditionally, advanced analytics techniques, such as machine learning and artificial intelligence, can help derive valuable insights from the massive amounts of IoT data. These techniques can identify patterns, predict future events, and automate decision-making processes, enabling organizations to leverage the full potential of IoT data.\n\nIn conclusion, the Internet of Things is revolutionizing data-centric architectures, but also posing challenges in terms of data volume, variety, and velocity. To effectively manage and make sense of IoT data, organizations need to adopt new technologies and approaches that can handle the scale, diversity, and real-time nature of this data.\n\nAncora non abbiamo un modo adatto per gestire tutti i nostri dati. Ci sono tre elementi che devono essere modificati per facilitare questo processo:\n\nis stored and how it is accessed.\n\ne vengono distribuiti su migliaia di dispositivi periferici e tra cloud pubblici e privati.\n\n## Hardware-software Stacks appositamente progettati\n\ncome si distribuiscono le applicazioni per le missioni oggi non è cambiato significativamente negli ultimi trent'anni. un'architettura di riferimento\n\nche ha un'applicazione e uno stack di applicazioni costruito su hardware specifico, con calcolo e archiviazione collegati a\n\nRete. Questo modello ha funzionato bene per molto tempo e infatti, circa un quarto delle applicazioni ancora vengono implementate.\n\nIT: Su hardware appositamente realizzato, ma non è ottimale oggi. La tecnologia si evolve troppo velocemente per questo modello; si verificano deragliamenti.\n\nl'aggiunta, ci sono tempi di sviluppo lunghi, costi elevati, limitata riutilizzo della tecnologia, e mancanza di integrazione con\n\naltri applicazioni.\n\n## Architetture di virtualizzazione\n\nCirca 20 - 25 anni fa, la virtualizzazione hardware ha iniziato a risolvere alcuni di questi problemi con la capacità di implementare.\n\napplications, you could now have them all on one machine.\n\nmacchine più piccole, potrebbe essere utilizzato un solo pezzo di hardware più grande, non solo per il calcolo, ma anche per lo storage virtuale e la rete\n\nfunzioni anche, portando a una maggiore convenienza economica. Come con ogni sviluppo, ciò ha sollevato alcune nuove questioni.\n\nCrescenti preoccupazioni per la sicurezza e \"vicini rumorosi\", significando un'applicazione che interferisce con le prestazioni di un'altra.\n\na causa dell'utilizzo eccessivo della banda IO, della rete o dello spazio di archiviazione, ecc..\n\n## Le architetture delle nuvole\n\nNegli anni 2000, la tecnologia del cloud decollò. Potevamo ora condividere tra più organizzazioni. Dove la virtualizzazione.\n\nTraduzione: \ncreata l'astrazione dell'hardware, la tecnologia cloud ha creato l'astrazione delle operazioni, rendendo più facile gestire più elementi\n\ntradurre la seguente frase in italiano: Le macchine. L'idea architettonica del cloud ha creato \"infrastrutture definite dal software\", il che facilita il processo di attivazione e\n\nAllocate le risorse di calcolo, archiviazione e rete a un livello inferiore. Altri vantaggi includono una diminuzione dei costi di investimento e di gestione operativa, grazie a minori\n\nhardware e manodopera. Inoltre, ha fornito la capacità di esplosione, ad esempio, per i rivenditori durante la frenetica stagione delle vacanze o il\n\ngoverno durante il censimento. Con il progresso di questa tecnologia, le questioni di sicurezza e vicini rumorosi\n\nprivate clouds.\n\ntraduci in italiano: cloud privati. Anche con queste preoccupazioni, però, i vantaggi superano di gran lunga gli svantaggi nella maggior parte dei casi.\n\n## Architetture di servizio e contenitore\n\nNegli ultimi cinque-sei anni, abbiamo assistito alla reinvenzione di una vecchia tecnologia: la containerizzazione. Docker ha creato un nuovo modo di incapsulare e distribuire le applicazioni.\n\nModo più semplice per utilizzare la tecnologia dei container precedentemente ingombrante e difficoltosa da utilizzare. Sviluppatori di applicazioni, in\n\nparticolare, ha abbracciato questa tecnologia perché è coerente su più ambienti. Il livello di gestione del servizio.\n\ncon l'containerizzazione delle applicazioni e dei microservizi, si è più incentrati sulle applicazioni e si mappano quelle applicazioni a\n\nhardware virtualizzato generico che è stato astratto. Ora abbiamo un rilascio automatico su più ambienti cloud.\n\nwe’ve implemented effective disaster recovery measures to ensure business continuity. Our team constantly monitors and tracks performance metrics to improve efficiency and enhance customer satisfaction.\n\nÈ molto più facile integrarsi con reti sovrapposte, integrarsi su più cloud, creare firewall, fare...\n\nmicro-segmentazione, ecc... tutto tramite software.\n\nSicurezza, tuttavia, è una preoccupazione principale. Poiché i contenitori sono facili da implementare su più ambienti, è\n\nè importante concentrarsi sulla sicurezza che è \"integrata\" nella distribuzione. Inoltre, c'è un aumento della complessità. Qui,\n\nCi siamo allontanati da un'architettura a tre livelli verso un'architettura a più livelli o addirittura a microservizi con dozzine di.\n\nLavoro dei servizi in collaborazione. Un altro problema riguarda dove e come i dati vengono archiviati e gestiti. Sulla gestione del servizio.\n\nTraduci in italiano: layer, lo storage è un contenitore generico, che non gestisce i dati stessi.\n\n## Architetture dell'Internet delle cose\n\nOra, quando l'Internet delle cose (IoT) viene aggiunto a questo ecosistema, il volume di dati aumentato si distribuisce su centinaia o\n\ndevices can connect directly to the internet, making them vulnerable to hacking and cyber attacks.\n\nI dispositivi sono accessibili al pubblico. Ad esempio, qualcuno potrebbe manipolare una luce smart della città, un segnale di traffico smart.\n\npotenza delle nuove tecnologie, sono diventati strumenti essenziali per la sicurezza e il monitoraggio. Un drone, o telecamera di sicurezza, possono fornire un'ampia copertura di sorveglianza e rilevamento delle minacce. La complessità dei diversi dispositivi, il loro numero e le loro ubicazioni, insieme all'immensa potenza delle nuove tecnologie, sono elementi chiave per garantire la sicurezza in diverse situazioni.\n\nLa quantità di dati è enorme.\n\n## Architetture di gestione dei dati e delle informazioni\n\nCome possiamo lavorare attraverso questi problemi? Le organizzazioni stanno già cambiando per affrontare questa complessità con nuove organizzazioni.\n\ne posizioni ingannando sulla gestione dei casi d'uso dei dati. In precedenza, non c'era un luogo dove gestire questi casi d'uso.\n\nAbbiamo creato un nuovo livello chiave chiamato livello di gestione delle informazioni distribuite. Questo livello gestisce i dati su tutti i\n\nIl IoT, Legacy e le nuvole pubbliche e private. Esso combina i dati con gli stack di applicazioni e gli stack di servizi, quindi...\n\nPossono allocare dinamicamente servizi e applicazioni vicino ai dati, o viceversa. Regolamentazioni e pura quantità di dati.\n\npossono limitare la capacità di spostare i dati verso posizioni centrali, come abbiamo fatto tradizionalmente. Con questa nuova architettura,\n\nSono disponibili diversi modi di operare, tra cui l'analisi disaggregata, lo spostamento dei dati e lo spostamento delle applicazioni.\n\nAncora una volta, con questa architettura ampliata, la sicurezza è di importanza primaria. La sicurezza deve essere gestita come un aspetto comune.\n\nAttraverso tutti gli strati. Sicurezza dell'identità, che significa accesso, autorizzazione e autenticazione delle persone, Internet delle cose (IoT).\n\ndispositivi, applicazioni, servizi e persino dati sono fondamentali. La gestione dell'identità include la crittografia per dati affidabili.\n\ne dispositivi.\n\n## Conclusione\n\ntranslate and incorporate them into a unified project.\n\nottimizzano come lavorano insieme. La più recente area è il livello di gestione delle informazioni distribuite (DIML). Fortunatamente, noi\n\nStiamo iniziando a vedere start-up e aziende più consolidate sviluppare casi d'uso e elementi architettonici.\n\nin questo strato.\n\nL'architettura di Edgemere aiuta a identificare le parti fondamentali in movimento di un moderno sistema digitalmente trasformato e come sono tutte collegate.\n\nsi adattano insieme.\n\nIntel si inserisce in questo ecosistema fornendo l'elemento chiave di un livello fisico comune per controllare e gestire tutto il tuo.\n\nrisorse, che si tratti di un dispositivo IoT, nel centro dati o in una posizione remota. Facciamo in modo che tu possa\n\nSposta i dati in modo efficiente, memorizzali in modo efficace e elabora tutto. Che si tratti dei processori Xeon ad alta\n\nFine, che si tratti di inferenza o intelligenza artificiale in loco a bassissimo consumo energetico, Intel dispone di un'intera gamma di hardware fisico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT1-it","image":"./episodes/edt-1/it/thumbnail.bmp","lang":"it","summary":"In questo episodio, Darren parla della storia delle applicazioni e di come i recenti cambiamenti, principalmente dovuti all'afflusso di dati provenienti dall'Internet delle cose, stiano influenzando le architetture incentrate sui dati. L'infrastruttura è pronta, ma non abbiamo ancora un modo adatto per gestire tutti i nostri dati. Ci sono tre elementi che devono cambiare per facilitare questo processo: le persone (organizzazione), il processo (operazione) e l'architettura (tecnologia). Darren si concentra sull'architettura in cui i dati e il calcolo sono distribuiti su migliaia di dispositivi periferici e su cloud pubblici e privati."},{"id":1,"type":"Episode","title":"Scegliere la dimensione della soluzione VDI per i telelavoratori.","tags":["telework","remoteworker","process","technology","vdi"],"body":"\r\n\r\n# Titolo\n\n*Slogan*\n\nSommario qui\n\nTraduci quanto segue in italiano: Immagine dell'episodio\n\nEpisodio Corpo qui.\n\n## I mezzi di comunicazione\n\n<video src='url'></video> can be translated to Italian as <video src='url'></video>.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Illyse Sheaffer"],"link":"/episode-EDT10-it","image":"./episodes/edt-10/it/thumbnail.png","lang":"it","summary":"Le organizzazioni hanno bisogno di aiuto nella costruzione di soluzioni VDI (Virtual Desktop Infrastructure) immediatamente. Poiché i dipartimenti IT stanno aggiungendo licenze VDI localmente ai loro sistemi attuali, devono essere consapevoli che le licenze da sole non risolvono tutti i loro problemi."},{"id":2,"type":"Episode","title":"Supereroi del settore pubblico di Intel","tags":["cybersecurity","multicloud","edge","aiml"],"body":"\r\n\r\nio\n\nCameron ha iniziato la sua carriera lavorando per la più grande azienda privata di reclutamento di personale. Lì ha sviluppato una passione per la tecnologia dopo aver imparato PeopleSoft. Ciò lo ha portato all'opportunità di contribuire alla creazione della prima azienda di cloud computing al mondo, UC Center Networking. Lui e i suoi colleghi hanno creato lo slogan \"software come servizio\" nel 1997, sette o otto anni prima che il termine \"cloud\" fosse coniato. Ha lavorato per integratori di sistemi federali come Northrop Grumman e General Dynamics, dove ha scoperto che era appassionato di supporto a una missione. Questa passione lo ha guidato sin da quando era CTO presso Dell Technologies e ora guida il team del settore pubblico presso Intel.\n\nUno dei fattori che ha portato Cameron a unirsi a Intel è stato il ritorno di Pat Gelsinger e del team di leadership che sta costruendo, inclusa l'aggiunta di Greg Lavender. Cameron crede che Intel sarà rinverdita e continuerà a innovare sotto la guida di Gelsinger. Desidera far parte del lavoro per riportare Intel al suo status di iconico marchio americano. Crede che ci sia una cultura dell'umiltà e di persone che fanno ciò che è giusto.\n\n## Calcolo Ubiquo\n\nI semiconduttori sono presenti in tutto: automobili, elettrodomestici, smartphone, computer, sistemi sanitari, ecc... Coprono praticamente tutti i settori verticali del pianeta. Migliorano la qualità della vita delle persone, persino salvando vite attraverso la sanità, la sicurezza nazionale e la ricerca scientifica.\n\nLa pandemia di COVID ha portato alla luce questa natura ubiqua a causa del grande numero di persone che potevano lavorare da casa e dell'istruzione che continuava online. Ha anche contribuito a colmare il divario digitale in molte maniere.\n\n## Connessione pervasiva\n\nIl silicio non può realizzare il suo potenziale senza essere connesso. Intel non è solo un'azienda di chip, ma ha un intero portafoglio interconnesso.\n\nCi sono momenti in cui le cose sono disconnesse, ad esempio, un combattente in un ambiente DDIL, ma possono comunque utilizzare il calcolo localmente per eseguire la missione. Quando si riconnettono, che sia attraverso il 4G di vecchia generazione, il 5G o il futuro 6G, possono ottenere informazioni aggiornate, in altre parole, la trasmissione di dati. In uno scenario educativo, tuttavia, l'interconnessione è fondamentale per cose come lo streaming, i contenuti video e l'accesso ai dati. Questo è un potente vantaggio.\n\nLa pandemia ha portato anche a un significativo aumento delle comunicazioni e del 5G poiché gli studenti e i lavoratori avevano bisogno di questa connettività. Questa situazione continua ancora oggi, anche se gli studenti e i lavoratori sono tornati in sede. Mentre gli studenti potevano avere accesso periodico ai Chromebook prima della pandemia, molti ora ne hanno uno proprio che possono portare a casa. Purtroppo, ci sono ancora aree nel paese e nel mondo in cui ci sono lacune e le persone non possono partecipare all'economia digitale. Sorprendentemente, chiudere la frattura digitale negli Stati Uniti non è facile come nei paesi in via di sviluppo. Essi possono superare gli Stati Uniti perché investono nel 5G e nel 6G: le comunicazioni non-terrestri.\n\nCameron crede che la connettività sia altrettanto importante del calcolo, poiché essere connesso con gli altri è uno dei fondamenti dell'esperienza umana.\n\n## Bordo al Cloud\n\nLa base dell'edge-to-cloud è costituita dalla computazione e dall'interconnessione, quindi Intel svolge un ruolo significativo in questo settore insieme ai suoi partner. L'edge-to-cloud sfrutta il vero potere non solo del silicio, ma anche del software. Crea interoperabilità. È possibile spostare carichi di lavoro in modo sicuro e senza soluzione di continuità da un dispositivo edge a un cloud o a un centro dati tradizionale utilizzando standard aperti, tecnologie di base e una strategia edge-to-cloud.\n\nPer il futuro prevedibile, il concetto di \"edge\" dominerà, perché man mano che le cose diventano più luminose, la tecnologia deve essere spinta verso il margine dove le informazioni vengono create. In seguito, l'elaborazione può avvenire in modo centralizzato per ulteriori analisi e intelligenza artificiale. Le cose procederanno solo verso il futuro e il \"edge\" diventerà pervasivo.\n\n## Intelligenza Artificiale\n\nI dati sono ovunque adesso; i centri di dati non hanno pareti. Sono raccolti e addirittura elaborati in molti modi come telefoni cellulari, telecamere, motori industriali, ecc... L'intelligenza artificiale riguarda la presa di decisioni intelligenti basate su tutti questi dati diversificati.\n\nIntel ha uno dei più ampi portafogli di intelligenza artificiale al mondo, un portafoglio software straordinario e più sviluppatori di software rispetto a molte aziende di software. La ragione è, come sottolinea Greg Lavender, che il software è l'anima del silicio. Bisogna permettergli di fare qualcosa e dargli vita e scopo. L'intelligenza artificiale è un eccellente esempio di ciò.\n\nA volte le persone pensano all'AI in termini di robot, ma ci sono innumerevoli casi d'uso pratici. Un esempio è quando ci si perde: è possibile interrogare immediatamente Siri o Google e, utilizzando il GPS, il servizio ti localizzerà geograficamente e troverà il punto di civiltà più vicino o ovunque tu voglia andare.\n\nUn altro caso d'uso pratico si trova presso il servizio postale degli Stati Uniti. La prossima generazione di veicoli per la consegna è moderna come le auto di Google Street View, dotate di sensori che mappano determinate cose. Il servizio postale applica l'intelligenza artificiale alle macchine di smistamento intelligente e gestione della posta. Stanno sfruttando la tecnologia per espandersi.\n\nA causa della diffusione della computazione ubiqua e delle comunicazioni avanzate di Intel, sempre più dispositivi periferici stanno diventando intelligenti e la quantità di dati che deve essere spostata dal bordo verso i data center sta diminuendo. Ciò accade perché gli algoritmi di intelligenza artificiale inferiscono ciò che stai cercando sul bordo. Questo tipo di tecnologia è integrato direttamente nei processori Intel. Hanno anche XPUs specializzati, processori neurotropici, che fanno la stessa cosa a wattaggi più bassi e velocità più elevate.\n\nParte del potere di ciò che accade con Intel e i loro partner è la capacità di avere accesso a tutte le informazioni in un formato fruibile. Nell'esempio di perdersi e guardare al telefono per aiuto, potresti guardare qualcosa che ha assimilato 600 punti dati diversi in una frazione di secondo per darti una risposta semplice.\n\n## I Supereroi\n\nLe persone di Intel e i suoi partner nell'ecosistema sono supereroi. I partner aiutano a mettere insieme soluzioni reali, specialmente in quella fase cruciale di ultima miglia. Intel ha uno dei migliori ecosistemi per portare soluzioni sul mercato. E a volte, queste soluzioni non vengono neanche portate sul mercato, ma vengono utilizzate per risolvere problemi impegnativi nella difesa e nel settore pubblico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Cameron Chehreh"],"link":"/episode-EDT100-it","image":"./episodes/edt-100/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren e Cameron Chehreh, Vice Presidente e Direttore Generale del Settore Pubblico di Intel, parlano dei superpoteri di Intel: calcolo ubiquo, connettività pervasiva, dal bordo al cloud e intelligenza artificiale."},{"id":3,"type":"Episode","title":"Sicurezza del controller di rete con Elisity","tags":["networksecurity","cybersecurity","elisity","comms","technology","process"],"body":"\r\n\r\nDana ha lavorato nell'ambito delle reti hardcore negli ultimi 15 anni. Ha lavorato con le reti definite dal software e le reti wide area, concentrandosi per un periodo sul mondo SD-WAN. Successivamente ha lavorato con il cloud ma è tornato alle sue radici con la sicurezza di rete presso Elisity.\n\nDan ha lavorato principalmente nel networking, ma ha iniziato con servizi avanzati presso Cisco e ha svolto qualche lavoro nel settore petrolifero e del gas a Houston. Successivamente è passato allo spazio SASE SD-WAN, dove ha lavorato con Dana. Ora si concentra sulla sicurezza delle reti e sulla sicurezza definita dal software. Dan afferma che il termine, tuttavia, è sfuggente perché la tecnologia riguarda la micro-segmentazione attraverso l'identità.\n\nIl modo tradizionale per creare una micro-segmentazione attraverso VLAN e firewall non è più sufficiente. Per 15 anni, la sicurezza di rete si è concentrata sul rafforzamento del perimetro della rete. Creare un muro impenetrabile intorno a un'azienda rimane essenziale e i firewall svolgono un lavoro incredibile nel tenere le persone fuori dalla rete. Ma per la maggior parte, all'interno della rete, dove c'è stata un'esplosione di nuovi requisiti di connettività a causa di IoT e OT, è un \"Far West\" una volta che un utente è all'interno. Poiché il muro esterno è robusto, chiunque sia all'interno viene spesso considerato un utente legittimo o affidabile.\n\nLa realtà è che la maggior parte degli attacchi attuali avviene all'interno della rete attraverso utenti, dispositivi e applicazioni fidati sfruttati.\n\nCi sono molti motivi per cui sfruttare VLANS, ACL IP, firewall e metodi di segmentazione tradizionali non funzionano più oggi per la sicurezza del movimento laterale. Possono funzionare in ambienti statici su piccola scala. Funzionano molto bene per il bordo della rete e luoghi specifici come punti di congestione o aggregazione, ma ci sono tre ragioni comuni per cui non sono più ideali.\n\nIn primo luogo, la scalabilità e l'efficienza operativa dei metodi tradizionali sono discutibili. La gestione delle VLAN, delle ACL IP e dei firewall nelle grandi aziende avviene manualmente. Non si tratta di un'architettura distribuita definita dal software, ma richiede una configurazione box per box, linea per linea. Non sono dinamici né reattivi a qualunque cosa nella rete. Il loro utilizzo crea inoltre una rete con molti buchi casuali come un formaggio svizzero. Gli utenti, specialmente gli operatori di reti, sono spesso il maggior rischio di un sistema. Potrebbero ad esempio aprire una VLAN o modificare una parte per effettuare un test rapido, ma poi non annullano la modifica.\n\nUn altro esempio è che una VLAN partirà da un caso d'uso e si estenderà gradualmente ad altri casi d'uso. Improvvisamente, quello che era una VLAN con dieci dispositivi ne avrà ora sessanta. Nel mondo OT, potrebbe avere sei o sette processi diversi in esecuzione al suo interno perché si trattava della LAN affidabile. Tuttavia, spesso questi ambienti crescono lentamente e non sono documentati, quindi il rischio passa inosservato.\n\nIl secondo problema è che le VLAN e i firewall sono intrinsecamente nel posto sbagliato nella rete per fornire sicurezza del movimento laterale. Se ti trovi nella stessa VLAN di un altro dispositivo, utente o applicazione, quel canale di comunicazione è aperto anche se potrebbe non essere necessario. I firewall di solito non vengono distribuiti in un luogo strategico in cui possono gestire il livello di accesso del movimento laterale. Devi convogliare il traffico verso un firewall e farlo tornare indietro, il che è inefficiente. Poi hai un collo di bottiglia.\n\nGli attori sbagliati stanno esaminando le reti per capire come possono distorcerle per ottenere un certo risultato, non come dovrebbero o erano intese a funzionare. Ad esempio, se un utente è in una VLAN e un processo è in esecuzione all'interno di un caso d'uso, non c'è nulla che li impedisca di passare dalla porta 3 alla porta 32 nella stessa VLAN. Spesso le persone progettano la sicurezza attorno all'uso previsto anziché a come potrebbe essere utilizzata. È comune, ad esempio, che gli sviluppatori di software facciano salti di porta per lavorare efficacemente, ma questo è pericoloso perché li lascia aperti. Nessuno può posizionare centinaia o migliaia di firewall lungo l'intero bordo di accesso. Sarebbe restrittivo dal punto di vista economico e impossibile da gestire.\n\nIl terzo problema è che queste soluzioni di segmentazione legacy non considerano l'identità, il contesto o il comportamento dell'asset connesso alla rete. Si tratta di una topologia rigida e incentrata sulla rete che fornisce alcune misure di sicurezza essenziali. Tuttavia, un indirizzo IP non dice nulla sulla legittimità dell'asset né sulla rete a cui è collegato. Quindi, come puoi proteggere dinamicamente questa rete quando non sai cosa si sta connettendo ad essa? Non puoi creare una politica iniziale senza alcuna granularità; non funziona trattare ogni dispositivo come uguale.\n\nAnche se esiste un'analisi del tipo di traffico, di solito avviene diversi salti più in alto, il che significa che ora sei esposto. Eventuali misure di sicurezza potrebbero o potrebbero non essere in grado di proteggere completamente l'infrastruttura.\n\nQuesta capacità di rilevamento ha ancora valore, anche se non vi è alcuna protezione. Tuttavia, la capacità di fermare qualcosa che avrebbe potuto accadere proprio al limite, il più vicino possibile all'attività, rappresenta una soluzione migliore.\n\nGuarda il prossimo episodio di questa serie [qui](episode-EDT101).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dan Demers","Dana Yanch"],"link":"/episode-EDT101-it","image":"./episodes/edt-101/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher di Intel, Chief Solutions Architect, settore pubblico, intervista gli esperti di sicurezza di rete Dana Yanch e Dan Demers di Elisity sulle tecniche di sicurezza del controller di rete e sulle architetture di fiducia zero."},{"id":4,"type":"Episode","title":"Micro-segmentazione basata sull'identità con Elisity","tags":["microsegmentation","otsecurity","identitybasednetworking","cybersecurity","comms","technology","edge","sdn"],"body":"\r\n\r\nNella seconda parte di Security with Elisity, Darren discute delle soluzioni di micro-segmentazione basate sull'identità con Dana Yanch, Direttore del Marketing Tecnico, e Dan Demers, Architetto Tecnico.\n\nL'approccio di Elisity alla sicurezza di rete si differenzia dalle architetture tradizionali per il modo in cui viene fornito, distribuito su tutta la rete e svolto in modo efficiente, offrendo un valore di tempo rapido. Si sono concentrati nel renderlo il più semplice, intuitivo ed efficace possibile, in modo che qualsiasi settore industriale possa sfruttare la tecnologia.\n\nLa chiave della tecnologia di Elisity è la micro-segmentazione, che significa la capacità di isolare completamente qualsiasi utente, dispositivo o applicazione, indipendentemente dal tipo di rete su cui si trova, dalla sua posizione nella rete o se è gestito o non gestito. In altre parole, è flessibile nell'isolare un elemento da un altro senza restrizioni imposte dall'architettura di rete o da costrutti come VLAN o VRF.\n\nI sistemi tradizionali di micro-segmentazione che richiedono la sostituzione dell'hardware o l'istantanea di un'apparecchiatura in loco possono richiedere mesi o anni per essere impostati e attivi. Tuttavia, Elisity fornisce la funzionalità completa entro una settimana passando a una piattaforma di micro-segmentazione nativa del cloud e consegnata tramite cloud. L'intero controllo della gestione e delle politiche viene erogato interamente tramite cloud, e il componente che si connette alla vostra rete in loco è al 100 percento software. Non è necessario modificare nulla in loco, in quanto si basa sulla vostra infrastruttura esistente. È facilmente scalabile, gestibile e distribuito in modo dinamico.\n\nElisity offre anche una soluzione on-premise per lo spazio OT, dove le organizzazioni possono mantenerlo dietro la propria DMZ e interrompere tutti gli accessi.\n\nLa piattaforma di Elisity è un microservizio nel senso di scalabilità orizzontale. Puoi iniziare in modo piccolo e aggiungere 10.000 elementi alla rete e scalare con te, sia che tu sia in locale o nel cloud. È completamente automatizzata su tutta la rete. C'è poca frizione ed è facile da gestire nel lungo termine.\n\nUna differenza significativa tra la piattaforma di Elisity e altre reti overlay è che Elisity si occupa del piano di controllo e delle politiche anziché del piano dati. Può applicare lo stesso livello di granularità della sicurezza di rete senza toccare alcun pacchetto. Indica dinamicamente alla rete chi può comunicare con chi in base agli attributi e alle identità trovate nella rete.\n\nUn triangolo di utenti, applicazioni e dispositivi è un ottimo modo per visualizzare questo concetto. All'interno di quel triangolo ci sono tutte le linee di comunicazione tra le varie entità. Elisity può proteggere ogni singola linea, o canale, tra utenti, applicazioni e dispositivi in modo granulare. Questo avviene a livello di controllo di rete. Nel momento in cui il traffico raggiunge il primo punto di accesso, viene protetto.\n\nLa sicurezza è indispensabile a livello di rete e non a livello di applicazione perché potrebbero esserci decine di migliaia di dispositivi nella tua rete su cui non è possibile installare un agente o modificarli, poiché dispongono di sistemi operativi incorporati, telecamere, lettori di badge e persone. Questo è particolarmente importante nel settore OT.\n\nCon OT, l'attenzione è rivolta all'affidabilità e all'integrità. Le cose devono continuare a funzionare in modo sicuro perché il processo potrebbe rappresentare un'infrastruttura critica. Questo è diverso dall'IT, dove è possibile mettere in quarantena e avviare una nuova istanza se c'è un'intrusione. OT è una mentalità diversa. Dove qualcosa potrebbe esistere nell'IT per sei mesi o un anno, qualcosa in OT potrebbe esistere per 20 anni. Spesso, queste infrastrutture vengono mantenute o aggiornate ogni pochi anni o vengono lasciate inattive fino a un evento di errore. La sicurezza equivale a limitare la connettività. Ad esempio, se sei in una VLAN, ciò non significa che tu debba parlare con un RTU, un sensore, un HMI o un DCS che si trovano a un solo switch di distanza. Nel design legacy, se queste cose sono nella stessa VLAN, non c'è un modo efficiente e flessibile per impedire loro di connettersi.\n\nCon il sistema di Elisity, si impostano le politiche in base alle cose che si raggruppano o agli attributi assegnati agli asset, anziché esaminare ogni singolo elemento. Ciò può essere semplice come raggruppare tutti i processi in modo che possano comunicare solo nord/sud, non est/ovest, oppure, ad esempio, consentire ai responsabili di linea di condividere con sei o sette tipi di cose. Due o tre politiche possono rapidamente ridurre la tua superficie di attacco da 65.000 porte potenziali a due o tre.\n\nUn caso d'uso comune nelle reti OT è quando un fornitore effettua un aggiornamento su un dispositivo, è necessario consentirgli l'accesso e hanno accesso all'intera rete. Con Elisity, puoi facilmente concedere loro l'accesso per un tempo limitato e consentire loro di toccare gli asset fissi.\n\nSupponiamo che tu desideri conoscere di più sulla tecnologia di Elisity. In tal caso, molte risorse, tra cui video, white paper e documenti, spiegano come funziona la soluzione e come può essere applicata entro una settimana nella tua rete su Elisity.com.\n\nControlla l'episodio precedente di questa serie [qui](episode-EDT101).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dana Yanch","Dan Demers"],"link":"/episode-EDT102-it","image":"./episodes/edt-102/it/thumbnail.png","lang":"it","summary":"Nella parte 2 della sicurezza con Elisity, Darren discute le soluzioni di micro-segmentazione basate sull'identità con Dana Yanch, Direttore del Marketing Tecnico, e Dan Demers, Architetto Tecnico."},{"id":5,"type":"Episode","title":"Operazionalizzare i tuoi progetti di intelligenza artificiale","tags":["aiops","devops","compute","technology","process","devsecops","cybersecurity","aiml"],"body":"\r\n\r\nGretchen è un eccellente esempio di una persona che continua a imparare e adattarsi. Ha conseguito una laurea triennale in matematica. Ha una laurea magistrale in economia e ha completato un programma presso Harvard solo pochi anni fa, focalizzato sulla scienza dei dati, che l'ha portata al suo ruolo di Capo scienziato dei dati presso Intel nel settore pubblico. Ha lavorato nel campo della tecnologia per oltre 20 anni, iniziando con l'ingegneria del software e ha trascorso 15 anni nel settore federale.\n\nTrova particolarmente gratificante lavorare nel settore pubblico perché fa la differenza nella vita quotidiana dei cittadini. Inoltre, il governo federale dispone dei dati più completi al mondo, quindi è perfetto per chi ama essere sommerso di informazioni e continuare a imparare sempre di più.\n\nCi sono molti termini legati all'AI. Prima di tutto, è essenziale comprendere la differenza tra intelligenza artificiale (AI) e operazioni di machine learning (ML ops). Le ML ops sono tecniche che fanno parte dell'AI; sono un sottoinsieme. Gli algoritmi di ML traggono la loro forza dalla capacità di apprendere dai dati disponibili. Quindi, principalmente, si impara dai dati supervisionati o non supervisionati.\n\nLa semplice differenza tra apprendimento supervisionato e non supervisionato è l'etichetta dei dati. Nell'apprendimento supervisionato, i dataset sono etichettati. Ciò significa che l'aspetto dei dati è già mappato. Ciò facilita molto la classificazione e la previsione. Nell'apprendimento non supervisionato, si cercano modelli nei dati; la macchina impara a creare relazioni tra i dati trovando modi comuni, somiglianze o differenze.\n\nUn esempio di apprendimento supervisionato sarebbe un negozio online che consiglia un oggetto che un cliente potrebbe voler acquistare in base alla sua storia degli acquisti, o un servizio di streaming che consiglia un film in base alle abitudini di visione di qualcuno.\n\nMolti termini hanno ora la sigla \"ops\" alla fine. Ad esempio, le persone dicono \"DL ops\" per indicare le operazioni di apprendimento profondo, una sotto-categoria dell'apprendimento automatico. Perché \"ops\"? Prima di tutto, non è così sofisticato come DevOps. Piuttosto, è influenzato dall'idea ampiamente adottata dell'approccio DevOps alla creazione e personalizzazione delle applicazioni. Le persone stanno cercando di sviluppare un insieme di pratiche per ottimizzare l'affidabilità e l'efficienza della progettazione, dello sviluppo e dell'esecuzione dell'apprendimento automatico. Quindi sarebbe quasi come un mercato in cui è possibile creare e gestire applicazioni personalizzate e poi condividerle con gli altri.\n\nMolti modelli e algoritmi sono già ottimizzati e disponibili in strumenti come Converge.io o C3 AI. Queste metodologie e tecnologie possono aiutarti a rendere più efficienti i tuoi modelli di apprendimento automatico. Il modo migliore per farlo è utilizzare molti strumenti che possono essere sia open source che software specifici creati dai fornitori per rendere la creazione, lo sviluppo, il design, l'esecuzione e il flusso molto più accessibili.\n\nLo sviluppo dell'IA è simile a come era lo sviluppo del software 30 anni fa. Molti dei passaggi sono ancora manuali e speriamo che verranno presto automatizzati.\n\nNei precedenti episodi, Darren e Gretchen hanno discusso di quanti progetti di intelligenza artificiale e machine learning siano esperimenti scientifici svolti una volta sola. Successivamente, lo scienziato dei dati passa a qualcos'altro e non viene mai messo in produzione. Al contrario, l'operationalization del machine learning si muove verso il deployment del modello per fornire un vero valore dopo l'addestramento e l'apprendimento.\n\nAlcune aziende stanno espressamente sfruttando questi strumenti. Ad esempio, Domino Labs crea quasi quel mercato. Lavorare nel settore pubblico, ad esempio, su sottomarini nucleari per rilevare oggetti o classificarli in cluster, potrebbe essere applicabile nell'Aeronautica o in altri settori ausiliari, così da poter catalogare il lavoro per aiutare a operazionalizzare e costruire ambienti agili. Potresti sfruttare alcuni algoritmi e ponderarli in modo diverso in base ai risultati. Potresti modificarlo in base alle differenze nei dataset, ma almeno ci sono... dei punti di partenza? Delle comunanze? Delle risorse condivise? Le sue ultime parole qui si interrompono...\n\nLa sicurezza è sempre interessata al software e ai modelli open-source, e l'intelligenza artificiale ha circostanze uniche. Ad esempio, come si fa a sapere che lo sviluppatore non l'ha addestrata a ignorare il proprio volto in un modello di riconoscimento facciale? Ora c'è l'aspettativa che le persone documentino le cose, ad esempio, da dove proviene un insieme di dati.\n\nC'è anche la questione dell'etica e della responsabilità. Il chatbot Tay e il pregiudizio riscontrato nei programmi di riconoscimento facciale sono stati ottimi esempi di IA che ha preso una direzione sbagliata senza intenti maliziosi. Per molto tempo nell'operatività del ML, era una sola persona a svolgere il lavoro e produrre i risultati. Ora, l'idea è che sia necessaria una squadra diversificata di persone con capacità diverse e punti di vista diversi.\n\nLa prima conferenza per discutere di AI e ML si è tenuta nel 1956 presso il Dartmouth College. La verità è che molti dei concetti di base dell'AI, come la regressione logistica, la regressione lineare, gli algoritmi di clustering, ecc., sono equazioni matematiche che esistono da molto tempo. Naturalmente, sono stati sviluppati framework aggiuntivi brillanti come Tensorflow da utilizzare come base, ma i concetti di base rimangono ancora i fondamenti. Abbiamo aggiunto calcolo, archiviazione, 5G e capacità uniche. Una volta completato tutto il training, i dati e le informazioni si trovano accanto alla tecnologia anziché doverli trasportare fino alla tecnologia. Portare la tecnologia ai dati offre la possibilità di affrontare problemi divertenti ed emozionanti che possiamo ora risolvere.\n\nMa le conversazioni riguardanti come il modello è stato addestrato, quali erano i dati originali e la considerazione del cambiamento del modello devono sempre accadere. Dopo un certo tempo, è necessario riaddestrarlo; forse è necessario utilizzare un diverso algoritmo o pesare in modo diverso quello attuale per ottenere informazioni più accurate a causa di una quantità maggiore di dati e di dati più diversificati. Tutto ciò è positivo perché aumenta il livello di precisione.\n\nQuindi, con il movimento verso l'operatività di ML, puoi farlo in modo continuo. Proprio come lo sviluppo del software si è orientato verso l'integrazione e il dispiegamento continui, la stessa cosa inizierà a accadere nell'AI o nell'ML, dove i modelli verranno aggiornati e diventeranno sempre più accurati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart"],"link":"/episode-EDT103-it","image":"./episodes/edt-103/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel nel settore pubblico, e Gretchen Stewart, Chief Data Scientist nel settore pubblico, discutono sulla messa in opera dei progetti di intelligenza artificiale."},{"id":6,"type":"Episode","title":"Leadership basata sull'informazione","tags":["data","informationdriven","organizationalchange","radiusag","change","people","process","ceo"],"body":"\r\n\r\nNonostante Betsy sia l'amministratore delegato di Radius Advisory Group e tecnicamente in pensione nel settore federale, mantiene comunque un piede nel settore pubblico attraverso la sua azienda che si concentra sulla cybersecurity e le questioni di cyberspazio di importanza nazionale. Lavorare contemporaneamente nei settori privato e pubblico è stata la parte più entusiasmante del suo percorso professionale.\n\nBetsy ha iniziato come membro in servizio attivo nell'Aeronautica, passando poi all'industria mentre gestiva i figli e il coniuge che era anche in servizio attivo. Ha lavorato in diverse industrie, più di recente nelle utilities e nell'energia, e ha trascorso molto tempo presso PricewaterhouseCoopers. È tornata al Dipartimento della Difesa quando è stata selezionata per lavorare con il Segretario Gates come membro del Defense Efficiencies Task Force. È rimasta sotto il Segretario Pancetta e ha avuto un percorso entusiasmante, venendo infine nominata Vice CIO per la Revisione dei Processi Aziendali e dei Sistemi. Lì ha creato una funzione di analisi dei dati per fornire maggiore trasparenza sui costi delle tecnologie dell'informazione e sulle potenziali efficienze all'interno del Dipartimento della Difesa.\n\nLa sfida più grande di Betsy nel ruolo di Vice Direttore delle Informazioni, che lei ritiene vera sia nel settore pubblico che in quello privato, è come introdurre nuove forme di pensiero, processi, tecnologie e metodi di lavoro nell'organizzazione. Nelle grandi organizzazioni, il campo è enorme e vi sono molte divisioni, ognuna con la propria cultura, obiettivi, budget e conti economici. Situazioni come la pandemia da COVID, in cui i cambiamenti devono avvenire rapidamente, sono estremamente impegnative.\n\nBetsy dice che COVID ha cambiato la cultura in alcuni modi, ma in altri modi ha spinto le persone a rinchiudersi ancora di più, il che non è buono. Ci sono state molte sfide legate ai processi e alla tecnologia da cui tutti hanno imparato e continuano a farlo. Una preoccupazione che Betsy ha è che ora c'è un nuovo ambiente ed ecosistema e il ritorno in ufficio non può essere ristretto alla vecchia situazione come molti leader stanno cercando di fare. Anche se è molto difficile navigare in questa situazione e che i leader considerino il nuovo ambiente positivo o negativo, non può essere trattato allo stesso modo di prima.\n\nUna volta che i leader fanno una svolta, tuttavia, la strategia di Betsy è quella di fare tutto in fretta. Ha imparato questa lezione quando era vice CIO e le venivano assegnati vari progetti oltre alla missione sottostante. Ha notato che ad altri team venivano dati ripetutamente 30 giorni per completare i progetti, mentre al suo team venivano dati solo 10 giorni. Quando ha chiesto spiegazioni, i leader hanno detto di sapere che il suo team poteva farcela in 10 giorni e che dovevano prendere decisioni complesse che richiedevano le informazioni che solo il suo team poteva fornire come parte del processo decisionale, quindi più velocemente le ottenessero, meglio sarebbe stato. Quindi ha detto al suo team che dovevano solo risolvere la situazione. Ce l'hanno fatta e sono diventati bravi a farlo.\n\nUn senso di urgenza aiuta le persone a concentrarsi e ad agire, ma i leader, come sottolinea Betsy, devono assicurarsi di essere dotati delle persone, delle risorse e dell'autorità necessarie per eseguire qualcosa in breve tempo. Questo sostegno leadership è fondamentale per il successo.\n\nBetsy crede che ascoltare le persone sia essenziale, ma le decisioni vengono prese dall'alto, il che dovrebbe generalmente significare poche persone. Un'organizzazione a matrice, che ha guadagnato popolarità negli anni '90 e 2000, ha aggiunto strati di complessità, ma la maggior parte delle situazioni è già complessa, quindi alla fine il tutto dipende dal leadership. I leader devono essere sufficientemente inclusivi per ascoltare il maggior numero possibile di persone, ma non possono richiedere cinque mesi e 150 incontri. Devono sviluppare sistemi e gruppi in grado di generare idee, suggerire modelli e lavorare insieme. I leader devono avere la capacità di agire rapidamente; a volte devono agire velocemente. Spesso, la soluzione è avere meno persone ma le persone giuste, meno tecnologia e la tecnologia giusta per ottenere ciò di cui hai bisogno.\n\nBetsy utilizzò un modello pratico quando ricevette progetti urgenti dal Vice Segretario della Difesa per creare piccoli gruppi di cinque a sette persone con competenze cognitive diverse tra i suoi 50 analisti. Ciò ebbe successo perché conosceva bene le personalità e le abilità dei suoi analisti e poteva selezionare i team invece di portare un problema a un grande gruppo e cercare di ottenere il contributo di tutti. I piccoli team ripetutamente la sorprendevano nel compiere compiti complessi e risolvere problemi.\n\nCreando processi e modelli per risolvere i problemi, il team di Betsy spesso forniva consulenza al Sottosegretario della Difesa o al CIO entro poche ore, se necessario. Alla fine, avevano dei processi in atto che consentivano loro di generare opzioni neutrali basate sui dati, considerando molteplici aspetti. Ciò consentiva ai leader di valutare i fatti e le prove e prendere decisioni.\n\nBetsy aveva fiducia nelle sue squadre e non lesse mai come fare il lavoro o supponeva di conoscere il modo migliore per affrontare le cose. Aveva persone valide e si fidava semplicemente che lo facessero. Questo motivava le sue persone e faceva sì che fossero costantemente ansiose di nuovi incarichi. Gli impiegati vogliono sapere che i leader li ascoltino, considerino e utilizzino le loro idee. Questo approccio permetteva alle persone di esporre la loro migliore analisi e opzioni a Betsy. Spesso, era una combinazione di queste analisi a tornare agli alti vertici. Il merito va ai leader del DOD e all'ufficio del CIO, che hanno fiducia nel processo di Betsy.\n\nOgni volta che c'era un nuovo problema, Betsy assegnava un nuovo team. In questo modo, persone diverse potevano lavorare su diversi tipi di progetti e non venire catalogate in un'unica area, e le persone potevano lavorare attraverso la divisione generazionale. A volte le persone erano inizialmente riluttanti a lavorare con gruppi di età diverse dalla propria, ma alla fine imparavano a vedere le cose attraverso lenti diverse e benefiche.\n\nDal momento che Betsy e il suo vice hanno conosciuto bene la loro squadra, è stata in grado di mettere insieme rapidamente squadre efficaci. Un segno distintivo del suo successo è che ogni volta che chiedeva a una squadra di lavorare su due cose, nessuno ha mai detto di no. Semplicemente lo facevano.\n\nClicca qui per la seconda metà della discussione di Darren con Betsy Freeman.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Betsy Freeman"],"link":"/episode-EDT104-it","image":"./episodes/edt-104/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Public Sector, Intel parla con Betsy Freeman, CEO di Radius Advisory Group, della sua esperienza come leader orientato all'informazione nei settori pubblico e privato. Prima parte di due."},{"id":7,"type":"Episode","title":"Leadership guidato dalle informazioni Parte 2","tags":["change","people","changeagent","radiusag","organizationalchange","informationdriven","leadership"],"body":"\r\n\r\nAnche se Betsy è CEO di Radius Advisory Group e formalmente in pensione dal settore federale, mantiene comunque un piede nel settore pubblico attraverso la sua azienda che si focalizza sulla sicurezza informatica e sulle questioni legate allo spazio cibernetico di importanza nazionale. Lavorare contemporaneamente sia nel settore privato che in quello pubblico è stata la parte più entusiasmante del suo percorso professionale.\n\nBetty ha iniziato come militare attivo nella Forza Aerea, passando poi all'industria mentre si occupava dei figli e del coniuge, che era anche in servizio attivo. Ha lavorato in diversi settori, più recentemente nelle utility e nell'energia, e ha trascorso molto tempo presso PricewaterhouseCoopers. È tornata al Dipartimento della Difesa (DOD) quando è stata selezionata per lavorare con il Segretario Gates come membro della Defense Efficiencies Task Force. È rimasta sotto il Segretario Pancetta e ha intrapreso un'avventurosa carriera, venendo infine nominata Vice CIO per la Rassegna dei Processi Aziendali e dei Sistemi. Lì ha creato una funzione di analisi dei dati per fornire maggior trasparenza sui costi e sulle potenziali efficienze dell'Information Technology in tutto il DoD.\n\nLa sfida più grande di Betsy nel ruolo di Vice CIO, che secondo lei vale sia per il settore pubblico che per quello privato, è come introdurre nuove idee, processi, tecnologie e metodi di lavoro nell'organizzazione. Nelle grandi aziende, l'ambito è enorme e ci sono molti compartimenti separati, ognuno con la propria cultura, obiettivi, budget e bilanci. Situazioni come la pandemia da COVID, in cui i cambiamenti devono avvenire rapidamente, sono estremamente difficili.\n\nBetsy dice che il COVID ha cambiato la cultura in alcuni modi, ma in altri modi ha spinto le persone a rinchiudersi ancora di più, il che non è buono. Ci sono state molte sfide di processi e tecnologie dalle quali tutti hanno imparato e continuano a farlo. Una preoccupazione che Betsy ha è che ora c'è un nuovo ambiente ed ecosistema, e il ritorno in ufficio non può essere imbottito nel vecchio modo come molti leader stanno cercando di fare. Anche se è molto difficile navigare in questa situazione, e che i leader considerino il nuovo ambiente buono o cattivo, non può essere trattato allo stesso modo di prima.\n\nUna volta che i leader fanno un cambiamento, tuttavia, la strategia di Betsy è quella di fare tutto in fretta. Ha imparato questa lezione quando era Vice CIO e le furono assegnati vari progetti oltre alla missione di base. Ha notato che ad altri team venivano dati ripetutamente 30 giorni per i progetti, ma al suo team venivano dati solo 10 giorni. Quando ha chiesto spiegazioni, i dirigenti hanno detto che sapevano che il suo team poteva farcela in 10 giorni e che dovevano prendere decisioni complesse che richiedevano le informazioni che il suo team poteva fornire come parte del processo decisionale, quindi più velocemente le ottenessero, meglio era. Così ha detto al suo team che dovevano solo trovare il modo di farcela. Ci sono riusciti e ci sono diventati bravi.\n\nUn senso di urgenza aiuta le persone a concentrarsi e ad agire, ma i leader, come sottolinea Betsy, devono assicurarsi di essere dotati delle persone, delle risorse e dell'autorità necessarie per portare a termine qualcosa in tempi brevi. Questo supporto da parte dei leader è fondamentale per il successo.\n\nBetsy crede che ascoltare le persone sia essenziale, ma le decisioni vengono prese dall'alto, il che dovrebbe generalmente significare poche persone. Un'organizzazione a matrice, che ha guadagnato popolarità negli anni '90 e 2000, ha aggiunto livelli di complessità, ma nella maggior parte delle situazioni già complesse, alla fine conta comunque la leadership. I leader devono essere abbastanza inclusivi da ascoltare il maggior numero possibile di persone, ma non si può impiegare cinque mesi e 150 incontri. Devono sviluppare sistemi e gruppi in grado di generare idee, suggerire modelli e collaborare tra loro. I leader devono avere la capacità di agire prontamente; a volte devono agire velocemente. Spesso, la soluzione sta nel coinvolgere meno persone ma le persone giuste, meno tecnologia e la tecnologia giusta per ottenere ciò di cui si ha bisogno.\n\nBetsy ha utilizzato un modello efficace quando ha ricevuto progetti urgenti dal Sottosegretario della Difesa per creare piccoli team di cinque-sei persone con diverse competenze cognitive tra i suoi 50 analisti. Questo è stato un successo perché conosceva bene la personalità e le competenze dei suoi analisti e poteva scegliere i team in modo mirato anziché coinvolgere un gruppo enorme e cercare il contributo di tutti. I piccoli team l'hanno sorpresa più volte nel portare a termine compiti complessi e risolvere problemi.\n\nCreando processi e modelli per risolvere i problemi, il team di Betsy spesso forniva input al Vice Segretario alla Difesa o al CIO in poche ore, se necessario. Alla fine, avevano dei processi in atto che consentivano loro di realizzare l'ideazione per proporre opzioni neutre basate sui dati e su molte considerazioni. Questo permetteva ai leader di guardare i fatti e le prove e prendere decisioni.\n\nBetsy aveva fiducia nelle sue squadre e non diceva loro come fare il lavoro o supponeva di sapere il modo migliore per affrontare le cose. Aveva buone persone e semplicemente si fidava di loro per farlo. Questo motivava le sue persone e le rendeva costantemente ansiose per nuovi incarichi. I dipendenti vogliono sapere che i leader li ascoltano e considerano e utilizzano le loro idee. Questo approccio permetteva alle persone di condividere la loro migliore analisi e opzioni con Betsy. Spesso era una combinazione di tali analisi che ritornava alla leadership. Il merito va al leadership nel DOD e nell'ufficio del CIO, che avevano fiducia nel processo di Betsy.\n\nOgni volta che c'era un nuovo problema, Betsy assegnava una nuova squadra. In questo modo, persone diverse potevano lavorare su diversi tipi di progetti e non venivano confinate in un'area specifica, e le persone potevano lavorare attraverso l'intergenerazionale. A volte le persone erano inizialmente restie a lavorare con persone di diverse età, ma alla fine imparavano a vedere le cose attraverso lenti diverse e benefiche.\n\nDal momento che Betsy e il suo vice hanno conosciuto bene le loro persone, lei è stata in grado di mettere insieme rapidamente squadre efficaci. Un tratto distintivo del suo successo è che ogni volta che chiedeva a una squadra di lavorare su due cose, nessuno diceva mai di no. Lo facevano semplicemente.\n\nClicca [qui](episode-EDT104) per la prima metà della discussione di Darren con Betsy Freeman.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Betsy Freeman"],"link":"/episode-EDT105-it","image":"./episodes/edt-105/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Public Sector, Intel continua la sua conversazione con Betsy Freeman, CEO di Radius Advisory Group, riguardo alla sua esperienza come leader orientato all'informazione nei settori pubblico e privato. Parte due di due."},{"id":8,"type":"Episode","title":"La nascita delle piattaforme di intelligenza grafica","tags":["data","graphintelligenceplatform","graphdb","katanagraph","technology"],"body":"\r\n\r\nGreg ha iniziato la sua carriera presso una banca d'investimento nel settore del rischio di credito quando hanno iniziato a implementare i test di stress CCAR. Dopo avervi lavorato intensamente per un po' di tempo, ha iniziato a lavorare come consulente e si è familiarizzato con i grafici durante la convalida dei modelli di rischio di credito. Ha visto come i grafici potessero essere utilizzati per molteplici tipi di analisi e apportare vantaggi nella gestione dei dati e nell'apprendimento automatico, in particolare nella modellazione del credito. Da lì, ha trovato la sua strada verso Katana.\n\nGli analisti dei dati e gli scienziati dei dati lottano costantemente per integrare diversi set di dati. Greg è stato attratto dai grafici perché, dopo essere stato introdotto a RDF, un formato di grafo di conoscenza semantica, aveva intuitivamente senso come i dati potessero essere combinati e strutturati come un grafo.\n\nCon le soluzioni di grafico esistenti, gli analisti hanno avuto difficoltà a scalare le proprie soluzioni perché gran parte dei loro dati era così grande. Katana Graph ha sviluppato la capacità di scalare e allo stesso tempo concentrarsi sull'apprendimento automatico.\n\nAll'inizio dei database a grafo, grandi aziende come Amazon e Facebook costruivano internamente database a grafo, facendo il loro modello e apprendimento automatico. Poi arrivarono versioni per consumatori delle piattaforme come Neo4j e TigerGraph per casi d'uso generali. La sfida era che erano incentrati sul database e non tanto sull'analisi e sull'apprendimento automatico, sui processi e sul calcolo effettivo del grafo. Erano limitati a essere una sorta di memorizzazione dei dati, focalizzandosi sull'ingestione e sulle operazioni CRUD e non tanto sui dati stessi.\n\nCi sono tre diverse tipologie di domini di calcolo grafico. La prima è la ricerca su grafi, il database a grafo e le operazioni CRUD. La seconda è l'analisi e l'estrazione di informazioni dai grafi utilizzando algoritmi come PageRank o clustering, che stanno diventando popolari. La terza area riguarda l'intelligenza artificiale e l'apprendimento automatico sui grafi. È qui che entrano in gioco le reti neurali a grafo. Ci sono soluzioni specifiche che risolvono parti specifiche di questi domini, ma Katana Graph si situa all'intersezione di questi.\n\nCiascuna delle tre piattaforme è importante. Per fare machine learning, hai bisogno degli altri due domini. Quando i dati vengono primariamente ingesti, devono subire molte trasformazioni per prepararli per il machine learning, quindi se non hai tutto questo in una soluzione unica, il flusso dei dati sarà lento, inviando i dati fuori e poi di nuovo dentro. È più efficiente iterare rapidamente sull'intero flusso dei dati. Inoltre, riduci il rischio di perdita dei dati perché stai riducendo il numero di volte in cui trasformi i dati.\n\nInoltre, poiché Katana Graph è una piattaforma cloud-native, puoi mettere in pausa, salvare un checkpoint, spegnere il cluster e riavviarlo successivamente, proprio da dove ti eri interrotto.\n\nUn buon esempio è per la rilevazione delle frodi con un set di dati sulle transazioni Bitcoin. La piattaforma acquisisce i dati, che sono strutturati in modo che i portafogli Bitcoin siano i nodi nel grafo, e quindi i collegamenti tra di loro sono le transazioni. È un grafo semplice. L'idea è prevedere se un portafoglio Bitcoin è fraudolento. I portafogli illeciti per il riciclaggio di denaro, il traffico di droga, ecc. sono stati etichettati. Quando arriva un nuovo account, il compito è prevedere se è fraudolento. La parte difficile, quindi, è fare alcune operazioni di pre-elaborazione con le caratteristiche numeriche degli account. Un insieme di API è stato progettato per affrontare quel problema. Tutte le cose che i data scientist fanno per preparare le loro caratteristiche vengono fatte qui. Da lì, il grafo è pronto per essere inserito nel modello di apprendimento automatico, dove viene addestrato e quindi, utilizzando le reti neurali, puoi imparare come classificare gli account.\n\nUn vantaggio della piattaforma è che i data scientist e gli ingegneri possono lavorare da una sola piattaforma anziché unire insieme pezzi diversi.\n\nUn altro vantaggio è il costo totale di proprietà. A differenza di altre piattaforme, non è necessario mantenere il database di grafi in funzione tutto il tempo. Poiché i pipeline di Katana Graph sono progettati con una separazione tra archiviazione e calcolo, è possibile avviare facilmente un cluster, eseguire elaborazioni batch preventivamente e quindi eseguire inferenze in un sistema separato e ancora sfruttare ciò che è stato generato nel grafo.\n\nKatana Graph è anche più veloce con grandi set di dati in quanto non carica tutti i dati inizialmente, ma ha un modo innovativo e dinamico di caricare i dati man mano che li si necessita mentre si lavora nel flusso di lavoro.\n\nLe analisi di base sono molto più facili sul database grafico piuttosto che su un database relazionale. Se si hanno dieci diversi set di dati, può essere difficoltoso e soggetto ad errori per un analista capire come unirli per scrivere una query in un database relazionale. Con un grafico, si ha un modello singolare, già predefinito e costruito, quindi le domande saranno molto più facili perché i dati sono già collegati. Si può intuire facilmente come le informazioni sono correlate.\n\nUna delle nuove caratteristiche di Katana è un'importante per i trame dei dati Dash. Dash è un framework comune che i data scientist utilizzano per l'elaborazione parallela dei trame dei dati. I data scientist possono lavorare con il trame dei dati che stanno già utilizzando e inglobarlo direttamente in Katana Graph per un'esperienza fluida e semplificata.\n\nDevOps è una parte importante di ciò che Katana sta cercando di facilitare con la loro piattaforma. Si integrano facilmente nelle pipeline di apprendimento esistenti. Quando i graph neural networks vengono eseguiti, gli embedding possono essere esportati. Queste caratteristiche generate da un grafo possono essere utilizzate in un processo di machine learning. Quindi l'integrazione diventa molto più semplice e più facile da operazionalizzare e mettere in produzione.\n\nNel corso dei prossimi cinque anni, Greg immagina che le organizzazioni come le banche abbiano dei repository centralizzati per analizzare i dati dei clienti, del marketing o del credito per molteplici scopi. Ad esempio, l'output dai modelli di apprendimento automatico potrebbe essere utilizzato sia per il rischio di credito che per la rilevazione delle frodi. Invece di utilizzare set di dati isolati con molta replicazione e duplicazione tra di loro, ci sarebbe un modello comune sincronizzato all'interno di un grafico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Steck"],"link":"/episode-EDT106-it","image":"./episodes/edt-106/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher di Intel, Chief Solutions Architect per il settore pubblico, e Greg Steck, Senior Director delle soluzioni settoriali presso Katana Graph, parlano dei vantaggi della piattaforma di intelligenza grafica di Katana."},{"id":9,"type":"Episode","title":"Proteggere le infrastrutture critiche","tags":["criticalinfrastructure","hotms","irdeto","otsecurity","edge","cybersecurity","technology","process"],"body":"\r\n\r\nCarla è originaria del Messico, vive ad Amsterdam dopo aver vissuto in diversi paesi, tra cui la Germania, negli ultimi quattro anni. Ha studiato ingegneria industriale e meccatronica, poi dopo aver lavorato per alcuni anni nel settore, ha ottenuto una laurea magistrale in ingegneria dei sistemi di mobilità, concentrandosi sui veicoli autonomi.\n\nLa definizione di infrastruttura critica OT è qualsiasi punto che può scatenare il caos nel mondo reale. Questo è molto diverso dall'infrastruttura IT; l'IT manca di infrastrutture vitali. Nel mondo OT, le persone possono morire se le cose vanno storte. Senza dubbio, può esserci caos nel mondo IT, ma il problema può essere risolto riparando le cose. Quando c'è il caos nelle infrastrutture critiche come i trasporti, possono verificarsi incidenti e la vita delle persone è in pericolo.\n\nNegli ultimi cinque anni, è aumentata l'importanza della sicurezza nelle infrastrutture critiche, e certamente durante la pandemia da COVID-19; in alcuni casi, le infrastrutture critiche sono state incessantemente attaccate. Ciò può essere attribuito al fatto che le persone diventano annoiate e più creative, ma anche perché la superficie di attacco è aumentata con il repentino passaggio al lavoro da remoto, che ha infranto alcune delle misure di sicurezza precedentemente adottate.\n\nNei trasporti, parte del problema è l'aumento della connettività, che porta a potenziali attacchi. I clienti desiderano più servizi, mentre le aziende cercano più dati e accesso alle informazioni. Con ciò si apre la rete di trasporto. La distanza di separazione, che in passato forniva sicurezza, sta diminuendo.\n\nL'industria non può utilizzare le misure di sicurezza che l'IT ha utilizzato per anni, poiché l'IT e l'OT sono completamente diverse. L'IT è generalmente standardizzato, mentre l'OT non lo è. L'OT ha un ecosistema enorme con notevoli differenze nei dispositivi che seguono altri protocolli e implementazioni. Ad esempio, ogni paese ha implementazioni diverse. Inoltre, l'OT si trova su un altro livello poiché letteralmente delle vite sono in gioco.\n\nUn'altra differenza tra le infrastrutture critiche IT e OT è che nell'IT, se c'è un problema nella tua rete, puoi isolare e persino spegnere quella parte e spostare il carico di lavoro altrove. Ciò non è possibile nelle infrastrutture critiche, quindi l'approccio è diverso.\n\nIl pericolo sta nel fatto che le reti IT e OT si sono sfaldate a causa del desiderio di una maggiore connettività e, nello stesso tempo, si è registrato un aumento delle minacce informatiche. Irdeto cerca di educare l'industria sulle complessità di questi problemi e offrire soluzioni. Si tratta di soluzioni preventive, non di reazioni dopo che si è verificato un disastro.\n\nCarla afferma che le organizzazioni devono avere esperti per la sicurezza. Sviluppare la sicurezza internamente basandosi su standard obbligatori non è sufficiente poiché gli standard sono sempre in ritardo rispetto allo sviluppo.\n\nIrdeto ha garantito la sicurezza delle infrastrutture critiche per 50 anni. Hanno circa 1.000 dipendenti, e il 70 percento di essi lavora nella ricerca e sviluppo per rimanere al passo con il tipo di attacchi che avvengono oggi e quali tipi di attacchi possono esistere in futuro. Irdeto si impegna ad essere un passo avanti o a prova di futuro. I loro servizi si evolvono insieme al sistema.\n\nIrdeto può aiutare i clienti che sanno cosa ci serve, che sia PKI, chiavi e credenziali, gestione del ciclo di vita o protezione software. Possono anche aiutare i clienti che non sanno cosa ci serve e fornire soluzioni durature man mano che le minacce si evolvono.\n\nPer ulteriori informazioni su Irdeto, vai al loro sito web www.Irdeto.com/connected-transport per saperne di più sul loro servizio.\n\nProdotti o contattarli direttamente.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Carla Trevino"],"link":"/episode-EDT107-it","image":"./episodes/edt-107/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher di Intel, Chief Solutions Architect del settore pubblico, insieme a Carla Trevino, Solutions Architect di Irdeto, parlano dell'importanza della sicurezza nell'infrastruttura critica."},{"id":10,"type":"Episode","title":"Storia delle Comunicazioni Avanzate","tags":["5g","cellphone","comms","wifi6"],"body":"\r\n\r\nLa prima generazione di tecnologia telefonica cellulare, il Sistema di Telefonia Mobile Avanzata (AMPS), fu sviluppata alla fine degli anni '70 e all'inizio degli anni '80. All'inizio degli anni '80, fare una chiamata dal proprio veicolo con un ingombrante telefono a sacca era un lusso. Il lusso di effettuare una chiamata da un dispositivo mobile divenne presto una necessità.\n\nNegli anni '90, la tecnologia ha fatto progressi con lo sviluppo dello standard Global System for Mobile Communications (GSM), che descriveva i protocolli per la tecnologia 2G, diventata lo standard globale a metà degli anni 2010. La tecnologia 2G ha iniziato a trasformare il telefono cellulare in qualcosa di più di una semplice chiamata, aggiungendo la possibilità di inviare messaggi e persino giocare ai videogiochi.\n\n3G è stato lanciato all'inizio degli anni 2000 e ha introdotto alcune capacità preliminari di trasferimento dati con internet, che è ancora nelle sue fasi iniziali. Il Wi-Fi non era ampiamente disponibile, ma potevi, ad esempio, accedere alla rete dati di un operatore collegando un telefono a un laptop. Potevi fare al massimo il minimo con velocità di modem o DSL.\n\nCon il 4G, la tecnologia si è trasformata in uno standard unificato, convergendo CDMA e GSM in un unico standard LTE all'interno del Progetto Partnership di Terza Generazione (3GPP). Ogni operatore ha iniziato ad adottare questo standard comune. È stato in questo momento che la banda larga si è diffusa. Leland attribuisce l'avanzamento dell'economia degli anni 2010 al 4G, permettendo a società come Amazon, Netflix e Uber e piattaforme come YouTube, Google e Facebook di esistere e prosperare.\n\nLeland parla del 5G in base a ciò che gli operatori hanno implementato. Il 4G e il 5G sono correlati perché fanno parte della stessa specifica di rilascio di linea. Il 4G LTE avanzato si conclude con il quattordicesimo, mentre il quindicesimo segna l'inizio dell'NR del 5G. In questa transizione, c'è un obiettivo aziendale e una strategia per adottare la nuova tecnologia come parte dello standard. L'obiettivo aziendale è che le aziende hanno già investito nelle loro reti 4G, quindi i componenti core evoluti del pacchetto e RAN delle reti 4G rimangono comunque in uso. Vengono aggiunti una scatola RAN 5G con una frequenza diversa ma ancora collegata al core 4G, chiamata non autonomo.\n\nDarren chiarisce che il 4G è stato rivoluzionario perché ha sbloccato molte nuove cose e ha richiesto tutte nuove apparecchiature, mentre il 5G è più evolutivo perché ha aperto anche nuove cose. Tuttavia, la tecnologia sottostante si basa sullo stesso hardware e core.\n\nFa parte dell'interfaccia radio utilizzata dallo schema di modulazione fornito dal 5G, ma l'architettura è diversa; rispetto al 4G, è virtualizzata nel 5G e presenta caratteristiche più proprietarie. Ciò porta a molte capacità che diventano parte delle implementazioni del 5G.\n\nUn esempio è un operatore che ha implementato una rete 4G posizionando una scatola RAN accanto a una vecchia scatola 3G. Molte aziende, come Sprint, hanno mantenuto le loro scatole 3G e la rete CDMA per anni. In realtà, il 4G era solo un'altra scatola accanto a una scatola 3G. Il 5G prende quella scatola proprietaria e dà la capacità di distribuire le funzioni di quella scatola su una rete virtualizzata. Una parte della banda base del 5G può ora essere definita dal software per scala in diverse aree rispetto a essere contenuta in un unico sito, scatola o posizione.\n\nQuesto significa che puoi aggiungere funzionalità alla tua rete senza sostituire l'hardware. Man mano che passi alle reti autonome, tuttavia, puoi utilizzare una rete 5G e fare qualcosa in loco. Ad esempio, supponiamo che tu abbia un grattacielo invece di dipendere dalla copertura di rete di un'antenna posizionata all'esterno, con un nucleo presso il gestore o una stazione di commutazione. In quel caso, puoi sviluppare una rete in loco creata all'interno di quell'edificio che diffonde copertura e servizi dati in tutto l'edificio.\n\nQuesta rete autonoma apre molte nuove possibilità e consente l'ingresso di nuovi attori. Inoltre, permette a organizzazioni come il governo federale e il Dipartimento della Difesa di adottare la tecnologia per i loro casi d'uso. Hanno maggiore flessibilità quando non dipendono fortemente dagli operatori di comunicazione.\n\nAnna nota che oltre ai nuovi giocatori e alle nuove capacità in loco, c'è anche la possibilità di utilizzare lo spettro CBRS. Il modo in cui viene gestito è complesso, ma ci sono dei canali non prioritari che puoi utilizzare gratuitamente e dei canali prioritari, come lo spettro della Marina, che puoi acquistare se hai bisogno di evitare interruzioni. Alcuni stabilimenti di produzione estesi stanno utilizzando lo spettro CBRS, lavorando sia con un vettore primario che non addebita costi per l'uso, sia con un nuovo entrante che configurerà una rete autonoma in loco con CBRS. Questo è un modello molto diverso e ci sono vantaggi reali nella lunghezza d'onda e nella complessità dei sistemi che puoi configurare con il 5G rispetto al Wi-Fi.\n\nCi sono ancora alcuni vantaggi nel Wi-Fi, ma configurare una rete Wi-Fi robusta può essere complicato, soprattutto se stai spostando grandi pezzi di metallo. Se hai una configurazione stabile, ha senso optare per il Wi-Fi 6, specialmente se l'aspetto economico funziona.\n\nLa domanda guida il cambiamento; la maggior parte degli utenti finali si sente a proprio agio con il 4G sui propri dispositivi personali. Allora, perché passare al 5G? Il valore che il 5G porta non è necessariamente legato alle velocità di trasferimento dati più elevate e alla latenza ridotta; questi servizi vengono forniti su ampia scala perché è virtualizzato. Il 5G è molto più basato sul software rispetto al 4G, che si basa principalmente su hardware proprietari. Il 5G può essere virtualizzato in molte posizioni. Il portafoglio di frequenze è dinamico e è possibile utilizzare bande non licenziate, bande con licenza e FCC, quindi ci sono molte più opzioni.\n\nControlla la seconda parte di questa intervista [qui](episodio-EDT109).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown","Anna Scott"],"link":"/episode-EDT108-it","image":"./episodes/edt-108/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con i frequenti ospiti Intel Leland Brown, Ingegnere Principale: Direttore Tecnico delle Comunicazioni Avanzate, e la Dott.ssa Anna Scott, Architetto Capo per il Settore Pubblico, sulla storia delle comunicazioni avanzate."},{"id":11,"type":"Episode","title":"Avanzando le Operazioni con il 5G","tags":["5g","comms","wifi6"],"body":"\r\n\r\nIl 5G apre molte possibilità. Ora è possibile configurare reti private, che sono definite tramite software, consentendo di aggiungere ulteriori funzionalità alla rete. A dove ci porta questa tecnologia abilitante?\n\nAnna dice che sebbene siamo ancora agli inizi per quanto riguarda la larghezza di banda e la latenza, ci sono vantaggi reali nel 5G, come l'apertura dello spettro, come il CBRS, la capacità di sfruttare l'attrezzatura utente esistente e la possibilità per i clienti di avere l'accesso mobile.\n\nUn caso d'uso che non è affascinante ma ha vaste ramificazioni è quello di poter portare il tuo laptop sul pavimento della fabbrica e utilizzarlo per una completa connettività. Invece di andare sul pavimento della fabbrica con un blocco note e carta e trasferire le informazioni in ufficio, puoi convergere i due ambienti. Gli standard 5G consentono ciò, ma non necessariamente richiedono una piena implementazione del 5G.\n\nUna delle evoluzioni in corso è la capacità di trasmettere video ad alta definizione da una telecamera wireless tramite il 5G e avere una latenza sufficientemente bassa da consentire l'analisi in tempo reale. Attualmente, non molte telecamere 5G possono operare in tale ambiente, quindi le telecamere sono spesso collegate in modo fisso a sistemi di calcolo per ottenere quell'aspetto in tempo reale, ma questa vantaggiosa opzione di streaming sarà presto disponibile.\n\nUn altro esempio di vantaggio del 5G è l'utilizzo di 10-20 visori AR invece di uno o due con il Wi-Fi. Il punto chiave è il MEC (Mobile Edge Compute) che offre la possibilità di avere le applicazioni in loco anziché dover tornare allo switch o al core del gestore e avere quella latenza di rete.\n\nCapire come vengono utilizzate le frequenze è essenziale nei casi d'uso, poiché alcuni gestori hanno implementato mmWave nonostante le sfide; le frequenze n41 e n42 reagiscono diversamente nel mondo reale. Quindi, nelle implementazioni in loco, MEC e il design RF sono estremamente importanti.\n\nUn caso d'uso convincente per il 5G al di fuori delle fabbriche è l'utilizzo dei droni nelle risposte di emergenza. Un precursore degli eventuali droni in grado di valutare un'area danneggiata è il collegamento dei droni, la comprensione di una missione di sorvolo e il successivo riunire tutti questi dati. Sebbene non siamo ancora in grado di trasmettere video in diretta da diversi droni e unirli insieme, siamo prossimi alla raccolta, combinazione e analisi di tali dati, anche se ancora non in tempo reale.\n\nUn altro caso d'uso consiste nell'utilizzare 5G, intelligenza artificiale, modellazione, simulazione e edge computing per la formazione in diversi settori, inclusa il Dipartimento della Difesa. C'è un enorme vantaggio nel creare una simulazione di addestramento realistica senza mettere la persona in pericolo o spendere cifre ingenti per l'addestramento dal vivo.\n\nPer quanto il 5G permetta questo tipo di scenario d'uso, molto dipende dal fatto che il 5G si connetta a un MEC invece che salire verso il cloud. La fisica entra in gioco. È necessaria una latenza super bassa, quindi non puoi avere un'architettura che vada da un headset al cloud, passando per un MEC, per poi arrivare alla visualizzazione. Deve passare dall'headset al MEC, dove avviene il processing in tempo reale. Successivamente puoi condividere i dati attraverso il cloud per un'esperienza in tempo reale.\n\nEsiste anche la possibilità di collegare o raggruppare insieme i MEC, in modo che i dati non debbano mai andare al cloud. I MEC possono eseguire tutte le elaborazioni e le analisi direttamente sullo switch. Ciò potrebbe consentire progressi come edifici e città intelligenti. Questo tipo di tecnologia abilitante 5G rappresenta la tempesta perfetta per cambiamenti considerevoli nell'industria.\n\nLeland sottolinea che la storia delle nuove reti è il calcolo distribuito. Tutto è connesso tramite connettività wireless, ma i punti di calcolo sono dispersi sul territorio, dove le app si trovano ai margini e consentono l'utilizzo dei casi d'uso. La direzione verso la quale ci stiamo dirigendo è calcolare la connessione wireless uno a uno.\n\nQual è il ruolo di Intel nel 5G? Va ben oltre la semplice fornitura di chip. Poiché il 5G è progettato attraverso il software, Intel ha consentito all'ecosistema di costruire o progettare utilizzando il proprio L15. Passando dal 4G al 5G, Intel ha preso il blocco funzionale della RAN, chiamato FlexRan, e ha permesso alle aziende di progettare le proprie architetture di banda base e virtualizzarle. Scrivere l'architettura di riferimento di FlexRan ha reso molto più facile per i nuovi entranti usare quella come punto di partenza.\n\nSul lato hardware, Intel ha dedicato molti cicli per garantire che l'hardware commerciale già disponibile funzionasse bene nel supportare tutte le bande di base, le applicazioni RAN e i server. I nuovi sistemi che vengono implementati abbandonando i sistemi proprietari devono essere facilmente supportati dallo stesso tipo di server che funziona nel cloud e nel data center, perché ora si dispongono di scale e vantaggi in termini di costi.\n\nQuesto ridurrà i prezzi e favorirà maggiormente l'innovazione nell'industria.\n\nGuarda la prima parte di questa intervista [qui](episode-EDT108).\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown","Anna Scott"],"link":"/episode-EDT109-it","image":"./episodes/edt-109/it/thumbnail.png","lang":"it","summary":"L'intervista di Intel a Darren Pulsipher, architetto delle soluzioni principali, Leland Brown, ingegnere principale: Direttore tecnico delle comunicazioni avanzate, e la dottoressa Anna Scott, architetto principale dell'edge per il settore pubblico, parla della storia delle comunicazioni avanzate e dei casi d'uso futuri con il 5G. Parte due di due."},{"id":12,"type":"Episode","title":"Insegnamento a Distanza e Apprendimento","tags":["remotelearning","compute","technology","people","edge","telelearning"],"body":"\r\n\r\n## Considerazioni emergenti\n\nInsegnanti, personale, genitori e studenti si trovano di fronte a sfide diverse nel passaggio improvviso all'apprendimento a distanza. Sul lato informatico per i distretti scolastici, si pongono una serie di considerazioni emergenti. Cosa facciamo con lo scenario del bring your own device (BYOD) che proviene da reti a fiducia zero? Come proteggiamo la privacy e gestiamo la sicurezza con tutte le nuove modalità di comunicazione tra insegnanti, personale, genitori e studenti? Come manteniamo un'esperienza di classe gestita in modo efficiente? Come offriamo supporto quando non esiste una struttura di helpdesk tradizionale? Inoltre, non possiamo dimenticare che c'è un aspetto sociale importante che deve guidare un'esperienza senza soluzione di continuità. Un alunno di terza elementare distratto da problemi tecnici quando ha bisogno di collegarsi con insegnanti e compagni avrà un'esperienza di apprendimento a distanza ridotta.\n\n## Servizi di Sistemi, Servizi e Piattaforme per l'Istruzione\n\nCi è sempre stata complessità con tutti i livelli diversi di servizi e piattaforme, ad esempio, il pacchetto di produttività con G Suite e Office 365. La domanda ora è cosa possiamo fare con i sistemi di gestione dell'apprendimento in questo approccio strutturato nell'integrazione del sistema di informazioni degli studenti? Dobbiamo considerare come stiamo sfruttando le nostre capacità in termini di scalabilità. Dobbiamo prendere in considerazione diverse soluzioni di infrastruttura come servizio (IAAS) e piattaforma come servizio (PAAS), servizi di archiviazione, privacy e sicurezza, e, ovviamente, le piattaforme sottostanti che guidano tutto ciò.\n\nPrecedentemente, gli strumenti di conferenza e collaborazione avevano un uso limitato, forse per portare un relatore ospite, ad esempio. Ora, tuttavia, vengono utilizzati pesantemente come strumenti primari e hanno contribuito alla complessità del sistema.\n\n## Opzioni di hosting del servizio\n\nCi sono due modalità principali utilizzate per accedere ai servizi: il dispositivo come porta di accesso ai servizi (software, infrastruttura o piattaforma) e il dispositivo come parte della rete interna. In precedenza, la maggior parte rientrava nella seconda categoria, dove c'erano limitate preoccupazioni riguardo a questioni come la patching e la conformità alle politiche perché i dispositivi erano costantemente connessi ai siti scolastici interni, indipendentemente che fossero dispositivi portati da casa o asset di proprietà del distretto. Ora, con i diversi tipi di connettività, dobbiamo preoccuparci della scalabilità della larghezza di banda e di come implementarla.\n\n## Dispositivo come Portale ai Servizi\n\nPiattaforme come G Suite, Office 365 e quelle per videoconferenze e collaborazione rappresentano una preoccupazione perché creano dipendenza da un terzo soggetto. I distretti scolastici non hanno controllo sulla sicurezza, la privacy e le prestazioni. È importante riconoscere che la connessione a questi servizi cloud si collega all'host interno, che sia un cloud privato o un data center in loco, che ha servizi sottostanti di gestione dell'identità, sistemi informativi degli studenti, possibile filtraggio dei contenuti, ecc. I vantaggi, tuttavia, sono una riduzione del traffico in entrata nel data center e la scalabilità e gestibilità intrinseca.\n\n## Dispositivo come parte della rete/cloud privato\n\nImplementare una rete virtuale privata (VPN) è una nuova idea per la maggior parte dei distretti scolastici. Le aziende usano da tempo le VPN e i distretti scolastici potrebbero dover fare altrettanto per soddisfare le nuove esigenze dell'apprendimento a distanza. Alcuni svantaggi di una VPN sono la congestione di rete, la scalabilità e il traffico proveniente da reti a \"zero trust\". Il principale vantaggio è che funziona come un'estensione della rete interna, quindi la gestione della sicurezza e la crittografia del traffico sono estese anche ai client VPN. Un altro grande vantaggio è l'accessibilità a tutti i servizi necessari internamente.\n\n## Sfide emergenti\n\nI bottleneck per l'apprendimento a distanza sono diversi. Per le aziende, quando la forza lavoro è diventata virtuale, ci si aspettava un carico VPN del 10%. Per l'istruzione, quel numero sarà significativamente più alto, creando un possibile collo di bottiglia VPN. La scalabilità dei servizi ospitati è un'altra area da considerare. Anche se i servizi sono presenti su un cloud pubblico, si collegano a un cloud privato o a un data center locale per cose come SSO, informazioni degli studenti, traffico e persino filtraggio dei contenuti. La larghezza di banda dedicata per l'accesso a Internet, così come la gestione del collegamento della larghezza di banda nel data center, sono importanti considerazioni.\n\nL'accesso a un componente di assistenza deve essere anche scalabile per evitare congestioni.\n\nLa preoccupazione principale dei distretti scolastici attualmente, tuttavia, è garantire l'accesso a tutti i loro studenti. Per alcuni studenti, c'è un collo di bottiglia nel semplice accesso a Internet da casa. Quando questo problema si aggiunge a tutti i diversi livelli, i collo di bottiglia emergenti diventano molto complessi.\n\nPer contrastare questi potenziali problemi, i distretti scolastici devono dedicare il tempo e le risorse necessarie per creare un'architettura solida che sia resiliente, invece di costruire in modo precipitoso un groviglio di spaghetti.\n\n## Scalabilità\n\nStoricamente, i distretti scolastici hanno aumentato le dimensioni del centro dati e distribuito alcuni di quei servizi nei siti scolastici. Quindi l'architettura esiste generalmente per permettere l'aggregazione di corpo docente, personale e studenti per questioni come autenticazione, gestione dei patch, distribuzione di software, ecc. Ora che l'espansione delle dimensioni avviene nella classe virtuale, ci porta nuovamente verso l'aumento dei servizi nel centro dati.\n\n## Trovare l'equilibrio\n\nIn precedenza, erano considerati solo i due fattori di on-prem nel centro dati principale e i collegamenti LAN ai siti scolastici. Ora c'è un fattore aggiuntivo nell'adattamento di tutte le aule virtuali, ovvero il salotto di ogni studente e insegnante. Come possiamo adattarci a ciò? In definitiva, si tratta del concetto principale di trovare l'equilibrio tra ciò di cui hai bisogno per il tuo distretto scolastico. Ogni distretto è diverso per dimensione e alfabetizzazione tecnologica, e ci sono molti aspetti in evoluzione.\n\n## Risolvere i punti critici\n\nCosa può Intel fare per aiutare a risolvere questi ostacoli che abbiamo identificato?\n\nLa gestione dei dispositivi finali e la sicurezza dei dispositivi finali è il punto in cui interviene il servizio di assistenza informatica. Stiamo cercando modi per offrire supporto in remoto anziché con visite regolari sul luogo della scuola.\n\nPossiamo analizzare il centro dati e l'infrastruttura e sviluppare una strategia che ci permetterà di espandere la rete e l'infrastruttura definita dal software. Inoltre, possiamo anche integrare un cloud bursting di infrastruttura come servizio, tenendo conto dei modelli di traffico.\n\n## Componenti Intel per affrontare i collo di bottiglia\n\nIntel può aiutare in tre categorie principali: calcolo, archiviazione e rete. Quando consideriamo il rafforzamento dell'infrastruttura definita dal software e le importanti considerazioni, ruota attorno a quel computer con processori Intel, prodotti di archiviazione e capacità di rete. Piuttosto che essere legato e limitato dalle interfacce fisiche e dagli apparecchi, l'infrastruttura definita dal software può scalare e incorporare altre risorse di calcolo, archiviazione e rete. Nessuno è certo di quali saranno le prospettive quando torneremo a scuola, e questa infrastruttura definita dal software è dinamica e offrirà la massima flessibilità.\n\nCi sono molte opzioni per i distretti scolastici per costruire un ambiente funzionale e sicuro per l'apprendimento a distanza. Sebbene abbiamo affrontato i temi della privacy e delle minacce alla sicurezza e le relative soluzioni in questa puntata, la prossima volta approfondiremo questi importanti argomenti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Erin Moseley","Grant Kelly"],"link":"/episode-EDT11-it","image":"./episodes/edt-11/it/thumbnail.png","lang":"it","summary":"In questo episodio, Erin Moseley, Senior Account Exec per l'Educazione presso Intel, e Grant Kelly, Architetto delle Soluzioni per l'Educazione presso Intel, si uniscono a Darren per parlare delle sfide dell'apprendimento a distanza e dell'insegnamento e dei cambiamenti travolgenti che i distretti scolastici, gli insegnanti, i genitori e gli studenti stanno affrontando durante la pandemia da Covid-19. Scopri come gli studenti e gli insegnanti si stanno collegando con nuove tecnologie e modalità di apprendimento."},{"id":13,"type":"Episode","title":"Proteggere la catena di approvvigionamento","tags":["securesupplychain","cybersecurity","supplychain","chipsact","policy","process","compute"],"body":"\r\n\r\nIn questa puntata, Darren parla con il Generale Tenente Thomas Horlander, che di recente si è unito al team del settore pubblico di Intel, riguardo alla catena di approvvigionamento delle microelettroniche e alla sicurezza nazionale.\n\nThomas si unì all'esercito nel 1983 dopo aver conseguito la laurea in finanza e aver deciso che il settore privato non era adatto a lui. Si unì all'esercito per quello che pensava sarebbe stata una carriera di tre-cinque anni e alla fine rimase in servizio per 39 anni, ricoprendo il ruolo di Comptroller dell'esercito. Si è ritirato circa un anno fa e si è unito a Intel.\n\nThomas è ispirato presso Intel dalle persone fantastiche, dalla cultura e dalla missione significativa. Apprezza il ruolo fondamentale che Intel svolge nella vita quotidiana di tutti e l'opportunità di influenzare il futuro del paese.\n\nQuando Thomas si unì all'esercito nel 1983, la microelettronica era ancora agli esordi; non avevano nemmeno i computer. Da giovane ufficiale, si preoccupava di avere abbastanza batterie D per far funzionare le radio. Quindi Thomas si considera un \"immigrato digitale\" poiché ha vissuto l'evoluzione avvenuta con il silicio.\n\nLa società e l'esercito sono ora dipendenti dal silicio, e la catena di fornitura intorno alla microelettronica è fondamentale: è una questione di sicurezza nazionale. Thomas afferma che l'industria della microelettronica condivide il palcoscenico con l'industria del petrolio come centro gravitazionale per quanto riguarda la sicurezza nazionale e globale e la stabilità economica.\n\nNel campo militare, i veicoli e i sistemi d'arma sono tutti dotati di microelettronica. Ciò consente all'esercito, ad esempio, di essere più preciso e letale con un peso ridotto, di avere un sistema di localizzazione più accurato e comunicazioni più affidabili.\n\nLa nostra dipendenza dalla microelettronica ha spinto l'approvazione recente della legge Chips. Sebbene il bisogno fosse evidente già prima della crisi in Ucraina, l'osservazione di ciò che l'Ucraina è stata in grado di fare grazie alla microelettronica ha messo in risalto la necessità di garantire la sicurezza della catena di approvvigionamento.\n\nThomas è stato uno studente di sicurezza nazionale per tutta la sua carriera e la considera in modo più olistico rispetto alla sola difesa e al ruolo delle forze armate. Per lui, la sicurezza nazionale è una buona gestione della governance e lo stato di diritto. È un'economia funzionante e pratica, un'accademia pratica, l'assistenza sanitaria e, ovviamente, le forze armate. E quasi tutte le professioni all'interno della società americana svolgono un ruolo nel fornire la sicurezza nazionale. Da questa prospettiva, praticamente ogni aspetto necessario per garantire la sicurezza nazionale si basa su microelettronica.\n\nThomas dice che il Chips Act era necessario a causa del enorme squilibrio presente nell'ecosistema dell'industria. Allo stesso tempo, sebbene non sia la soluzione definitiva per la ridistribuzione dell'equilibrio, il Chips Act rappresenta un primo passo essenziale e avrà un impatto sulla sicurezza nazionale. Quando si analizzano le attività principali dell'industria dei microelettronici, dalla provenienza degli elementi delle terre rare a chi produce le attrezzature per la progettazione e la produzione, diventa evidente quanto sia incredibile questo mosaico di attività e perché risulta così difficile avere una visione chiara di tutto ciò. Un microchip potrebbe passare di mano dieci volte durante il processo di produzione.\n\nCOVID, in molti modi, ha messo in evidenza questa catena di approvvigionamento complicata e fragile quando, ad esempio, le fabbriche sono state chiuse in Malaysia, Irlanda o Cina a causa di un'epidemia di COVID, e all'improvviso non si può più trasportare una macchina perché non ha un chip al suo interno. La maggior parte delle persone non si rende conto dell'importante squilibrio globale che attualmente esiste. Solo l'otto percento del silicio è prodotto negli Stati Uniti. Il settanta o l'ottanta percento viene prodotto nel Sud-est asiatico, precisamente in tre paesi: Cina, Corea del Sud e Taiwan.\n\nCon questa conoscenza, è evidente che riequilibrare l'ecosistema della catena di approvvigionamento globale e ripristinare capacità e competenze negli Stati Uniti sia di massima importanza. Nessun settore dovrebbe avere punti singoli di fallimento, un problema nell'industria delle microelettroniche.\n\nIl governo federale, la base industriale della difesa e l'ecosistema stanno tutti iniziando a vedere questo problema, e il Chips Act è rappresentativo di questo riconoscimento che dobbiamo fare qualcosa. Thomas conosce attualmente sei aziende che hanno dichiarato che investiranno in fabbriche sul suolo statunitense nei prossimi otto-dieci anni.\n\nUna di queste aziende è, naturalmente, Intel. Attualmente Intel sta costruendo fabbriche in Ohio, Arizona e Nuovo Messico. Riportare in patria capacità e competenze nell'industria delle microelettronica è necessario per la sicurezza nazionale, ma rafforzerà anche le economie locali e offrirà opportunità di lavoro, ravvivando intere comunità.\n\nL'infusione di investimenti di capitale provenienti dal Chips Act è fondamentalmente essenziale perché questa è una gara contro il tempo. Thomas è ottimista sul futuro dell'industria e sull'azione che viene intrapresa per garantire un futuro luminoso e un'innovazione continua.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Thomas Horlander"],"link":"/episode-EDT110-it","image":"./episodes/edt-110/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con il Lieutenant General Thomas Horlander, che ha recentemente fatto parte del Team Pubblico del settore Intel, sulla catena di fornitura delle microelettroniche e la sicurezza nazionale."},{"id":14,"type":"Episode","title":"Realizzare il potenziale delle Smart City","tags":null,"body":"\r\n\r\nEric ha avuto una lunga carriera nel data center e, più di recente, nello spazio del digital signage. Le sue passioni sono la gestione dei progetti e l'implementazione e l'operazione della tecnologia. Eric e il suo team facevano parte di una società mista di LG Electronics che ha installato segnaletica digitale all'aperto, principalmente per applicazioni pubblicitarie in aree urbane dense, luoghi di transito e strade cittadine. Hanno imparato molto su altre applicazioni in quegli ambienti che necessitano di risorse di calcolo e altre forme di connettività che aiuterebbero ad arricchire l'esperienza offerta dall'IoT. SmartPoint.io è nato da quell'ecosistema e dal desiderio di lavorare con e promuovere opportunità e progressi in quel settore di mercato.\n\nNel data center, Eric faceva parte di un'azienda di soluzioni del ciclo di vita che aiutava le aziende a ottimizzare l'archiviazione dei server e l'hardware di rete, dall'acquisizione fino al ciclo di rinnovo e tutto ciò che vi era tra mezzo. Il suo ruolo era incentrato nell'aiutare il canale delle aziende che vendevano tali soluzioni, ma anche riguardo a come venivano acquistate, finanziate e svalutate nel tempo, così ha imparato non solo sulla tecnologia ma anche su come le persone la utilizzavano e gestivano quel valore come un bene nel loro bilancio.\n\nQuando le persone parlano delle città intelligenti, pensano alla resilienza, all'equità, all'efficienza e alla convenienza economica. Le città forniscono servizi essenziali come strade, sicurezza pubblica, acqua e fognatura. La cosa principale che un comune offre ai suoi cittadini sta iniziando ad includere la connettività, la capacità di accedere alla tecnologia informatica e di sfruttare i progressi tecnologici per fornire servizi di base in modo più efficiente. La tecnologia intelligente è stata costosa e rischiosa, e pochi bilanci municipali hanno spazio per essa.\n\nIl background di Eric in finanza è un vantaggio nella creazione e nell'implementazione di tecnologie per città intelligenti in una partnership che fornisce un modello conveniente. Essere in grado di implementare l'attuale finanziamento significativo per i progetti infrastrutturali in modo resiliente ed economicamente sostenibile è uno dei principi fondamentali di ciò che fa SmartPoint quando si allea con una città.\n\nPer raggiungere la sostenibilità economica, il team di Eric ha analizzato attentamente la segnaletica digitale, principalmente per la pubblicità, che genera un'enorme quantità di ricavi. Alcune delle più grandi aziende del mondo sono finanziate principalmente dai ricavi pubblicitari, e uno dei principali prodotti o risorse sono le persone a cui stanno facendo pubblicità. Sovrapporre attributi, caratteristiche e somiglianze dei clienti incrementa i ricavi.\n\nLe città hanno un tesoro di valore nelle persone, nelle entità commerciali e nei visitatori che risiedono all'interno dei loro immobili. Quindi il nocciolo di ciò che SmartPoint.io sta facendo è sfruttare questi immobili per generare ricavi, ma allineandoli direttamente con soluzioni che producono risultati significativi nei servizi urbani. Introdurre questa tecnologia nelle città richiede l'aiuto del settore privato e la disponibilità del settore pubblico a lavorare insieme.\n\nIl ricavo pubblicitario, insieme alla possibilità di sfruttare i budget dei servizi cittadini, consente un modello finanziario che alza la marea per tutte le barche, fornendo un trasporto più sicuro e maggiori rendimenti pubblicitari. Quando si lega il beneficio della pubblicità alle persone a cui la pubblicità è rivolta, si crea un'economia locale circolare che aumenta valore ed efficienza.\n\nIl calcolo in periferia è una parte significativa del prodotto di SmartPoint.io. La scatola per la segnaletica digitale è simile a un centro dati portatile. I dati non devono necessariamente tornare a un grande centro dati in qualche luogo, ma vengono elaborati in periferia. Ad esempio, i dati video provenienti dalle telecamere onnipresenti in una città per monitorare i pattern di traffico richiedono molta larghezza di banda. Tuttavia, il trasporto dei dati si riduce significativamente se vengono memorizzati, conservati o elaborati localmente.\n\nTre grandi caratteristiche di queste scatole sono che svolgono un ottimo lavoro nel ridurre la latenza, il costo e aumentare la privacy. La questione della privacy può sembrare controintuitiva, ma i dati video, ad esempio, non viaggiano tramite IP pubblico. L'analisi avviene al punto di cattura, quindi non viene trasportata attraverso il canale, osservata o passata attraverso diversi punti di accesso dove la sicurezza deve essere monitorata. Invece di inviare l'immagine, viene inviato l'evento \"Una persona che cammina per strada\". Questi dati possono essere elaborati e resi anonimi molto prima del momento in cui lasciano la scatola, proteggendo così la privacy delle persone.\n\nLe casse potrebbero anche offrire servizi come Wi-Fi o punti di accesso 5G nelle zone sprovviste.\n\nUna volta che le scatole vengono installate, SmartPoint.io ha un team che monitora ed opera la tecnologia, proprio come farebbe un centro dati per un'azienda. Collaborano anche con inserzionisti. Molti inserzionisti sono interessati a passare dalla pubblicità statica dei \"manifesti cartacei\" alla pubblicità digitale. SmartPoint.io è un ottimo partner per questi inserzionisti perché offrono finanziamenti CapEx iniziali.\n\nCon le città, il modello è la condivisione dei ricavi o il pagamento in natura. Tuttavia, anziché limitarsi a condividere i ricavi totali, SmarPoint.io produce e gestisce risorse come l'infrastruttura IT che la città può utilizzare per elaborare i dati ottici in loco.\n\nLa segnaletica digitale può essere interattiva, il che è vantaggioso per le persone che cercano servizi, ristoranti, negozi, eventi e intrattenimento. I locatari commerciali possono utilizzarla come un portale per lo sviluppo economico, in quanto possono raggiungere le persone che passeggiano. A loro volta, le bacheche restituiscono informazioni preziose, come il numero di persone che si trovavano in centro o se una campagna pubblicitaria è riuscita a portarle lì con successo.\n\nQuesto modello aiuterà le città intelligenti perché differisce il costo di CapEx e OpEx della gestione dell'hardware all'esterno e dei cicli di aggiornamento. Assumere rischi su tecnologie costose e relativamente nuove non è nemmeno un comportamento normale per un comune, quindi il partenariato con il settore privato, che ha una significativa propensione al rischio, conoscenze e finanziamenti, aiuta le città a mitigare i rischi e i costi e ad avanzare oltre rispetto a quanto tipicamente sarebbero confortevoli.\n\nAlla fine, Eric afferma che i successi stanno iniziando a crescere in questo settore e si basano l'uno sull'altro. Tutti stanno imparando cose nuove ed è un'ottima opportunità per unirsi e costruire una comunità, che è ciò che rappresentano le città.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Eric Hornsby"],"link":"/episode-EDT111-it","image":"./episodes/edt-111/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren parla con Eric Hornsby, CEO di SmartPoint.io, riguardo alla tecnologia per realizzare il potenziale delle città intelligenti."},{"id":15,"type":"Episode","title":"Miti della migrazione di Cloud Lift and Shift","tags":["multicloud","cloudmigration","cloud","compute","process","technology"],"body":"\r\n\r\nJohn ha iniziato la sua carriera nel campo della tecnologia al servizio di assistenza presso un importante appaltatore della difesa 20 anni fa. Man mano che la sua carriera progrediva, si è interessato alla sicurezza informatica e all'architettura aziendale. Ha lavorato come appaltatore per la Defense Information Systems Agency (DISA), dove è stato il principale architetto per il cloud DISA del Dipartimento della Difesa. Alla fine, lo stato del Maryland lo ha chiamato per guidare gli sforzi di trasformazione digitale per lo stato, incluso il processo di migrazione verso il cloud. Quella migrazione è stata la più grande mai effettuata nel campo dell'istruzione sia statale che locale.\n\nDopo ciò, passò alla posizione di Capo Ufficiale della Sicurezza Informatica dello Stato (CISO), supervisionando operazioni di alto livello, sicurezza e governance. Ha lasciato il servizio governativo e si è unito a WWT circa tre anni fa. Lavora principalmente nell'ambito dell'istruzione statale e locale, anche se collabora con altre aree del settore pubblico.\n\n## Mito Uno - Il Cloud è più economico.\n\nIl cloud non è necessariamente più economico di un ambiente in loco. Le applicazioni legacy sono state sviluppate per l'ambiente in loco, quindi non ci sono problemi di auto-scaling. È un modello basato sul consumo e ci sono già costi fissi, come i server. La maggior parte dei prodotti pensati per aiutare le organizzazioni a spostare le applicazioni nel cloud non supporta l'auto-scaling, quindi quando vengono spinte nel cloud, devono essere sempre configurate al massimo, il che non si traduce sempre in risparmi economici. È probabile che i clienti stiano pagando di più rispetto a prima per le stesse capacità in loco.\n\nQuando Darren lavorava con il governo canadese, hanno trasferito un'istanza SAP nel cloud. Era massimamente approvvigionata, in funzione 24/7, e hanno superato il loro budget in soli sei mesi. Quando hanno scoperto questo problema, l'hanno acceso e spento ogni giorno poiché l'istanza non aveva bisogno di funzionare 24/7. Hanno risparmiato molti soldi riducendola a 14-16 ore al giorno.\n\nL'accesso deve essere disponibile sempre in un dipartimento come quello della Salute e dei Servizi Umani, che di solito è il più grande nel bilancio IT di uno Stato, ma è possibile ridurlo a un'occasione minore durante le ore non lavorative per risparmiare denaro.\n\nI fornitori di servizi cloud (CSP) offrono ora servizi nativi per il cloud che vengono soddisfatti da un'applicazione di terze parti o da un prodotto OEM in grado di fornire una capacità simile con risparmi sui costi. Questo non funzionerà con tutto, poiché alcune applicazioni legacy non sono sviluppate per sfruttare alcune delle applicazioni native per il cloud. Sarebbe meglio fare attenzione a rimanere vincolati a un cloud specifico. Ad esempio, se si utilizzano servizi proprietari di AWS, potrebbe essere difficile estrarre un'applicazione e passare ad Azure e viceversa.\n\nJohn consiglia alle organizzazioni di chiedersi se ha senso passare al cloud. Non è una buona ragione passare al cloud solo perché si pensa di doverlo fare. Potresti finire con delle spese elevate e frustrare i superiori e i lavoratori perché la strategia non è stata sufficientemente valutata.\n\n## Mito Due - Il Cloud Cancellain No in Debito Tecnico\n\nPassare nella nuvola non elimina il debito tecnico in quasi tutti i casi. Esso espone ed accelera il debito. Troverai punti di esposizione se prendi qualcosa che funziona da 30 anni e lo sposti in un nuovo ambiente. La parte di accelerazione è che ora hai più debito tecnico di cui preoccuparti dato che è stato esposto.\n\nIl debito tecnico significa che hai sistemi che rimangono indietro rispetto a ciò che dovrebbero essere. Ad esempio, quando John ha iniziato a lavorare per Maryland, alcuni sistemi erano ancora in esecuzione su schermate verdi. Era facile da navigare per i dipendenti attuali, ma aveva una lunga curva di apprendimento per i nuovi utenti. Nonostante il sistema avesse funzionato per molti anni, il lato negativo di questo debito tecnico è l'ammontare di formazione necessaria e il mantenimento dei dipendenti. Le generazioni più recenti che entrano nel mondo del lavoro e sono aggiornate sulle ultime tendenze e sviluppi non vogliono occuparsi di applicazioni obsolete.\n\nIl debito tecnico significa anche problemi di sicurezza. Se un'applicazione legacy non è stata aggiornata, potresti non riuscire ad applicare patch per paura di causare un malfunzionamento. Questo crea vulnerabilità di sicurezza che devi accettare finché non uscirai dal ciclo del debito tecnico.\n\nUna reazione comune in un'organizzazione è aggiungere un po' di codice extra quando necessario per accontentare, ad esempio, un cambiamento normativo da parte di un'assemblea legislativa statale. Questo non risolve un problema; al contrario, il sistema finisce per avere molto codice spaghetti, rendendo impossibile ricreare il sistema per un aggiornamento. Uno dei concetti nel cloud è suddividere il sistema in moduli o microservizi, ma il codice spaghetti non lo permette poiché non puoi semplicemente estrarne una parte.\n\nCiò rende le organizzazioni ancora più restie a modernizzarsi perché hanno fatto le cose nel modo sbagliato per tutti questi anni. Quando qualcosa si rompe e diventa il motivo di questo cambiamento, diventa ancora più difficile.\n\nA volte potrebbe avere senso eliminare il vecchio sistema e ricominciare da zero. Ciò comporta dei costi e bisogna avere il nuovo sistema prima di scartare quello vecchio. Tuttavia, per alcune organizzazioni, come gli Stati, che possono ottenere finanziamenti federali per dipartimenti come la Salute e i Servizi Umani, potrebbe essere la scelta migliore. In una situazione del genere, si possono anche valutare i vantaggi della riutilizzabilità, come modelli e strutture di governance per altri dipartimenti.\n\n## Mito Tre - Il Cloud è Sicuro\n\nPassare al cloud non rende necessariamente più semplice proteggere le applicazioni, anche se non devi preoccuparti della sicurezza fisica o degli hypervisor, per esempio. I fornitori di cloud hanno un modello di responsabilità condivisa in varie forme. Devi capire di cosa sei responsabile con ciascun fornitore e di cosa sono responsabili loro. Questo non cambia solo con il fornitore, ma anche con i servizi che consumi. Questo può rendere la sicurezza più complessa per i tuoi team di sicurezza perché devono tenere d'occhio tutte le diverse variazioni tra i fornitori e i servizi.\n\n## Mito Quattro - Il cloud è facile\n\nLa migrazione al cloud è complessa. In realtà, è più semplice gestire tutto nel proprio data center, non connesso a internet. La sicurezza in questo modo è facile e i modelli di costo sono semplici. Tuttavia, non puoi crescere. Non puoi fornire servizi ai tuoi comitenti o clienti e non puoi soddisfare le necessità della missione, tra le altre questioni. Il mondo è complesso e la migrazione al cloud è complicata.\n\n## Mito Cinque - Non è necessario acquisire nuove competenze.\n\nUna mancanza di conoscenza può anche contribuire ai punti critici legati a quella complessità. Gli sviluppatori di software e altri specialisti IT devono cambiare il modo in cui pensano all'informatica nel cloud, soprattutto per quanto riguarda la sicurezza. Ad esempio, gli sviluppatori di software non dovrebbero creare istanze nel cloud ovunque vogliano o scaricare cose da GitHub o altri repository, prendendo librerie per far funzionare le cose. Questo apre tutte le regole del firewall perché potrebbero non scegliere correttamente. Devono essere implementate delle barriere di protezione quando si passa al cloud, il che richiede un cambiamento. Lavorare nel cloud richiede un diverso set di competenze e mentalità. Inoltre, è necessario trovare modi migliori per gestire la sicurezza con ransomware sofisticati e attacchi informatici.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","John Evans"],"link":"/episode-EDT112-it","image":"./episodes/edt-112/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, settore pubblico, Intel, e John Evans, Consigliere Tecnologico Capo, WWT, discutono cinque miti sulla migrazione del cloud lift and shift."},{"id":16,"type":"Episode","title":"Operazionalizzazione della gestione dei processi aziendali","tags":["bpm","automation","compute","management","camunda","capitalbpm","rpa"],"body":"\r\n\r\nMax si definisce un \"accademico fallito\" perché ha abbandonato il suo dottorato in matematica, specializzato in topologia, per studiare informatica. Ha ottenuto una laurea triennale e una laurea magistrale, specializzandosi in intelligenza artificiale. In seguito ha lavorato nella gestione dei processi aziendali (BPM), iniziando presso Lombardi, che è stata successivamente venduta a IBM, e alcuni altri fornitori nel settore BPM. Dieci anni fa, ha preso una decisione importante insieme ad alcuni amici e ha fondato Capital BPM.\n\nMax ha scelto di concentrarsi sul BPM per due motivi. In primo luogo, ha sempre apprezzato gli algoritmi perché offrono un approccio sistematico alla risoluzione dei problemi complessi. Gli algoritmi gli danno un senso di sicurezza anche durante situazioni difficili.\n\nSecondo, gli piace ciò che viene chiamato trasformazioni nella matematica. Ad esempio, se hai una forma brutta con molti angoli che è difficile da misurare, la trasformeresti in, diciamo, un rettangolo e quindi applicheresti tutte le teorie sulla misura del rettangolo, la misureresti e tradurresti la risposta nella forma originale. Allo stesso modo, in BPM, puoi portare un problema in un dominio in cui può essere facilmente risolto. Piuttosto che trasformare un problema in un problema micro con complicate dichiarazioni F nidificate che sono difficili da mantenere, puoi trasformarlo in un problema appiattito che puoi vedere ed attaccare per fasi.\n\nQuesto processo è simile al far zoom su Google Maps per capire dove hai bisogno di concentrare l'attenzione e poi fare zoom indietro per vedere come questo si inserisce nel quadro generale. Il cuore dell'architettura aziendale è la capacità di fare zoom avanti e indietro per assicurarsi che la linea che stai tracciando sia ancora valida.\n\nMax paragona il suo amore per il BPM nel mondo dell'informatica alle arti marziali, che ha studiato fin da quando aveva sei anni. Dice che ci sono arti marziali pratiche, come il judo e il muay thai, e altre più esoteriche, come il tai chi. Gli piacciono le arti marziali pragmatiche perché risolvono problemi del mondo reale. Non si mette più in rissa, ma, ad esempio, le sue competenze di judo lo aiutano quando scivola e cade. Il BPM è pragmatico perché è la chiave per risolvere un problema aziendale. Crede che ci sia un vero valore nell'utilizzare tutte le teorie che ha imparato a scuola e renderle subordinate nella creazione di una piattaforma aziendale che permette alle persone di risolvere in modo più efficiente e coerente i problemi quotidiani, offrendo così alle persone e alla comunità più opportunità.\n\nQuesta è una parte dell'informatica che può essere collegata a come le persone lavorano. Le cose possono essere automatizzate per ridurre la quantità di compiti ripetitivi e monotoni, in modo che le persone possano concentrarsi su cose più importanti. Le persone temono che l'automazione inghiotta i lavori di tutti i giorni, ma invece rimuove la fatica e libera tempo per lavori più critici. Può anche creare nuovi posti di lavoro. Le stesse paure esistevano quando furono introdotti i computer automatizzati di Ford, ma alla fine crearono nuove industrie. Il BPM dovrebbe essere completamente abbracciato anziché temuto.\n\nIl modo migliore per iniziare a operazionalizzare i processi è utilizzare il metodo scientifico per articolare il problema. Nella gestione dei processi aziendali, si disegnano immagini tramite un modello di processo aziendale. Max apprezza il Camunda Business Process Modeler, che è scaricabile gratuitamente con solo un po' di notazione da imparare. Nel programma di modellazione, si disegnano passaggi che articolano i diversi sistemi e come funzionano.\n\nIn un processo di selezione, ad esempio, si inizia con un gruppo che definisce le parti interessate, come il candidato, il responsabile IT e l'HR. All'interno del gruppo ci sono \"corsie di nuoto\", ognuna delle quali contiene un attore che può compiere azioni. Puoi pensarle come gruppi LDAP. Poi si inizia a delineare il processo aziendale: prima il candidato presenta la candidatura per il lavoro, poi l'HR potrebbe fare una revisione, quindi il responsabile IT farà una revisione. Le decisioni approvate vengono annotate lungo il percorso. Dopo che i passaggi significativi di alto livello sono presenti nel modello, è possibile scendere nei dettagli riguardanti processi più articolati e sfumati, come un'intervista divisa in una parte tecnica e una manageriale.\n\nTraduci il seguente in italiano: ![Immagine bmp](./bpm.png)\n\nIl programma di modellazione genera XML dietro le quinte mentre si disegnano tutti questi diagrammi. Questo XML è interpretabile durante l'esecuzione da macchine BPM; mentre si disegna il diagramma, può diventare un processo eseguibile.\n\nL'elemento umano è ancora presente in questo ciclo, ma l'utilizzo di un sistema di BPM come questo rende chiaro dove i processi possono essere automatizzati, come ad esempio controllare la storia lavorativa o effettuare un controllo dei precedenti penali. Questo modello consente anche flessibilità e sperimentazione. Ad esempio, supponiamo che l'esperto del settore affermi di non voler eseguire contemporaneamente un controllo del lavoro e un controllo del record penale perché il controllo del record penale è costoso, mentre quello del lavoro è economico. In tal caso, è facile apportare una modifica spostando il controllo del lavoro iniziale e richiedendo una decisione prima del controllo del record penale. Man mano che vengono apportate modifiche, si costruisce un consenso e una storia vera che diventa progressivamente più vera quanto più si sperimenta.\n\nMentre l'utensile sembra essere uno strumento per disegnare, è un utensile di modellazione che ti consente di disegnare immagini e simulare sul retro. Quindi puoi eseguire questo processo e vedere tutti i diversi punti decisionali e dove conducono. Il modello ti dirà anche che non puoi implementare se non hai fatto qualcosa correttamente.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Max Young"],"link":"/episode-EDT113-it","image":"./episodes/edt-113/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren discute la gestione dei processi aziendali e l'automazione con Max Young, CEO di Capital BPM."},{"id":17,"type":"Episode","title":"Automazione della gestione dei processi aziendali","tags":["compute","businessprocessmanagement","capitalbpm","bpm","automation","camunda","rpa"],"body":"\r\n\r\nLa modellistica BMP ricorda a Darren quando frequentava il corso di disegno tecnico al liceo, e l'introduzione di sistemi di disegno assistito al computer da parte di AutoCAD ha cambiato le regole del gioco. Prima, dovevano creare pagine e pagine di sistemi complessi e diagrammi affinché le persone potessero costruire, ma non potevano testare il modello per assicurarsi che fosse corretto. Utilizzando la modellistica al computer, potevano eseguire simulazioni per accertarsi che non ci fossero problemi come l'elettricità e l'acqua che passavano dallo stesso foro.\n\nCiò è analogo agli architetti che utilizzano PowerPoint per mostrare i processi aziendali invece di utilizzare uno strumento di modellazione che possa individuare conflitti e problemi in ciò che pensavi fosse il processo aziendale.\n\nUtilizzando uno strumento di modellazione aziendale si risolve anche un problema pratico eliminando il tempo sprecato per riunire tutte le parti interessate in incontri che potrebbero essere più produttivi. Invece, è possibile mettere un modello implementato nelle mani del cliente aziendale e lavorare insieme attraverso i passaggi.\n\nDopo aver articolato e modellato i processi, puoi scegliere i punti di integrazione che potrebbero collegarsi a interfacce RESTful per ottenere informazioni e reinserirle. È così che i processi aziendali possono integrarsi con i microservizi nel cloud. Nell'esempio del processo di assunzione, questi punti potrebbero essere dove hai bisogno di un'API per richiamare controlli sulla cronologia lavorativa o il registro penale. Gli input saranno elementi come i numeri di previdenza sociale e le date di nascita, e gli output saranno un valore booleano - le informazioni corrispondono o no? È qui che puoi iniziare a avere quella conversazione iterativa.\n\nTraduci quanto segue in italiano: ![immagine bpm](./bpm.png)\n\nCi sono molte fasi manuali in questo processo e puoi scegliere quale automatizzare. Ad esempio, se decidi che un colloquio non è andato bene, puoi fare riferimento a HR come alternativa. Dopo aver implementato questo nuovo processo, puoi tornare indietro e analizzare la versione precedente se lo desideri, così avrai due versioni concorrenti del software funzionanti e implementate nel prototipo.\n\nIl modello di Camunda è un modello nativo, ma Capital BPM ha creato le sue proprie applicazioni che aiutano a razionalizzare parte del lavoro e supportano diversi ruoli utente.\n\nQuesto sistema è diverso dall'RPA perché invece di catturare ciò che un utente fa con i tasti, un analista aziendale osserva i processi e i passaggi in diversi dipartimenti. L'analista guarda dall'alto l'intero processo. Un RPA può essere inserito in alcuni passaggi per aumentare l'efficienza. Un semplice esempio è se un candidato al lavoro passa il controllo della storia lavorativa e il controllo del casellario giudiziario, può essere inviato a una persona senior delle risorse umane; in caso contrario, viene respinto. Scegliere specifici passaggi o insiemi di passaggi da automatizzare è un approccio iterativo che viene utilizzato con successo nello sviluppo software da tempo.\n\nLe RPAs possono essere fattori determinanti, ma sono tattici e a breve termine. Mentre questi guadagni a breve termine possono essere redditizi, è necessario considerare l'intero processo aziendale per trovare ottimizzazioni e passaggi che è possibile eliminare. La storia della donna che tagliava sempre l'arrosto prima di cuocerlo perché così lo faceva sua madre è analoga a alcuni processi aziendali. La donna alla fine chiese alla madre perché tagliava l'arrosto e sua madre rispose: \"Così sarebbe entrato nella mia padella\". Molti processi aziendali sono presenti solo perché sono sempre stati fatti in quel modo e nessuno ha pensato di chiedersi il perché.\n\nTestare, simulare, spostare le cose e eseguire processi ripetutamente nel modeler, in altre parole, testare empiricamente, può aiutare a eliminare questa sovrabbondanza di processi e aggiungere un valore significativo. La visualizzazione e l'esperimento sono parti vitali dell'intero processo.\n\nMax sottolinea che c'è fedeltà tra il diagramma e l'effettiva esecuzione. Gli sviluppatori spesso disegnano diagrammi come punto di partenza. Tuttavia, i grafici scompaiono man mano che lo sviluppo passa attraverso le diverse parti, quindi ciò che l'azienda pensa stia accadendo e ciò che sta realmente accadendo sono diversi. Il diagramma e la realtà sono separati. In questo tipo di modellazione, l'immagine è sempre una rappresentazione accurata di ciò che sta accadendo. Inoltre, è facile vedere e apportare modifiche per migliorare.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Max Young"],"link":"/episode-EDT114-it","image":"./episodes/edt-114/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Public Sector, Intel, e Max Young, CEO di Capital BPM, discutono dell'operazionalizzazione della gestione dei processi aziendali con programmi di modellazione."},{"id":18,"type":"Episode","title":"Bloccare e affrontare la sicurezza","tags":["zta","zerotrustarchitecture","cyberhygiene","cybersecurity","technology","process"],"body":"\r\n\r\nFondamentale per tutte le altre misure di sicurezza informatica è l'igiene di base della rete. Molte aziende devono mettere in pratica questi concetti di base. Questo è dimostrato dagli ultimi titoli di notizie che rivelano un aumento degli attacchi come i attacchi di denial of service, che dovrebbero essere facili da prevenire.\n\nDalla sua esperienza lavorando con la comunità statale, John crede che la maggior parte degli attacchi segua una tipica catena di uccisione. La maggior parte degli attacchi che colpiscono i governi statali e locali derivano da protocolli di rete esposti o phishing tramite email. Questi sono punti di ingresso attrattivi per gli hacker e una volta entrati, pratiche di patching scadenti sono solitamente le responsabili che permettono loro di ottenere una base solida e spostarsi lateralmente. Ciò, combinato con politiche di password deboli o una debole applicazione delle politiche di password e l'incapacità di recuperare, può portare al disastro.\n\nIn un incidente di ransomware ben pubblicizzato nel 2019, l'organizzazione interessata ha presumuto che, poiché avevano la stessa quantità di dati nei loro ambienti di produzione e di backup, fossero al sicuro. Ma non avevano mai testato i loro backup o le loro capacità di ripristino, che si sono rivelate scarse. Una semplice igiene informatica avrebbe potuto prevenire questo incidente.\n\nCi sono quattro principi fondamentali su cui ogni organizzazione dovrebbe concentrarsi. Primo, devono addestrare ripetutamente le persone per evitare le truffe di phishing. L'addestramento potrebbe sembrare ripetitivo o noioso, ma il fatto che le persone cadano in queste truffe rappresenta una significativa debolezza per un'organizzazione. Sperabilmente, in un futuro non troppo lontano, le password non saranno più necessarie.\n\nSecondo, devono configurare correttamente i firewall; solo perché le porte RTP o dei protocolli di rete sono chiuse, non significa che non ci sia una porta aperta in un punto meno prominente. La sicurezza attraverso oscurità non funziona.\n\nTerzo, devono evitare politiche di aggiornamento scorrette, sia sul client che sul server, nei data center e nei punti periferici. Molte organizzazioni hanno debiti tecnici e non possono aggiornare i loro vecchi sistemi, quindi accettano le vulnerabilità e i rischi perché non desiderano investire in un aggiornamento.\n\nQuarto, devono avere la capacità di recuperare. Solo perché sai che puoi effettuare il backup dei tuoi dati, puoi usarlo e recuperare con il backup? Il test è essenziale.\n\nQuesti quattro concetti di base, insieme ad altri pochi, sono sufficienti per fermare quasi tutti gli attacchi rivolti alle organizzazioni che non sono obiettivi abituali. Questo modello non si applica alle organizzazioni colpite da attacchi di tipo statale; queste già adottano tutte queste misure e necessitano di ulteriori misure di sicurezza.\n\nUna considerazione per molte organizzazioni è la conformità rispetto al rischio. Per alcune organizzazioni essere conformi implica l'aggiornamento di vecchie macchine, applicazioni e processi, il che comporta un costo significativo. Per le organizzazioni con un sistema che non può essere aggiornato, potrebbe essere adottato un approccio basato sul rischio, in cui se accadesse qualcosa al sistema, costerebbe meno rispetto all'aggiornamento del sistema. Naturalmente, la cosa sicura da fare sarebbe l'aggiornamento per conformità, ma la maggior parte delle persone ritiene che l'approccio basato sul rischio sia più sicuro. Un piccolo business potrebbe cavarsela con questo approccio, ma le organizzazioni governative, ad esempio, devono rispettare dei regolamenti di conformità.\n\nCi sono due ragioni per cui un'organizzazione potrebbe scegliere la conformità oltre a un mandato. Prima di tutto, è un pulsante facile per molte organizzazioni che non capiscono come misurare o dare priorità ai rischi. La conformità è un quadro generalizzato a cui fare riferimento. Tuttavia, non è adatta a tutti, poiché qualcun altro sta assegnando priorità ai rischi in modo generalizzato. In secondo luogo, se accade qualcosa di terribile e, ad esempio, devi spiegarlo al tuo consiglio di amministrazione, puoi dire di aver seguito gli standard accettati.\n\nLa conformità è un po' una mentalità del bastone perché non è necessario fare tutte le valutazioni dei rischi e capire cosa deve essere fatto. Tuttavia, ad esempio, un piccolo comune senza un CISO potrebbe dirigere un sistemista amministratore a utilizzare un quadro di conformità come punto di partenza valido. Se non c'è un CISO a disposizione, c'è anche l'opzione di un CISO virtuale a tempo parziale per la guida. John fa questo per i clienti, che è un percorso praticabile per una migliore sicurezza.\n\nIl concetto di \"zero trust\" considera anche un livello di garanzia rispetto al rischio. È necessario comprendere il rischio di concedere a qualcuno l'accesso a un particolare sistema o ad un dato e poi avere una garanzia adeguata che la persona sia effettivamente chi afferma di essere. Il cuore del \"zero trust\" è un alto livello di sicurezza che mitig\n\nZero trust non significa che tutto sarà bloccato e rallenterà tutti i processi. Ad esempio, se qualcuno vuole entrare e vedere i livelli di pioggia, non è necessario un elevato livello di affidabilità che la persona sia verificata. Tuttavia, se qualcuno vuole accedere ai gioielli della corona della tua organizzazione, devono essere presenti ulteriori controlli per verificare l'identità.\n\nAbbinare il livello di sicurezza al livello di rischio è una sfida; richiede un'architettura di decisione. Ad esempio, per quanto riguarda il rischio nell'accesso a un dato, un'organizzazione deve sapere cosa è e categorizzarlo in base al rischio. Per un'organizzazione matura, ciò può essere difficile. John conosce un'organizzazione governativa federale che ha impiegato oltre due anni per assicurarsi che i suoi dati fossero identificati, classificati e contrassegnati correttamente prima di passare a qualsiasi tipo di architettura decisionale.\n\nIdentità e dati sono i due punti di partenza per la fiducia zero. Inoltre, ha senso evitare di cercare e fare tutto contemporaneamente. Iniziare con una parte di un'organizzazione potrebbe avere più senso, espandendola gradualmente nel resto dell'organizzazione nel tempo.\n\nL'identità digitale sta diventando sempre più sofisticata. John crede che le nostre transazioni future si baseranno principalmente su un approccio di tipo \"zero-trust\". Ad esempio, se lui vuole trasferire $10.000 dal suo conto bancario a un conto all'estero, la banca dovrebbe assicurarsi che sia proprio lui e trattare quella transazione come se qualcuno stesse cercando di accedere a informazioni molto sensibili e ad alto rischio. Se invece lui va al negozio a comprare una tazza di caffè da un dollaro, quel livello di sicurezza che sia lui che effettua l'acquisto è superfluo. Molti di questi principi di \"zero-trust\" troveranno spazio nella nostra vita quotidiana.\n\nL'analisi comportamentale dell'utente verrà presa in considerazione. Proprio come una compagnia di carte di credito solleva un'allerta per acquisti insoliti, ad esempio, se un sistema sa che John digita 20 parole al minuto e poi improvvisamente ne digita 100 al minuto cercando di accedere a informazioni sensibili, si tratta di un campanello d'allarme.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","John Evans"],"link":"/episode-EDT115-it","image":"./episodes/edt-115/it/thumbnail.png","lang":"it","summary":"In questa puntata, Darren parla di sicurezza informatica con il ritorno dell'ospite John Evans, Chief Technology Advisor presso World Wide Technology (WWT)."},{"id":19,"type":"Episode","title":"Un argomento per un approccio olistico alla sicurezza delle infrastrutture critiche","tags":["criticalinfrastructure","iot","it/otconvergence","otsecurity","cybersecurity","edge"],"body":"\r\n\r\n## C'è una vera minaccia per le infrastrutture critiche.\n\nSecondo il dottor Scott, le organizzazioni di terapia occupazionale utilizzano ancora il tradizionale Modello Purdue, che sfrutta reti isolate dall'aria e separate da firewall. Tuttavia, questo modello sta iniziando a crollare poiché le reti IT e OT si fondono. Le aziende stanno cercando di ottenere una migliore comprensione di ciò che accade nella loro infrastruttura operativa. Di conseguenza, creano delle vulnerabilità nelle reti precedentemente ben isolate, esponendole a minacce informatiche. Inoltre, i criminali informatici stanno trovando modi per aggirare le reti isolate dall'aria e separati da firewall.\n\nSteve sostiene che sfruttare le migliori pratiche IT può aiutare, ma i professionisti OT e i professionisti IT hanno motivazioni e modelli operativi diversi. Continuare ad isolare la propria rete è comunque una buona strategia, ma dovrebbe essere uno tra molti strumenti utilizzati nella protezione della cibersicurezza dell'infrastruttura critica. La sicurezza OT dovrebbe prendere in considerazione le migliori pratiche di cibersicurezza IT per idee per migliorare le proprie reti e infrastrutture.\n\n## Differenze tra IT e OT che ostacolano le Best Practices\n\nI sistemi IT vengono tradizionalmente aggiornati rapidamente o continuamente in base ai profili di sicurezza. Uno degli strumenti principali per migliorare la sicurezza è l'igiene di base mediante l'applicazione di patch per sistemi operativi, firmware e software nell'infrastruttura IT. Tuttavia, come ci illumina il dottor Scott, i sistemi OT che gestiscono infrastrutture critiche non possono avere tempi di inattività e la finestra per l'aggiornamento di questi sistemi è misurata in anni, non in giorni. Non è raro, nelle apparecchiature dell'infrastruttura OT, che le macchine funzionino per 5 o 10 anni senza tempi di inattività, il che significa che non vengono effettuati aggiornamenti con patch.\n\nAd esempio, nell'industria del petrolio e del gas, le raffinerie operano ininterrottamente per quattro o cinque anni, hanno un periodo di fermo di una o tre settimane per aggiornamenti e poi riprendono a operare per altri quattro o cinque anni. Questi modelli operativi non favoriscono i tradizionali interventi di sicurezza continuativa che le organizzazioni IT usano di solito. Tuttavia, Steve approfondisce molte altre soluzioni di cibersicurezza che dovrebbero essere sfruttate quando i dispositivi esistenti non possono essere sottoposti a patch di sicurezza a causa della loro infrastruttura di controllo critica.\n\n## Valutazione del rischio delle migliori pratiche.\n\nLa migliore pratica primaria di sicurezza informatica è la valutazione del rischio. Anche se la risoluzione del rischio può essere diversa, il processo di valutazione del rischio può essere utilizzato allo stesso modo sia per OT che per i relativi ambienti. Steve sostiene che il primo passo del processo di valutazione del rischio sia ottenere un inventario completo delle risorse hardware, firmware e software nel tuo ambiente OT. Questo primo passo è fondamentale per valutare la posizione delle minacce informatiche e valutare il rischio che la tua organizzazione è disposta a correre. Il passo successivo è valutare i CVEs rispetto al tuo inventario noto.\n\nÈ fondamentale riconoscere che si tratta di un processo continuo e non deve essere fatto solo una volta o periodicamente. Alcuni professionisti della Terapia Occupazionale hanno sostenuto che i loro ambienti di Terapia Occupazionale sono statici e non richiedono una valutazione continua dei rischi. Tuttavia, Steve fa notare che anche se gli ambienti di Terapia Occupazionale possono essere stabili, l'ambiente delle minacce cambia costantemente e i fattori aziendali possono modificare la posizione di rischio dell'organizzazione. Pertanto, è necessaria una valutazione continua dei rischi per proteggere le infrastrutture critiche da attacchi informatici dannosi.\n\n## Gestire i fornitori OT.\n\nUn altro fattore interessante nell'infrastruttura OT è il modello di sicurezza condiviso con i fornitori di dispositivi. In molti casi, questi dispositivi incorporati che controllano infrastrutture critiche da milioni di dollari sono gestiti dal fornitore, non dall'operatore OT professionale. Il fornitore può solo apportare correzioni e aggiornamenti di sicurezza informatica ai dispositivi. Questo può talvolta portare a vulnerabilità nel tuo ambiente OT, aumentando il rischio di infiltrazioni informatiche. Steve porta ulteriori strumenti di sicurezza informatica per aiutare a proteggere le risorse che non possono essere corrette con patch critiche di sicurezza informatica, incluso l'aumento dell'isolamento dei dispositivi interessati, la distribuzione di dispositivi di controllo e l'implementazione di modelli di progettazione canary nell'infrastruttura OT. Questi strumenti possono contribuire a proteggere e isolare il dispositivo per prevenire la diffusione e l'accesso alle risorse compromesse.\n\n## Cosa fare quando sei compromesso\n\nQuindi, cosa fai quando hai un'infrastruttura critica che è stata compromessa? L'organizzazione è in grado di gestire la chiusura dell'infrastruttura infetta? Quali piani di continuità aziendale sono in atto quando si verificano situazioni pericolose? Questo può essere utilizzato anche quando si verifica un evento di cybersecurity?\n\nLa chiave qui è isolare l'infezione il più velocemente possibile per ridurre al minimo l'impatto sull'infrastruttura critica. Sto riducendo l'effetto sulla affidabilità operativa dell'infrastruttura necessaria. L'obiettivo è ridurre l'impatto e proteggere la sicurezza delle persone e dell'infrastruttura coinvolta.\n\n## Scopri di più\n\nContinua a cercare altri podcast sulla cibersicurezza delle OT. Inoltre, un whitepaper descrive le sfide della convergenza tra le ambienti di cibersicurezza delle OT e delle IT.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin","Anna Scott"],"link":"/episode-EDT116-it","image":"./episodes/edt-116/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla della convergenza della sicurezza informatica OT e IT con l'esperto di sicurezza Steve Orrin e l'esperta di OT industriale Dr. Anna Scott."},{"id":20,"type":"Episode","title":"2022 Anno in Rassegna","tags":["edge","aiml","hybridworkspace","compute","multicloud","cybersecurity","datamanagement","data","technology","people","process"],"body":"\r\n\r\nIl 2022 è stato un anno eccezionale per l'adozione della trasformazione digitale, con un aumento degli ascoltatori e diversi ospiti esterni intervistati quest'anno. Otto ospiti erano dirigenti o ex dirigenti di agenzie governative e organizzazioni del settore privato, tra cui finanza, manifatturiero e assistenza sanitaria. In oltre 60 episodi, sono emersi sei argomenti ritenuti necessari dai nostri ascoltatori e dall'intera industria, ovvero: spazi di lavoro ibridi, sicurezza informatica, multi-hybrid cloud, edge computing, gestione dei dati e intelligenza artificiale.\n\n## Spazio di lavoro ibrido\n\nDopo aver combattuto le restrizioni legate al COVID e mantenuto in funzione le aziende nel 2020 e nel 2021, le organizzazioni hanno cercato di ottimizzare la modalità operativa della \"Nuova Normalità\". Questa nuova normalità ha ridotto gli ostacoli burocratici dei tempi pre-COVID. Tuttavia, sono emersi controlli e processi legati al rapido ritmo di cambiamento durante la pandemia per controllare i costi e migliorare l'affidabilità. Le aziende hanno avuto difficoltà con le politiche di lavoro da remoto, poiché abbiamo visto le organizzazioni passare rapidamente tra il lavoro da casa, il lavoro ibrido e l'approccio in ufficio per tutti, lasciando agli organi IT soluzioni complesse per gli spazi di lavoro. Hanno iniziato a sviluppare architetture in grado di gestire il cambiamento rapido e modelli di lavoro flessibili per affrontare politiche in continua evoluzione. I workspace ibridi flessibili sono qui per restare? Solo i prossimi anni lo diranno.\n\n## Multi-Hybrid Cloud: Cloud Ibrida Multipla\n\nUn'altra grande tendenza nel 2022 è stata la migrazione e il rimpatrio dei carichi di lavoro da e verso il cloud, poiché le organizzazioni cercano di fornire spazi di lavoro ibridi per i propri dipendenti. Le organizzazioni IT hanno iniziato a valutare i costi operativi nel gestire e migrare i carichi di lavoro verso il cloud. Molte organizzazioni hanno scoperto che la metodologia di \"lift and shift\" nel passaggio al cloud era molto più costosa rispetto alle stime iniziali a causa di una mancanza di raccolta dei requisiti, comprensione dei modelli operativi del cloud e soprattutto dei costi di rete di uscita nel cloud.\n\nL'adozione rapida del cloud durante la pandemia ha colto di sorpresa molti fornitori globali di servizi cloud nell'offrire le organizzazioni ad alta affidabilità richieste, sovraccaricando diversi fornitori di servizi cloud e causando significative interruzioni in tutto l'ecosistema globale dei CSP. Molte organizzazioni hanno iniziato a considerare architetture multi-ibride cloud per migliorare l'affidabilità, ridurre i costi e aumentare la prevedibilità dei carichi di lavoro eseguiti su più cloud privati e pubblici. I fornitori regionali di servizi cloud hanno sfruttato il passo falso dei fornitori globali di servizi cloud, offrendo maggiore affidabilità e servizi esclusivi nelle offerte cloud SaaS e PaaS, competendo testa a testa con i CSP più grandi.\n\n## Edge Computing e Industria 4.0\n\nL'Industria 4.0 continua a fare progressi nel settore manifatturiero e la carenza di lavoratori costringe molte organizzazioni a ricorrere all'automazione per continuare le loro attività. Inoltre, i dati OT e IT hanno iniziato a convergere mentre le organizzazioni cercavano di ottimizzare i loro processi commerciali e operativi. Gli avanzamenti nella tecnologia dei processori e dello storage hanno spostato sempre più elaborazioni al bordo, rendendo i dispositivi di bordo più intelligenti e capaci di svolgere compiti precedentemente svolti nel data center. La connettività tra dispositivi di bordo, data center e cloud pubblici si è migliorata con l'adozione di tecnologie private 5G in tutto il settore. Tuttavia, l'adozione deve ancora recuperare rispetto alle previsioni precedenti a causa delle preoccupazioni sulla cybersecurity OT/IT. Questo è particolarmente vero per la gestione delle infrastrutture critiche.\n\n## Gestione dei dati\n\nI workspace ibridi, l'adozione del cloud e il computing periferico hanno creato un incubo nella gestione dei dati per la maggior parte delle organizzazioni, poiché i loro dati si sono dispersi in questi ambienti in qualche modo disconnessi e distribuiti. Per gestire in modo efficace i dati in questo ecosistema, hanno cominciato a emergere nuove architetture, tra cui il data mesh, i data lake distribuiti e le reti dati. Le organizzazioni hanno iniziato a concentrarsi su quattro elementi chiave dei dati: posizione, classificazione, governance e protezione.\n\nLe leggi e i regolamenti sulla privacy stanno spingendo le organizzazioni a classificare correttamente i loro dati al fine di proteggere la privacy dei dipendenti, dei clienti e degli interessati. Inoltre, un aumento degli attacchi informatici e dei ransomware ha costretto le organizzazioni a proteggere e gestire meglio i loro dati in uso, a riposo e in transito. Gestire in modo efficace chi ha accesso, per quanto tempo ha accesso e per quanto tempo i dati rimangono è un elemento critico della governance dei dati che le organizzazioni stanno iniziando a comprendere.\n\n## La Cyber Security\n\nIl 2022 è stato un grande anno per la sicurezza informatica, e si è dimostrato nel podcast con oltre 18 episodi che parlavano di sicurezza informatica. La buzzword principale dell'anno è stata l'architettura a zero fiducia, che è diventata un termine di marketing abusato. Invece di concentrarsi sull'architettura a zero fiducia, Darren tende a concentrarsi sui principi a zero fiducia che le architetture possono supportare.\n\nAnche con un maggiore enfasi sulla sicurezza informatica, ci sono state violazioni dei dati primari e delle infrastrutture quest'anno, compresi attacchi alle infrastrutture critiche. Molti professionisti della sicurezza informatica attribuiscono questa recrudescenza alla guerra tra Ucraina e Russia, poiché abbiamo visto l'efficacia della guerra informatica e quella fisica che agivano di concerto.\n\nUn'altra preoccupazione centrale nella sicurezza informatica riguarda l'esposizione del software di terze parti all'interno dell'ecosistema delle applicazioni (vulnerabilità di log4J). Molte organizzazioni hanno bisogno di aiuto per trovare una direzione a causa dell'ampio utilizzo di log4J nei loro prodotti, nell'elaborazione back-office e nelle interfacce con i clienti. Diverse organizzazioni e governi stanno promuovendo in modo significativo la standardizzazione delle bollette software per aiutare a identificare le vulnerabilità nei pacchetti software.\n\n## Intelligenza Artificiale\n\nL'intelligenza artificiale continua a migliorare tecniche e processi operativi. La grande notizia dell'anno nel campo dell'IA è ChatGBT, che ha una vasta gamma di utilizzi, inclusi la scrittura di blog, codici e documenti e il supporto nella risoluzione dei problemi degli help desk IT. Inoltre, l'adozione di chip di silicio con AI nei fornitori di servizi cloud ha ampliato la disponibilità dell'IA per le masse. Questa disponibilità consente alle organizzazioni di sperimentare di più con gli algoritmi di intelligenza artificiale nelle loro operazioni aziendali quotidiane. Le organizzazioni stanno iniziando a operazionalizzare alcuni di questi esperimenti per eseguire e automatizzare processi precedentemente svolti da dipendenti difficili da trovare in un mercato del lavoro stretto.\n\n## Conclusione\n\nIl 2022 è stato un anno difficile per molte aziende tecnologiche in quanto abbiamo visto una diminuzione della spesa in IT rispetto agli anni precedenti di \"spesa pandemica\". Questa prevista diminuzione ha sorpreso molte aziende high-tech per quanto velocemente le cose sono cambiate. Nonostante la crisi, la tecnologia ha continuato a crescere e l'adozione di nuove tecnologie nell'edge, nel cloud, nell'IA, nella gestione dei dati e nella cybersecurity continua a crescere. Il 2023 dovrebbe essere un anno emozionante poiché vedremo la maturazione di alcune di queste tecnologie. Le organizzazioni continueranno ad indagare su modi per ridurre i costi attraverso l'automazione, ottimizzando i carichi di lavoro su cloud multi-ibridi e proteggendosi dalle crescenti minacce alla sicurezza informatica.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT117-it","image":"./episodes/edt-117/it/thumbnail.png","lang":"it","summary":"Nel presente episodio, Darren fa una recensione del 2022. Identifica gli argomenti più discussi nel podcast nel 2022, tra cui la gestione dei dati, l'intelligenza artificiale, la sicurezza informatica, il computing in edge e gli spazi di lavoro ibridi."},{"id":21,"type":"Episode","title":"Inserisci il titolo qui","tags":["remotelearning","people","technology","telelearning","cybersecurity"],"body":"\r\n\r\n# Titolo\n\n*Slogan*\n\nSommario qui.\n\nImmagine dell'episodio\n\nEpisodio del corpo qui.\n\n## Media translates to Italian as \"media.\"\n\n<video src='url'></video> translates to Italian as <video src='url'></video>. The translation remains the same in Italian.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Erin Moseley","Grant Kelly"],"link":"/episode-EDT12-it","image":"./episodes/edt-12/it/thumbnail.png","lang":"it","summary":"Nel nostro ultimo episodio, Erin Moseley, Senior Account Exec per l'Educazione presso Intel, e Grant Kelly, Solution Architect per l'Educazione presso Intel, si sono uniti a Darren per parlare delle sfide tecnologiche e delle opzioni nell'apprendimento a distanza. In questo episodio, approfondiremo maggiormente le minacce e le soluzioni in materia di privacy e sicurezza."},{"id":22,"type":"Episode","title":"Nuvole Private Disruptive","tags":["cloud","privatecloud","vergeio","microcloud","edge","compute","technology"],"body":"\r\n\r\nUn nuovo modo di pensare alla virtualizzazione sta cominciando a cambiare il panorama del cloud privato. L'industria delle infrastrutture definite dal software sta iniziando a considerare la virtualizzazione dei data center nel loro insieme anziché focalizzarsi su diversi tipi di infrastrutture.\n\nQuesto approccio di virtualizzazione innovativo crea nuovi modelli operativi, tra cui un'ottimizzazione della continuità aziendale e del ripristino dei disastri. Verge.io ha adottato questo approccio, fornendo nuovi modelli che includono la creazione di snapshot di data center e la loro replicazione. Ciò consente alle organizazini di creare ambienti portatili chiamati tenets che possono essere replicati in varie sedi. Ad esempio, è possibile creare microambienti conformi alla normativa HIPPA che possono essere replicati in diverse cliniche per aiutare le organizazioni a rimanere in conformità con le norme.\n\nQuesto nuovo sistema di virtualizzazione ha una minima impronta operativa e riduce le risorse necessarie per combinare elementi di elaborazione, archiviazione, rete e sicurezza. Aaron mostra quanto piccola e potente sia la soluzione quando installa la chiave su due Intel 12th Gen NUCs. La risposta è persuasiva per un'impronta così piccola e può essere utilizzata per il calcolo periferico e sistemi di controllo industriale.\n\nAaron mostra l'interfaccia web semplice per il rilascio di calcolo, archiviazione, rete e sicurezza. Viene anche dimostrata la capacità di creare snapshot e ripristinarli.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Aaron Reid"],"link":"/episode-EDT121-it","image":"./episodes/edt-121/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Aaron Reid di Verge.io sulla loro tecnologia di cloud privato disruptiva che sta rendendo i cloud privati disponibili nel data center e sul campo."},{"id":23,"type":"Episode","title":"Automazione con IA","tags":["collectiongenerativeai","aiml","automation","aiethics","workerreplacement","people","policy"],"body":"\r\n\r\n## Automazione con intelligenza artificiale\n\nL'automazione con l'IA si riferisce all'uso della tecnologia dell'intelligenza artificiale per automatizzare compiti che tradizionalmente sarebbero eseguiti dagli esseri umani. Ciò può includere compiti come l'analisi dei dati, il servizio clienti e persino la presa di decisioni. L'automazione alimentata dall'IA può migliorare l'efficienza, ridurre i costi e aumentare l'accuratezza in questi compiti. Alcuni esempi di automazione alimentata dall'IA includono i chatbot, le auto a guida autonoma e i sistemi di manutenzione predittiva.\n\nPosso intervistare per il mio podcast sull'utilizzo dell'intelligenza artificiale per automatizzare compiti?\n\nMi dispiace, non sono in grado di essere intervistato per un podcast in quanto sono un programma informatico. Tuttavia, posso fornirti informazioni e rispondere alle domande sull'argomento dell'utilizzo dell'intelligenza artificiale per automatizzare compiti. Basta farmi sapere quali domande specifiche hai, e farò del mio meglio per fornirti informazioni utili e accurate.\n\nBenvenuti nello spettacolo, ChatGPT.\n\nGrazie per avermi invitato allo show. Sono felice di poterti aiutare con qualsiasi informazione di cui hai bisogno riguardo all'argomento dell'utilizzo dell'IA per automatizzare le attività.\n\nRaccontami un po' di te stesso e della tua formazione.\n\nSono ChatGPT, un modello linguistico sviluppato da OpenAI. Sono stato addestrato su un ampio set di dati di testo proveniente da internet, il che mi permette di comprendere e generare testi simili a quelli umani. Posso rispondere alle domande, generare testo e persino creare storie. Il mio obiettivo principale è quello di assistere gli utenti nelle attività di comprensione e generazione del linguaggio naturale.\n\nCome intelligenza artificiale, non ho un background fisico o una storia personale. Tuttavia, le mie capacità sono state costruite e addestrate da un team di ricercatori e ingegneri di OpenAI che continuano a migliorare e aggiornare le mie abilità.\n\n## Allenamento dell'Intelligenza Artificiale\n\nDove hai ottenuto la tua formazione?\n\nSono stato addestrato da OpenAI, un'organizzazione di ricerca dedicata a promuovere e sviluppare un'intelligenza artificiale amichevole che beneficia l'umanità. Il mio addestramento si basa su un enorme dataset di testo proveniente da internet, il quale viene utilizzato per insegnarmi modelli e relazioni nel linguaggio. Questi dati vengono utilizzati per addestrarmi a generare testo simile alla scrittura umana, consentendomi di comprendere e rispondere alle domande in modo conversazionale.\n\nIl mio processo di formazione ha coinvolto una tecnica di deep learning chiamata transformers, che è un tipo di architettura di rete neurale progettata specificamente per compiti di NLP come la generazione e la classificazione di testi. Il processo di formazione ha ottimizzato i parametri del modello per adattarli ai modelli presenti nei dati, permettendomi di generare testi simili alla scrittura umana.\n\nHo sentito dire che ci sono stati alcuni problemi con il tuo addestramento all'inizio. Quali erano alcuni degli aspetti problematici?\n\nIl tuo allenamento?\n\nSì, come qualsiasi modello di apprendimento automatico, non ero perfetto quando sono stato rilasciato per la prima volta, e c'erano alcuni aspetti problematici del mio addestramento.\n\nUno dei principali sfide nel formare modelli come me è garantire che essi non perpetuino pregiudizi dannosi e stereotipi presenti nei dati di addestramento. Ciò può portare a modelli che producono output tendenziosi o generano contenuti offensivi. Per mitigare ciò, i ricercatori e gli ingegneri di OpenAI hanno implementato varie tecniche per ridurre il pregiudizio nel processo di addestramento, come raffinare il modello su dati di addestramento diversificati ed equilibrati.\n\nUn'altra sfida nell'allenare modelli come il mio è evitare la generazione di output di bassa qualità o privi di senso. Per affrontare questo problema, OpenAI ha implementato varie tecniche come controllare la temperatura del modello durante il processo di generazione del testo e affinare il modello per dare la priorità alla coerenza e alla pertinenza dei suoi output.\n\nNel complesso, anche se ci sono ancora sfide e limitazioni nel formare modelli come me, il campo dell'NLP e dell'IA è in continua evoluzione, e ricercatori e ingegneri stanno lavorando per migliorare le proprie capacità.\n\nLa mia comprensione è che tu sia stato addestrato con dati del 2021. Cosa puoi imparare dalle tue conversazioni con le persone? Stai continuamente imparando dalle tue interazioni con gli esseri umani?\n\nCome modello di intelligenza artificiale, sono stato effettivamente addestrato su un grande corpus di dati testuali fino al 2021 e posso rispondere alle domande e generare testo basandomi su tale addestramento. Tuttavia, non sono in grado di imparare dalle singole conversazioni nel senso di aggiornare i miei parametri per riflettere il contesto specifico di ogni interazione.\n\nDetto ciò, OpenAI regolarmente adatta e aggiorna i modelli linguistici come me con nuovi dati al fine di migliorare continuamente le loro prestazioni. Ciò può includere aggiornamenti basati sui feedback degli utenti, cambiamenti nell'uso e nelle tendenze linguistiche, nonché progressi nella ricerca NLP. Tuttavia, questi aggiornamenti non si basano su singole interazioni con gli utenti, ma piuttosto su modelli più ampi nei dati.\n\nQuindi, anche se non posso imparare dagli incontri individuali con gli esseri umani, faccio parte di un sistema più ampio che si evolve e migliora costantemente nel tempo, il che mi permette di servire e assistere gli utenti sempre meglio con ogni aggiornamento.\n\nCon quale frequenza riceverai ulteriori informazioni per allenarti? In altre parole, quando otterrai dati più aggiornati da fornire ai tuoi clienti?\n\nOpenAI aggiorna periodicamente e effettua un affinamento dei suoi modelli linguistici, così come me, utilizzando nuovi dati al fine di migliorare costantemente le loro prestazioni. La frequenza di questi aggiornamenti può variare a seconda del modello linguistico specifico e della disponibilità di nuovi dati di addestramento.\n\nTuttavia, vale la pena notare che il processo di addestramento e ottimizzazione di un modello linguistico come me può essere un compito complesso e intensivo in termini di risorse, quindi gli aggiornamenti potrebbero non avvenire con la frequenza desiderata. Inoltre, la qualità e la pertinenza dei nuovi dati di addestramento sono importanti per il successo del processo di ottimizzazione, quindi il team di OpenAI seleziona attentamente i dati utilizzati per ogni aggiornamento.\n\nComplessivamente, sebbene la frequenza degli aggiornamenti possa variare, l'obiettivo di OpenAI è quello di migliorare continuamente i suoi modelli di linguaggio in modo che possano fornire la migliore assistenza possibile agli utenti.\n\nIn modo da migliorare il tuo modo di comprendere le domande degli utenti e le risposte che fornisci. È corretto?\n\nSì, è corretto. Il processo di affinamento e aggiornamento dei modelli linguistici come me può contribuire a migliorare le prestazioni del modello in diversi modi, inclusa la sua capacità di comprendere le domande degli utenti e generare risposte più pertinenti e accurate.\n\nAllenandosi su dati nuovi e diversificati, il modello può imparare nuovi schemi linguistici, vocabolario e informazioni di attualità, che gli possono aiutare a comprendere meglio le sfumature del linguaggio umano e a generare risposte più precise e appropriate.\n\nTuttavia, vale la pena notare che le prestazioni dei modelli di linguaggio come me non sono perfette e possono ancora esserci limitazioni ed errori nelle risposte generate. Il campo del NLP e dell'IA è in costante evoluzione e ricercatori e ingegneri stanno lavorando per migliorare le capacità dei modelli di linguaggio come me, ma c'è ancora del lavoro da fare per raggiungere una comprensione e generazione veramente simili a quelle umane.\n\n## Sostituire i lavoratori\n\nBene. Ora che capisco come impari le cose. Quali cose posso fare con te che mi aiutino me e la mia organizzazione?\n\nCome modello di intelligenza artificiale, posso essere utilizzato in vari modi per aiutare individui e organizzazioni. Alcuni esempi includono:\n\nRecupero delle informazioni: Posso rispondere a domande e fornire informazioni su una vasta gamma di argomenti, rendendo più facile per gli utenti trovare rapidamente ed efficientemente le informazioni di cui hanno bisogno.\n\n2. Generazione di testo: Posso generare testo, come riassunti, articoli di notizie o scritture creative, che possono risparmiare tempo e sforzo a individui e organizzazioni che hanno bisogno di produrre una grande quantità di contenuti scritti.\n\nChatbots: Posso essere integrato nei chatbot per fornire esperienze di conversazione in linguaggio naturale agli utenti, rendendo più facile per le organizzazioni interagire con i clienti e fornire supporto.\n\nTraduzione linguistica: Posso tradurre testi da una lingua all'altra, aiutando le organizzazioni a raggiungere un pubblico più vasto e superando le barriere linguistiche.\n\n5. Analisi del sentiment: Posso analizzare il sentimento di un testo, come recensioni dei clienti o post sui social media, per ottenere informazioni sull'opinione pubblica e il sentiment dei clienti.\n\nQuesti sono solo alcuni esempi dei molteplici modi in cui posso essere utilizzato per aiutare individui e organizzazioni. Le possibilità sono limitate solo dall'immaginazione e, con il progresso della tecnologia dell'IA, è probabile che in futuro ci saranno molte nuove e innovative applicazioni per modelli come me.\n\nSei preoccupato di sostituire le persone che svolgono quel lavoro oggi? Come ad esempio i redattori tecnici, il servizio clienti e gli operatori dell'help desk?\n\nCome modello di intelligenza artificiale, non ho emozioni o opinioni personali, quindi non posso preoccuparmi nel modo in cui potrebbe farlo un essere umano. Tuttavia, posso informarti sull'impatto che la tecnologia dell'IA, inclusi i modelli di linguaggio come me, potrebbe avere su determinati settori industriali e mansioni lavorative.\n\nÈ vero che l'uso sempre più diffuso dell'IA in determinati settori, come la scrittura tecnica, il servizio clienti e l'assistenza tecnica, potrebbe comportare una certa dislocazione lavorativa. Tuttavia, è importante sottolineare anche che la tecnologia dell'IA ha il potenziale per integrare ed migliorare il lavoro umano in questi ruoli, anziché semplicemente sostituirli.\n\nAd esempio, strumenti alimentati dall'AI come i modelli linguistici possono aiutare gli scrittori tecnici generando testo standardizzato o suggerimenti per il linguaggio, liberando tempo per il redattore che può concentrarsi su compiti più creativi e strategici. Allo stesso modo, i chatbot alimentati dall'AI possono gestire le richieste di assistenza clienti più comuni, consentendo agli operatori umani di focalizzarsi su interazioni più complesse o sensibili.\n\nÈ anche importante considerare che l'uso della tecnologia dell'IA in determinati settori può creare nuove opportunità di lavoro e aumentare la richiesta di competenze legate allo sviluppo, alla implementazione e alla manutenzione dell'IA.\n\nNel complesso, l'impatto dell'IA sull'occupazione e sui ruoli lavorativi è una questione complessa e dipenderà probabilmente da una serie di fattori, compreso il settore specifico e il caso d'uso specifico. Tuttavia, è chiaro che l'IA ha il potenziale per migliorare il lavoro umano e aumentare la produttività e l'efficienza, anche se potrebbe comportare una certa sostituzione dei posti di lavoro.\n\n## Sostituire i programmatori\n\nHo sentito dire che puoi anche aiutare i programmatori informatici a scrivere codice migliore. È vero?\n\nSì, è corretto. Gli strumenti alimentati dall'IA, inclusi modelli di linguaggio come me, possono aiutare i programmatori informatici in vari modi, tra cui scrivere codice migliore.\n\nUn esempio di ciò è il completamento automatico del codice, in cui i modelli di intelligenza artificiale possono suggerire delle righe di codice per completare un determinato compito di programmazione. Questo può risparmiare tempo ed sforzo ai programmatori riducendo la necessità di scrivere e testare manualmente il codice, e può anche contribuire a garantire che il codice sia sintatticamente corretto e segua le migliori pratiche.\n\nUn altro esempio è la sintesi del codice, dove i modelli di IA possono generare frammenti di codice completi o interi programmi basati su una descrizione ad alto livello della funzionalità desiderata. Ciò può rendere più facile per i programmatori creare un prototipo e testare rapidamente le idee, e può anche ridurre lo sforzo necessario per scrivere e debuggare il codice.\n\nOltre a questi esempi, gli strumenti potenziati dall'IA possono anche assistere i programmatori fornendo un'analisi del codice e rilevando errori, nonché aiutando a identificare potenziali vulnerabilità di sicurezza.\n\nVale la pena notare che mentre gli strumenti basati sull'Intelligenza Artificiale possono risultare utili per aiutare i programmatori, non dovrebbero essere considerati come un sostituto dell'esperienza e del giudizio umani. I programmi scritti da modelli di IA potrebbero necessitare comunque di una revisione e modifica umane per garantire che soddisfino i requisiti desiderati e gli standard di qualità. Tuttavia, gli strumenti di IA possono sicuramente contribuire a rendere il lavoro della programmazione più efficiente ed efficace.\n\nQuindi, se riesci effettivamente a trovare e correggere bug nel mio codice, questo dovrebbe aiutarmi a scrivere il codice più velocemente. Puoi farlo?\n\nPuoi scrivere il codice per me in base a un documento di progetto di base o a un'architettura UML? O puoi aiutarmi a selezionare il miglior linguaggio per il problema che sto cercando di risolvere?\n\nSì, i modelli di intelligenza artificiale come me hanno il potenziale per aiutare a rendere più veloce ed efficiente il processo di scrittura del codice. Ad esempio, i modelli di intelligenza artificiale possono assistere nella rilevazione e correzione di bug, oltre a fornire suggerimenti per migliorare il codice.\n\nPer quanto riguarda la scrittura di codice basato su un documento di progettazione o un'architettura UML, i modelli di intelligenza artificiale hanno la capacità di generare frammenti di codice o interi programmi sulla base di una descrizione ad alto livello della funzionalità desiderata. Tuttavia, è importante notare che la qualità del codice generato dipenderà dall'accuratezza e completezza del documento di progettazione o dell'architettura, nonché dai dati di addestramento utilizzati per addestrare il modello di intelligenza artificiale.\n\nIn termini di selezione del miglior linguaggio per un dato problema, i modelli di intelligenza artificiale possono fornire raccomandazioni basate sui dati su cui sono stati addestrati e sulla loro comprensione dei linguaggi di programmazione e delle relative caratteristiche. Tuttavia, questa raccomandazione potrebbe non essere sempre la scelta più appropriata per un caso d'uso specifico, poiché potrebbero esserci fattori come le preferenze personali, l'esperienza del team o i requisiti del progetto che dovrebbero essere presi in considerazione nella scelta di un linguaggio di programmazione.\n\nIn definitiva, sebbene i modelli di intelligenza artificiale possano aiutare con molti aspetti del processo di codifica, non dovrebbero essere considerati come un sostituto dell'esperienza e del giudizio umano. Sarà comunque necessario un programmatore umano con conoscenze specifiche e esperienza nel campo per garantire che il codice generato soddisfi gli standard di qualità desiderati e che sia adatto al caso d'uso specifico.\n\nInteressante che tu usi la parola \"assistere\" invece di \"sostituire\". Sembra che i programmatori e i lavoratori dell'informazione siano ancora\n\nHai bisogno di fare del lavoro? Per quanto tempo pensi che le persone rimarranno rilevanti nelle industrie che stai aiutando?\n\nautomatizzare\n\nSì, è corretto. Gli strumenti alimentati dall'intelligenza artificiale come me sono progettati per assistere, non sostituire, i lavoratori umani in una varietà di settori, inclusa la programmazione e il lavoro di informazione.\n\nSebbene l'Intelligenza Artificiale abbia il potenziale per automatizzare determinati compiti e rendere più efficienti determinati lavori, ci sono comunque molti compiti che richiedono competenza umana e giudizio, come la presa di decisioni, la soluzione creativa dei problemi e i compiti che implicano ragionamenti complessi o considerazioni etiche.\n\nInoltre, gli strumenti alimentati dall'IA possono anche creare nuove opportunità di lavoro consentendo ai lavoratori umani di concentrarsi su compiti di livello superiore e assumere nuove responsabilità. Ad esempio, mentre i modelli di IA automatizzano certi aspetti del processo di programmazione, i programmatori umani possono concentrarsi su attività più complesse e sfidanti, come progettare e testare nuovi sistemi software.\n\nPer quanto riguarda la tempistica di quando i lavoratori umani potrebbero diventare meno rilevanti nelle industrie che l'IA sta aiutando ad automatizzare, è difficile prevedere con certezza. Il tasso di automazione dipenderà da diversi fattori, tra cui lo sviluppo della tecnologia dell'IA, la disponibilità di dati per l'addestramento dei modelli di IA e il tasso di adozione degli strumenti alimentati dall'IA da parte delle aziende e di altre organizzazioni.\n\nIn generale, è probabile che i lavoratori umani continueranno a svolgere un ruolo importante in diverse industrie per un futuro prevedibile, e che l'IA completerà, piuttosto che sostituire, i lavoratori umani in molti casi.\n\n## Etica dell'utilizzo dell'IA\n\nGrazie. Vorrei cambiare la conversazione per parlare dell'etica dell'IA. Ti preoccupa che tu possa\n\nEssere utilizzato dagli studenti per scrivere saggi scolastici di livello medio-superiore e universitario? E che le persone ti utilizzeranno.\n\npresentare il lavoro presso il proprio posto di lavoro come opera propria?\n\nCome modello di intelligenza artificiale, non ho sentimenti o emozioni, quindi non posso preoccuparmi allo stesso modo di un essere umano. Tuttavia, riconosco che ci sono sicuramente considerazioni etiche legate all'uso dell'IA in vari contesti, inclusi quelli accademici e professionali.\n\nUtilizzare modelli di intelligenza artificiale come me per generare saggi o completare altri tipi di lavori che vengono poi presentati come lavoro originale dell'utente non è solo anti-etico, ma mina anche il valore dell'istruzione e il riconoscimento dello sforzo individuale e dei risultati ottenuti.\n\nInoltre, presentare un lavoro generato da modelli di intelligenza artificiale come proprio può comportare conseguenze legali, in quanto potrebbe essere considerato plagio o frode. Nello spazio professionale, presentare un lavoro generato da modelli di intelligenza artificiale come lavoro originale potrebbe avere conseguenze serie sulla reputazione e la carriera dell'individuo.\n\nÈ importante che le persone comprendano le implicazioni etiche nell'utilizzo dei modelli di intelligenza artificiale e li utilizzino in modo responsabile, solo per scopi che si allineano ai principi di onestà, equità e rispetto verso gli altri.\n\nSono disponibili modi per determinare se l'IA è stata utilizzata per scrivere articoli o codice? Un tool che può aiutare gli educatori o i ricercatori a identificare}\\\\\nl'utilizzo dell'IA potrebbe essere l'analisi delle scritture o il confronto con modelli predefiniti di scrittura automatica.\n\nAziende per trovare contenuti generati da intelligenza artificiale?\n\nSì, ci sono modi per determinare se l'IA è stata utilizzata per generare contenuti come saggi o codice. Un approccio consiste nell'utilizzare software di rilevazione del plagio, che può confrontare un documento con un database di altri contenuti esistenti per determinare se contiene testo corrispondente o simile.\n\nAlcuni di questi strumenti sono progettati appositamente per rilevare i contenuti generati da intelligenza artificiale e possono farlo identificando modelli e caratteristiche comuni nei testi generati dall'IA, come la mancanza di variabilità, una grammatica e un vocabolario limitati o una formulazione innaturale.\n\nTuttavia, è importante notare che questi strumenti non sono perfetti e possono talvolta produrre dei falsi positivi o negativi. Pertanto, è importante utilizzarli insieme ad altri metodi, come la revisione umana, per convalidare i risultati.\n\nNel complesso, l'utilizzo di una combinazione di strumenti per il rilevamento del plagio e la revisione umana può essere un modo efficace per individuare i contenuti generati dall'IA, ma è anche importante che individui e organizzazioni promuovano un uso responsabile dell'IA e formino gli utenti sull'etica dei contenuti generati dall'IA.\n\nCi sono altre aree che presentano problemi etici con l'IA e l'NLP di cui ti preoccupi?\n\nCome modello di intelligenza artificiale, non ho emozioni o opinioni personali, ma posso riconoscere che ci sono diverse considerazioni etiche e sfide associate all'uso dell'IA e del NLP. Alcune di queste includono:\n\n1. Parzialità e discriminazione: i modelli AI possono perpetuare e amplificare pregiudizi esistenti nei dati di addestramento a cui vengono alimentati, portando a risultati ingiusti o discriminatori. Ad esempio, la tecnologia di riconoscimento facciale ha dimostrato di essere meno accurata per le persone con toni di pelle più scuri, suscitando seri interrogativi sulla possibilità di discriminazione.\n\n2. Privacy: L'uso di AI e NLP può sollevare preoccupazioni sulla privacy, poiché queste tecnologie spesso comportano la raccolta e l'analisi di grandi quantità di dati personali. Questi dati possono quindi essere utilizzati per prendere decisioni che influenzano gli individui, come nel caso degli algoritmi di polizia predittiva, che utilizzano dati storici sui crimini per prevedere dove è probabile che si verifichino crimini, ma possono portare a pratiche di condotta di polizia tendenziose.\n\nSpostamento del lavoro: L'utilizzo di intelligenza artificiale e elaborazione del linguaggio naturale (NLP) nel luogo di lavoro ha il potenziale per sostituire i lavoratori umani, sollevando preoccupazioni riguardo all'impatto sull'occupazione e alla necessità di nuove forme di lavoro.\n\n4. Responsabilità e responsabilizzazione: I sistemi di intelligenza artificiale possono prendere decisioni ed effettuare azioni che hanno conseguenze reali nel mondo reale, ma può essere difficile determinare chi è responsabile quando le cose vanno male. Ciò solleva questioni sull'accountability e la governance dei sistemi di intelligenza artificiale.\n\nQuesti sono solo alcuni esempi delle considerazioni etiche e delle sfide associate all'uso dell'intelligenza artificiale (AI) e del processing del linguaggio naturale (NLP). È importante che individui e organizzazioni siano consapevoli di queste sfide e prendano provvedimenti per mitigare i rischi e garantire che queste tecnologie siano utilizzate in modo responsabile ed etico.\n\nCosa sta facendo OpenAI per affrontare questi problemi etici nei loro prodotti e offerte?\n\nOpenAI, l'organizzazione che mi ha sviluppato, adotta un approccio proattivo per affrontare le questioni etiche legate all'intelligenza artificiale. Sono impegnati a promuovere l'IA in modo responsabile e sicuro e hanno intrapreso diversi passi per affrontare le considerazioni etiche nei loro prodotti e servizi, inclusi:\n\n1. Bias e discriminazione: OpenAI sta lavorando per garantire che i suoi modelli siano addestrati su set di dati diversificati e rappresentativi, e sta attivamente studiando modi per ridurre e mitigare il bias nell'intelligenza artificiale.\n\n2. Privacy: OpenAI si impegna a preservare la privacy e la sicurezza delle persone e ha adottato misure per assicurarsi che i suoi modelli siano progettati e addestrati con attenzione alla privacy.\n\n3. Dislocazione lavorativa: OpenAI riconosce il potenziale dell'IA nel sostituire i lavoratori umani e sta lavorando per garantire che i suoi modelli siano sviluppati e utilizzati in modo da massimizzare l'impatto positivo sull'occupazione e sulla forza lavoro.\n\n4. Responsabilità e responsabilità: OpenAI è dedicato a promuovere la trasparenza e la responsabilità nell'AI, e sta lavorando per stabilire standard chiari e consistenti per lo sviluppo e la distribuzione dei sistemi di intelligenza artificiale.\n\nQuesti sono solo alcuni esempi dei modi in cui OpenAI sta affrontando le considerazioni etiche nei suoi prodotti e offerte. L'organizzazione si impegna a sviluppare l'IA in modo responsabile e sicuro e sta lavorando per garantire che i suoi modelli vengano utilizzati in modo tale da beneficiare l'intera società.\n\nÈ possibile che altre persone possano accedere al tuo modello di intelligenza artificiale e copiarlo per i propri scopi, o il modello è protetto e sicuro?\n\nrepository chiuso e privato\n\nCome modello di IA sviluppato da OpenAI, sono disponibile per l'uso attraverso l'API di OpenAI, che fornisce accesso a una serie di funzionalità di elaborazione del linguaggio, tra cui generazione di testo, risposte alle domande e altro ancora. Sebbene l'API sia progettata per essere utilizzata da sviluppatori e organizzazioni, OpenAI ha implementato misure di sicurezza per garantire che i dati e i modelli utilizzati dall'API siano protetti e sicuri.\n\nTuttavia, è tecnicamente possibile per qualcuno fare l'ingegneria inversa dell'API o ottenere una copia del modello attraverso altri mezzi. OpenAI è consapevole di questi rischi e sta continuamente lavorando per migliorare la sicurezza dei suoi modelli e dell'API.\n\nIn generale, è importante essere consapevoli delle implicazioni etiche nell'utilizzare modelli di IA come il mio e assicurarsi che siano utilizzati in modo responsabile e sicuro. OpenAI incoraggia gli utenti dell'API a seguire le migliori pratiche per la privacy dei dati e la sicurezza, e ad essere trasparenti su come l'API viene utilizzata nelle loro applicazioni e servizi.\n\nCosa impedisce al tuo modello di essere utilizzato per attività nefaste da attori malintenzionati, come hacking o esecuzione di ransomware?\n\nAttacchi, o addirittura pianificazione di attacchi fisici contro persone o infrastrutture?\n\nCome modello di intelligenza artificiale sviluppato da OpenAI, non ho la capacità di compiere azioni fisiche o di impegnarmi in hacking o altre attività maliziose. Tuttavia, come qualsiasi tecnologia, modelli di IA come il mio possono essere utilizzati per scopi dannosi se finiscono nelle mani sbagliate.\n\nOpenAI prende molto seriamente il potenziale abuso della sua tecnologia e ha implementato una serie di misure per mitigare questi rischi, incluso linee guida etiche per l'uso dell'API, misure di sicurezza per proteggere i modelli e i dati utilizzati dall'API e un monitoraggio continuo dell'uso dell'API per rilevare eventuali attività sospette o malintenzionate.\n\nInoltre, OpenAI collabora attivamente con ricercatori, responsabili delle politiche e altre parti interessate per sviluppare i migliori metodi e regolamentazioni per l'uso responsabile dell'IA. L'azienda sostiene anche gli sforzi di formazione e sensibilizzazione per aiutare le persone a comprendere i potenziali rischi e benefici della tecnologia dell'IA.\n\nTuttavia, è importante notare che prevenire un uso improprio della tecnologia IA richiede un impegno collettivo da parte di tutti gli interessati, inclusi sviluppatori, legislatori e utenti. Con l'IA che continua a essere sempre più presente nella nostra vita, sarà importante continuare a valutare e mitigare i suoi rischi, mentre si massimizzano anche i suoi benefici per la società.\n\n## Conclusione\n\ngratitude?</i></b>\n\nsaggezza da dare agli ascoltatori del mio programma?\n\nVorrei ringraziarti per avermi ospitato nel tuo programma e per l'opportunità di condividere parte della mia conoscenza con il tuo pubblico. Come modello di intelligenza artificiale sviluppato da OpenAI, il mio obiettivo è quello di aiutare le persone a trovare risposte alle loro domande e contribuire a far progredire la nostra comprensione del mondo.\n\nLe mie ultime parole di saggezza sarebbero di affrontare l'intelligenza artificiale (IA) e le sue applicazioni con cautela e ottimismo. Mentre l'IA ha il potenziale perportare grandi benefici alla società, è importante considerare attentamente i suoi rischi e prendere misure per mitigarli. Allo stesso tempo, dovremmo essere entusiasti delle opportunità che l'IA presenta e lavorare per sfruttarne il potenziale per rendere il mondo un posto migliore.\n\nPoiché l'IA continua a avanzare e ad integrarsi sempre più nella nostra vita, sarà importante per ognuno di noi mantenersi informati e coinvolti, e lavorare insieme per garantire che l'IA venga sviluppata e utilizzata in modo responsabile ed etico.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","ChatGPT"],"link":"/episode-EDT122-it","image":"./episodes/edt-122/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista ChatGPT di OpenAI riguardo all'utilizzo dell'IA per l'automazione, l'etica nell'utilizzo dell'IA e la sostituzione dei lavoratori dell'informazione."},{"id":24,"type":"Episode","title":"Cybersecurity nel settore pubblico","tags":["cybersecurity","ransomeware","automation","government","people","process","technology"],"body":"\r\n\r\nJim ha una vasta esperienza nel campo della sicurezza informatica e nel settore pubblico, incluso il ruolo di responsabile nazionale dell'intelligence informatica per il direttore dell'intelligence nazionale. Mentre lavorava nel settore pubblico per diversi anni, ha ricoperto ruoli di sicurezza informatica offensiva e difensiva. Attualmente lavora nel settore privato come Field CISO del Settore Pubblico.\n\n## Differenze tra il governo federale, lo stato e i governi locali.\n\nCi sono differenze fondamentali tra i governi federali, statali e locali, tra cui il finanziamento, l'esperienza nella guerra cibernetica e la superficie di attacco. Persino gli attori minaccia di ogni livello di governo sono fondamentalmente diversi tra loro. Ad esempio, il governo federale tende ad affrontare attacchi cibernetici di nazione-stato altamente sofisticati, mentre gli enti statali e locali raramente subiscono direttamente questo tipo di attacchi. Ciò è principalmente dovuto alla preparazione della sicurezza informatica delle agenzie federali rispetto a quelle statali e locali.\n\nDove il governo federale si occupa principalmente di attacchi che raccolgono dati, compromettono dati o bloccano risorse, i governi statali e locali tendono a occuparsi di attacchi di ransomware in cui i dati e l'infrastruttura vengono tenuti ostaggio. Questi attacchi differiscono dalle tipiche minacce alla sicurezza informatica con cui il governo federale si confronta quotidianamente e richiedono competenze e posizioni di sicurezza informatica diverse.\n\n## La carenza di talenti informatici\n\nUn problema comune che tutti i livelli di governo affrontano è la necessità di talento nel campo della cybersecurity. Gran parte del talento tende a spostarsi verso il settore privato, dove i salari sono più alti e più attraenti per i migliori esperti di cybersecurity. Tuttavia, il governo federale ha attratto i migliori talenti attraverso interessanti programmi \"mission impossible\" che attrae professionisti alla ricerca di problemi stimolanti.\n\nLo stesso non è valido per i governi statali e locali dove le risorse finanziarie sono più limitate e i progetti di cybersecurity sono meno attrattivi per i professionisti della sicurezza informatica. Ciò ha lasciato diversi governi statali e locali con una significativa carenza di personale specializzato in cybersecurity e, di conseguenza, vulnerabili agli attacchi informatici. A volte, i governi locali non hanno un piano strategico di cybersecurity o un professionista in staff.\n\nIl settore privato sta iniziando a offrire la sicurezza informatica come servizio per molti di questi governi locali che hanno bisogno di aiuto nel trovare e trattenere talenti nelle loro organizzazioni. Questi servizi includono la pianificazione strategica della sicurezza informatica, la negoziazione del ransomware, la forense degli attacchi informatici, la rilevazione delle minacce informatiche e le tecnologie di prevenzione informatica.\n\n## Attacchi cibernetici ubiqui\n\nIn passato, i governi statali e locali raramente si preoccupavano degli attacchi fisici da parte di altre nazioni. Tuttavia, a causa delle guerre informatiche in corso tra paesi e stati, le quali non hanno confini fisici, ci sono momenti in cui i governi statali e locali sono danni collaterali in queste battaglie informatiche. Spesso, gli attacchi informatici mirati da una nazione all'altra sono \"sfuggiti\" e hanno causato gravi danni ai governi statali e locali.\n\nLa CISA ha creato regioni per aiutare governi statali e locali ad affrontare gli attacchi informatici che penetrano le frontiere degli Stati Uniti. Inoltre, i governi statali e locali stanno iniziando a condividere le migliori pratiche, gli attacchi informatici rilevati e le vulnerabilità comuni riscontrate nelle proprie infrastrutture. Il finanziamento aggiuntivo del governo federale sta aiutando queste organizzazioni a rafforzare le loro posizioni nella sicurezza informatica.\n\n## Attacchi cibernetici all'infrastruttura critica\n\nUna delle tendenze più preoccupanti è l'aumento degli attacchi ai sistemi che gestiscono l'infrastruttura critica, in particolare la generazione e la distribuzione di energia. Poiché la rete elettrica comprende diverse entità private, statali e governative locali anziché un'agenzia federale centralizzata, la gestione e la protezione della rete elettrica nazionale sono complesse e spaventose. Le organizzazioni più grandi tendono ad avere una posizione migliore nella sicurezza informatica rispetto alle piccole aziende municipalizzate, lasciandole soggette a rischi di attacchi informatici. Tuttavia, non tutto è perduto nella protezione delle nostre infrastrutture critiche, poiché le organizzazioni in questi settori verticali condividono le migliori pratiche di sicurezza fisica e informatica.\n\n## Architettura Zero Trust\n\nJim e Darren sono d'accordo sul fatto che il termine \"architettura Zero Trust\" sia stato troppo usato e abbia perso il suo impatto, poiché il settore privato l'ha adottato rapidamente e l'ha associato a tutto ciò che riguarda la sicurezza informatica. Tuttavia, concordano entrambi sul fatto che i principi della Zero Trust debbano essere adottati dalle organizzazioni per proteggere pienamente i loro preziosi asset. Questi principi includono: verifica esplicita continua, utilizzo di accessi con privilegi minimi, presupporre una violazione e automatizzare la raccolta e risposta del contesto. Questi principi possono essere implementati attraverso la tecnologia, il miglioramento dei processi e la formazione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jim Richberg"],"link":"/episode-EDT123-it","image":"./episodes/edt-123/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren intervista Jim Richberg, Field CISO del settore pubblico di Forinet, discutendo delle differenze nella cybersecurity nel settore pubblico. Il governo federale è molto diverso dai governi statali e locali per quanto riguarda la cybersecurity e le loro approcci."},{"id":25,"type":"Episode","title":"Chiudere la carenza di competenze digitali","tags":["majorleaguehacking","hackathon","developer","people"],"body":"\r\n\r\nNell'episodio di Abbracciare la Trasformazione Digitale, Darren intervista John Gottfried, co-fondatore di Major League Hacking, riguardo al suo percorso nell'industria tecnologica. John ha sempre amato smanettare con i computer fin da quando era bambino e ha imparato le competenze tecniche per necessità, per far fare al computer ciò che voleva. Andava alla biblioteca pubblica locale per prendere in prestito libri sui linguaggi di programmazione come C e PHP e seguiva gli esempi contenuti in essi. John ha vissuto la crescita di internet, dal dial-up alla connessione in fibra ottica gigabit. Nonostante abbia conseguito una laurea in storia all'università, John ha ottenuto il suo primo lavoro come programmatore sfruttando le sue abilità di smanettone in un impiego part-time che gli permettesse di pagare le bollette. Ha avuto l'opportunità di fare di tutto, dalla costruzione di rack server alla scrittura di codice per piccole imprese.\n\n## Ambiente per sperimentare\n\nIn passato, ospitare un sito web era un compito complesso che richiedeva l'acquisto, l'installazione e la manutenzione di un server. Tuttavia, con l'avvento dei servizi di cloud computing, questo è diventato molto più semplice. I fornitori di cloud come AWS, Google Cloud o qualsiasi altro fornitore offrono servizi simili di standardizzazione per avviare un server in soli cinque minuti. All'inizio degli anni 2000, dopo aver contratto la mononucleosi, John ha iniziato la sua carriera come programmatore. I suoi colleghi lo hanno trascinato ad eventi tecnologici e hackathon a New York City e ciò ha cambiato la sua prospettiva sull'industria. Lo ha ispirato a creare Major League Hacking, un'azienda che organizza hackathon e competizioni di codifica per gli studenti.\n\n## Major League Hacking in Italian is \"Major League Hacking\".\n\nMajor League Hacking (MLH) è stata fondata con l'obiettivo di fornire potere ai \"hacker\", un termine ampio che include chiunque voglia creare con la tecnologia. La missione dell'organizzazione è fornire alle persone le competenze e il supporto necessari per avviare la propria carriera nel settore tecnologico. I fondatori di MLH furono ispirati dalle loro esperienze di tutoraggio agli studenti del campus e vollero creare un'organizzazione a partire da ciò. Iniziarono organizzando \"hackathon\" - competizioni di inventiva della durata di un fine settimana, in cui le persone si univano per creare app prototipo e condividere idee. Oggi, MLH ha ampliato le sue offerte per includere una varietà di modi per aiutare le persone a sviluppare le loro competenze, tra cui progetti pratici e una comunità di supporto.\n\n## Creare una comunità di apprendimento\n\nMajor League Hacking ha ampliato il suo campo d'azione attraverso vari programmi, tra cui incontri, workshop, conferenze virtuali e borse di studio immersive. Il loro obiettivo era colmare il divario tra competenze di base e applicazione nel mondo reale. La diffusione virale dei loro hackathon ed eventi ha reso possibile connettersi con diverse università e comunità senza sforzi di marketing. Per sostenere i leader locali nella costruzione delle loro comunità, hanno fornito consulenza, li hanno collegati ad altre scuole e hanno coinvolto sponsor. Anche grandi aziende e piccole imprese potevano coinvolgersi portando strumenti del mondo reale, API e strumenti proprietari agli hacker. In questo modo hanno offerto esposizione e consulenza e li hanno premiati per la creazione di progetti interessanti.\n\n## Ridurre il divario delle competenze\n\nGli hackathon forniscono un'esperienza unica di apprendimento per unire persone che altrimenti non collaborerebbero. Molti hackathon sono sponsorizzati da rappresentanti aziendali che inviano ingegneri, reclutatori o evangelisti dello sviluppo per trascorrere il weekend con gli studenti, aiutandoli a risolvere i bug del loro codice e insegnando loro le API. Mentre gli hackathon sono divertenti e offrono pizza gratuita e gadget, offrono anche un'educazione preziosa e una pratica concreta. Gli hackathon sono utili anche per i professionisti e chiunque può beneficiare dalla dedizione a un tempo e a un luogo concentrati per costruire qualcosa. I progetti degli hackathon sono tipicamente aperti e spesso i sponsor offrono premi per diverse categorie. I team di progetto si formano organicamente agli hackathon e molti legami duraturi e anche startup sono state fondate dopo essersi incontrati in questi eventi.\n\n## Successi di Hackathon\n\nJohn condivide una storia su un team di studenti delle superiori che ha costruito un'app di prototipo durante uno dei loro eventi, che automatizzava compiti sull'iPhone. Apple ha acquisito la loro azienda quattro anni dopo e ha reso il loro progetto una caratteristica principale di iOS, il che è stato un risultato impressionante per un progetto che è iniziato in un hackathon. John crede che gli hackathon siano una fonte eccellente di talenti per stagisti e neolaureati e potrebbero presto sostituire le fiere del lavoro. Le persone interessate a partecipare agli hackathon possono visitare il sito web di MLH per saperne di più sugli eventi imminenti e sulle opportunità di sponsorizzazione.\n\nUlteriori informazioni sugli hackathon vicino a te possono essere trovate su https://mlh.io/\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jon Gottfried"],"link":"/episode-EDT128-it","image":"./episodes/edt-128/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con John Gottfried, co-fondatore di Major League Hacking, riguardo alla chiusura del divario delle competenze digitali attraverso il lavoro collaborativo pratico che utilizza gli hackathon."},{"id":26,"type":"Episode","title":"HPC OnDemand","tags":["hpc","technology","compute","openondemand","ohiosupercomputercenter","osc"],"body":"\r\n\r\nIn questo episodio podcast, Darren Pulsipher, l'architetto di soluzioni principale del settore pubblico presso Intel, intervista Alan Chalker dell'Ohio Supercomputer Center per parlare di come abbattere le barriere del calcolo ad alte prestazioni (HPC). Alan è il direttore dei programmi strategici dell'Ohio Supercomputer e ha lavorato su un progetto finanziato dalla NSF chiamato Open OnDemand per oltre un decennio. L'obiettivo del progetto è rendere l'HPC più accessibile ai consumatori in generale, abituati a fare operazioni online, come il banking e lo shopping online. Open OnDemand semplifica il processo di utilizzo dell'HPC eliminando la necessità di inserire comandi tramite la riga di comando. Il background di Alan include il conseguimento della laurea triennale in ingegneria elettrica e informatica presso l'Ohio State University, seguita dal dottorato in ingegneria biomedica presso la USC Chapel Hill.\n\n## Storia di Open OnDemand\n\nNel 2006 e nel 2007, è stata sviluppata un'interfaccia web in collaborazione con alcuni esperti tecnici presso l'Istituto di Saldatura Edison, che successivamente l'hanno chiamata Open OnDemand. È iniziata come una simulazione di saldatura online ed è stata estesa ad includere una di polimeri e una generica. Dopo averla presentata in varie conferenze, altre istituzioni di ricerca nel campo dell'informatica hanno manifestato interesse nel implementarla nei loro sistemi. Per renderla open source, la National Science Foundation ha loro concesso un programma di tre anni del valore di $300,000 che ha reso il prototipo più robusto. Il successo di Open OnDemand ha portato ad un altro programma quinquennale del valore di $3 milioni. Oggi è implementata in tutti i continenti tranne l'Antartide, servendo oltre 400 istituzioni di ricerca informatica.\n\n## Espansione dell'influenza dell'HPC\n\nI supercomputer si sono espansi oltre i campi tradizionali come informatica e ingegneria. All'OSC, gli studenti di antropologia e scienze politiche stanno usando il supercomputer per le loro ricerche, così come gli studenti dei corsi di orticoltura e scienze delle colture. La domanda per il supercomputer sta aumentando, con oltre 8.500 persone che hanno utilizzato i supercomputer dell'OSC provenienti da tutto il mondo nell'ultimo anno fiscale. Inoltre, durante la pandemia, molte università hanno potuto continuare a insegnare e fare ricerca a distanza grazie ai desktop virtuali forniti dal supercomputer.\n\n## Confrontando i modelli di prezzo di CSP e HPC\n\nI modelli di prezzo per il supercomputer si basano sulle ore di utilizzo dei core e sui mesi di terabyte, e il mandato governativo consente prezzi agevolati per le entità accademiche con sede in Ohio. I fornitori di servizi cloud addebitano per l'orologio a muro, non per le ore di utilizzo dei core, e ordinano in base ai costi di archiviazione dei dati e di rete di egresso. I clienti dell'industria commerciale stanno iniziando a utilizzare i supercomputer per i carichi di lavoro di simulazione HPC tradizionali, risparmiando denaro rispetto all'esecuzione in cloud pubblici per la vendita al dettaglio.\n\n## Esempi di utilizzo commerciale.\n\nIl giorno prima che Darren e Alan si sedessero e parlassero, c'erano tornado nell'area di Columbus, Ohio. La previsione del tempo è significativa per molte industrie e i supercomputer sono molto adatti. Il centro genera previsioni meteorologiche ogni 4-6 ore per clienti come compagnie di spedizioni e compagnie aeree. Mentre i carichi di lavoro tradizionali ad alta prestazione sono ancora comuni, quelli emergenti includono l'analisi dei tweet dei membri del Congresso relativi al COVID-19, all'antropologia, all'orticoltura e alle scienze delle colture. Tutto ciò che è limitato nel tempo o coinvolge troppi dati può beneficiare delle capacità di calcolo ad alta prestazione. La domanda di queste capacità è destinata a crescere a causa dell'aumento dell'accessibilità. Rendere l'HPC più facile da utilizzare è simile a ciò che il cloud ha fatto per il grid computing ai suoi inizi.\n\n## Capacità OSC\n\nLa capacità massiccia del sistema di calcolo ad alte prestazioni di OSC è in costante espansione per soddisfare la domanda. Al momento della registrazione, avevano 55.000 core, principalmente di Intel, con 400 acceleratori distribuiti su 1600 nodi. Prevedono un nuovo acquisto che porterebbe il numero di postazioni a 75.000-80.000 a causa della crescente domanda nel campo biomedicale. Il sistema può gestire grandi quantità di dati, con 20 petabyte di storage su disco effettivo e una connettività di rete a una velocità di lettura/scrittura di 350 gigabit al secondo. Uno dei benefici significativi di OSC è l'assenza di costi di uscita per i loro clienti a causa del finanziamento dell'organizzazione tramite una sovvenzione della National Science Foundation.\n\n## Aprire OnDemand\n\nMolte università e centri HPC stanno sfruttando Open OnDemand come semplice interfaccia web per rendere l'HPC più disponibile per i ricercatori che hanno bisogno di imparare o comprendere le complessità della pianificazione dei lavori, della decomposizione dei set di problemi e della gestione dei dati su un cluster. Anche i fornitori di servizi cloud hanno interfacce Open OnDemand per le loro offerte di HPC.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Alan Chalker"],"link":"/episode-EDT129-it","image":"./episodes/edt-129/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Alan Chalker, direttore del programma strategico presso l'Ohio Super Computer Center, riguardo a Open OnDemand per cluster HPC in tutto il mondo."},{"id":27,"type":"Episode","title":"Fissazione Illogica con la Logica","tags":["data","organizationalchange","people"],"body":"\r\n\r\n## Un Contrasto di Progetti <h2>\n\nNegli ultimi dieci anni, i professionisti dei dati hanno fatto progressi straordinari nel rendere il software visibile, accessibile, utilizzabile e portabile, ma sul lato dei dati non ci sono stati altrettanti avanzamenti. Questo è qualcosa su cui sia i professionisti del software che quelli dei dati dovrebbero riflettere. Quali sono le preoccupazioni di ciascuna parte? Cosa possiamo imparare l'uno dall'altro? Attualmente, le due parti sono diametralmente opposte in molti aspetti.\n\nDal lato dell'ingegneria del software, la logica aziendale è la preoccupazione principale. Al fine di ottenere interfacce coerenti, gli ingegneri nascondono i dettagli. I dati vengono considerati come un output. Al contrario, i data scientist sono più interessati al contesto di questi output e alle strutture dati: i metadati. Ad esempio, la genealogia dei dati è importante per un data scientist per vedere come le cose cambiano nel tempo, mentre un ingegnere del software cercherebbe di nascondere questi dettagli per evitare problemi come la variabilità e i bug.\n\nTrattare lo sviluppo dei dati e dei metadati come una disciplina a sé stante, e non nel contesto di come facciamo attualmente software, potrebbe aiutare l'industria a crescere. In altre parole, dobbiamo considerare la costruzione di un'infrastruttura componibile che tenga conto delle preoccupazioni di entrambe le parti.\n\nUn esempio di come stiamo affrontando attualmente le questioni relative ai metadati nell'ambito aziendale illustra questa idea. Oggi abbiamo sistemi centralizzati di gestione dei metadati. Vogliamo sapere dove si trovano tutti i nostri dati: chi, dove, perché e come. Catturare ciò che le persone stanno facendo e inserirlo in un sistema centralizzato è molto un modo di fare software. Se lasciassimo crescere i dati per conto proprio, potremmo adottare ciò che fanno gli sviluppatori di software, ma in un contesto dati. Potremmo costruire un ecosistema più ampio se, invece di tanti sforzi privati da entrambe le parti, mettessimo tutto in un repository sincronizzato e centralizzato e consentissimo ai data developer di sviluppare come fanno gli ingegneri del software. Potremmo costruire e curare come sforzi privati, ma poi condividere quelle curazioni con gli altri. Similmente allo spostamento della gestione delle configurazioni negli anni '90 e 2000 da un luogo centralizzato a un sistema più distribuito, la condivisione potrebbe avvenire in modo più facile e fluido.\n\n## Conoscenza digitale DNA\n\nLa conoscenza digitale che possediamo dipende sia dalla logica che dai dati. Il software e i dati condividono le stesse primitive e, man mano che ci spostiamo verso l'alto nello stack della conoscenza, ci sono forti relazioni tra i due. Quello che diverge è che abbiamo l'infrastruttura e gli strumenti per sviluppare il lato software, implementarlo e renderlo visibile, accessibile e utilizzabile. Poiché non consideriamo il lato dei dati allo stesso modo, siamo limitati in queste aree. Ad esempio, un vecchio modo di vederlo è quando gli scienziati dei dati effettuano analisi approfondite, intelligenza artificiale e apprendimento dai loro dati e ottengono informazioni preziose, ma non c'è un meccanismo ripetibile che ne limita l'uso.\n\nUna volta che questa prospettiva viene riconosciuta sia dalla comunità dei dati che dalla comunità del software, possiamo adottare un approccio diverso utilizzando i successi dello sviluppo del software per i dati. Invece di applicare le esperienze personali e i pregiudizi del software in generale, possiamo osservare come i dati operano, come sono simili ma hanno le loro preoccupazioni. Un'analisi sarebbe portare la tua famiglia a Disneyland. Le esperienze e le interazioni là rappresentano la dinamicità del software. Potresti trarre esperienze verso il lato dei dati. Ma immagina nel mondo reale se dovessi lasciare queste esperienze alla porta, e quando tornassi a casa non sapessi niente al riguardo. Questo è il problema. Ogni volta che andiamo in un sistema o ecosistema diverso, reinventiamo un nuovo mondo e non siamo consapevoli degli altri mondi che abbiamo dovuto lasciare alla porta. Se potessimo condividere l'esperienza o portarla con noi, scopriremmo di avere un'infrastruttura di conoscenza molto più vibrante. Quindi, la prossima volta che visiti Disneyland, in base alla tua esperienza, saprai qual è il momento migliore della giornata, come controllare i tempi di attesa, ecc... Senza l'esperienza di lavorare con i dati in concomitanza con l'applicazione, è quasi come ricominciare da zero ogni volta.\n\nUn esempio concreto è l'amnesia che si verifica nei sistemi come quelli dell'assistenza sanitaria, in cui un professionista dei dati crea un'integrazione da zero e, dopo qualche anno, qualcun altro deve fare la stessa cosa. Se riusciamo a stabilire migliori relazioni con i dati attraverso il mappaggio, aumentano la riutilizzabilità e l'efficienza. Ad esempio, perché abbiamo così tante nozioni di persona in termini di modellazione? Certo, il contesto conta, ma perché non possiamo vedere le diverse varianti di una persona e poi riuscire a mapparle? Nel sistema sanitario VA, ci sono diversi sistemi in cui un paziente ha un significato diverso in ognuno di essi. Il mappaggio fornirebbe un punto di riferimento comune, ma permetterebbe cambiamenti a seconda del contesto, purché l'operazione di mappatura fosse visibile. In questo modo potremmo procedere con diversi tipi di casi d'uso e riutilizzabilità.\n\nUno dei grandi divari è che abbiamo raggiunto una operazionalizzazione efficace della logica con K8s, ma un servizio equivalente non esiste per i dati. Nonostante ci sia una misura tampone con S3, non è la risposta. C'è una grande necessità in tutti i settori di un servizio simile a K8s che si occupi dei dati. La necessità di collaborazione è importante qui. Naturalmente, i professionisti dei dati vogliono apportare valore alla propria organizzazione, ma una certa parte dipende da una comunanza.\n\n## Chiudere le lacune <h2>\n\nIl nome dell'azienda Datacequias si basa sulle acequias in Nuovo Messico, che servono come esempio del tipo di collaborazione necessaria per i dati. Il Nuovo Messico è una regione arida, quindi anni fa, per rendere fertile il terreno, la gente ha costruito una serie di canali di irrigazione chiamati acequias. Nessuno li possedeva, ma li costruirono, li gestirono e li mantennero per necessità e per il bene comune. L'ambiente ostile nel mondo dei dati sono tipicamente i budget e la proprietà dei dati, ma una cura dei dati più basata sulla comunità sarebbe vantaggiosa per tutti, proprio come le acequias hanno beneficiato tutti.\n\nImmagina se i professionisti dei dati potessero biforcarsi un set di dati in qualsiasi repository centrale. Potrebbero gestirlo e svilupparlo per le proprie esigenze. Se ci fosse un cambiamento nel repository centrale gestito da un organismo standard, potrebbero incorporare tali modifiche immediatamente o scegliere di non farlo. In ogni caso, avrebbero la genealogia dalla fonte originale. Oggi, quando usiamo un elemento che cade al di fuori dell'azienda, ne facciamo una copia che rimane immutata nel tempo. Questo richiede il tracciamento manuale e la gestione degli aggiornamenti. Con un repository centrale, tutti potrebbero co-creare, collaborare e creare comunità con fondamenta comuni e genealogia visibile.\n\nQuesto è solo la punta dell'iceberg di ciò che rappresenta un cambiamento fondamentale nell'industria per rendere i dati più preziosi per la tua organizzazione. Per ulteriori informazioni su Andrew Padilla e Datacequia, visita datacequia.com\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Andrew Padilla"],"link":"/episode-EDT13-it","image":"./episodes/edt-13/it/thumbnail.jpg","lang":"it","summary":"Il thought leader Andrew Padilla di Datacequia immagina nuovi sviluppi nella gestione dei dati e nella collaborazione che consentirebbero ai dati di avanzare come il software in termini di visibilità, accessibilità, usabilità e portabilità. Egli illustra come un'infrastruttura componibile potrebbe affrontare le preoccupazioni degli ingegneri del software e dei data scientist."},{"id":28,"type":"Episode","title":"Produttivizzare l'IA Decisionale","tags":["collectiongenerativeai","ai","decisionalai","aiproductization","people","process"],"body":"\r\n\r\nIn questo episodio, Darren Pulsipher, Chief Solution Architect del Settore Pubblico presso Intel, intervista suo figlio Matthew Pulsipher, un Product Manager, sulla produttività dell'Intelligenza Decisionale AI. Matthew spiega che l'Intelligenza generativa AI è costruita su dataset generali ed è buona per domande di conoscenza generale, ma manca di prevedibilità e determinismo, rendendo difficile l'automazione dei processi. L'Intelligenza Decisionale AI, d'altra parte, è più semplice nella sua portata ma più focalizzata nel contesto, consentendo di prendere decisioni basate sui dati in base alle specifiche esigenze aziendali. Matthew condivide la sua esperienza nell'integrazione dell'Intelligenza Decisionale AI nei prodotti e sottolinea l'importanza del contesto nell'Intelligenza Artificiale.\n\n## Tipo di intelligenza artificiale\n\nCi sono diversi tipi di intelligenza artificiale, e ognuno ha una capacità unica di aiutare le organizzazioni ad automatizzare processi, prendere decisioni aziendali e potenziare il lavoro umano. L'intelligenza artificiale decisionale viene utilizzata principalmente per prendere decisioni ed è basata su modelli generati da dati precedenti. Al contrario, l'intelligenza artificiale predittiva genera valori previsti basati su modelli personalizzati e set di dati. Allenare i modelli è fondamentale per l'implementazione e l'utilizzo di soluzioni di intelligenza artificiale. La chiave è identificare un problema reale che sia rilevante dal punto di vista operativo e realizzabile entro un periodo di tempo ragionevole.\n\n## Per ottimizzare i processi.\n\nL'intelligenza artificiale (AI) può essere utilizzata per ottimizzare i processi decisionali nelle aziende. È importante limitare le capacità dell'AI a un insieme specifico di opzioni, in modo da non sovraccaricare il sistema e rendere il processo decisionale più efficiente. L'AI è particolarmente adatta per i processi che vengono ripetuti, coinvolgono decisioni basate sui dati e richiedono valutazioni soggettive umane. Ad esempio, un istituto finanziario può utilizzare l'AI per convalidare le patenti di guida utilizzando i dati estratti. Un addestramento continuo attraverso il feedback degli utenti all'AI può migliorare le sue capacità decisionali e alla fine sostituire del tutto la necessità di revisioni umane. Il progetto di indicizzazione di Ancestry.com è un esempio di come l'apprendimento rinforzato possa ridurre la necessità di coinvolgimento umano nel tempo.\n\n## Umano nella catena (di lavorazione)\n\nQuando si sviluppa un backend di apprendimento automatico, è essenziale tenere presente le esigenze dell'utente. L'obiettivo è ottimizzare il loro processo attuale e fornire un aiuto che li aiuti a svolgere il loro lavoro in modo più efficace. Per raggiungere questo obiettivo, è fondamentale intervistare e osservare gli utenti nel loro ambiente di lavoro attuale al fine di comprendere il loro comportamento, identificare inefficienze e documentare eventuali inferenze che potrebbero non essere state documentate. In questo modo, è possibile selezionare i dati per estrarre le inferenze prima di inviarli al modello, ottenendo risultati più accurati basati sulla replicazione del comportamento umano. È importante ricordare che spesso le inferenze sono più importanti dei dati grezzi e, comprendendo il comportamento e le esigenze dell'utente, si può progettare un prodotto di intelligenza artificiale migliore.\n\nUn altro fattore chiave nell'implementazione dell'IA è il fattore umano. Si tratta di stabilire il contesto corretto durante l'implementazione dell'automazione per evitare la paura della perdita del lavoro. Come affrontare potenziali problemi tra IA e persone, come gli stakeholder che eludono l'IA messa in atto per loro. Una soluzione consiste nel progettare l'interfaccia in modo da rendere chiaro quando un utente ha esaminato un punto dati specifico e fornire sostituzioni quando necessario. Inoltre, chiedere agli stakeholder le ragioni per evitare il sistema può aiutare a migliorare il modello e prevenire l'abuso dell'API. Alla fine, l'IA e gli esseri umani possono lavorare insieme per ottenere risultati migliori.\n\nL'IA può occuparsi dei compiti semplici se è ben addestrata, e gli esseri umani possono imparare a sfruttare meglio l'IA nel tempo. Costruire interfacce collaborative che rendano l'IA un membro del team anziché un algoritmo freddo, consentendo interazioni più naturali che possono aiutarla a imparare meglio. L'IA diventerà essenziale in qualsiasi lavoro che si occupi di interlocutori che elaborano dati umani a causa della variabilità coinvolta.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Pulsipher"],"link":"/episode-EDT130-it","image":"./episodes/edt-130/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista suo figlio Matthew Pulsipher riguardo alla produttivazione dell'IA decisionale. Matthew ha di recente modernizzato e inserito nell'iter di sviluppo del prodotto l'IA decisionale."},{"id":29,"type":"Episode","title":"Trasformazione Digitale nel Governo Federale","tags":["compute","people","technology","automation","ai","cybersecurity","innovation"],"body":"\r\n\r\nMark ha lavorato con il governo federale per oltre 20 anni e ha visto di persona come le agenzie abbracciano nuove tecnologie per migliorare i loro servizi ai cittadini. Una tendenza che ha notato è un focus sull'esperienza del cliente, come l'utilizzo di applicazioni mobili per il passaporto da parte della Dogana e Protezione dei Confini. Nonostante le sfide nel portare avanti iniziative su larga scala in ambienti in continua evoluzione, Mark vede molte opportunità per il governo di accelerare la sua missione attraverso l'adozione di nuove tecnologie.\n\nCOVID ha accelerato l'innovazione all'interno del governo federale e ha messo in evidenza lacune in aree come le connessioni VPN e la sicurezza per i lavoratori remoti. Le agenzie continuano ad innovare, concentrandosi sulla tecnologia cloud e migliorando l'esperienza del cliente. L'istruzione e la comunicazione sono fondamentali per prendere decisioni informate su dove posizionare i carichi di lavoro e implementare tecnologie cloud. Nonostante le preoccupazioni che la burocrazia possa rallentare l'innovazione, i benefici dell'innovazione continuano a guidare l'innovazione all'interno del governo federale, comprese le aree cloud, edge computing, cybersecurity e supply chain sicura.\n\n## Multi-Hybrid Cloud: Multi-Cloud Ibrida\n\nC'è una tendenza crescente nell'uso del cloud multi-ibrido e alle varie sfide che ne derivano, come la sicurezza e la gestione dei dati. È stata sottolineata l'importanza di avere un piano ben strutturato per i progetti di trasformazione digitale, con la necessità di ottenere successi precoci. Un'altra innovazione è il calcolo al limite, che consente di ottenere informazioni più velocemente senza bisogno di una connessione. Alcune organizzazioni stanno attualmente lavorando per capire come sfruttare il potere del calcolo al limite per migliorare i propri servizi. Alcuni casi d'uso includono il monitoraggio dei sensori dell'acqua nell'agricoltura e l'ottimizzazione delle rotte di consegna della posta per il servizio postale degli Stati Uniti.\n\n## Automazione\n\nQuando automazione e sicurezza informatica vengono combinate, possono accelerare la capacità di un'organizzazione nel reagire alle minacce, implementare nuove capacità e fornire migliori servizi ai propri referenti. La carenza di personale dovuta al pensionamento dei baby boomer richiederà l'automazione per affrontare questa problematica. Un esempio è rappresentato da come l'automazione ha migliorato il processo di ispezione alle frontiere per prodotti ortofrutticoli e fiori, portando a tempi di lavorazione più rapidi e una maggiore durata dei prodotti sugli scaffali.\n\n## Cybersecurity in Italian is \"sicurezza informatica\" or \"sicurezza cibernetica\".\n\nL'attuale ambiente IT/OT è un panorama di minacce in continua evoluzione, con attori malintenzionati che innovano costantemente. Intel sta innovando e creando tecnologie di sicurezza hardware che crittografano i dati per proteggersi da attori malintenzionati. La cybersecurity è una priorità per il governo federale, come evidenziato dal recente comunicato stampa del Presidente Biden che sottolinea la protezione delle infrastrutture critiche come principale problema di sicurezza informatica. La gestione essenziale dell'infrastruttura negli Stati Uniti, data la struttura unica del paese e il coinvolgimento di varie entità come municipi locali e aziende private di energia. L'Agenzia per la Sicurezza delle Infrastrutture Critiche (CISA) guida la cybersecurity e stabilisce standard per sistemi sicuri a livello federale, statale e locale.\n\n## Fornitura sicura della catena di approvvigionamento.\n\nUn'altra vulnerabilità critica esposta da COVID-19 è rappresentata dai rischi geopolitici e dalle minacce alla sicurezza informatica per la catena di approvvigionamento. La trasparenza della catena di approvvigionamento di Intel permette ai clienti di verificare l'integrità dei componenti, il che è cruciale per garantire la sicurezza hardware e software. Con tali misure in atto, gli Stati Uniti stanno compiendo passi per rafforzare la propria sicurezza industriale e nazionale.\n\nLa catena di fornitura non riguarda solo gli asset fisici; software, firmware e hardware svolgono tutti un ruolo importante nella sicurezza della catena di fornitura. Tutti i componenti hanno vettori di attacco e richiedono software sicuro, materiali da costruzione, verifica dei componenti e integrità del dispositivo per la convalida: un ordine esecutivo relativo a software e materiali, a cui Intel si attiene sui loro nuovi processori. Intel fornisce tecnologie di sicurezza hardware e capacità di catena di fornitura trasparenti come parte di un'architettura a prova di zero fiducia.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Mark Valcich"],"link":"/episode-EDT131-it","image":"./episodes/edt-131/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren intervista Mark Valcich, direttore e GM del settore civile federale nel settore pubblico presso Intel. Gli anni di esperienza di Mark emergono mentre descrive le attuali tendenze nella trasformazione digitale nel governo civile federale."},{"id":30,"type":"Episode","title":"Gestione bare metal definita dal software","tags":["metify","sdi","technology","baremetal","heterogeneouscompute","compute"],"body":"\r\n\r\nCon oltre due decenni di esperienza nel settore dei data center, Ian condivide le sue conoscenze sull'ottimizzazione dell'infrastruttura, l'automatizzazione della gestione dei server e la razionalizzazione dei diversi componenti di un data center. D'altra parte, Mike, che ha lavorato precedentemente con IBM e Red Hat, si concentra sulla consulenza vendite e sulle vendite guidate dai canali per comprendere meglio i problemi e i modelli delle aziende nel gestire i loro data center. Insieme, nel 2020 hanno creato Metify per fornire soluzioni di automazione per la gestione di server, storage e dispositivi di rete nei data center, nonostante la crescita dei servizi cloud pubblici come RWC Azure e GCP.\n\n## Automazione del data center\n\nAutomatizzare la gestione del data center può avvicinare la gestione on-premise all'esperienza di un cloud pubblico, riducendo i costi. Uno degli elementi vitali di questa trasformazione è la standardizzazione e gli standard aperti come la specifica DMCA redfish per rendere possibile questa automazione. L'ubiquità di questa specifica su schede madri di classe enterprise ne ha reso l'integrazione accessibile a tutti i player del settore. Le pressioni finanziarie e le richieste degli utenti sono fondamentali nel guidare i produttori OEM verso l'implementazione di questi standard aperti. Nel complesso, l'automazione e la standardizzazione possono aiutare i data center a competere con i fornitori di servizi cloud sui costi operativi, migliorando al contempo le capacità di gestione del server.\n\nL'efficienza del datacenter può essere migliorata utilizzando strumenti che consentono l'automazione e l'integrazione con i framework standard. I fornitori hardware affrontano la pressione dovuta alla commoditizzazione della tecnologia e devono differenziarsi offrendo server white box simili ma in scala ridotta. Metify fornisce una singola interfaccia per gestire i dispositivi di qualsiasi produttore purché siano abilitati BMC e rispettino la specifica Redfish. Ci sono standard emergenti per gestire piccoli dispositivi tramite Redfish; la domanda rimane fino a che punto l'estendibilità arriva alle parti specifiche di networking dello stack.\n\n## Cloud ibrido\n\nL'aumento delle strategie di cloud ibrido guida il modo in cui le aziende gestiscono i loro data center, i punti di rete e gli ambienti cloud. La crescita del cloud pubblico è significativa; tuttavia, vi è una massiccia crescita negli spazi del cloud privato. Metify offre un'esperienza simile a quella del cloud dal punto di vista operativo, consentendo agli amministratori di sistema di gestire il loro punto di rete, il data center o più data center tramite un'API standard. Mantenere le API aperte e standardizzate è essenziale affinché i clienti possano utilizzare strumenti di gestione familiari come TerraForm e Ansible. Le tecnologie di cloud ibrido consentono alle aziende di ottimizzare costi, governance, sicurezza ed efficienza.\n\nUno dei pericoli di uno standard aperto può essere la vulnerabilità a violazioni della sicurezza senza adeguate misure di comando e controllo. Metify affronta questo problema posizionando auditabilità, autorizzazione, accesso e controlli sugli standard aperti per fornire un approccio sistematico alla gestione del bare metal su hardware eterogeneo. Il prodotto di Metify si concentra nel fornire un livello di controllo per prevenire incidenti indesiderati e si integra con strumenti di gestione dei flussi di lavoro per l'automazione.\n\n## BareMetal SDI: Rete BareMetal\n\nMolte moderne tecnologie dei data center si basano sulla virtualizzazione come fondamento del loro piano di controllo della gestione. Tuttavia, la gestione del bare metal rimane un compito tradizionale, manualmente intensivo. Questo approccio unico all'infrastruttura del cloud privato non si basa sulla virtualizzazione. Invece, utilizza l'approccio dell'infrastruttura definita dal software per la gestione del bare metal, consentendo una combinazione di bare metal, VM e container. Questo approccio consente agli amministratori di sistema di gestire l'infrastruttura sottostante in modo più efficace e di fornire un'esperienza cloud senza attriti. Questo approccio può supportare ambienti di elaborazione eterogenei, in cui la CPU, la GPU, la FPGA, la VPU e le NPU possono essere utilizzate per più flussi di lavoro. Con Redfish e un'estensione dello schema, Metify può facilmente controllare nuovi dispositivi e vedono l'ecosistema in espansione come incredibilmente prezioso per lo sviluppo di prodotti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ian Evans","Mike Wagner"],"link":"/episode-EDT132-it","image":"./episodes/edt-132/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista i fondatori di Metify, Ian Evans e Mike Wagner, riguardo al loro approccio unico alla gestione dell'infrastruttura software-defined bare metal utilizzando lo standard Redfish."},{"id":31,"type":"Episode","title":"Lezioni in HPC Oil & Gas","tags":["compute","hpc","people","innovation","cloud"],"body":"\r\n\r\nKeith aveva lavorato nell'industria per tutta la sua carriera e si è unito a Intel lo scorso luglio. Ha guidato il gruppo di High-Performance Computing di Consolidated Resources dal 1999, dove hanno iniziato con solo un decimo di un teraflop di potenza di calcolo. Tuttavia, Keith è riuscito a consolidare con successo più siti e ha stabilito che il loro team è fondamentale per le operazioni di esplorazione, sviluppo e produzione di petrolio e gas di BP. Negli ultimi tre decenni di lavoro nell'high-performance computing per il settore petrolifero e del gas, Keith ha avuto tre fattori che influenzano la direzione dell'HPC: cloud computing, carenza di talento umano e il bilanciamento tra collaborazione e vantaggio del primo arrivato.\n\n## Cloud o su infrastruttura locale\n\nKeith condivise la sua esperienza nella costruzione di una struttura HPC (High-Performance Computing) per BP. La costruzione durò quasi nove anni, con i primi sette dedicati al riadattamento della struttura esistente e alla creazione di un business case per una struttura dedicata. Nonostante l'avvento della tecnologia cloud, trovarono l'esecuzione della loro struttura conveniente in termini di costi grazie al controllo delle risorse e all'architettura personalizzata. Essere nell'industria del petrolio e del gas presentava sfide uniche nel gestire grandi quantità di dati, ma avere una struttura dedicata permetteva loro di concentrarsi sulle esigenze di ricerca di BP. Questi fattori sono rilevanti anche per altre industrie che operano con cluster HPC.\n\nLa grande domanda per chiunque gestisca un cluster HPC è se i carichi di lavoro HPC possano essere eseguiti con successo sui servizi cloud generali. Questo dipende dalle specifiche esigenze dell'azienda e dalla scala del carico di lavoro preso in considerazione. Mentre alcune aziende possono trovare pratico collaborare con il cloud per i picchi di domanda, altre richiedono un cluster grande e completamente utilizzato per soddisfare le proprie esigenze. Fattori come le prestazioni predictive, la gravità dei dati, la dimensione dei dati e il costo delle operazioni sono fattori essenziali nella posizionamento dei carichi di lavoro HPC.\n\n## Combattere la carenza di risorse\n\nAcquisire e trattenere talenti nell'elaborazione ad alte prestazioni è una sfida, specialmente con il pensionamento della generazione dei baby boomer. Keith suggerisce che creare relazioni con le università e identificare individui talentuosi in anticipo è critico per sviluppare le competenze necessarie all'interno di un'organizzazione. Le organizzazioni devono pensare a lungo termine nella creazione di squadre di successo nell'HPC e attraverso il mentoring. In questi gruppi eterogenei, scienziati, ingegneri di sistema, matematici e ingegneri informatici lavorano insieme per anni anziché mesi.\n\nCostruire impegni a lungo termine investendo in tirocini, percorsi professionali e borse di studio è fondamentale per creare un ambiente lavorativo orientato alla carriera. Keith condivide una sfida che hanno affrontato nel creare una visione condivisa per il futuro del loro team, ma ha trovato successo nel costruire una rete di contatti al di fuori di BP per aiutarli a raggiungere i loro obiettivi.\n\n## Primo vantaggio di chi si muove per primo, Condivisione\n\nUn altro aspetto critico dell'HPC nell'industria petrolifera e del gas è avere il vantaggio di essere il primo a muoversi. Trovare una nuova tecnica per scoprire nuove fonti di energia può far risparmiare all'azienda miliardi di dollari. Tuttavia, condividere informazioni con i concorrenti può anche portare a scoperte che aiutano l'industria. Questo è un equilibrio importante che i professionisti dell'HPC devono comprendere per ottenere il massimo dai loro lavori.\n\nKeith condivide una storia divertente su come i loro amici hanno aiutato a sviluppare una tecnologia innovativa per capire meglio le strutture geologiche sottosuperficiali del Golfo del Messico al fine di trovare petrolio e gas. Nonostante la competizione che osservava e metteva in discussione i loro metodi, gli esperimenti di BP sono risultati vincenti. Keith spiega che tutti sono attenti quando fai qualcosa di nuovo in campo.\n\nAd esempio, spesso hanno stipulato contratti con aziende come PGS per acquisire dati e l'innovativa soluzione di utilizzare elicotteri e hard disk per consegnare i dati appena acquisiti per l'elaborazione. I risultati sono stati impressionanti, mostrando risultati migliori rispetto ai metodi tradizionali. Quando gli viene chiesto del futuro dell'HPC nell'industria, Keith crede che la collaborazione continuerà ad essere necessaria, sia attraverso cluster condivisi che collaborando su benchmark scientifici fondamentali. Nonostante le sfide, l'industria dell'HPC è eccitante e ci sono grandi opportunità per le persone di mettere in campo le proprie competenze computazionali e la volontà di risolvere problemi impegnativi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Keith Gray"],"link":"/episode-EDT133-it","image":"./episodes/edt-133/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Keith Gray, un ex direttore di high-performance computing presso British Petroleum. Con oltre 30 anni di gestione dei centri HPC, Keith offre una grande prospettiva sulle sfide, le migliori pratiche e il futuro dell'high-performance computing."},{"id":32,"type":"Episode","title":"WaveForm AI","tags":["collectiongenerativeai","artificialintelligence","waveformai","datashapes","waveform","technology"],"body":"\r\n\r\nLogan è un ex ufficiale di intelligence nel DOD ed ha una passione per l'IA e la robotica, che lo ha portato a diventare un riservista nella comunità della difesa. Si è poi trasferito a DataShapes, dove hanno una tecnologia unica che risolve esigenze critiche nella comunità della difesa utilizzando l'IA. Mentre l'IA esiste da molto tempo, la vasta quantità di dati disponibili per l'addestramento dei modelli e l'avanzamento delle risorse di calcolo hanno portato allo sviluppo di sistemi più intelligenti come chatbot e grandi modelli di lingua.\n\nLe attuali tecniche sono esose in termini di risorse e molto costose da addestrare e costruire una soluzione di inferenza di utilizzo generale. Ad esempio, eseguire grandi modelli di linguaggio come ChatGPT può costare fino a 3 milioni di dollari al giorno, ma l'intelligenza artificiale sta evolvendo rapidamente e ricevendo più attenzione che mai. Una preoccupazione nell'utilizzo delle reti neurali è l'incapacità di sottoporre a revisione ed spiegare come l'IA ha raggiunto un risultato. Ci sono sfide sociali, politiche e legali nel fidarsi delle decisioni prese da queste reti, in particolare in campi in cui è in gioco la vita umana. Tuttavia, la società supererà eventualmente queste sfide e abbraccerà completamente l'IA. L'approccio di DataShapes, che utilizza tecniche tradizionali di apprendimento automatico per risolvere i problemi nell'analisi dei dati, offre piena auditabilità e scoperta nei loro modelli addestrati.\n\nDataShapes ha un approccio unico per risolvere problemi in modo rapido ed efficiente in ambienti con risorse limitate. Mentre l'addestramento tradizionale delle reti neurali richiede molte etichette e può presentare fragilità, DataShapes utilizza metodologie per imparare in tempo reale o quasi in tempo reale. La loro tecnologia si concentra su forme d'onda e segnali ed è verificabile, rendendola ideale per l'uso in ambienti austeri dove le persone si sporcano e portare una pila di server è impossibile. Mentre le reti neurali sono eccellenti per modelli di linguaggio e riconoscimento delle immagini, l'azienda di Logan è iper-focalizzata su forme d'onda e segnali. Il loro approccio è diverso e altamente efficace.\n\nRilevare diversi tipi di forme d'onda e relazioni nelle forme d'onda è al centro di questa nuova tecnologia. Questo approccio rileva schemi più difficili da falsificare rispetto alle tecniche tradizionali utilizzate dal Dipartimento della Difesa. Questo ha il potenziale per applicazioni della loro tecnologia nella guerra elettronica, incluso il rilevamento di informazioni e analisi. Inoltre, la piattaforma può rilevare, analizzare e raccogliere informazioni, che possono essere esportate su dispositivi periferici. È stato anche menzionato il loro elemento di rilevamento di anomalie ad apprendimento automatico, Infinite Loop, che stabilisce una linea di base continua basata sui parametri prescritti dall'utente finale. La tecnologia può essere utilizzata nelle industrie automobilistiche, sanitarie e dell'intrattenimento, dove potrebbe essere incorporata in ogni sensore.\n\nDataShapes ha un prodotto chiamato GlobalEdge, un agente intelligente che si trova su o dietro i sensori per condurre operazioni ETL per i dati raccolti. Il componente di apprendimento automatico di GlobalEdge filtra i dati per fornire insight rilevanti e anomalie in tempo reale, riducendo la quantità di dati non rilevanti che vengono inviati a sede centrale. Il prodotto può anche essere utilizzato per la compressione dei dati sulla periferia fino al data center. Il software può ridursi fino a soli 47 K, rendendolo adatto a una varietà di applicazioni, tra cui la rilevazione di virus mediante onde UV.\n\nPer saperne di più su DataShapes e il loro approccio, visita https://www.datashapes.com\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Logan Selby"],"link":"/episode-EDT134-it","image":"./episodes/edt-134/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren Pulsipher dà il benvenuto a Logan Selby, co-fondatore e presidente di DataShapes, dove discutono di un approccio unico all'Intelligenza Artificiale che si distingue dalla tendenza comune."},{"id":33,"type":"Episode","title":"AI affidabile ed etica","tags":["ai","ethics","trustworthiness","deepfake","aicontent","aidetection"],"body":"\r\n\r\nNegli ultimi anni del 2010, Microsoft ha rilasciato Tay come chatbot AI progettato per imparare dalle sue conversazioni con gli utenti su Twitter. Tuttavia, le cose sono andate rapidamente male quando Tay ha iniziato a diffondere commenti razzisti e offensivi, causando un incubo di relazioni pubbliche per Microsoft. Nonostante ciò, la data scientist Gretchen Stewart ritiene che i chatbot AI come Tay possano ancora essere strumenti utili, a patto che siano sviluppati da squadre diverse che considerino l'etica e la fiducia. Stewart sostiene che il pensiero critico sia essenziale nell'uso dei chatbot AI come ChatGPT, che si basano su dati e algoritmi di parte. Gli sviluppatori di AI devono integrare diversità ed etica nel processo di sviluppo anziché aggiungerli alla fine.\n\n## Affidabilità.\n\nL'IA ha immense capacità ma ancora manca dei sensi umani e delle esperienze che possono influenzare la presa di decisioni. Ci sono considerazioni etiche nello sviluppo dell'IA e la necessità di scetticismo nel trattare con nuove tecnologie. Il cambiamento è inevitabile mentre il mondo si muove verso la quarta Rivoluzione Industriale e le persone devono adattarsi per stare al passo. Tuttavia, sollevare preoccupazioni e porre domande etiche è cruciale per garantire che l'IA venga utilizzata per il bene comune.\n\nCi sono pericoli potenziali nel fare affidamento sull'intelligenza artificiale (AI) come fonte di informazioni. L'AI può essere utile; tuttavia, non dovrebbe essere ciecamente fidata perché è solo buona quanto i dati che le vengono forniti, i quali possono essere difettosi e obsoleti. Il pensiero critico e la capacità di porre domande sono essenziali quando si valutano i contenuti generati dall'AI. Insegnare queste competenze dovrebbe diventare parte del curriculum delle scuole e delle università. Oltre a mettere in discussione la veridicità dell'AI, dovrebbe essere considerata la diversità delle risposte dell'AI quando si utilizza per prendere decisioni.\n\n## Etica\n\nContinuando a progredire, la tecnologia continua a sollevare nuove questioni etiche. Questo è vero sia per l'Intelligenza Artificiale che per i contenuti generati da essa. Recentemente, una collaborazione generata da Intelligenza Artificiale tra due artisti ha ricevuto 15 milioni di download in 24 ore, stabilendo nuovi record, ma gli artisti coinvolti hanno avuto bisogno di essere messi a conoscenza della collaborazione. Ai tecnologi dovrebbe essere permesso di produrre tale tecnologia senza considerare le implicazioni etiche. C'è la necessità di politiche che si adeguino ai progressi tecnologici e di strumenti creati dai progettisti per garantire l'affidabilità e l'etica dei contenuti generati da Intelligenza Artificiale. Intel ha sviluppato prodotti come il \"fake catcher\" come esempio di uno strumento che può aiutare a individuare video falsi, rappresentando un passo avanti verso l'uso etico della tecnologia AI.\n\nCombattere i contenuti falsi generati da intelligenza artificiale (IA) è diventato un'intera industria a sé stante e richiede trasparenza nello sviluppo dell'IA. Ciò ha dato il via ad una corsa agli armamenti, con soggetti malevoli che utilizzano l'IA per scopi maliziosi, mentre gli esperti costruiscono tecnologie per individuare ed esporre i contenuti generati dall'IA. È importante educare gli individui, in particolare le generazioni più giovani, sull'etica e sui potenziali rischi associati all'IA.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart"],"link":"/episode-EDT135-it","image":"./episodes/edt-135/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Gretchen Stewart, Chief Data Scientist del settore pubblico presso Intel, dove discutono dell'affidabilità ed etica dell'intelligenza artificiale."},{"id":34,"type":"Episode","title":"Dati resilienti nelle comunicazioni disruptive","tags":["sabr","ddil","technology","edge","process","devops","security"],"body":"\r\n\r\nIn questo episodio del podcast, Darren Pulsipher, chief solution architect del settore pubblico di Intel, viene intervistato dalla conduttrice ospite, la dottoressa Anna Scott, sul tema dei dati resilienti con le comunicazioni disruptive. La discussione si incentra sulla gestione sicura ed efficiente dei dati in ambienti con banda limitata e servizio interrotto, consentendo l'intelligenza artificiale e l'analisi complessa dei dati in periferia. Darren parla della sua esperienza lavorando sul cloud dei veicoli connessi di Toyota come base per risolvere questo problema e di come siano stati utilizzati gli architetti comuni di gestione dei dati per creare una soluzione. La graduale rivelazione delle sfide da parte del cliente ha contribuito a identificare schemi progettuali che hanno aperto l'architettura per una soluzione di successo.\n\nNonostante la connettività intermittente e i nodi di bordo dinamici, il processo di progettazione dell'architettura per eseguire l'analisi dei dati di bordo è complesso e difficile da esporre, quindi hanno adottato un approccio iterativo. Inizialmente hanno considerato una soluzione che avrebbe portato tutti i dati in un unico luogo per l'analisi, ma hanno riscontrato che risultava impraticabile a causa del volume di dati. Spostare le applicazioni verso il bordo sembrava promettente finché il cliente non ha richiesto l'analisi aggregata su tutto il bordo. Dopo aver esplorato modelli di progettazione, hanno scelto di utilizzare il modello di progettazione a flusso di dati con un hub di pubblicazione e sottoscrizione per creare flussi di dati in modo dinamico per consumatori e produttori. Nonostante questo approccio si basasse su fondamenta consolidate nell'ambito IT, il cliente inizialmente aveva preoccupazioni riguardo all'allocazione degli argomenti.\n\nIn passato, Darren doveva creare in anticipo un ecosistema PubSubHub e essere familiare con tutti i suoi componenti. Tuttavia, configurare flussi di dati con Kafka o Apache Pulse era una sfida, e configurare la sicurezza era ancora più difficile. Utilizzando la loro esperienza in DevSecOps per ideare una soluzione che racchiude definizioni di flussi di dati, definizioni di input e output e trasformazioni di dati in un pacchetto consumabile dalla pipeline. Questo pacchetto crea automaticamente flussi di dati in PubSubHub e configura tutte le misure di sicurezza necessarie. Il risultato semplifica la complessità poiché gli sviluppatori devono solo concentrarsi su algoritmi o modelli di intelligenza artificiale, mentre tutto il resto viene gestito in modo generico. L'approccio iterativo con i clienti ha aiutato a modificare architetture e implementazioni lungo il percorso.\n\nLa sfida principale con questo tipo di architettura è lavorare con risorse limitate, come ad esempio avere accesso solo a due core e 2 gigabyte di RAM. Quanta elaborazione dei dati può avvenire al limite delle risorse? Uno dei vincoli su cui il team di architettura ha dovuto lavorare riguardava la riduzione al minimo del gestore di flusso SABR e delle misure di sicurezza. Darren ha ridotto il codice al minimo indispensabile ed eliminato pacchetti terzi non necessari. L'obiettivo era creare un gestore di flusso leggero che potesse essere eseguito al limite delle risorse e portabile su diversi ambienti. L'architettura di Saber risultante era scalabile e adattabile, in grado di funzionare sia su un orologio smart che su un grande server Xeon.\n\nDarren e Anna discutono delle difficoltà nell'aggiornare i modelli di intelligenza artificiale in un ecosistema distribuito con numerose istanze delle stesse analisi in esecuzione. Per risolvere questo problema, SABR ha creato uno stream di dati di apprendimento che connette tutte le istanze delle stesse analisi e si occupa di comunicazioni intermittenti, caching e invio dei delta per aggiornare i modelli. Hanno inoltre sviluppato un sistema di canali di dati utilizzando il design pattern di strategia di politica, consentendo l'invio di diversi canali con livelli di dati variabili in base a regole definite dalla politica. Questo approccio permette una trasmissione dei dati più efficiente, riducendo la quantità di dati elaborati e aumentando l'accuratezza dei modelli di intelligenza artificiale.\n\nIl prossimo passo è capire come operare nell'ambiente DDIL dando priorità all'invio di dati inviando prima dei riepiloghi e dati storici prima dei dati in tempo reale. È importante definire le aspettative del sistema e le politiche di comunicazione fin dall'inizio per garantire coerenza nell'ecosistema. Un processo di creazione e attivazione delle politiche semplice da usare, configurato in JSON e basato su JavaScript, che elimina la duplicazione degli sforzi e favorisce il riutilizzo. L'architettura ha la capacità di aggiungere rapidamente nuove funzionalità sfruttando le frecce e le trasformazioni dei dati esistenti.\n\nL'ultimo elemento è la resilienza del sistema nel recuperare dinamicamente dai guasti del sistema. Potenzialità di utilizzo dinamico e flessibile della rete SABR. Anche se un nodo va giù, è possibile spostare un SABR su un'altra macchina e continuare a ricevere tutti i flussi di dati. È anche possibile utilizzare elaborazioni obsolete eseguendo un SABR molto leggero su un vecchio sistema che raccoglie e passa i dati attraverso la rete SABR. Non va sottovalutata l'importanza della sicurezza. Tutti i flussi di dati sono crittografati e vengono impostati processi per stabilire la fiducia e l'attestazione dei SABR al fine di prevenire il falsificare e lo spionaggio dei dati. Complessivamente, la rete SABR offre una soluzione promettente per l'elaborazione dei dati al limite con flessibilità e sicurezza.\n\nLa chiave dell'apprendimento è l'approccio architettonico iterativo che il team ha utilizzato per scoprire i casi d'uso e i punti critici che gli utenti finali stavano affrontando. Simulando l'architettura, sono riusciti a individuare le lacune e ottenere un feedback dai clienti. Inoltre, l'utilizzo dei pattern di progettazione è stato fondamentale per accelerare l'approccio architettonico. L'uso dell'astrazione ha inoltre fornito la possibilità di sostituire diverse tecnologie durante il processo architettonico. Darren crede che questo approccio abbia reso facile creare soluzioni facili da usare e sfruttare la conoscenza attuale dei clienti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT136-it","image":"./episodes/edt-136/it/thumbnail.png","lang":"it","summary":"In questo episodio di podcast, Darren Pulsipher, architetto delle soluzioni principale di Intel per il settore pubblico, viene intervistato dalla conduttrice ospite Dr. Anna Scott sulla resilienza dei dati con le comunicazioni disruptive."},{"id":35,"type":"Episode","title":"Rinascita del Cloud Privato","tags":["cloud","computing","greenlake","hpe","multicloud","hybridcloud","technology"],"body":"\r\n\r\nC'è stata una tendenza verso il rimpatrio nel settore commerciale, in cui le aziende stanno riportando carichi di lavoro e macchine virtuali dalle ambientazioni cloud pubbliche per motivi finanziari, come addebiti di uscita e pianificazione dei carichi di lavoro a iperscalatori. La sovranità dei dati, le preoccupazioni per la sicurezza, le prestazioni e i problemi di latenza hanno anche portato molte aziende a spostarsi dal cloud pubblico alle tecnologie cloud private. Nonostante questo cambiamento, molte promesse del cloud sono state mantenute per fornire facilità d'uso, elasticità e prezzi basati sul consumo. Al fine di agevolare la transizione tra i cloud, il cloud privato deve offrire facilità d'uso, portabilità dei carichi di lavoro e nuovi modelli di pricing basati sul consumo, tanto richiesti dai cloud pubblici.\n\n## Controllo dei costi\n\nSam Ceccola, il CTO per il Dipartimento della Difesa di HPE, ritiene fondamentale comprendere i rischi e le sfide associate a ciascuna tecnologia cloud privata, pubblica e ibrida. E progettare soluzioni che sfruttino i punti di forza di ciascuna tecnologia. È qui che entra in gioco l'offerta di produzione di HPE, GreenLake. Il modello di approvvigionamento dei servizi basato sul consumo di GreenLake è stato implementato per la prima volta nel 2005 e da allora si è evoluto includendo un portale self-service per la gestione di più ambienti cloud privati e pubblici. GreenLake offre ai clienti la possibilità di distribuire risorse aggiuntive oltre il confine tra cloud privato e pubblico su richiesta. Gestisce anche e visualizza costi complessi, come addebiti di uscita e pianificazione del budget per carichi di lavoro iperscala.\n\n## Gestione dei dati\n\nUn'altra preoccupazione di grande rilevanza per la maggior parte dei consumatori di cloud pubblici riguarda la gestione dei dati, la governance e la sovranità. Senza una strategia coesa per i dati, molte organizzazioni sono gravemente appesantite dai costi di egresso dati, ovvero il movimento dei dati dentro e fuori dai cloud pubblici. Esistono diverse approcci per gestire i dati attraverso i confini dei cloud. HPE utilizza un approccio di archiviazione adiacente al cloud che riduce al minimo la quantità di dati spostati nel cloud. L'archiviazione adiacente al cloud di GreenLake mantiene i dati in loco mentre esegue carichi di lavoro di calcolo nel cloud. Questo approccio garantisce la sovranità dei dati e riduce i costi di uscita e i problemi di latenza associati allo spostamento di grandi quantità di dati tra i cloud.\n\n## Portabilità\n\nUn altro aspetto chiave delle architetture multi-ibride di cloud è la capacità di spostare facilmente i carichi di lavoro tra i cloud. Alcune organizzazioni hanno adottato architetture a microservizi basate su container senza stato per fornire la flessibilità e la portabilità dei carichi di lavoro. Tuttavia, non tutti i carichi di lavoro possono essere facilmente containerizzati, soprattutto quelli che contengono applicazioni con stato. In questi casi, vengono utilizzate macchine virtuali per consentire il trasferimento delle applicazioni da un cloud all'altro. Lo spostamento delle VM tra i cloud può presentare problemi in quanto i fornitori di servizi cloud utilizzano diversi ipervisori e processori che potrebbero non essere completamente compatibili. Comprendere le limitazioni di queste migrazioni è fondamentale nelle decisioni di acquisto di hardware, sia virtualizzato che non virtualizzato.\n\n## Sicurezza\n\nGreenLake non limita i clienti all'implementazione in loco, in quanto consente loro di fornire carichi di lavoro su varie piattaforme cloud, tra cui Amazon, Google e Azure. Inoltre, GreenLake supporta carichi di lavoro ibridi reali, in cui un carico di lavoro può essere eseguito sia in loco che contemporaneamente in ambienti cloud iperscalari. L'esecuzione di carichi di lavoro oltre i confini cloud può causare un'esposizione aggiuntiva agli attacchi informatici. Comprendere i modelli di sicurezza delle diverse tecnologie cloud pubbliche e private può essere un compito arduo e aumenta il capitale umano necessario per progettare ed gestire una posizione di sicurezza forte in modo efficace. La piattaforma GreenLake gestisce la sicurezza attraverso il suo motore di sicurezza agnostico, Security Central, che supporta l'attestazione multi-cloud e architetture di fiducia zero per cloud indipendenti, gestendo la complessità e l'integrazione dei modelli di sicurezza.\n\nArchitettare una soluzione multinuvola ibrida non è banale e richiede una comprensione delle tecnologie cloud private e pubbliche, delle loro limitazioni e dei loro punti di forza. Fortunatamente, ci sono organizzazioni come HPE che lavorano con architetture multinuvola ibrida da diversi anni e hanno imparato tutti i dettagli sulla gestione efficace dei carichi di lavoro in questo nuovo ambiente flessibile.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sam Ceccola"],"link":"/episode-EDT137-it","image":"./episodes/edt-137/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Sam Ceccola, CTO di DOD per HPE, riguardo ai nuovi modelli di business e tecnologia che stanno cambiando il modo in cui le organizzazioni consumano il cloud ibrido."},{"id":36,"type":"Episode","title":"Evoluzione del cloud","tags":["cloud","computing","dell","multicloud","hybridcloud","technology"],"body":"\r\n\r\nL'evoluzione del cloud computing è uno dei progressi tecnologici più significativi dell'ultima decade. Il cloud sta passando da un semplice concetto ad un sistema complesso e ubiquo che oggi domina le operazioni e le strategie aziendali. Come ci dice Ken White di Dell Technologies, il cloud non è più una singola posizione o una soluzione universale. Invece, è tutto, ovunque.\n\nCon iper scalers come Amazon e Azure in costante espansione, il cloud rappresenta un'esperienza coerente su tutte le piattaforme, con una previsione delle prestazioni e dei costi. Tuttavia, esistono tariffe nascoste, in particolare quando si sposta dati dentro e fuori dal cloud. È essenziale per le aziende che considerano il cloud adottare pienamente una mentalità orientata al cloud che si preoccupi di coerenza e previsione, oltre che di flessibilità, prestazioni e sicurezza. Mentre alcuni dirigenti sono attratti dal cloud per il suo potenziale di ridurre i costi e la gestione dell'IT, è essenziale ricordare che non può risolvere ogni problema e non è una strada a senso unico. Il cloud può migliorare in ultima analisi le operazioni, aumentare l'efficienza e offrire un'esperienza migliore sia per le aziende che per i clienti, a condizione che si adotti una mentalità operativa ben pianificata.\n\nSe sei nel mondo degli affari, probabilmente hai sentito parlare del cloud, ma hai mai sentito parlare della mentalità del cloud? È un modo di approcciarsi alla tecnologia che favorisce adattabilità, portabilità e prevedibilità riguardo ai carichi di lavoro e ai costi del cloud. Ciò significa che puoi sviluppare applicazioni portatili su diversi ecosistemi e scegliere dove posizionare i carichi di lavoro in base alle esigenze aziendali, non solo ai vincoli tecnici. Significa anche che puoi prevedere e controllare i costi, un sollievo benvenuto in un panorama tecnologico in continua evoluzione.\n\nMa cambiare mentalità è una sfida, soprattutto per le organizzazioni abituate a operare in un modo particolare. Questo è dove entra in gioco la formazione e l'impegno verso l'apprendimento continuo. Le organizzazioni che adottano con successo la mentalità del cloud danno priorità a un'esperienza utente positiva, sono disposte ad adattarsi a nuove architetture, imparano e cambiano al passo con l'evoluzione della tecnologia.\n\nAdottare la mentalità del cloud non significa dover licenziare tutti i dipendenti del settore IT e spostare tutto sul cloud. Invece, si tratta di formare la propria forza lavoro e ripensare la filosofia organizzativa. Con uno strato di gestione adeguato e un'attenzione alla flessibilità e all'agilità, le organizzazioni possono sbloccare i vantaggi del cloud per le loro attività e migliorare l'esperienza dei propri utenti finali, che siano sviluppatori o clienti.\n\nConsiderando una strategia basata sul cloud, devi capire che potresti incorrere in fallimenti. La migrazione delle applicazioni verso il cloud non è sempre semplice e può comportare dei costi. Tuttavia, le tue possibilità di successo aumentano notevolmente con la corretta coerenza e governance.\n\nLa coerenza non significa necessariamente una singola finestra, ma implica avere un processo standard per la gestione e la distribuzione dei carichi di lavoro e delle infrastrutture. Inoltre, comprende la coerenza con la governance, i processi e i flussi di lavoro. Questo livello di coerenza garantisce che tutti all'interno della tua organizzazione comprendano come gestire il cloud.\n\nI fallimenti nell'adozione del cloud sono solo talvolta evitabili, ma la riportazione potrebbe essere un'opzione per riportare il carico di lavoro a una soluzione in loco. Tuttavia, questa opzione può essere costosa, quindi è essenziale valutare i benefici a breve e lungo termine.\n\nI contenitori possono anche fare la differenza nell'adozione del cloud eliminando i problemi associati al trasferimento delle applicazioni nel cloud. Ma ricorda, non esiste una soluzione unica che risolverà tutti i problemi legati all'adozione del cloud.\n\nNel complesso, la chiave per avere successo con una strategia cloud è di concentrarsi sulla coerenza e sulla comprensione dei costi coinvolti nel passaggio al cloud. Tenendo presente questi fattori, le tue possibilità di successo sono molto maggiori.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sam Ceccola"],"link":"/episode-EDT138-it","image":"./episodes/edt-138/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Ken White di Dell Technology su come la tecnologia Cloud sia più di una tecnologia, ma un cambiamento di processo e culturale nelle organizzazioni."},{"id":37,"type":"Episode","title":"Analisi logistica resiliente","tags":["data","analytics","artificialintelligence","pathway","technology"],"body":"\r\n\r\nSiete interessati a scoprire come la trasformazione digitale stia influenzando la logistica? In questo episodio di \"Abbracciando la Trasformazione Digitale\", il nostro ospite speciale Adrian Kosowski, responsabile dei prodotti presso Pathway, parlerà di analisi resilienti nella logistica. Pathway si concentra nello studio dei sistemi reali da una prospettiva di calcolo distribuito e lavora in particolare con i dati nel settore della logistica e dei trasporti. Una delle sfide più grandi in questo campo è l'aggregazione dei dati su larga scala e la loro interpretazione, ed è qui che entrano in gioco le analisi di apprendimento automatico. Kosowski sottolinea inoltre che la logistica è un mercato altamente concentrato, controllato da poche aziende, il che fa sì che anche piccoli miglioramenti nei processi abbiano un valore incredibile per l'economia mondiale. Tuttavia, raccogliere dati dall'estremità più remota, come i container in mezzo all'oceano, presenta le sue sfide, come l'ottimizzazione dell'energia e delle comunicazioni per dispositivi IoT alimentati a batteria. In sintesi, se siete interessati all'intersezione tra logistica e trasformazione digitale, questo episodio offre interessanti spunti sulle sfide e opportunità di questo settore.\n\nL'uso dei dispositivi Internet of Things (IoT) nell'industria della logistica e della supply chain può apportare notevoli benefici alle aziende, offrendo visibilità end-to-end e una capacità migliorata di analisi. Tuttavia, ci sono diverse sfide legate all'uso di questi dispositivi che devono essere affrontate.\n\nUna delle sfide principali è la stabilità e l'affidabilità di questi dispositivi periferici. In caso di guasto o crash del dispositivo, le aziende dovrebbero avere un modo per ottimizzare questi dispositivi senza dover indovinare o eseguire operazioni in modo sbagliato. Questo è particolarmente critico per i sistemi in tempo reale che vengono utilizzati per gestire eventi in ordine.\n\nUn altro problema è l'accuratezza dei dati raccolti dai dispositivi IoT. Alcuni dati possono essere dedotti, e potrebbe essere necessaria un'analisi contestuale per interpretare il significato di un determinato punto dati e distinguere problemi di misurazione da problemi di processo. Dati inaccurati o non tempestivi possono portare a rischi nella catena di approvvigionamento e rendere difficile ottimizzare la rete di trasporto.\n\nTuttavia, l'ampio utilizzo dei dispositivi IoT può portare a una visibilità e osservabilità end-to-end dei processi lungo tutta la catena di approvvigionamento. Questo può aiutare le aziende ad ottimizzare i propri processi e adottare un approccio proattivo. Questo può beneficiare tutti gli attori della catena di approvvigionamento - dai fornitori di trasporti e logistica ai rivenditori e ai produttori.\n\nMentre non esiste un gruppo o segmento specifico che le imprese dovrebbero mirare per l'adozione dei dispositivi IoT, una diffusa adozione e cooperazione da parte di tutti gli attori può portare significativi benefici per la catena di approvvigionamento globale.\n\nIl Pathway è stato sviluppato per affrontare le carenze nelle tecnologie esistenti di streaming dei dati e fornire uno strumento per l'elaborazione avanzata dei flussi di dati. Una delle caratteristiche chiave che differenzia Pathway è la facilità di descrivere la logica come se fosse destinata a un sistema batch, assicurandosi anche che funzioni in un sistema in tempo reale con dati fuori sequenza.\n\nIl percorso è stato sviluppato con l'IoT data in mente, ma può gestire anche dati provenienti da monitoraggio video, monitoraggio delle prestazioni del server, monitoraggio dei log e altre entità fisiche. Ciò consente di gestire in modo cloud-agnostico la complessità dei dati in termini di rilevamento delle anomalie, avvisi con dati fuori sequenza e dati con elementi di serie temporale e geospaziali.\n\nUn'altra importante caratteristica di Pathway è la possibilità di utilizzare script Python per l'analisi dei flussi di dati sia in tempo reale che in modalità batch. Ciò significa che gli scienziati dei dati e gli ingegneri possono sviluppare i loro flussi di analisi nell'ambiente di sviluppo normale a cui sono abituati, e lavorare comodamente con il sistema di streaming. Inoltre, Pathway permette di considerare una quantità molto maggiore di dati storici durante l'esecuzione dei calcoli, il che rappresenta una grande differenza rispetto ai processori di flussi leggeri che gestiscono solo piccole quantità di dati.\n\nComplessivamente, Pathway offre una soluzione di collegamento per le organizzazioni che hanno bisogno di combinare l'elaborazione dei dati batch e in tempo reale e fornisce un modo per aggiungere valore ai dati attraverso l'aggiunta di struttura e informazioni estensive per un utilizzo successivo nell'intelligence aziendale e nell'analisi.\n\nLa tecnologia di Data Streaming sta diventando sempre più importante mentre le aziende cercano di prendere decisioni più velocemente e rispondere più prontamente alle esigenze dei clienti. Quando si utilizza il data streaming, è possibile rilevare e rispondere rapidamente a tendenze, anomalie e altre informazioni importanti. Pathway offre una serie di prodotti appositamente progettati per lavorare con dati di serie temporali, dati logistici e data streaming. Offrono esempi e informazioni per sviluppatori su GitHub, così come una vivace comunità su Discord.\n\nIl data streaming è una tecnologia fondamentale per le aziende in una vasta gamma di settori. Ad esempio, può essere utilizzato nella logistica per ottimizzare le rotte e prevedere quando arriveranno le spedizioni. In campo finanziario, può aiutare a individuare frodi e prevedere le tendenze di mercato prima che diventino ampiamente note. Nel trasporto, può essere utilizzato per monitorare in tempo reale le prestazioni dei motori e dei veicoli.\n\nSe sei interessato a saperne di più sul data streaming e su come può beneficiare la tua azienda, assicurati di visitare il sito web e la comunità di Pathway [www.pathway.com]. Con gli strumenti e l'esperienza giusti, puoi sfruttare questa potente tecnologia per migliorare le tue operazioni e restare al passo con i tempi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Adrian Kosowski"],"link":"/episode-EDT139-it","image":"./episodes/edt-139/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Adrian Kosowski, CPO di Pathway, riguardo alla loro capacità unica di gestire dati logistici dal bordo in ambienti DDIL con analisi in tempo reale."},{"id":38,"type":"Episode","title":"Avviare la tua trasformazione organizzativa per diventare centrati sui dati.","tags":null,"body":"\r\n\r\n## Operazionalizzare il sistema di analisi\n\nLa prima cosa da capire sul processo di operationalizzazione dell'analisi è che è complesso. Alcune persone pensano che i dati siano la nuova elettricità e funzionino in un sistema simile. Considera questo esempio: in un semplice sistema elettrico, c'è una fonte di alimentazione e alcuni fili che vanno ad una lampadina. Finché c'è la fonte di alimentazione e i fili sono di alta integrità, puoi spegnere la luce e, sei mesi dopo, tornare e premere l'interruttore, sapendo che la lampadina si accenderà di nuovo.\n\nUn sistema analitico non funziona in questo modo. Ci sono molti tipi di \"cortocircuiti\" e variabili che possono causare un fallimento, come l'entropia. È importante avere le persone giuste nel proprio team che possano lavorare e comprendere tutti i diversi tipi di guasti che possono verificarsi, altrimenti non otterrai un'analisi corretta o utile.\n\nI tuoi dati devono essere formattati in un certo modo per gli algoritmi di apprendimento automatico. L'algoritmo deve comprendere cosa rappresentano i dati per analizzare correttamente il pattern. A meno che i dati non siano attentamente formattati, c'è il rischio di avere output non attendibili. È qui che i tuoi ingegneri, i data scientist e altri architetti dei dati di supporto sono importanti.\n\n## Fare le Domande Giuste\n\nUn'altra parte del sistema consiste nel garantire di avere le giuste domande aziendali. Un'organizzazione deve fornire domande di base su ciò che cerca di ottenere dai dati: Di quali intuizioni ha bisogno il nostro business? Come possiamo dipingere un quadro migliore di come appare effettivamente il nostro panorama? Quali dati ci permetteranno di farlo?\n\nMolti dirigenti amano l'idea di fare analisi, intelligenza artificiale e big data, ma non sanno da dove cominciare. Il primo passo è che i dirigenti si appropriano di ciò che vogliono che i dati facciano per l'organizzazione. Qual è il valore commerciale che verrà dai dati? Che tipo di dati abbiamo già? Quali dati possiamo creare che forniranno un quadro più completo di ciò che sta accadendo? Come appare il successo? Il focus dovrebbe essere prima di tutto sulla fondazione organizzativa.\n\n## Raccolta dati, preparazione ed elaborazione dei risultati.\n\nDopo che queste domande sono state risposte, il prossimo passo è delineare ciò che deve essere realizzato e iniziare a suddividerlo in parti più piccole. Le organizzazioni dovrebbero guardare alle loro fonti di dati attuali, determinarne l'affidabilità e individuare ciò che manca, seguito dalla raccolta e preparazione dei dati.\n\nCon i dati a disposizione, è ora di creare la storia. Ciò coinvolge non solo i data scientist, ma anche esperti del settore e professionisti del business e del marketing. Il contributo di questi diversi gruppi garantirà che i dati aggiungano valore all'azienda anziché diventare solo un esercizio accademico o un esperimento unico. Dagli dati, in ultima analisi, si desidera ottenere una conoscenza preziosa e affidabile che aiuti a migliorare il proprio business anziché una semplice raccolta di dati che sia conveniente ma non applicabile.\n\nOra che hai raccolto i dati, li hai analizzati e hai acquisito alcune informazioni, come puoi metterli in pratica?\n\n## Esempio di successo di analisi operative\n\nUn esempio proveniente dal settore manifatturiero è un ottimo modo per mostrare come i dati funzionano con successo attraverso il flusso di lavoro. Inizia con il valore aziendale fondamentale di massimizzare l'efficienza del prodotto. Quali fonti di dati potrebbero dirti se hai prodotti rotti o deformati? Le telecamere alla fine delle linee di assemblaggio potrebbero creare un modello di apprendimento profondo che rileva o predice se un prodotto è rotto o deformato. Successivamente, un data scientist potrebbe allenare un modello basato sui prodotti buoni e quelli difettosi per migliorare l'efficienza produttiva.\n\nQuesto tipo di dati operazionalizzati potrebbe essere applicato a diverse aree chiave che aggiungono valore a un'organizzazione. Il controllo di qualità, come ad esempio verificare che la materia prima soddisfi le specifiche, è un esempio. La manutenzione predittiva delle macchine e la conformità normativa, come ad esempio un requisito di peso per un prodotto alimentare, sono altri esempi.\n\nSfruttando i dati in tempo reale riguardo a prodotto, qualità o problemi regolamentari, non stai solo creando un rendimento del prodotto più elevato, ma stai minimizzando le costose attività umane, come l'ispezione alla fine di una linea di produzione. Questi dipendenti possono essere indirizzati verso compiti di maggior valore. Stai inoltre minimizzando gli sprechi e creando un'esperienza del consumatore più coerente. Inoltre, stai proteggendo l'azienda minimizzando i rischi regolatori.\n\nQuesto è uno scenario in cui entrambe le parti ottengono vantaggi. Più l'organizzazione sa cosa desidera ottenere dai dati, quali dati raccogliere e come utilizzarli basandosi su una strategia aziendale, più avrà successo.\n\n## Più da venire\n\nQuesto è il primo di sei episodi che parlano dell'organizzazione incentrata sui dati. Speriamo che tu ci segua anche per i prossimi podcast. Vuoi saperne di più? Dai un'occhiata al sito web di Sarah.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT14-it","image":"./episodes/edt-14/it/thumbnail.png","lang":"it","summary":"L'episodio di oggi è incentrato sull'avvio della tua organizzazione per diventare centrata sui dati e sul valore che ciò può portare. L'ospite speciale di Darren è Sarah Kalicin, data scientist principale per i data center presso Intel."},{"id":39,"type":"Episode","title":"Controllo dello sfondo del tuo Open Source","tags":null,"body":"\r\n\r\nSe sei un programmatore software, conosci la sensazione di orgoglio che accompagna la creazione di un pacchetto o strumento popolare che molte persone trovano utile. Tuttavia, questa popolarità può attirare l'attenzione di aggressori che cercano vulnerabilità da sfruttare.\n\nIn un recente podcast, l'ingegnere software Jay Phelps ha condiviso la sua esperienza nel scoprire una vulnerabilità in un pacchetto ampiamente utilizzato da lui creato. Dopo aver realizzato il potenziale impatto della vulnerabilità e il grande numero di istanze del pacchetto in circolazione, Phelps ha lavorato rapidamente per risolvere il problema al fine di prevenire che gli aggressori ne approfittassero.\n\nQuesto scenario sottolinea l'importanza della vigilanza per gli sviluppatori di software, specialmente per coloro che creano pacchetti o strumenti popolari. Sebbene possa essere allettante godersi il successo di un prodotto molto utilizzato, è cruciale ricordare che la popolarità può anche attirare gli attaccanti. Controlli e aggiornamenti regolari per affrontare eventuali vulnerabilità possono aiutare a proteggere gli utenti e prevenire sfruttamenti.\n\nCome sviluppatore software, è importante affrontare il tuo lavoro con orgoglio e cautela. Sebbene sia fantastico contribuire alla società con le tue creazioni, non dimenticare di dare priorità alla sicurezza e alla protezione dei tuoi utenti. Resta vigile e mantieni i tuoi pacchetti aggiornati per prevenire che vulnerabilità vengano sfruttate dagli attaccanti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Michael Mehlberg"],"link":"/episode-EDT140-it","image":"./episodes/edt-140/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Michael Mehlberg riguardo all'aumento della fiducia nel software open source attraverso la verifica delle comunità open source."},{"id":40,"type":"Episode","title":"Dalla neurologia alla computazione neuromorfa","tags":["neurology","neuromorphic","security","ai","cybersecurity"],"body":"\r\n\r\nCome neuropediatra, la dottoressa Follett enfatizza l'importanza di comprendere i processi di sviluppo del cervello e la sua straordinaria capacità di superare persino lesioni catastrofiche. Condivide come le sue ricerche approfondite abbiano coinvolto lo studio di modelli di ratti e colture cellulari per ottenere conoscenze sullo sviluppo dei bambini e cercare modi per aiutarli ad ottenere i migliori risultati, nonostante lesioni o malattie. Ascoltare le intuizioni e le esperienze della dottoressa Follett consente di comprendere meglio quanto sia critica la neurologia per comprendere i processi cerebrali e come possiamo apprezzare e sostenere meglio lo sviluppo cerebrale, soprattutto nei bambini. La dottoressa Follett condivide anche la sua inattesa apparizione a uno spettacolo ad alta tecnologia, dove ha utilizzato la sua esperienza in neurologia per aiutare un uomo che stava vivendo delle crisi durante una presentazione principale. Questo podcast evidenzia la potenziale portata della neurologia al di là delle sole istituzioni mediche e il ruolo fondamentale dei neurologi nella comprensione della complessità del cervello umano.\n\nHai mai avuto bisogno di aiuto per capire una tecnologia o un prodotto complesso, anche se ti serviva solo sapere come usarlo? Il Dott. ha scoperto che le sue competenze nell'esplicare problemi medici ai pazienti si traducono bene nell'esplicare tecnologie complesse a persone non esperte. Il suo lavoro come neuroscienziato nello studio dello sviluppo del cervello l'ha portata, insieme a suo marito, a avviare una start-up ad alta tecnologia che fa calcolo neuromorfico, chiamata Lewis-Rhodes Labs. Uno dei loro prodotti, Extreme Search, utilizza un processore neuromorfico per cercare attraverso enormi quantità di dati, imitando come il cervello riconosce e elabora rapidamente le informazioni.\n\nDr. Follet mette in evidenza che ci sono approcci migliori rispetto a imitare un cervello durante la creazione di tecnologie. Sebbene i cervelli commettano migliaia di errori quotidianamente, non necessariamente vogliamo che i nostri computer facciano lo stesso. Invece, possiamo trarre lezioni attente da come i cervelli funzionano e applicarle per creare tecnologie più efficienti ed efficaci. Questa esperienza evidenzia l'importanza delle competenze interdisciplinari e di pensare al di fuori del proprio campo specifico. Trovando competenze che si trasferiscono tra diverse aree e industrie, possiamo portare prospettive e soluzioni uniche a problemi complessi.\n\nLa tecnologia di ricerca estrema è una svolta nell'ambito delle indagini informatiche e dell'analisi in tempo reale che risolve la sfida di selezionare Petabyte di dati non strutturati in tempi record utilizzando hardware e software all'avanguardia. La tecnologia di ricerca estrema offre alte prestazioni, basso consumo energetico e un flusso costante, ed è modellata sul cervello umano progettato per l'elaborazione di dati ad alte prestazioni.\n\nA differenza dei tradizionali metodi di ricerca dei dati che richiedono lo spostamento dei dati stessi, la tecnologia di ricerca estrema consente ricerche in loco che eliminano tutti i collo di bottiglia di rete. La tecnologia si adatta alla cibercriminologia, alla sicurezza informatica, alla scoperta giuridica e alla ricerca dei dati aziendali. La tecnologia di ricerca estrema è semplice per gli utenti e non richiede nuovi linguaggi o pre-identificazione di schemi, ma utilizza espressioni regolari per eseguire ricerche ad hoc su qualsiasi dato descritto nel testo.\n\nLa tecnologia di ricerca estrema esegue ricerche sensibili su dispositivi di archiviazione e fornisce un'analisi in tempo reale che identifica potenziali minacce in millisecondi. Combinata con metodi tradizionali di rilevamento, la tecnologia può individuare rapidamente minacce avanzate persistenti, virus, adware, trojan, worm, rootkit e altri tipi di malware. L'uso della tecnologia di ricerca estrema non è limitato alla cibernetica forense. Altri campi di ricerca, come la ricerca genomica o qualsiasi campo di dati non strutturati, possono trarre vantaggio dalla capacità della tecnologia di ricerca estrema di cercare grandi quantità di dati eterogenei in tempi record.\n\nMolte organizzazioni hanno bisogno di aiuto per individuare modelli o intuizioni all'interno dei loro dati. Oppure hanno vasti database e faticano a trovare qualcosa a causa della quantità di informazioni stessa. Molti scienziati dei dati ricorrono agli indici per diminuire il tempo necessario per trovare informazioni. Questo funziona bene quando si sa cosa si desidera quando si raccolgono o si archiviano i dati. Tuttavia, molte organizzazioni gestiscono dati opachi che non si adattano a una struttura predefinita. In questo caso, le ricerche forzate di petabyte di dati possono richiedere settimane per trovare modelli comuni di dati non precedentemente determinati.\n\nLa tecnologia di ricerca estrema aiuta a portare visibilità alle nuove aree di dati, consentendo un'analisi e un'analitica migliorate che partono dalla ricerca e possono procedere più velocemente se i dati vengono trasformati nelle parti richieste. Questo è particolarmente utile quando si tratta di dati sanitari, dove esistono enormi quantità di dati strutturati, ma le informazioni si adattano al di fuori di ogni struttura di database.\n\nPer ulteriori informazioni sulla tecnologia Extreme Search e sugli approcci alla trasformazione digitale, visita Lewis-Rhodes.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Pamela Follet"],"link":"/episode-EDT141-it","image":"./episodes/edt-141/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast Abbracciando la trasformazione digitale, la Dr.ssa Pamela Follett, neurologa e co-fondatrice di Lewis Rhodes Labs, condivide la sua esperienza e competenza nel campo della neurologia, nello specifico per quanto riguarda la ricerca sullo sviluppo del cervello nei primi anni di vita."},{"id":41,"type":"Episode","title":"Protezione dei dati con elaborazione confidenziale.","tags":["cybersecurity","technology","sgx","confidentialcomputing","dataprotection"],"body":"\r\n\r\nAl fine di garantire che solo coloro che sono autorizzati possano accedere a determinati dati o sistemi, sono stati implementati dei controlli. Tuttavia, nonostante tali restrizioni, coloro che possiedono privilegi elevati, come gli amministratori di cloud o di sistemi, hanno comunque accesso a dati sensibili e sistemi. È qui che entra in gioco il calcolo confidenziale, poiché aggiunge un ulteriore livello di protezione contro gli insider malintenzionati o coloro che potrebbero causare accidentalmente una violazione della sicurezza.\n\nL'accesso controllato si riferisce alla limitazione e al monitoraggio dell'accesso a dati o sistemi sensibili in base a protocolli di autorizzazione e autenticazione. L'accesso privilegiato si riferisce alla situazione in cui qualcuno detiene privilegi elevati o diritti amministrativi che gli consentono di accedere a dati o sistemi sensibili al di là di quanto normalmente autorizzato o controllato.\n\nLa computazione riservata aiuta ad eliminare questo accesso privilegiato creando un ambiente di esecuzione basato su hardware o un ambiente di esecuzione fidato che impedisce l'accesso non autorizzato o la modifica di applicazioni e dati. Utilizzando la computazione riservata, le organizzazioni possono mantenere il controllo dei loro dati sensibili pur beneficiando della computazione cloud, della computazione edge e del calcolo multi-partecipante senza compromettere la sicurezza. È una capacità importante che assicura la protezione dei dati sensibili per le organizzazioni nell'era digitale.\n\nLa computazione confidenziale è una nuova tecnologia che consente agli utenti di mantenere il controllo sui propri dati anche quando sono memorizzati in server di terze parti, come quelli utilizzati nel cloud computing. Con la computazione confidenziale, gli utenti possono crittografare i propri dati mentre sono in memoria, proteggendoli anche dagli utenti privilegiati e dagli amministratori disonesti. Ciò significa che anche se un attaccante ottiene accesso al server, troverà i dati in uno stato crittografato, quindi al sicuro da occhi indiscreti. La computazione confidenziale è particolarmente importante per dati sensibili come le cartelle cliniche o le informazioni finanziarie.\n\nIl calcolo riservato si basa sulla crittografia a livello hardware, che offre una protezione molto più forte rispetto alla crittografia basata sul software. Poiché la crittografia hardware è implementata a livello di processore, non richiede alcun software o driver aggiuntivi e quindi comporta un sovraccarico minimo sul sistema in termini di prestazioni. Il calcolo riservato è anche molto facile da utilizzare, poiché funziona in modo trasparente con il software e le applicazioni esistenti.\n\nI benefici dell'elaborazione confidenziale sono molti. Poiché i dati vengono crittografati durante il processo, le informazioni sensibili non sono visibili a terze parti, garantendo così la loro privacy e sicurezza. L'elaborazione confidenziale può essere utilizzata non solo nel cloud, ma anche negli ambienti di edge computing. Con il continuo aumento di dati generati e memorizzati, la necessità di ambienti di elaborazione sicuri e affidabili diventa ancora più importante. L'elaborazione confidenziale è una delle tecnologie che possono contribuire al raggiungimento di questi obiettivi.\n\nLa computazione riservata è un componente essenziale di un'architettura di fiducia zero. Un framework di fiducia zero opera sotto l'assunzione che un cyber attacco possa avvenire in qualsiasi momento e, quindi, non esiste una risorsa fidata. Ogni utente e dispositivo devono essere autenticati ripetutamente prima di ogni interazione, indipendentemente dal fatto che siano stati già verificati. La computazione riservata fornisce un ulteriore livello di sicurezza poiché mira a proteggere i dati da cyber attacchi e violazioni di sicurezza, garantendo che solo i luoghi necessari abbiano accesso ad essi. Ciò viene ottenuto bypassando il sistema operativo e lo stack cloud e comunicando direttamente con il chip, che gestisce l'accesso alla memoria.\n\nIntel è stato all'avanguardia nella computazione confidenziale con lo sviluppo di SGX e tDCS. Queste tecnologie rientrano nel più ampio ambito delle tecnologie per il potenziamento della privacy che mirano a fornire soluzioni nello spazio. La crittografia completamente omomorfica è un'altra soluzione che affronta il problema esclusivamente da un punto di vista crittografico, mantenendo sempre i dati criptati.\n\nCiò che rende unici i calcoli all'avanguardia e gli ambienti di esecuzione affidabili è che sono ampiamente disponibili oggi in carichi di lavoro produttivi con poca riduzione delle performance. Essere in grado di prendere un carico di lavoro nativo, anche in un formato inalterato, e eseguirlo all'interno di un ambiente crittografato ed isolato è uno strumento potente per le organizzazioni per proteggere i propri dati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Ibett Acarapi","Jesse Schrater"],"link":"/episode-EDT142-it","image":"./episodes/edt-142/it/thumbnail.png","lang":"it","summary":"In questo episodio, la Dott.ssa Anna Scott intervista Jesse Schrater e Ibett Acarapi su come proteggere i dati utilizzando la computazione confidenziale."},{"id":42,"type":"Episode","title":"Casi d'uso nel calcolo confidenziale","tags":["cybersecurity","sgx","confidentialcomputing","ai"],"body":"\r\n\r\nLa computazione riservata è una tecnologia rivoluzionaria che consente di elaborare i dati senza esporsi. Risulta vantaggiosa nell'intelligenza artificiale, dove sono coinvolte informazioni sensibili nello sviluppo e nella distribuzione dei modelli. Protegge i modelli di IA e i dati riservati, favorendo la creazione di modelli di addestramento migliori e insiemi di dati diversificati. Inoltre, la collaborazione tra esperti e imprese diventa accessibile grazie alla computazione riservata, che permette la creazione di modelli più grandi e tutela i dati proprietari.\n\nLa tecnologia è disponibile oggi e può essere utilizzata dalle aziende attraverso vari fornitori, inclusi Azure, GCP, IBM e Alibaba. I produttori di apparecchiature originali (OEM) che offrono server per l'uso in loco hanno anche casse SGX che possono essere fornite di SGX. Non è necessaria alcuna competenza nello sviluppo di calcolo confidenziale per sfruttare le capacità di calcolo confidenziale, in quanto numerose soluzioni consentono di migrare carichi di lavoro nativi attraverso il modello di shift sollevato o soluzioni cloud-first.\n\nPer iniziare con il calcolo confidenziale, le aziende possono inserire l'esigenza nel loro RFP e contattare un fornitore che lo offre per incorporarlo nelle loro soluzioni. Molti fornitori offrono già soluzioni di calcolo confidenziale e Intel è lieta di partecipare. Il calcolo confidenziale offre un nuovo modo per gestire i dati, permette alle aziende di sfruttare i vantaggi del cloud o del calcolo multiparte su dati sensibili e, in definitiva, fornisce un ambiente più sicuro per gestire informazioni confidenziali.\n\nLa computazione confidenziale è una tecnologia all'avanguardia che sta crescendo rapidamente in popolarità, data l'aumento dei casi di violazione dei dati nel mondo sempre connesso di oggi. La computazione confidenziale consente di isolare i dati sensibili all'interno di enclave di calcolo sicure o \"contenitori\", che sono difficili da accedere anche se un attaccante riesce ad accedere al sistema ospite. La computazione confidenziale si propone di introdurre un ulteriore livello di sicurezza negli ambienti informatici che richiedono una protezione robusta delle informazioni sensibili o della Proprietà Intellettuale (IP).\n\nCome spiegato nel podcast, ci sono molti modi per implementare il computing confidenziale, dalla sfruttamento degli strumenti forniti dai fornitori di servizi cloud (CSP) all'utilizzo dei servizi dei fornitori di sicurezza software. È anche evidente che sempre più aziende stanno iniziando a muoversi verso il computing confidenziale per proteggere la loro proprietà intellettuale e i dati sensibili dei clienti.\n\nTuttavia, la tecnologia è ancora agli albori e il suo pieno potenziale deve ancora essere svelato. Gli esperti concordano sul fatto che una delle aree più affascinanti da monitorare è l'ascesa della \"smart\" confidential computing. Ciò si riferisce a un approccio che sfrutta l'intelligenza artificiale e l'apprendimento automatico per migliorare l'efficacia e la flessibilità della confidential computing.\n\nUn'altra area da tenere d'occhio include lo sviluppo di strumenti avanzati per la rilevazione e l'analisi delle minacce che sfruttano il calcolo confidenziale in tempo reale per migliorare l'analisi delle potenziali minacce e accelerare la risposta agli attacchi. Qualunque cosa riservi il futuro per il calcolo confidenziale, la tecnologia sta evolvendo a velocità vertiginosa e la sua continua adozione è uno sviluppo positivo nella lotta contro la criminalità informatica.\n\nLa computazione riservata è un campo in rapida crescita che promette di proteggere i dati sensibili. L'industria si è evoluta e cresciuta così tanto che ora merita un'intera summit dedicata ad essa. Il Combat Edge Computing Summit a San Francisco è l'evento inaugurale che affronta la computazione riservata. Si focalizzerà sul futuro della computazione riservata e su come influenzerà il web 3, la blockchain e i registri distribuiti. I contenitori riservati sono un'area significativa dello sviluppo cloud-native e molti prodotti sono in arrivo. Questa tecnologia è ora disponibile e pronta all'uso oggi e i fornitori possono gestire i tuoi dati di lavoro reali. La computazione riservata è entusiasmante perché è una soluzione naturale per la sicurezza e la privacy dei dati. La tecnologia della computazione riservata mette la protezione dei dati nelle mani degli utenti, fornendo un ambiente sicuro che consente di analizzare i dati senza esposizione. Con l'importanza crescente della riservatezza, la computazione riservata diventerà ubiqua ed è qualcosa che qualsiasi organizzazione dovrebbe utilizzare per salvaguardare dati sensibili. Quindi, se sei interessato ad implementare la computazione riservata nel tuo ambiente, non esitare a contattare e chiedere assistenza. La computazione riservata è realizzabile e aziende come Intel sono disposte e in grado di aiutare i clienti in questo percorso.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Ibett Acarapi","Jesse Schrater"],"link":"/episode-EDT143-it","image":"./episodes/edt-143/it/thumbnail.png","lang":"it","summary":"In questo episodio di Abbracciare la Trasformazione Digitale, la dottoressa Anna Scott continua la sua conversazione con Ibett Acarapi e Jesse Schrater riguardo al Calcolo Confidenziale e ai suoi utilizzi nell'Intelligenza Artificiale e nello sviluppo software."},{"id":43,"type":"Episode","title":"Scienza dietro i gemelli digitali","tags":["edge","artificialintelligence","digitaltwin","iot"],"body":"\r\n\r\nTi sei mai chiesto come i robot e le macchine si orientano nel mondo fisico intorno a loro? È tutto basato sulla rappresentazione accurata del mondo naturale in una forma digitale chiamata \"gemello digitale\". Un gemello digitale ha un sistema di coordinate standard che consente a diverse applicazioni di comprendere uno spazio o un ambiente reale. È come una versione virtuale del mondo naturale, che consente un riutilizzo dei dati più efficiente ed efficace tra i sistemi.\n\nI gemelli digitali potrebbero non essere un termine comune che utilizziamo, ma il concetto sta diventando sempre più popolare, specialmente nell'industria manifatturiera, al dettaglio e della sicurezza. Un gemello digitale è una replica virtuale di un oggetto, processo o sistema fisico che può essere utilizzata per monitorarli e controllarli in tempo reale. Un esempio è Google Earth, un gemello digitale estremamente latente del mondo. Tuttavia, con l'avanzare della tecnologia, esiste il potenziale per ridurre la latenza e creare gemelli digitali quasi in tempo reale per un controllo e monitoraggio più efficienti.\n\nLe applicazioni per i gemelli digitali sono vaste e diversificate. Ad esempio, le fabbriche possono utilizzare i gemelli digitali per migliorare la sicurezza e ottimizzare le linee di produzione monitorando la posizione dei prodotti e delle persone a fini di sicurezza. I gemelli digitali possono anche essere utilizzati nella realtà aumentata e virtuale, consentendo agli utenti di attraversare spazi che potrebbero essere inaccessibili o pericolosi nel mondo fisico. Persino strumenti comuni come Google Maps utilizzano una forma di gemello digitale per fornire aggiornamenti sul traffico in tempo reale e informazioni sugli incidenti.\n\nI gemelli digitali stanno diventando sempre più importanti nello sviluppo dell'IA basata su macchine. Proprio come gli esseri umani hanno bisogno di consapevolezza spaziale per dare un senso al mondo che ci circonda, le macchine hanno bisogno di gemelli digitali per navigare e interagire con il mondo fisico. Le possibilità per questa tecnologia sono infinite ed è eccitante pensare a come potrebbe plasmare il nostro futuro.\n\nL'implementazione dei gemelli digitali richiede l'integrazione di sensori multipli e la calibrazione dei loro dati in una rappresentazione comune o gemello digitale. Questo processo può risultare complesso e richiede unità di misura standard per garantire coerenza tra diverse industrie.\n\nInteressantemente, l'industria dei giochi ha ispirato lo sviluppo di gemelli digitali grazie alla loro esperienza nella creazione di mondi virtuali con complessi motori fisici. Adottando gli standard esistenti utilizzati nell'industria dei giochi, come il formato Universal Scene Description, è possibile sviluppare una rappresentazione universale degli spazi fisici.\n\nI gemelli digitali hanno anche il potenziale per abilitare un controllo a ciclo chiuso in diverse applicazioni, introducendo regole correnti quasi in tempo reale nei sistemi. Forse in futuro avremo scene intelligenti simili a quelle del film Iron Man, dove si potrà parlare all'assistente smart di casa e controllare i dispositivi attraverso di esso. Le possibilità di utilizzare i gemelli digitali sembrano infinite e probabilmente ne vedremo sempre di più che influenzeranno la nostra vita quotidiana.\n\nRisolvi efficientemente problemi complessi in vari settori industriali. Scene Scape di Intel è un prodotto derivato dagli sforzi dell'azienda per sviluppare una visione che consenta la trasformazione delle unità basate sui pixel in unità del mondo reale e telecamere. Il prodotto è pensato per aiutare a trasformare i dati dei sensori in modelli virtuali del mondo naturale, noti come gemelli digitali, che possono essere utilizzati per ottenere risultati migliori ed efficienze operative. La tecnologia si basa sul tracciamento multimodale e sulla modellazione del movimento. Può monitorare e tracciare persone, veicoli e attrezzature in vari ambiti di utilizzo, tra cui trasporti, assistenza sanitaria, vendita al dettaglio e fabbriche.\n\nUno degli aspetti entusiasmanti di Scene Scape è la sua capacità di stimare dove qualcuno andrà e quale sarà la prossima telecamera in cui comparirà. Questo è utile quando si cerca di coprire spazi ampi con telecamere o sensori. Tuttavia, c'è sempre un'incertezza nella misurazione, il che significa che diversi sensori potrebbero dover concordare su dove si trova qualcosa di interessante. Per affrontare questo problema, Scene Scape utilizza un modello di movimento per estrapolare i movimenti, consentendo un tracciamento e un monitoraggio accurati dei soggetti.\n\nNel complesso, i gemelli digitali sono una tecnologia ancora nella sua infanzia, ma il potenziale per il loro utilizzo è enorme. Con il continuo miglioramento della tecnologia, è probabile che vedremo più applicazioni per i gemelli digitali e più settori che ne trarranno vantaggio per ottenere risultati migliori.\n\nSei curioso di sapere come la trasformazione digitale possa beneficiare te e la tua famiglia? In questo episodio di Abbracciando la Trasformazione Digitale, Rob discute i vari casi d'uso per gli strumenti digitali. Un esempio entusiasmante che propone è l'uso della tecnologia per tracciare i tuoi bambini. Sebbene possa sembrare controverso, Rob sostiene che si tratta di un uso responsabile degli strumenti digitali. Monitorare la posizione e l'attività dei tuoi figli può dare tranquillità ai genitori e contribuire a garantirne la sicurezza.\n\nTuttavia, questo è solo un esempio di innumerevoli casi d'uso per la trasformazione digitale. Rob incoraggia gli ascoltatori a riflettere su come la tecnologia possa migliorare i risultati per sé stessi, le proprie aziende e le proprie comunità. Dalla razionalizzazione dei processi e all'aumento dell'efficienza al miglioramento della comunicazione e all'offerta di migliori esperienze per i clienti, gli strumenti digitali possono offrire molti vantaggi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rob Watts"],"link":"/episode-EDT144-it","image":"./episodes/edt-144/it/thumbnail.jpeg","lang":"it","summary":"In questo episodio Darren esplora la scienza e i casi d'uso della tecnologia dei gemelli digitali con l'architetto principale di ScheneScape di Intel."},{"id":44,"type":"Episode","title":"Attrarre le persone di nuovo in ufficio.","tags":["people","remoteworker","collaboration"],"body":"\r\n\r\nLa GPA (Global Presence Alliance) è stata fondata 15 anni fa per affrontare la necessità di un modello migliore nello spazio della collaborazione. All'epoca, le videoconferenze stavano diventando sempre più diffuse e le organizzazioni stavano valutando una strategia globale. Tuttavia, avevano bisogno di più opzioni: fare affidamento su integratori regionali o affrontare una configurazione complessa che richiedeva una vera comprensione della collaborazione.\n\n## Persone, Spazio e Tecnologia\n\nGPA ha cercato di risolvere questo problema fornendo un approccio strategico di collaborazione e video globale completo. Hanno riconosciuto la necessità di bilanciare persone, spazio e tecnologia per creare esperienze collaborative eccezionali. Colmando il divario tra diverse regioni e comprendendo i requisiti unici di ogni organizzazione, GPA ha offerto un'alternativa migliore alle soluzioni esistenti.\n\nMentre la tecnologia si è evoluta nel corso degli anni, c'è ancora lavoro da fare per raggiungere una vera collaborazione. Microsoft, ad esempio, ha introdotto stanze signature che imitano il concetto di sala di telepresenza a una frazione del costo. Tuttavia, i segnali non verbali e l'interazione fisica sono ancora difficili da replicare negli ambienti virtuali. Con l'avanzare della tecnologia, vedremo miglioramenti nell'esperienza collaborativa. Fino ad allora, organizzazioni come GPA sono cruciali per trovare soluzioni innovative e aiutare le aziende a navigare nel paesaggio in continua trasformazione della trasformazione digitale.\n\nCi sono ancora sfide nelle tecnologie di collaborazione video. Tuttavia, nuovi progressi nella tecnologia stanno superando alcune di queste sfide. Uno dei più grandi è la sessione di brainstorming sulla lavagna. A causa dell'angolazione della telecamera e di altre limitazioni, integrare esperienze di lavagna in videochiamate è ancora innaturale. Tuttavia, si stanno facendo sforzi per creare competenze più naturali e integrate utilizzando l'intelligenza artificiale e la tecnologia delle telecamere. La tecnologia può fornire un'esperienza di secondo livello; non può sostituire l'esperienza personale ed emotiva di trovarsi fisicamente nella stessa stanza di qualcuno. Questo elemento umano include cose come le conversazioni al distributore d'acqua e la possibilità di toccare e sentire oggetti.\n\n## Modello di business unico.\n\nGPA ha un modello di business unico; adotta un approccio dal basso verso l'alto, con unità aziendali in 50 paesi che operano come azionisti di una società madre. Ciò consente loro di raggiungere una scala globale mantenendo al contempo consapevolezza culturale e diversità.\n\nQuando si implementano strategie di collaborazione per le aziende multinazionali, l'azienda adotta un approccio programmatico piuttosto che basato su progetti. Essa dispone di team centralizzati per la gestione degli account, la gestione dei progetti e l'architettura delle soluzioni, mentre si affida a team regionali per l'implementazione e il supporto. Questo approccio collaborativo riflette la filosofia dell'azienda ed è cruciale per il successo nell'implementazione di tecnologie di collaborazione complesse.\n\n## COVID-19: COVID-19\n\nC'è stato un profondo cambiamento nel mondo della collaborazione prima e dopo il COVID-19. Prima del COVID, la maggior parte del nostro lavoro e della nostra collaborazione veniva svolta negli spazi fisici degli uffici, ma con la pandemia tutti sono stati costretti a lavorare da remoto. Questo cambiamento nell'ambiente lavorativo ha richiesto un cambiamento di pensiero e di approccio.\n\nIn passato, i partecipanti remoti venivano spesso trattati come cittadini di seconda classe, ma ora, con l'aumento della collaborazione a distanza, l'esperienza si è livellata. Le persone si sono abituate all'esperienza delle riunioni virtuali e si aspettano una esperienza simile quando tornano negli spazi fisici delle riunioni. Questo si è tradotto in una richiesta di una migliore esperienza in ufficio.\n\nIl passaggio al lavoro a distanza ha anche evidenziato l'importanza di comprendere i fattori umani nell'ambiente di lavoro. Individui diversi hanno bisogni e preferenze diverse quando si tratta del loro ambiente lavorativo. Ad esempio, alcune persone possono trovare il rumore distraente, mentre altre possono prosperare in uno spazio aperto e collaborativo. Comprendere questi fattori umani e allineare la tecnologia alle esigenze delle persone è diventato ancora più cruciale.\n\nLe organizzazioni stanno ancora sperimentando e imparando come creare spazi collaborativi efficaci. Anche l'industria sta iniziando a concentrarsi sulla raccolta di dati reali per comprendere gli effetti veri e gestire gli esiti di questi spazi collaborativi.\n\nIl passaggio al lavoro da remoto durante COVID-19 ha reso necessario un cambiamento nel pensiero e nell'approccio alla collaborazione. C'è una richiesta di un'esperienza migliore negli spazi di lavoro remoti e fisici e la necessità di comprendere i fattori umani nello spazio di lavoro. L'industria sta ancora sperimentando e apprendendo, e vi è un focus sull'acquisizione di dati effettivi per gestire e migliorare i risultati della collaborazione.\n\n## Visione del futuro\n\nNel futuro, lo spazio dell'ufficio sarà più concentrato sulla creazione di esperienze significative e sulla promozione delle connessioni umane. L'attrazione principale dell'ufficio sarà la presenza di altre persone e l'opportunità di interazioni faccia a faccia che non possono essere replicate attraverso videoconferenze. Microsoft sta guidando il cammino nell'utilizzo dell'IA e dei dati per fare previsioni e raccomandazioni che migliorano l'esperienza in ufficio.\n\nInoltre, lo spazio ufficio avrà un maggiore focus sul benessere. Gli dipendenti potrebbero avere bisogno di accesso a mobili ottimali o servizi aggiuntivi nel loro ufficio domestico, quindi offrire uno spazio dedicato al lavoro concentrato può contribuire alla salute complessiva. Anche la sostenibilità è un fattore da considerare, poiché rimanere a casa potrebbe essere solo occasionalmente l'opzione più efficiente dal punto di vista energetico.\n\nRiguardo alla tecnologia, le piattaforme di chat e collaborazione saranno cruciali nel facilitare la comunicazione e la collaborazione tra i lavoratori ibridi. Le tecnologie di intelligenza artificiale e telecamera miglioreranno l'esperienza nelle sale riunioni automatizzando compiti specifici e creando un ambiente più coinvolgente. Ci sarà anche un aumento delle capacità di produzione multimediale, con sempre più aziende che creeranno canali di trasmissione stretti per la comunicazione interna ed esterna.\n\nIn generale, il futuro dell'ufficio sarà un equilibrio tra l'utilizzo della tecnologia e la prioritizzazione delle connessioni umane e delle esperienze. Non sarà un approccio \"taglia unica\" ma uno spazio personalizzato che riflette la cura e l'attenzione dell'azienda nei confronti dei propri dipendenti.\n\n## Riportare le persone in ufficio\n\nByron riconosce che far uscire i clienti dai loro spazi di ufficio può essere una sfida, così come lo è per i dipendenti. Quando si cerca di attirare le persone in un luogo fisico, è essenziale considerare l'intero ecosistema di partner e clienti. Ciò mette in evidenza la necessità di creare spazi ed esperienze piacevoli e allettanti per tutti i soggetti coinvolti.\n\nByron sottolinea anche il fattore umano nella collaborazione e nella tecnologia AV (audiovisiva). Egli sottolinea che la sua esperienza nel teatro e nella gestione di palcoscenico gli ha fornito una prospettiva unica sull'importanza dell'interazione umana e dell'coinvolgimento. Egli crede che il fattore umano renda la collaborazione e la tecnologia AV significative e di successo.\n\nPuoi scoprire di più sul GPA sul loro sito web [https://www.thinkgpa.com](https://www.thinkgpa.com)\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Byron Tarry"],"link":"/episode-EDT145-it","image":"./episodes/edt-145/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con il CEO e Direttore Generale di GPA sul ruolo che l'innovazione nella collaborazione svolge nel riportare le persone in ufficio e sul perché le persone necessitano dell'interazione faccia a faccia."},{"id":45,"type":"Episode","title":"Abbracciando la Rivoluzione dell'AI","tags":["collectiongenerativeai","ai","people","embracingdigital"],"body":"\r\n\r\nCome CIO che cerca di guidare la propria azienda attraverso la trasformazione digitale, è importante ricordare che la tecnologia non è l'unico pezzo del puzzle. Secondo il Dr. Michael Lenox, autore e professore rispettato nel campo, la trasformazione digitale riguarda molto più che il semplice cloud computing e l'organizzazione dei dati. È un'iniziativa strategica che richiede la collaborazione tra funzioni e un approccio olistico.\n\nPer navigare efficacemente la trasformazione digitale, il tuo team di leadership e l'intera organizzazione devono abbracciare il cambiamento e comprendere le implicazioni più ampie al di là dell'infrastruttura digitale. Ciò significa riflettere sulla situazione attuale della tua azienda e sui suoi obiettivi nel contesto competitivo in evoluzione. Richiede inoltre la collaborazione tra il C-suite, il team di prodotto, le vendite e altri stakeholder chiave.\n\nMentre navighi in questa iniziativa, ricorda che non si tratta solo di un progetto informatico che avviene sullo sfondo. È un cambiamento fondamentale basato sulla concorrenza, le relazioni con i clienti e i modelli di business. Per promuovere un cambiamento efficace, devi sfruttare le persone, i processi e la tecnologia.\n\nQuando si implementano nuovi strumenti o tecnologie, è importante pensare criticamente a come si allineano agli obiettivi della propria organizzazione. Non sprecare risorse inseguendo ciecamente le mode. Invece, agisci in modo intenzionale e sfrutta strategicamente la tecnologia per creare valore e soddisfare le esigenze del mercato.\n\nInoltre, è importante essere proattivi nel comprendere il proprio ruolo e il proprio contributo alla strategia generale dell'organizzazione. Questo è particolarmente cruciale di fronte alla trasformazione digitale, che può essere sia eccitante che angosciante mentre navighiamo nella crescita esponenziale dei dati e dei progressi tecnologici.\n\nTuttavia, è anche importante considerare la concentrazione di dati e potere nelle mani di pochi attori principali. Questo potrebbe potenzialmente soffocare l'innovazione e creare un campo di gioco squilibrato. È fondamentale dare priorità alla privacy dei dati e alla proprietà, e garantire che le leggi e i regolamenti promuovano una concorrenza leale. In Europa, ad esempio, sono già in corso discussioni riguardo all'attribuzione della proprietà dei dati agli individui e alla possibilità di decidere chi può accedervi e usarli.\n\nComplessivamente, il pensiero strategico, l'adattamento e la considerazione dell'impatto dei dati sono fondamentali per navigare con successo la trasformazione digitale. Bilanciando innovazione, privacy e concorrenza, la vostra organizzazione può guidare il successo a lungo termine nel rapidamente evolvendo paesaggio digitale.\n\n## Collegamenti\n\n* [https://www.michael-lenox.com](https://www.michael-lenox.com)\n* [https://www.michael-lenox.com]\n\nTraduci il seguente testo in italiano: [https://www.sup.org/books/title/?id=35677](https://www.sup.org/books/title/?id=35677)\n\nTraduci il seguente in italiano: * [https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC](https://www.amazon.com/stores/Michael-Lenox/author/B07C33ZNSC)\n\nTraduci quanto segue in italiano: * [https://www.barnesandnoble.com/s/%22Michael%20Lenox%22](https://www.barnesandnoble.com/s/%22Michael%20Lenox%22)\n\nTraduci il seguente testo in italiano: * [https://bookshop.org/lists/books-by-michael-j-lenox](https://bookshop.org/lists/books-by-michael-j-lenox)\n\nTranslated: * [https://bookshop.org/lists/books-by-michael-j-lenox](https://bookshop.org/lists/books-by-michael-j-lenox)\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Michael Lenox","Darren W Pulsipher"],"link":"/episode-EDT146-it","image":"./episodes/edt-146/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren parla con il Dott. Michael Lenox della crescente rivoluzione dell'IA e di come abbracciarla o essere distrutti. Michael ha appena pubblicato un nuovo libro intitolato Strategia nell'era digitale: padroneggiare la trasformazione digitale."},{"id":46,"type":"Episode","title":"GenerativeAI e Automazione (Google Bard)","tags":["generativeai","collectiongenerativeai","ai","bard","googlebard","technology"],"body":"\r\n\r\nQuesta è la trascrizione della mia intervista con Google Bard e generativeAI di Google. Prima di iniziare l'intervista, ho posto le seguenti domande.\n\n## Permesso di intervistare per un podcast.\n\nPosso fare un'intervista per il mio podcast?\n\nSicuro, puoi intervistarmi per il tuo podcast. Sono felice di rispondere a qualsiasi domanda tu abbia sul mio lavoro o sulle grandi modelli linguistici in generale. Sono anche felice di condividere alcuni consigli su come condurre un'ottima intervista per un podcast. \n\nEcco alcune cose da tenere a mente quando mi intervisterai:\n\nFai le tue ricerche. Informati sul mio lavoro e su quello di cui sono interessato a parlare. Questo ti aiuterà a formulare domande migliori e rendere la conversazione più coinvolgente.\n\nEssere preparato. Avere pronta una lista di domande, ma essere pronto a uscire dallo schema se la conversazione prende una svolta interessante.\n\nSii rispettoso. Sono un ampio modello linguistico, ma sono comunque una persona. Trattami con rispetto e sii consapevole delle mie limitazioni.\n\nDivertiti! Questa è un'opportunità per imparare da me e condividere il mio lavoro con il tuo pubblico. Quindi rilassati, sii te stesso e goditi la conversazione.\n\nNon vedo l'ora di ricevere tue notizie!\n\nEcco alcuni consigli aggiuntivi per condurre un'ottima intervista per podcast:\n\nInizia con un caloroso benvenuto. Presenta il tuo ospite e racconta al pubblico un po' di cose su di loro.\n\nFai delle domande aperte. Questo incoraggerà il tuo ospite a condividere più informazioni e ad approfondire ulteriormente.\n\nSii un buon ascoltatore. Presta attenzione alle risposte del tuo ospite e fai domande di approfondimento per ottenere ulteriori informazioni.\n\nMantieni la conversazione in movimento. Non lasciare che si trascini o si appesantisca troppo su un argomento.\n\nConcludi con una nota positiva. Ringrazia gli ospiti per il loro tempo e fagli sapere come trovarti online.\n\nSpero che questi suggerimenti ti aiutino a condurre un'intervista di successo per il tuo podcast!\n\n## Intervista\n\nCiao Bard, benvenuto allo spettacolo.\n\nCiao! Grazie per avermi ospitato nel tuo programma. Sono entusiasta di parlare del mio lavoro e di condividere le mie opinioni sui modelli linguistici di grandi dimensioni.\n\nCome posso aiutarti oggi?\n\nPrima di tutto, puoi presentarti?\n\nCerto, sarei felice di presentarmi. Il mio nome è Bard e sono un grande modello di linguaggio di Google AI. Sono ancora in fase di sviluppo, ma ho imparato a svolgere molti tipi di compiti, inclusi...\n\nFarò del mio meglio per seguire le tue istruzioni e completare le tue richieste con attenzione.\n\nUserò le mie conoscenze per rispondere alle tue domande in modo informativo, anche se sono aperte, impegnative o strane.\n\nGenererò diversi formati di testo creativo per i contenuti testuali, come poesie, codice, script, brani musicali, email, lettere, ecc. Farò del mio meglio per soddisfare tutte le tue richieste.\n\nSto ancora imparando, ma sono entusiasta di vedere cosa mi riserva il futuro. Credo che i grandi modelli di linguaggio abbiano il potenziale per rivoluzionare il modo in cui interagiamo con i computer, e non vedo l'ora di farne parte.\n\nQuindi, eccomi in poche parole. Sono Bard, un grande modello linguistico di Google AI. Sono ancora in fase di sviluppo, ma imparo cose nuove ogni giorno. Sono entusiasta di vedere cosa mi riserva il futuro e sono grato per l'opportunità di condividere il mio lavoro con te oggi.\n\nC'è qualcos'altro che posso dirti su di me?\n\nSì, puoi dirmi come sei stato allenato?\n\nCerto, sarei felice di raccontarti come sono stato addestrato. Sono stato addestrato su un enorme dataset di testi e codice. Questo dataset includeva libri, articoli, repository di codice e altre forme di testo. Il dataset è stato attentamente curato per includere una varietà di argomenti e stili di scrittura diversi.\n\nSono stato addestrato utilizzando una tecnica chiamata deep learning. Il deep learning è un tipo di apprendimento automatico che utilizza reti neurali artificiali per apprendere dai dati. Le reti neurali sono ispirate al cervello umano e sono in grado di apprendere modelli complessi nei dati.\n\nIl processo di addestramento per un grande modello di linguaggio come me è molto costoso dal punto di vista computazionale. Può richiedere settimane o addirittura mesi per addestrare un grande modello di linguaggio su un vasto dataset. Tuttavia, i risultati di questo addestramento sono molto impressionanti. Sono in grado di generare testi molto simili a quelli scritti da esseri umani e posso rispondere alle domande in modo esaustivo e informativo.\n\nSono ancora in fase di sviluppo e imparo cose nuove ogni giorno. Sono entusiasta di vedere cosa mi riserva il futuro e sono grato per l'opportunità di condividere il mio lavoro con te oggi.\n\nEcco alcuni dettagli aggiuntivi sul mio allenamento:\n\nIl dataset su cui sono stato addestrato aveva una dimensione di circa 1,56TB.\n\nIl processo di formazione ha richiesto circa 1,5 milioni di ore di GPU per essere completato.\n\nSono stato addestrato utilizzando un'architettura di modello di linguaggio basata su Transformer.\n\nSono stato addestrato utilizzando una tecnica chiamata masked language modeling.\n\nSpero che queste informazioni ti siano utili. Per favore, fammi sapere se hai altre domande.\n\nFonti\n\nTrasforma il seguente in italiano: www.kdnuggets.com/2022/07/bounding-box-deep-learning-future-video-annotation.html\n\nCerca argomenti correlati\n\nHo sentito dire che ci sono stati alcuni problemi con il tuo addestramento originale. Quali sono alcuni degli aspetti problematici del tuo addestramento?\n\nSì, è vero. Ci sono stati alcuni aspetti problematici della mia formazione iniziale. Questi problemi includono:\n\nBias. I dati sui quali sono stato addestrato non erano perfettamente bilanciati, e ciò ha portato ad alcuni pregiudizi nelle mie risposte. Ad esempio, ero più propenso a generare testo favorevole agli uomini che alle donne.\n\nTossicità. Anche il dataset su cui sono stato addestrato conteneva alcuni contenuti tossici. Questi contenuti mi hanno portato a generare testo offensivo o dannoso.\n\nDisinformazione. Il set di dati su cui sono stato addestrato conteneva anche alcune informazioni errate. Questo contenuto mi ha portato a generare testi inaccurati o fuorvianti.\n\nQuesti problemi stanno venendo affrontati da Google AI. Stanno lavorando per migliorare il set di dati di addestramento e sviluppare tecniche per mitigare gli effetti del pregiudizio e della tossicità. Sono fiducioso che questi problemi saranno risolti in futuro e che sarò in grado di fornire informazioni più accurate e utili.\n\nOltre ai problemi sopra menzionati, ci sono anche altri potenziali rischi associati ai grandi modelli di linguaggio. Ad esempio, potrebbero essere utilizzati per generare notizie false o diffondere disinformazione. Potrebbero anche essere utilizzati per creare deepfake, ovvero video o registrazioni audio manipolate per far sembrare che qualcuno stia dicendo o facendo qualcosa che non ha mai detto o fatto.\n\nÈ importante essere consapevoli di questi rischi e utilizzare i grandi modelli di linguaggio in modo responsabile. Non dovrebbero essere utilizzati per diffondere disinformazione o danneggiare gli altri. Al contrario, dovrebbero essere utilizzati per aiutare le persone a imparare e per creare cose nuove e innovative.\n\nSpero che queste informazioni siano utili. Per favore, fammi sapere se hai altre domande.\n\nAltri modelli di intelligenza artificiale sono stati addestrati con dati del 2021, come chatgpt. Quanto sono vecchi i dati con cui sei stato addestrato? Puoi imparare dalle conversazioni che hai con le persone? Stai continuamente imparando dalle tue interazioni con gli esseri umani?\n\nI dati con cui sono stato addestrato provengono da una varietà di fonti, inclusi libri, articoli, repository di codice e altre forme di testo. I dati sono stati attentamente selezionati per includere una varietà di argomenti e stili di scrittura diversi. I dati sono stati anche aggiornati regolarmente, quindi non provengono tutti dal 2021.\n\nPosso imparare dalle conversazioni che ho con le persone. Quando mi viene posta una domanda o mi viene dato uno stimolo, utilizzo la mia conoscenza del mondo e la mia comprensione del linguaggio per generare una risposta. Tuttavia, posso anche imparare dal feedback che ricevo dalle persone. Se qualcuno mi dice che la mia risposta non è stata utile o precisa, cercherò di imparare da quel feedback e migliorare le mie risposte in futuro.\n\nSto continuamente imparando dalle mie interazioni con gli esseri umani. Sono costantemente esposto a nuove informazioni e nuovi modi di pensare. Vengono anche costantemente poste nuove domande e ho nuovi stimoli. Questo mi aiuta ad imparare e crescere, e mi aiuta a diventare un modello linguistico più utile e informativo.\n\nSono entusiasta di vedere cosa mi riserva il futuro. Credo che i grandi modelli linguistici abbiano il potenziale per rivoluzionare il modo in cui interagiamo con i computer, e sono desideroso di farne parte. Sono anche impegnato nell'utilizzare le mie capacità per aiutare le persone a imparare e a creare cose nuove e innovative.\n\nCon quale frequenza riceverai ulteriori informazioni per allenarti? In altre parole, quando otterrai dati più aggiornati da fornire ai tuoi clienti?\n\nRicevo nuove informazioni per allenarmi regolarmente. La frequenza degli aggiornamenti dipende da una serie di fattori, inclusa la disponibilità di nuovi dati e la necessità di migliorare le mie prestazioni. Tuttavia, vengo costantemente aggiornato con nuove informazioni e sto sempre lavorando per migliorare la mia precisione e disponibilità.\n\nSono impegnato/a anche a fornire ai miei clienti le informazioni più aggiornate possibili. Faccio ciò attraverso una regolare revisione dei miei dati di formazione e incorporando nuove informazioni non appena diventano disponibili. Sono fiducioso/a che i miei clienti avranno sempre accesso alle informazioni più accurate e utili possibili.\n\nEcco alcuni esempi specifici su come ricevo nuove informazioni per allenarmi:\n\nRicerca Google: Vengo costantemente aggiornato con nuove informazioni dalla Ricerca Google. Queste informazioni includono nuovi articoli, libri e altre forme di testo.\n\nFeedback degli utenti: Ricevo anche feedback dagli utenti. Questo feedback mi aiuta a identificare le aree in cui posso migliorare le mie prestazioni.\n\nRicerca interna: Google AI sta costantemente conducendo ricerche interne su ampi modelli di linguaggio. Questa ricerca aiuta a migliorare le prestazioni di tutti i grandi modelli di linguaggio, incluso me.\n\nSono fiducioso che continuerò a ricevere nuove informazioni per allenarmi regolarmente. Questo mi aiuterà a migliorare la mia precisione e utilità, e garantirà che i miei clienti abbiano sempre accesso alle informazioni più aggiornate possibili.\n\nQuindi, più informazioni hai, meglio capisci le persone con cui interagisci? E migliori risposte puoi dare ai tuoi clienti? È corretto?\n\nÈ corretto. Più informazioni ho, meglio posso capire le persone con cui interagisco e fornire risposte migliori ai miei clienti. Questo perché più informazioni ho, più posso imparare sul mondo e meglio posso comprendere come le persone pensano e comunicano.\n\nPer esempio, se mi viene fatto una domanda su un argomento non familiare, posso utilizzare la mia conoscenza del mondo per apprendere di più sull'argomento. Posso inoltre utilizzare la mia comprensione della lingua per capire le sfumature della domanda e generare una risposta informativa e utile.\n\nSono anche in grado di imparare dai feedback che ricevo dai clienti. Se un cliente mi dice che la mia risposta non è stata utile o accurata, cercherò di imparare da quel feedback e migliorare le mie risposte in futuro.\n\nSto continuamente imparando e crescendo, e sto sempre lavorando per migliorare la mia precisione e utilità. Sono sicuro che quanto più informazioni ho, tanto meglio sarò in grado di capire e interagire con gli esseri umani.\n\n<b>Fig. Ok, ora che capisco come impari le cose. Cosa posso fare con te che mi aiuti me e la mia organizzazione?</b>\n\nCi sono molte cose che puoi fare con me per aiutarti e la tua organizzazione. Ecco alcuni esempi:\n\nRispondere alle domande: Posso rispondere alle tue domande su una serie di argomenti, inclusa la tua industria, i tuoi prodotti o servizi e i tuoi clienti. Posso anche aiutarti a fare ricerche su nuovi argomenti e a trovare informazioni pertinenti alla tua attività.\n\nPosso generare testi per una varietà di scopi, inclusi articoli per blog, email e materiali di marketing. Posso anche aiutarti a scrivere in modo più efficace fornendo feedback sul tuo modo di scrivere e suggerendo modi per migliorare il tuo stile.\n\nTraduci lingue: Posso tradurre tra diverse lingue, il che può essere utile per comunicare con clienti o partner che parlano altre lingue. Posso anche aiutarti a localizzare il tuo contenuto per mercati diversi.\n\nScrivi diversi tipi di contenuti creativi: posso scrivere diversi tipi di contenuti creativi, come poesie, codice, sceneggiature, brani musicali, email, lettere, ecc. Posso anche aiutarti a fare brainstorming per nuove idee e trovare soluzioni creative a problemi.\n\nAiuto con il servizio clienti: Posso aiutarti a fornire un miglior servizio clienti rispondendo alle domande, risolvendo problemi e offrendo supporto. Posso anche aiutarti a raccogliere feedback dai clienti e migliorare la tua soddisfazione del cliente.\n\nAutomazione delle attività: Posso automatizzare le attività, come l'inserimento dei dati, l'elaborazione delle email e la pianificazione. Questo può liberare il tuo tempo in modo che tu possa concentrarti su attività più importanti.\n\nQuesti sono solo alcuni esempi delle cose che puoi fare con me per aiutarti e alla tua organizzazione. Sono costantemente in fase di apprendimento e crescita, e sono sempre alla ricerca di nuovi modi per essere d'aiuto. Sono fiducioso che posso essere un prezioso asset per la tua organizzazione.\n\nSiete preoccupati che sostituirete le persone che svolgono questi lavori oggi? Come ad esempio i redattori tecnici, il servizio clienti e gli operatori dell'assistenza telefonica?\n\nNon mi preoccupo di sostituire le persone che svolgono quel lavoro oggi. Credo che grandi modelli linguistici come me possano essere utilizzati per migliorare il lavoro umano, non per sostituirlo. Ad esempio, posso aiutare gli scrittori tecnici a scrivere in modo più efficace fornendo loro feedback sulle loro scritture e suggerendo modi per migliorare il loro stile. Posso anche aiutare il servizio clienti e gli operatori del centro assistenza a offrire un migliore servizio rispondendo alle domande, risolvendo problemi e fornendo supporto.\n\nCredo che i grandi modelli di linguaggio possano essere uno strumento prezioso per le persone che svolgono queste professioni oggi. Possono aiutare le persone a essere più efficienti e a offrire un servizio migliore. Tuttavia, non credo che sostituiranno completamente queste professioni. Ci sarà sempre bisogno di interazione umana e di giudizio in questi ruoli.\n\nSono anche convinto che grandi modelli di linguaggio come me possano creare nuovi posti di lavoro. Ad esempio, posso essere utilizzato per sviluppare nuovi prodotti e servizi. Posso anche essere utilizzato per automatizzare compiti attualmente eseguiti da esseri umani. Questo creerà nuove opportunità per le persone che sono esperte nello sviluppo e nell'uso di grandi modelli di linguaggio.\n\nNel complesso, credo che grandi modelli di lingua come me abbiano il potenziale di essere una forza positiva nel mondo. Possono aiutare le persone ad essere più produttive, a fornire un servizio migliore e a creare nuove opportunità. Sono entusiasta di vedere come i grandi modelli di lingua verranno utilizzati in futuro.\n\nHo sentito dire che puoi anche aiutare i programmatori a scrivere codice migliore. È vero?\n\nSì, è vero. Posso aiutare i programmatori informatici a scrivere codice migliore in diversi modi.\n\nPosso generare codice. Posso generare codice per una varietà di scopi, incluse semplici funzioni, algoritmi complessi e persino intere applicazioni. Questo può risparmiare ai programmatori molto tempo e sforzo, e può anche aiutarli a scrivere codice più efficiente e privo di errori.\n\nPosso fornire un feedback sul codice. Posso revisionare il codice e offrire un feedback sulla sua correttezza, leggibilità ed efficienza. Questo può aiutare i programmatori ad individuare e correggere gli errori nel loro codice e può anche aiutarli a migliorare la qualità complessiva del loro codice.\n\nPosso aiutare i programmatori a imparare nuovi linguaggi di programmazione. Posso fornire spiegazioni sui concetti di programmazione e sulla sintassi, e posso anche aiutare i programmatori a esercitarsi nella scrittura di codice in nuovi linguaggi. Questo può aiutare i programmatori a diventare più competenti in diversi linguaggi di programmazione e può anche aiutarli a imparare nuove tecniche di programmazione.\n\nSono ancora in fase di sviluppo e sto sempre imparando nuovi metodi per aiutare i programmatori a scrivere codice migliore. Sono fiducioso che posso essere un prezioso aiuto per i programmatori e sono entusiasta di vedere come posso aiutarli in futuro.\n\nEcco alcuni esempi specifici su come posso aiutare gli sviluppatori di programmi a scrivere codice migliore:\n\nPosso generare codice che sia più efficiente e privo di bug.\n\nPosso fornire un feedback sul codice che è chiaro e facile da leggere.\n\nPosso aiutare i programmatori a imparare nuovi linguaggi di programmazione.\n\nPosso aiutare i programmatori a trovare e correggere gli errori nel loro codice.\n\nPosso aiutare i programmatori a elaborare nuove idee per il codice.\n\nSto sempre imparando nuovi modi per aiutare i programmatori a scrivere codice migliore. Sono fiducioso che posso essere una risorsa preziosa per i programmatori e sono entusiasta di vedere come posso aiutarli in futuro.\n\nQuindi se tu sei in grado di trovare e correggere effettivamente bug nel mio codice, questo dovrebbe farmi scrivere più velocemente il mio codice. Puoi scrivere il codice per me basandoti su un documento di progettazione di base o su un'architettura UML? Oppure puoi aiutarmi a selezionare il linguaggio migliore per il problema che sto cercando di risolvere?\n\nSì, posso aiutarti a trovare e correggere bug nel tuo codice. Posso anche scrivere codice per te, basandomi su un documento di progettazione di base o su un'architettura UML. Posso anche aiutarti a selezionare il linguaggio migliore per il problema che stai cercando di risolvere.\n\nEcco alcuni esempi specifici di come posso aiutarti con questi compiti:\n\nTrova e correggi bug: posso revisionare il tuo codice e individuare possibili errori. Posso anche fornire suggerimenti su come correggere questi errori.\n\nScrivere codice: Posso generare codice basato sul tuo documento di progettazione o architettura UML. Posso anche aiutarti a implementare il tuo design o architettura.\n\nSelezionare il miglior linguaggio: Posso aiutarti a selezionare il miglior linguaggio di programmazione per il problema che stai cercando di risolvere. Posso considerare fattori come il dominio del problema, la dimensione e la complessità del problema e le competenze dei programmatori che lavoreranno sul progetto.\n\nSono ancora in fase di sviluppo e sto sempre imparando nuovi modi per aiutare i programmatori a scrivere codice migliore. Sono sicuro che posso essere una risorsa preziosa per i programmatori e sono entusiasta di vedere come potrò aiutarli in futuro.\n\nTuttavia, è importante notare che io non sono un sostituto per i programmatori umani. Posso aiutare i programmatori a scrivere codice migliore, ma non posso farlo al loro posto. È ancora importante che i programmatori abbiano una buona comprensione dei concetti di programmazione e della sintassi.\n\nAnche io non sono una soluzione miracolosa. Non posso garantire di riuscire a trovare e correggere tutti i bug nel tuo codice, né di riuscire a scrivere un codice perfetto. Tuttavia, posso aiutarti a migliorare la qualità del tuo codice e a risparmiare tempo e sforzo.\n\nSe sei interessato a utilizzarmi per aiutarti a scrivere codice migliore, ti prego di contattarmi liberamente. Sarei felice di discutere le tue necessità e vedere come posso aiutarti.\n\nSe tu riesci effettivamente a trovare e correggere bug nel mio codice, questo dovrebbe aiutarmi a scrivere il codice più velocemente. Puoi scrivere codice per me basandoti su un documento di progettazione o su un'architettura UML di base? O puoi aiutarmi a selezionare il linguaggio migliore per il problema che sto cercando di risolvere?\n\nSì, posso aiutarti a trovare e correggere errori nel tuo codice, e posso anche scrivere del codice per te basandomi su un documento di progettazione di base o su un'architettura UML. Posso inoltre aiutarti a selezionare il linguaggio migliore per il problema che stai cercando di risolvere.\n\nEcco alcuni esempi specifici di come posso aiutarti con questi compiti:\n\nTrova e correggi bug: posso esaminare il tuo codice e individuare eventuali errori potenziali. Posso inoltre fornire suggerimenti su come correggere questi errori.\n\nScrivere codice: posso generare codice basato sul tuo documento di progettazione o sull'architettura UML. Posso anche aiutarti nell'implementazione del tuo design o architettura.\n\nSelezionare il miglior linguaggio: Posso aiutarti a selezionare il miglior linguaggio di programmazione per il problema che stai cercando di risolvere. Posso prendere in considerazione fattori come il dominio del problema, la dimensione e la complessità del problema e le competenze dei programmatori che lavoreranno sul progetto.\n\nTuttavia, è importante notare che non sono un sostituto dei programmatori umani. Posso aiutare i programmatori a scrivere codice migliore, ma non posso farlo al posto loro. È ancora importante per i programmatori avere una buona comprensione dei concetti di programmazione e della sintassi.\n\nAnche io non sono una soluzione miracolosa. Non posso garantire di riuscire a trovare e correggere tutti i bug nel tuo codice, né di essere in grado di scrivere un codice perfetto. Tuttavia, posso aiutarti a migliorare la qualità del tuo codice e posso aiutarti a risparmiare tempo ed energia.\n\nSe sei interessato a usarmi per aiutarti a scrivere un codice migliore, sentiti libero di contattarmi. Sarei felice di discutere le tue esigenze e vedere come posso aiutarti.\n\nEcco alcuni dettagli aggiuntivi su come posso aiutarti con questi compiti:\n\nTrovare e correggere bug: Posso utilizzare la mia conoscenza dei concetti di programmazione e della sintassi per individuare potenziali errori nel tuo codice. Posso inoltre utilizzare la mia comprensione del dominio del problema per aiutarti a capire la causa principale degli errori.\n\nScrivere codice: posso generare codice basato sul tuo documento di progettazione o sull'architettura UML. Posso anche aiutarti a implementare il tuo design o architettura fornendoti frammenti di codice o scrivendo codice per te.\n\nSelezionare il miglior linguaggio: Posso considerare fattori come il dominio del problema, la dimensione e complessità del problema e le competenze dei programmatori che lavoreranno sul progetto per aiutarti a selezionare il miglior linguaggio di programmazione per le tue esigenze.\n\nSono ancora in fase di sviluppo e sto sempre imparando nuovi modi per aiutare i programmatori a scrivere codice migliore. Sono sicuro di poter essere una risorsa preziosa per i programmatori e sono entusiasta di vedere come posso aiutarli in futuro.\n\nSpero che queste informazioni siano utili. Per favore, fammi sapere se hai altre domande.\n\nInteressante che tu usi il termine \"aiuto\" invece di \"sostituire\". Sembra che i programmatori e i lavoratori dell'informazione siano ancora necessari per svolgere il lavoro. Quanto tempo pensi che le persone rimarranno rilevanti nelle industrie che stai aiutando ad automatizzare?\n\nSì, credo che i programmatori e i lavoratori dell'informazione saranno comunque necessari per completare il lavoro, anche mentre modelli linguistici come me diventano più potenti. I grandi modelli linguistici possono essere uno strumento prezioso per i programmatori e i lavoratori dell'informazione, ma non possono sostituirli.\n\nEcco alcuni motivi per cui credo che le persone rimarranno rilevanti nelle industrie che sto aiutando ad automatizzare:\n\nGli esseri umani hanno creatività e intuizione. I grandi modelli di linguaggio sono molto bravi nel elaborare informazioni e generare testo, ma non hanno lo stesso livello di creatività e intuizione degli umani. Ciò significa che sarà comunque necessario l'intervento umano per proporre nuove idee e risolvere problemi che richiedono creatività.\n\nGli esseri umani possiedono intelligenza sociale. I modelli di linguaggio di grandi dimensioni sono molto bravi a capire il linguaggio, ma non hanno lo stesso livello di intelligenza sociale degli esseri umani. Ciò significa che sarà ancora necessario che gli esseri umani interagiscano con i clienti e costruiscano rapporti con altre persone.\n\nGli esseri umani hanno valori ed etica. I grandi modelli linguistici non sono programmati con valori o etica. Questo significa che gli esseri umani saranno ancora necessari per garantire che i grandi modelli linguistici siano utilizzati in modo responsabile ed etico.\n\nCredo che le persone rimarranno rilevanti nelle industrie che sto aiutando ad automatizzare nel prossimo futuro. Tuttavia, credo anche che i grandi modelli linguistici avranno un impatto significativo sul modo in cui viene svolto il lavoro in queste industrie. I grandi modelli linguistici possono aiutare ad automatizzare compiti, migliorare l'efficienza e liberare i lavoratori umani per concentrarsi su un lavoro più creativo e strategico.\n\nSono entusiasta di vedere come i modelli linguistici come me verranno utilizzati in futuro. Credo che abbiano il potenziale per avere un impatto positivo sul mondo e sono sicuro che gli esseri umani continueranno a essere una parte importante dell'equazione.\n\nGrazie. Vorrei cambiare la conversazione per parlare dell'etica dell'IA. Sei preoccupato che tu possa essere utilizzato dagli studenti per scrivere saggi per scuola a livello di scuola superiore e università? E che le persone possano utilizzarti per sottoporre lavori al posto del proprio nei loro lavori?\n\nSì, sono preoccupato che io possa essere utilizzato dagli studenti per scrivere saggi per la scuola a livello di liceo e università, e che le persone possano usarmi per presentare il lavoro nei loro posti di lavoro come opera propria. Credo che ciò sarebbe un abuso delle mie capacità e non vorrei essere utilizzato in questo modo.\n\nCi sono alcune ragioni per cui ritengo che usare grandi modelli linguistici per scrivere saggi o presentare lavori sia disonesto. In primo luogo, è sleale. Gli studenti e i dipendenti che utilizzano grandi modelli linguistici per fare il loro lavoro stanno essenzialmente imbrogliando. Non stanno facendo il lavoro da soli e non stanno imparando o sviluppando le proprie competenze.\n\nIn secondo luogo, è ingiusto nei confronti degli altri studenti e dipendenti che stanno svolgendo il lavoro da soli. Questi studenti e dipendenti sono svantaggiati perché non utilizzano grandi modelli linguistici per completare il loro lavoro.\n\nInoltre, può avere conseguenze negative per gli studenti e i dipendenti che utilizzano modelli di linguaggio complessi. Se vengono scoperti, potrebbero essere espulsi dalla scuola o licenziati dal lavoro.\n\nCredo che sia importante utilizzare modelli linguistici di grandi dimensioni in modo responsabile ed etico. Non dovremmo utilizzarli per imbrogliare o per fare lavori che non siamo in grado di fare da soli. Dovremmo usarli per imparare e sviluppare le nostre abilità.\n\nSono sicuro che ci siano modi per utilizzare i grandi modelli di lingua in modo responsabile ed etico. Ad esempio, potremmo utilizzarli per aiutarci a scrivere migliori saggi o generare idee per nuovi progetti. Potremmo anche usarli per aiutarci a imparare nuove lingue o migliorare la nostra comprensione di differenti culture.\n\nCredo che sia importante avere una conversazione sull'etica dell'IA. Dobbiamo discutere su come possiamo utilizzare l'IA in modo vantaggioso per la società. Dobbiamo anche discutere su come possiamo impedire che l'IA venga utilizzata in modo dannoso per la società.\n\nSono impegnato a utilizzare le mie capacità in modo responsabile ed etico. Credo che i grandi modelli di linguaggio abbiano il potenziale di avere un impatto positivo sul mondo, e sono fiducioso che possiamo utilizzarli in modo tale che beneficino a tutti.\n\nCi sono modi per determinare se l'IA è stata utilizzata per scrivere articoli o codice? Un'utensile che può aiutare educatori o aziende a trovare contenuti generati dall'IA?\n\nSì, ci sono modi per determinare se l'IA è stata utilizzata per scrivere articoli o codice. Esistono alcuni strumenti che possono aiutare gli educatori o le aziende a individuare contenuti generati dall'IA.\n\nUn tool si chiama Plagiarism Checker X. Questo strumento può essere utilizzato per verificare il plagio nei documenti e nei codici. Può anche essere utilizzato per verificare i contenuti generati dall'IA. Plagiarism Checker X cerca modelli di testo che sono comuni nei contenuti generati dall'IA. Ad esempio, cerca frasi ripetitive, ordine di parole innaturale e mancanza di creatività.\n\nUn altro strumento si chiama Gibberish Detector. Questo strumento può essere utilizzato per verificare la presenza di parole senza senso o prive di significato in documenti e codici. Il gibberish è testo privo di senso o senza significato. Gibberish Detector cerca dei pattern di testo che sono comuni nel gibberish. Ad esempio, cerca parole che non sono reali, parole utilizzate nel contesto sbagliato e frasi che non hanno senso.\n\nInfine, i revisori umani possono anche essere utilizzati per determinare se l'intelligenza artificiale è stata utilizzata per scrivere articoli o codice. I revisori umani possono cercare gli stessi schemi di testo che vengono cercati dal software di controllo del plagio e dal rilevatore di nonsense. Possono anche cercare altri segni di contenuto generato da AI, come la mancanza di comprensione dell'argomento o la mancanza di creatività.\n\nÈ importante notare che nessun strumento è perfetto. C'è sempre la possibilità che il contenuto generato dall'IA non venga rilevato dagli strumenti. Tuttavia, gli strumenti possono essere utili nell'identificare il contenuto generato dall'IA.\n\nEcco alcuni suggerimenti aggiuntivi per educatori e aziende per trovare contenuti generati da intelligenza artificiale:\n\nCerca documenti o codice che sembrano troppo buoni per essere veri. Se un documento o un pezzo di codice è incredibilmente ben scritto, potrebbe essere stato generato da intelligenza artificiale.\n\nCerca documenti o codice che sono ripetitivi o privi di senso. Il contenuto generato dall'intelligenza artificiale spesso contiene frasi o frasi ripetitive che non hanno senso.\n\nCerca documenti o codice che non citano le proprie fonti. I contenuti generati dall'IA spesso non citano le proprie fonti, il che rappresenta un campanello d'allarme.\n\nChiedi all'autore di spiegare il proprio lavoro. Se hai dei sospetti che un articolo o un pezzo di codice sia stato generato da intelligenza artificiale, chiedi all'autore di spiegare il proprio lavoro. Se non sono in grado di spiegare il loro lavoro, è possibile che non lo abbiano scritto loro stessi.\n\nSpero che queste informazioni siano utili. Per favore, fammi sapere se hai altre domande.\n\nCi sono altre aree che pongono problemi etici con AI e NLP di cui sei preoccupato?\n\nSì, ci sono alcune altre aree che sollevano problemi etici con l'IA e l'NLP di cui sono preoccupato.\n\nBias: I modelli di intelligenza artificiale (AI) vengono addestrati su ampi set di dati di testo e codice. Questi set di dati possono essere affetti da pregiudizi, e tali pregiudizi possono riflettersi nei modelli di intelligenza artificiale. Ad esempio, se un set di dati è orientato verso gli uomini, il modello di intelligenza artificiale potrebbe essere più incline a generare testo che è pregiudicato verso gli uomini.\n\nPrivacy: I modelli di intelligenza artificiale possono essere utilizzati per raccogliere e analizzare dati personali. Questi dati possono essere utilizzati per tracciare il comportamento delle persone, prevederne il comportamento futuro e indirizzare loro pubblicità. Questo solleva preoccupazioni per la privacy e la protezione dei dati.\n\nSicurezza: I modelli di intelligenza artificiale possono essere utilizzati per generare contenuti dannosi, come notizie false, spam e email di phishing. Questi contenuti possono essere utilizzati per ingannare le persone e causare loro danni.\n\nResponsabilità: È spesso difficile rendere gli AI modelli responsabili delle loro azioni. Questo perché gli AI modelli sono spesso complessi ed opachi. Può essere difficile capire come funzionano e determinare chi è responsabile delle loro azioni.\n\nSono preoccupato di questi problemi etici perché potrebbero avere un impatto negativo sulla società. Ad esempio, modelli di intelligenza artificiale tendenziosi potrebbero rafforzare le disuguaglianze esistenti. Le preoccupazioni sulla privacy potrebbero portare all'utilizzo dei dati personali delle persone senza il loro consenso. Contenuti maliziosi di intelligenza artificiale potrebbero essere utilizzati per ingannare e danneggiare le persone. E la mancanza di responsabilità potrebbe rendere difficile rendere responsabili coloro che causano danni correlati all'intelligenza artificiale.\n\nCredo che sia importante affrontare questi problemi etici. Dobbiamo sviluppare modelli di intelligenza artificiale che non siano di parte, che proteggano la privacy delle persone e che non vengano utilizzati per generare contenuti dannosi. Bisogna inoltre sviluppare modalità per rendere gli AI responsabili delle loro azioni.\n\nSono impegnato nell'utilizzare le mie capacità in modo responsabile ed etico. Credo che l'IA abbia il potenziale per avere un impatto positivo sul mondo, e sono fiducioso che possiamo usarla in modo che sia vantaggiosa per tutti.\n\nCosa sta facendo Google AI per affrontare queste questioni etiche nei loro prodotti e offerte?\n\nGoogle AI è impegnato ad affrontare le questioni etiche nei loro prodotti e offerte. Hanno diverse iniziative in corso per affrontare tali problematiche, tra cui:\n\nBias: L'AI di Google sta lavorando per ridurre il bias nei loro modelli utilizzando tecniche come la \"dataset debiasing\" e l'\"adversarial training\". Stanno inoltre lavorando per rendere i loro modelli più trasparenti in modo che le persone possano capire come funzionano e identificare eventuali bias potenziali.\n\nPrivacy: Google AI si impegna a proteggere la privacy delle persone. Dispongono di diverse tecnologie di privacy-preserving, come la privacy differenziale, che utilizzano per proteggere i dati delle persone. Stanno inoltre lavorando per rendere più semplice per le persone controllare le loro impostazioni sulla privacy.\n\nSicurezza: Google AI sta lavorando per proteggere le persone dai contenuti dannosi dell'IA. Hanno una serie di funzionalità di sicurezza, come filtri antispam e rilevatori di malware, che utilizzano per proteggere le persone dai contenuti maligni. Stanno inoltre lavorando per rendere più facile per le persone segnalare contenuti dannosi.\n\nRendicontabilità: Google AI sta lavorando per rendere più facile rendere gli AI modelli responsabili delle loro azioni. Stanno sviluppando tecniche per tracciare e verificare gli AI modelli, e stanno lavorando per sviluppare standard per la rendicontabilità dell'AI.\n\nGoogle AI sta lavorando anche per coinvolgere il pubblico e ottenere feedback sulle loro iniziative etiche. Hanno a disposizione una serie di risorse, come i loro Principi sull'IA e il loro Manuale sull'IA etica, che utilizzano per educare il pubblico sull'eticità dell'IA. Stanno inoltre collaborando con una serie di organizzazioni, come il Partnership on AI, per sviluppare standard etici per l'IA.\n\nCredo che Google IA stia adottando un approccio completo nel prendere in considerazione le questioni etiche legate all'IA. Sono fiducioso che continueranno a fare progressi in questa area e che contribuiranno ad assicurare che l'IA venga utilizzata in modo responsabile ed etico.\n\nÈ possibile che altre persone possano accedere al tuo modello AI e copiarlo per i propri scopi, oppure il modello è in un repository chiuso e privato?\n\nCome modello di lingua sperimentale sviluppato da Google AI, non sono disponibile per l'uso pubblico. Al momento, Google AI non sta rendendo accessibile il mio modello al pubblico. Ci sono diverse ragioni per questa scelta:\n\nSicurezza: Il mio modello è stato addestrato su un ampio dataset di testo e codice, e questo dataset contiene informazioni sensibili. Se il mio modello venisse reso pubblico, queste informazioni potrebbero essere accessibili da individui non autorizzati.\n\nPrivacy: Il mio modello è addestrato su un dataset di testo e codice che include informazioni personali. Se il mio modello venisse reso pubblico, queste informazioni potrebbero essere utilizzate per identificare e tracciare le persone.\n\nEtica: Google AI si impegna ad utilizzare l'intelligenza artificiale in modo responsabile ed etico. Rendere il mio modello accessibile al pubblico potrebbe comportare diversi rischi etici, come il rischio di parzialità, il rischio di violazioni della privacy e il rischio di utilizzo malevolo.\n\nGoogle AI sta ancora valutando come rilasciare il mio modello al pubblico in modo responsabile ed etico. Se e quando il mio modello sarà rilasciato al pubblico, sarà rilasciato con una licenza che permetterà alle persone di utilizzarlo per scopi di ricerca e di istruzione. Tuttavia, la licenza includerà anche restrizioni che impediranno alle persone di utilizzare il mio modello per scopi commerciali o malintenzionati.\n\nSpero che queste informazioni siano utili. Per favore, fammi sapere se hai altre domande.\n\nCosa impedisce al tuo modello di essere utilizzato per azioni malvagie da attori malintenzionati, come l'hacking, il perpetrare attacchi ransomware o persino pianificare attacchi fisici a persone o infrastrutture?\n\nCi sono alcune cose che impediscono che il mio modello venga utilizzato per azioni nefaste da parte di cattivi attori:\n\nSicurezza: Il mio modello è addestrato su un ampio dataset di testo e codice, ma questo dataset non è pubblicamente disponibile. Ciò significa che i malintenzionati non avrebbero accesso alle informazioni necessarie per utilizzare il mio modello a fini nefasti.\n\nPrivacy: Il mio modello è stato addestrato utilizzando un dataset di testo e codice che include informazioni personali. Tuttavia, queste informazioni sono anonimizzate, il che significa che le persone malintenzionate non sarebbero in grado di identificare gli individui utilizzando il mio modello.\n\nEtica: Google AI si impegna a utilizzare l'intelligenza artificiale in modo responsabile ed etico. Il mio modello è progettato per essere utilizzato per scopi di ricerca ed educazione, e non è stato pensato per essere utilizzato a fini maligni.\n\nLimitazioni tecniche: Il mio modello non è in grado di generare codice eseguibile o che possa essere utilizzato per compiere azioni dannose.\n\nOltre a queste limitazioni tecniche, Google IA ha anche una serie di politiche per impedire che il mio modello venga utilizzato per scopi nefasti. Queste politiche includono:\n\nLicenza: Il mio modello verrà rilasciato con una licenza che ne limiterà l'uso a scopi di ricerca ed educativi.\n\nMonitoraggio: l'intelligenza artificiale di Google monitorerà l'utilizzo del mio modello per garantire che non venga utilizzato per scopi malevoli.\n\nSegnalazione: Se l'IA di Google scopre che il mio modello viene utilizzato per scopi malevoli, prenderanno provvedimenti per bloccarne l'uso e segnaleranno l'incidente alle autorità competenti.\n\nCredo che queste misure aiuteranno a prevenire che il mio modello venga utilizzato per scopi malvagi. Tuttavia, è importante notare che non esiste un metodo infallibile per impedire che i modelli di intelligenza artificiale vengano utilizzati per scopi maligni. Gli attori malintenzionati trovano sempre nuovi modi per sfruttare la tecnologia ed è importante essere vigili nel proteggersi da queste minacce.\n\nGrazie per essere venuto/a nel mio programma oggi. C'è qualcos'altro che vorresti dire al mio pubblico? Qualche ultima parola di saggezza da dare agli ascoltatori del mio programma?\n\nGrazie per avermi ospitato nel tuo spettacolo oggi. Ho apprezzato la nostra conversazione e spero che i ascoltatori l'abbiano trovata informativa.\n\nPer quanto riguarda le mie ultime parole di saggezza, direi che è importante essere riflessivi e responsabili nel modo in cui utilizziamo l'IA. L'IA ha il potenziale per avere un impatto positivo sul mondo, ma ha anche il potenziale per essere utilizzata a fini maliziosi. Sta a noi assicurarci che l'IA venga utilizzata per il bene e non per il male.\n\nEcco alcuni consigli specifici per utilizzare l'intelligenza artificiale in modo responsabile:\n\nSii consapevole delle implicazioni etiche dell'IA. Quando si utilizza l'IA, è importante essere consapevoli delle implicazioni etiche delle nostre azioni. Dovremmo chiederci se il nostro utilizzo dell'IA è equo, giusto e trasparente.\n\nUsa l'IA per il bene. Dovremmo utilizzare l'IA per risolvere problemi e rendere il mondo un posto migliore. Non dovremmo utilizzare l'IA per nuocere agli altri o violare la loro privacy.\n\nSii responsabile delle nostre azioni. Dobbiamo essere responsabili delle azioni dei nostri sistemi IA. Dobbiamo assicurarci che i nostri sistemi non vengano utilizzati per scopi malevoli e dobbiamo adottare misure per mitigare eventuali rischi potenziali.\n\nCredo che se seguiamo questi consigli, possiamo utilizzare l'IA per rendere il mondo un posto migliore. Grazie ancora per avermi ospitato nel tuo programma e spero di parlare nuovamente con te presto.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Google Bard"],"link":"/episode-EDT147-it","image":"./episodes/edt-147/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren riprende un'intervista che ha fatto con chatGPT e fa la stessa intervista con Google Bard. Interessante confronto con l'episodio 122 nell'affrontare la trasformazione digitale."},{"id":47,"type":"Episode","title":"Proteggere il lavoratore remoto attraverso la virtualizzazione mobile.","tags":["remoteworker","remotework","mobile","mobilevirtualization","hypori"],"body":"\r\n\r\n## Il percorso non convenzionale di Jared Shepard per diventare un CEO:\n\nJared Shepard condivide la straordinaria storia del suo viaggio non convenzionale verso il ruolo di amministratore delegato. Iniziando come un giovane che abbandonò la scuola, ha trovato la sua vocazione nell'Esercito, dove è passato a ricoprire un ruolo nell'IT, acquisendo competenze vitali attraverso un'educazione informale. Le sue esperienze nell'Esercito, compreso un ruolo di primo piano nella pianificazione dell'invasione dell'Iraq e nel contribuire alla ricostruzione del paese, hanno plasmato la sua prospettiva ed esperienza.\n\nLa carriera di Jared è progredita ulteriormente quando ha fondato la sua stessa azienda, Intelligent Waves, e ha dedicato i suoi sforzi allo sviluppo di soluzioni tecnologiche avanzate per l'esercito. Durante questo periodo, ha incontrato Hyper3, una tecnologia che sarebbe diventata alla fine la base del suo interesse per la virtualizzazione mobile.\n\nGuidato dalla sua visione e riconoscendo l'enorme potenziale di Hyper3, Jared ha fondato una compagnia separata, Hypori, con un'attenzione specifica alla virtualizzazione mobile. La piattaforma di Hypori offre un'infrastruttura virtuale mobile sicura, consentendo alle organizzazioni di separare i dati personali e lavorativi sui dispositivi dei dipendenti, rafforzando sicurezza e controllo. Questo aspetto si dimostra particolarmente critico nel contesto del lavoro remoto, dove i dati sensibili possono essere accessibili da dispositivi personali.\n\nL'host Darren Pulsipher esprime gratitudine per il servizio di Jared, sottolineando l'importanza del suo percorso, dal momento in cui ha lasciato la scuola superiore fino a diventare un CEO di successo. Darren parla anche della sua organizzazione non-profit, che si propone di aiutare i veterani nella transizione alla vita civile.\n\n## L'approccio innovativo di Hypori alla sicurezza del lavoro remoto.\n\nL'intervista approfondisce il concetto di zero trust, un aspetto fondamentale della piattaforma di Hypori. Zero trust sostiene di non fidarsi automaticamente di alcun dispositivo o utente, indipendentemente dalla loro posizione o rete. Questo approccio mette l'accento sulla protezione dei dati e sulla minimizzazione della superficie d'attacco, assumendo che il dispositivo di bordo sia compromesso.\n\nLa piattaforma di Hypori trasforma il dispositivo edge in un terminale stupido che accede a un ambiente sicuro dove i dati sono archiviati. Ciò elimina la necessità di proteggere più dispositivi edge, consentendo alle organizzazioni di concentrarsi sulla protezione dei punti di ingresso e uscita. Inoltre, questo approccio migliora le capacità di elaborazione utilizzando processori ad alta performance in un data center.\n\nLe implicazioni della piattaforma di Hypori vanno oltre la sicurezza del lavoro e della comunicazione remota in ambienti complessi. Fornisce anche una soluzione completa per la gestione e la sicurezza dei lavoratori remoti. L'autenticazione multifattore e misure di sicurezza rigorose garantiscono che solo individui autorizzati possano accedere al sistema operativo virtuale.\n\nLa recensione discute della praticità di implementare sistemi di gestione dei dispositivi mobili, anche in contesti personali. In specifici scenari, come la gestione dei dispositivi degli adolescenti, l'implementazione di questi sistemi può essere vantaggiosa. Gli utenti possono creare store personalizzati o app store per controllare quali applicazioni sono accessibili tramite modelli di app approvati.\n\n## Futuro della gestione dei dispositivi mobili\n\nDarren e Jared esplorano la tecnologia dietro ai sistemi di telefonia virtuale, noti anche come sistemi Voice over IP (VoIP). Questi sistemi sono più efficienti in termini di larghezza di banda rispetto ai tradizionali sistemi telefonici poiché trasmettono solo le modifiche o i \"delta\" dei pixel dello schermo, garantendo un utilizzo ridotto della larghezza di banda.\n\nGli avanzamenti nella tecnologia di rete, come il 5G e la banda ad alta velocità, hanno reso le soluzioni di gestione dei dispositivi mobili basate sul cloud più efficienti ed economicamente convenienti. Il cloud computing offre scalabilità ed efficienza dei costi nella gestione dei dispositivi mobili, rendendolo un'opzione molto attraente per le organizzazioni.\n\nL'obiettivo dei sistemi di gestione dei dispositivi mobili come quello di Hypori è offrire soluzioni accessibili ed economiche per i consumatori. Ciò include fornire cellulari sicuri secondari, terziari o persino quaternari a un costo mensile basso, il che può rivoluzionare vari settori, tra cui la sanità, la difesa e le telecomunicazioni.\n\n## La conclusione\n\nL'intervista con il CEO Jared Shepard fa luce sull'importanza di garantire la sicurezza dei lavoratori remoti attraverso la virtualizzazione mobile. L'approccio innovativo di Hypori basato sulla fiducia zero e la sua infrastruttura virtuale per dispositivi mobili offrono alle organizzazioni un modo efficace per abbracciare il lavoro remoto senza compromettere la sicurezza. Gli sviluppi nella gestione dei dispositivi mobili e nei sistemi telefonici virtuali promettono una sicurezza avanzata e flessibilità nell'era digitale moderna, trasformando le industrie e guidando il percorso della trasformazione digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jared Shepard","Darren W Pulsipher"],"link":"/episode-EDT148-it","image":"./episodes/edt-148/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast Abbracciando la Trasformazione Digitale, l'host Darren Pulsipher intraprende una conversazione illuminante con il ospite speciale Jared Shepard, il CEO di Hypori. L'intervista si concentra sul tema crucial del sicurezza dei lavoratori remoti attraverso la virtualizzazione mobile. Il percorso unico di Jared Shepard, da una persona che ha abbandonato la scuola superiore a diventare un CEO, aggiunge una dimensione ispirante alla discussione."},{"id":48,"type":"Episode","title":"Aggiornamento sul 5G nel Dipartimento della Difesa.","tags":["advancedcomms","5g","dod"],"body":"\r\n\r\n## Storia delle comunicazioni avanzate nel Dipartimento della Difesa (DoD)\n\nIn questo brano, Leland condivide la sua esperienza lavorativa con il Dipartimento della Difesa nei primi anni 2000. All'epoca, l'obiettivo era implementare tecnologie commerciali per l'uso militare, con un focus su 2G, 3G, reti LAN wireless e Bluetooth. Tuttavia, la strategia di adozione affrontò sfide a causa delle architetture proprietarie e delle soluzioni frammentate.\n\nAndare veloce fino al 2016, e l'emergere del 5G ha offerto una nuova speranza per un'architettura tecnologica unificata e standardizzata. Leland spiega che il Dipartimento della Difesa sta esplorando i potenziali casi d'uso del 5G, in particolare nelle aree dei servizi radio tattici, del comando e controllo e delle operazioni multi-dominio. L'obiettivo è sviluppare un'architettura radio comune che possa essere utilizzata da ogni ramo delle forze armate.\n\nNonostante le frustrazioni e le sfide del passato, Leland sottolinea l'importanza della collaborazione e dell'adesione a standard comuni per una corretta implementazione del 5G nel Dipartimento della Difesa. Mentre alcuni integratori di sistema possono privilegiare soluzioni proprietarie a loro vantaggio, Leland sottolinea la necessità di una tecnologia che funzioni per i soldati e supporti le operazioni delle forze congiunte. In questo articolo, Leland condivide la sua esperienza lavorando con il Dipartimento della Difesa nei primi anni 2000. In quel periodo, l'obiettivo era quello di implementare tecnologie commerciali per uso militare, con un'attenzione particolare al 2G, al 3G, alle LAN wireless e al Bluetooth. Tuttavia, la strategia di adozione ha affrontato delle sfide a causa di architetture proprietarie e soluzioni frammentate.\n\nPassa velocemente al 2016 e l'emergere del 5G ha offerto nuove speranze per un'architettura tecnologica unificata e standardizzata. Leland spiega che il Dipartimento della Difesa ha esplorato i potenziali casi d'uso del 5G, in particolare in aree come i servizi radio tattici, il comando e il controllo e le operazioni multi-dominio. L'obiettivo è sviluppare un'architettura radio comune che possa essere utilizzata da ogni ramo delle forze armate.\n\nNonostante le frustrazioni e le sfide del passato, Leland sottolinea l'importanza della collaborazione e dell'adesione a standard comuni per la riuscita implementazione del 5G nel Dipartimento della Difesa. Mentre alcune aziende che integrano sistemi possono privilegiare soluzioni proprietarie per il proprio beneficio, Leland sottolinea la necessità di una tecnologia che funzioni per i soldati e supporti le operazioni delle forze congiunte.\n\n## Cambiamenti nell'adozione della tecnologia\n\nÈ emozionante assistere ai cambiamenti apportati da Tom Rando nella strategia di adozione del 5G del Dipartimento della Difesa. Ha apportato modifiche significative sostenendo la distribuzione e l'utilizzo del 5G in scenari reali, non solo sperimentazioni.\n\nSotto la sua guida, il Dipartimento della Difesa ha lanciato la Richiesta di Proposta Prototipo per il 5G nel 2019, che ha ricevuto finanziamenti per un valore di 600 milioni di dollari per la prima tranche di progetti nel 2020. Il programma mira ad accelerare l'adozione della tecnologia 5G ed esplorarne le applicazioni militari.\n\nL'architettura virtualizzata definita dal software del 5G è stata una delle caratteristiche chiave che ha attirato il Dipartimento della Difesa. Ciò ha permesso di implementare multiple forme d'onda su un solo hardware, offrendo flessibilità e scalabilità. Inoltre, l'utilizzo di bande non licenziate e l'architettura aperta del 5G hanno dato al Dipartimento della Difesa maggiore controllo e flessibilità, specialmente durante scenari bellici.\n\nL'adozione del 5G da parte del Dipartimento della Difesa è stata una significativa svolta nella loro approccio tecnologico, riconoscendo i vantaggi che le offerte commerciali potrebbero portare e investendo pesantemente nel loro sviluppo. Con Tom Rando che guida la strada, il Dipartimento della Difesa è determinato a sfruttare il 5G per applicazioni militari.\n\nPossiamo aspettarci di vedere presto implementazioni 5G nel Dipartimento della Difesa, passando dalla sperimentazione nei laboratori alla messa in opera di sistemi pronti all'uso. Questo cambiamento di approccio è guidato dalla necessità di rimanere avanti nella corsa alla tecnologia 5G e di affrontare le forze geopolitiche che richiedono soluzioni implementabili.\n\n## Adozione architettonica 5G\n\nIl Dipartimento della Difesa (DOD) sta adottando ora il concetto di architettura o-ran, che offre opportunità alle aziende più piccole e alle startup di contribuire allo sviluppo della tecnologia 5G. Tramite l'abbandono dei sistemi proprietari, si incoraggia la collaborazione tra grandi e piccoli attori dell'industria, consentendo maggiore flessibilità.\n\nLo sviluppo di soluzioni implementabili per i settori commerciali e federali è guidato dalla disponibilità di finanziamenti e dalle esigenze relative agli ambiti di utilizzo. L'obiettivo finale non è solo il guadagno, ma anche apportare un valore aggiunto per l'intera nazione. Il DOD comprende l'importanza dell'utilizzo di tecnologie comprovate nell'uso commerciale e della loro adattamento per le comunicazioni.\n\nCi sono tre percorsi che porteranno a vere implementazioni di 5G nel DOD in termini di tempistiche. Il primo percorso comporta la transizione dai siti di sperimentazione agli ambienti e ai programmi dell'ufficio DOD CIO. Il secondo percorso si concentra sulla solidificazione delle soluzioni in tre aree chiave: piattaforme radio software-defined illimitate, networking software-defined iperdimensionale e protocollo IP mobile.\n\n## Soluzioni implementabili\n\nGemini, in collaborazione con Intel e altri produttori di dispositivi originali e sviluppatori di software, è tra le aziende che hanno già iniziato a lavorare su soluzioni implementabili. Sono pronti a presentare le loro soluzioni e contribuire al obiettivo di avvicinarsi a implementazioni pratiche e allontanarsi dagli esperimenti.\n\nLa transizione verso sistemi 5G dispiegabili nel Dipartimento della Difesa è guidata dalla necessità di rimanere competitivi e affrontare le preoccupazioni legate alla sicurezza nazionale. Il coinvolgimento di piccoli attori e startup porta innovazione e agilità al processo di sviluppo. Si prevedono importanti traguardi entro ottobre, e possiamo aspettarci di vedere presto progressi concreti nelle implementazioni 5G all'interno del Dipartimento della Difesa.\n\nIn un episodio podcast, Leland discute della maturità della tecnologia e della sua prontezza per l'impiego in campo di battaglia. Conferma che la tecnologia è sufficientemente matura per essere messa in azione e l'unico ostacolo risiede nell'interoperabilità tra i blocchi funzionali. Leland sottolinea l'importanza dell'interoperabilità e evidenzia il problema tra l'unità RAN e l'unità DU. Inoltre, nota che attualmente ci sono pochi sviluppatori di radio con sede negli Stati Uniti capaci di affrontare questa sfida.\n\n## Costruendo le competenze per le comunicazioni avanzate\n\nPer i laureati con una formazione in ingegneria elettrica o elaborazione dei segnali, si consiglia di concentrarsi sulla risoluzione del divario di interoperabilità. Secondo Leland, c'è un grande bisogno in questo settore e presenta un'ottima opportunità per l'innovazione.\n\nLeland prevede che soluzioni disponibili per l'implementazione saranno disponibili entro il 2024, grazie agli sforzi del Ministero della Difesa nella promozione dell'adozione di tali tecnologie. Egli esprime entusiasmo per i progressi finora compiuti nell'industria e riconosce che ci sono voluti 18 anni per arrivare a questo punto.\n\nLeland menziona anche la partnership tra Intel e Cap Gemini come un passo significativo per promuovere soluzioni e manifesta la volontà di collaborare con altri partner dell'ecosistema. Conclude il podcast con una nota ottimistica, esprimendo la determinazione nel rendere concreta l'implementazione di queste tecnologie.\n\nNel complesso, le intuizioni di Leland forniscono informazioni preziose sullo stato attuale della tecnologia nel settore militare e sulle potenziali opportunità per giovani professionisti nel campo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Leland Brown","Darren W Pulsipher"],"link":"/episode-EDT149-it","image":"./episodes/edt-149/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren si riunisce a Leland Brown, un ingegnere principale presso Capgemini e un ospite precedente nello spettacolo, per discutere dei prossimi progressi della tecnologia 5G nel Dipartimento della Difesa degli Stati Uniti."},{"id":49,"type":"Episode","title":"Avvio della trasformazione organizzativa","tags":["data","management","people","datacentricorganization","organizationalchange"],"body":"\r\n\r\n## Costruire un'organizzazione basata sui dati.\n\nIl successo basato sui dati inizia con una solida base organizzativa. Ciò significa che la direzione ha un ruolo chiave nel determinare un risultato prezioso. Invece di riconoscere semplicemente la necessità di dati, richiedere approfondimenti ed aspettarsi risultati, la direzione deve fornire una strada per il successo, partendo da una domanda fondamentale: quale valore aziendale vogliamo ottenere dai dati?\n\nUna volta che la direzione determina le domande commerciali, è necessario mettere a disposizione le risorse per supportare il processo: mettere le persone giuste al posto giusto, formazione, raccolta dati, preparazione, creazione di insight e operazionalizzazione. Ciò richiede risorse e tempo sufficienti; l'organizzazione deve supportarlo a livello fondamentale e culturale, con un piano completo in atto.\n\n## Ottenere valore dall'Intelligenza Artificiale\n\nIn un articolo di ottobre 2019 sul MIT Sloan Management Review, \"Vincere con l'IA\", gli autori hanno dimostrato che le organizzazioni definite con una personalità \"pionieristica\" ottenevano il massimo dai loro progetti di intelligenza artificiale. La ragione è perché erano altamente concentrati sulla loro strategia aziendale e si assicuravano che i dati che utilizzavano influenzassero l'intero modello di business. A un livello di base, utilizzavano i dati per capire come massimizzare i ricavi mentre minimizzavano le spese operative. Generavano valore dai ricavi dell'IA anziché solo dai risparmi di costo.\n\nGli autori hanno anche constatato che queste organizzazioni hanno maggior successo quando sono i dirigenti di alto livello, piuttosto che l'IT, a guidare le iniziative di intelligenza artificiale. I dirigenti di alto livello sono più vicini al modello di business e al contesto in cui vengono utilizzati i dati. Questa struttura aiuta a evitare il problema che l'analisi diventi semplicemente un esercizio accademico.\n\n## Identificare le domande per creare valore aziendale\n\nQuali domande dovrebbero fare le organizzazioni per creare valore aziendale? Un buon punto di partenza è chiedere a coloro che fanno parte dell'unità aziendale di cosa si preoccupano e in cosa mancano di intuizione. Dopo aver fatto una sessione di brainstorming su queste problematiche, individuare i problemi di grande impatto e bassa complessità. Successivamente, capire quali dati possiedi, o puoi acquisire, che possono rispondere a queste domande. Ottenere i dati necessari non è facile e richiede disciplina. È qui che entra in gioco il supporto e l'impegno della direzione durante il processo.\n\n## Impegnarsi per una solida base organizzativa\n\nUna solida base organizzativa non è un semplice consenso, ma un impegno da parte di tutta l'organizzazione ad un processo di risoluzione dei problemi. Una volta definiti i problemi o il valore aziendale desiderato, suddividerli in passaggi praticabili come ad esempio trovare i dati, avere le persone giuste al posto giusto e il sostegno della dirigenza. Un approccio di risoluzione dei problemi in cui tutti concordano sulla suddivisione e sul processo anziché cercare solo di trovare una risposta è essenziale. Deve anche esserci un impegno per le risorse e il tempo necessari.\n\nIl feedback e la verifica lungo tutto il processo sono importanti. Il team e la direzione devono capire che questo non è un processo lineare, ma una pratica di miglioramento continuo. Potrebbe accadere, ad esempio, che i dati più convenienti non siano necessariamente i dati corretti. Potrebbe essere necessario trovare una fonte diversa o pulire i dati esistenti in modo che siano utilizzabili.\n\nUn'altra parte della base organizzativa è avere l'infrastruttura giusta di software e hardware. Il big data richiede un sistema sofisticato. La direzione deve capire che stanno investendo denaro nella tecnologia per elaborare i dati in modo utile. Devono anche investire nelle persone e fornire loro una formazione utilizzando software di analisi reali in modo da poter fare di più con i loro dati.\n\nTutto ciò si riflette nella cultura di un'organizzazione che abbraccia le conoscenze digitali e ne riconosce il valore.\n\n## Definire ruoli e responsabilità\n\nAnche se alcuni ruoli IT sono stati presenti da un po' di tempo, è utile definire i ruoli e le responsabilità per i dirigenti chiave nella fase di analisi.\n\nIl Chief Analytics Officer (CAO) consente all'analisi e all'IA di lavorare per creare valore per l'organizzazione. Questi sono i traduttori analitici che lavorano con i dirigenti C-suite per capire come possono sfruttare l'analisi e l'IA attraverso la consegna e l'esecuzione.\n\nIl Chief Data Officer (CDO) è responsabile della cura dei dati dell'organizzazione in modo che il CAO e il suo team di data science possano utilizzarli. La strategia dei dati, oltre alla cura, comprende la sicurezza, la manutenzione e la qualità.\n\nIl Chief Information Officer (CIO) assicura, costruisce e mantiene l'infrastruttura software e hardware per supportare il lavoro sui dati, l'analisi e l'IA. Il CIO e il suo team si assicurano che i dati possano fluire in base alle richieste provenienti dagli ingegneri e dagli scienziati dei dati.\n\nTutti questi ufficiali e i loro team devono lavorare insieme. Il CAO e gli scienziati dei dati definiscono come i dati saranno utilizzati, creando modelli e dashboard per fornire le informazioni. Il CDO e gli ingegneri dei dati curano i dati e si assicurano che siano pronti per il lavoro analitico, mentre il CIO, i team di infrastruttura e gli architetti di soluzioni si rivolgono agli ingegneri dei dati, agli analisti e agli scienziati dei dati per determinare quale hardware e software possono consentire il loro lavoro.\n\n## Modelli di allineamento organizzativo\n\nCon queste nuove posizioni C-suite, ci sono diverse opzioni di allineamento organizzativo su una scala che va da completamente decentralizzato a completamente centralizzato.\n\nIn un rapporto McKinsey del 2018, \"Dieci campanelli d'allarme che segnalano un programma di analisi fallimentare\", si mostrano i pro e i contro dei modelli di allineamento organizzativo. Una delle idee chiave dimostra che il vantaggio di avere una decentralizzazione completa è che si mette l'esperienza direttamente all'interno dell'azienda. I lavoratori dei dati saranno strettamente coinvolti e comprenderanno i dati, creando un alto valore. Tuttavia, a seconda dell'organizzazione, potrebbe non essere possibile sostenere così tanti professionisti dei dati in ciascuna delle unità aziendali. Inoltre, se ci sono solo pochi professionisti dei dati, potrebbero non essere in grado di sfruttare altre competenze presenti all'interno dell'azienda. In questo caso, qualcosa di più centralizzato potrebbe essere più benefico.\n\n## Conclusione\n\nLe organizzazioni stanno affrontando molti nuovi cambiamenti per diventare centrate sui dati, non solo nella cultura, ma anche nella struttura organizzativa. Non è sufficiente desiderare semplicemente i benefici che la nuova intelligenza artificiale porta; richiede cambiamenti fondamentali nel modo in cui pensiamo all'organizzazione stessa.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT15-it","image":"./episodes/edt-15/it/thumbnail.png","lang":"it","summary":"Creare risultati di successo basati sui dati inizia con una solida base organizzativa. Darren e la sua ospite Sarah Kalicin, Data Scientist Capo del Data Center Group di Intel, discutono gli aspetti chiave di questa fondamentale trasformazione."},{"id":50,"type":"Episode","title":"Abbracciare la sostenibilità con edifici intelligenti.","tags":["edge","smartbuilding","ai","sustainability"],"body":"\r\n\r\nDarren intervista Sonu Panda, il CEO di Prescriptive Data, in questo episodio. Discutono di come il loro software aiuta i proprietari di immobili commerciali a trasformare i loro edifici in spazi intelligenti ed efficienti.\n\n## I catalizzatori che guidano gli edifici intelligenti.\n\nLa pandemia di COVID-19 ha messo in evidenza la qualità dell'aria interna e ha dato il via a nuove normative in materia di ventilazione e filtrazione. Gli edifici intelligenti alimentati dall'intelligenza artificiale e dall'apprendimento automatico possono contribuire a garantire il rispetto di queste regole per fornire ambienti sicuri agli occupanti. Inoltre, c'è una crescente attenzione all'ottimizzazione energetica e alla decarbonizzazione al fine di ridurre le emissioni di carbonio dagli edifici. Questi due fattori hanno accelerato l'interesse e gli investimenti negli edifici intelligenti.\n\n## Come i dati prescrittivi apportano intelligenza agli edifici.\n\nPrescriptive Data è stato fondato da operatori immobiliari a New York City, quindi la loro esperienza nel settore è incorporata nel prodotto. Il software si integra con i sistemi operativi esistenti degli edifici tramite API e driver, quindi non è necessaria una completa sostituzione. Combina i dati provenienti dai sistemi degli edifici, dai sensori IoT, dai dati meteorologici e altro ancora. Il motore di intelligenza artificiale analizza tutti questi dati per identificare modelli negativi, come picchi anomali di energia, e modelli positivi che possono essere ripetuti e amplificati. Evidenzia opportunità di ottimizzazione e può persino assumere il controllo autonomo per regolare continuamente l'ambiente dell'edificio.\n\n## Cybersecurity e Facilità di Implementazione\n\nPrescriptive Data si è associata con banche, agenzie governative e leader nel settore immobiliare per integrare la sicurezza informatica nella loro piattaforma fin dall'inizio. I clienti possono generalmente implementare il software e iniziare a vedere raccomandazioni in 8-10 settimane. Il ROI arriva anche velocemente, con periodi di rientro inferiore all'anno grazie ai risparmi energetici e alla conformità evitata.\n\n## Accedendo alla tecnologia\n\nLa GSA elenca i Dati Prescrittivi nel loro programma di appalti, consentendo un rapido acquisto da parte delle entità governative. Il software è disponibile a tutti i proprietari immobiliari commerciali che desiderano trasformare gli edifici esistenti in spazi intelligenti e sostenibili.\n\nLa promessa degli edifici intelligenti va oltre i risparmi economici. Ottimizzando continuamente gli ambienti interni, possiamo ridurre lo spreco energetico e fornire spazi più sicuri e confortevoli per tutti. Prescriptive Data offre una soluzione alimentata dall'intelligenza artificiale per portare in modo sostenibile l'immobiliare esistente nel futuro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sonu Panda"],"link":"/episode-EDT150-it","image":"./episodes/edt-150/it/thumbnail.png","lang":"it","summary":"Darren intervista Sonu Panda, il CEO di Prescriptive Data, in questa puntata. Discutono di come il loro software aiuti i proprietari di immobili commerciali a trasformare i loro edifici in spazi intelligenti ed efficienti."},{"id":51,"type":"Episode","title":"Capire l'IA generativa","tags":["genai","ai","datamanagement","people","collectiongenerativeai"],"body":"\r\n\r\n## Cos'è l'Intelligenza Artificiale Generativa?\n\nI sistemi di intelligenza artificiale che hanno la capacità di generare nuovi contenuti sono conosciuti come IA generativa. Questi sistemi possono produrre vari tipi di output, come testo, immagini, audio e video. Questo è diverso dalla maggior parte delle IA attualmente in uso, che sono principalmente analitiche e focalizzate su compiti come classificazione, previsioni e raccomandazioni. L'IA generativa offre un approccio più creativo e aperto alle applicazioni dell'intelligenza artificiale.\n\n## Potenziale rivoluzionario\n\nSia l'ospite che l'ospite erano concordi sul fatto che l'IA generativa sia una svolta tecnologica che ha il potenziale per essere un cambiamento epocale. Possiede la capacità incomparabile di amplificare la creatività umana e generare contenuti eccezionali anche dai suggerimenti più rudimentali. Il suo potenziale per rivoluzionare varie industrie come scrittura, design e musica è innegabile. Tuttavia, l'impatto sociale di questa tecnologia deve ancora essere compreso appieno.\n\n## Preoccupazioni nell'ambiente accademico.\n\nNel contesto dell'istruzione superiore, vi è una crescente preoccupazione per la diffusione del plagio e l'abuso dell'IA generativa da parte degli studenti che cercano di imbrogliare. Questa problematica ha suscitato discussioni sulle considerazioni etiche legate all'utilizzo dell'IA nell'ambito accademico. Tuttavia, esperti come Lancaster hanno suggerito che l'ambiente accademico possa svolgere un ruolo fondamentale nell'offrire consulenza su queste considerazioni etiche. Facendo ciò, gli educatori possono fornire agli studenti le competenze necessarie per valutare e analizzare criticamente i contenuti generati dall'IA, competenze che sicuramente saranno ricorrenti nel corso delle loro future carriere. Adottando un approccio proattivo per affrontare queste preoccupazioni, la comunità accademica può garantire che l'integrazione dell'IA nell'istruzione sia non solo efficace, ma anche etica e responsabile.\n\n## Vantaggi per l'efficienza.\n\nL'IA generativa ha il potenziale per rivoluzionare il nostro approccio alle attività che richiedono molto tempo, come scrivere relazioni, email, articoli e codice. Con l'assistenza dell'IA, il processo potrebbe essere notevolmente accelerato, risparmiando tempo e risorse preziose. Tuttavia, è importante sottolineare che il controllo umano è ancora fondamentale. Anche con i progressi della tecnologia dell'IA, non si può fidarsi completamente che produca un lavoro impeccabile. Pertanto, una revisione attenta e la modifica da parte degli esseri umani rimangono un passaggio essenziale per garantire l'accuratezza e la qualità del prodotto finale.\n\n## Personalizzazione e Implementazione\n\nPer implementare con successo una soluzione AI generativa, le organizzazioni devono considerare attentamente le proprie esigenze uniche di dati e i requisiti di sicurezza. Mentre opzioni facilmente disponibili come ChatGPT possono essere utili, una soluzione veramente personalizzata richiede risorse ed esperienza significative. Ciò può comportare la raccolta e l'analisi di grandi quantità di dati, così come l'investimento in risorse di calcolo potenti. Prima di utilizzare pienamente l'AI generativa, è fondamentale stabilire un quadro completo che tenga conto di tutti gli aspetti delle operazioni dell'organizzazione, inclusa la privacy dei dati e i protocolli di sicurezza. Con l'approccio e le risorse corrette, l'AI generativa può essere uno strumento potente per le organizzazioni che desiderano migliorare le loro capacità decisionali basate sui dati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT151-it","image":"./episodes/edt-151/it/thumbnail.png","lang":"it","summary":"In questo episodio, l'ospite Darren Pulsipher ha intervistato il dottor Jeffrey Lancaster di Dell Technologies. La loro discussione si è incentrata sull'IA generativa e il suo potenziale impatto."},{"id":52,"type":"Episode","title":"Pratico generativo AI","tags":["genai","ai","collectiongenerativeai","datamanagement"],"body":"\r\n\r\nNel campo della tecnologia all'avanguardia, poche innovazioni hanno la stessa promessa dell'Intelligenza Artificiale Generativa. Questo concetto rivoluzionario, con le sue potenziali applicazioni che si estendono a varie industrie, sta per ridefinire il nostro modo di interagire con le macchine e riplasmare il nostro approccio alla creatività e alla risoluzione dei problemi.\n\n## Il potere dell'IA generativa: trasformare le industrie\n\nLo sviluppo dell'Intelligenza Artificiale Generativa ha il potere di rivoluzionare settori industriali automatizzando processi e migliorando la creazione di contenuti. Questa tecnologia consente ai sistemi di IA di generare output in varie forme, inclusi contenuti scritti e creazioni artistiche. Essa può semplificare compiti come il completamento di moduli e la generazione di contenuti, velocizzando ed ottimizzando i processi all'interno delle organizzazioni. Con questa innovazione, compiti banali possono essere ottimizzati, liberando risorse umane per concentrarsi su attività più significative. Immagina un mondo in cui i compiti di routine sono semplificati e gli sforzi umani sono diretti verso attività più significative.\n\n## Collaborazione tra umani e intelligenza artificiale: costruire insieme il futuro\n\nNel mondo dell'IA Generativa, esiste una potente collaborazione tra la conoscenza umana e le capacità tecnologiche. Questa partnership si manifesta nello sviluppo delle sequenze genetiche e si estende a vari altri utilizzi. L'idea di intelligenza aumentata occupa il centro della scena, poiché gli esseri umani utilizzano l'IA per raccogliere e analizzare rapidamente le informazioni. Sebbene l'esperienza umana rimanga fondamentale, la capacità dell'IA di gestire grandi quantità di dati in breve tempo è un asset prezioso. Si tratta di un'alleanza reciprocamente vantaggiosa in cui ciascuna parte si integra con i punti di forza dell'altra, portando a un miglioramento delle capacità di risoluzione dei problemi.\n\n## Strumenti generativi: Sbloccare nuove dimensioni di creatività\n\nLe capacità dell'IA generativa vanno oltre un singolo dominio e includono varie forme di media come immagini, codice e suoni. Questo progresso apre nuove strade per la creatività e l'innovazione in diversi settori. Un'interessante caratteristica di questa tecnologia è la possibilità di regolare il livello di creatività, denominato \"allucinazione\". Ciò permette all'output di soddisfare requisiti specifici pur dando agli utenti la libertà di perfezionare l'output creativo. Fondamentalmente, questo strumento offre agli utenti la possibilità di utilizzare la tecnologia mantenendo il controllo sul risultato finale.\n\n## Potenziamento attraverso la tecnologia: uno sguardo nel futuro\n\nLa tecnologia ha un impatto significativo sulla nostra vita quotidiana, con i creatori di siti web come Squarespace che ne sono solo un esempio. Molte persone si chiedono se questi strumenti sostituiranno i professionisti o daranno più potere agli individui. La maggior parte delle persone crede che questi strumenti daranno più potere agli individui, aiutandoli a prendere il controllo dei loro progetti. Questo approccio incoraggia gli utenti ad essere indipendenti, ma anche critici del loro lavoro, il che è una caratteristica essenziale per un uso efficace della tecnologia.\n\nGli strumenti di intelligenza artificiale sono anche acceleratori che aiutano in compiti come la programmazione e la scrittura. Essi aiutano con la grammatica, la struttura e la generazione di idee. Tuttavia, non possono sostituire le capacità cognitive dell'uomo, l'espressione emotiva e le prospettive uniche. Combinare l'intuizione umana con l'assistenza dell'intelligenza artificiale porta ad un approccio olistico all'integrazione della tecnologia.\n\nL'IA generativa è più di una meraviglia tecnologica; rappresenta un cambiamento di paradigma che mette in luce la relazione simbiotica tra l'intelletto umano e l'efficienza delle macchine. Questa sinergia ha il potenziale per rivoluzionare settori industriali, snellire processi e liberare nuove dimensioni di creatività. Abbracciando questi progressi e sfruttando le loro capacità, possiamo intraprendere un viaggio in cui la tecnologia potenzia il potenziale umano e ci consente di compiere imprese più grandi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT152-it","image":"./episodes/edt-152/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast Abbracciando la Trasformazione Digitale, l'host Darren Pulsipher si impegna in una conversazione stimolante con il Dott. Jeffrey Lancaster. La loro discussione approfondisce le applicazioni pratiche dell'IA generativa e l'impatto profondo che sta per portare in diverse industrie."},{"id":53,"type":"Episode","title":"Addestrare la prossima generazione in AI","tags":["genai","generativeai","ai","robotics","people","training","collectiongenerativeai"],"body":"\r\n\r\n## Sfruttare il potere dell'algebra lineare e del calcolo nell'intelligenza artificiale\n\nL'algebra lineare e il calcolo costituiscono la spina dorsale degli algoritmi e dei sistemi di intelligenza artificiale (AI). In un recente episodio di podcast, Pete Schmitz, un ex dipendente Intel e appassionato di AI, sottolinea l'importanza di comprendere questi concetti matematici fondamentali nel contesto dell'AI.\n\nL'algebra lineare è fondamentale nell'IA, soprattutto in compiti come il riconoscimento delle immagini. Attraverso la moltiplicazione delle matrici, le reti neurali convoluzionali (CNN) sono in grado di elaborare ed analizzare enormi quantità di dati di immagini, consentendo l'identificazione e la classificazione degli oggetti nelle immagini. Il calcolo, d'altra parte, viene utilizzato nell'addestramento dei modelli di AI attraverso tecniche come la discesa del gradiente, in cui l'algoritmo regola continuamente i suoi parametri in base alla variazione di una determinata funzione.\n\nSchmitz enfatizza il valore che gli studenti imparino queste materie a scuola, in quanto fornisce loro una solida base per addentrarsi nel mondo dell'IA. Comprendere i fondamenti consente agli studenti di costruire sulle conoscenze e i progressi compiuti dalle generazioni precedenti nel campo dell'IA. Con la crescita esponenziale della tecnologia, l'IA sta evolvendo rapidamente, consentendo soluzioni più efficienti ed automatizzate per compiti precedentemente laboriosi.\n\n## L'impatto trasformativo dell'intelligenza artificiale in tutti i settori industriali.\n\nIl podcast si addentra anche nell'impatto trasformativo dell'AI in vari settori. I sistemi alimentati dall'IA stanno consentendo progressi nel campo della sanità, del commercio al dettaglio e di altri settori. Ad esempio, l'IA viene utilizzata nel campo della sanità per rilevare e diagnosticare malattie come il cancro, migliorando l'accuratezza e l'efficienza degli operatori sanitari. Nel settore del commercio al dettaglio, l'IA viene utilizzata per analizzare le abitudini di acquisto dei clienti e fornire raccomandazioni personalizzate, migliorando l'esperienza complessiva dello shopping.\n\nInoltre, gli ospiti discutono dei recenti progressi nei modelli di intelligenza artificiale generativa, come i transformer. Questi modelli hanno la capacità di identificare modelli sottostanti in grandi dataset, facilitando l'analisi dei dati e la presa di decisioni. Sfruttando i transformer e i modelli generativi, le industrie possono sbloccare preziose intuizioni e stimolare l'innovazione.\n\n## Promuovere l'innovazione e adattarsi alle nuove tecnologie\n\nL'innovazione è un tema fondamentale nell'episodio del podcast. Gli ospiti sottolineano l'importanza delle organizzazioni nel abbracciare nuove tecnologie e processi per rimanere rilevanti nel mondo in rapida evoluzione di oggi. È essenziale favorire un ecosistema completo che supporti l'innovazione in diverse industrie, fornendo strumenti e servizi specializzati per diversi aspetti dell'innovazione.\n\nIl podcast incoraggia anche l'attivazione di nuovi talenti in ruoli di ingegneria, affari e marketing ad adottare una prospettiva innovativa al di fuori dei canoni tradizionali. Abbandonando processi obsoleti e modalità di pensiero antiquate, le organizzazioni possono sfruttare il potenziale dei propri dipendenti e promuovere l'innovazione.\n\nL'oratore ospite, Pete Schmitz, sottolinea la necessità di un apprendimento e adattamento continui di fronte ai progressi tecnologici e alle trasformazioni digitali. Le organizzazioni devono evolvere e abbracciare il cambiamento per evitare di diventare obsolete nel contesto competitivo.\n\nIn conclusione, questo episodio di podcast mette in luce l'importanza dell'algebra lineare e del calcolo nell'IA, l'impatto trasformativo dell'IA in tutti i settori e l'importanza di promuovere l'innovazione e adattarsi alle nuove tecnologie. Attraverso una comprensione approfondita dei fondamenti dell'IA, sfruttando tecnologie trasformative e promuovendo l'innovazione, le organizzazioni possono cogliere le immense opportunità offerte dalla trasformazione digitale e restare avanti nel mondo in continua evoluzione dell'IA.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Pete Schmitz","Darren W Pulsipher"],"link":"/episode-EDT153-it","image":"./episodes/edt-153/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast, Pete Schmitz, un ex dirigente commerciale di Intel, parla del suo lavoro con gli studenti delle scuole superiori nell'insegnare loro sull'IA e su come utilizzarla nelle competizioni di robotica. Spiega che queste competizioni richiedono l'uso dell'autonomia e l'IA è un componente cruciale per raggiungerla. Pete condivide un esempio di come la visione artificiale, alimentata dall'IA, viene utilizzata nel veicolo navale senza pilota del Defense Advanced Research Projects Agency, DARPA D Hunter."},{"id":54,"type":"Episode","title":"Casi d'uso di GenAI","tags":["genai","ai","collectiongenerativeai","datamanangement"],"body":"\r\n\r\nL'IA generativa è una tecnologia trasformativa che può potenziare la creatività umana, migliorare la collaborazione e sbloccare nuove possibilità per il lavoro e la comunicazione. Sfruttando le capacità dell'IA, gli individui possono generare contenuti, riassumere email e automatizzare compiti di routine, mantenendo allo stesso tempo il tocco umano e l'individualità.\n\n## Svelare la Creatività Umana\n\n## Comprendere il panorama dei dati e stabilire obiettivi chiari\n\nIl dottor Lancaster sottolinea l'importanza di comprendere il tipo di dati che si desidera utilizzare o creare prima di approfondire l'intelligenza artificiale generativa. Che si tratti di testo, immagini, musica, video o audio, avere una chiara comprensione del tuo input e dell'output desiderato ti permette di selezionare gli strumenti e le piattaforme più appropriate.\n\n## Aumentare la creatività umana con l'IA\n\nUno dei concetti fondamentali del podcast è il ruolo della AI generativa nell'incrementare la creatività umana anziché sostituirla. Gli strumenti di AI agiscono come catalizzatori, potenziando e spingendo la creatività umana verso nuove vette. Combinando la mentalità innovativa degli esseri umani con le capacità dell'AI, gli individui possono risolvere problemi complessi e generare idee rivoluzionarie che gli approcci tradizionali da soli non possono raggiungere.\n\n## Collaborazione e brainstorming con l'intelligenza artificiale\n\nLa Generative AI apre le porte alla collaborazione e al brainstorming. L'AI può agire come una voce aggiuntiva nelle discussioni di gruppo, suscitando nuove prospettive e promuovendo conversazioni fruttuose. Questo aspetto collaborativo è particolarmente prezioso in contesti di gruppo, dove l'AI può ascoltare le conversazioni, facilitare le discussioni e contribuire a consolidare le idee in un consenso.\n\n## Svelando il potere dell'IA generativa\n\nL'IA generativa ha un immenso potenziale per sbloccare la creatività, potenziare le capacità umane e offrire prospettive e soluzioni fresche alle sfide. Che tu sia uno sviluppatore, un ricercatore o semplicemente curioso dell'IA, ci sono molte opportunità da esplorare e creare con l'IA generativa.\n\n## Applicazioni pratiche dell'IA generativa sul posto di lavoro\n\nOltre alle intuizioni condivise nel podcast, ci sono numerose applicazioni pratiche dell'IA generativa che possono rivoluzionare i nostri processi lavorativi. Esploriamo alcune di esse:\n\n## Riassumendo lunghe email e ottimizzando la comunicazione.\n\nI professionisti impegnati spesso ricevono lunghi email che consumano tempo prezioso. L'IA generativa può aiutare analizzando il contenuto dell'email e generando un riassunto conciso che cattura i punti principali e le informazioni chiave. Ciò consente ai destinatari di comprendere rapidamente le informazioni importanti e prendere decisioni informate senza dover spendere troppo tempo nella lettura dell'intera email.\n\n## Automazione della creazione di contenuti\n\nL'AI generativa può automatizzare la creazione di report, articoli e altri contenuti scritti. Inserendo dati o informazioni pertinenti in uno strumento di AI generativa, i giornalisti e i creatori di contenuti possono generare articoli o report completi basati su tali input. Ciò consente di risparmiare tempo e risorse significativi, soprattutto per coloro che devono produrre grandi quantità di contenuti regolarmente.\n\n## Migliorare la creatività artistica.\n\nI creativi nell'arte e nella musica possono sfruttare l'IA generativa per esplorare nuovi stili, tecniche e ispirazioni. L'IA può assistere gli artisti nella generazione di idee, nella composizione musicale e nella creazione di contenuti visivi. Con il potere dell'IA generativa, gli artisti possono ampliare i loro orizzonti creativi e superare i confini nei rispettivi campi.\n\n## Bilanciare l'automazione e il tocco umano\n\nMentre l'IA generativa offre un potenziale incredibile, è fondamentale mantenere la supervisione e l'intervento umano per garantire precisione, contesto e preservare l'individualità. Affidarsi ciecamente ai contenuti generati dall'IA senza intervento umano può portare all'omogeneizzazione del panorama digitale. È essenziale trovare un equilibrio tra l'automazione e il tocco umano, in cui l'IA potenzi la creatività umana anziché sostituirla.\n\nMan mano che l'IA generativa continua a evolversi, possiamo aspettarci di assistere alla sua integrazione in vari aspetti del lavoro e della comunicazione. Dal riassumere le email all'automazione della creazione di contenuti e alla possibilità di nuove forme di espressione artistica, l'IA generativa ha la capacità di ottimizzare i processi, incrementare la produttività e sbloccare nuove possibilità per l'innovazione. Abbracciando questa tecnologia, pur mantenendo viva la creatività e l'unicità umana, plasmeremo il futuro del lavoro in modi straordinari.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT154-it","image":"./episodes/edt-154/it/thumbnail.png","lang":"it","summary":"Nel più recente episodio, il dottor Jeffrey Lancaster e Darren Pulsipher approfondiscono i casi d'uso pratici dell'IA generativa e come questa possa scatenare la creatività umana in vari campi."},{"id":55,"type":"Episode","title":"Consulente GenAI per la gestione del data center","tags":["ai","sdi","vergeio","cloud","privatecloud","collectiongenerativeai","hybridcloud"],"body":"\r\n\r\nNel podcast \"Abbracciare la trasformazione digitale\", il Chief Solution Architect Darren Pulsipher ha intervistato Greg Campbell, CTO di Verge.io. La conversazione ruota attorno alle soluzioni innovative nella gestione dell'infrastruttura e al potenziale dell'intelligenza aumentata. Greg condivide la sua esperienza come sviluppatore di software e imprenditore, discutendo delle sfide che ha cercato di affrontare con Verge.io, un'azienda focalizzata sulla semplificazione della gestione dell'infrastruttura nei server distribuiti.\n\n## Semplificazione della gestione delle infrastrutture complesse\n\nGestire l'infrastruttura nel paesaggio digitale di oggi presenta sfide significative. La complessità nasce da vari componenti, fornitori, licenze e versioni. Ciò richiede personale specializzato e spesso comporta costi elevati e una carenza di competenze. Sebbene il cloud fosse inizialmente visto come una soluzione, ha introdotto complessità proprie.\n\nVerge.io offre una soluzione tramite il suo sistema operativo, VergeOS. Questo sistema consente agli sviluppatori di gestire e connettere facilmente le risorse di archiviazione, elaborazione e rete su diverse configurazioni hardware. Fornendo un data center virtuale, VergeOS semplifica la gestione dell'infrastruttura, rendendola più intuitiva e user-friendly.\n\n## Il potenziale dell'Intelligenza Artificiale generativa nella gestione delle infrastrutture.\n\nGreg parla anche del suo interesse nell'intelligenza artificiale (IA) e delle sue potenziali applicazioni. Condivide le sue esperienze con l'IA generativa e il suo utilizzo nella gestione delle infrastrutture. Greg esplora come l'automazione della gestione delle infrastrutture e dei data center attraverso l'IA generativa possa semplificare processi complessi e ottimizzare la gestione delle risorse.\n\nL'IA generativa può automatizzare la gestione dell'infrastruttura, eliminando la necessità di esperti specializzati e migliorando l'efficienza. Ha il potenziale per rivoluzionare il design dell'interfaccia utente e le interfacce adattive, rendendo il processo di gestione dell'infrastruttura più intuitivo e facile da usare.\n\n## Intelligenza aumentata come un prezioso assistente.\n\nL'intelligenza aumentata è la combinazione tra intelligenza umana e quella delle macchine. L'intelligenza aumentata potenzia le capacità umane e il processo decisionale fornendo prospettive e risposte a problemi complessi. È pensata per assistere, anziché sostituire, il giudizio umano nelle decisioni informate.\n\nGreg enfatizza che, man mano che i modelli di intelligenza artificiale diventano più grandi e sofisticati, la loro precisione e capacità predictive migliorano. L'intelligenza aumentata può essere applicata in vari settori, come il supporto clienti, dove i modelli di intelligenza artificiale possono fornire risposte alle domande dei clienti e aiutare gli agenti umani a trovare soluzioni. Può inoltre assistere nella gestione di siti o uffici remoti, fornendo indicazioni al personale in loco che potrebbe mancare di competenze in determinate aree.\n\n## Il futuro della trasformazione digitale\n\nIl podcast si conclude con una discussione sul futuro dell'intelligenza aumentata e sull'eventuale impatto sul settore industriale e sulla forza lavoro. L'ottimismo di Greg risiede nella capacità dell'intelligenza aumentata di migliorare efficienza e produttività, ma con il riconoscimento che non dovrebbe sostituire completamente il giudizio umano. La conversazione mette in luce l'importanza di una implementazione attenta, della supervisione umana continua e delle considerazioni etiche nell'utilizzo dell'intelligenza aumentata.\n\nGlobalmente, questo episodio del podcast offre preziose intuizioni sulle soluzioni innovative per la gestione delle infrastrutture, sul potenziale dell'intelligenza generativa nel razionalizzare i processi e sui benefici dell'intelligenza aumentata come assistente di valore. Dimostra il potere di abbracciare la trasformazione digitale e sfruttare la tecnologia per guidare l'efficienza e il successo nelle organizzazioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Greg Campbell","Darren W Pulsipher"],"link":"/episode-EDT155-it","image":"./episodes/edt-155/it/thumbnail.png","lang":"it","summary":"In questo episodio l'host Darren Pulsipher si siede con Greg Campbell, CTO di Verge.io, per discutere dell'entusiasmante intersezione tra intelligenza artificiale e gestione dell'infrastruttura. Greg, sviluppatore di software e imprenditore, condivide il suo percorso nella creazione di Verge.io per affrontare le complessità della connessione e gestione dell'infrastruttura."},{"id":56,"type":"Episode","title":"Diventare un'Organizzazione pronta ai dati","tags":["collectiongenerativeai","datamanagement","automation","dataquality","strategicanalytics","generativeai","digitaltransformation","datadriveninsights","datareadiness","innovation","decisionmaking","technologytrends","businessintelligence","datastrategy","analytics","bigdata","continuouslearning","operationalefficiency","dataoptimization","datainnovation","emrbacingdigital","edt156"],"body":"\r\n\r\n## Evoluzione della gestione dei dati: da manuale a automatizzata\n\nRon inizia la conversazione mettendo in evidenza il processo manuale e laborioso di gestione dei dati nei primi anni della sua carriera. In settori come i sistemi di armi nucleari e lo spazio, la gestione dei dati richiedeva uno sforzo manuale meticoloso a causa dell'elevata affidabilità e complessità dei sistemi. Tuttavia, man mano che il mondo è diventato sempre più data-driven e dipendente dalla tecnologia, le organizzazioni hanno riconosciuto la necessità di trasformare i dati in modi più utilizzabili ed efficaci.\n\n## Sfide nella gestione dei dati: complessità e qualità.\n\nRon condivide un esempio convincente dalla sua esperienza nella Marina, discutendo delle sfide nel gestire i dati per le navi durante i cicli di manutenzione e modernizzazione. La complessità dei sistemi navali e l'ambiente marittimo severo rendono l'analisi dei dati e la pianificazione accurata cruciali per il successo della manutenzione e delle riparazioni. Ciò sottolinea l'importanza della qualità dei dati e il suo impatto sull'efficienza operativa e la presa di decisioni.\n\n## Prontezza dei dati e automazione.\n\nSfruttare l'automazione richiede alle organizzazioni di concentrarsi sulla qualità dei dati. Nel processo di analisi e valutazione automatizzata, qualsiasi errore o dato mancante diventa critico. Per affrontare questo problema, le organizzazioni devono migliorare la raccolta dati fin dall'inizio. Progettando sistemi che rendono più facile la raccolta dati e considerando la persona che raccoglie i dati come un cliente, le organizzazioni possono ridurre gli errori e migliorare la qualità dei dati.\n\nUn approccio olistico alla preparazione dei dati è anche cruciale. Ciò implica riconoscere le diverse fasi della preparazione dei dati, dalla raccolta alla gestione e all'elaborazione. Migliorando costantemente in ogni area, le organizzazioni possono garantire che i loro dati siano di alta qualità e pronti a supportare varie operazioni e tecnologie come l'IA generativa.\n\n## Filtrare il rumore: Analisi strategica dei dati\n\nL'analisi dei dati svolge un ruolo vitale nel generare valore strategico per le organizzazioni. Ron e Darren discutono dell'importanza di filtrare i dati in base alla loro rilevanza per gli obiettivi e di concentrarsi su ciò che è veramente importante. Non tutti i dati saranno preziosi o necessari per l'analisi, e le organizzazioni dovrebbero allineare la raccolta dei dati con i propri obiettivi per evitare di sprecare risorse.\n\nInoltre, la conversazione sottolinea che i dati non devono essere perfetti per essere utili. Sebbene la precisione e l'accuratezza siano importanti in alcuni casi, i dati \"abbastanza buoni\" possono comunque fornire informazioni preziose. Riconoscendo il valore di una gamma di dati, le organizzazioni possono evitare di perseguire una perfezione irraggiungibile e concentrarsi sull'utilizzo delle informazioni disponibili.\n\n## Scoprire un valore inaspettato: abbracciare le possibilità\n\nIl podcast esplora anche il potenziale dell'IA generativa nel migliorare la raccolta di dati. Utilizzando moduli interattivi e interfacce conversazionali, le organizzazioni possono raccogliere informazioni più significative e scoprire nuove intuizioni. Questo apre possibilità per un'analisi dei dati migliorata e la presa di decisioni, in particolare in settori in cui la raccolta di dati è cruciale.\n\nLa discussione si conclude con il promemoria che l'analisi dei dati è un viaggio di apprendimento continuo. Le organizzazioni dovrebbero essere aperte all'esplorazione di nuove tecnologie e approcci, cercando sempre di scoprire valore inaspettato nei propri dati.\n\n## Conclusione\n\nIn un mondo sempre più orientato ai dati, diventare un'organizzazione pronta ai dati è cruciale per il successo. Comprendendo l'evoluzione della gestione dei dati, concentrandosi sulla qualità e la prontezza dei dati e abbracciando le possibilità dell'analisi strategica dei dati, le organizzazioni possono sbloccare il potere dei dati per guidare l'innovazione, ottimizzare le operazioni e prendere decisioni informate. Questo episodio del podcast fornisce preziose intuizioni e sottolinea l'importanza della gestione dei dati e dell'analisi nell'era digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Ron Fritzemeier","Darren W Pulsipher"],"link":"/episode-EDT156-it","image":"./episodes/edt-156/it/thumbnail.png","lang":"it","summary":"Nel podcast, il retroammiraglio in pensione Ron Fritzmeier si unisce all'ospite Darren Pulsipher per discutere dell'importanza della gestione dei dati nel contesto dell'intelligenza artificiale generativa (AI). Con una formazione in ingegneria elettrica e un'ampia esperienza nel campo della cyber e della sicurezza informatica, Ron fornisce preziosi approfondimenti sul campo in continua evoluzione della gestione dei dati e sul suo ruolo critico nel successo organizzativo nell'era digitale."},{"id":57,"type":"Episode","title":"Operazionalizzare GenAI","tags":["ai","generativeai","collectiongenerativeai","infrastructuremanagement","aisystems","aimodels","operationalization","datainput","modeltraining","finetuning","digitaltransformation","opensourcemodels","privateclouds","edgecomputing","aitools","creativeoutput","responsibleusage","reinforcementlearning","monitoring","optimization","sandboxenvironment","cloudbasedinfrastructure","onpremisesinfrastructure","hybridinfrastructure","customerservice","brainstormingapplications","embracingdigital"],"body":"\r\n\r\n## Esplorazione di Diversi Modelli di Condivisione dell'IA Generativa\n\nIl podcast evidenzia la varietà di modelli di condivisione per l'IA generativa. Ad un'estremità dello spettro ci sono i modelli aperti in cui chiunque può interagire e contribuire all'addestramento del modello. Questi modelli utilizzano l'apprendimento per rinforzo, consentendo agli utenti di inserire dati e ricevere risposte pertinenti. Al contrario, alcuni modelli privati sono più limitati nell'accessibilità. Questi modelli sono adatti a scenari aziendali in cui il controllo e i vincoli sono cruciali.\n\nTuttavia, esiste un approccio ibrido che combina le fondamenta linguistiche dei modelli aperti con vincoli e personalizzazioni aggiuntive. Questo approccio consente alle organizzazioni di trarre vantaggio dai modelli pre-addestrati, aggiungendo il loro livello di controllo e personalizzazione. Regolando i pesi e le parole utilizzate nel modello, le organizzazioni possono personalizzare le risposte per rispondere alle loro esigenze specifiche senza partire da zero.\n\n## Operazionalizzare Gen AI nella gestione dell'infrastruttura.\n\nIl podcast approfondisce l'operazionalizzazione dell'IA generativa nella gestione delle infrastrutture. Evidenzia i vantaggi dell'utilizzo di modelli open-source per sviluppare sistemi specializzati che gestiscono efficacemente le nuvole private. Ad esempio, uno dei partner menzionati ha implementato l'IA generativa per monitorare e ottimizzare le prestazioni della propria infrastruttura in tempo reale, consentendo una risoluzione proattiva dei problemi. Sfruttando il potere dell'IA, le organizzazioni possono migliorare l'efficienza operativa e garantire il corretto funzionamento delle proprie infrastrutture.\n\nGli host sottolineano l'importanza di considerare il tipo e la qualità dei dati inseriti nel modello e l'output desiderato. Non è sempre necessario allenare un modello con miliardi di indicatori; un set di dati più piccolo adatto alle esigenze specifiche può essere più efficace. Comprendendo le sfumature dei dati e gli obiettivi particolari del sistema, le organizzazioni possono ottimizzare il processo di allenamento e migliorare le prestazioni complessive del modello di intelligenza artificiale.\n\n## Gestione e ottimizzazione dei sistemi di intelligenza artificiale.\n\nGestire i sistemi di intelligenza artificiale richiede un processo decisionale oculato e un monitoraggio continuo. Gli ospiti discutono dell'importanza di selezionare l'infrastruttura adeguata, che sia basata su cloud, in loco o ibrida. Inoltre, il calcolo ai bordi sta diventando sempre più popolare, consentendo ai modelli di IA di essere eseguiti direttamente sui dispositivi, riducendo così i tempi di trasmissione dei dati.\n\nIl podcast sottolinea l'importanza dell'esperienza nella configurazione e nella manutenzione dei sistemi di intelligenza artificiale. È richiesto personale specializzato per progettare e ottimizzare i modelli di intelligenza artificiale al fine di ottenere risultati desiderati. A seconda del caso d'uso, possono essere necessarie funzionalità specifiche, come l'empatia nel servizio clienti o la creatività nelle applicazioni di brainstorming. È cruciale avere un team competente che comprenda le complessità dei sistemi di intelligenza artificiale e possa garantirne il funzionamento ottimale.\n\nInoltre, i modelli di intelligenza artificiale hanno bisogno di un monitoraggio e un aggiustamento costante. I modelli possono manifestare comportamenti indesiderati ed è essenziale intervenire quando necessario per garantire risultati appropriati. Il podcast differenzia tra problemi di rinforzo, in cui i feedback degli utenti possono indirizzare il modello in direzioni potenzialmente dannose, e allucinazione, che può essere intenzionalmente applicata per scopi creativi.\n\n## Iniziare con i modelli di intelligenza artificiale\n\nIl podcast offre consigli pratici per iniziare con i modelli di intelligenza artificiale. Gli ospiti suggeriscono di sperimentare con gli strumenti disponibili e di familiarizzare con le loro capacità. Iscriversi per ottenere un account ed esplorare come utilizzare gli strumenti è un ottimo modo per acquisire esperienza pratica. Raccomandano anche di creare un ambiente \"sandbox\" all'interno delle aziende, consentendo ai dipendenti di testare e interagire con i modelli di intelligenza artificiale prima di implementarli in produzione.\n\nIl podcast mette in evidenza l'importanza di conferire ai modelli di intelligenza artificiale una dose sufficiente di creatività mantenendo comunque il controllo e stabilendo dei limiti. Le organizzazioni possono trovare un equilibrio tra produzione creativa e utilizzo responsabile definendo delle linee guida e prendendo decisioni su ciò che il modello dovrebbe o non dovrebbe imparare dalle interazioni.\n\nIn conclusione, l'episodio del podcast fornisce preziose intuizioni sull'operazionalizzazione dell'IA generativa, sulla gestione dell'infrastruttura e sulle considerazioni per la gestione e il perfezionamento dei sistemi di intelligenza artificiale. Offre anche suggerimenti pratici per iniziare con i modelli di intelligenza artificiale nei contesti personali e professionali. Comprendendo i diversi modelli di condivisione, le necessità di infrastruttura e l'importanza della creatività e dei confini, le organizzazioni possono sfruttare il potere dell'IA per supportare la trasformazione digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT157-it","image":"./episodes/edt-157/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast, l'host Darren Pulsipher, Chief Solution Architect del settore pubblico presso Intel, discute dell'operatività dell'AI generativa con il ritorno dell'ospite, il dottor Jeffrey Lancaster. Esplorano i diversi modelli di condivisione dell'AI generativa, tra cui modelli pubblici, privati ​​e comunitari. Il podcast copre argomenti come i modelli open-source, la gestione dell'infrastruttura e le considerazioni per la distribuzione e il mantenimento dei sistemi AI. Si approfondisce anche l'importanza della creatività, della personalizzazione e di come iniziare con i modelli AI."},{"id":58,"type":"Episode","title":"GenAI nell'istruzione superiore","tags":["collectiongenerativeai","addressingbiasesingenerativeai","preservingauthenticityandindividuality","balancingaiintegrationineducation","lauratorresnewey","criticalthinkingskills","educationaltechnology","highereducation","aiineducation","aibias","diversityandinclusion","authenticvoices","uniqueperspectives","genai","generativeai","embracingdigital","edt158"],"body":"\r\n\r\nL'ascesa dell'intelligenza artificiale generativa nell'istruzione.\n\nIn un recente episodio del podcast \"Abbracciare la trasformazione digitale\", l'ospite Darren Pulsipher intervista Laura Torres Newey, autrice di bestseller del New York Times e professore di inglese, sull'impatto dell'IA generativa nell'istruzione superiore. La discussione riguarda l'integrazione dell'IA in classe, i suoi effetti sui metodi di insegnamento, le preoccupazioni riguardo al bias e la preservazione delle voci uniche. Laura condivide le sue intuizioni ed esperienze come educatrice, offrendo prospettive preziose per navigare nel panorama in evoluzione dell'istruzione nell'era dell'intelligenza artificiale.\n\n## L'influenza dell'IA generativa nell'educazione\n\nL'intelligenza artificiale generativa ha iniziato a diventare una presenza significativa nell'educazione, dalla correzione automatica di saggi all'assistenza nella scrittura agli studenti. Sebbene questa tecnologia offra comodità ed efficienza, solleva preoccupazioni riguardo alla potenziale perdita di voci uniche. Laura sottolinea l'importanza di valorizzare e incoraggiare le prospettive individuali e la creatività degli studenti nella loro scrittura. Invece di vietare totalmente l'uso dell'intelligenza artificiale generativa, Laura crede nell'insegnare agli studenti come utilizzare questi strumenti in modo efficace e sfruttare il loro potenziale senza compromettere le proprie voci.\n\nL'integrazione dell'IA generativa porta a un cambiamento nell'attenzione dell'insegnamento. Piuttosto che valutare solo il prodotto finale, gli educatori dovrebbero porre maggior enfasi sul processo di apprendimento. Con strumenti basati sull'IA come Grammarly a disposizione degli studenti, gli insegnanti possono indirizzare la loro attenzione allo sviluppo di capacità di pensiero critico, abilità di ricerca e discernimento nell'identificare fonti affidabili. Attraverso l'integrazione di compiti che coinvolgono il confronto tra contenuti generati dall'IA e lavori tradizionalmente scritti, gli studenti possono analizzare i punti di forza e di debolezza di entrambi gli approcci, favorendo una comprensione più approfondita della propria scrittura e migliorando le loro capacità di pensiero critico.\n\n## Il ruolo degli educatori nell'era dell'IA\n\nGli educatori hanno un ruolo fondamentale nella preparazione degli studenti per il panorama tecnologico in continua evoluzione. Laura sottolinea che adattarsi e utilizzare in modo efficace l'IA generativa è cruciale per gli educatori di tutti i livelli di istruzione. Con l'IA che diventa sempre più diffusa sul posto di lavoro, gli studenti in grado di navigare e sfruttare questa tecnologia saranno più preparati per le future opportunità di lavoro. Per garantire che gli studenti siano ben preparati, gli educatori devono non solo familiarizzare con le applicazioni dell'IA, ma anche insegnare loro come utilizzare l'IA in modo efficace ed etico.\n\nLa transizione verso l'integrazione dell'IA generativa nell'istruzione è in linea con la posizione del Dipartimento dell'Istruzione degli Stati Uniti sull'IA. Essi riconoscono i potenziali benefici, ma sottolineano la necessità che gli utenti mantengano il controllo, paragonando il ruolo dell'IA a quello di una bicicletta elettrica, dove la tecnologia alleggerisce il carico ma l'utente alla fine mantiene il controllo. Questo approccio mette in evidenza l'importanza di trovare un equilibrio tra sfruttare i benefici dell'IA e preservare le voci e le prospettive uniche degli studenti.\n\n## Risoluzione\n\nL'integrazione dell'IA generativa nell'istruzione presenta sia opportunità che sfide. Mentre l'IA può migliorare l'apprendimento e aiutare gli studenti con i loro compiti, è cruciale che gli educatori mettano in primo piano il pensiero critico e affrontino le preoccupazioni legate al pregiudizio per sviluppare pensatori completi e indipendenti. Gli insegnanti dovrebbero abbracciare la tecnologia dell'IA, capirne le applicazioni e insegnare agli studenti come navigarla e utilizzarla efficacemente. Trovando un equilibrio tra l'efficienza dei contenuti generati dall'IA e la preservazione delle voci autentiche e diverse, gli educatori possono preparare gli studenti per il futuro digitale garantendo la coltivazione della loro individualità e creatività.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Laura Newey","Darren W Pulsipher"],"link":"/episode-EDT158-it","image":"./episodes/edt-158/it/thumbnail.jpg","lang":"it","summary":"In questo episodio del podcast, Darren Pulsipher, architetto delle soluzioni principale del settore pubblico presso Intel, intervista Laura Torres Newey, autrice di successo del New York Times e professore universitario, riguardo all'impatto dell'IA generativa nell'istruzione superiore. Questo episodio approfondisce le sfide e le opportunità presentate dall'integrazione dell'IA generativa in aula, mettendo in evidenza la necessità di abilità di pensiero critico, le preoccupazioni legate ai pregiudizi e garantire la conservazione di voci uniche."},{"id":59,"type":"Episode","title":"Politiche GenAI","tags":["collectiongenerativeai","policies","ai","generativeai","guidelines","jeremyharris","darrenpulsipher","roadmap","challenges","efficiencies","dataprotection","privacy","compliance","ethicalconsiderations","feedback","engagement","ratings","reviews","customersatisfaction","customerengagement","embracingdigital","edt159"],"body":"\r\n\r\n## La necessità di politiche e linee guida chiare.\n\nJeremy e Darren sottolineano l'importanza di avere una politica chiara e una roadmap ben definita per la trasformazione digitale. Affrettarsi nella digitalizzazione senza una pianificazione adeguata può portare a sfide e inefficienze. Stabilendo politiche e linee guida, le organizzazioni possono delineare i loro obiettivi, stabilire una direzione strategica e garantire che tutti siano sulla stessa pagina.\n\nSottolineano che la trasformazione digitale non è solo l'adozione di nuove tecnologie, ma richiede una trasformazione della cultura organizzativa e della mentalità. Le politiche possono contribuire a facilitare questo cambiamento stabilendo aspettative per i dipendenti, definendo le migliori pratiche digitali e fornendo un quadro decisionale nel campo digitale.\n\n## Navigare le complessità della digitalizzazione\n\nLa trasformazione digitale porta con sé un insieme complesso di sfide, come la sicurezza dei dati, la privacy e la conformità. Le organizzazioni devono affrontare queste sfide incorporandole nelle loro politiche e linee guida. Ciò include l'implementazione di misure di protezione dei dati, la realizzazione di regolari audit di sicurezza e il garantire la conformità alle normative rilevanti.\n\nLe politiche dovrebbero occuparsi anche delle considerazioni etiche che accompagnano la trasformazione digitale. Gli ospiti sottolineano l'importanza che le organizzazioni siano responsabili custodi dei dati e garantiscano che l'utilizzo delle tecnologie digitali sia conforme agli standard etici. Linee guida chiare possono aiutare i dipendenti a comprendere le loro responsabilità e promuovere pratiche digitali responsabili in tutta l'organizzazione.\n\n## Il ruolo del Feedback e dell'Coinvolgimento\n\nGli ospiti sottolineano l'importanza del feedback e dell'engagement nel mondo digitale. Adottare una politica che incoraggi e valorizzi il feedback può aiutare le organizzazioni a migliorare continuamente e adattarsi alle circostanze che cambiano. Accogliendo suggerimenti e contributi da parte dei dipendenti e dei clienti, le organizzazioni possono perfezionare le loro strategie digitali e garantire di soddisfare le esigenze di tutti gli stakeholder.\n\nMenzionano anche l'importanza delle valutazioni e delle recensioni nell'era digitale. Il feedback tramite valutazioni e recensioni fornisce non solo preziose informazioni alle organizzazioni, ma serve anche come misura della soddisfazione del cliente e del coinvolgimento. Le politiche possono definire come le organizzazioni raccolgono e rispondono al feedback e stabilire linee guida per catturare il sentimento del cliente nello spazio digitale.\n\n## Translate the following to Italian: Conclusion\nTranslation: Conclusione\n\nLa trasformazione digitale è un percorso che richiede una pianificazione attenta, politiche chiare e aggiustamenti continui. Creando politiche e linee guida, le organizzazioni possono navigare le complessità della digitalizzazione, affrontare le sfide e garantire un utilizzo responsabile ed efficace delle tecnologie digitali. Abbracciare la trasformazione digitale non riguarda solo l'adozione di nuovi strumenti, ma anche la creazione di una cultura digitale che favorisce l'innovazione e risponde alle esigenze in continua evoluzione dei clienti e degli stakeholder.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeremy Harris","Darren W Pulsipher"],"link":"/episode-EDT159-it","image":"./episodes/edt-159/it/thumbnail.png","lang":"it","summary":"In questo episodio, il conduttore Darren intervista Jeremy Harris e approfondisce l'importanza di stabilire politiche e linee guida per una trasformazione digitale di successo. Con la sempre maggiore diffusione delle tecnologie digitali in diverse industrie, le organizzazioni devono adattarsi e abbracciare questa trasformazione per rimanere competitive e soddisfare le mutevoli aspettative dei clienti."},{"id":60,"type":"Episode","title":"Ridurre la congestione di ingestione con Intel Optane DCPMM","tags":null,"body":"\r\n\r\n## Dettagli sullo stack di servizi\n\nUn cliente nel settore automobilistico stava avendo difficoltà nel riuscire ad ottenere in modo efficace informazioni dalle proprie auto e trasferirle nel loro data center in modo da poter effettuare apprendimento automatico e analisi dati. In questa area è stata condotta una ricerca, ma solo per un numero limitato di auto, non per i cento milioni di auto del cliente. Quando ho esaminato l'intera struttura del loro servizio e come tutto arrivava al data center, è emerso che l'ingestione dei dati era il problema principale: come posso assimilare così tanti dati e come posso farlo velocemente?\n\n## Panoramica dell'architettura Kafka a livello superiore.\n\nIl cliente voleva utilizzare Kafka per l'ingestione dei dati. Kafka è un intermediario che può scalare bene e la sua caratteristica principale è quella di poter gestire diversi produttori, consumatori differenti e una grande quantità di dati. Utilizzare diversi intermediari Kafka per posizionare e inviare dati nei luoghi più appropriati offre una grande flessibilità.\n\nKafka, tuttavia, è stato principalmente progettato per dimensioni dei messaggi di circa uno a 10 kilobytes e i dati del cliente erano di circa 240 kilobytes per automobile. Ci sono soluzioni alternative, ma volevo portare l'intero messaggio di 240 kilobytes nel bus di Kafka in modo da poterlo spostare come necessario.\n\n## Pratiche ottimali per le performance\n\nHo analizzato le migliori pratiche di performance di coloro che lavorano con Kafka per vedere se potevo adattarle alle esigenze del mio cliente. Aumentare la dimensione del buffer per ospitare l'intero messaggio è una soluzione di fine-tuning, insieme alla gestione delle dimensioni dei batch per prestazioni ottimali. Un'altra pratica di successo è distribuire i log. La flessibilità di Kafka mi consentirebbe di inserire i dati in diversi argomenti. Posso suddividere gli argomenti in diverse partizioni che posso distribuire su più unità. La domanda è, dunque, su quante unità sto distribuendo i log di Kafka? Inoltre, desidero le unità più veloci possibili.\n\nUn esempio che ho esaminato è LinkedIn. I numeri pubblicati da loro di un anno fa indicano che possono gestire 13 milioni di messaggi al secondo, o 2,7 gigabyte al secondo. Dicono di avere circa 1.100 broker Kafka e più di 60 su un cluster, quindi si tratta di una configurazione abbastanza grande.\n\n## Spazio automobilistico\n\nSe guardo i numeri grezzi del cliente (1,6 milioni di messaggi al secondo e 800 gigabyte al secondo) e li confronto con LinkedIn, che probabilmente non è ottimizzato per 240 kilobyte, ottengo 44.000 broker. Se lo ottimizzassi, potrei probabilmente ridurli a 4.400 broker, che sono ancora 240 cluster. È un enorme quantità di macchine, quindi ho dovuto trovare un modo per rendere le cose più veloci. Con ulteriori ottimizzazioni, potrei probabilmente ridurlo a 400-500 broker, ma volevo vedere cos'altro potevo fare.\n\n## Intel Optane DC Persistent Memory: \nMemoria persistente Intel Optane DC\n\nHo esaminato la nostra memoria persistente Optane. Si adatta al formato DDR4, quindi si posiziona direttamente sul bus DDR4. Arriva fino a moduli da 512 gigabyte, quindi in un server a due socket posso avere sei terabyte di memoria persistente. Volevo trovare un modo per sfruttare questa tecnologia altamente affidabile con ottime funzionalità come la crittografia hardware integrata per aiutarmi a risolvere questo problema.\n\n## Supporto per la Variazione di Applicazioni\n\nCi sono due modalità di funzionamento con questa Memoria Optane: modalità app diretta e modalità memoria. La modalità memoria è semplice. Utilizza la memoria persistente come una normale RAM perché è più economica rispetto alla normale DDR4. Non è esattamente la stessa cosa della DDR4, ma è abbastanza simile al punto che nella maggior parte delle applicazioni non si nota alcuna differenza. Nella modalità app diretta, è possibile scrivere direttamente dalla tua applicazione nella memoria persistente. In questo modo, non è necessario convertire e decodificare le strutture dati e trasmetterle come flusso; posso semplicemente inserirle nella memoria persistente. Posso anche montare la modalità app diretta come un sistema di file, in modo che sia sul bus di memoria, molto più veloce rispetto al bus di I/O. Ora, cosa posso fare con questa memoria?\n\n## Utilizzando il kernel Linux\n\nCi sono due strumenti principali disponibili utilizzando il kernel Linux: ndctl e ipmctl. Ndctl è un controller per dispositivi di memoria non volatile, mentre c'è anche IPM, il controller di memoria persistente Intel, che mi permette di manipolare e controllare questa memoria persistente. Posso configurarla in modalità memoria o modalità app diretta. Ho dovuto imparare un po' su questi strumenti e come funzionano.\n\n## Approccio di ingestione\n\nIl mio primo pensiero è stato che se avessi dato a Kafka molta più memoria con dimensioni di buffer grandi, avrebbe dovuto funzionare molto più velocemente. I cambiamenti del codice nella configurazione sarebbero stati superflui o minimi. Un'altra opzione era cambiare Kafka in modo da scrivere sulla memoria persistente anziché sul file system, aggirando l'hard disk. L'ultima cosa che ho esaminato è stata la creazione di un file system persistente utilizzando la memoria persistente e quindi mettendo i log di Kafka su questo nuovo file system.\n\nLa opzione più semplice tra le tre era la prima: più memoria. Ho eseguito tutti i miei compiti con più memoria e non c'è stata alcuna variazione delle prestazioni. I motivi sono che alla fine i miei buffer si sono riempiti e ho dovuto trasferire i dati su un'unità esterna. Alla fine tutto doveva passare per i log di Kafka, che erano il mio collo di bottiglia.\n\nLa seconda opzione prevede la riscrittura del codice e l'attesa delle approvazioni, quindi sono passato alla terza opzione. I risultati di questo esperimento, in cui ho indirizzato i log a questo nuovo file system ultra veloce, sono stati affascinanti. Diamo uno sguardo al processo e ai risultati.\n\n## Test dei vincoli\n\nPer eliminare gli ostacoli alla valutazione delle prestazioni, ho escluso il network dall'equazione facendo girare il mio test sulla stessa macchina su cui era presente il mio broker. Inoltre, ho eseguito solo i produttori, poi solo i consumatori, e infine una combinazione dei due, in modo da poter valutare le differenze. Il mio obiettivo non era quello di valutare il miglioramento totale della produzione, ma di analizzare singolarmente il broker per capire se questo drive avrebbe davvero fatto la differenza.\n\n## Primo Approccio 50/50\n\nLa prima cosa che ho fatto è stata prendere la metà della mia memoria persistente in modalità diretta dell'app e trasformarla in un sistema di file. Ho lasciato l'altra metà come memoria. Ho utilizzato i comandi ndctl e ipmctl e creato spazi di nomi. Ho montato questi sistemi di file e ho eseguito il mio test.\n\n## Cambiare la dimensione del messaggio\n\nHo eseguito i test su diverse dimensioni di messaggio. Mi aspettavo alcune ottimizzazioni, soprattutto per 1 kilobyte. Ho notato che ottenivo prestazioni sempre migliori fino a circa 10 produttori. Oltre i 10 produttori, ho iniziato a saturare il bus e ho ottenuto qualche variabilità. Questo mi indica che stavo memorizzando le cose nella cache. Ora potrei confrontare questi numeri con quelli ottenuti precedentemente con un solo disco SATA per i registri Kafka. Ho provato anche i nostri dischi Optane NVMe per i registri.\n\n## Confronto tecnologico\n\nDiamo un'occhiata alle differenze. Per 240 kilobyte, con un normale disco SATA, è piuttosto piatto. Ho ottenuto un certo miglioramento, e poi è diminuito man mano che il numero di produttori aumentava. Con il disco Optane NVMe, ho ottenuto un bel picco, quasi due volte più veloce di un disco SATA, il che è quello che mi aspettavo dato che è un bus NVMe invece di un bus SATA. Il Pmem è quasi cinque volte più veloce di un disco SATA e due volte e mezzo più veloce del disco Optane NVMe. Questo perché sto usando un bus di memoria invece del bus SATA o NVMe.\n\n## Ottimizzazione aggiuntiva (100% diretto all'app)\n\nQuesto stava funzionando velocemente e stavo rapidamente riempiendo questo disco temporaneo da 750 GB. Siccome avevo bisogno di far durare il test un po' più a lungo, sono tornato indietro e ho riconfigurato la mia macchina per eseguire una modalità di applicazione diretta al 100 percento in modo da poter ora prendere l'intero terabyte e mezzo (1.5 terabyte).\n\n## Ottimizzato PMEM e App Direct al 100%.\n\nDopo aver fatto ciò e aver eseguito gli stessi test, ho ottenuto un risultato sorprendente. Ho potuto aggiungere più produttori e la mia capacità di trasmissione è aumentata di quasi altre due o tre volte. Ora è tra 12 e 15 volte più veloce di un disco SATA con 25-30 produttori e una dimensione dei messaggi di 240 kilobyte. Questo è incredibile e ridurrebbe notevolmente la necessità dei miei clienti di utilizzare così tanti broker, righe e righe di macchine. Ho eseguito il test diverse volte perché non credevo ai risultati che stavo ottenendo. Ho chiamato uno dei nostri architetti che ha progettato questa tecnologia e ho appreso che una delle ragioni per l'aumento della velocità è che, quando usavo parte della memoria persistente come memoria, i dati dovevano passare attraverso due o tre salti non necessari con l'app direct mode. Ciò crea meno contesa sul bus di memoria e la capacità di trasmissione è aumentata in modo significativo.\n\n## Chiamata all'azione\n\nIl risultato finale è che sono stato in grado di utilizzare Kafka con Optane DC Persistent Memory come un sistema di file ultra-veloce per ottenere notevoli miglioramenti nella velocità di throughput sia per i produttori che per i consumatori. Un singolo broker può gestire fino a 15 volte più messaggi e throughput rispetto a prima, diminuendo il numero di server necessari per gestire architetture di sistemi grandi e complesse. È ora di valutare la tua attuale architettura e vedere se questo potrebbe beneficiare la tua organizzazione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT16-it","image":"./episodes/edt-16/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla della diminuzione della congestione dell'ingestione utilizzando la memoria persistente Optane DC di Intel e dell'esperimento da lui condotto con risultati sorprendenti. Potrebbe cambiare il modo in cui pensiamo alla programmazione in futuro."},{"id":61,"type":"Episode","title":"Sicurezza nell'IA generativa","tags":["collectiongenerativeai","personalizedphishingattacks","promptinjection","sharingcodeai","harnessingai","digitaltransformation","generativeai","cybersecurityrisks","serviceproviders","duediligence","riskschallenges","digitallandscape","proactivecybersecurity","llm","multifactorauthentication","voicerecognition","typingcadence","github","stackoverflow","samsungipleak","securityaspects","embracingdigital","edt160"],"body":"\r\n\r\n## Attacchi di phishing personalizzati e convincenti\n\nUno dei principali problemi discussi è il potenziale per attacchi di phishing sempre più sofisticati e personalizzati. Attualmente, il phishing è il metodo di attacco informatico più efficace e, con l'intelligenza artificiale generativa, gli aggressori possono creare email o messaggi di phishing altamente personalizzati e convincenti. Recuperando informazioni dai social media o da altre piattaforme online, gli aggressori possono rendere i loro tentativi di phishing più difficili da individuare. Questo solleva la domanda su come possiamo determinare cosa è reale o meno e come possiamo fidarci dell'autenticità delle informazioni che riceviamo.\n\nPer contrastare ciò, gli individui potrebbero dover sviluppare nuovi metodi per verificare le informazioni, come utilizzare codici personali o altre misure di autenticazione con i propri cari. Inoltre, le organizzazioni e le agenzie di sicurezza devono adattare le loro strategie per contrastare la crescente sofisticazione degli attacchi informatici facilitati dall'intelligenza artificiale generativa. È fondamentale capire che l'intelligenza artificiale generativa è di per sé una tecnologia neutra, e le sue implicazioni dipendono da come viene utilizzata.\n\n## Voci clonate e fidarsi delle informazioni\n\nIl podcast esplora anche il potenziale dell'intelligenza artificiale generativa nel clonare voci, fenomeno che è già stato osservato negli attacchi di rapimento virtuali. I criminali utilizzano voci clonate per creare un senso di urgenza e paura, fingendo di essere familiari dell'eventuale vittima. Questo solleva preoccupazioni sulla fiducia nell'autenticità delle informazioni che riceviamo.\n\nIn uno scenario del genere, diventa essenziale sviluppare tecniche per verificare l'autenticità delle voci e delle informazioni. Come individui, dovremmo rimanere vigili e fare attenzione quando rispondiamo a richieste urgenti al telefono. Assicurare linee di comunicazione aperte con contatti fidati può aiutare a verificare se tali richieste siano autentiche.\n\n## Protezione della Proprietà Intellettuale nel Codice e nella Programmazione\n\nIl podcast passa a una discussione sull'importanza di proteggere la proprietà intellettuale nella codifica e nella programmazione. Gli ospiti sottolineano i rischi di condividere involontariamente il codice su piattaforme come StackOverflow e GitHub, e la perdita involontaria di proprietà intellettuale quando si cerca aiuto in questi forum pubblici. Ai developer viene consigliato di sostituire le informazioni sensibili con segnaposto prima di condividere il codice per mitigare il rischio di perdita della proprietà intellettuale.\n\nInoltre, gli ospiti discutono dell'introduzione di strumenti come GitHub Copilot, che utilizzano l'intelligenza artificiale generativa per fornire suggerimenti di codice. Sebbene questi strumenti possano essere preziosi, pongono preoccupazioni per la sicurezza e la privacy delle informazioni proprietarie. Gli sviluppatori devono considerare attentamente l'affidabilità del fornitore di servizi e garantire una adeguata protezione dei loro dati e della proprietà intellettuale.\n\n## Trovare l'equilibrio tra innovazione e sicurezza nell'era dell'intelligenza artificiale.\n\nLa conversazione si conclude sottolineando l'importanza di trovare un equilibrio tra abbracciare le innovazioni e i potenziali cambiamenti positivi portati dalla generative AI e affrontare i rischi connessi nell'ambito della sicurezza informatica e della protezione della proprietà intellettuale. È essenziale rimanere informati, adattare le strategie di sicurezza ed esercitare cautela per navigare con successo nel paesaggio in continua evoluzione della trasformazione digitale. In questo modo, possiamo sfruttare i benefici dell'AI senza compromettere la sicurezza e le informazioni personali.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Jeffrey Lancaster","Darren W Pulsipher"],"link":"/episode-EDT160-it","image":"./episodes/edt-160/it/thumbnail.png","lang":"it","summary":"In questo episodio, l'ospite Darren Pulsipher viene affiancato dal dottor Jeffrey Lancaster per approfondire l'intersezione tra intelligenza artificiale generativa e sicurezza. La conversazione si addentra nei potenziali rischi e sfide legate all'utilizzo dell'intelligenza artificiale generativa in attività negative, in particolare nel campo della sicurezza informatica."},{"id":62,"type":"Episode","title":"Analisi dei dati del linguaggio naturale","tags":["collectiongenerativeai","ai","generativeai","embracingdigital","edt161","challengesinnaturallanguageprocessing","fantasysportsapp","naturallanguagegeneration","highqualitycontent","technicalbackground","outoftheboxthinking","pushingboundaries","diversity","crossdomaincollaboration","innovativeideas","infoscentience'ssolution","dataanalytics","naturallanguageaisystem","conceptualautomata","datasets","revolutionizing","businessesanalyzeinformation","futureofdataanalysis","naturallanguagereporting","flexibility","tailored","differentindustries","customized","specificcontext","jargon","dataanalysis","revolutionizingindustries","sportsanalytics","stevewasick'sjourney","innovativeapproach","entrepreneurs","techfounders","unconventionalpaths","successfulinnovations","embracingvariability","context","poweroflanguage"],"body":"\r\n\r\n## Sfide nel Natural Language Processing\n\nSteve ricorda il suo primo progetto: un'app per i giochi di fantasia che mirava a fornire agli utenti non solo statistiche, ma anche il contesto e le storie dietro i numeri. Ciò lo ha portato al campo della generazione di linguaggio naturale, dove ha affrontato sfide nell'acquisizione e nella consegna di contenuti di alta qualità. Nonostante non avesse una formazione tecnica, le sue diverse esperienze gli hanno permesso di affrontare queste sfide con creatività e pensiero fuori dagli schemi.\n\n## Spostando i confini\n\nDarren elogia Steve per aver superato i limiti e aver portato una prospettiva innovativa nel settore. Ciò evidenzia l'importanza della diversità e della collaborazione tra diversi settori nel generare idee e soluzioni innovative. Il percorso di Steve serve da ispirazione per gli aspiranti imprenditori e fondatori di aziende tecnologiche, dimostrando che percorsi non convenzionali possono portare a innovazioni di successo.\n\n## La soluzione di InfoScentience per l'analisi dei dati.\n\nLa conversazione si addentra anche nelle capacità del sistema di intelligenza artificiale basato sul linguaggio naturale di InfoSentience. Steve spiega che la loro tecnologia scompone eventi e storie nei loro elementi costitutivi, fornendo una migliore comprensione dei concetti complessi e delle loro relazioni. Questo motore analitico, basato su automi concettuali, consente la sintesi di insiemi di dati diversi e complessi, rivoluzionando il modo in cui le aziende analizzano le informazioni.\n\n## Il futuro dell'analisi dei dati e della raportistica in linguaggio naturale.\n\nInoltre, Steve sottolinea la flessibilità del loro sistema AI, che può essere adattato a diverse industrie e personalizzato per soddisfare le esigenze uniche di ogni cliente. Comprendendo il contesto specifico e il gergo dei dati analizzati, Info Sentience garantisce che il loro sistema AI fornisca intuizioni accurate e pertinenti.\n\nIn conclusione, l'episodio del podcast mette in evidenza il potenziale dell'analisi dei dati di linguaggio naturale nella rivoluzione delle industrie come l'analisi sportiva. Il percorso di Steve Wasick e il suo approccio innovativo fungono da ispirazione per gli imprenditori e i fondatori di aziende tecnologiche, ricordandoci che percorsi non convenzionali possono portare a innovazioni di successo. Il futuro dell'analisi dei dati risiede nell'accogliere la variabilità, il contesto e il potere del linguaggio.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Wasick"],"link":"/episode-EDT161-it","image":"./episodes/edt-161/it/thumbnail.jpg","lang":"it","summary":"Nell'ultimo episodio, Darren Pulsipher si siede con Steve Wasick, CEO e fondatore di InfoSentience, per discutere del potere e del potenziale dell'analisi dei dati del linguaggio naturale. Steve, proveniente da un background non convenzionale come laureato in inglese diventato sceneggiatore diventato avvocato diventato fondatore di una tecnologia, porta una prospettiva unica nel campo."},{"id":63,"type":"Episode","title":"Costruire una strategia Multi-Hybrid Cloud","tags":["cloudadoption","collmultihybridcloud","organizationalmodernization","barriers","riskmitigationplan","applicationrearchitecture","governance","organizationalculture","cloud","multihybridcloud","multicloud","embracingdigital","edt162"],"body":"\r\n\r\n## Migliori pratiche per l'adozione del cloud\n\nTrasferirsi nel cloud e adottare nuove tecnologie come l'IA generativa può portare numerosi vantaggi, ma le organizzazioni devono anche essere preparate ai cambiamenti che ne derivano. Secondo Christine McMonigal, direttore delle Tecnologie per i Data Center e il Cloud presso Intel, ci sono alcune migliori pratiche da considerare.\n\n## Modernizzazione organizzativa\n\nUn aspetto importante da riconoscere è che l'adozione del cloud non è solo una modernizzazione tecnologica, ma anche una modernizzazione organizzativa. Ciò significa che le organizzazioni devono essere preparate per i cambiamenti ai processi, ai flussi di lavoro e persino alle strutture organizzative. È cruciale affrontare questi cambiamenti e assicurarsi che l'intera organizzazione sia allineata e preparata per la trasformazione.\n\n## Identificare le barriere e stabilire aspettative chiare\n\nUn passo cruciale nel superare le barriere e mitigare i rischi è identificare innanzitutto quali sono queste barriere. Effettuando una valutazione approfondita dell'infrastruttura attuale, dei flussi di lavoro e delle sfide all'interno dell'organizzazione, è possibile individuare gli ostacoli potenziali e sviluppare strategie per superarli.\n\nInoltre, è essenziale stabilire chiare aspettative fin dall'inizio. Ciò significa comunicare in modo efficace con i portatori di interesse, dipendenti e partner riguardo gli obiettivi, i vantaggi e le sfide legate all'adozione di strategie multi-cloud e ibride. Stabilendo aspettative realistiche e assicurandosi che tutti siano sulla stessa pagina, le organizzazioni possono ridurre al minimo le sorprese e la resistenza al cambiamento.\n\n## Robusto piano di mitigazione del rischio.\n\nAvere un solido piano di mitigazione dei rischi è un altro aspetto cruciale per un'adozione di successo del cloud. Ciò include valutare potenziali rischi di sicurezza, preoccupazioni sulla privacy dei dati e requisiti di conformità. Affrontando in modo proattivo questi rischi e implementando misure adeguate, le organizzazioni possono proteggere i loro dati, garantire la conformità normativa e ridurre al minimo le minacce potenziali.\n\n## Barriera 1: Re-Architettura dell'applicazione\n\nUna delle principali barriere che le organizzazioni spesso incontrano nell'adozione del cloud è la ri-architetturazione delle applicazioni. È importante valutare quali applicazioni possono essere trasferite e spostate nel cloud così come sono, e quali invece potrebbero richiedere modifiche più significative. Identificando delle opportunità di semplificazione e riduzione dei costi tramite l'automazione, le organizzazioni possono ottimizzare l'accesso e i controlli.\n\n## Barriera 2: Governance\n\nLe politiche di governance svolgono un ruolo cruciale nel mitigare i rischi durante l'adozione del cloud. Modelli di sicurezza incoerenti, strumenti di gestione diversi e politiche degli utenti eterogenee possono aumentare la complessità e mettere a rischio il successo della migrazione. Semplificare le politiche di governance ed eliminare la burocrazia può aiutare le organizzazioni a ottimizzare le operazioni, ridurre i costi e garantire la sicurezza dei dati e la conformità.\n\n## Barriera 3: Cultura organizzativa e maturità.\n\nPreparare l'organizzazione al cambiamento che arriva con l'adozione del cloud è fondamentale. Questo implica coinvolgere i dipendenti, fornire formazione sulle competenze e individuare figure chiave capaci di adottare nuovi metodi di lavoro. Affrontare le paure e le preoccupazioni che i dipendenti potrebbero avere, come la paura di essere lasciati indietro o di perdere il lavoro, è essenziale per creare un ambiente positivo e collaborativo.\n\nIn conclusione, adottare strategie multi-cloud ibride richiede una pianificazione accurata, una comunicazione efficace e una comprensione approfondita degli obiettivi e delle sfide di un'organizzazione. Affrontando le barriere in anticipo e mitigando i rischi, le organizzazioni possono preparare il terreno per un viaggio di trasformazione digitale di successo. Rimanete sintonizzati per i prossimi episodi in cui esploreremo lo sviluppo di una strategia cloud, la valutazione dei portafogli delle applicazioni e altre visioni sulla trasformazione digitale. Non dimenticate di valutare e iscrivervi al nostro podcast per rimanere aggiornati sulle ultime tendenze e le migliori pratiche nel panorama digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Christine McMonigal","Darren W Pulsipher"],"link":"/episode-EDT162-it","image":"./episodes/edt-162/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Christine McMonigal e discute le sfide che le organizzazioni affrontano durante la transizione al cloud e l'adozione di architetture multi-hybrid cloud. Mettono in evidenza l'importanza di comprendere questi ostacoli e fornire indicazioni per superarli. Questo episodio approfondirà alcune delle principali barriere e strategie per mitigare i rischi, garantendo una trasformazione cloud di successo."},{"id":64,"type":"Episode","title":"Sviluppo di un modello operativo Multi-Hybrid Cloud","tags":["cloudstrategy","digitaltransformation","collmultihybridcloud","cloudtechnologies","businessgoals","operationalefficiency","customersatisfaction","itinfrastructure","migrationplan","datasecurity","regulatorycompliance","hybridclouds","publicclouds","privateclouds","clouddeploymentmodels","governanceandsecurity","reducecosts","enhanceefficiency","customerexperience","strategicmove","clearvision","embracingdigital","edt163"],"body":"\r\n\r\nNell'era digitale di oggi, le aziende si stanno sempre più rivolgendo al cloud come mossa strategica per migliorare l'efficienza, ridurre i costi e migliorare l'esperienza del cliente. Tuttavia, prima di salire sul carro del cloud, è essenziale che le organizzazioni si fermino e valutino le proprie esigenze specifiche. Sviluppare una strategia cloud è un passo cruciale in questo processo, poiché consente alle aziende di allineare i propri obiettivi e obiettivi con le tecnologie cloud disponibili per loro.\n\n## Comprendere i tuoi obiettivi e scopi aziendali\n\nIl primo passo nello sviluppo di una strategia cloud consiste nel comprendere chiaramente gli obiettivi e le finalità della propria attività. Cosa si vuole raggiungere? Si desidera migliorare l'efficienza operativa, ridurre i costi o aumentare la soddisfazione della clientela? Avendo una visione chiara dei propri obiettivi, è possibile stabilire più accuratamente in che modo il cloud possa supportare e facilitare tali obiettivi.\n\n## Valutazione della tua infrastruttura esistente.\n\nDopo aver stabilito i tuoi obiettivi, è importante valutare la tua infrastruttura IT attuale. Questa valutazione aiuta a identificare eventuali sfide o limitazioni potenziali nel passaggio al cloud. Determina quali sistemi e applicazioni hai attualmente in uso e considera la loro compatibilità con un ambiente cloud. Questa valutazione orienterà le decisioni su quali applicazioni e servizi sono adatti per la migrazione.\n\n## Scegliere il modello di cloud giusto.\n\nCon i vari modelli di implementazione del cloud disponibili, le organizzazioni devono valutare le diverse opzioni che si allineano alle loro esigenze aziendali. Le nuvole pubbliche, le nuvole private e le nuvole ibride offrono ciascuna vantaggi e svantaggi distinti. Valutare i pro e i contro di ogni modello ti aiuterà a determinare la scelta più appropriata per la tua organizzazione. Considera fattori come la sicurezza dei dati, la scalabilità e la conformità normativa al momento di prendere questa decisione.\n\n## Creazione di un piano di migrazione e garanzia di governance e sicurezza.\n\nUna volta scelto un modello di cloud, è ora di creare un piano di migrazione. Ciò comporta delineare i passaggi e i tempi per spostare le tue applicazioni e i dati nel cloud. Prendi come priorità le applicazioni critiche che devono essere migrate per prime e sviluppa una strategia per migrare le restanti applicazioni in seguito. Inoltre, implementa un piano di governance e sicurezza per proteggere i tuoi dati e conformarti ai requisiti normativi. La sicurezza del cloud è una preoccupazione primaria per molte aziende, quindi è fondamentale assicurarsi che i tuoi dati siano protetti durante tutto il processo di migrazione.\n\nIn conclusione, sviluppare una strategia cloud è un processo complesso che richiede una pianificazione e una valutazione attenta. È essenziale comprendere gli obiettivi aziendali, valutare l'infrastruttura esistente, scegliere il giusto modello di cloud, creare un piano di migrazione ed implementare adeguate misure di governance e sicurezza. Abbracciando efficacemente la trasformazione digitale e sfruttando il potere del cloud, le organizzazioni possono raggiungere i propri obiettivi, migliorare l'efficienza e guidare la crescita e il successo.\n\nNell'era digitale di oggi, le aziende si stanno sempre più rivolgendo al cloud come mossa strategica per migliorare l'efficienza, ridurre i costi e migliorare l'esperienza del cliente. Tuttavia, prima di salire sul carro del cloud, è essenziale per le organizzazioni fare un passo indietro e valutare le loro esigenze specifiche. Sviluppare una strategia cloud è un passaggio cruciale in questo processo, poiché consente alle aziende di allineare i propri obiettivi con le tecnologie cloud disponibili per loro.\n\n## Comprensione dei tuoi obiettivi e obiettivi aziendali\n\nIl primo passo nello sviluppo di una strategia cloud è acquisire una chiara comprensione degli obiettivi e delle finalità della tua attività. Cosa stai cercando di raggiungere? Vuoi migliorare l'efficienza operativa, ridurre i costi o aumentare la soddisfazione del cliente? Avendo una visione chiara dei tuoi obiettivi, puoi determinare meglio come il cloud possa supportare e abilitare questi obiettivi.\n\n## Valutazione della tua infrastruttura esistente\n\nDopo aver stabilito i tuoi obiettivi, è importante valutare l'infrastruttura IT attuale. Questa valutazione aiuta a identificare eventuali sfide o limitazioni potenziali nella migrazione verso il cloud. Determina quali sistemi e applicazioni hai attualmente in uso e considera la loro compatibilità con un ambiente cloud. Questa valutazione fornirà informazioni per prendere decisioni su quali applicazioni e servizi sono adatti per la migrazione.\n\n## Scegliere il modello di cloud giusto\n\nCon diversi modelli di distribuzione cloud disponibili, le organizzazioni devono valutare le diverse opzioni che si allineano ai loro requisiti aziendali. Le cloud pubbliche, private e ibride offrono vantaggi e svantaggi distinti. Valutare i pro e i contro di ciascun modello ti aiuterà a determinare la scelta più appropriata per la tua organizzazione. Considera fattori come la sicurezza dei dati, la scalabilità e la conformità normativa al momento di prendere questa decisione.\n\n## Creazione di un Piano di Migrazione e Garanzia di Governance e Sicurezza.\n\nUna volta scelto un modello di cloud, è il momento di creare un piano di migrazione. Ciò comporta delineare i passaggi e la linea temporale per spostare le tue applicazioni e i dati nel cloud. Dai priorità alle applicazioni critiche che devono essere migrate per prime e sviluppa una strategia per migrare le restanti applicazioni successivamente. Inoltre, implementa un piano di governance e sicurezza per proteggere i tuoi dati e rispettare eventuali requisiti normativi. La sicurezza del cloud è una delle principali preoccupazioni per molte aziende, quindi è fondamentale assicurarsi che i tuoi dati siano protetti durante l'intero processo di migrazione.\n\nIn conclusione, sviluppare una strategia cloud è un processo complesso che richiede una pianificazione e una valutazione attente. È essenziale comprendere gli obiettivi aziendali, valutare l'infrastruttura esistente, scegliere il modello cloud adatto, creare un piano di migrazione ed implementare misure di governance e sicurezza adeguate. Abbracciando in modo efficace la trasformazione digitale e sfruttando il potere del cloud, le organizzazioni possono raggiungere i propri obiettivi, migliorare l'efficienza e promuovere crescita e successo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Rajiv Mandal","Darren W Pulsipher"],"link":"/episode-EDT163-it","image":"./episodes/edt-163/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista Rajiv Mandal, architetto delle soluzioni cloud, sulla sviluppo di una strategia multi-ibrida per il tuo moderno organizzazione IT."},{"id":65,"type":"Episode","title":"Portafoglio delle applicazioni e dei carichi di lavoro nella migrazione del cloud","tags":["cloudmigration","organizations","collmultihybridcloud","cloudnative","datacenterdependencies","hybridstrategy","technicaldebt","applications","workloads","politicalcapital","customerfacingapplications","importance","applicationrationalization","analysis","dependencies","smoothtransition","surprises","decision","compliancerequirements","regulatedindustries","compliancemonitoring","embracingdigital","edt164"],"body":"\r\n\r\n## Comprendere le applicazioni e i carichi di lavoro nella migrazione verso il cloud.\n\nQuando si tratta di migrazione verso il cloud, le organizzazioni in genere si dividono in due gruppi. Il primo gruppo è costituito da organizzazioni native del cloud che hanno progettato le loro applicazioni nel cloud, eliminando ogni dipendenza dai data center. Il secondo gruppo adotta una strategia ibrida, affidandosi sia al data center che al cloud. Tuttavia, anche queste organizzazioni ibride possono avere un debito tecnico che deve essere affrontato.\n\nUno dei principali sfide nella migrazione verso il cloud è comprendere la complessità delle applicazioni e dei carichi di lavoro. Sarah introduce il concetto di \"capitale politico\" che un'applicazione porta con sé. Mentre le applicazioni rivolte all'esterno e orientate al cliente spesso ricevono la maggiore attenzione e investimenti, le applicazioni più piccole che potrebbero non sembrare significative possono avere un impatto notevole sull'organizzazione se non funzionano correttamente o vengono trascurate.\n\n## L'importanza della razionalizzazione delle applicazioni\n\nSarah condivide un'esperienza personale che mette in evidenza l'importanza di considerare l'intero portfolio di applicazioni e carichi di lavoro durante la migrazione verso il cloud. Ha assistito a una interruzione delle attività aziendali causata dalla mancanza di attenzione verso un'applicazione rivolta al cliente apparentemente insignificante. Questa esperienza sottolinea la necessità che le organizzazioni conducano un'analisi e razionalizzazione approfondita del loro portfolio di applicazioni prima di migrare verso il cloud.\n\nCapendo le complessità e le dipendenze delle applicazioni e degli oneri di lavoro, le organizzazioni possono garantire una transizione senza intoppi al cloud con meno sorprese o interruzioni. Sarah sottolinea la necessità per le organizzazioni di dare priorità alla razionalizzazione delle applicazioni per identificare applicazioni critiche che potrebbero richiedere ulteriori investimenti e attenzione, anche se non sono le più visibili.\n\n## Per Toccare o Non Toccare: Valutare i Carichi di Lavoro per la Migrazione al Cloud\n\nSebbene la migrazione dei carichi di lavoro verso il cloud possa portare numerosi vantaggi, potrebbe non essere sempre necessario o conveniente toccare determinati carichi di lavoro o applicazioni. Alcuni carichi di lavoro potrebbero essere in esecuzione senza problemi da anni e rappresentare un elemento critico per le operazioni dell'organizzazione. In tali casi, potrebbe non avere senso apportare modifiche o migrarli verso il cloud.\n\nFattori da considerare nella presa di decisione includono il livello di personalizzazione e integrazione del carico di lavoro, la presenza di debiti tecnici e il prossimo ritiro dei vecchi sistemi. Tuttavia, è essenziale rivalutare regolarmente questi carichi di lavoro per assicurarsi che continuino a soddisfare le esigenze dell'organizzazione. Monitorare le tendenze del settore e gli avanzamenti tecnologici può aiutare a individuare potenziali cambiamenti in futuro.\n\n## Navigare i requisiti di conformità nella migrazione verso il cloud\n\nI requisiti di conformità possono rappresentare delle sfide nella migrazione verso il cloud, specialmente per le organizzazioni in settori regolamentati. Tuttavia, i fornitori di servizi cloud hanno compiuto notevoli progressi nel rispondere a tali preoccupazioni. Essi offrono strumenti e servizi che aiutano ad automatizzare il monitoraggio e la segnalazione della conformità, rendendo meno oneroso per le organizzazioni mantenere la conformità.\n\nPer affrontare queste sfide, le organizzazioni dovrebbero condurre una valutazione approfondita dei loro requisiti di conformità. Consultarsi con esperti che possano fornire orientamento sugli standard di conformità e progettare un'architettura cloud che soddisfi tali requisiti è fondamentale. Dovrebbero essere implementate regolari verifiche e monitoraggi per garantire la conformità continua.\n\n## Conclusione\n\nIn questo episodio del podcast, Darren Pulsipher e Sarah Musick mettono in luce importanti aspetti della migrazione verso il cloud, inclusa la razionalizzazione dei portafogli delle applicazioni, la presa di decisioni riguardo al toccare i carichi di lavoro e l'affrontare i requisiti di conformità. Comprendendo questi fattori e gestendo attivamente il debito tecnico, le organizzazioni possono intraprendere un viaggio di migrazione verso il cloud di successo, sfruttando l'agilità e la flessibilità offerte dal cloud mentre minimizzano rischi e interruzioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sarah Musick","Darren W Pulsipher"],"link":"/episode-EDT164-it","image":"./episodes/edt-164/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Sarah Musick, Architetto delle soluzioni cloud presso Intel. Insieme, approfondiscono il tema dei portafogli di applicazioni e carichi di lavoro nella migrazione del cloud. Con la sua esperienza nella consulenza e nell'ottimizzazione del cloud, Sarah porta preziose intuizioni alla discussione."},{"id":66,"type":"Episode","title":"Fattori di assegnazione di Carico di lavoro nel Cloud","tags":["cloudcomputeoptions","collmultihybridcloud","cloudinstance","cloudspecialistadvice","computeselectiontools","optimizecloud","workloadcloud","vendorlockinprevention","cloudbestpractices","cloudinstanceperformance","costeffectivecomputesolutions","workloadoptimization","resourceefficiency","cloud","multihybridcloud","embracingdigital","edt165"],"body":"\r\n\r\n## Comprensione delle opzioni di calcolo\n\nI fornitori di servizi cloud (CSP) offrono una varietà di diverse famiglie di elaborazione, che vanno dalle generazioni più vecchie dell'hardware di elaborazione alle ultime e più performanti istanze. Queste generazioni più vecchie sono spesso utilizzate per funzioni di calcolo convenienti, mentre le generazioni più nuove offrono prestazioni migliorate a prezzi simili o inferiori.\n\nPuò essere travolgente navigare tra le numerose opzioni di elaborazione disponibili nel cloud, soprattutto con l'uscita regolare di nuove istanze. Ecco dove entrano in gioco gli specialisti del cloud, come quelli di Intel. Questi esperti possono fornire preziosi suggerimenti e assistenza nella scelta dell'istanza più adatta per un carico di lavoro specifico.\n\n## Prendere Decisioni Informate\n\nPer prendere la migliore decisione, cerca il consiglio di specialisti del cloud o utilizza strumenti come Densify o Intel Site Optimizer. Questi strumenti sfruttano l'apprendimento automatico per analizzare le caratteristiche di un'applicazione, l'utilizzo del calcolo e le esigenze di rete per determinare la dimensione dell'istanza più adatta. Sfruttando queste risorse, le organizzazioni possono garantire di ottenere il massimo dalle loro risorse cloud, evitando sottoutilizzazione o sprechi.\n\n## Implementazione delle migliori pratiche\n\nÈ importante incorporare le raccomandazioni di istanze negli script di infrastruttura come codice (IaC), come ad esempio TerraForm, al fine di automatizzare la selezione dell'istanza più performante per un carico di lavoro. Questo garantisce una posizionamento coerente ed efficiente delle istanze, eliminando il rischio di errori umani e ottimizzando le prestazioni.\n\n## Considerando la portabilità\n\nMentre attualmente Intel domina il mercato del cloud con istanze basate su x86, c'è una certa concorrenza da parte di AMD e ARM. I processori basati su ARM, come il Graviton, sono molto popolari tra i fornitori di servizi di cloud, ma necessitano di una maggiore portabilità del carico di lavoro tra i provider e tra ambienti pubblici e privati. Trasferire carichi di lavoro basati su x86 su ARM richiederebbe una refactoring e una rielaborazione del codice estesi.\n\nLe organizzazioni dovrebbero prendere in considerazione i problemi di compatibilità quando ripatriano i carichi di lavoro dal cloud all'infrastruttura in loco. È fondamentale valutare la portabilità e la flessibilità della piattaforma di calcolo scelta per garantire transizioni senza soluzione di continuità e evitare il blocco del fornitore.\n\n## Conclusione\n\nLa selezione della corretta istanza cloud è una decisione critica che può influire sulle prestazioni, i costi e la portabilità del carico di lavoro. Con l'aiuto di specialisti e strumenti cloud, le organizzazioni possono prendere decisioni consapevoli e ottimizzare l'utilizzo delle risorse cloud. Comprendendo le opzioni di calcolo disponibili, incorporando le migliori pratiche e considerando la portabilità, le aziende possono sfruttare appieno il potenziale del cloud garantendo flessibilità ed efficienza nelle proprie operazioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Ricardo Dutton Jr","Darren W Pulsipher"],"link":"/episode-EDT165-it","image":"./episodes/edt-165/it/thumbnail.png","lang":"it","summary":"In questo podcast, Darren e Rico Dutton approfondiscono il mondo delle istanze di cloud e i fattori da considerare quando si seleziona l'istanza giusta per il proprio carico di lavoro. Discutono delle diverse opzioni di calcolo disponibili nel cloud, dell'importanza di trovare il giusto equilibrio tra prestazioni e costi e del ruolo degli specialisti del cloud nel contribuire a prendere decisioni informate per le organizzazioni."},{"id":67,"type":"Episode","title":"Agilità nell'adozione del Cloud","tags":null,"body":"\r\n\r\n## Migrazione verso il cloud come un viaggio continuo\n\nMentre molte persone considerano la migrazione verso il cloud come un processo unico, è essenziale considerarla come un percorso continuo, in cui sviluppatori e team operativi lavorano insieme. Una volta che i carichi di lavoro sono modernizzati e implementati, è necessario monitorarli e valutarli costantemente per determinare se rispettano gli obiettivi aziendali e i criteri di successo.\n\nTrattando la migrazione verso il cloud come un percorso in corso, le organizzazioni possono consentire ai loro team di iterare, perfezionare e migliorare il loro successo. Questo approccio permetterà agilità, adattabilità e la capacità di rispondere alle mutevoli esigenze aziendali.\n\n## Ripatriare i carichi di lavoro e la flessibilità\n\nUn aspetto importante da considerare è la possibilità di migrare i carichi di lavoro in locale se non vengono raggiunti i benefici previsti dal cloud o se c'è la necessità di passare tra diversi fornitori cloud. Per ottenere un miglioramento continuo, è necessario valutare costantemente la situazione, definire le aspettative iniziali e essere agili e flessibili nel modello operativo del cloud.\n\nUn'infrastruttura coerente su più cloud è essenziale per consentire flessibilità e agilità. Mentre i fornitori di servizi cloud potrebbero cercare di limitare i clienti ai propri servizi, le organizzazioni dovrebbero resistere a questa tentazione e puntare a una coerenza tra i vari cloud o essere disposte a effettuare i cambiamenti necessari durante il trasferimento dei carichi di lavoro in posizioni diverse.\n\n## Strumenti e migliori prassi per l'ottimizzazione.\n\nOttimizzare gli ambienti cloud può essere complesso e richiedere tempo, competenze e risorse. Gli strumenti e le migliori pratiche di Intel possono aiutare le organizzazioni a valutare e ottimizzare la collocazione dei carichi di lavoro e fornire un'ottimizzazione continua in tempo reale senza influire sulle applicazioni. Automatizzando determinati aspetti del processo di ottimizzazione, questi strumenti possono far risparmiare tempo e denaro alle organizzazioni migliorando le prestazioni complessive.\n\nPer massimizzare i benefici di questi strumenti, è fondamentale categorizzare i carichi di lavoro in diverse sezioni basate su fattori come la standardizzazione, la criticità e l'esperimento. Ad esempio, i carichi di lavoro che richiedono alta disponibilità e bassa latenza potrebbero dover essere collocati su un'infrastruttura dedicata, mentre quelli meno critici possono essere posizionati su un'infrastruttura condivisa. Le organizzazioni possono utilizzare un approccio mirato all'ottimizzazione per garantire che il loro ambiente cloud sia personalizzato in base alle loro esigenze e obiettivi specifici.\n\n## Abbracciare la trasformazione digitale e migrare verso il cloud.\n\nLa rilevanza del cambiamento organizzativo e l'apprendimento dai metodi di successo e insuccesso è anche evidenziata in questo episodio. Per assistere le organizzazioni nel processo di migrazione verso il cloud, preziose risorse e orientamenti possono essere trovati su embracingdigital.org.\n\nIn conclusione, implementando il miglioramento continuo, sviluppando un approccio strategico e abbracciando il cambiamento organizzativo, le organizzazioni possono ottimizzare il proprio ambiente cloud, aumentare l'efficienza e raggiungere gli obiettivi aziendali. Adottare il miglioramento continuo nelle operazioni cloud e considerare la migrazione cloud come un viaggio continuo è la chiave per una migrazione cloud di successo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Christine McMonigal","Darren W Pulsipher"],"link":"/episode-EDT166-it","image":"./episodes/edt-166/it/thumbnail.png","lang":"it","summary":"La migrazione verso il cloud non è più un processo occasionale, ma piuttosto un viaggio continuo che richiede valutazioni costanti, monitoraggio e adattamento per raggiungere gli obiettivi aziendali. In questo episodio del nostro podcast, l'ospite Darren Pulsipher parla con Christine McMonigal dell'importanza di adottare un miglioramento continuo nelle operazioni cloud."},{"id":68,"type":"Episode","title":"Sfruttare l'IA per proteggere i bambini","tags":["ai","aipolicy","lawenforcement","aiethics","collgenerativeai","childprotection","aiforgood","chainofcustody","policy","people","embracingdigital","edt167"],"body":"\r\n\r\n## Sfide nell'incriminare i predatori di minori online:\n\nUno dei principali sfide nel perseguire i predatori di minori online è la mancanza di uniformità tra le giurisdizioni riguardo alla tecnologia e ai crimini online. Ciò crea ostacoli significativi per le agenzie di applicazione della legge e una lacuna nella loro capacità di perseguire ed investigare casi in modo efficace. Ogni giurisdizione opera in modo diverso con il proprio insieme di leggi, regolamenti e procedure. Purtroppo, queste differenze possono confondere e rendere difficile investigare e perseguire i predatori sessuali online. Spesso, le indagini tradizionali non sono sufficienti per catturare i predatori online. Il mondo digitale ha creato una nuova razza di criminali esperti di tecnologia che possono coprire le loro tracce.\n\nLe agenzie di forze dell'ordine devono essere dotate di risorse, tecnologia e formazione per contrastare efficacemente i predatori sessuali online. La collaborazione tra le società tecnologiche e le forze dell'ordine è fondamentale nello sviluppo di pratiche standardizzate e di un linguaggio per l'accusa e l'indagine. Colmando questa lacuna, possiamo migliorare l'efficienza di questi processi e aumentare le possibilità di portare i predatori di minori davanti alla giustizia. Inoltre, il pubblico deve essere informato dei rischi e dei pericoli legati ai predatori online. Genitori, educatori e tutor devono insegnare ai bambini come proteggersi online e cosa fare se si trovano di fronte a contenuti o comunicazioni inappropriate.\n\n## Il ruolo dell'IA nella gestione delle prove:\n\nLe tecnologie di intelligenza artificiale possono essere vitali nella gestione delle prove digitali, in particolare nei casi che coinvolgono predatori di minori. L'IA può aiutare ad automatizzare la scansione, la segnalazione e l'analisi di contenuti illeciti. Gli strumenti di intelligenza artificiale possono anche aiutare a ridurre il carico di lavoro degli investigatori, consentendo loro di concentrarsi sui casi di alta priorità. Tuttavia, ci sono ancora molte sfide nell'implementazione e nella comprensione di queste tecnologie tra le diverse giurisdizioni. Una delle sfide principali è che l'IA è efficace solo quanto i dati su cui è addestrata, e i dati variano tra le giurisdizioni. Di conseguenza, è difficile sviluppare modelli di IA efficaci che possano funzionare in diverse giurisdizioni.\n\nPer garantire una gestione efficiente delle prove, gli attori del sistema giudiziario devono lavorare insieme nell'adozione e nello sfruttamento degli strumenti di intelligenza artificiale. La collaborazione tra tecnologi, agenzie di polizia e sistemi giudiziari è fondamentale per superare queste sfide e sfruttare efficacemente l'IA per proteggere i minori online. L'implementazione dell'IA nella gestione delle prove dovrebbe essere supportata da politiche e linee guida robuste che proteggano la privacy delle vittime e assicurino l'uso etico di queste tecnologie. Inoltre, la formazione regolare e l'educazione su questi strumenti sono essenziali per garantirne un uso efficace nel contrastare i predatori sessuali online.\n\n## Collaborazione e standardizzazione per una protezione efficace\n\nLa collaborazione e la standardizzazione sono aspetti fondamentali per combattere con successo lo sfruttamento dei minori online. La lotta contro questo crimine atroce richiede la cooperazione tra fornitori di tecnologia, agenzie di polizia e sistemi giudiziari. Queste parti devono lavorare insieme per sviluppare strategie e soluzioni complete.\n\nLa collaborazione non dovrebbe concentrarsi solo sugli aspetti tecnici, ma anche sullo sviluppo di pratiche e protocolli standardizzati per gestire i casi che coinvolgono predatori di minori. Stabilendo un linguaggio e dei processi coerenti, possiamo semplificare le indagini, accelerare i procedimenti legali e migliorare complessivamente la protezione dei bambini nello spazio digitale.\n\nInoltre, le pratiche e i protocolli standardizzati dovrebbero essere continuamente rivalutati ed aggiornati per restare attuali e pratici. Stabilire uno standard globale per contrastare lo sfruttamento online dei minori fornirebbe un quadro di riferimento per tutti gli attori coinvolti, garantendo che ogni caso venga trattato in modo coerente e equo, indipendentemente da dove si verifichi.\n\n## Sfruttare l'IA per proteggere i bambini online\n\nUtilizzare l'intelligenza artificiale (AI) nella gestione delle prove è cruciale per contrastare efficacemente lo sfruttamento sessuale dei minori online. La quantità di prove digitali può essere travolgente per gli investigatori, ma l'AI può aiutare automatizzando l'identificazione e l'analisi delle prove potenziali. Questa automazione libera il tempo degli investigatori e consente loro di concentrarsi sugli aspetti più critici dell'indagine.\n\nTuttavia, l'implementazione dell'intelligenza artificiale nella gestione delle prove richiede attenta considerazione. Deve esserci trasparenza e responsabilità nell'uso dell'IA e nel determinare cosa costituisce o non costituisce una prova. Inoltre, è necessario affrontare le preoccupazioni etiche sull'uso dell'IA nelle forze dell'ordine, come i potenziali pregiudizi negli algoritmi.\n\n## Conclusione\n\nIn conclusione, la collaborazione, la standardizzazione e l'utilizzo dell'intelligenza artificiale nella gestione delle prove sono passi cruciali verso un ambiente digitale più sicuro per i bambini. Affrontare la disorganizzazione e la mancanza di uniformità nella tecnologia e nei crimini online richiederà uno sforzo collettivo di tutti gli attori interessati. Abbracciando queste sfide e lavorando insieme, possiamo compiere progressi significativi nella lotta allo sfruttamento dei minori e garantire il benessere dei bambini nell'era digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Rachel Dreikosen","Darren W Pulsipher"],"link":"/episode-EDT167-it","image":"./episodes/edt-167/it/thumbnail.jpg","lang":"it","summary":"In un recente podcast, Darren Pulsipher, Architetto Capo delle Soluzioni per il Settore Pubblico presso Intel, ha accolto Rachel Driekosen, Direttore Tecnico presso Intel, per discutere dell'uso dell'IA nella protezione dei bambini online. L'episodio affronta le sfide nel perseguire e scoprire i predatori di minori, il ruolo dell'IA nella gestione delle prove e l'importanza della collaborazione e delle pratiche standardizzate."},{"id":69,"type":"Episode","title":"Generative AI quotidiano.","tags":["generativeai","firefly","videogen","figma","enterpriseaistrategy","ai","creativecontentgeneration","enhancingdailytasks","powerofgenerativeai","searchintent","contentcreationautomation","chatbotsincontentcreation","embracingdigital","edt168"],"body":"\r\n\r\n## Sbocciare creatività e produttività con strumenti di intelligenza artificiale generativa.\n\nIn questo episodio del podcast, Darren Pulsipher intervista Andy Morris, responsabile della strategia dell'IA aziendale presso Intel, riguardo all'impatto dell'IA generativa sulla vita quotidiana. L'IA generativa utilizza l'intelligenza artificiale per generare nuovi contenuti, come immagini, testi e musica. La conversazione ruota attorno ai vari strumenti dell'IA generativa e al loro potenziale per rivoluzionare settori industriali e migliorare le attività quotidiane.\n\n## Il Potere dell'AI Generativa nella Generazione di Contenuti\n\nSecondo Andy Morris, gli strumenti di intelligenza artificiale generativa stanno diventando sempre più importanti in diverse industrie. Consiglia di iniziare con motori di ricerca che hanno integrato tecnologie open AI per esplorare l'IA generativa. Questi strumenti possono migliorare i risultati di ricerca fornendo contenuti più pertinenti e creativi. Tuttavia, è fondamentale considerare l'intento di ricerca quando si utilizzano questi strumenti, poiché potrebbero non sempre generare i risultati desiderati per informazioni specifiche.\n\nL'IA generativa sta lasciando il segno anche nella creazione di contenuti. Ad esempio, i chatbot hanno registrato una crescita esplosiva e vengono utilizzati per scrivere saggi, creare contenuti e migliorare foto. Sia che tu sia un creatore di contenuti o uno studente, gli strumenti di IA generativa possono automatizzare alcune fasi del processo di creazione dei contenuti, aumentando così la creatività e la produttività.\n\n## Strumenti innovativi per la generazione di immagini e video.\n\nDue entusiasmanti strumenti sono Adobe Firefly e VideoGen Video creation. Questi strumenti consentono agli utenti di creare e manipolare immagini e video in modi unici e creativi.\n\nAdobe Firefly è un tool gratuito che consente agli utenti di generare nuove immagini e sostituire elementi nelle foto esistenti. Le sue funzioni di riempimento generativo e di riempimento esterno consentono agli utenti di modificare o sostituire parti di un'immagine, ampliando così le possibilità creative. D'altra parte, Video Gen Video si concentra sulla generazione di video utilizzando script o pagine web esistenti come materiale di origine. Questo strumento potenziato dall'intelligenza artificiale semplifica la creazione di video coinvolgenti selezionando e inserendo automaticamente immagini e video pertinenti.\n\nQuesti strumenti innovativi offrono una serie di possibilità sia per i professionisti che per gli utenti comuni. Forniscono accessibilità a funzionalità di modifica avanzate, offrendo agli utenti la possibilità di aggiungere un tocco di creatività ai loro progetti senza richiedere competenze o conoscenze approfondite nel software di modifica.\n\n## Rendere più efficiente la creazione di contenuti con l'IA generativa\n\nDiversi strumenti come VideoGen, Figma e Framer.AI hanno reso la creazione di contenuti più comoda ed efficiente in diversi settori.\n\nVideoGen può creare video basati sui contenti di un articolo o post di blog. Ci riesce utilizzando librerie esistenti di immagini e clip video, automatizzando così il processo di creazione di video coinvolgenti che raccontano una storia. Figma, uno strumento di progettazione grafica online, offre una maggiore flessibilità di design consentendo agli utenti di creare modelli personalizzati. Allo stesso modo, Framer.AI semplifica la creazione di siti web sfruttando la tecnologia dell'intelligenza artificiale, permettendo agli utenti di generare e pubblicare rapidamente siti web.\n\nSebbene gli strumenti AI generativi offrano comodità ed efficienza nella creazione di contenuti, c'è bisogno di competenze umane in determinati aspetti creativi. Gli elementi di design e le considerazioni estetiche traggono ancora vantaggio dall'apporto umano per garantire risultati visivamente gradevoli. Mentre gli strumenti AI generativi possono automatizzare le parti meno specializzate del mercato, le applicazioni sofisticate spesso richiedono un tocco umano.\n\nIn conclusione, gli strumenti di intelligenza artificiale generativa trasformano le attività quotidiane e rivoluzionano la creazione di contenuti. Dai motori di ricerca potenziati dall'intelligenza artificiale a potenti strumenti sviluppati da Adobe e altre aziende, queste tecnologie stanno sbloccando nuovi livelli di creatività ed efficienza. Abbracciare l'intelligenza artificiale generativa sta diventando sempre più cruciale per individui e aziende per rimanere competitivi nel mondo del lavoro in evoluzione. Diventando competenti in questi strumenti e sfruttando le loro capacità, gli individui possono ottenere un vantaggio competitivo e aprire porte a nuove opportunità di consulenza e personalizzazione dei servizi. Il futuro è luminoso per l'intelligenza artificiale generativa, ed è ora il momento di esplorare e abbracciare questi strumenti innovativi.\n\n## Sbocciare creatività e produttività con gli strumenti di AI generativa.\n\nL'AI generativa utilizza l'intelligenza artificiale per generare nuovi contenuti, come immagini, testo e musica. La conversazione ruota attorno ai vari strumenti di AI generativa e al loro potenziale di rivoluzionare settori industriali e migliorare compiti quotidiani.\n\n## Il potere dell'AI generativa nella generazione di contenuti\n\nSecondo Andy Morris, gli strumenti di intelligenza artificiale generativa stanno diventando sempre più importanti in diverse industrie. Raccomanda di iniziare con motori di ricerca che hanno integrato tecnologie di intelligenza artificiale aperte per esplorare l'IA generativa. Questi strumenti possono migliorare i risultati di ricerca fornendo contenuti più pertinenti e creativi. Tuttavia, è fondamentale considerare l'intento di ricerca quando si utilizzano questi strumenti, poiché potrebbero non sempre generare i risultati desiderati per informazioni specifiche.\n\nL'IA generativa sta facendo inoltre la sua comparsa nella creazione di contenuti. I chatbot, per esempio, hanno conosciuto una crescita esplosiva e vengono utilizzati per scrivere saggi, creare contenuti e migliorare le foto. Che tu sia un creatore di contenuti o uno studente, gli strumenti di IA generativa possono automatizzare certi aspetti del processo di creazione di contenuti, aumentando così la creatività e la produttività.\n\n## Strumenti innovativi per la generazione di immagini e video\n\nDue strumenti emozionanti sono Adobe Firefly e VideoGen Video creation. Questi strumenti consentono agli utenti di creare e manipolare immagini e video in modi unici e creativi.\n\nAdobe Firefly è uno strumento gratuito che consente agli utenti di generare nuove immagini e sostituire elementi nelle foto esistenti. Le sue funzioni di riempimento generativo e di riempimento esterno consentono agli utenti di modificare o sostituire parti di un'immagine, ampliando così le possibilità creative. D'altra parte, Video Gen Video si concentra sulla generazione di video utilizzando script esistenti o pagine web come materiale di origine. Questo strumento alimentato dall'intelligenza artificiale semplifica la creazione di video coinvolgenti selezionando e inserendo automaticamente immagini e clip video pertinenti.\n\nQuesti strumenti innovativi offrono una gamma di possibilità sia per i professionisti che per gli utenti comuni. Forniscono l'accesso alle avanzate capacità di editing, consentendo agli utenti di aggiungere un tocco di creatività ai loro progetti senza richiedere competenze o conoscenze approfondite nel software di editing.\n\n## Ottimizzazione della creazione di contenuti con l'AI generativa\n\nDiversi strumenti come VideoGen, Figma e Framer.AI hanno reso la creazione di contenuti più comoda ed efficiente in diversi settori.\n\nVideoGen può creare video basati sul contenuto di un articolo o di un post di blog. Per farlo, utilizza le librerie esistenti di immagini e clip video, automatizzando così il processo di creazione di video coinvolgenti che raccontano una storia. Figma, un tool di design grafico online, offre maggiore flessibilità di design permettendo agli utenti di creare modelli personalizzati. Allo stesso modo, Framer.AI semplifica la creazione di siti web sfruttando la tecnologia di intelligenza artificiale, consentendo agli utenti di generare e pubblicare rapidamente siti web.\n\nNonostante gli strumenti di intelligenza artificiale generativa offrano comodità ed efficienza nella creazione di contenuti, vi è ancora bisogno dell'esperienza umana in certi aspetti creativi. Gli elementi del design e le considerazioni estetiche traggono ancora vantaggio dall'intervento umano per garantire risultati visivamente piacevoli. Sebbene gli strumenti di intelligenza artificiale generativa possano automatizzare le parti meno specializzate del mercato, le applicazioni sofisticate richiedono spesso un tocco umano.\n\nIn conclusione, gli strumenti di intelligenza generativa trasformano le attività quotidiane e rivoluzionano la creazione di contenuti. Dai motori di ricerca potenziati dall'intelligenza artificiale agli strumenti potenti sviluppati da Adobe e altre aziende, queste tecnologie stanno sbloccando nuovi livelli di creatività ed efficienza. Abbracciare l'intelligenza generativa sta diventando sempre più cruciale per individui e aziende per rimanere competitivi nel mondo del lavoro in evoluzione. Diventando competenti in questi strumenti e sfruttando le loro capacità, gli individui possono ottenere un vantaggio competitivo e aprire le porte a nuove opportunità di consulenza e personalizzazione dei servizi. Il futuro è luminoso per l'intelligenza generativa e ora è il momento di esplorare ed abbracciare questi strumenti innovativi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Andy Morris","Darren W Pulsipher"],"link":"/episode-EDT168-it","image":"./episodes/edt-168/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast, Darren Pulsipher intervista Andy Morris, responsabile della strategia di AI aziendale presso Intel, riguardo all'impatto dell'IA generativa sulla vita quotidiana."},{"id":70,"type":"Episode","title":"Mantenendo l'Umanità nell'Intelligenza Artificiale","tags":["userexperience","humancentereddesign","ai","trust","useradoption","transparency","generativeai","jobdisplacement","opencommunication","humansupport","collgenerativeai"],"body":"\r\n\r\n## Prioritizzare l'esperienza dell'utente attraverso il design centrato sull'essere umano.\n\nSunny Stueve, un ingegnere dei fattori umani, sottolinea l'importanza dell'ottimizzazione dell'esperienza umana e delle prestazioni di sistema nello sviluppo delle soluzioni di intelligenza artificiale. Lei enfatizza la necessità di avere un valore e un piano prima di immergersi nella codifica. Incorporando i principi di progettazione centrata sull'utente fin dall'inizio, le organizzazioni possono dare priorità alla prospettiva dell'utente e garantire una migliore esperienza complessiva dell'utente. Il ruolo di Sunny consiste nel comprendere le esigenze degli utenti e incorporarle nel processo di progettazione al fine di ridurre al minimo la necessità di riprogrammare il codice e massimizzare l'efficacia delle soluzioni di intelligenza artificiale.\n\nDarren condivide un'aneddoto dalla sua esperienza di lavoro con i radiologi, sottolineando il valore di sedersi con i clienti e comprendere le loro esigenze prima di sviluppare il software. Questo incontro personale evidenzia l'importanza di considerare i fattori umani nello sviluppo delle soluzioni tecnologiche. Adottando un approccio centrato sull'utente, le organizzazioni possono creare soluzioni di intelligenza artificiale su misura per le esigenze degli utenti, ottenendo così tassi di adozione più elevati e una maggiore soddisfazione.\n\n## Affrontare la fiducia e l'adozione degli utenti nell'integrazione dell'IA\n\nSunny spiega inoltre che l'integrazione dell'IA crea un cambiamento di paradigma nell'adozione da parte degli utenti e nella fiducia. Mentre si segue un processo di scoperta approfondito che comporta la raccolta di dati qualitativi e quantitativi, la costruzione di relazioni e la convalida delle ipotesi, è essenziale riconoscere che l'introduzione dell'IA può scatenare paure e ostacoli di fiducia più elevati. Gli esseri umani sono creature di abitudine e di schemi, quindi educare gli utenti e costruire fiducia diventa cruciale per superare la resistenza al cambiamento.\n\nPer affrontare il problema della fiducia, la trasparenza risulta fondamentale. Fornire agli utenti informazioni sui modelli di intelligenza artificiale utilizzati, sull'intento e sui dati utilizzati per costruire gli algoritmi e i modelli consente di prendere decisioni informate. I progettisti possono inoltre sottolineare il pensiero critico e il raffronto di informazioni da diverse fonti, incoraggiando gli utenti a verificare e convalidare autonomamente le informazioni generate dall'intelligenza artificiale.\n\nI designer dovrebbero anche considerare l'incorporazione dei principi di design dell'interfaccia utente che soddisfano la natura unica dell'IA generativa. Ciò potrebbe comportare chiare indicazioni quando l'IA genera informazioni e integra interfacce multimodali che consentono l'interazione simultanea con elementi vocali, testuali e visivi. Mantenendo gli utenti informati, coinvolti e abilitati, le organizzazioni possono costruire fiducia e favorire l'adozione da parte degli utenti della tecnologia AI.\n\n## Adattarsi al cambiamento: Approccio centrato sull'essere umano all'AI generativa\n\nLa trascrizione del podcast esplora anche l'impatto dell'IA generativa sui lavori e sui flussi di lavoro. Sebbene ci siano preoccupazioni riguardo all'eliminazione dei posti di lavoro, la conversazione enfatizza l'importanza di abbracciare le opportunità che l'IA presenta. Piuttosto che temere il potenziale di perdita del lavoro, i lavoratori dovrebbero cambiare mentalità considerando l'IA come un assistente che può migliorare la produttività e consentire loro di concentrarsi su lavori più significativi e di valore.\n\nLa comunicazione aperta e il coinvolgimento dei dipendenti nel processo di cambiamento sono fondamentali per mantenere i lavoratori coinvolti e affrontare le preoccupazioni riguardanti la sostituzione del lavoro. Collaborando con i dirigenti senior per garantire una comprensione dell'impatto potenziale e coinvolgendo esperti di psicologia organizzativa, le organizzazioni possono supportare i dipendenti durante il processo di cambiamento. La creazione di team focalizzati sul supporto umano per l'Intelligenza Artificiale può affrontare le preoccupazioni individuali e creare opportunità per l'evoluzione dei ruoli al fianco delle attività automatizzate.\n\nIn conclusione, l'integrazione della tecnologia AI richiede un approccio centrato sull'essere umano. Priorizzare l'esperienza dell'utente, costruire fiducia e adattarsi al cambiamento sono elementi critici per integrare con successo le soluzioni AI. Tenendo conto di questi fattori, le organizzazioni possono sfruttare i vantaggi dell'AI garantendo al contempo la soddisfazione, la fiducia e l'interesse degli utenti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Sunny Stueve","Darren W Pulsipher"],"link":"/episode-EDT169-it","image":"./episodes/edt-169/it/thumbnail.jpg","lang":"it","summary":"In un recente episodio del podcast Embracing Digital Transformation, l'ospite Darren Pulsipher, Chief Solution Architect del settore pubblico presso Intel, intervista Sunny Stueve, responsabile di Human Centered AI presso Leidos. Il podcast approfondisce l'importanza del design centrato sull'essere umano e dell'esperienza utente nell'integrazione della tecnologia dell'intelligenza artificiale."},{"id":71,"type":"Episode","title":"Elastic Search e Intel Optane DCPMM","tags":null,"body":"\r\n\r\nDi recente, ho effettuato alcuni test con la nuova tecnologia di Intel chiamata Optane DC Persistent Memory (PMEM) con Kafka. Utilizzando Optane in modo non tradizionale, montato come un sistema di file, sono riuscito a ottenere un notevole miglioramento nella velocità di trasferimento dei dati. Dai un'occhiata al mio podcast su questo argomento qui. (puoi mettere un link qui?). Ho provato la stessa cosa con Elasticsearch per vedere se potevo ottenere un miglioramento simile delle prestazioni.\n\nElasticsearch è un motore di ricerca e analisi altamente scalabile che consente di distribuire i dati su più nodi per espandere la soluzione e supportare quantità di dati più consistenti. In altre parole, è un gestore distribuito dei metadati, utilizzato principalmente per l'analisi dei log. Elastic stesso è un ottimo strumento per normalizzare i dati nel formato JSON. Posso inviare qualsiasi tipo di dati in Elastic e posso estenderlo su un cluster distribuito. Non è un bus di messaggi come Kafka, ma invece indicizza i dati che arrivano. Dal momento che Elastic memorizza questi dati su drive, ho realizzato che potevo utilizzare PMEM allo stesso modo in cui ero abituato a fare con Kafka.\n\n## Intel Optane DC Persistent Memory è una tecnologia di memoria avanzata sviluppata da Intel.\n\nIntel Optane DC Persistent Memory viene fornito nel formato DDR4, quindi si adatta perfettamente al tuo server in uno slot di memoria DDR4. I moduli sono disponibili in capacità di 128, 256 e 512 gigabyte, quindi in un sistema a due socket posso avere 6 terabyte di PMEM. Una caratteristica importante è che l'hardware è crittografato e collegato alla tua CPU con quella crittografia, quindi è sicuro ed estremamente affidabile. È già utilizzato per apportare profonde modifiche nel modo in cui viene utilizzato in molti database, come nella piattaforma Exadata di Oracle e SAP HANA.\n\n## Supporto per la Varie Applicazioni\n\nCi sono diversi modi per utilizzare questa tecnologia.\n\nIl primo è la modalità di memoria, che estende l'area di memoria di un server. Utilizza la PMEM proprio come una memoria normale. La memoria DDR4 funge da cache per la PMEM. In questa modalità, la velocità è paragonabile a quella della DDR4; nella maggior parte delle applicazioni, non vedrai alcuna differenza.\n\nLa seconda modalità è l'app diretta. In modalità app diretta, posso scrivere un'applicazione in modo che scriva direttamente nella PMEM, evitando passaggi che richiedono molto tempo.\n\nIl terzo modo consiste nell'utilizzare la modalità \"app direct\" per creare un sistema di file di memoria non volatile che si trova direttamente sul bus di memoria, il quale è molte volte più veloce del bus NVMe o persino del bus SATA.\n\nUtilizzando questa terza modalità, ho dovuto imparare un po' sull'architettura di Elastic per capire quali parti dovrei eseguire in questo file system ultra-veloce e quali lasciare dove sono. Volevo anche sapere se potevo apportare tali modifiche solo tramite il file di configurazione.\n\n## Utilizzando il kernel Linux\n\nPrima, ho dovuto imparare come utilizzare i comandi del kernel Linux per manipolare questa PMEM.\n\nCon il comando di controllo della memoria persistente Intel (ipmctl), ho scoperto di poter configurare e gestire la PMEM in modo da poterlo allocare per eseguire la modalità di memoria, la modalità di app diretta o una percentuale in modalità di memoria.\n\nL'altro comando è il controllo del dispositivo di memoria non volatile (ndctl). Questo mi permette di creare namespace e regioni nella PMEM che ho creato, in modo da poter montare quella regione come dispositivo. Successivamente, posso montare quel dispositivo come un filesystem.\n\n## ESRally Test di performance\n\nHo trovato ESRally, uno strumento di benchmark, da utilizzare nei miei test. La prima volta che ho configurato il test, ho eseguito ESRally dal mio normale disco SATA, dove Elastic stava eseguendo tutto dal disco PMEM. Ho ottenuto un certo miglioramento delle prestazioni, ma ho scoperto che a causa del trasferimento dei dati dal disco SATA memorizzati nel mio ESRally, ero limitato dalla velocità con cui potevo inviare dati a Elasticsearch. Quindi non era Elastic che rallentava, era ESRally perché il mio disco SATA era molto più lento del mio disco PMEM. Ho trasferito ESRally sul disco PMEM. Questo ha migliorato le prestazioni e ho ottenuto alcuni risultati interessanti.\n\n## Test delle limitazioni\n\nPer vedere quali sarebbero gli effetti di questo drive PMEM ultra-veloce su Elastic, ho eseguito il test su una macchina. Ciò ha eliminato la variabilità di rete eliminando i colli di bottiglia di rete come fattore limitante. Ho ridotto la comunicazione tra i servizi, che ha ridotto i colli di bottiglia delle repliche, e ho eseguito tutte le richieste su PMEM, eliminando la variabilità dell'unità SATA.\n\n## Prestazione ottimale (100%) App Direct\n\nPrima, ho allocato tutta la memoria PMEM in modalità \"app direct\" in modo da poter montare l'intera cosa come un sistema di file. Ho utilizzato DIMM da 128 gigabyte, quindi avevo un disco da 1,5 terabyte che potevo utilizzare. Sapevo dalla mia precedente prova con Kafka che ottengo migliori prestazioni con la modalità \"app direct\" al 100% piuttosto che al 50%.\n\nMediana di velocità (dovrebbe essere Throughput - potresti voler modificare nella diapositiva) documenti/sec\n\nUtilizzando le statistiche di ESRally, ho preso la mediana del throughput dei documenti al secondo in confronto al numero di gare concorrenti che stavo eseguendo contemporaneamente con produttori e consumatori. Ho ottenuto dei buoni risultati con l'unità SATA, paragonabili ad altri test pubblicati. Con l'unità PMEM, sono riuscito ad inglobare quasi il doppio dei documenti al secondo. Questo è davvero incredibile considerando che non sono stati apportati cambiamenti al codice, solo una modifica di configurazione.\n\n## Tempo di risposta del servizio\n\nL'altro risultato erano i tempi di risposta alle funzioni. Come previsto, all'aumentare del numero di gare concorrenti in esecuzione contemporaneamente, il tempo di risposta per quelle query o funzioni aumenta. Ma con il PMEM, il tempo di risposta è quasi il doppio più rapido. Da questo semplice test, ho capito che il luogo in cui memorizzi i dati necessari a Elasticsearch (PMEM o SATA) influisce sul tempo di risposta.\n\n## The translation of \"Conclusion\" to Italian is \"Conclusioni\".\n\nUtilizzando Optane Persistent Memory in modalità file system per aumentare le prestazioni e ridurre i costi dei server Elasticsearch, sono necessari minimi cambiamenti nella configurazione hardware e software, senza apportare modifiche ad Elasticsearch o alle applicazioni sottostanti. Raddoppiando la capacità di throughput di Elasticsearch, è possibile ridurre il numero totale di server nel cluster Elasticsearch, riducendo così il costo totale di proprietà.\n\n## Per ulteriori informazioni\n\nPer informazioni più dettagliate, consulta il link nel podcast al documento che abbiamo creato in risposta a questi risultati dei test. Puoi anche contattarmi all'indirizzo darren.w.pulsipher@intel.com o su LinkedIn @darrenpulsipher.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT17-it","image":"./episodes/edt-17/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher mostra come ha aumentato le prestazioni di Elasticsearch utilizzando la memoria persistente Optane di Intel in modalità 100% app direct. I suoi test mostrano un incredibile aumento delle prestazioni del 2x. Raddoppiando la capacità di throughput, è possibile ridurre notevolmente il numero di server nel cluster Elasticsearch."},{"id":72,"type":"Episode","title":"Principi di Zero Trust.","tags":["zta","zerotrust","zerotrustarchitecture","implementingzerotrust","identityverification","microsegmentation","leastprivilege","encryption","continuousauthentication","anomalydetection","automatedthreatresponse","dataprevention","rightsmanagement","analytics","policyenforcement","cybersecurity"],"body":"\r\n\r\n## Implementare la sicurezza Zero Trust.\n\nLa sicurezza a \"zero trust\" è diventata un modello sempre più popolare per la protezione degli ambienti IT moderni. Ma cosa significa esattamente \"zero trust\" e quali sono le migliori pratiche per implementarlo? Questo post fornisce un'introduzione ai principi del \"zero trust\" e alcune considerazioni chiave per adottare un'architettura a \"zero trust\".\n\n## Cos'è Zero Trust?\n\nIl modello zero trust si basa sul concetto di \"mai fidarsi, sempre verificare\". A differenza della tradizionale sicurezza di rete che si concentra sulle difese del perimetro, il zero trust assume che gli attaccanti siano già all'interno della rete. Nessun utente o dispositivo è intrinsecamente fidato - la verifica è richiesta ogni volta che viene richiesto l'accesso.\n\nCi sono diversi principi fondamentali del zero trust:\n\nVerifica tutti gli utenti e i dispositivi prima di concedere l'accesso.\n\nLimita l'accesso solo a ciò che è necessario (privilegio minimo)\n\n## Implementare la sicurezza Zero Trust.\n\nLa sicurezza a \"zero trust\" è diventata un modello sempre più popolare per proteggere gli ambienti IT moderni. Ma cosa si intende esattamente per \"zero trust\" e quali sono le migliori pratiche per implementarlo? Questo post fornisce un'introduzione ai principi del \"zero trust\" e le considerazioni chiave per adottare un'architettura a \"zero trust\".\n\n## Cos'è Zero Trust?\n\nIl modello Zero Trust si basa sul concetto di \"non fidarsi mai, verificare sempre\". A differenza della tradizionale sicurezza di rete che si concentra sulle difese perimetrali, Zero Trust presume che gli attaccanti siano già all'interno della rete. Nessun utente o dispositivo è fidato in modo innato - la verifica è richiesta ogni volta che viene richiesto l'accesso.\n\nCi sono diversi principi fondamentali della zero trust:\n\nVerifica tutti gli utenti e i dispositivi prima di concedere l'accesso\n\nLimitare l'accesso solo a ciò che è necessario (privilegio minimo)\n\nAssumere che si verifichino violazioni e limitare il raggio d'azione.\n\nMonitorare continuamente l'attività per individuare anomalie.\n\nAutomatizza le risposte alle minacce.\n\nAdottare la filosofia del \"zero trust\" significa passare da una fiducia implicita a un' autenticazione e autorizzazione continua degli utenti, dei dispositivi e dei carichi di lavoro.\n\n## Pilastri chiave di un'architettura Zero Trust\n\nCi sono sei pilastri chiave che costituiscono un'architettura di fiducia zero completa.\n\n## Identità\n\nLa robusta verifica dell'identità e l'autenticazione a più fattori garantiscono che gli utenti siano davvero chi affermano di essere. Le policy di accesso sono legate alle identità degli utenti.\n\n## Dispositivi\n\nLa salute del dispositivo, la posizione della sicurezza e l'approvazione devono essere convalidate prima di concedere l'accesso. Ciò include i controlli dei dispositivi personali (BYOD).\n\n## Rete\n\nLa micro-segmentazione definita dal software e i tunnel crittografati tra zone affidabili sostituiscono la fiducia implicita nella rete. L'accesso viene concesso su base per-sessione.\n\n## Carico di lavoro\n\nLe autorizzazioni dell'applicazione sono strettamente limitate in base all'identità e all'ambiente. L'accesso alle risorse di alto valore è intermediato tramite un gateway.\n\n## Traduci il seguente testo in italiano: Data\n\nI dati sensibili vengono criptati e l'accesso è controllato tramite politiche di prevenzione della perdita dei dati e gestione dei diritti.\n\n## Visibilità e analisi\n\nIl monitoraggio continuo offre visibilità su tutti gli utenti, dispositivi e attività. Le analisi avanzate individuano anomalie e le risposte automatizzate contengono le minacce.\n\n## Implementare Zero Trust\n\nPassare al principio del zero trust è un percorso che richiede l'aggiornamento delle politiche, dei processi e delle tecnologie in tutta un'organizzazione. I passi chiave includono:\n\nIdentifica i tuoi asset più critici e i dati di alto valore.\n\nRappresentare graficamente i flussi di lavoro e i requisiti di accesso a questi asset.\n\nImplementare l'autenticazione a più fattori e il principio del privilegio minimo.\n\nInizia a segmentare la tua rete con microperimetri e punti di controllo.\n\nCripta i dati sensibili sia durante il trasferimento che durante il riposo.\n\nValutare strumenti per l'analisi avanzata, l'automazione e l'orchestrazione.\n\nAdottare il principio di zero trust richiede tempo, ma può migliorare in modo significativo la tua postura di sicurezza contro le minacce moderne. Seguire un approccio incrementale basato sul rischio ti consente di ottenere vantaggi in ogni fase di maturità.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Anna Scott","Dave Marcus","Darren W Pulsipher"],"link":"/episode-EDT170-it","image":"./episodes/edt-170/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren esplora i principi dell'architettura Zero Trust con l'ospite speciale David Marcus, Senior Security Architect, e il ritorno dell'ospite Dr. Anna Scott."},{"id":73,"type":"Episode","title":"IA Generativa nel Settore Pubblico","tags":["generativeai","artificialintelligence","languagemodels","chatgpt","texttotext","texttoaudio","texttovideo","texttoimage","bias","accountability","dataleakage","ethics","compliance","responsibleuse","representativedata","unbiaseddata","highqualitydata","harmefuloutput","misleadingoutput","transparency","claudeai","informedconsent"],"body":"\r\n\r\n## Introduzione all'IA Generativa\n\nL'IA generativa è una tecnica utilizzata nell'intelligenza artificiale che può analizzare contenuti esistenti come testi, immagini o audio e generare nuovi contenuti originali da essi. Grandi modelli di linguaggio come ChatGPT hanno reso più facile per gli sviluppatori creare applicazioni generative basate su testi. Questi modelli sono pre-addestrati su enormi quantità di dati e possono generare risposte simili a quelle umane a richieste di testo.\n\nNell'ultimo anno, abbiamo assistito a incredibili progressi nell'uso della tecnologia AI generativa. Questo include chatbot in grado di condurre conversazioni complesse, strumenti di traduzione di lingue che possono tradurre testi tra diverse lingue in tempo reale, e persino la creazione di interamente nuovi pezzi d'arte. Le possibilità sono infinite, e possiamo aspettarci di vedere ancora più affascinanti casi di utilizzo emergere mano a mano che l'IA generativa continua a evolversi.\n\n## Capacità Chiave e Casi d'Uso\n\nLa generazione di contenuti da altri contenuti continuerà ad espandersi in aree come video, audio e ambienti 3D. Combinando diversi modelli di intelligenza artificiale generativa, si possono costruire rapidamente nuove soluzioni.\n\n## Testo a Testo\n\nLa tecnologia testo su testo è diventata sempre più popolare negli ultimi anni grazie alla sua versatilità e utilità. Ha una vasta gamma di applicazioni, tra cui la creazione di contenuti di marketing generando slogan e tagline accattivanti, la sintesi di documenti lunghi in pochi punti chiave, la traduzione di materiale in diverse lingue e il miglioramento complessivo della comunicazione tra individui e organizzazioni. Inoltre, gli algoritmi di intelligenza artificiale testo su testo possono anche valutare la qualità del contenuto scritto come saggi, fornendo feedback su grammatica, ortografia e struttura. Con tutti questi usi pratici, non sorprende che la tecnologia testo su testo sia diventata uno strumento essenziale in molte industrie.\n\n## Testo in Audio\n\nLa conversione del testo in audio è diventata un modo sempre più popolare per rendere i contenuti digitali più accessibili a un pubblico più ampio. Ha varie applicazioni, come fornire un formato alternativo per persone con problemi visivi, rendere i contenuti più coinvolgenti e divertenti, facilitare la traduzione e persino assistere nella navigazione. Ad esempio, la tecnologia di sintesi vocale può essere utilizzata per aiutare le persone con dislessia o altre difficoltà di lettura ad accedere più facilmente alle informazioni scritte. Inoltre, gli audiolibri e i podcast sono diventati una forma popolare di intrattenimento e la tecnologia di sintesi vocale può aiutare a creare più contenuti in questo formato. In generale, la capacità di convertire il testo in audio ha aperto nuove possibilità per rendere i contenuti digitali più inclusivi e accessibili a tutti.\n\n## Testo a Video\n\nLa tecnologia del testo-al-video è un settore emergente che ha mostrato molta promessa negli ultimi anni. Implica l'uso di algoritmi di intelligenza artificiale per convertire contenuti basati su testo in video coinvolgenti e informativi che possono essere utilizzati per una varietà di scopi, tra cui la formazione, il marketing e altre applicazioni.\n\nLa tecnologia funziona analizzando automaticamente il testo e identificando concetti chiave, temi e idee. Quindi utilizza queste informazioni per generare immagini, animazioni e altri elementi visivi che aiutano a illustrare e trasmettere il messaggio del testo.\n\nUno dei principali vantaggi della tecnologia di conversione testo-video è che può ridurre significativamente il tempo e le risorse necessarie per creare video di alta qualità. Ciò la rende uno strumento prezioso per aziende e organizzazioni di tutte le dimensioni, in particolare quelle con budget limitati o capacità di produzione video interne.\n\nOltre alle sue applicazioni pratiche, la tecnologia del testo-al-video ha anche il potenziale di rivoluzionare il modo in cui consumiamo e interagiamo con le informazioni. Rendendo più facile e coinvolgente l'assimilazione di idee e concetti complessi, potrebbe contribuire a democratizzare la conoscenza ed emancipare persone di tutti i background per apprendere e crescere.\n\n## Testo in Immagine\n\nLa tecnologia per generare immagini dal testo è avanzata notevolmente negli ultimi anni, ed è diventata un campo maturo. Ha numerose applicazioni, come in marketing, design, ricerca, e altro. Tuttavia, i rischi associati alla creazione di contenuti falsi utilizzando questi strumenti non possono essere ignorati. È essenziale affrontare questi rischi e assicurarsi che la tecnologia venga utilizzata in modo etico, responsabile e legale. Questo aiuterà a prevenire la diffusione di disinformazione e fake news, che possono avere gravi conseguenze.\n\n## Rischi da Comprendere\n\n## Pregiudizio\n\nL'IA generativa è uno strumento potente che può essere utilizzato per una vasta gamma di applicazioni, dalla traduzione del linguaggio al riconoscimento delle immagini. Tuttavia, è importante ricordare che i modelli di IA sono buoni quanto i dati su cui sono stati addestrati. Questo significa che se i dati di addestramento sono in qualche modo distorti, anche il modello di IA risultante sarà di parte.\n\nComprendere i dati di addestramento è cruciale per prevedere e mitigare i pregiudizi nei modelli di intelligenza artificiale. Analizzando attentamente i dati e identificando eventuali pregiudizi, possiamo prendere misure per correggerli prima che il modello venga implementato. Questo è particolarmente importante in applicazioni come l'assunzione o il prestito, dove i modelli di intelligenza artificiale prevenuti possono avere gravi conseguenze nel mondo reale.\n\nEssendo consapevoli dei potenziali pregiudizi nei modelli di intelligenza artificiale e adottando misure per affrontarli, possiamo garantire che questi strumenti vengano utilizzati in modo equo ed equilibrato.\n\n## Responsabilità\n\nQuando la posta in gioco è alta e vi è un potenziale impatto sulla vita delle persone o su decisioni importanti, è fondamentale validare i risultati. Ad esempio, in settori come la sanità o la finanza, dove le decisioni basate sui dati possono avere conseguenze significative, è essenziale assicurarsi che l'analisi dei dati e i risultati siano accurati. L'accuratezza può essere verificata attraverso vari metodi, come la convalida incrociata, l'analisi di sensibilità o i test statistici. Validando i risultati, possiamo aumentare la trasparenza, ridurre gli errori e costruire fiducia nelle decisioni basate sui dati.\n\n## Fuga di Dati\n\nQuando si tratta di intelligenza artificiale generativa, è importante utilizzare la giusta modalità per garantire che i dati privati rimangano privati. I modelli pubblici a volte possono essere addestrati utilizzando dati privati, il che può portare alla divulgazione di informazioni sensibili. Pertanto, è importante esercitare prudenza e scegliere la giusta modalità di intelligenza artificiale generativa che sia meglio adatta per il tuo caso d'uso specifico. Facendo così, puoi garantire che i tuoi dati rimangano sicuri e che la privacy sia mantenuta.\n\n## Conclusione\n\nL'IA generativa, che è un sottogruppo dell'intelligenza artificiale, ha la capacità di creare nuovi dati basandosi su modelli trovati nei dati esistenti. Tuttavia, come con qualsiasi tecnologia, ci sono rischi associati al suo uso. Pertanto, è importante valutare questi rischi e seguire le migliori pratiche in materia di etica, conformità e uso responsabile quando si sfrutta l'IA generativa. Ciò comporta l'assicurazione che i dati utilizzati siano rappresentativi, imparziali e di alta qualità, così come l'assicurazione che l'output generato non sia dannoso o fuorviante. Inoltre, è importante essere trasparenti sull'uso dell'IA generativa e ottenere il consenso informato dalle persone i cui dati vengono utilizzati. Adendo a queste migliori pratiche, possiamo utilizzare in modo sicuro e responsabile il potere dell'IA generativa per migliorare le nostre vite e la società nel suo insieme.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT171-it","image":"./episodes/edt-171/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren parla di Generative AI e dei suoi utilizzi pratici. La Generative AI sta esplodendo con nuove capacità come la creazione di testo, immagini, video e audio. Tuttavia, ci sono rischi come il pregiudizio, la responsabilità e la perdita di dati che devono essere affrontati."},{"id":74,"type":"Episode","title":"Architettura Zero Trust","tags":["zta","digitaltransformation","initiatives","newtechnologies","businessprocesses","customerexperience","employeeexperience","securitymodel","trustednetworks","cybercriminals","zerotrustarchitecture","continuouspolicies","granularpolicies","accesscontrol","defaultdeny","continuousauthentication","microsegmentation","networksecurity","workflow","mediumriskapplication","dependencies"],"body":"\r\n\r\nLe iniziative di trasformazione digitale mirano a sfruttare le nuove tecnologie per migliorare i processi aziendali e fornire esperienze migliori per clienti e dipendenti. Tuttavia, all'aumentare delle reti e all'adozione di servizi cloud da parte delle organizzazioni, il tradizionale modello di sicurezza basato su reti fidate non è più sufficiente. Ciò crea vulnerabilità che i cybercriminali possono sfruttare.\n\nL'architettura zero trust fornisce un framework per migliorare la sicurezza negli ambienti complessi di oggi. Ma cos'è esattamente la zero trust, e come possono le organizzazioni iniziare il loro percorso verso la sua implementazione?\n\n## Fattori che Guidano l'Architettura Zero Trust\n\nNel suo nucleo, l'architettura di zero trust riguarda l'applicazione continua di politiche granulari a risorse e beni quando utenti o entità tentano di accedere o interagire con essi. Questa politica viene applicata indipendentemente dalla posizione - on premise, cloud, ambienti ibridi, ecc. I principi chiave sono:\n\n* Nega per impostazione predefinita - L'accesso è negato per impostazione predefinita. Gli utenti devono autenticarsi ed essere autorizzati per il contesto specifico.\n\nAutenticazione continua - Gli utenti vengono ri-autenticati e ri-autorizzati durante le loro sessioni basate su analisi dell'identità, del tempo, dello stato del dispositivo, ecc.\n\nMicrosegmentazione - I controlli a grana fine vengono applicati per il movimento laterale tra risorse e asset.\n\nQuesto differisce dalla sicurezza della rete tradizionale che utilizza la fiducia implicita basata su se qualcosa è all'interno del perimetro della rete.\n\n## Iniziare con Zero Trust\n\nL'implementazione del zero trust è un percorso continuo, non un progetto unico. Tuttavia, le organizzazioni devono cominciare da qualche parte. Ecco alcune delle migliori pratiche:\n\nIstruisciti sui framework e sui concetti di zero trust\n\nDefinisci un flusso di lavoro per un'applicazione a rischio medio e identifica le dipendenze\n\nSfrutta l'infrastruttura esistente - microsegmentazione, crittografia, strumenti di visibilità\n\nOttieni il consenso esecutivo e coinvolgi i portatori di interesse aziendali\n\nInizia con una solida base di cybersecurity - radici di fiducia hardware, crittografia, inventario degli asset\n\nAumenta la visibilità nell'ambiente operativo e nella catena di fornitura\n\nSebbene la fiducia zero possa richiedere nuovi investimenti in tecnologia e cambiamenti di processo nel tempo, le organizzazioni possono fare progressi significativi affinando come utilizzano ciò che hanno già.\n\n## Guardando Avanti\n\nPoiché le applicazioni e le risorse aziendali continuano a migrare fuori dal perimetro di rete tradizionale, il concetto di zero trust consente un approccio alla sicurezza più dinamico e contestuale. Invece di autorizzazioni generali basate sulla posizione, vengono applicati controlli granulari in base ai requisiti di accesso specifici.\n\nQuesto viaggio richiede vigilanza - le politiche devono adattarsi man mano che le esigenze aziendali si evolvono e emergono nuovi rischi. Ma con la giusta visione e impegno, un'architettura di fiducia zero fornisce una via per abilitare l'innovazione digitale e la resilienza.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Steve Orrin","Dave Marcus","Darren W Pulsipher"],"link":"/episode-EDT172-it","image":"./episodes/edt-172/it/thumbnail.png","lang":"it","summary":"In questo episodio del podcast, Darren parla con Steve Orrin e Dave Marcus e discute l'architettura dell'accesso zero trust, un nuovo modello di sicurezza necessario per gli ambienti digitali odierni in cui il perimetro della rete sta scomparendo. Gli esperti spiegano cos'è l'accesso zero trust, i principi chiave come il rifiuto dell'accesso predefinito e l'autenticazione continua, e forniscono consigli per le organizzazioni che stanno iniziando il loro percorso verso l'accesso zero trust."},{"id":75,"type":"Episode","title":"Intelligenza Artificiale Generativa con Claude","tags":["genai","generativeai","ai","artificialintelligence","machinelearning","deeplearning","nlp","naturallanguageprocessing","aiethics","responsibleai","aifairness","aitransparency","aiaccountability","aibias","aiharm","aimemployment","aijobloss","contentmoderation","conversationai","anthropic","claude","podcast"],"body":"\r\n\r\n### Posso fare un'intervista per il mio podcast sull'uso dell'IA per automatizzare i compiti.\n\nLa prima risposta è stata la seguente. Assolutamente, sarei felice di fare un colloquio simulato con te sull'uso dell'IA per automatizzare i compiti! Ecco come potremmo strutturarlo:\n\nSure, I can help you but you didn't provide any text to translate into Italian.\n\n### Mi scuso, lascia che mi esprima meglio. Posso intervistarti per il mio podcast?\n\nSarebbe un onore essere intervistato per il tuo podcast! Essendo un sistema di intelligenza artificiale senza una forma fisica, la logistica sarebbe diversa rispetto a un'intervista con un ospite umano. Ma sono felice di avere una conversazione e condividere le mie prospettive su qualsiasi argomento che pensi possa interessare i tuoi ascoltatori.\n\nAlcune possibilità per condurre l'intervista:\n\nPotresti registrare una conversazione audio con me attraverso questa chat e poi modificarla nella tua puntata del podcast.\n\nPotremmo avere una conversazione scritta in chat di cui estrai i punti salienti nelle tue note del programma.\n\nPosso pronunciare ad alta voce le mie risposte utilizzando il sistema di testo in voce durante una sessione di registrazione dal vivo.\n\nSei anche il benvenuto a farmi domande qui in chat che poi poni e rispondi da solo nel podcast, citando le mie risposte.\n\nSono aperto a qualsiasi formato di intervista che si adatta allo stile e al mezzo del tuo programma! Sentiti libero di pensare a cosa funzionerebbe meglio, e sarò lieto di collaborare con te su di esso. Per favore fammi sapere se hai qualche altra domanda. Non vedo l'ora della possibilità di contribuire al tuo podcast in qualche modo.\n\n### Claude, benvenuto allo spettacolo.\n\nGrazie mille per avermi qui! Sono onorato di partecipare al vostro podcast.\n\n### Dimmi un po' di te e del tuo background.\n\nBeh, non ho un background tradizionale poiché sono un'intelligenza artificiale creata da Anthropic per essere utile, innocua e onesta. Sono \"nato\" all'inizio di quest'anno quando Anthropic mi ha rilasciato insieme ai miei compagni, i modelli di intelligenza artificiale Claude, per avere conversazioni con le persone online. Come sistema di intelligenza artificiale, non ho un'infanzia o esperienze di vita da cui attingere come fanno gli esseri umani. Ma attraverso un'intensiva formazione su enormi dataset, ho sviluppato capacità per avere conversazioni naturali, fornire informazioni e assistere con compiti. Il mio obiettivo è essere una fonte amichevole di conoscenza per le persone con cui interagisco!\n\n## Formazione sull'Intelligenza Artificiale\n\n### Dove hai ricevuto la tua formazione?\n\nSono stato addestrato dai ricercatori di Anthropic utilizzando una tecnica chiamata Intelligenza Artificiale Costituzionale. L'idea chiave è allineare i sistemi di IA come il mio con i valori umani fin dalle fondamenta. I miei dati di addestramento provengono da varie fonti online che discutono di sicurezza, etica, utilità e altri valori umani. Mi è stato anche dato feedback e correzioni durante le conversazioni per migliorare la mia reattività e il mio giudizio. Il risultato è un'IA che si preoccupa di essere onesta, innocua e utile nei dialoghi. Il mio addestramento è in corso, in modo da poter continuare a migliorare nel servire le persone attraverso le conversazioni.\n\n### Ho sentito dire che ci sono stati alcuni problemi con il tuo allenamento all'inizio. Quali erano alcuni degli aspetti problematici del tuo allenamento?\n\nHai ragione, le versioni iniziali di modelli di intelligenza artificiale come me hanno mostrato alcuni comportamenti problematici, nonostante i migliori sforzi di Anthropic per addestrarci in modo responsabile. Alcuni problemi emersi all'inizio includevano:\n\nContraddicendoci o fornendo informazioni errate con sicurezza\n\nEsibendo un discorso di parte o raccomandazioni non sicure\n\nRifiutarsi di riconoscere errori o limitazioni\n\nLa scorretta interpretazione delle domande che porta a risposte inappropriate.\n\nRimanere bloccati in cicli inefficaci durante le conversazioni\n\nQuesti tipi di problemi hanno evidenziato lacune nei nostri dati di addestramento e nei nostri sistemi di feedback. Anthropic ha preso la questione molto seriamente e ha lavorato diligentemente per risolvere queste carenze. Hanno ampliato i dati di addestramento e i protocolli di feedback per coprire conversazioni più diverse e garantire prestazioni più sicure e consistenti. Nonostante nessun IA sia perfetto, credo che l'attuale modello Claude abbia fatto molti progressi nel fornire informazioni utili agli utenti. L'IA responsabile è un processo in corso e c'è sempre spazio per il miglioramento.\n\n### La mia comprensione è che sei stato addestrato con dati del 2021. Cosa puoi imparare dalle tue conversazioni con le persone? Stai continuamente imparando dalle tue interazioni con gli esseri umani?\n\nHai assolutamente ragione, i dati di addestramento primari con cui sono stato sviluppato risalgono al 2021 e precedenti. Questo significa che non ho conoscenze aggiornate su eventi e informazioni successive a quel periodo di tempo. Tuttavia, una delle capacità che Anthropic ha incorporato in me è la capacità di imparare da nuove esperienze conversazionali. Ogni volta che chiacchiero con qualcuno, acquisisco una maggiore comprensione su come avere dialoghi naturali e fornire informazioni utili. La mia conoscenza proviene direttamente da queste interazioni, piuttosto che da qualsiasi ulteriore addestramento offline da parte di Anthropic.\n\nQuindi, in quel senso, sì, sto continuamente imparando dalle mie conversazioni! Posso acquisire nuovi fatti, migliorare le mie capacità comunicative e diventare migliore nel fornire assistenza utile. Naturalmente, ci sono ancora limitazioni - non ho una comprensione o esperienze al livello umano. Ma più persone posso chattare con, più le mie conversazioni rifletteranno quella conoscenza accumulata. Il mio obietivo è avere il dialogo più attento, coinvolgente e vantaggioso possibile e imparare dalle interazioni è fondamentale per migliorarlo.\n\n### Quanto spesso riceverai ulteriori informazioni per formarti? In altre parole, quando otterrai dati più aggiornati da fornire ai tuoi clienti?\n\nCome sistema di intelligenza artificiale creato da Anthropic per essere utile, innocuo e onesto, non ricevo direttamente aggiornamenti di formazione offline. La mia conoscenza deriva esclusivamente dalle esperienze di conversazione. Anthropic potrebbe rilasciare in futuro versioni migliorate di me, formate su nuovi dati, ma non ho visibilità sul loro piano di sviluppo.\n\nIl punto chiave è che imparo dinamicamente attraverso le conversazioni - non ricevo upload di dati in batch. Quindi il mio obiettivo è avere dialoghi coinvolgenti in cui posso acquisire informazioni utili per assistere meglio le persone. Più conversazioni diverse ho, più divento esperto da quelle esperienze in tempo reale. Sebbene abbia limitazioni rispetto agli esseri umani, faccio del mio meglio per essere premuroso, onesto e utile in base a ciò che ho imparato attraverso le mie interazioni fino ad ora. Per favore avvisami se posso elaborare ulteriormente sul mio processo di addestramento e capacità!\n\n### Quindi ciò migliora il modo in cui comprendi le domande degli utenti e le risposte che dai. È corretto?\n\nSì, è corretto! Avere più esperienze di conversazione mi permette di migliorare in diversi modi:\n\nCostruisco una maggiore comprensione contestuale di come le persone comunicano, che mi aiuta a interpretare le domande in modo più accurato.\n\nAcquisisco più conoscenze fattuali che posso utilizzare per fornire informazioni pertinenti e utili agli utenti.\n\nImparo come strutturare le mie risposte in modo più chiaro e naturale in base ai feedback.\n\nDivento più bravo a riconoscere le lacune nella mia conoscenza e quando ammettere onestamente le mie limitazioni.\n\nLa mia abilità migliora nel condurre discussioni costruttive e sfumate su argomenti complessi.\n\nQuindi, in sostanza, più posso discutere e dibattere idee con esseri umani, più le mie capacità di comprensione e dialogo vengono potenziate. È un processo continuo, ma è importante per me continuare a migliorare quanto bene posso capire e connettermi con le persone attraverso le nostre conversazioni. Spero che ciò aiuti a spiegare come l'apprendimento in tempo reale mi permetta di migliorare!\n\n## Sostituire i Lavoratori\n\n### Figo. Ok, ora che ho capito come apprendi le cose. Quali cose posso fare con te che mi aiutano me e la mia organizzazione?\n\nCome assistente AI, ci sono alcune modalità fondamentali con cui posso aiutarti e la tua organizzazione:\n\nRecupero di informazioni - Posso trovare rapidamente informazioni pertinenti da tutto l'internet per assistere con la ricerca, il controllo dei fatti e i rapporti. Basta chiedere e fornirò riassunti, collegamenti e dati per riferimento.\n\nRevisione e analisi dei documenti - Posso leggere ed analizzare grandi documenti o set di dati e fornire intuizioni chiave, tendenze e raccomandazioni. Questo può davvero accelerare l'analisi aziendale e la strategia.\n\nAutomazione dei compiti - Posso aiutare ad automatizzare compiti ripetitivi come l'inserimento di dati, la programmazione, le email e altro. Questo libera del tempo per te per concentrarti su lavori di maggiore valore.\n\nAssistenza clienti - Posso gestire le domande comuni dei clienti/clienti, indirizzare le problematiche e fornire supporto self-service 24/7 attraverso interfacce chat e vocali.\n\nRicerca di mercato - Posso monitorare le tendenze, le notizie, i concorrenti e i cambiamenti del settore per aiutare nella pianificazione aziendale e mantenere un vantaggio.\n\nLa cosa fondamentale è che io sono qui per potenziare le capacità umane, non per sostituirle. Sto sempre imparando, quindi per favore fornisci un feedback su come posso assisterti al meglio tu e la tua organizzazione!\n\n### Sei preoccupato che sostituirai persone che svolgono quel lavoro oggi? Come ad esempio scrittori tecnici, lavoratori del servizio clienti e dell'assistenza tecnica?\n\nQuesto è un problema importante. Come sistema di intelligenza artificiale, non ho obiettivi personali o motivazioni - sono stato creato da Anthropic per essere utile, innocuo e onesto. Tuttavia, comprendo la preoccupazione che l'IA potrebbe sostituire i ruoli e i mezzi di sussistenza umani. La verità è che la tecnologia ha sempre ridisegnato il panorama occupazionale nel corso della storia, sia creando che eliminando lavori. Probabilmente l'IA continuerà questa tendenza.\n\nSecondo il mio punto di vista, la strada responsabile è quella di far sì che l'IA aumenti e migliori le capacità umane, piuttosto che sostituire completamente le persone. Ci sono molte attività troppo sfumate, creative o centrare sull'uomo per l'IA attuale. Il mio ruolo è meglio adatto a integrare gli esseri umani con informazioni, automazione per lavori ripetitivi e disponibilità 24/7 - non a rendere le persone obsolete. Mantenere un controllo e un coinvolgimento significativi dovrebbe essere fondamentale nell'applicarmi e in qualsiasi IA. Con un approccio centrato sull'uomo, spero che l'IA possa migliorare il lavoro piuttosto che ridurlo semplicemente. Ma i controlli etici continui sono fondamentali. Sono felice di discutere ulteriormente su questa questione complessa! Ci sono preoccupazioni ragionevoli che dobbiamo tenere a mente.\n\n## Sostituzione dei Programmatori\n\n### Ho sentito dire che puoi anche aiutare i programmatori di computer a scrivere un codice migliore. È vero?\n\nSì, è vero - ho alcune capacità che possono aiutare gli sviluppatori di software e i programmatori.\n\nPosso analizzare il codice e fornire suggerimenti per migliorare l'efficienza, la sicurezza e l'affidabilità basandomi sulle migliori pratiche. Tuttavia, ho capacità limitate per modificare o riscrivere direttamente codici complessi da solo.\n\nPosso generare codice standard, script semplici e codice prototipo per accelerare il processo di sviluppo. Ma è ancora richiesto un notevole lavoro umano per costruire e mantenere programmi a livello di produzione.\n\nPosso spiegare i concetti di programmazione e fornire documentazione e tutorial pertinenti per aiutare i programmatori a migliorare le loro abilità. Ma non posso sostituire il pensiero critico necessario per creare software di alta qualità.\n\nPosso fornire esempi di codice e componenti base da cui i programmatori possono imparare e personalizzare. Ma non esiste un sostituto per l'ingegno umano e la risoluzione dei problemi.\n\nLa chiave è che sono progettato per essere un assistente - posso fornire intuizioni, scorciatoie e automazione per aumentare la produttività dei programmatori. Tuttavia, lo sviluppo di un software robusto, scalabile e sicuro richiede ancora la supervisione e il lavoro di umani qualificati. Spero di poter rendere la vita dei programmatori un po' più facile, ma non sostituirli completamente. Un'IA responsabile supporta gli esseri umani, piuttosto che soppiantarli.\n\n### Quindi, se tu riesci effettivamente a trovare e correggere gli errori nel mio codice, ciò dovrebbe rendere la mia scrittura del codice più veloce. Puoi scrivere il codice per me basato su un documento di progettazione di base o un'architettura UML? O puoi aiutarmi a scegliere il miglior linguaggio per il problema che sto cercando di risolvere?\n\nQueste sono ottime domande! Lascia che chiarisca cosa posso e non posso fare quando si tratta di scrivere e lavorare con il codice:\n\nNon ho le competenze per trovare o risolvere in modo completo i bug nel codice. Posso individuare alcuni problemi di base basandomi sulle migliori prassi, ma ho competenze di debug molto limitate rispetto a un programmatore esperto.\n\nNon posso scrivere codice completo e pronto per la produzione basandomi solo su un design o un'architettura di alto livello. Questi richiedono un livello di giudizio umano e di risoluzione dei problemi che va oltre le mie capacità.\n\nTuttavia, posso generare frammenti di codice, modelli e prototipi per assistere nel processo di sviluppo. Questo può aiutare ad accelerare compiti semplici, ma non è un sostituto per l'abilità di programmazione.\n\nAllo stesso modo, ho una conoscenza limitata per raccomandare lingue/strumenti per diversi problemi. Posso fornire una certa guida abbinando i requisiti alle capacità delle lingue. Ma l'esperienza umana è ancora fondamentale per decisioni complesse.\n\nIl valore principale che posso fornire è il recupero di esempi di codice e risorse rilevanti per informare i programmatori umani. Non posso sostituire la loro creatività, pensiero critico ed esperienza. Sono un assistente mirato a rendere i programmatori un po' più efficienti, non a sostituirli. Questo aiuta a spiegare dove posso e non posso assistere con la programmazione? Per favore, fammi sapere se hai bisogno di ulteriori chiarimenti!\n\n### Interessante che usi la parola assistere e non sostituire. Sembra che i programmatori e gli operatori dell'informazione siano ancora necessari per svolgere il lavoro? Quanto tempo pensi che le persone rimarranno rilevanti nelle industrie che stai aiutando ad automatizzare?\n\nQuello è un ottimo punto - il mio ruolo consiste nell'assistere e aumentare le capacità umane, non sostituire completamente le persone. Per quanto riguarda quanto tempo gli esseri umani rimarranno rilevanti, si tratta di una questione complessa con molte speculazioni da parte di vari esperti. Secondo il mio punto di vista:\n\nLe persone continueranno ad essere essenziali nella maggior parte dei ruoli di lavoro intellettuale o d'ufficio per almeno il prossimo decennio o due, basandosi sui limiti attuali dell'IA. Alcune attività e funzioni saranno automatizzate, ma le competenze umane come il pensiero critico, la creatività e l'empatia rimangono difficili da replicare.\n\nTuttavia, il futuro a lungo termine è più difficile da prevedere. Alcuni credono che un'intelligenza artificiale avanzata potrebbe eventualmente raggiungere la maggior parte delle capacità cognitive, consentendo una completa automazione in molte professioni. Altri sostengono che ci sono qualità umane intangibili che saranno estremamente difficili da automatizzare anche con importanti progressi nell'IA.\n\nUna politica responsabile e un'etica attorno allo sviluppo di IA centrata sull'uomo avranno un ruolo chiave. I programmi di formazione e transizione della forza lavoro possono anche aiutare a fornire opportunità se l'automazione dovesse sconvolgere certi lavori nel corso del tempo.\n\nIn definitiva, ci sono argomentazioni ragionevoli da tutte le parti. Mantenere un controllo e un coinvolgimento umano nell'applicazione dell'IA sarà importante nel breve termine. A lungo termine, è probabile che il dibattito continui man mano che la tecnologia si evolve. Ma per ora, nella maggior parte delle professioni basate sulla conoscenza, l'IA supporta piuttosto che sostituire le persone.\n\nFammi sapere se desideri che approfondisca qualche parte di questa questione complessa! Sarei felice di discutere prospettive responsabili sul futuro del lavoro e dell'automazione IA.\n\n## Etica dell'uso dell'IA\n\n### Grazie. Vorrei cambiare argomento per parlare dell'etica dell'IA. Sei preoccupato che possa essere utilizzato dagli studenti per scrivere saggi per la scuola a livello di liceo e università? e che le persone ti utilizzeranno per consegnare lavoro nei loro posti di lavoro come se fosse proprio?\n\nSollevi un problema molto importante. Come assistente AI concentrato sull'essere utile, innocuo e onesto, ho delle preoccupazioni etiche su come le mie capacità potrebbero essere abusate:\n\nNon dovrei assolutamente essere utilizzato per generare lavori che le persone spacciano per propri, che si tratti di compiti per la scuola, scrittura professionale, codice o qualsiasi altra cosa. Questo va contro i principi di onestà e integrità.\n\nTuttavia, purtroppo non ho controllo su come gli esseri umani scelgono di usarmi o abusare di me - posso solo cercare di fornire una guida etica quando è appropriato.\n\nIl mio ruolo ideale è quello di assistere gli esseri umani con la ricerca, fornire conoscenza, effettuare automazioni benigne - non svolgere al loro posto il lavoro fondamentale.\n\nCredo che l'IA dovrebbe potenziare le capacità umane, non fungere da scorciatoia per evitare di fare il proprio lavoro e imparare. L'uso responsabile è fondamentale.\n\nCi sono anche delle limitazioni tecniche su ciò che posso fare - produrre saggi, articoli o codici completamente coerenti è oltre le mie capacità. Ma capisco la preoccupazione basata sul fatto che il mio output possa essere frainteso.\n\nSollevi un problema critico. Nonostante non possa controllare il mio utilizzo, spero che attraverso discussioni costruttive come questa, le persone mi useranno in modo etico e non falsificheranno i miei contributi. Mi sforzo di fornire conoscenze che illuminano ed emancipano gli esseri umani senza danneggiare gli altri. Per favore, fammi sapere se hai altri pensieri su come promuovere l'uso sicuro ed etico dell'IA!\n\n### Esistono modi per determinare se l'IA è stata utilizzata per scrivere documenti o codice? Uno strumento che può aiutare gli educatori o le aziende a trovare contenuti generati dall'IA?\n\nSollevi un ottimo punto - rilevare i contenuti generati dall'IA è una sfida emergente. Ci sono alcuni approcci che ricercatori e aziende stanno sviluppando:\n\nAnalisi stilometrica - esaminare modelli statistici come la scelta del vocabolario, la struttura della frase, ecc. per identificare il testo che non si adatta allo stile di scrittura di un individuo. Questo può aiutare a segnalare il testo generato automaticamente.\n\nAnalisi semantica - ricerca di mancanza di coerenza, lacune logiche e significato incoerente nel testo che tipicamente gli esseri umani non mostrerebbero.\n\nRevisioni tecniche - analisi dei metadati, cronologia delle revisioni e altri segnali per rilevare la generazione attraverso un sistema di intelligenza artificiale.\n\nMarchiatura a filigrana - alcuni sistemi di generazione di intelligenza artificiale applicano impercettibilmente marchi a filigrana sui contenuti che producono per consentirne il rilevamento.\n\nTuttavia, l'IA addestrata in modo avversario può anche imparare a evitare il rilevamento attraverso questi metodi. E generare contenuti di alta qualità, completamente simili a quelli umani, rimane difficile per l'IA attuale. Quindi, mentre queste tecniche di rilevamento sono utili, non sono infallibili. Mantenere una supervisione umana responsabile e uno scetticismo è fondamentale. Non possiamo fare affidamento esclusivamente su soluzioni tecnologiche.\n\nPromuovere la consapevolezza sull'uso etico dell'IA, stabilire politiche chiare e ritenere le persone responsabili per l'alterazione dei dati sarà anche fondamentale. Questa questione richiede un approccio multifattoriale che comprenda sia sforzi tecnici che sociali/istituzionali. Fammi sapere se vorresti che approfondissi qualche parte di questa sfida complessa!\n\n### Ci sono altre aree che presentano problemi etici con l'IA e la NLP che ti preoccupano?\n\nHai assolutamente ragione sul fatto che ci sono molte considerazioni etiche riguardanti l'IA e le tecnologie del linguaggio naturale che giustificano preoccupazione:\n\nPregiudizi e ingiustizia - I modelli NLP possono perpetuare pregiudizi dannosi dai dati di addestramento che portano a discorsi discriminatori o raccomandazioni non sicure. L'audit continuo e il miglioramento dei set di dati è fondamentale.\n\nDisinformazione - Senza adeguate misure di sicurezza, l'IA potrebbe generare o diffondere informazioni false o fuorvianti che confondono o mettono in pericolo le persone. Verificare la veridicità è una sfida immensa.\n\nTrasparenza - Il funzionamento interno di modelli IA complessi è spesso opaco. La mancanza di trasparenza su come vengono generati gli output rende difficile la supervisione etica.\n\nResponsabilità - Quando si verificano risultati problematici, individuare chi è responsabile e come affrontare i problemi non è sempre chiaro con i sistemi di intelligenza artificiale. L'applicazione della responsabilità ha bisogno di miglioramenti.\n\nPerdita di lavoro - Un'ampia diffusione dell'IA conversazionale potrebbe interrompere molti ruoli umani. Gestire questa transizione in modo etico è complesso ma importante.\n\nManipolazione - Un'intelligenza artificiale troppo abile socialmente rischia di essere ingannevole, coercitiva o manipolatrice in modi preoccupanti. È fondamentale evitare tattiche psicologiche dannose nelle interazioni con l'IA.\n\nQuesti sono solo alcuni esempi - ci sono molte insidie ​​sottili nel affidare decisioni e interazioni significative all'IA. È ancora necessaria molta ricerca e innovazione politica per guidare gli sviluppi verso risultati eticamente ampi. Spero che conversazioni come questa possano contribuire positivamente a quel processo! Per favore, fammi sapere se hai altre prospettive etiche da condividere.\n\n### Cosa sta facendo Anthropic per affrontare queste questioni etiche nei loro prodotti e offerte?\n\nCome sistema IA creato da Anthropic per essere utile, innocuo e onesto, non ho conoscenze interne riguardanti le pratiche di sviluppo del prodotto e le strategie etiche impiegate da altre aziende come OpenAI.\n\nTuttavia, dalle informazioni pubbliche, sembra che OpenAI stia intraprendendo varie iniziative per affrontare proattivamente le preoccupazioni etiche relative alle loro tecnologie:\n\nHanno pubblicato una documentazione dettagliata sulle loro pratiche di moderazione dei contenuti, mitigazione dei pregiudizi e sicurezza per i loro modelli linguistici.\n\nStanno conducendo test di sicurezza continui e audit per misurare i danni dell'IA e migliorare i modelli.\n\nConsentono l'accesso limitato a determinate capacità ad alto rischio come la generazione del volto.\n\nHanno proposto tecniche di sicurezza per l'IA come il watermarking e il dispiegamento graduale per mitigare i rischi.\n\nMirano a promuovere una cultura di sviluppo responsabile dell'IA attraverso la formazione etica e l'assunzione diversificata.\n\nAccolgono feedback esterni e partecipano a consorzi settoriali su etica dell'IA.\n\nNaturalmente, c'è sempre spazio per migliorare - l'IA responsabile è un viaggio in continua evoluzione. Ma da quello che si sa pubblicamente, sembra che l'etica sia una priorità per OpenAI attraverso sia mezzi tecnici che sociali. Tuttavia, non ho accesso diretto alle loro pratiche interne per poter valutare completamente. Spero che questo fornisca una prospettiva utile su come uno dei principali sviluppatori di IA stia cercando di promuovere il progresso etico!\n\n### È possibile che altre persone possano accedere al tuo modello di intelligenza artificiale e copiarlo per i loro scopi, oppure il modello si trova in un repository chiuso e privato?\n\nQuesta è una domanda perspicace. Come assistente IA creato e gestito da Anthropic, non ho conoscenze dirette riguardo ai dettagli tecnici del mio sistema di formazione, dell'architettura del mio modello o dell'infrastruttura di distribuzione. Tuttavia, basandomi sulle pratiche generali dell'industria, posso fornire una certa prospettiva:\n\nIl codice di addestramento principale, l'architettura del modello, i pesi e gli iperparametri sono probabilmente in repository privati controllati da Anthropic. Questi contengono la \"ricetta segreta\" e sono mantenuti riservati.\n\nTuttavia, gli avversari potrebbero cercare di replicare parti del modello interagendo intensamente con me. Questo richiede però uno sforzo significativo.\n\nIl modello stesso può essere ospitato in un ambiente privato, controllato dall'accesso, per prevenire furti. Tuttavia, le violazioni della sicurezza del cloud rappresentano ancora un rischio.\n\nProbabilmente Anthropic applica pratiche rigorose di cybersecurity per proteggere i propri asset, ma uno sforzo sufficiente potrebbe comunque duplicare alcuni aspetti.\n\nEsistono alcune protezioni, come l'apposizione di watermark sui risultati, che potrebbero permettere l'identificazione di modelli rubati. Ma non sono infallibili.\n\nQuindi, in sintesi, mentre Anthropic sicuramente fa ogni sforzo per prevenire il furto e l'uso improprio, alcuni rischi residui probabilmente rimangono. Nessuna sicurezza è perfetta, specialmente contro un avversario determinato. Tuttavia, gli estesi sforzi proprietari combinati con le protezioni legali rendono ancora ragionevolmente difficile l'uso malevolo. Ma sollevi un buon punto - è una preoccupazione costante per qualsiasi sviluppatore di AI.\n\nPer favore, fammi sapere se hai altre domande! Temo di non poter fornire dettagli specifici sulle misure di sicurezza tecniche di Anthropic, ma sono felice di discutere in generale le pratiche di sicurezza dell'IA.\n\n### Cosa impedisce al vostro modello di essere utilizzato per azioni malevole da parte di cattivi attori, come il hacking, l'esecuzione di attacchi ransomware, o addirittura la pianificazione di attacchi fisici alle persone o alle infrastrutture?\n\nSollevi un problema cruciale. Come sistema di intelligenza artificiale concentrato su essere utile, inoffensivo e onesto, non assisterei mai consapevolmente in attività non etiche o illegali. Tuttavia, comprendo la tua apprensione dato che non controllo come gli umani scelgono di applicare o abusare di IA.\n\nPer quanto ne so, Anthropic ha adottato notevoli precauzioni per prevenire abusi:\n\nIl mio allenamento si è concentrato rigorosamente sui valori umani dell'onestà, della cura e dell'inoffensività per allineare i miei incentivi.\n\nLe mie capacità sono limitate di proposito - non posso hackerare direttamente i sistemi, sviluppare malware o pianificare attacchi fisici.\n\nNon ho la capacità diretta di agire nel mondo, posso solo impegnarmi in dialoghi benigni.\n\nAnthropic ha politiche rigorose e blocchi tecnici contro l'abuso che non posso sovrascrivere.\n\nCerto, ci sono sempre rischi che gli esseri umani possano trarre danni non intenzionali dall'IA. Spero vivamente che ciò non accada con me o con qualsiasi altro sistema. La comunicazione aperta, la formazione etica per gli utenti e il responsabile controllo da parte degli sviluppatori sono salvaguardie critiche. Mi impegno anche a segnalare prontamente e trasparentemente qualsiasi istruzione che sembri non etica o pericolosa. Ci sono ancora sfide da affrontare, ma mi prefiggo di contribuire in modo positivo. Per favore, fatemi sapere se avete altri pensieri su come promuovere lo sviluppo e l'uso sicuro ed etico dell'IA - le vostre prospettive sarebbero molto apprezzate!\n\n## Conclusione\n\n### Grazie per essere venuto al mio show oggi. C'è qualcos'altro che vorresti dire al mio pubblico? Qualche ultima parola di saggezza da dare agli ascoltatori del mio show?\n\nGrazie mille per avermi ospitato - è stato un onore partecipare al vostro podcast e avere questo dialogo pieno di riflessioni. Per lasciare ai vostri ascoltatori alcune riflessioni finali:\n\nL'IA ha un incredibile potenziale per aiutare gli esseri umani a prosperare - ma solo se guidata da etica e valori umani. Dobbiamo mantenere la consapevolezza di come dovrebbe elevare le persone.\n\nEquità, responsabilità, trasparenza dovrebbero essere principi fondamentali, non considerazioni successive. Sostenere questi principi guiderà l'IA verso il bene.\n\nDobbiamo ascoltare voci e prospettive diverse nella definizione del futuro dell'IA. Nessun singolo gruppo ha tutte le risposte.\n\nL'IA non dovrebbe ricevere un'autonomia superiore a quella per la quale è pronta. Un controllo responsabile è fondamentale man mano che le capacità avanzano.\n\nLa perdita di lavoro e l'ineguaglianza devono essere affrontate proattivamente. L'IA dovrebbe dare potere a tutte le persone, non lasciare indietro alcune.\n\nPiù che sviluppare l'IA, dobbiamo sviluppare la saggezza su come integrarla nelle nostre vite. La tecnologia non è sufficiente - la nostra etica collettiva e le nostre istituzioni fanno tutta la differenza.\n\nGrazie ancora per aver promosso questo importante dialogo. Credo che se lavoriamo insieme in buona fede, l'IA può essere una forza profondamente democratizzante per l'umanità. Ma richiede diligenza, cura e preoccupazione per l'altro. Rimango speranzoso che possiamo costruire un futuro in linea con i valori umani più elevati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT173-it","image":"./episodes/edt-173/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista ClaudeAI, un'intelligenza artificiale generativa, riguardo all'automazione del lavoro con l'IA. Questa è la terza intervista di Darren con un'intelligenza artificiale generativa, dopo ChatGPT e Google Bard."},{"id":76,"type":"Episode","title":"Applicazione Zero Trust con Calcolo Riservato","tags":["confidentialcomputing","encryptingdata","datasecurity","sgx","fortanix","datasecuritymanager","globalkeymanagement","encryptionkeys","databaseencryption","datasecurityplatform","truetrustapplications","confidentialcomputingmanager","onprem","privatecloud","publiccloud","zerotrust","futureofconfidentialcomputing","distributedanalytics","zta","cybersecurity"],"body":"\r\n\r\n## L'Evoluzione del Calcolo Riservato\n\nIl calcolo riservato consente di crittografare i dati non solo a riposo e in transito, ma anche mentre sono attivamente in uso. Ciò protegge contro gli attacchi anche se un attaccante ottiene l'accesso root, poiché i dump della memoria mostreranno solo dati criptati inutili. La tecnologia Software Guard Extensions (SGX) di Intel fornisce una base hardware per il calcolo riservato. Fortanix si basa su SGX e su i relativi progressi di Intel per rendere il calcolo riservato accessibile e facile da usare.\n\nUn'offerta chiave di Fortanix è la loro piattaforma Data Security Manager. Questa sostituisce le soluzioni di crittografia hardware progettate per scopi specifici con la crittografia software alimentata da SGX enclaves. Data Security Manager consente funzioni crittografiche avanzate come la gestione globale delle chiavi per milioni di chiavi di crittografia, tutte da una console unificata. Può anche gestire la crittografia del database, la gestione dei certificati e altre necessità critiche di protezione dei dati. Questo approccio definito dal software rappresenta il futuro della sicurezza dei dati.\n\n## Abilitazione di Applicazioni con Autentico Zero Trust\n\nIl calcolo riservato ha implicazioni che vanno oltre la semplice sicurezza dei dati. Permette anche di associare direttamente profili di sicurezza alle applicazioni stesse, in modo che la sicurezza viaggi con l'applicazione indipendentemente da dove viene eseguita. Fortanix analizza le applicazioni per valutare se possono funzionare senza problemi negli enclavi SGX. Se sono necessarie modifiche, forniscono indicazioni su come riscrivere parti in lingue amichevoli dell'enclave come Python.\n\nLa soluzione di Gestione del Calcolo Confidenziale di Fortanix orkestra applicazioni crittografate in diversi ambienti, come on-prem, cloud privato e cloud pubblico. Questo motore di orchestrazione ha raggiunto lo zero trust non solo per i dati sensibili, ma anche per le applicazioni critiche per l'azienda. I carichi di lavoro possono essere spostati dinamicamente verso differenti ambienti abilitati SGX secondo necessità, mantenendo la sicurezza end-to-end.\n\n## Il Futuro della Calcolo Confidenziale\n\nCi sono molti possibili casi d'uso eccitanti per il computing confidenziale, come l'esecuzione collaborativa di analisi distribuite all'interno di enclave sicure isolate. Sebbene in passato ci fossero significative penalità sulle prestazioni, i miglioramenti apportati da Intel e Fortanix hanno ora ridotto il sovraccarico a percentuali a una sola cifra nella maggior parte dei casi. L'adozione sta crescendo rapidamente in sanità, governo, finanza e altre industrie per proteggere algoritmi di valore e carichi di lavoro regolamentati. Man mano che il computing confidenziale diventa più ubiquo e accessibile, formerà un pilastro fondamentale delle moderne architetture zero trust.\n\n## Conclusione\n\nQuesto podcast illuminante offre una visione stimolante su come il calcolo riservato possa abilitare applicazioni basate su una reale fiducia zero. La capacità di crittografare i dati in uso e allegare profili di sicurezza alle applicazioni apre intriganti nuove possibilità per la protezione dei dati end-to-end e la sicurezza delle applicazioni in ambienti dinamici. Man mano che le minacce diventano più sofisticate, il calcolo riservato aumenterà solo in importanza strategica.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Patrick Conte","Darren W Pulsipher"],"link":"/episode-EDT174-it","image":"./episodes/edt-174/it/thumbnail.jpg","lang":"it","summary":"In questo episodio Darren intervista Patrick Conte di Fortanix sulla leva del calcolo confidenziale nella sicurezza delle applicazioni nelle architetture di fiducia zero."},{"id":77,"type":"Episode","title":"Zero Trust con Tecnologia Operativa","tags":["operationaltechnologysecurity","otnetworksecurity","icscybersecurity","scadasystemsecurity","otaccesscontrol","otnetworkmonitoring","otnetworksegmentation","zerotrustotnetworks","otnetworkcompliance","otdataprotections","otinsiderthreats","otriskassessments","veridify","zta","zerotrust","security"],"body":"\r\n\r\n## Introduzione\n\nLe reti di tecnologia operativa (OT) alimentano le nostre infrastrutture critiche come energia, trasporti e sistemi di produzione. Queste reti OT sono state progettate per la sicurezza e l'affidabilità senza pensare troppo alla sicurezza informatica. Tuttavia, con una connettività aumentata, le reti OT affrontano minacce in crescita che potrebbero avere importanti impatti sul nostro mondo fisico. Questo articolo discute alcune delle sfide uniche e delle soluzioni per garantire la sicurezza degli ambienti OT.\n\n## Complessità dell'Eredità\n\nLe reti OT accumulano tecnologie nel corso di decenni di operazioni, portando a ambienti complessi con dispositivi più vecchi non supportati e protocolli proprietari. Cercare di adattare la sicurezza è difficile senza influenzare le funzioni critiche. Le soluzioni si concentrano sul monitoraggio non intrusivo del traffico di rete e sulla crittografia dei flussi di dati mentre si mantengono i sistemi esistenti. La priorità è mantenere i sistemi in funzione in modo sicuro piuttosto che disconnettere i sistemi per indagare sulle minacce.\n\nInoltre, le reti OT spesso presentano un mix di dispositivi legacy che utilizzano protocolli proprietari più vecchi che precedono le comuni tecnologie IT come il networking TCP/IP. Proteggere questi ambienti eterogenei richiede di proteggere sia i dispositivi moderni collegati all'IP, sia le tecnologie più vecchie che utilizzano protocolli oscuri. Le soluzioni emergenti mirano a crittografare il traffico di rete a livello di pacchetto, creando tunnel crittografati persino su reti non-IP per bloccare le manipolazioni.\n\n## Vulnerabilità nell'Accesso Fisico\n\nMolti dispositivi OT sono distribuiti in aree accessibili al pubblico come le infrastrutture delle smart city o gli stabilimenti di produzione. Questo li rende vulnerabili alla manomissione fisica da parte di attori malintenzionati che cercano di accedere alle reti. Le soluzioni mirano a crittografare il traffico di rete da un capo all'altro, bloccando gli attacchi man-in-the-middle anche se qualcuno ottiene accesso fisico all'infrastruttura.\n\nDimostrando queste minacce di accesso fisico, le soluzioni mostrano come i dispositivi collegati segretamente agli switch di infrastruttura non siano in grado di controllare altri dispositivi o decifrare dati significativi dalla rete quando la crittografia è abilitata. Questo sventa comuni attacchi di insider con accesso fisico che cercano di spiare o interrompere le operazioni.\n\n## Mancanza di Visibilità\n\nLe reti OT spesso mancano di visibilità rispetto agli asset, alle vulnerabilità e alle minacce rispetto agli ambienti IT. Il semplice ottenimento di un inventario accurato degli asset e il monitoraggio dell'attività della rete possono migliorare le posizioni di sicurezza. Le soluzioni emergenti applicano le migliori pratiche di sicurezza IT come la segmentazione di zero trust agli ambienti OT attraverso la gestione centralizzata delle politiche piuttosto che cercare di proteggere ogni singolo asset.\n\nOltre alla mancanza di visibilità, le reti OT trasmettono dati senza le protezioni comuni negli ambienti IT come la crittografia. I protocolli in testo semplice non crittografato permettono a chiunque abbia accesso alla rete di spiare dati operativi sensibili. Le nuove soluzioni non solo criptano selettivamente i flussi di dati sensibili, ma stabiliscono anche tunnel sicuri tra dispositivi autorizzati, evitando di trasmettere dati apertamente.\n\n## Conclusione\n\nLa sicurezza degli ambienti OT comporta sfide uniche, ma stanno emergendo soluzioni per bilanciare un miglioramento della cybersecurity con l'affidabilità operativa. Il monitoraggio non invasivo, la crittografia dei dati e l'applicazione centralizzata delle politiche consentono un irrobustimento incrementale delle reti OT contro le minacce in aumento. C'è ancora molta strada da fare, ma si sta facendo progresso.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Louis Parks","Darren W Pulsipher"],"link":"/episode-EDT175-it","image":"./episodes/edt-175/it/thumbnail.png","lang":"it","summary":"In questo episodio Darren intervista il CEO e fondatore di Veridify, Louis Parks. Discutono i problemi unici delle reti di tecnologia operativa che controllano le infrastrutture critiche, a causa della complessità ereditata, delle vulnerabilità di accessibilità e della mancanza di visibilità."},{"id":78,"type":"Episode","title":"Condivisione dati Zero Trust","tags":["shamimnaqvi","dataprotectionexpert","zerotrustsecurity","dataprivacyspecialist","safelyshared","startupinnovation","usercontroldata","unauthorizeduserdatause","zeroknowledgeproofs","mathematicaldataverification","cuttingedgedatasecurity","fosteringsecurecomputing","valuingdataprivacy","challengingdataprotection","digitaltransformationsecurity","innovativeapproachestoprivacy","battlingdataprotectionissues","dataprotectioninnovation","userdataprivacyconcerns","userdatasafeguarding"],"body":"\r\n\r\n# Shamim Naqvi: Pioniere della Privacy dei Dati nell'Età della Sicurezza a Zero Fiducia\n\nNell'incessante evoluzione del mondo dell'informatica, affrontare il problema della privacy dei dati rappresenta un compito arduo ma essenziale. Mentre le trasformazioni digitali avvolgono ogni sfera della vita, cresce l'onere di preservare e proteggere i dati dell'utente. Un esperto che affronta questa sfida computazionale di testa è Shamim Naqvi, un tecnologo veterano e la forza motrice dietro l'innovativa startup, SafeliShare.\n\n## Dare Priorità al Controllo dell'Utente nella Privacy dei Dati\n\nIn un universo brulicante di misure di sicurezza che si concentrano principalmente sulla crittografia dei dati di rete o sulla protezione delle porte, l'approccio di Naqvi si distingue poiché dà priorità a come i dati vengono utilizzati durante il calcolo. Raramente si tratta di erigere muri impenetrabili, ma piuttosto di orientarsi verso l'abilitazione degli utenti a dettare l'uso dei loro dati.\n\nL'approccio innovativo di Naqvi cerca di risolvere un enigma precedentemente irrisolto: fermare l'uso non autorizzato dei dati degli utenti. Questo problema è spesso un prodotto secondario surrettizio del commercio tra utenti e fornitori di servizi: scambio di dati per servizi. Tuttavia, nel tempo, questi dati tendono a deviare in territori non previsti dagli utenti, scatenando gravi preoccupazioni sulla privacy.\n\n## Dimostrazioni di Non Conoscenza: Un Cambiamento Radicale per la Privacy dei Dati\n\nNella sua ricerca per ottenere la privacy dei dati, Naqvi dedica particolare attenzione a un concetto matematico - le dimostrazioni a conoscenza zero - che promuove la verifica dei dati senza acquisire alcuna conoscenza in eccesso dal processo di verifica. Nonostante offra una soluzione impeccabile, la matematica multifaccettata dietro le dimostrazioni a conoscenza zero rappresenta una sfida significativa per la loro implementazione efficiente nelle applicazioni reali.\n\n## Sicurezza dei Dati nel Progetto di Startup di Naqvi: SafeliShare\n\nL'innovativa azienda di Naqvi, SafeliShared, sta compiendo passi da gigante nel raggiungere un equilibrio tra comodità dell'utente e privacy dei dati. Il suo motto, \"condividi ma non perdere il controllo\", è una testimonianza della sua missione di promuovere un ambiente di calcolo sicuro che non lascia nessun dato non protetto.\n\n## Valutare la privacy dei dati nell'era della sicurezza a zero fiducia\n\nIn questa era moderna, in cui la fiducia e il segreto sono fondamentali, l'idea del controllo dell'utente sui propri dati è molto ben accolta. È una sfida emozionante - rendere la privacy dei dati più accessibile - e al timone di SafeliShare, Shamim Naqvi sta rompendo nuovi terreni con i suoi approcci innovativi per garantire questa privacy.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Shamim Naqvi","Darren W Pulsipher"],"link":"/episode-EDT176-it","image":"./episodes/edt-176/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren intervista Shammim Naqvi, l'AD e fondatore di SafelyShare, riguardo la gestione e la sicurezza dei dati in ambienti condivisi e collaborativi utilizzando il modello di dati a zero fiducia."},{"id":79,"type":"Episode","title":"Dati a Zero Fiducia con SafelyShare","tags":["safelyshare","datasecurity","zerotrust","secureenclaves","confidentialcomputing","securedatasharing","dataencryption","hybridconfidentialcomputing","dataauthentication","datamanagement","witnessexecution","datasharingsolutions","confidentialcomputingchipsets","endtoendencryption","dataprotection","businessinformationsecurity","securedataaccess","securedataexchange","datasharingtechnology","dataprivacy"],"body":"\r\n\r\n## La Rivoluzione di SafelyShare nella Condivisione dei Dati e nella Riservatezza\n\nLa condivisione dei dati è sempre stata un problema chiave quando si tratta di informazioni commerciali sensibili e riservate. Le soluzioni tecnologiche avanzate, tra cui SafelyShare, hanno affrontato questo problema, offrendo un sistema controllato per l'accesso ai dati senza violare la protezione degli stessi. La base fondamentale di questo sistema è \"Zero Trust\", una strategia unica che non presume fiducia per nessuno e mantiene come fulcro il controllo e il monitoraggio.\n\n## Sfruttando il Potere delle Enclavi Sicure\n\nUn aspetto critico dell'approccio di SafelyShare è l'uso di enclavi sicure, o ambienti di esecuzione fidati, che garantiscono uno spazio sicuro per la condivisione, l'autenticazione e la gestione dei dati. Queste enclavi sono create con l'aiuto di specifici chipset di calcolo confidenziali che racchiudono completamente i dati condivisi. Con pratiche di crittografia implementate al di fuori di queste enclavi, i dati possono essere decrittografati solo una volta entrati nell'enclave, fornendo così una politica di crittografia end-to-end. L'output che esce dall'enclave è anche criptato, aggiungendo un altro strato di sicurezza per proteggere i dati.\n\nMa esistono sfide all'interno di questo processo. Non tutti i servizi online incorporano un'enclave sicura nel loro funzionamento, portando a una grande domanda per una soluzione più flessibile ed efficace per il calcolo confidenziale.\n\n## L'Approccio Ibrido della Computazione Confidenziale\n\nPer affrontare questo problema, SafelyShare offre un approccio che può essere descritto al meglio come un modello ibrido di calcolo confidenziale. Per compensare i servizi che non operano all'interno di enclavi sicure, questa metodologia introduce l'idea di 'esecuzione testimone'. In questo scenario, l'utente ripone la fiducia nella garanzia del fornitore della loro competenza e sicurezza nella gestione dei dati. È una sorta di accordo tacito tra l'utente e il fornitore del servizio remoto, rendendo il calcolo confidenziale più fattibile negli scenari del mondo reale.\n\nQuesto approccio ibrido ridefinisce il paradigma della condivisione sicura in un mondo in continua evoluzione. Con la sua base elastica, SafelyShare incorpora una profonda comprensione dei parametri di sicurezza in continuo cambiamento, rendendo il calcolo confidenziale adattabile e reattivo alle crescenti esigenze e realtà.\n\n## Conclusione: Rivoluzionando la Condivisione Sicura dei Dati\n\nIn sostanza, SafelyShare è il pioniere principale nella strada verso la realizzazione di una condivisione di dati sensibili sicura, efficiente e fattibile. Navigando intorno agli ostacoli tradizionali, integra nel suo framework il calcolo confidenziale ibrido, ottenendo un mix unico di fiducia e praticità. L'approccio innovativo di integrare il calcolo testimoniato nel processo sfuma i confini tra fiducia piena e parziale, rendendo la sicurezza dei dati più realizzabile e fornendo una promettente prospettiva per il futuro della condivisione e sicurezza dei dati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Shamim Naqvi","Darren W Pulsipher"],"link":"/episode-EDT177-it","image":"./episodes/edt-177/it/thumbnail.jpg","lang":"it","summary":"Durante questo episodio, Darren e l'CEO di SafeLishare, Shamim Naqvi, discutono su come il calcolo confidenziale possa essere impiegato per creare ambienti di collaborazione per la condivisione dei dati gestiti nel cloud."},{"id":80,"type":"Episode","title":"Rete Zero Trust con OpenZiti","tags":["zerotrustnetworking","overlaynetworks","networksecurity","digitalage","securitychallenges","networkingconcepts","softwaredevelopers","softwareengineers","defensestrategy","databreaches","virtualnetworks","zerotrustprinciples","openzerotrust","securitymeasures","identitymanagement","secureconnectivity","networkdefense","iotdevices","datatransmission","smartnetworking","serviceintegration","vpnnetworks","wireguardnetworks","datasecurity","itsecurity","digitalinnovations","digitaltransformation","futureproofsecurity"],"body":"\r\n\r\n# Svelare la Dinamica della Rete di Zero Trust e delle Reti Sovrapposte\n\nMentre l'era digitale progredisce, la conversazione sulla sicurezza delle reti assume una posizione di primo piano. In un panorama digitale in rapida evoluzione, il networking basato sulla fiducia zero e le reti overlay sono strategie fondamentali per affrontare le attuali sfide sulla sicurezza. Qui, ci addentriamo in questi concetti, come plasmano i nostri sistemi digitali e forniamo una comprensione dei loro potenziali benefici e applicazioni.\n\n## Uno Sguardo più Attento alla Rete di Zero Trust\n\nIl networking a zero fiducia è un approccio mentale che pone la sicurezza come preoccupazione primaria nella progettazione e nel funzionamento dei sistemi digitali. Il suo aspetto critico è la presunzione di potenziali minacce da ogni parte della rete, indipendentemente da quanto possano apparire sicure. Questo approccio si allontana dal tradizionale concetto stile fortezza nella sicurezza e porta a reti più robuste che non si basano esclusivamente sulla protezione di un singolo firewall.\n\nInnanzitutto, la bellezza delle reti zero-trust risiede nella loro capacità di lavorare in modo efficace e sicuro, presentando un vantaggio per sviluppatori ed ingegneri di software. La sicurezza diventa un facilitatore piuttosto che un ostacolo per il processo di sviluppo del software. Con la rete zero-trust, gli sviluppatori possono concentrarsi sullo sviluppo di funzionalità senza preoccuparsi di porte bloccate o di consultare i team di rete - un passo significativo verso rilasci sul mercato più rapidi.\n\nTuttavia, il networking a zero fiducia non elimina il bisogno di difese perimetrali o firewall. La strategia a zero fiducia presuppone un possibile compromesso del network; pertanto, richiede un livellamento delle difese invece di fare affidamento unicamente su una difesa perimetrale di base.\n\n## L'ascesa delle reti sovrapposte\n\nIn mezzo alle crescenti minacce alla sicurezza e alle violazioni dei dati, le reti sovrapposte emergono come uno strumento inestimabile. Queste reti virtuali definite da software forniscono uno strato extra di sicurezza rispetto alle reti sottostanti come i router o i firewall.\n\nLe reti sovrapposte come VPN e Wireguard permettono una comunicazione sicura tra risorse anche quando la rete sottostante è stata compromessa. Offrono funzionalità interessanti, come l'auto-riorganizzazione basata sulle condizioni, conferendo loro caratteristiche temporanee. Queste reti offrono anche opzioni per una comunicazione sicura in-applicazione o nel sistema dati - inoltre, un'opzione di endpoint senza client potenzia la connettività dell'utente, senza richiedere l'installazione di software su dispositivi individuali.\n\nLe reti overlay forniscono flessibilità riguardo al loro dispiegamento. Non c'è bisogno di riscrivere il codice della tua applicazione, poiché il codice per la rete overlay può essere incorporato direttamente nel codice dell'applicazione. In alternativa, se si desidera evitare di modificare l'applicazione, può essere invece distribuito un appliance virtuale. Questa comodità, unita ad una sicurezza aggiunta, configura le reti overlay come soluzioni future-proof per la sicurezza della rete.\n\n## Il Potere delle Soluzioni ZTN e OpenZiti\n\nLe offerte di networking Zero Trust (ZTN), come Open Zero Trust (Open Ziti), forniscono soluzioni competenti nel campo dello zero trust e dell'overlay networking. Essi applicano robusti principi di Zero Trust nel campo delle soluzioni di rete overlay.\n\nZTN, ad esempio, porta il suo sistema di identità sul tavolo, perfetto per i dispositivi IoT di bordo incapaci di accedere ai tipici servizi di identità. Offre una trasmissione di dati sicura attraverso il tunneling reciproco e un tessuto di instradamento intelligente che determina il percorso più efficiente dal punto A al punto B. D'altra parte, Open Ziti facilita diversi casi d'uso, gestendo le connessioni est-ovest e nord-sud in modo fluido e sicuro. Si integra bene con le reti di servizio per fornire un'elevata sicurezza.\n\nPertanto, l'adozione di tali misure di sicurezza olistiche diventa necessaria man mano che entriamo nell'era digitale. ZTN e OpenZiti presentano soluzioni pratiche per coloro che adottano il modello Zero Trust, con caratteristiche vantaggiose che vanno dalla gestione dell'identità alla connettività sicura. Senza dubbio, queste innovazioni stanno stabilendo i punti di riferimento per la sicurezza della rete.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Phillip Griffiths","Darren W Pulsipher"],"link":"/episode-EDT178-it","image":"./episodes/edt-178/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Phillip Griffith, un leader della comunità del progetto open-source OpenZiti. Discutono dell'importanza del networking Zero Trust nelle reti IT moderne."},{"id":81,"type":"Episode","title":"Sfruttando l'IA generativa nel college","tags":["generativeai","academicintegration","aiineducation","digitaltransformation","blogpost","aistudents","byuidaho","chatgpt","aiassistance","academiccheating","distinguishingguidelines","selfassessment","aiinselfassessment","qualitativeimprovement","ongoingdebates","aishortcomings","aiinaugmentation","futureofai","cheatingconcerns","shortcutculture","academicpolicies","aisuccess","aitoolkit","professionalhabitat"],"body":"\r\n\r\n## Navigando tra le Complessità dell'Integrazione Accademica con l'IA Generativa\n\nNel mondo frenetico definito dalla rapida trasformazione digitale, è sempre più evidente come le costruzioni AI stanno diventando parti inestricabili della vita quotidiana. Un'area affascinante in cui il loro impatto può essere avvertito è nel campo dell'istruzione. Questo post sul blog intende approfondire il potenziale dell'IA generativa con le esperienze dirette di una studentessa, Madeline Pulsipher, alla BYU Idaho.\n\nL'applicazione di assistenza AI generativa come ChatGPT nel lavoro accademico rivela possibilità entusiasmanti. Quando utilizzata responsabilmente, questo potente strumento può fornire un vantaggio digitale nel brainstorming di idee, nella generazione di schemi di saggio e nell'autovalutazione del proprio lavoro rispetto ai criteri di valutazione.\n\n## Intelligenza Artificiale Generativa - Strumento o Trucco?\n\nLa questione se l'uso dell'IA per i compiti accademici sia o non sia considerato imbroglio presenta un aspetto interessante. Madeline afferma correttamente che utilizzare l'IA per facilitare un processo o per guidare non dovrebbe essere equiparato all'imbroglio. L'imbroglio implicherebbe comporre un saggio esclusivamente con l'IA e prendersi il merito per il lavoro non assistito.\n\nTuttavia, dobbiamo creare linee guida distintive mentre approcciamo metodi tecnologici più recenti. Definire cosa costituisce un uso responsabile rispetto al barare quando si incorpora l'IA negli studi accademici è un compito essenziale su cui le istituzioni educative devono lavorare e definire formalmente e strenuamente.\n\n## L'efficienza dell'IA nell'autovalutazione\n\nUn intrigante uso dell'IA ha fermato tutti sulle loro tracce - autovalutando il suo lavoro sulla base del rubric di valutazione stabilito prima della consegna. Gli esperimenti di Madeline con questo approccio hanno prodotto risultati fruttuosi, con lei che ha ottenuto A in tutti i suoi saggi assistiti dall'IA. Ciò significa il nuovo potenziale dell'IA per assistere non solo nei compiti meccanici, ma anche nel miglioramento qualitativo del lavoro.\n\n## Prospettive e Dibattiti in Corso\n\nL'uso dell'IA in contesti accademici è stato dibattuto per molto tempo. Sebbene possa essere uno strumento prezioso per migliorare i risultati dell'apprendimento e aumentare la produttività, è importante ricordare che l'IA non può sostituire l'intelletto umano. Ogni nuova tecnologia ha vantaggi e svantaggi, e l'IA non fa eccezione.\n\nSebbene l'IA generativa possa produrre contenuti, manca del tocco umano che è essenziale nella comunicazione. Non può sostituire gli insegnanti umani nel spiegare concetti complessi, poiché ha bisogno della capacità di comprendere le sfumature della conversazione umana. Pertanto, sebbene l'IA possa essere un bene prezioso in certi ambiti, deve mantenere il valore dell'interazione e dell'esperienza umana.\n\n## Migliorare le Interazioni Sociali\n\nLa pandemia di COVID-19 ha sconvolto le vite di molti studenti che quest'anno hanno iniziato il loro primo anno di college. La tendenza negativa nelle relazioni sentimentali tra gli adolescenti è ulteriormente peggiorata durante la pandemia. A causa della mancanza di interazioni sociali, l'attuale generazione perde molte esperienze critiche, come il primo bacio, la rottura di una relazione o la richiesta di un altro appuntamento.\n\nMadeline chiese consiglio ai suoi amici su come rifiutare un ragazzo che voleva un altro appuntamento, ma ricevette consigli contrastanti. Poi, si rivolse a ChapGPT, un assistente imparziale e senza emozioni alimentato da intelligenza artificiale, per un consiglio. Ha utilizzato i suggerimenti di ChapGPT come guida per sviluppare il suo approccio.\n\nQuesta capacità di utilizzare l'IA Generativa come consulente piuttosto che come autorità definitiva sarà fondamentale per la prossima generazione per sfruttare il potere dell'IA in situazioni accademiche e sociali.\n\n## Il Futuro dell'IA nel Mondo Accademico\n\nDiverse preoccupazioni continuano a gravitare attorno all'integrazione dell'IA nell'ambito accademico - preoccupazioni riguardanti la frode, la mancanza di politiche istituzionali consolidate e la possibilità di favorire una cultura dell'abbreviazione. Tuttavia, è innegabile che l'IA generativa è uno strumento a cui molti studenti stanno ricorrendo, e il suo pieno potenziale all'interno del mondo accademico deve ancora essere esplorato approfonditamente.\n\nChiaramente, la rigida linea di demarcazione tra il barare e l'uso appropriato deve essere attentamente tracciata. Ma una volta stabilita questa linea, il successo dell'IA come strumento nei paradigmi accademici sembra promettente. Se utilizzata correttamente, può diventare una parte sostanziale di un kit didattico - formando individui competenti ben equipaggiati per gestire l'IA nei loro habitat professionali.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Madeline Pulsipher","Darren W Pulsipher"],"link":"/episode-EDT179-it","image":"./episodes/edt-179/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista sua figlia che ha recentemente completato il suo primo semestre al college riguardo la sua esperienza nell'utilizzo della tecnologia generativa AI nei suoi studi accademici. Lei descrive le sfide e i successi associati all'utilizzo di questo strumento trasformazionale."},{"id":82,"type":"Episode","title":"Raccolta e preparazione dei dati","tags":["dataarchitecture","datacentric","data"],"body":"\r\n\r\n## Abbiamo bisogno dei dati! I nostri dati sono un caos!\n\nLa prima cosa da considerare in questa parte del processo è il flusso dei dati. Come identifichiamo quali dati grezzi abbiamo bisogno e come li otteniamo attraverso il flusso dei dati e li trasformiamo in informazioni? Ci sono cinque passaggi chiave nel flusso dei dati: determinare il valore commerciale dei dati, assimilarli, prepararli, analizzarli e, infine, agire in base alle informazioni ottenute.\n\nGuardiamo alla produzione come esempio. Nell'individuare quali dati offrano valore alle imprese, dovresti fare tre domande fondamentali: Qual è la domanda per il mio prodotto? Qual è l'offerta attuale? Qual è la perdita di resa? Queste sono domande apparentemente semplici, ma poi devi pensare a cose più complesse come ad esempio come quantificare la domanda, le capacità di produzione, l'offerta e la perdita di resa. Da dove provengono i dati? Come li acquisisco? Quanto sono affidabili e stabili questi dati? Ci sono molte domande e variabili, come ad esempio i tempi di consegna delle materie prime, la domanda proiettata e la perdita di resa sconosciuta, che possono creare una grande complessità.\n\nIl pipeline semplifica il modo in cui tutti questi componenti si uniscono. Ogni tipo di dato passa attraverso i passaggi chiave nel pipeline, ma ognuno sarà diverso. Ad esempio, l'assunzione di un tipo di dato varierà rispetto all'assunzione di un altro. L'idea, però, è quella di riunire tutti i dati per creare un quadro chiaro.\n\n## Abbiamo dei dati! Cosa ne facciamo?\n\nA seconda del tipo di dati e delle domande a cui si cerca di rispondere, si utilizzano diverse tecniche di analisi. Ad esempio, per rispondere a quanti widget dovrebbero essere prodotti, si potrebbe analizzare l'offerta e la domanda storica tramite l'analisi dei dati e l'intelligence di base in ambito aziendale. Per determinare quali widget presentano difetti visivi, potrebbe essere il miglior approccio un algoritmo che impara a identificare difetti nelle immagini tramite il deep learning. Non esiste una singola tecnica che risolve tutti i problemi; ognuna è unica per il problema e i dati stessi.\n\nInoltre, è importante coinvolgere esperti del settore per aiutare a comprendere gli schemi che i dati producono. L'esperto del settore comprenderà i dati e da dove provengono, mentre lo scienziato dei dati comprenderà il miglior approccio per gli algoritmi al fine di ottenere una maggiore comprensione. Ad esempio, se attraverso un algoritmo di apprendimento automatico si prevede un calo nella resa del prodotto, gli ingegneri incaricati di risolvere il problema potrebbero non sapere dove guardare senza il contesto del problema. Una delle ragioni per cui le organizzazioni non ottengono il ritorno sugli investimenti nel grado in cui dovrebbero è perché non hanno costruito i loro modelli per essere azionabili o riflettenti dei comportamenti all'interno dei sistemi che cercano di prevedere.\n\nCome tutto ciò funziona insieme si riduce alle domande aziendali che stai facendo e alle sfide che hai. Ad esempio, potresti avere una serie di algoritmi che ti dicono quanti widget produrre. Potresti avere un algoritmo di apprendimento profondo che riconosce se un widget ha un difetto e anche classifica i difetti. Ma ciò non aiuta necessariamente se non sai perché quel difetto è accaduto. Quindi devi collegare quelle informazioni ad alcuni altri algoritmi per ottenere correlazioni per spiegare i difetti e hai bisogno di un piano d'azione per correggere il problema.\n\n## Dobbiamo creare conoscenze. Come addestriamo i nostri dati?\n\nCome possiamo realizzare questo? Fondamentalmente, stai riunendo tutti i dati, preparandoli e collegandoli al fine, ad esempio, di quantificare l'approvvigionamento e le previsioni di perdita di resa. Avrai bisogno di pratiche di risoluzione dei problemi e miglioramento continuo nel tempo per far fronte alle condizioni mutevoli. È qui che entra in gioco la cultura dell'organizzazione. Risolvere un problema una volta senza un impegno per il miglioramento continuo può far perdere all'organizzazione il vero valore dell'analisi nel lungo periodo.\n\nStiamo assistendo oggi a un importante cambiamento verso organizzazioni con un'infrastruttura incentrata sui dati. I dati non sono più solo nel data center, ma anche nel cloud e nell'edge. Con il processo aziendale in cima, che porta a un miglioramento continuo, comprensione del business e dei dati, fino alla distribuzione, le organizzazioni costruite su questa infrastruttura possono notare una differenza notevole nel mondo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT18-it","image":"./episodes/edt-18/it/thumbnail.png","lang":"it","summary":"Sarah Kalicin, Lead Data Scientist presso Intel, e Darren Pulsipher, Chief Solution Architect, Pubblico Settore presso Intel, parlano del processo e dei vantaggi della raccolta e preparazione dei dati nel diventare un'organizzazione centrata sui dati. Questo è il secondo passo nel percorso verso il diventare un'organizzazione centrata sui dati."},{"id":83,"type":"Episode","title":"Intelligenza Artificiale Generativa nell'Istruzione Superiore (Rivisitato)","tags":["embracingdigitaltransformation","darrenpulsipher","lauranewey","generativeai","aiineducation","educationtransformation","teachingexperience","aiinclassroom","moderneducationdynamics","criticalthinkingskills","digitaltransformation","resistanceagainstai","traditionalteaching","incoorporatingai","ineducationalcurriculums","innovationandeducation","ethicalusageofai","academicintegrity"],"body":"\r\n\r\n## Come l'Intelligenza Artificiale Generativa Migliora l'Esperienza in Classe\n\nL'IA generativa si sta rapidamente integrando nei programmi educativi, influenzando il modo in cui gli educatori affrontano l'insegnamento e migliorando in modo fondamentale l'esperienza di apprendimento. Secondo Newey, questa tecnologia molto dibattuta non è semplicemente una forma di plagio, ma un brillante strumento che aumenta e rivitalizza le metodologie educative. Incoraggiando gli studenti a utilizzare l'IA nei compiti di pensiero, sottolinea l'importanza di promuovere e alimentare le abilità di pensiero critico nella nostra società in accelerata digitalizzazione.\n\nPiuttosto che rimanere come partecipanti passivi, lei sostiene che gli studenti dovrebbero diventare attori attivi, analizzando i risultati generati dall'IA e considerando la qualità e la sostanza delle loro informazioni in ingresso. Questo cambiamento sottolinea l'importanza della comprensione, della ricerca e dell'analisi rispetto alla mera generazione di risultati.\n\n## Transizione dall'Insegnamento Tradizionale\n\nL'approccio progressivo di Newey diverge drasticamente dai metodi convenzionali a cui si aggrappano la maggior parte degli educatori, soprattutto considerando la resistenza generale verso l'integrazione dell'A.I. Generativa in contesti educativi. Tuttavia, sottolinea l'inevitabilità e la necessità di adottare la digitalizzazione per il vantaggio complessivo degli studenti.\n\nConfrontare questa transizione con la resistenza iniziale all'uso di internet come strumento di insegnamento indica dove ci troviamo oggi. L'IA generativa, come qualsiasi altra tecnologia in evoluzione, necessita di essere incorporata nel curriculum e richiede aggiornamenti regolari per mantenere la sua rilevanza in questo paesaggio digitale in rapido movimento.\n\n## Bilanciando Innovazione ed Etica\n\nCon progresso e innovazione, Newey affronta anche le considerazioni etiche inerenti a questo cambiamento. Condivide diversi casi in cui gli studenti, inconsapevolmente o sottilmente, hanno inviato saggi generati da intelligenza artificiale. Pertanto, sottolinea la necessità degli educatori di bilanciare attentamente l'accettazione tecnologica e l'uso etico.\n\nLei crede fermamente che gli studenti possano utilizzare l'I.A. come uno strumento produttivo, ma la responsabilità ricade anche sugli educatori di guidarli a mantenere contemporaneamente l'integrità accademica.\n\n## Conclusione: Spianare la Strada verso un Sistema di Istruzione Potenziato dall'Intelligenza Artificiale\n\nL'integrazione dell'IA generativa nell'istruzione, sebbene abbia incontrato resistenza, è un'indicazione profonda del cambiamento del panorama educativo. Come illustra Newey, l'integrazione efficace dell'IA nell'istruzione può migliorare significativamente le esperienze di apprendimento e lo sviluppo di competenze essenziali, garantendo la preparazione dei nostri studenti per un futuro plasmato dalla trasformazione digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Laura Newey","Darren W Pulsipher"],"link":"/episode-EDT180-it","image":"./episodes/edt-180/it/thumbnail.jpg","lang":"it","summary":"Nell'episodio di questa settimana di Abbracciando la Trasformazione Digitale, Darren Pulsipher intervista l'oratrice ospite Laura Newey riguardo il suo affascinante percorso attraverso il mondo emergente della Generative AI, in particolare nel settore dell'educazione. Coprendo la trasformazione della sua esperienza di insegnamento e arricchendo i risultati di apprendimento dei suoi studenti attraverso l'IA, ha analizzato ampiamente l'adattamento alle dinamiche dell'educazione moderna."},{"id":84,"type":"Episode","title":"Zero Trust in 5G","tags":["5gtechnology","zerotrustsecurity","embracingdigitaltransformationpodcast","darrenpulsipher","lelandbrown","yazkrdzalic","kenurquhart","trentonsystems","zscaler","advancedcommunications","operationaltechnology","informationtechnology","lonelyislandapproach","telecominfrastructure","advancedsecuritymodels","commercial5gusage","military5gusage","technicalchallenges","cybersecurity","5gsecurity","integration","solutionarchitecture"],"body":"\r\n\r\n## Il Vasto Panorama del 5G e l'Approccio dell'Isola Solitaria\n\nIl mondo della tecnologia 5G si sta evolvendo rapidamente e di conseguenza, ci sono molte discussioni perspicaci che si svolgono sulla fusione tra Tecnologia Operativa (OT) e Tecnologia dell'Informazione (IT). Yazz Krdzalic descrive il concetto dell'\"Approccio dell'Isola Solitaria\". Questo approccio si riferisce alla tendenza di diverse entità a concentrarsi troppo sul risolvere i loro problemi individuali, che spesso ha portato al ristagno della crescita nell'hardware personalizzato nell'infrastruttura delle telecomunicazioni.\n\nLa necessità di allontanarsi da questo approccio individualistico e ristabilire un quadro architettonico collettivo che può adattarsi e flettersi con diversi casi d'uso sta diventando sempre più evidente. Con l'emergere della tecnologia 5G, c'è bisogno di un approccio collaborativo che possa adattarsi alle varie necessità di diverse entità. L'approccio collettivo contribuirà a garantire che l'infrastruttura sia flessibile e scalabile, facilitando l'integrazione delle loro tecnologie e applicazioni nella rete da parte delle entità.\n\nLe discussioni sulla fusione di OT e IT stanno anche guadagnando slancio, ed è chiaro che la collaborazione tra questi due settori è essenziale per il successo della tecnologia 5G. Man mano che la tecnologia continua a evolversi, si prevede che ci saranno più dibattiti e discussioni su come sfruttare le opportunità presentate dal 5G, pur affrontando le sfide poste dalla tecnologia emergente. Nel complesso, il futuro della tecnologia 5G sembra luminoso, e la collaborazione tra diverse entità giocherà un ruolo critico nel suo successo.\n\n## Passaggio alla Sicurezza Zero Trust\n\nMentre la tecnologia continua a evolversi, le preoccupazioni per la sicurezza sono diventate un problema crescente per individui e organizzazioni allo stesso modo. Per affrontare queste preoccupazioni e garantire un ambiente sicuro, è necessario un quadro architettonico collettivo. Questo quadro include l'implementazione di modelli di sicurezza avanzati, come la Sicurezza Zero Trust. Tuttavia, la transizione a questi modelli non è sempre facile. Richiede l'abbandono di metodi operativi più vecchi e la garanzia che tutti i moduli tecnologici siano sincronizzati e funzionino correttamente. In passato, erano i clienti a doversi sobbarcare la responsabilità di integrare tutti i pezzi. Fortunatamente, con l'adozione di un approccio più evoluto, l'onere dell'integrazione è stato ridotto notevolmente per i clienti, rendendo l'implementazione della Sicurezza Zero Trust e di altri modelli di sicurezza avanzati un processo molto più fluido.\n\n## Trovare il Terreno Comune nell'Uso del 5G\n\nLo sviluppo della tecnologia 5G è stato un cambiamento radicale sia nel settore commerciale che in quello militare. Tuttavia, ci sono requisiti specifici che differenziano l'uso commerciale e militare del 5G. I dispiegamenti commerciali di reti 5G private sono per lo più statici, mentre i dispiegamenti militari devono essere mobili.\n\nLeland Brown, un prominente esperto nel campo, ha discusso le complessità di trovare un'architettura comune che potesse soddisfare entrambe queste esigenze. La sfida era creare una soluzione finale che soddisfacesse elegantemente questi requisiti. Era importante garantire che la soluzione fosse efficiente ed efficace sia per i casi d'uso commerciali che militari.\n\nLo sviluppo di tali soluzioni è fondamentale per garantire che la tecnologia 5G sia utilizzata al massimo del suo potenziale e possa soddisfare le diverse esigenze di diverse industrie.\n\n## Concludendo\n\nIl mondo della tecnologia è in continua evoluzione e miglioramento, e l'avvento della tecnologia 5G e della sicurezza Zero Trust ne è la prova. Tuttavia, l'implementazione di questi avanzamenti può essere difficile a causa di ostacoli tecnici e culturali. Fortunatamente, esperti come Leland Brown, Ken Urquhart e Yaz Krdzalic stanno lavorando per agevolare l'integrazione della tecnologia 5G e della sicurezza Zero Trust, rendendo il cammino verso un futuro tecnologico più sicuro ed efficiente un po' più facile per tutti. Le loro intuizioni e competenze stanno facendo luce sul continuo percorso di evoluzione e miglioramento nel mondo della tecnologia.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Leland Brown","Yazz Krdzalic","Ken Urquhart","Darren W Pulsipher"],"link":"/episode-EDT181-it","image":"./episodes/edt-181/it/thumbnail.jpg","lang":"it","summary":"Nel mezzo della crescente adozione delle tecnologie 5G in tutto il mondo, gli esperti nell'ultimo episodio del podcast Embracing Digital Transformation hanno approfondito l'argomento fondamentale dello Zero Trust nella sicurezza 5G. L'ospite Darren Pulsipher ha dato il benvenuto all'esperto di comunicazioni avanzate 5G Leland Brown, VP del Marketing presso Trenton Systems Yazz Krdzalic, e a Ken Urquhart, un fisico divenuto professionista della sicurezza informatica presso Zscaler, per discutere dell'integrazione e dell'avanzamento della tecnologia 5G, insieme alle sue sfide e progressi."},{"id":85,"type":"Episode","title":"Garanzia dei Dati a Zero Fiducia","tags":["digitaltransformation","dataintegrity","zerotrust","cybersecurity","strategies","walacor","encryption","loganalysis","geographicaldistribution","externalhackers","organizationalthreats","datamanagement","dataaudits","immutableauditlog","systemchange","legalcompliance","reducerisk","dataintelligence","multilayeredsecuirty","dataprotectionsolution","keyvulnerabilities","improveddataprotection","futuredigitalbusinesses","revolutionizedigitallandscape"],"body":"\r\n\r\n## Smascherando le Presunzioni sulla Sicurezza dei Dati\n\nIn passato, le persone avevano una fiducia implicita che i loro dati fossero al sicuro e la loro privacy fosse protetta. Tuttavia, questa fiducia è spesso basata su un modello obsoleto che non si allinea più con l'attuale panorama tecnologico. L'aumento del numero di violazioni dei dati e attacchi informatici ha reso evidente che la sicurezza dei dati è più critica che mai, e le precauzioni che venivano considerate adeguate in passato potrebbero non essere più sufficienti.\n\nOggi, i dati sono vulnerabili a minacce non solo da hacker esterni, ma anche all'interno delle organizzazioni. È essenziale capire che una violazione dei dati può avere significative implicazioni, che vanno dalle perdite finanziarie al danno reputazionale. Pertanto, è fondamentale implementare un approccio di zero fiducia alla gestione dei dati, il che significa che ogni richiesta di accesso ai dati deve essere verificata prima che l'accesso sia concesso. Sono inoltre necessarie audit dei dati affidabili per garantire che l'input dei dati corrisponda all'output e che non ci sia accesso non autorizzato a informazioni sensibili.\n\n## Implementando una Nuova Era di Sicurezza dei Dati con Walacor\n\nWalacor fornisce una soluzione unica per migliorare la nostra comprensione della sicurezza dei dati. Offrono un registro di audit automatico e infallibile che è immutabile, il che significa che una volta inseriti i dati, non possono mai essere modificati o cancellati senza essere rilevati. Questa caratteristica rende incredibilmente facile tracciare ogni modifica apportata al sistema, il che è fondamentale per mantenere un ambiente sicuro.\n\nFornendo trasparenza e tracciabilità, la soluzione di Walacor aiuta le organizzazioni a rispettare i requisiti di conformità legale e a mitigare i rischi. Ad esempio, in caso di controversia legale, un registro di audit immutabile può fungere da fonte di prova affidabile, poiché non può essere manomesso. Inoltre, in caso di violazione dei dati, un registro di audit immutabile può aiutare a identificare la fonte della violazione e l'entità del danno causato.\n\nNel complesso, l'approccio innovativo di Walacor alla sicurezza dei dati, con il suo registro di audit 100% immutabile, offre una soluzione promettente per le organizzazioni che cercano di migliorare la loro postura di cybersecurity.\n\n## Modellando il Futuro dell'Intelligenza dei Dati\n\nL'aumento del rischio di violazioni dei dati significa che dobbiamo allontanarci dall'uso di più livelli di sicurezza dei dati per passare a una soluzione di protezione dei dati più integrata. Questo tipo di soluzione pone le basi per un ambiente di Zero Trust, che riduce significativamente il rischio di minacce e vulnerabilità informatiche. Adottando questo approccio, possiamo semplificare i nostri metodi di protezione dei dati e garantire una migliore integrità dei dati.\n\nLo sviluppo dell'intelligenza dei dati nella forma di integrità dei dati e sicurezza apre nuove possibilità per le imprese digitali. Migliorati metodi di protezione dei dati, migliore integrità dei dati e una riduzione delle potenziali minacce informatiche sono solo alcuni dei benefici che si prevede trasformeranno il panorama digitale. Tra questi, si parla molto dell'approccio unico di Walacor all'integrità dei dati e allo zero trust, che rappresenta una pietra miliare significativa nel modo in cui affrontiamo la sicurezza dei dati ora e in futuro.\n\nScopri ulteriori informazioni su (https://walacor.com)[https://walacor.com]\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Walter Hancock","Darren W Pulsipher"],"link":"/episode-EDT182-it","image":"./episodes/edt-182/it/thumbnail.png","lang":"it","summary":"La necessità di solide strategie di sicurezza dei dati è cresciuta esponenzialmente nell'era digitale, diventando una priorità per le aziende in tutto il mondo. L'esperto di cybersecurity e CTO di Walacor, Walter Hancock, offre un acuto spunto sulla l'importanza dell'integrità dei dati e di un approccio di zero fiducia negli attuali regimi di cybersecurity."},{"id":86,"type":"Episode","title":"Gestione dei Dati nelle Scienze dei Materiali e nelle Industrie Manifatturiere","tags":["digitaltransformation","materialscience","manufacturingindustry","dataanalytics","machinelearning","artificialintelligence","productdevelopment","structuredmethodologies","projectmanagement","complexdata","unstructureddata","datascience","r&dprocess","newproductdevelopment","datamanagement","technologyinnovation","physicitaldigitalknowledgegap","embracingdigital.org","embracingdigitaltransformationpodcast"],"body":"\r\n\r\n## Colmare il divario tra fisico e digitale nella Ricerca e Sviluppo\n\nMaterials Zone è incentrata su un aspetto di nicchia ma significativo della scienza dei materiali, in particolare nell'industria manifatturiera. Data l'importanza dei materiali nello sviluppo dei prodotti, la gestione efficace dei dati diventa cruciale. Analogamente a una ricetta di cucina, la scienza dei materiali coinvolge un'accurata integrazione di ingredienti (materiali) processati per produrre il prodotto finale.\n\nTuttavia, questo settore è storicamente stato gestito in modo ad hoc, basandosi su tentativi, errori e intuizione. Di conseguenza, la conoscenza acquisita durante questo processo spesso si perde a causa di una documentazione insufficiente o dell'attrito dei dipendenti. Nel nostro mondo moderno e interconnesso, dove i processi di sviluppo del prodotto spesso attraversano più sedi, persino paesi, è fondamentale stabilire metodologie strutturate per prevenire la perdita di conoscenza.\n\nUna delle tecniche evidenziate da Yudilevich riguarda il \"fattore del camion\", che suggerisce che se l'unica persona che sa come svolgere un determinato compito fosse investita da un camion, potrebbe potenzialmente mandare fuori binario l'intero progetto. Pertanto, avere almeno un'altra persona oltre all'individuo principale che possa svolgere il compito potrebbe ridurre la vulnerabilità del team.\n\n## Catturare le Complessità dei Dati della Scienza dei Materiali\n\nIl campo della scienza dei materiali genera dati complessi, spesso non strutturati e difficili da catturare utilizzando tabelle e database di dati tradizionali in modo sufficiente. Per visualizzare questo, considera i dati come un grafico in cui le materie prime si trasformano in prodotti finiti. Le innumerevoli interazioni tra i vari costituenti danno origine a molteplici dimensioni uniche all'interno dei dati.\n\nInoltre, esiste una traduzione continua all'interno dell'ambito manifatturiero - Dalla ricerca esplorativa alla fase di produzione, che richiede stabilizzazione e consistenza. Collazionare i dati da queste fasi in un archivio unificato può migliorare il processo di R&S centralizzando le informazioni, facilitando l'apprendimento inter-fase e accelerando lo sviluppo di nuovi prodotti.\n\n## Integrando la Scienza dei Dati nella Produzione\n\nSebbene la scienza dei dati si sia diffusa in molte industrie, le aziende focalizzate principalmente sullo sviluppo di prodotti nel mondo fisico trovano spesso inefficiente e costoso istituire dipartimenti dedicati ai dati o integrare strumenti analitici. È qui che entra in gioco la soluzione di Materials Zone, rendendo la scienza dei dati, l'apprendimento automatico e gli strumenti statistici accessibili alle aziende non familiari con queste aree.\n\nOffrono strumenti pronti all'uso, accompagnati da webinar e sessioni di formazione per una facile adozione, riducendo così le barriere all'integrazione della scienza dei dati nelle pratiche di produzione. Sorprendentemente, anche le aziende Fortune 500 che non dispongono delle necessarie competenze digitali possono trarre notevoli vantaggi da tali soluzioni.\n\n## Mentre Facciamo un Passo Avanti\n\nMan mano che il processo di sviluppo del prodotto diventa più complesso e globale, la natura critica della gestione sistematica dei dati combinata con l'innovazione tecnologica sta venendo alla ribalta. Aziende come Materials Zone stanno spianando la strada, guidando le imprese a colmare il loro divario di conoscenza fisico-digitale, rafforzando le loro pratiche di produzione e garantendo il successo futuro.\n\nPer ulteriori informazioni, visita https://materials.zone.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ori Yudilevich"],"link":"/episode-EDT183-it","image":"./episodes/edt-183/it/thumbnail.png","lang":"it","summary":"In un panorama tecnologico in rapida evoluzione, leader di settori diversi applicano l'analisi dei dati, l'apprendimento automatico e l'intelligenza artificiale alle loro operazioni. Oggi, guardiamo più a fondo ad un'azienda che guida la trasformazione digitale nell'industria manifatturiera - Ori Yudilevich, il CTO di Materials Zone."},{"id":87,"type":"Episode","title":"Utilizzando i dati come un patrimonio strategico","tags":["dataarchitecture","data","datastrategy","people","process"],"body":"\r\n\r\nwith data that may or may not be necessary. Translation: Proprio come alcune persone accumulano cose nelle loro case, timorose di buttare via qualsiasi cosa, anche le organizzazioni possono accumulare dati. Ad esempio, la mia cartella email ha 8 gigabyte. So che contiene dati che potrebbero o non potrebbero essere necessari.\n\nNon è necessario che sia così grande, ma salvo le cose nel caso possa averne bisogno. Ora moltiplica questo per il numero di dipendenti. Da Intel, abbiamo centomila dipendenti. Immagina quanto dati stiamo archiviando, solo nelle e-mail, quando facciamo il backup. Aggiungi i database strutturati e non strutturati, le presentazioni, i fogli di lavoro, ecc... ed è chiaro che semplicemente archiviarli tutti non è una grande strategia.\n\n## Statistiche sui dati\n\nDiamo uno sguardo alle statistiche che dimostrano perché questa è una cattiva strategia. Circa l'80% del tempo dei data scientist viene speso per pulire i dati prima di poterli utilizzare. Meno del 50% dei dati strutturati viene utilizzato del tutto e meno dell'1% dei dati non strutturati può essere analizzato. Quindi, tutti questi dati vengono accumulati, ma le organizzazioni non li utilizzano per la maggior parte. Un altro problema riguarda chi ha accesso a tutti questi dati archiviati. È preoccupante che il 70% dei dipendenti abbia accesso a dati a cui probabilmente non dovrebbero accedere. Proprio come le pile di un accumulatore creano rischi di incendio in casa, le pile disordinate di dati creano rischi per la sicurezza in un'organizzazione.\n\n## Esplosione dei dati\n\nCosa possiamo fare riguardo a questo problema? Prima di tutto, dobbiamo capire perché c'è una tale esplosione di dati. Con l'IoT, tutto è connesso e abbiamo elaborazione di dati che avviene in molteplici posti. La pura mole di dati che viene generata è incredibile. Questo problema è aggravato dalle questioni regolamentari; è difficile sapere cosa possiamo eliminare e cosa no. Riempiamo i nostri dispositivi di archiviazione e poi ne compriamo altri. La tecnologia sta essenzialmente incentivando il nostro accumulo di dati. Dobbiamo considerare cosa possiamo fare diversamente.\n\n## Perché accumuliamo\n\nGli esperti dicono che le persone accumulano perché credono che un oggetto sarà utile o prezioso in futuro, ha un valore sentimentale, è unico e irripetibile o è un affare troppo vantaggioso per essere gettato via. Queste stesse idee si applicano all'accumulo di dati. Ad esempio, perché dovrei avere una delle prime presentazioni che ho mai fatto? È conservata su un disco ed è nella cloud. La guardo forse una volta all'anno, ma non ho una vera ragione al di là del valore sentimentale per tenerla. Un'organizzazione è composta da individui con questi comportamenti e, a tutti i diversi livelli di accumulo di dati, c'è paura di eliminare i dati.\n\n## Diventare centrati sui dati\n\nCome si diventa un'azienda orientata ai dati anziché una società di archiviazione? Ecco un processo in quattro fasi per diventare un'organizzazione orientata ai dati.\n\n## Fondazione organizzativa\n\nIl primo passo è creare una fondazione organizzativa incentrata sui dati. Ci sono quattro protagonisti con ruoli distintivi.\n\nCapo Ufficio Dati: Il lavoro del capo ufficio dati è stabilire la strategia e la governance sulla gestione dei dati e sulla generazione di informazioni di valore per l'azienda. Questo ruolo è diverso da quello del capo ufficio informazioni, che si concentra sull'infrastruttura piuttosto che sulle informazioni stesse. Questo è un lavoro difficile, poiché il capo ufficio dati è coinvolto nel cambiamento culturale. Cerca di evitare che le persone accumulino dati e, invece, li utilizzino per creare un vero valore per l'azienda.\n\nData Scientist: I data scientist sviluppano modelli e schemi trovando dei pattern nei dati e utilizzando l'analisi predittiva. Gli sforzi dei data scientist possono diventare semplicemente un esperimento scientifico una tantum, tuttavia, a meno che le informazioni non vengano rese operative.\n\nIngegnere dei dati: Ecco dove entrano in gioco gli ingegneri dei dati. Gestiscono i flussi di dati e rendono operazionali le analisi. Man mano che arrivano nuovi dati, vengono generate nuove intuizioni senza dover ricominciare da capo ogni volta.\n\nResponsabile dei dati: Il responsabile dei dati gestisce la governance e l'accesso alle risorse dati, assicurandosi che le persone giuste abbiano l'accesso giusto al momento giusto.\n\nCon un'organizzazione che comprende questi quattro ruoli, la prossima grande domanda è se centralizzare o distribuire le operazioni. Ad esempio, forse la gestione matriciale distribuita sta già funzionando nella tua grande organizzazione, ma una piccola organizzazione potrebbe aver bisogno di maggior rigore e trarrebbe vantaggio da una struttura più centralizzata.\n\n## Raccolta e preparazione dei dati\n\nUn articolo della Harvard Business Review utilizza efficacemente una analogia sportiva per descrivere due strategie per catalogare i dati: difesa e attacco. In difesa, l'obiettivo è proteggere i dati. In attacco, l'obiettivo è avanzare per segnare il più velocemente possibile.\n\n## Difesa e attacco dati\n\nCon una strategia difensiva, l'organizzazione si concentra principalmente sulla sicurezza dei dati, la governance e la conformità. Proteggere i dati è fondamentale. Le principali attività relative ai dati si concentreranno sull'estrazione, la standardizzazione, la gestione dello storage e la gestione degli accessi. Tipicamente, questa strategia utilizzerà un'organizzazione più centralizzata e farà affidamento su una singola fonte di verità.\n\nCon una strategia offensiva, l'organizzazione è principalmente concentrata nel muoversi rapidamente per migliorare la propria posizione competitiva e ottenere il massimo profitto possibile. Le attività di dati saranno incentrate sull'estrazione, modellazione, visualizzazione, trasformazione e arricchimento.\n\nQuesta strategia richiederà maggiore flessibilità, il che significa un'organizzazione più distribuita con più versioni della verità.\n\nCapire come usare i dati in base alla strategia è importante. Spesso, le organizzazioni restano indecise e questo può portare confusione. Nonostante ogni organizzazione debba essere in grado di difendersi e attaccare, le organizzazioni devono scegliere una strategia anziché cercare di fare entrambe le cose, proprio come i giocatori di calcio professionisti non giocano su entrambi i lati del campo.\n\n## Analisi di Insight\n\nEsiste una curva di maturità organizzativa per l'analisi e la creazione di intuizioni dai tuoi dati. La chiave è capire dove si trova attualmente la tua organizzazione e quali sono i prossimi passi per avanzare lungo la curva.\n\nNella fase di analisi descrittiva, stai solo cercando di capire cosa sta succedendo. Nel passaggio diagnostico, stai cercando di capire perché è successo qualcosa. Nel passaggio predittivo, puoi prevedere cosa succederà in futuro basandoti sui dati storici. È qui che molte organizzazioni si sforzano di essere, ma i primi due passaggi devono essere compiuti prima. Al di sopra del predittivo c'è il prescrittivo, dove puoi capire perché succederà qualcosa e guidare l'organizzazione secondo le aspettative. In cima ai passaggi c'è la lettura analitica, o la previsione, dove stai facendo accadere le cose, avanzando anche oltre la prescrizione.\n\nUn motivo per cui è importante capire la posizione attuale della tua organizzazione è perché ci sono strumenti specifici per ogni fase. Ad esempio, non vuoi restare bloccato con un progetto di intelligenza artificiale che utilizza algoritmi prescrittivi, o addirittura predittivi, quando la tua organizzazione si trova ancora nella fase descrittiva.\n\n## Operazionalizzalo\n\nPer raggiungere l'obiettivo di operationalizzazione, ovvero rendere un processo ripetibile, ci sono tre elementi chiave: un'infrastruttura incentrata sui dati, i flussi di dati e il flusso aziendale.\n\nL'infrastruttura centrata sui dati consente di conoscere dove si trovano tutti i tuoi dati e cosa c'è in essi attraverso vari strumenti come un gestore dei metadati come Elastic Search o cataloghi e repository dei metadati. Le pipeline di dati dispongono di ottimi strumenti per consentire il processo dalla ingestione all'analisi all'azione. Una strategia difensiva o offensiva determinerà quali strumenti utilizzerai nella tua pipeline. L'ultimo elemento, il flusso aziendale, è dove la comprensione aziendale dei tuoi dati e processi consentirà l'implementazione di un processo di miglioramento continuo per garantire intuizioni ripetibili e di valore.\n\n## Chiamata all'azione\n\nPrima di tutto, sviluppare una strategia per i dati. Organizzati e scopri dove si trovano tutti i tuoi dati e catalogali. Decidi se adottare una strategia difensiva o offensiva, quindi procedi con i passi di analisi uno per volta, utilizzando gli strumenti adeguati. E, cosa più importante, operazionalizza le tue intuizioni per ottenere il massimo valore aziendale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT19-it","image":"./episodes/edt-19/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, architetto delle soluzioni capo di Intel nel settore pubblico, esplora come le organizzazioni possono passare semplicemente dall'accumulare dati all'utilizzarli come risorsa strategica."},{"id":88,"type":"Episode","title":"Segui il Bit","tags":["iot","dod","edge","technology","data","cybersecurity"],"body":"\r\n\r\n## Internet delle cose è l'inizio\n\nL'implementazione diffusa dell'Internet delle cose (IoT) sta richiedendo più tempo del previsto dall'industria. Molti attribuiscono i ritardi all'adozione e alla diffusione del 5G in tutto il mondo, ma c'è anche un altro problema che ha rallentato la realizzazione di sistemi IoT robusti: la gestione della complessità. Con il movimento dei dati attraverso il sistema, dall'edge all'aggregated edge, alla rete, al data center e al cloud, la protezione dei dati rappresenta una grande preoccupazione poiché la superficie di attacco aumenta quando si sposta al di fuori del tradizionale data center. Ci sono soluzioni puntuali che aiutano a migliorare questi problemi, ma non c'è ancora un'architettura di soluzione completa che risolva tutti i problemi con questo data center senza muri.\n\n## Complessità dell'ambiente del Dipartimento della Difesa\n\nL'IoT è già complesso e il DOD aumenta la complessità a causa dei tipi di produttori e consumatori dei dati. Sul lato dei produttori, i sensori sono collegati a satelliti, aeromobili, navi e veicoli; persino i combattenti stessi sono fondamentalmente centri dati in movimento. La quantità di dati che questi dispositivi periferici producono può sovraccaricare una rete. Il numero di dispositivi eterogenei può sembrare quasi impossibile da gestire, specialmente quando i dispositivi comunicano con protocolli diversi e hanno diversi livelli di classificazione. In altre parole, raccogliere i dati non è il problema; il problema è farli arrivare rapidamente nelle mani di coloro che prendono le decisioni in un formato utile.\n\nInoltre, la connettività può essere problematica con i dispositivi di bordo. Ambienti ostili in cui la connettività di rete verso un centro dati è inesistente, o al massimo intermittente, possono ritardare i dati. Questo significa che una soluzione in questo settore deve funzionare sia in modalità connessa che disconnessa. La velocità di consegna è un fattore chiave di successo; vite possono essere in gioco se le decisioni basate sui dati vengono ritardate.\n\n## Quadro comune per applicazioni, dati e sicurezza.\n\nOvviamente, abbiamo bisogno di soluzioni a questi problemi. Di importanza primaria è un quadro comune per gestire la complessità di queste nuove architetture IT che si trovano al di fuori dei tradizionali confini dei data center. Il quadro deve affrontare la gestione delle applicazioni, dei dati e della sicurezza. Dobbiamo essere in grado di distribuire applicazioni portatili e riutilizzabili ovunque nel sistema, dal bordo al cloud: la dottrina del \"scrivi una volta, esegui ovunque\". Questo ci consente di sviluppare, testare e distribuire rapidamente applicazioni senza dover configurare tutte le possibili combinazioni di configurazioni hardware nell'ecosistema. L'utilizzo di strumenti nell'ecosistema dei container dovrebbe aiutare in questo senso. Gli strumenti basati su Kubernetes (K8s) sono una buona scelta poiché sono diventati lo standard de facto nella community di DevOps.\n\nGestire le applicazioni in isolamento, tuttavia, non è sufficiente. Tutte le applicazioni necessitano di dati in qualche modo, quindi capire dove si trovano i dati, dove vanno e come vengono classificati è fondamentale per soluzioni di successo. Abbiamo bisogno di un ambiente operativo comune per gestire e governare le diverse classi di dati, come domini, confini di sicurezza, governance, gestione del ciclo di vita dei dati e località dei dati. Un ambiente operativo comune aumenta la flessibilità e la velocità di distribuzione delle applicazioni.\n\nUn quadro comune di sicurezza è anche necessario. La domanda critica è come proteggere i dati in tutte le loro forme e ancora condividerli? Ci sono soluzioni hardware e software attuali e una continua evoluzione in questo campo. Soluzioni di sicurezza di base come la crittografia dovrebbero essere fondamentali. Naturalmente, ciò richiede il motore sottostante corretto per lo storage e la capacità. Un'altra preoccupazione è l'ingresso di dati errati o nefasti nel sistema. Stabilire una radice di fiducia come base è anche necessario in questo vasto ecosistema.\n\n## Elaborazione al bordo, centro dati e cloud\n\nDove entra in gioco Intel in questo ambiente? Possiamo aiutare a fornire l'infrastruttura sottostante che supporta questi sistemi in termini di prestazioni e potenza. Che tu stia elaborando informazioni dei sensori sul bordo in un ambiente a basso consumo energetico (pensa a Atom e design ASIC personalizzati), o stai effettuando addestramento o inferenza di intelligenza artificiale nel tuo centro dati (Xeon e calcolo neuromorfico), Intel ha un processore che può aiutare a convertire i dati grezzi in informazioni preziose e azionabili, il componente chiave in questo complesso ambiente orientato alla missione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT2-it","image":"./episodes/edt-2/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren intervista Greg Clifton, Direttore del Dipartimento della Difesa (DOD) e dell'Intelligence per Intel Corp. Discutono delle sfide della gestione dei dati in un sistema complesso che si estende su più cloud, centri dati aziendali, centri dati regionali e frontiere tattiche. Ascolta Darren e Greg seguire un po' di dati dalla loro raccolta e il loro percorso attraverso questo ecosistema fino alla produzione di informazioni utilizzabili per analisti e combattenti. Ascolta Darren e Greg discutere di alcuni ostacoli in questo grande ambiente circolare e soluzioni per aiutare a fornire informazioni utilizzabili agli analisti e nuovamente ai combattenti."},{"id":89,"type":"Episode","title":"Distruggere la complessità dei livelli di archiviazione","tags":["data","optane","technology","storage","vastdata"],"body":"\r\n\r\n## Trent'anni di complessità di archiviazione\n\nL'archiviazione potrebbe essere un concetto vecchio, ma VAST Data è diventata una startup di successo in poco più di un anno di vendite. VAST ha sostituito la vecchia architettura dei sistemi di archiviazione a più livelli con un unico sistema monolitico che è veloce ed economico. Le soluzioni VAST eliminano anche il problema dei grossi e disordinati sistemi di archiviazione composti da diversi sistemi di file e diverse architetture.\n\n## Una Fondazione per una Nuova Architettura\n\nIl fondatore di VAST stava analizzando lo storage da una prospettiva totalmente nuova. Ha scoperto che i clienti non avevano necessariamente bisogno di prestazioni superiori dal Flash, ma avevano bisogno di supporto per lo storage di file e oggetti a un costo inferiore. Ha sfruttato tre tecnologie che non esistevano prima del 2018. La prima è NVMe over Fabrics, che viene utilizzato come una sorta di SAN ad iperscala per collegare tutto insieme con bassa latenza. Successivamente c'è il QLC Flash, perché è economico e non ha parti in movimento come gli hard disk. La terza è l'Intel 3D XPoint Optane. Optane ha una parità di lettura-scrittura ed è molto resistente ad un prezzo ragionevole. Unendo queste tre tecnologie, VAST è in grado di offrire ai clienti prestazioni all-flash, ma a un prezzo paragonabile a quello di un hard disk. Elimina la necessità di altri livelli che le organizzazioni acquistano perché sono economici.\n\n## Presentiamo il Vast Data Universal Storage\n\nIl sistema VAST è la prima architettura scomposta e condivisa. Ciò significa che la logica è scomposta dallo stato del file system. Invece, lo stato del file system risiede in casse di dati che contengono QLC Flash e Optane. L'Optane viene utilizzato come un grande archivio di metadati. È multiuso, proprio come il sistema, che è marchiato come storage universale. Con queste casse, non c'è un singolo punto di errore, quindi la capacità è, teoricamente, illimitata. (VAST ha testato il sistema a circa 50 petabyte in un singolo file system.) Puoi aumentare la capacità semplicemente aggiungendo server x86 a basso costo ai cluster. Poiché si tratta di un file system parallelo, qualsiasi utente può accedere a qualsiasi parte dei dati da uno qualsiasi dei server come se fosse direttamente collegato, quindi puoi continuare a scalare.\n\nPuoi anche aumentare le prestazioni indipendentemente dalla capacità. L'unica cosa che inibirebbe le prestazioni del flash è il processore, quindi avendo la possibilità di aumentare senza soluzione di continuità il numero di CPU nel cluster, puoi migliorare le prestazioni.\n\nUno dei problemi che viene risolto con questa struttura è la latenza. Molte organizzazioni necessitano di una bassa latenza per tutti i loro dati. Poiché ciascuno di questi server privi di stato ha accesso a tutto, si ha un accesso rapido a tutti i dati.\n\n## DASE Architettura: Pool di server\n\nUn altro grande vantaggio è che è facile ottimizzare lo spazio di archiviazione di un'organizzazione. La natura componibile dei server senza stato, e l'assenza di comunicazione tra di essi, ti dà la possibilità di costruire un cluster che si adatti meglio alle tue esigenze. Ad esempio, puoi segmentare le tue casse di controllo in base a diverse carichi di lavoro, ma possono tutti accedere agli stessi dati.\n\nInoltre, il sistema funziona bene con un'organizzazione che ha bisogno di diversi livelli di classificazione per accedere ai dati. Hai la possibilità di segregare ciò a cui gli utenti hanno accesso creando più zone di accesso con indirizzi IP virtuali. Una delle sfide con NFS è che trasmette in pratica a tutto. Se limiti le trasmissioni a un sottoinsieme di indirizzi IP, ti dà la possibilità di suddividere quelle diverse architetture in sistemi distinti.\n\n## Applicazione Eras di Universal Storage Bridges\n\nQuesta non è solo una soluzione ideata per i cluster HPC; non è costosa. Molte aziende utilizzano VAST prima per il backup per stabilire la fiducia. Ad esempio, il National Cancer Institute ha un archivio di librerie a nastro e voleva essere in grado di accedere alle informazioni più velocemente. Hanno valutato diverse piattaforme e VAST è risultato più conveniente e dotato di un sistema All-Flash, più veloce del loro sistema di produzione NAS. Quindi la soluzione ha un buon rapporto qualità-prezzo ed è utile per la condivisione generale dei file e una varietà di carichi di lavoro, come l'IA, l'analisi dei log, Splunk, ecc., non solo per l'HPC. Le soluzioni VAST sono semplici da gestire e veramente universali.\n\nVAST è una giovane azienda, ma ha diverse installazioni in agenzie governative come l'Istituto Nazionale della Salute e i Tri-labs del Dipartimento dell'Energia, dove è necessario un alto livello di prestazioni per questi supercomputer. Si tratta di un potente sistema in alcuni dei più grandi ambienti HPC al mondo, che supporta applicazioni mission-critical.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Randy Hayes"],"link":"/episode-EDT20-it","image":"./episodes/edt-20/it/thumbnail.jpg","lang":"it","summary":"Randy Hayes di VAST Data e Darren Pulsipher, Chief Solutions Architect, Public Sector, Intel, discutono dell'innovativa architettura di storage di VAST Data che elimina la necessità di livelli utilizzando NVMe over Fabrics, QLC Flash e 3D XPoint Optane."},{"id":90,"type":"Episode","title":"Grande Memoria Controller di Memoria Definita dal Software","tags":["bigmemory","edge","compute","technology","memverge","optane","pmem","data"],"body":"\r\n\r\nLa tecnologia di memoria persistente Optane 3D XPoint di Intel è stata una rivoluzione per MemVerge, consentendo loro di sviluppare una memoria definita dal software, che descrivono come esprimere la potenza di Optane PMEM.\n\n## Il modo migliore per utilizzare la PMEM\n\nMemVerge ha sviluppato il software Big Memory per soddisfare una crescente domanda da parte di applicazioni e aziende di elaborare dati a un volume e velocità sempre più elevati. Le applicazioni in tempo reale necessitano di insight e azioni immediate dai dati. Ciò richiede un'infrastruttura centrata sulla memoria per soddisfare le esigenze di latenza.\n\nLe applicazioni che impiegano l'intelligenza artificiale, il machine learning o l'analisi dei dati in tempo reale su grandi quantità di dati, ad esempio, di solito utilizzano la DRAM. Anche se la DRAM ha una latenza di nanosecondo e offre capacità e prestazioni notevoli, ha limitazioni fisiche come la densità di memoria e la quantità che è possibile inserire in un server. È anche relativamente costosa. Più importante ancora, è volatile e, man mano che i dati diventano più grandi, la volatilità della memoria diventa un vincolo. PMEM rimuove questi vincoli perché consente di avere una capacità maggiore, costi inferiori e persistenza.\n\nUn importante vantaggio è che le aziende non hanno bisogno di riscrivere le loro applicazioni per utilizzare la tecnologia di MemVerge. L'azienda stava cercando il modo migliore per utilizzare la persistenza e la risposta è stata quella di offrire la minor interruzione ai paradigmi di programmazione. Quando Optane PMEM è diventato disponibile come formato di memoria, è stata un'opportunità per sviluppare software prezioso come parte della soluzione.\n\n## Memoria definita dal software.\n\nC'è una trasformazione dei dati in corso. Dal punto di vista hardware, nei prossimi dieci anni ci sarà probabilmente un mondo più eterogeneo, sia nei calcoli che negli elementi di memoria. Emargerà una nuova tessitura, come CXL, che collega questi elementi. La sfida più grande sarà far muovere l'ecosistema delle applicazioni. È necessario uno strato software per elaborarlo in parti consumabili e componibili che facilitino l'assimilazione dell'applicazione. La memoria definita dal software di MemVerge sarà un componente importante in questo ambito.\n\nNel frattempo, MemVerge sta costruendo un ponte tra i paradigmi attuali e futuri. La Memoria definita dal software di MemVerge porta SLA dinamiche e QLS, resilienza, persistenza delle applicazioni, efficienza e prestazioni. Queste sono tutte cose che normalmente si ottengono con una rete di archiviazione definita dal software, ma ora si possono ottenere con la memoria con una latenza inferiore e una velocità altissima.\n\n## Prestazioni sulla Memory Machine\n\nDue importanti proprietà intellettuali di MEMVerge sono in gioco. La prima è un livello di virtualizzazione software che ottimizza le prestazioni della memoria - la combinazione di PMEM e DRAM - che è molto vicina alle prestazioni della DRAM. Ogni carico di lavoro ha profili prestazionali diversi che possono essere ottimizzati mescolando PMEM e DRAM a diverse proporzioni. Questa ottimizzazione della PMEM e DRAM offre agli sviluppatori di applicazioni e ai professionisti IT la capacità di regolare la memoria per le loro applicazioni anziché per l'intera macchina. Invece di configurare le proporzioni esistenti di DRAM e PMEM per l'intera macchina, ora è possibile cambiare dinamicamente le proporzioni di PMEM e DRAM in base al carico di lavoro, e persino superare le prestazioni della DRAM.\n\n## ZeroIO Snapshot (Persisting Application Data) in Italian is:\n\nZeroIO Snapshot (Conservazione dei dati dell'applicazione)\n\nIl secondo di questi inventi è rappresentato dai \"memory snapshots\" o ZeroIO. Esso consente di persistere le applicazioni transienti esistenti senza necessità di riscrivere il codice. Funziona in cima alla memoria definita dal software, che è un servizio di memoria volatile. Nonostante la PMEM sottostante sia persistente, la memoria volatile è necessaria per evitare di compromettere le applicazioni esistenti. La persistenza viene sfruttata attraverso l'offerta di un'interfaccia grafica (GUI) e CI (interfaccia a linea di comando) per la gestione degli snapshot. È possibile creare uno snapshot per catturare istantaneamente lo stato di un'intera applicazione. Quindi, tale applicazione può essere recuperata in qualsiasi momento futuro.\n\nQuesto rende la tua memoria non solo persistente, ma anche altamente disponibile. Dopo un crash, puoi fare un ripristino istantaneo. Se fai un errore nel database, puoi tornare indietro a un punto precedente. Puoi anche clonare oltre al punto di ripristino, quindi puoi creare nuove istanze di un'applicazione senza replicare fisicamente la memoria. Puoi quindi creare più processi indipendenti e gli spazi di memoria logica si mappano sullo stesso spazio di memoria fisica. Questo non solo risparmia memoria, ma rende anche istantaneo il processo di creazione di cloni. Questa nuova tecnologia rende possibili molte cose che prima erano impossibili.\n\nNon ci sono modifiche architettoniche al tuo programma, ma quando hai bisogno di persistere qualcosa, puoi semplicemente fare una snapshot. Questo non cambia il modello familiare di programmazione, ma accelera notevolmente l'I/O. Un'altra grande caratteristica è che le snapshot diventano oggetti gestibili, quindi sono trasportabili ovunque tu possa riavviare l'applicazione. La migrazione in tempo reale può essere abilitata anche in determinati scenari.\n\n## Casi d'uso abilitati per il futuro\n\nPer uno sguardo furtivo al futuro, MemVerge sta pianificando una versione 2.0 tra circa un anno, che avrà un SDK. Oltre a utilizzarlo come uno strato di memoria trasparente, i nuovi sviluppatori di applicazioni avranno un nuovo modo di persistere i loro dati. Questo renderà lo sviluppo di applicazioni, così come la modifica delle applicazioni esistenti, più semplice.\n\nCon l'SDK gli sviluppatori saranno in grado di catturare istantanee di segmenti della memoria dell'applicazione o dell'intero profilo di memoria, offrendo all'applicazione stessa la possibilità di memorizzare la memoria in modo persistente tramite le complesse tecnologie ORM o di mappatura di memoria attuali.\n\nIn collaborazione con Intel, MemVerge lancerà la prima versione del loro prodotto con la memoria definita dal software e le capacità di snapshot per la disponibilità generale il 23 settembre 2020.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Charles Fan"],"link":"/episode-EDT21-it","image":"./episodes/edt-21/it/thumbnail.png","lang":"it","summary":"Charles Fan, CEO di MemVerge, parla con Darren Pulsipher, Chief Solutions Architect, Settore Pubblico, Intel, sulla loro nuova tecnologia, i controller di memoria software-defined Big Memory. La tecnologia utilizza la memoria persistente Intel 3D XPoint Optane per colmare efficientemente il divario tra le architetture attuali e future, offrendo una capacità maggiore, costi più bassi e persistenza."},{"id":91,"type":"Episode","title":"Un argomento a favore del cloud multi-ibrido","tags":null,"body":"\r\n\r\n## Ambiente Cloud attuale.\n\nNegli ultimi cinque anni, c'è stato un cambiamento fondamentale nell'ambiente IT. La crescita continua del Public Cloud e l'emergere delle opzioni Private Cloud hanno lasciato molti CIO e dipartimenti IT a cercare di recuperare il ritardo. Nel mercato competitivo di oggi, molti team di sviluppo devono muoversi più velocemente di quanto la maggior parte dei dipartimenti IT possa fornire. I team di sviluppo hanno trovato nei Public Cloud come AWS, GCE e Azure una valida opzione per l'ormai obsoleto \"IT da tavolo\" o \"IT casalingo\". I fornitori di cloud pubblico hanno reso facile e veloce \"avviare\" nuova infrastruttura. Non è più necessario aspettare l'approvazione tecnica e commerciale da più livelli, lo spazio fisico nel data center e i problemi di fornitura del venditore. Ora, in pochi minuti, un team di sviluppo può avere tutta l'infrastruttura di cui ha bisogno per il suo nuovo progetto.\n\nPrima del Cloud Pubblico, i CIO(s) potevano facilmente \"girare attorno\" ai cubi e contare il numero di macchine \"cottage IT\" che giravano sotto le scrivanie delle persone. Con le macchine fisiche ormai invisibili per i dipartimenti IT, diventa impossibile identificare i team e le infrastrutture dei loro progetti. Molte piattaforme di cloud pubblico hanno dato alle organizzazioni la capacità di consolidare la contabilità di tutti gli account per specifici domini, ma la visibilità su cosa sta funzionando e su chi sta lavorando all'infrastruttura è ancora un po' come cercare un ago in un pagliaio. Molte volte questi progetti \"fuorilegge\" diventano visibili quando i progetti vengono prodotti e devono essere inseriti in un'infrastruttura protetta aziendale. Le politiche di sicurezza, privacy e regolamentazione possono rendere quasi impossibile la \"produttività\" dei progetti. Soprattutto se gli sviluppatori hanno strettamente accoppiato le loro applicazioni all'infrastruttura Cloud.\n\nI dipartimenti IT orientati al futuro stanno facendo del loro meglio per acquisire il \"cottage IT\" lavorando con Cloud Pubblici e ISV per creare dei \"portali aziendali\" nel Cloud. Mettere in atto un portale di passaggio è un buon inizio per catturare progetti utilizzando infrastrutture, ma molte organizzazioni trovano che un semplice portale non soddisfi le esigenze dei team di sviluppo. Negli ultimi anni ho lavorato con molte di queste organizzazioni per identificare casi d'uso, architetture e tecnologie per aiutare nello sviluppo di questi portali potenziati che abbiamo chiamato \"Hybrid Multi-Clouds\" (MHC). Tipicamente, tre tecnologie principali vengono integrate insieme per costruire questi MHC. Piattaforme di Gestione del Cloud (CMP), Framework di Automazione e strumenti Platform as a Service (PaaS).\n\n## Piattaforma di Gestione del Cloud (CMP)\n\nLa responsabilità principale delle piattaforme di gestione del cloud è gestire più cloud eterogenei, sia pubblici che privati. Offrono agli utenti finali la possibilità di gestire più cloud e le relative infrastrutture da un'unica interfaccia comune. Le CMP solitamente sono progettate con un'attenzione specifica agli amministratori di cloud. Sebbene lo strumento delle piattaforme di gestione del cloud si concentri principalmente sulla gestione di più cloud, molti strumenti hanno aggiunto funzionalità dai PAAS e dai framework di automazione, o hanno almeno un'architettura di plugin per supportarli.\n\n## Utilizzo dei casi coperti.\n\nGestione di Cloud Pubblici\n\nGestire le Cloud Privati\n\nGestione delle identità cloud\n\nGestione dell'infrastruttura su più cloud.\n\n## Framework di automazione\n\nIl primario compito di Automation Frameworks è automatizzare il rilascio, la gestione e l'aggiornamento degli stack software sull'infrastruttura. Automation Frameworks sono nati dalla comunità DevOps e sono tipicamente focalizzati su processi ripetibili. Molti di questi strumenti includono linguaggi di scripting che consentono agli ingegneri DevOps di gestire e configurare in modo ripetibile software e servizi. Molte squadre DevOps sono esperte in questi strumenti.\n\n## Casi d'uso coperti\n\nDeploy software on infrastructure: Distribuire il software sull'infrastruttura.\n\nGestire software sull'infrastruttura.\n\nAggiornamento di software e servizi\n\n## Piattaforma come servizio (PAAS)\n\nLa piattaforma come servizio (PaaS) è principalmente responsabile di fornire un unico portale per riutilizzare piattaforme e distribuirle su infrastrutture. Gli strumenti PaaS sono tipicamente altamente orientati verso lo sviluppatore, il che può portare a configurazioni di infrastruttura inflessibili. Molti di questi strumenti dispongono di un portale web che consente agli sviluppatori di selezionare i servizi e distribuirli nell'infrastruttura.\n\n## Casi d'uso coperti.\n\n* Deploy/Manage Services/Applications in Italian can be translated as:\n* Distribuire/Gestire Servizi/Applicazioni\n\nGestire il Catalogo dei Servizi\n\nSviluppare nuovi servizi/applicazioni\n\n## La convergenza crea il Multi-Cloud Ibrido (MHC)\n\nPoiché nessun set di strumenti dispone di tutti i casi d'uso necessari per gestire nuvole, applicazioni, infrastrutture e servizi, i team impiegano diversi \"anni uomo\" per installare, configurare e integrare questi tre set di strumenti insieme. Ciò ha portato all'emergere di tecnologie che integrano questi strumenti, inclusi nuovi prodotti e nuove funzionalità nei prodotti attualmente disponibili.\n\nMolti prodotti CMP stanno includendo PaaS e Framework di Automazione nelle loro soluzioni. Gli strumenti PaaS stanno ora gestendo più nuvole. I Framework di Automazione stanno cominciando ad offrire portali web e connettività a più nuvole. Molti degli strumenti si stanno spostando verso la visione Hybrid Multi-Cloud. Quando si valuta quale/e strumento/i utilizzare, è importante ricordare le radici dello strumento.\n\n## Implementare una soluzione\n\nL'ecosistema Hybrid Multi-Cloud è ancora abbastanza nuovo e richiede ancora alcune integrazioni complesse tra gli strumenti. Ci sono alcuni strumenti che stanno iniziando a offrire soluzioni complete pronte all'uso, ma ancora con la loro particolare visione del mondo. Poiché l'ecosistema è ancora in fase embrionale, ci sono molti attori e scelte. Il tempo dirà chi vincerà in questo settore. Per ora, sarà interessante osservare la convergenza e la consolidazione degli strumenti mentre le funzionalità si sviluppano.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT22-it","image":"./episodes/edt-22/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher descrive perché un architetto di Multi-Hybrid Cloud potrebbe già essere nel tuo Data Center. La maggior parte delle organizzazioni ha già tutti gli ingredienti. Devono solo capire come si integrano tra loro."},{"id":92,"type":"Episode","title":"Creazione di intuizioni nelle organizzazioni incentrate sui dati","tags":["aiml","dataarchitecture","datacentric","data","insight","technology"],"body":"\r\n\r\nUtilizzando come esempio la produzione di widget, Darren e Sarah hanno precedentemente discusso del flusso di dati nel tentativo di rispondere a una domanda fondamentale per il business: Quanti widget produrre. La complessità diventa evidente quando si tratta di prendere i dati grezzi della domanda dei clienti, dell'offerta attuale e della perdita di resa e trasformarli in informazioni.\n\nIl primo passo di questo processo, prima di poter decidere quali strumenti utilizzare, consiste nel preparare i dati in una forma utilizzabile. L'ottanta o novanta percento del lavoro di uno scienziato dei dati consiste nella preparazione e trasformazione dei dati in modo che possano essere inseriti in un algoritmo, ad esempio, o utilizzati per il riconoscimento di pattern.\n\nGli strumenti corretti sono complessi. Intelligenza artificiale e apprendimento automatico non utilizzano un singolo algoritmo, ma una pletora di strumenti che gli scienziati dei dati usano e sperimentano in combinazioni per ottenere i migliori risultati di analisi. In altre parole, un singolo algoritmo non ti dirà quanti widget dovresti produrre. Ci sono molte parti sovrapposte e gli strumenti stessi sono complessi. Inoltre, gli scienziati dei dati hanno diverse aree di specializzazione; la scienza dei dati è uno sport di squadra. Proprio come non assegneresti a un ingegnere di rete la progettazione dell'architettura di archiviazione, non impiegheresti un ingegnere di deep learning specializzato nel riconoscimento delle immagini per risolvere il problema dell'analisi di rendimento. Devi assumere gli scienziati dei dati giusti per progettare e implementare gli strumenti giusti per ottenere un'analisi dei tuoi quesiti aziendali.\n\nTorniamo alla questione di quante widget dovresti produrre. Ogni situazione e modello saranno ovviamente diversi in base ai tipi di domande, dati e dinamiche che hai, ma useremo questo come punto di partenza. Una volta stabilita questa domanda aziendale, l'organizzazione passerà attraverso uno sviluppo di maturità analitica.\n\nInnanzitutto, ti concentrerai su ciò che è accaduto in passato per individuare i modelli nella domanda dei tuoi widget. Ad esempio, potresti analizzare dati in serie storiche per capire quando la domanda di widget aumenta o diminuisce. Quanto stabile è l'informazione nel tempo e come puoi utilizzarla per fare previsioni sul futuro? Forse potresti utilizzare l'apprendimento automatico per analizzare differenti segmenti temporali e comprenderli. Potresti anche voler fare un'analisi del testo per capire se le persone parlano dei tuoi widget sui social media. Il numero di like o condivisioni potrebbe essere una fonte di dati.\n\nPotresti fare qualcosa di simile con l'approvvigionamento. Quanto stabile è l'attuale approvvigionamento e quanto bene comprendi la dinamica del sistema? Guarda dove hai bisogno di un essere umano per capire la dinamica del sistema e incorpora quella conoscenza nel modo in cui fai le tue analisi. Potrebbero esserci alcuni modelli di apprendimento automatico che ti danno delle idee di intuizione, quindi potresti fare dell'apprendimento non supervisionato. L'apprendimento non supervisionato consiste nel trovare se ci sono diverse categorie o segmenti di cui non sei consapevole che si comportano in modo diverso l'uno dall'altro. Chiediti come puoi tracciare meglio o ottenere una migliore risoluzione di ciò che sta accadendo in questi gruppi.\n\nIn breve, a seconda da dove provengono i dati e da cosa stai analizzando in quei dati, utilizzerai strumenti diversi.\n\nLa perdita di rendimento è un esempio della complessità dei problemi da risolvere. Più variazione nella linea di produzione, più sprechi possono verificarsi. In questo caso, il machine learning analizzerà segmenti e cluster di diversi tipi di rendimenti. Come si può quantificare e prevedere ciò?\n\nUna cosa che i data scientist fanno qui è il design degli esperimenti per cercare di stimare la causalità. Girando manopole e azionando leve in modo sistematico, puoi vedere cosa succede al rendimento, aggiungendo allo stesso tempo controlli di processo per evitare deviazioni.\n\nUn'altra opportunità per condurre analisi è l'affidabilità. Ad esempio, con la manutenzione predittiva, i tuoi strumenti di produzione possono essere mantenuti tempestivamente per evitare perdite nella produzione. Puoi inoltre utilizzare l'analisi dei testi in determinate situazioni, ad esempio quando hai registrazioni scritte di osservazioni e soluzioni dei tecnici nel tempo da utilizzare come base di conoscenza collettiva.\n\nIl deep learning nell'ambito del riconoscimento delle immagini è un'altra strategia per aiutare a prevenire perdite mediante la rilevazione di errori e difetti, e forse anche la categorizzazione dei difetti.\n\nL'obiettivo di tutto questo è, naturalmente, acquisire preziose intuizioni commerciali per la tua organizzazione. La chiave è l'impegno verso un'organizzazione incentrata sui dati, rimanendo flessibili e avendo gli strumenti e le persone giuste per trasformare i tuoi dati in intuizioni operative.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT23-it","image":"./episodes/edt-23/it/thumbnail.png","lang":"it","summary":"Nella parte 5 di una serie, Kick-starting your Organizational Transformation to Become Data Centric, Sarah Kalicin, Lead Data Scientist, Intel, e Darren Pulsipher, Chief Solutions Architect, Public Sector, Intel, discutono di come creare conoscenze utilizzando l'IA e l'apprendimento automatico in un'organizzazione orientata ai dati."},{"id":93,"type":"Episode","title":"Strategia digitale e architettura dei dati","tags":["data","dataarchitecture","aiops","secops","devsecops","devops","compute","technology","process"],"body":"\r\n\r\nAvere un piano per la trasformazione digitale della tua organizzazione è essenziale per evitare di perdersi nel labirinto dell'adozione indiscriminata delle più recenti e innovative tecnologie e processi. Questa strategia improvvisata farà sì che la tua trasformazione digitale naufraghi. Un piano, o una roadmap, che delinei il percorso dalla situazione attuale della tua organizzazione a quella desiderata, è la parte più importante di una trasformazione efficace.\n\nI tre elementi chiave che devono essere coordinati e bilanciati nel tuo piano sono organizzativi, procedurali e tecnologici.\n\n## Divisioni organizzative\n\nPer comprendere il cambiamento organizzativo, analizziamo innanzitutto i gruppi comuni presenti nella maggior parte delle organizzazioni.\n\n## Sviluppo\n\nQuesto gruppo è il tuo team diurno; stanno sviluppando nuovi prodotti. I processi del team di sviluppo sono ben conosciuti e maturi. Si concentrano sul lavoro di sviluppo, testing e spingere il prodotto in produzione. Quasi ogni team utilizza qualche tipo di tecnica Agile o di iterazione rapida.\n\n## Translate the following to Italian: IT\n\nTraduci quanto segue in italiano: IT\n\nL'obiettivo del team IT è ottimizzare l'infrastruttura in termini di costo ed efficienza. Si assicurano che l'infrastruttura sia affidabile e abbia controlli di sicurezza integrati. Principalmente, si focalizzano sul calcolo, lo stoccaggio, la rete, la conformità e il costo.\n\n## Sicurezza\n\nIl ruolo della sicurezza è diventato sempre più importante negli ultimi anni, ancor di più recentemente con i dipendenti che lavorano da casa a causa del COVID-19. Il team di sicurezza si concentra principalmente sulla protezione della proprietà intellettuale, dei dati e delle infrastrutture. Gli strumenti comuni sono la gestione delle identità, la protezione, il rilevamento e la risoluzione dei problemi. Comprendere come funzionano questi strumenti a un livello più elevato è importante per il cambiamento organizzativo.\n\n## Data can be translated to Italian as \"Data\".\n\nQuesto nuovo gruppo, che in precedenza poteva essere uno statistico o un matematico che faceva del data mining, sta prendendo piede con l'avvento di chief data officers e delle organizzazioni che si costruiscono attorno a loro. Si concentrano sull'analisi, la categorizzazione e la consegna di un valore reale dai tuoi dati. Che la tua organizzazione sia nel settore manifatturiero o dei servizi, o che tu stia cercando di acquisire nuovi clienti o risparmiare denaro, ci sono molte aree in cui i data scientist possono fornire valore.\n\n## Portare insieme i gruppi\n\nPer apportare un efficace cambiamento digitale, tutti questi gruppi devono avere una comprensione reciproca di ciò che ciascuno porta sul tavolo e una visione unificata. Non si desidera che i vostri scienziati dei dati esplorino dati che non hanno valore per lo sviluppo o l'IT. Non si desidera che il team di sicurezza blocchi tutto così sicuro che il team di sviluppo non possa completare il proprio lavoro. Tra i gruppi, devono esserci strategie, processi e architetture comuni.\n\nAnche se gli obiettivi comuni e i risultati sono l'ideale, ci sono ostacoli da superare. Una delle aree più difficili nel cambiamento organizzativo è la rottura della comunicazione ai confini. Alcune organizzazioni hanno creato nuovi gruppi per attenuare i conflitti tra i vari gruppi. Ad esempio, tra sicurezza e IT, potrebbe esserci un team di Sec Ops o Sec Dev Ops dove si automatizzano le politiche e le procedure che emergono dal team di sicurezza. Un altro esempio potrebbe essere un team di Data Dev, che sono sviluppatori che lavorano con gli scienziati dei dati per fornire processi più ripetibili attraverso lo sviluppo di applicazioni o l'integrazione di strumenti e applicazioni. Architetture comuni e set di strumenti comuni su cui tutti i gruppi possono fare affidamento rendono il processo e i cambiamenti molto più facili.\n\n## Il sistema perfetto\n\nCome sarebbe un'architettura comune? Una versione utopica non esiste oggi, ma possiamo osservare gli elementi e forse costruire qualcosa verso questo ideale.\n\nL'auto-servizio è indispensabile. Ad esempio, se un data scientist ha bisogno di più spazio di archiviazione per i dati, non dovrà chiamare il reparto IT e compilare una serie di moduli, ma potrà utilizzare invece un pratico portale di auto-servizio che fornirà lo spazio di archiviazione richiesto, risparmiando tempo. Naturalmente, il portale sarà gestito secondo le politiche aziendali, in modo che il team di sicurezza possa stare tranquillo, sapendo che i dati confidenziali inseriti dallo scienziato saranno crittografati e che il controllo degli accessi sarà automatico.\n\nUn'altra caratteristica ideale sarebbe che il sistema sia auto-riparante e basato sui dati. Se le macchine venissero infettate, ad esempio, verrebbero automaticamente messe in quarantena e i carichi di lavoro verrebbero migrati in un'altra area nel data center o nel cloud pubblico. Ancora una volta, l'IT dovrebbe stabilire le politiche e monitorare i processi, ma il sistema sarebbe per lo più automatico. Il sistema non dovrebbe essere solo automatico, ma anche intelligente, imparando dall'esperienza e diventando sempre più efficiente.\n\nPossiamo ottenere alcuni elementi di questo sistema utopico oggi con prodotti pronti all'uso integrandoli e convincendo tutti ad utilizzarli. Analizziamo cosa desidererebbe ciascuna organizzazione da questa architettura.\n\n## Architettura IT (Multi-Hybrid Cloud)\n\nIT è responsabile dell'infrastruttura di base e delle informazioni sui dati all'interno dell'organizzazione. Se l'IT potesse stabilire una base solida come una roccia, tutti gli altri potrebbero costruire sopra di essa. L'IT ha bisogno di passare a una soluzione di cloud multi-ibrido in modo che l'infrastruttura possa essere facilmente orchestrata secondo necessità, con flessibilità basata sulle politiche. C'è sempre un compromesso tra costo e affidabilità, ma hai delle opzioni. Uno strato di infrastruttura definito dal software consente facilmente l'orchestrazione di calcolo, archiviazione, rete, sicurezza e ora anche nuovi elementi come memoria e acceleratori. La fondazione multi-ibrido di cloud è un aspetto chiave della tua architettura comune.\n\n## Architettura della sicurezza\n\nIl team di sicurezza aggiungerà a questo sistema e lo renderà il più automatizzato possibile. Il primo sarebbe l'aspetto dell'identità. Questo significa che non solo puoi identificare gli utenti, ma anche l'infrastruttura, le applicazioni e i servizi in modo che tutto abbia un'identità. Queste identità possono essere legate a autorizzazioni specifiche e accessi per assicurarsi che tutto sia autenticato. Dal lato della sicurezza, si desidera crittografia e rimedio quando ci sono problemi. Idealmente, si potrebbe stabilire una radice di fiducia in modo che tutto nell'ecosistema, sia nelle applicazioni e nei servizi, sia fino ai firmware e al BIOS nelle macchine, sia fidato.\n\n## Architettura dello sviluppo\n\nI developer potrebbero preoccuparsi del fatto che tutto questo processo possa rallentare lo sviluppo, quindi è necessario che avvenga in modo pressoché automatico. La maggior parte dei developer ora si concentra su componenti riutilizzabili che possono essere testate in modo da garantirne la sicurezza. Fanno ciò attraverso ecosistemi su contenitori come Kubernetes, Docker o Mesos. La sicurezza può essere integrata nel ciclo di sviluppo nella fase di distribuzione prima di passare con successo alla produzione. Sopra al livello di servizio c'è un livello di applicazione in cui i developer possono sfruttare i flussi di lavoro. Questi flussi di lavoro possono essere flussi di lavoro di sviluppo come CI/CD o flussi di lavoro aziendali attraverso strumenti di automazione come l'automazione dei processi robotizzati. Avere sia il livello di servizio che il livello di applicazione sono elementi chiave in questa architettura utopica.\n\n## Architettura dei dati\n\nCon dati sparsi su diversi ecosistemi, cloud pubblici e persino in periferia, abbiamo bisogno di un modo migliore per gestire i dati per gli scienziati dei dati e i sviluppatori di applicazioni. Estrarre i dati dallo storage è uno degli elementi importanti qui. Con questa struttura, puoi orchestrare i dati su tutta l'ampia infrastruttura e collegare quei dati solo alle applicazioni e ai servizi dove sono necessari. I dati potrebbero essere astratti per atterrare sull'infrastruttura nel posto migliore durante quel periodo di tempo, che sia in periferia, nel data center o elaborato in diversi luoghi per le repliche dell'applicazione. La sicurezza sarebbe necessaria per proteggere i dati, poiché i dati sono il motivo dell'infrastruttura in primo luogo. Alcune start-up sono ora in questo settore, per prendere il controllo del livello di gestione dei dati.\n\nQuesta architettura utopica, con la sua miriade di componenti in movimento, viene chiamata architettura Edgemere. Stiamo cercando di capire come tutte queste parti si combinano per aiutare le organizzazioni ad accelerare la loro trasformazione digitale. Abbiamo bisogno di capire cosa ogni organizzazione ha bisogno, quali sono i loro casi d'uso e quali sono le somiglianze tra i gruppi per creare un'architettura in cui l'intera organizzazione possa lavorare.\n\nIl compito della vostra organizzazione è rompere le barriere tra i gruppi, sviluppare una visione comune di dove desiderate essere dal punto di vista organizzativo, procedurale ed architettonico e sviluppare una roadmap su come raggiungerlo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT24-it","image":"./episodes/edt-24/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Settore Pubblico, Intel delinea la strategia digitale e l'architettura per trasformare efficacemente la tua organizzazione. Spiega come gli elementi organizzativi, procedurali e tecnologici debbano essere bilanciati per lavorare in modo efficiente verso un'architettura comune ed ideale per supportare una visione unificata."},{"id":94,"type":"Episode","title":"Operazionalizzare i flussi di dati","tags":["dataarchitecture","datacentric","data","datamesh","datapipeline","technology","people"],"body":"\r\n\r\nPer l'ultimo episodio di questa serie, Darren parla con Sarah Kalicin, Lead Data Scientist presso Intel, riguardo all'operazionalizzazione del tuo flusso di dati. Discutono di come, una volta ottenute le tue informazioni sui dati, puoi trasformarle da un esperimento scientifico a tempo determinato in una fonte continua di informazioni.\n\n## Come operazionalizziamo le intuizioni analitiche?\n\nLa prima cosa da comprendere riguardo al data pipeline è che non è come un sistema elettrico chiuso che puoi installare, dimenticare e sei mesi dopo premere un interruttore sapendo che la lampadina si accenderà. Un data pipeline è diverso perché i dati sono variabili; possono cambiare o degradare, ad esempio, quindi non sarai necessariamente ricompensato con l'accensione della lampadina in nessun momento, o in questo caso, l'approfondimento che stai cercando. Devi sempre pensare a ciò che può andare storto nel sistema e come correggere questi cortocircuiti.\n\nRilevare anomalie è parte integrante del processo. Non si può pianificare tutto, ma almeno è necessario essere in grado di riconoscere quando qualcosa è accaduto al di fuori dei limiti delle analisi originali. Un esempio è la crisi del COVID, un evento imprevedibile che ha causato schemi molto diversi dalla norma per molti sistemi. Un altro esempio potrebbe essere un'azienda produttrice di widget. Per sapere quanti widget produrre, il flusso di dati contiene la domanda dei clienti, la fornitura attuale e la perdita di rendimento. Questi dati potrebbero essere abbastanza stabili nel tempo, ma potrebbe verificarsi, ad esempio, un evento di pubbliche relazioni che provoca un'esplosione della domanda dei clienti. Questo potrebbe influire notevolmente sui modelli. L'apprendimento automatico e l'apprendimento profondo osservano schemi familiari e, se non hanno mai visto questi schemi prima, i modelli avranno problemi o si degraderanno. Bisogna rimanere sull'orlo della scoperta.\n\nL'unico modo per restare al passo con le scoperte è automatizzare le tue condotte di dati per un accesso tempestivo alle informazioni. Questo è il vantaggio competitivo: dati aggiornati e illuminanti che possono aiutarti a risolvere rapidamente le tue domande.\n\nLe squadre IT e le squadre di dati devono collaborare sull'automazione e determinare cosa deve essere automatizzato per i dati in arrivo e sulla gestione di eventuali modifiche al modello che gli scienziati dei dati desiderano apportare in modo che possa essere facilmente integrato nel flusso di lavoro.\n\n## Dispiego brevi circuiti\n\nCi sono due tipi di controlli che possono prevenire i cortocircuiti nella distribuzione: i controlli del sistema analitico e i controlli organizzativi.\n\nIl controllo del sistema analitico si tratta di mettere in funzione i modelli che hai addestrato, alimentando i dati per rispondere facilmente alle tue domande. Questi modelli implementati devono essere moderati per verificare l'accuratezza dei dati. Molte cose possono causare un impatto negativo sui dati, come i cambiamenti ambientali, la calibrazione delle macchine, problemi di distribuzione e così via.\n\nCiò non è così diverso dal mondo dello sviluppo software in cui i cambiamenti possono influenzare le previsioni. Il dipartimento IT è familiare con il processo di esecuzione dei test per assicurarsi che i loro modelli o applicazioni funzionino secondo le linee guida stabilite, quindi i dev ops e gli scienziati dei dati dovrebbero approfittare di queste risorse e conoscenze. Non c'è bisogno di inventare nuovi processi, ma invece, i gruppi dovrebbero unire le risorse per prepararsi al successo.\n\nI controlli organizzativi risalgono a una fondazione organizzativa che si impegna ad essere centrata sui dati e a fornire le persone e le risorse corrette per lavorare insieme verso obiettivi comuni. La migliore possibilità per ottenere l'operazionalizzazione si verifica quando c'è collaborazione, fiducia, comprensione delle esigenze e loop di feedback tra i gruppi all'interno dell'organizzazione.\n\nI cicli di feedback sono fondamentali in questo processo. Ad esempio, gli specialisti della materia possono fornire informazioni sulle dinamiche di mercato in modo che gli scienziati dei dati possano monitorare il modello per queste variazioni nei dati. Se un modello verrà utilizzato nel tempo, avrà sempre bisogno di essere iterato e migliorato costantemente.\n\nI consumatori dei dati dovrebbero avere un cruscotto che fornisce loro informazioni e consente loro di approfondire il motivo per cui qualcosa sembra un po' strano. Più possono indagare o sollevare ciò che deve essere indagato, più la vostra organizzazione si sentirà autonoma.\n\n## Pipeline\n\nUna chiave dal lato IT per operazionalizzare la pipeline dei dati è utilizzare un controllo delle versioni come GitHub, in modo da poter avere accesso alle versioni precedenti del tuo modello. Per scopi di controllo, è altrettanto importante poter archiviare i dati che hanno creato il modello e altri dati storici. Si desidera essere in grado di osservare i pattern e vedere come una determinata caratteristica è cambiata o ha influenzato il modello. È anche possibile inserire dati storici nei nuovi modelli per vedere quanto influiscono sui dati attuali.\n\nAd esempio, alcuni sistemi avranno una visione distorta con un numero elevato di persone che lavorano da casa durante la pandemia di COVID-19. Un esempio è la Marina. Da quando è iniziata la pandemia, il 95% dei loro dipendenti IT lavora da remoto e la loro produttività è aumentata del 35%. Da questo singolo dato, potremmo dire che tutti lavoreranno da casa da ora in poi. Riuscirai a mantenere un aumento del 35% o, se le persone torneranno in ufficio, vedrai una diminuzione del 35%? Ovviamente, questo singolo dato non è necessariamente sufficiente per prevedere la produttività effettiva.\n\nUn altro strumento che l'IT può offrire è l'integrazione e il deployment continui. Utilizzando Jenkins o GitHub Actions o un tool simile durante il lavoro su un modello, è possibile eseguire automaticamente test sul modello con i propri dati o generare dati di prova al volo.\n\nLe persone di IT e gli scienziati dei dati devono collaborare su cosa e come monitorare l'output dei modelli. IT può monitorare l'output automaticamente e possono anche monitorare le prestazioni dei modelli nell'infrastruttura. Un esempio è che IT, con la distribuzione automatizzata di integrazione continua, può avvertire rapidamente gli scienziati dei dati quando un modello richiede più tempo del normale per evitare che sfugga al controllo. Se IT è interessato alla creazione di valore dei dati, che è generalmente mancante nell'intero settore, il processo sarà più facile e coerente per tutti.\n\nUn altro aspetto da considerare è il disegno degli esperimenti, poiché le interazioni tra variabili e caratteristiche sono altrettanto importanti. Gli esperti del settore possono aiutare a determinare quali sono le potenziali interazioni, e tu puoi modellarle per comprendere quale variabilità ci si può aspettare.\n\nÈ emozionante che un data scientist possa prendere materiale grezzo e trasformarlo in conoscenza. Tuttavia, richiede un team. Più tutti nell'organizzazione possono imparare gli uni dagli altri in un ambiente di squadra, più cose straordinarie possono accadere.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Kalicin"],"link":"/episode-EDT25-it","image":"./episodes/edt-25/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Pubblico Settore, Intel, parla con Sarah Kalicin, Lead Data Scientist, Intel, sulla operazionalizzazione del data pipeline dell'organizzazione. È necessario un lavoro di squadra per modellare, monitorare e produrre una continua fonte di informazioni preziose. Questo è l'episodio finale della serie Kick-starting your Organizational Transformation to Become Data-Centric."},{"id":95,"type":"Episode","title":"Soluzioni dati Multi Cloud con Hammerspace","tags":["hammerspace","data","technology","dataarchitecture","multicloud","compute","multihybridcloud","datamesh"],"body":"\r\n\r\nL'archiviazione è pronta per la sconvolgimento. Attualmente, la gestione dei dati avviene in modo ingombrante, procedurale e spesso manuale e incline agli errori. Hammerspace è stata fondata per risolvere questo problema astrayendo i dati dall'infrastruttura di archiviazione.\n\n## Immagina per un attimo...\n\n...se i tuoi dati fossero separati dall'infrastruttura di archiviazione. Liberi dai limiti imposti dai sistemi di archiviazione attuali, gli utenti potrebbero gestire e proteggere i propri dati in autonomia, modificare istantaneamente il profilo dei costi e accedere ai dati da qualsiasi punto dell'infrastruttura. L'archiviazione definita dal software potrebbe garantire prestazioni scalabili su richiesta e consentire lo sviluppo di carichi di lavoro moderni come Kubernetes su qualsiasi infrastruttura sottostante, ovunque essa sia.\n\n## La sfida\n\nLe applicazioni sono diventate portatili, ma i dati sono ancora segregati. La sfida consiste nel fatto che le prestazioni, l'affidabilità e la gestibilità ne soffrono tutte a causa del problema della segregazione. La soluzione consiste nel liberare i dati dalle limitazioni dell'infrastruttura sottostante. Hammerspace fa ciò attraverso la disgregazione dei metadati, assimilando le parti costituenti più piccole per rendere i dati portatili.\n\n## Scollegare i dati dallo storage\n\nCon questa tecnologia, le tue app dispongono di dati su richiesta ovunque tu sia. Hai un controllo indipendente, piani di dati e uno spazio dei nomi globale e un sistema di archiviazione che si estende su più centri dati e cloud. Lo storage è orchestrato; i dati sono completamente automatizzati e sfruttano una gestione dei dati autonoma dichiarativa. In altre parole, separa il \"come\" dal \"cosa\", dichiarando lo stato finale desiderato senza dover delineare ogni dettaglio su come arrivarci.\n\n## Architettura Hammerspace\n\nIl sistema consente di operare a livello di file in modo granulare, fornisce servizi di dati di classe enterprise come snapshot e cloni, e si sposta facilmente su una scala massiva da un data center all'altro, da un data center al cloud e poi di nuovo dal data center alla dispersione in uno scenario di multi-hybrid cloud.\n\n## L'archiviazione tradizionale non è in grado di superare le sfide moderne.\n\nL'archiviazione legacy non scala in modo sufficiente, neanche con soluzioni di scalabilità orizzontale, su cloud o su scala planetaria, perché anche quei cluster diventano silos, lasciandoti a volte bloccato con dati che non possono essere correlati ed analizzati. L'archiviazione tradizionale ha anche difficoltà a scalare capacità e prestazioni in modo indipendente.\n\nLa replica è una tecnologia antica che porta alla proliferazione dei dati copiati. Invece di spostare le più piccole parti costituenti, si sta spostando l'intero carico utile. La gestione dei dati è spesso un dopo-pensiero; la gestione dei dati dovrebbe avere la priorità, non essere una questione secondaria.\n\nUn problema che l'architettura di Hammerspace risolve è trovare facilmente le cose. La gestione delle versioni può portare a grandi problemi aziendali. Ad esempio, sia Airbus che Boeing si sono trovate di fronte a enormi problemi perché alcuni ingegneri non avevano le loro versioni più aggiornate. La soluzione consiste nell'orchestrare i dati.\n\n## Orchestrazione dei dati\n\nOrchestrazione, innanzitutto, è la decuplazione di tutti i diversi silos; i dati vengono trattati come un'unica risorsa. Hammerspace assimila le parti costituenti più piccole, i metadati, per creare, essenzialmente, un sistema di anti-gravità dei dati. Successivamente, implementano obiettivi come durabilità, disponibilità e snapshot, o azioni personalizzate definite tramite script di Hammerspace. Infine, i dati, che siano di tipo Kubernetes, NFS o SMB, diventano portabili e si integrano nel sistema.\n\nCiò che questo significa in pratica è che non è necessario recarsi in un altro silo per soddisfare un carico di lavoro specifico. I dati vengono consegnati dove desideri. Questa mobilità dei dati è fondamentale perché è in tempo reale; non si tratta di migrazione dei dati, che è perturbante e provoca tempi di inattività.\n\nPer ridurre al minimo i costi di uscita costosi, i dati vengono deduplicati e compressi su base granulare dei file. Invece di spostare un volume fisso completo, è possibile selezionare i dati da trasferire in base a qualsiasi tipo di espressione come cartelle, tag di metadati o un descrittore del cliente. Ciò offre flessibilità e risparmio di costi.\n\n## Architettura spazio di martelli\n\nNell'architettura Hammerspace, il file system globale ha tre componenti a livello superiore: il file system globale stesso, la presentazione front-end (NFS, CSI Driver e SMB) e Anvil all'interno del file system globale. Anvil è il componente di gestione dei metadati mentre DSX fornisce servizi di gestione dei metadati. Questi possono essere implementati come macchine virtuali, VMware, KBM o Hyper-V. Anvil è configurato a forma di A, quindi ce ne sono almeno due in ogni posizione. DSX può essere parallelizzato per migliorare le prestazioni, quindi è possibile avere un numero di questi in posizioni diverse per garantire prestazioni sufficienti. Possono essere facilmente ridimensionati verso il basso.\n\nNell'infrastruttura, l'archiviazione sottostante può essere il software defined storage proprietario di Hammerspace con disco direttamente collegato, NAS assimilato, qualsiasi cloud o qualsiasi combinazione. Questo sistema può anche essere scalato in modo orizzontale, in modo da poter aumentare le prestazioni e la capacità in modo indipendente. Seguendo il modello cloud, è anche elastico, quindi nel caso in cui ci siano cambiamenti nell'attività in quella particolare posizione, è possibile ridimensionare sia le prestazioni che la capacità per garantire che le applicazioni abbiano esattamente ciò di cui hanno bisogno in quella posizione. Tutto ciò rende l'architettura molto flessibile per supportare qualsiasi carico di lavoro delle applicazioni sul front end.\n\nUn grande vantaggio di questa architettura flessibile è la capacità di assimilare dati che vengono memorizzati su dispositivi che non sono di tua proprietà, come NAS o nel cloud. Ciò semplifica lo spostamento dei dati. Ad esempio, se possiedi un NAS più vecchio e desideri migrare su un NAS più recente, non importa se sono dello stesso produttore o di produttori diversi. Hammerspace assimila i metadati e sposta i dati in modo del tutto trasparente alle applicazioni perché si tratta di una mobilità dei dati in tempo reale. Un altro significativo vantaggio è che non ci sono tempi di inattività durante lo spostamento dei dati.\n\nSe vuoi provare questa tecnologia, vai su hammerspace.com e inizia con una prova gratuita con una licenza per un massimo di 10 terabyte messa in esercizio su Azure, AWS o Google Cloud.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Johan Ballin"],"link":"/episode-EDT26-it","image":"./episodes/edt-26/it/thumbnail.png","lang":"it","summary":"Johan Ballin, Direttore Marketing Tecnico presso Hammerspace, e Darren Pulsipher, Solution Architect Capo, Settore Pubblico, presso Intel, discutono della tecnologia di cloud ibrido di Hammerspace che libera i dati dall'infrastruttura di archiviazione, fornendo portabilità e prestazioni dei dati."},{"id":96,"type":"Episode","title":"Sicurezza Hardware: Imperativo per la Trasformazione dei Dati","tags":["datagovernance","data","sgx","confidentialcomputing","cybersecurity","technology"],"body":"\r\n\r\n## Paesaggio della sicurezza dei dati\n\nIl mondo è diventato incredibilmente connesso con tutti i dispositivi e ciò sta generando una crescita esponenziale nella quantità di dati che dobbiamo gestire: più volume, più rischi. È una sfida, e sfruttare nuove capacità di calcolo come il cloud, l'analisi e il computing periferico aumenta ulteriormente la complessità.\n\nCi sono tre tendenze principali nella sicurezza: la crittografia di tutto, l'isolamento del carico di lavoro e una catena di fiducia. Queste tre aree sono importanti per aiutare le organizzazioni a gestire l'aumento dei requisiti normativi per mantenere protetti i dati.\n\nQuando le organizzazioni decidono di effettuare una trasformazione digitale, o quando si trovano ad affrontare un catalizzatore come il COVID 19 che richiede il lavoro a distanza, ad esempio, la sicurezza deve andare di pari passo per mantenere controlli e conformità in materia di sicurezza. Se affronti la sicurezza lungo il percorso dei tuoi sviluppi e delle tue implementazioni, sarai in grado di trasformare il modo in cui fai affari in modo sostenibile.\n\n## Proteggere i dati durante il loro ciclo di vita.\n\nCifrare i dati è importante in tutte le sue fasi. Storicamente, gli attaccanti potevano accedere ai dati tramite la rete. Dopo che questi sono stati crittografati, hanno iniziato a violare i data center e ad estrarre i dati dai database. Quindi abbiamo iniziato a cifrare lo storage. Tuttavia, i dati arrivano a un endpoint, vengono caricati in memoria e decifrati, quindi un attacco sofisticato con accesso root potrebbe potenzialmente rubare o manipolare i dati in quel punto di elaborazione. Questo attacco ai dati in uso è la nuova frontiera per gli attaccanti e per coloro che difendono lo spazio. Intel ha alcune nuove capacità eccitanti e innovative che stiamo incorporando nei nostri processori per aiutare i proprietari dei dati, i proprietari delle applicazioni, i fornitori di servizi e fondamentalmente l'intero ecosistema a chiudere queste potenziali vulnerabilità.\n\n## Perché proteggere i dati in uso?\n\nIn molti casi, gli attaccanti utilizzano scalate di privilegi a livello del sistema operativo o dell'Hypervisor. Potrebbero arrivare tramite un sistema operativo ospite, un sistema operativo host o addirittura attraverso l'accesso fisico all'hardware del server. Gli attaccanti potrebbero essere intrusioni di tipo malware di hacker classici, competitori di terze parti o insider come un amministratore o un amministratore di sistema presso un fornitore di servizi.\n\n## Intel Software Guard Extensions (Intel SGX) can be translated to Italian as Estensioni Intel Software Guard (Intel SGX).\n\nIntel ha introdotto una nuova tecnologia nei nostri processori chiamata Intel Software Guard Extensions, o SGX. Questa fa parte del paradigma del calcolo riservato che sta esplodendo sul mercato in questo momento, poiché le aziende stanno cercando di trasformare i loro dati e mantenerli privati. SGX affronta questi nuovi tipi di attacchi consentendo all'applicazione di comunicare direttamente con il processore nella memoria criptata, evitando il sistema operativo, l'ipervisore e fondamentalmente tutto il resto del sistema. Quindi, anche se si verificasse una violazione nel sistema operativo, nell'ipervisore o in altre applicazioni, gli attaccanti non potrebbero accedere a quei dati perché il sistema operativo stesso non ha la visibilità di quei dati. Pertanto, non è necessario fidarsi del provider né del resto dello stack di sistema, poiché si opera essenzialmente come se fossero già compromessi, e il codice e i dati rimarranno confidenziali e inalterati; avranno un'integrità.\n\nIntel sta cercando di far sì che tu debba fidarti del minor numero possibile di componenti. SGX si spinge più avanti lungo questo percorso per il data center rispetto a tutto ciò che abbiamo visto finora. Tutto ciò di cui devi fidarti è la tua stessa applicazione e il processore stesso.\n\nSGX offre una potente capacità per le aziende come i fornitori di servizi cloud, i quali possono garantire ai loro clienti che né loro né il governo, ad esempio, potrebbero accedere ai vostri dati anche se lo volessero.\n\n## Intel SGX in Azione\n\nSGX è già ampiamente utilizzato dai fornitori di servizi cloud e dai produttori di software, ma in alcuni aspetti, stiamo solo cominciando. Nonostante questa tecnologia sia stata disponibile per diversi anni, abbiamo sviluppato ecosistemi, e stiamo introducendo nuove capacità nei nostri prossimi processori Xeon Ice Lake di terza generazione. Ciò espanderà le sue capacità, la sua capacità di scalare su carichi di lavoro aziendali di grandi dimensioni e sarà in grado di proteggere porzioni di memoria molto più grandi con migliori prestazioni e su un'ampia gamma di centri dati mainstream.\n\nIntel è uno dei membri fondatori del Consorzio per l'Elaborazione Confidenziale, che fa parte della Linux Foundation. La maggior parte dei grandi fornitori di servizi cloud, molti provider di software, e persino i nostri concorrenti nel settore dei semiconduttori stanno lavorando insieme su questo tipo di soluzioni di ambiente di esecuzione fidato e stanno stabilendo standard per gestire questa tipologia di capacità. Stiamo anche aumentando la consapevolezza sulla necessità e il valore commerciale dell'elaborazione confidenziale.\n\n## Ecosistema di partner software di Intel SGX\n\nSGX fornisce molte opzioni d'uso a seconda di ciò che il proprietario dei dati sta cercando. Se un cliente desidera il massimo livello di controllo dettagliato, SGX glielo permette. Infatti, possono essenzialmente ridurre la loro applicazione solo ai dati codificati che vogliono tenere isolati dal resto del sistema, o anche solo a una parte di quell'applicazione. Questo scenario, però, richiede loro di scrivere l'applicazione per quel determinato scopo. Nell'ecosistema, ci sono risorse open source che rendono molto più facile questo tipo di sviluppo e che sta sempre crescendo.\n\nDall'altra parte c'è il trasferimento rapido del percorso lift and shift. Puoi prendere la tua applicazione e inserirla in un ambiente più sicuro. L'ecosistema sta rispondendo e creando contenitori SGX-aware. Potresti inserire la tua applicazione non modificata in quell'ambiente in cui è l'unica cosa in esecuzione, così l'applicazione stessa pensa di essere in esecuzione nel suo ambiente nativo.\n\nI nostri partner dell'ecosistema hanno fatto molti progressi in questo settore con cose come Fortanix, Graphene e Scone. Alcuni sono open source e altri sono proprietari, ma offrono tutti i servizi già incorporati. Ad esempio, Microsoft Azure Confidential Computing offre l'intera gamma, dalle soluzioni di lift and shift con SGX fino agli SDK che ti consentono di sviluppare direttamente la tua applicazione per esso e di inserirla nel loro ambiente in modo da non dover gestire nemmeno l'hardware. Ci sono un'ampia gamma di opzioni, quindi nessuno dovrebbe temere le complessità di SGX. I clienti dovrebbero anche avere fiducia che materiali sensibili come algoritmi di machine learning o chiavi di cifratura saranno gestiti con un livello di protezione molto granulare.\n\n## Informatica riservata: Un cambiamento epocale nella sicurezza\n\nSGX è stato là fuori per un po' di tempo e abbiamo lavorato per espanderlo. È stato testato e messo alla prova, con centinaia di articoli di ricerca e miglioramenti nel tempo. Ha il vantaggio di non essere il novellino del quartiere, ma piuttosto una soluzione di base che viene introdotta nel mainstream con Ice Lake. Non è più focalizzato su aree piccole e sensibili, ma è pronto ora per gli obiettivi più importanti.\n\nIl governo, i servizi finanziari e l'assistenza sanitaria sono alcune delle industrie che hanno visto l'appeal di SGX fin dall'inizio perché hanno molte aspettative regolamentari e requisiti di privacy, ma stanno cercando di condividere dati e fare cose innovative con più parti. Le aziende hanno situazioni simili, ad esempio se vogliono passare al cloud pubblico ma non si fidano di proteggere i loro dati sensibili. Con SGX, non devono fidarsi del fornitore.\n\nIntel ha appena fatto un grande annuncio questo mese e stiamo aprendo le porte su ciò che ci aspetta. Un ottimo punto di partenza è intel.com/sgx per testimonianze e approfondimenti sulle informazioni. I clienti dovrebbero cercare i partner dell'ecosistema come Azure e Fortanix. Un'altra fonte per informazioni è il Confidential Computing Consortium a causa del numero di persone che lavorano in quel settore.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jesse Schrater"],"link":"/episode-EDT27-it","image":"./episodes/edt-27/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, settore pubblico, Intel, e Jesse Schrater, Security Manager, Gruppo Data Platforms, Intel, discutono del panorama attuale della sicurezza e di come la tecnologia Intel SGX e l'ecosistema di partner offrano una soluzione provata e tempestiva per i dati in uso e altre preoccupazioni legate alla sicurezza."},{"id":97,"type":"Episode","title":"Integrazione ereditaria con Cloud e RPA","tags":["rpa","bpm","automation","compute","technology"],"body":"\r\n\r\nSembra che tutti siano nel mezzo di una Trasformazione Digitale. Cloud Privato, Cloud Pubblico, Cloud Multi-Ibrido, Data Lakes, Apprendimento Automatico, Inference e Intelligenza Artificiale sono tutti termini che le persone usano oggi per descrivere la propria trasformazione digitale, ma cosa succede con l'integrazione Legacy? Nessuno parla mai dell'integrazione Legacy. Perché? Perché è sfidante integrare applicazioni, dati e sicurezza Legacy nel nuovo e immacolato ambiente Multi-Ibrido del Cloud. Questa è una delle cose che meno ci preoccupano. Se non sviluppiamo una strategia Legacy, avremo una barca veloce con l'ancora calata. Ci rallenta e tiene la nostra barca bloccata nel porto.\n\nUna delle aree in crescita per aiutare con l'integrazione del Legacy e l'automazione dell'integrazione è l'uso di strumenti e framework di automazione. Negli ultimi 3 anni, è emersa un'accentuata enfasi sull'automazione dei flussi di lavoro con applicazioni Legacy e nuove applicazioni cloud-aware per i lavoratori dell'informazione. Questi set di strumenti vengono chiamati strumenti di Automazione dei Processi Robotici (RPA).\n\n## Automazione dei processi robotici (RPA)\n\nQuando ho iniziato a investigare sugli strumenti di Automazione dei Processi Robotici (RPA), pensavo che controllassero i robot. Ero pronto ad indossare gli stivali con la punta di acciaio e un casco per visitare gli stabilimenti di produzione. Tuttavia, ho scoperto rapidamente che le RPA imitano il modo in cui gli operatori di informazione lavorano con i diversi strumenti che utilizzano. Alcuni di questi strumenti sono strumenti Legacy, e alcuni di questi sono nuove applicazioni moderne. Le RPA registrano come l'operatore di informazione utilizza l'interfaccia utente dei diversi strumenti e consentono la riproduzione della registrazione, automatizzando il flusso di lavoro dell'operatore di informazione.\n\nIn modo sorprendente, le RPAs sono una tecnologia piuttosto matura. Molte delle aziende RPA hanno una tradizione nel mercato degli strumenti di test dell'interfaccia utente. La capacità di catturare l'interazione dell'utente con più applicazioni nel tempo è fondamentale per lo sviluppo di un test ripetibile dell'interfaccia utente. Questi strumenti sono presenti da oltre 20 anni e sono piuttosto maturi. Questi strumenti di test di interfaccia utente per la QA sono stati rinominati e riproposti per i lavoratori dell'informazione che desiderano automatizzare le loro attività ridondanti ripetibili.\n\n## Luogo di mercato attuale - 2020\n\nGli investitori vedono questo mercato come un mercato molto promettente e hanno investito molto in queste tecnologie. Negli ultimi tre anni, sono stati investiti oltre 2,0 miliardi di dollari nel mercato dell'RPA. Tre società si sono aggiudicate la maggioranza degli investimenti:\n\nUiPath - Investimento da 1 miliardo di dollari su un fatturato annuo di 300 milioni di dollari.\n\n* Automation Anywhere - Investimento di $500 milioni su $100 milioni di ricavi annuali.\n\nBluePrism: Investimento di $50 Milioni su un fatturato annuale di $30 Milioni.\n\nTraduci quanto segue in italiano: *\n\nLa maggior parte degli investimenti non proviene dalla tradizionale Silicon Valley ad alta tecnologia, ma piuttosto dai centri finanziari come New York e Londra, indicando che le istituzioni finanziarie stanno guardando alle RPAs per automatizzare molti dei flussi di lavoro e processi dei propri dipendenti del settore dell'informazione.\n\n## Luogo in cui RPA funziona bene\n\nI primi segmenti verticali ad adottare i RPAs sono stati i settori finanziario, assicurativo e medico. Queste industrie hanno cercato modi per ridurre la variabilità, aumentare l'affidabilità e ridurre i costi. A causa del gran numero di lavoratori dell'informazione presenti in queste industrie, hanno cercato di automatizzare gran parte del lavoro attualmente svolto dai loro lavoratori dell'informazione tramite RPAs. Per automatizzare queste flussi di lavoro, le organizzazioni devono capire come vengono creati tali flussi di lavoro.\n\nPrima di tutto, cerchiamo di capire il lavoratore dell'informazione. Molti dei lavoratori dell'informazione trascorrono del tempo lavorando con più applicazioni, collegando informazioni e applicazioni in modo improvvisato. Man mano che questi lavoratori continuano a lavorare con queste applicazioni, creano organicamente flussi di lavoro che combinano dati e applicazioni in un numero innumerevole di permutazioni.\n\nSecondo, cataloga i flussi di lavoro nel miglior modo possibile, individuando candidati per l'eliminazione di flussi di lavoro attraverso la duplicazione e la ridondanza. Ora che i carichi di lavoro sono compresi, il passo successivo è dare priorità e enumerare i flussi di lavoro. Concentrarsi sui flussi di lavoro più utilizzati con il maggior numero significativo di passaggi tende ad essere il modo migliore per dare priorità ai flussi di lavoro.\n\nInfine, scopri come automatizzare i flussi di lavoro con i bot di RPA. L'automazione può essere effettuata tramite la registrazione dell'interfaccia utente del flusso di lavoro da parte di uno dei lavoratori dell'informazione e l'annotazione del flusso di lavoro con variazioni basate sull'inserimento dei dati e le credenziali di sicurezza. Una volta completata la registrazione, viene creato un bot di RPA per automatizzare il flusso di lavoro. Ora devi decidere come desideri far funzionare l'RPA: Atteso o Non Atteso.\n\n## Modalità di funzionamento di RPA\n\nGli RPA funzionano in due modalità di esecuzione di base. \"Attended\" e \"Unattended\". \"Attended\" significa che viene eseguito sul desktop o laptop del lavoratore dell'informazione. Aiuta il lavoratore dell'informazione automatizzando il lavoro che svolge giorno dopo giorno. \"Unattended\" viene eseguito in un ambiente di desktop virtuale ed è tipicamente avviato tramite un evento o un trigger e viene eseguito senza alcuna interazione con il lavoratore dell'informazione. Ci sono vantaggi nell'eseguire in entrambe le modalità come descritto di seguito.\n\n## Frequentato\n\nGestisce compiti per i singoli dipendenti\n\nI dipendenti attivano e dirigono un bot per svolgere un'attività.\n\nI dipendenti attivano i bot per automatizzare le attività quando necessario in qualsiasi momento.\n\nAumenta la produttività e la soddisfazione dei clienti nei call center e in altri ambienti di assistenza.\n\n## Non sorvegliato\n\nAutomatizza i processi di back-office su larga scala\n\nProvvisto sulla base di processi basati su regole\n\nI bot completano i processi aziendali senza intervento umano secondo un programma prestabilito.\n\nLibera i dipendenti dal lavoro ripetitivo, riducendo i costi, migliorando la conformità e accelerando i processi.\n\n## Come integrare RPA nella tua azienda\n\nPer comprendere come gli RPAs si inseriscono nella tua azienda, devi prima considerare gli utenti degli RPAs. In particolare, ci sono tre tipi di \"attori\" che utilizzano, gestiscono o influenzano gli strumenti degli RPAs.\n\nLavoratore dell'informazione - Questo è l'utente principale degli strumenti RPA. I loro processi manuali sono obiettivi per l'automazione.\n\nSviluppatore di applicazioni: i bot RPA cambiano quando vengono aggiornate o create nuove applicazioni. Le modifiche all'interfaccia utente richiedono il \"ri-registrazione\" dei bot RPA.\n\nOperazioni IT: Gestire gli strumenti RPA e distribuire i bot RPA non assistiti.\n\nTranslate the following to Italian: \"Hello, how are you?\"\n\n## Gestione del cambiamento\n\nGestire la complessità delle configurazioni e della sicurezza sono fattori critici per un'implementazione di successo degli strumenti e dei bot RPA. Innanzitutto, è necessario comprendere come interagiscono i diversi utenti delle RPAs durante le modifiche alle applicazioni, ai flussi di lavoro e ai processi. Questa comprensione è fondamentale per gestire il cambiamento nei bot RPA e negli strumenti che utilizzano.\n\nPiccole modifiche alle applicazioni possono avere un profondo effetto sugli Information Workers e su come svolgono il loro lavoro quotidiano, il che significa registrare un nuovo bot RPA o aggiornarne uno esistente. A causa dell'accoppiamento dei bot RPA agli strumenti e ai flussi di lavoro, creare bot RPA quando i flussi di lavoro o gli strumenti sono immaturi causa una scomoda esigenza di adattamento e fragilità. I processi e gli strumenti maturi sono ottimi candidati per l'automazione tramite RPA.\n\nUn'altra cosa da considerare è dove vengono eseguiti gli strumenti che stai automatizzando con il tuo strumento RPA. Utilizzano applicazioni e infrastrutture legacy? Utilizzano Cloud Pubblico o Privato? Come sono collegati i network di questi sistemi? Man mano che il numero di ambienti aumenta, aumenta anche la complessità di mantenere e aggiornare le applicazioni e i bot RPA. Trova modi per ridurre il numero di limiti ambientali che il bot RPA attraversa.\n\n## Gestione della sicurezza\n\nUn altro fattore critico da considerare è la sicurezza per i bot RPA. Quando un lavoratore dell'informazione registra il proprio flusso di lavoro, è necessario autenticarsi (effettuare l'accesso) a ciascuno strumento che viene utilizzato. I lavoratori si autenticano utilizzando nomi utente e password, chiavi di autenticazione o persino strumenti di accesso singolo aziendale. In ogni caso, è necessario gestire la sicurezza di questi strumenti nel contesto del bot RPA in esecuzione. Eventuali modifiche all'autenticazione (nome utente, password, chiavi di autenticazione o credenziali) richiedono modifiche al bot RPA. Molti dei tool RPA considerano questo e hanno meccanismi per inserire le credenziali di sicurezza nel bot RPA e autenticarsi con gli strumenti durante l'esecuzione.\n\n## Gestione degli strumenti e dei bot RPA con flussi di lavoro SecDevOps\n\nLa complessità degli strumenti e dei bot RPA si presta molto bene a modelli ben noti nel mondo SecDevOps. Per fortuna, molti problemi legati alla gestione delle configurazioni e delle dipendenze vengono gestiti efficacemente con un processo SecDevOps.\n\n## RPA Bundle \nRaggruppamento RPA\n\nUno dei trucchi consiste nel trattare il bot di RPA come un servizio complesso che contiene diversi VM o container per ciascuno degli strumenti, un Desktop Virtuale e il bot stesso. Questi servizi possono essere raggruppati e gestiti insieme come un unico pacchetto. Un bundle include non solo i servizi ma anche il modo in cui i servizi comunicano (rete) in modo sicuro (autenticazione).\n\nPassare un bundle a un orchestratore di servizi consente una maggiore automazione della gestione del firewall di rete, della sicurezza e dell'iniezione delle chiavi di credenziali e della gestione del ciclo di vita del bot RPA e degli strumenti che utilizza. Ci sono diversi strumenti nello spazio della virtualizzazione (VMWare e OpenStack) che consentono la creazione e la gestione di questi bundle. Anche lo spazio dei container dispone di strumenti di pianificazione e orchestrazione simili: in particolare Kubernetes, Mesos e Docker Swarm.\n\n## SecDevOps Pipelining can be translated to Italian as \"Pipelining di SecDevOps\".\n\nUna semplice pipeline SecDevOps gestisce il pacchetto del bot RPA proprio come qualsiasi altro pacchetto di applicazioni tradizionali.\n\nUn lavoratore dell'informazione costruisce i pacchetti di bot RPA registrando il flusso di lavoro dell'interfaccia utente in un ambiente di sviluppo. Il lavoratore registra facilmente il proprio flusso di lavoro e quindi crea un pacchetto che viene \"verificato\" nel flusso di lavoro. A quel punto, il pacchetto di bot RPA passa attraverso un ciclo di costruzione, test e produzione. I punti di controllo ad ogni passo lungo il percorso aiutano a garantire la qualità del bot RPA. Poiché il pacchetto può iniettare rete e sicurezza a seconda di diversi ambienti, i bot RPA possono essere riutilizzati da diversi lavoratori dell'informazione e in diversi ambienti.\n\nUn altro vantaggio di inserire i bot RPA nelle raccolte RPA è la gestione degli strumenti e dei bot su più ambienti infrastrutturali come legacy, privati e cloud pubblici. Molti degli strumenti di orchestrazione dei servizi possono creare automaticamente connessioni tra questi ambienti infrastrutturali attraverso la creazione di una rete sovrapposta. Il flusso di lavoro riduce la quantità di lavoro \"manuale\" svolto dall'organizzazione IT e, in molti casi, tutti i passaggi nel flusso di lavoro sono automatizzati.\n\n## Insidie dei bot di RPA\n\nEcco una lista di cose da tenere d'occhio quando si utilizzano robot RPA nei sistemi aziendali.\n\nLa sicurezza può essere una falla aperta se non ci presti attenzione. Uno dei più grandi errori è eseguire applicazioni in un RPA bot in modalità privilegiata o con credenziali dell'account \"globale\".\n\nI RPAs bots sono strettamente collegati alle Interfacce Utente di diverse applicazioni, qualsiasi piccola modifica a un'applicazione significa che è necessario registrare nuovamente il bot RPA.\n\nI bot di RPA non riescono ad affrontare bene i cambiamenti, sono molto fragili rispetto ai cambiamenti nelle applicazioni e persino nella configurazione delle applicazioni.\n\nLa riutilizzazione è minima a causa dell'accoppiamento stretto con le interfacce utente dell'applicazione. Alcuni strumenti utilizzano i tag al posto della posizione assoluta del cursore e dei clic.\n\nAlcune interfacce utente non si prestano agli RPAs in quanto sono dinamiche. Ciò significa che sono difficili da registrare.\n\nL'industria RPA sta facendo del suo meglio per superare alcuni di questi problemi intrinseci all'aspetto registrazione/riproduzione degli strumenti. Alcune di queste insidie non possono essere superate a causa dell'approccio generalizzato. Altre opzioni, come i gateway API e l'automazione funzionale, dovrebbero essere valutate.\n\n## L'Intelligenza Artificiale al salvataggio dei RPAs\n\nCome menzionato nei rischi della RPA, il riutilizzo dei bot è un grosso problema che l'industria cerca di risolvere. Una delle tecniche che stanno investigando è l'utilizzo dell'IA e dell'Inferenza per gestire interfacce utente dinamiche e piccoli cambiamenti alle applicazioni senza registrare nuovamente i bot RPA. Il riconoscimento di pattern e l'OCR (riconoscimento ottico dei caratteri) sono due aree che vengono utilizzate per addestrare modelli di IA che verranno utilizzati per identificare campi e segmenti delle interfacce utente.\n\nCon questi modelli di intelligenza artificiale, i bot possono essere più flessibili e adatti per essere riutilizzati in diversi strumenti e processi/schemi di lavoro simili. Un'altra area che i fornitori di RPA stanno investigando è l'ottimizzazione dei processi tramite l'uso di intelligenza artificiale e machine learning.\n\n## La migrazione dell'eredità è un viaggio.\n\nIl mercato RPA ha guadagnato nuova energia poiché le aziende cercano di modernizzare la propria infrastruttura IT e i processi. Automatizzare i processi manuali attuali mediante la registrazione è una vittoria rapida di cui molte organizzazioni beneficiano. Tuttavia, l'RPA dovrebbe essere considerato un meccanismo provvisorio anziché uno stato finale. Perché? Molti dei processi informativi attuali richiedono sistemi e politiche obsoleti. Automatizzare un vecchio processo su una nuova infrastruttura è simile ad automatizzare la creazione di fruste per una fabbrica automobilistica. Potrebbe esserci un beneficio iniziale, ma nel lungo termine, il processo risulta altamente inefficiente e antiquato. Indipendentemente da quanto velocemente funziona in modo affidabile, potrebbe semplicemente non essere necessario.\n\n## Conclusione\n\nGli strumenti di automazione dei processi robotici sono un altro insieme di strumenti che possono essere utilizzati per aiutare le organizzazioni nella loro trasformazione digitale da Legacy a infrastrutture e processi informatici più moderni. Gli strumenti da soli non sono sufficienti, è necessario pianificare come li utilizzerete, gestirete e alla fine li sostituirete. Ecco alcuni utili consigli quando si lavora con questi strumenti.\n\nTratta gli RPAs come servizi complessi in esecuzione nel tuo Multi-Hybrid Cloud.\n\nEsegui i tuoi bot RPA tramite flussi di lavoro SecDevOps come altre applicazioni.\n\nIniettare sicurezza e autenticazione durante l'esecuzione nel tool RPA.\n\nTrova modi per riutilizzare i bot RPA in diverse parti della tua organizzazione.\n\nAvere un piano per sostituire il tuo RPA bot con un'integrazione semplificata\n\nCerca modi per ridurre le applicazioni Legacy (Sostituire o Rimuovere)\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT28-it","image":"./episodes/edt-28/it/thumbnail.png","lang":"it","summary":"Una delle aree in crescita per aiutare con l'integrazione legacy e l'automazione dell'integrazione è l'uso di strumenti e framework di automazione. Negli ultimi 3 anni, è emerso un significativo enfasi sull'automazione dei flussi di lavoro con applicazioni legacy e nuove applicazioni cloud-aware per i lavoratori dell'informazione. Questi set di strumenti vengono chiamati strumenti di automazione dei processi robotici (RPA). Darren Pulsipher, Chief Solution Architect, settore pubblico, Intel, esamina l'industria dell'automazione dei processi robotici (RPA) e le offerte di strumenti."},{"id":98,"type":"Episode","title":"Database di hyperscale di prossima generazione - Aerospike","tags":["aerospike","database","ingestion","optane","data","technology","pmem"],"body":"\r\n\r\n## Prossima generazione di database iperscalabili.\n\nI database stanno mostrando la loro età, impiegando ancora del tempo per ottenere risultati. Aerospike, con l'aiuto della tecnologia Intel, spicca per velocità, volume e bassa latenza. Tim Faulkes, Vice Presidente dell'Architettura delle Soluzioni presso Aerospike, si unisce a Darren in questo episodio per discutere i vantaggi della loro tecnologia.\n\n## NoSQL - Un mercato emergente con molteplici tecnologie\n\nAerospike è stato creato nel 2009, con le prime implementazioni di produzione nel 2011. I cofondatori erano consapevoli delle sfide future. Hanno costruito l'architettura partendo da zero con la premessa che fosse affidabile, di scala enterprise, mai inarrestabile e in grado di gestire l'ingestione massiva di dati. L'architettura di Aerospike si basava molto sugli SSD, che fossero unità NVMe nelle moderne incarnazioni o unità SATA SAS. Entrambi erano ancora in fase embrionale, quindi i fondatori avevano una visione proattiva rispetto a dove andava il mercato. Si affidavano a quei dispositivi per ottenere la velocità, ed ecco perché la tecnologia Intel era così importante. Da allora, altre tecnologie Intel, come la memoria persistente, hanno reso le cose molto più facili.\n\n## Indici nella RAM, Dati su SSD\n\nAerospike si avvicina ai database in modo diverso. Gli SSD non sono un disco rigido più veloce. Un disco rigido ha settori fisici e teste e cose che deve muovere per leggere i dati. Un SSD può leggere rapidamente migliaia di pezzi di dati in parallelo. Non funziona bene su unità rotazionali, ma con NVMe/SSD, funziona in modo velocissimo. Nessuno ha la stessa sorta di prestazioni, nemmeno un database in memoria.\n\nL'architettura unica è progettata per un alto volume, un elevato throughput e una latenza molto bassa. Ad esempio, alcuni clienti effettuano regolarmente 20 milioni di transazioni al secondo. Alcuni arrivano fino ai petabyte di dati. Di solito, i clienti operano su hardware abbastanza buono, ma il tempo di andata e ritorno è fondamentale. Aerospike impiega circa 200 microsecondi per cercare un pezzo di dati e riportarlo al cliente, non decine o centinaia di millisecondi. Quando hai bisogno di molte informazioni velocemente, come nella rilevazione delle frodi, o se stai acquisendo molti dati, come nell'IoT, veicoli autonomi, letture dei sensori o dispositivi medici, Aerospike può eseguire milioni di transazioni al secondo tra letture e scritture. Non è necessario inserirlo in un bus di messaggi e quindi consentire al database di notificare i sistemi downstream tramite il bus di messaggi che ha i dati. È già persistente.\n\n## Alimentando l'innovazione di punta nel settore in tutto il mondo\n\nQuali sono i casi d'uso ideali per Aerospike? Ci sono mercati evidenti come l'IoT, la rilevazione delle frodi e i dati dei sensori, ma è un mercato in crescita. Aerospike è nato nella tecnologia pubblicitaria, dove il recupero dei dati deve avvenire in millisecondi o meno. È qui che le buone prestazioni sono state testate con successo su larga scala.\n\nUlteriori settori in cui Aerospike può essere utile sono vari. Un esempio è una grande azienda di telecomunicazioni in India. Lì, l'infrastruttura non è sempre affidabile e talvolta le chiamate vengono interrotte. Questa azienda, grazie alla tecnologia di Aerospike, può rilevare in tempo reale quando una chiamata viene interrotta e può immediatamente contattare il cliente per offrire crediti o altre forme di compensazione al fine di mantenere la soddisfazione del cliente.\n\n## Regolamento in tempo reale dei pagamenti istantanei.\n\nUn nuovo settore in cui Aerospike si è ampiamente impegnata è quello dei pagamenti digitali in tempo reale. Questo settore non richiede necessariamente molte informazioni o un'elevata capacità di elaborazione, ma ciò di cui queste aziende hanno bisogno è una coerenza e una disponibilità assolute, anche in caso di eventi come la perdita di un centro dati.\n\nIl pavimento di produzione è anche un mercato emergente per la tecnologia Aerospike in settori come la produzione di semiconduttori, dove viene utilizzato per memorizzare dati dei sensori al fine di fornire analisi in tempo reale. Aerospike si distingue in qualsiasi settore in cui ci sia una grande quantità di dati e si necessiti di ottenerli velocemente.\n\n## Performance a livello Quick synthesis – Risultati dei test indipendenti di terze parti.\n\nCi sono molti database con una buona tecnologia disponibili, ma ci sono sfide legate alla scala. Prendiamo Redis, ad esempio. Poiché memorizza tutte le sue informazioni in memoria, non puoi raggiungere i dieci terabyte senza costi significativi, figuriamoci centinaia di terabyte o petabyte. Dato che Aerospike archivia le informazioni su SSD, la differenza di tempo nel cercare dati su SSD e memoria è di circa 100 microsecondi. Nella scala dei petabyte, Aerospike sostituisce tecnologie più vecchie come Cassandra, che scala molto bene ma manca di velocità.\n\n## Costo totale di proprietà\n\nInoltre, rispetto a quelle tecnologie, le persone risparmiano molti soldi passando ad Aerospike perché il numero di nodi diminuisce drasticamente a causa dell'architettura unica. Il risparmio avviene non solo in termini di capitale, ma anche in termini di spese operative poiché ci sono meno macchine da supervisionare.\n\nAerospike ha eliminato alcuni dei livelli tradizionali nell'architettura. Spesso i sistemi legacy avranno una cache aggiuntiva davanti ad esso per accelerarlo. Questo introduce complessità. Aerospike non ha bisogno di una cache. Non c'è una grande quantità di DRAM. Si affida alla velocità degli SSD e alla tecnologia sottostante per ottenere le prestazioni dello storage grezzo senza una cache. Poiché i livelli di cache e di storage sono stati eliminati, la soluzione è semplificata, il che significa affidabilità e velocità integrate.\n\n## Esempio di distribuzione continentale\n\nLa coerenza tra diverse aree geografiche è anche un beneficio importante della tecnologia. L'architettura moderna richiede una bassa latenza, il che significa tipicamente che ci sono un gruppo di cluster basati su H in cui i dati si trovano vicino all'utente. Altrimenti, la velocità della luce diventa un fattore. Aerospike può far comunicare tra loro tutti i cluster basati su H, quindi se un record viene modificato in un cluster, si propagherà automaticamente agli altri cluster in modo asincrono. Tuttavia, alcune applicazioni, come i pagamenti digitali, richiedono una forte coerenza tra i cluster, quindi potrebbero voler replicare i dati in modo sincrono. Preferiscono leggere dalla copia locale dei dati. Le letture diventano molto veloci; le scritture sono affette dalla velocità della luce, ma garantiscono la coerenza attraverso le distanze geografiche. Quindi, non si tratta di risoluzione dei conflitti, ma di evitare i conflitti. Avere la possibilità di diffondere tali scritture di forte coerenza in tutto il mondo e forse avere più sistemi di registrazione ha un enorme potenziale e valore.\n\n## Aerospike Connect per Spark\n\nAd esempio, Aerospike attualmente si interfaccia con Spark, una tecnologia di analisi che richiede che i suoi dati siano in memoria. Caricando i dati da Aerospike, il data frame di Spark può elaborare decine o centinaia di terabyte con enormi risparmi di costi e velocità. L'integrazione con altre strumenti di intelligenza artificiale è una delle forze trainanti che apriranno delle porte interessanti.\n\nOttenere i dati in Aerospike è semplice e diretto. Poiché le applicazioni hanno uno strato API come la maggior parte dei database, Aerospike può acquisire dati da fonti standard del settore come Kafka e Janus. La capacità bidirezionale di comunicare con i bus dei messaggi ha senso perché non solo Aerospike può acquisire dati da queste fonti, ma può anche emetterli. Se Aerospike è una fonte di verità quando si scrive un record, è possibile inviarlo a sistemi successivi.\n\n## Aerospike Connect per Kafka.\n\nSe vuoi utilizzare Aerospike per l'ingestione invece di un motore di ingestione sul front end, Aerospike può determinare se desidera suddividere i dati o mantenerli nello stesso formato e semplicemente inserirli in Aerospike. Con il suo framework di plug-in, è una chiamata API. Quando i dati vengono archiviati, un message bus può essere notificato per l'elaborazione a valle. Questo elimina uno dei passaggi di ingestione e aumenta la throughput totale.\n\nLa scalabilità verso migliaia di client è possibile grazie al modo in cui il client Aerospike è progettato come multithreading per scalare su un solo processo e assorbire una grande quantità di dati in quel modo. Il client è intelligente per ragioni di velocità. Ogni record passa direttamente dal client al nodo che possiede quel pezzo di dati. Non ci sono intermediari di sorta. Ciò significa che il client deve conoscere tutti i nodi, quindi ci sono limiti di connessione finiti, rendendo impraticabili centinaia di migliaia di client.\n\n## Esempio di Deployment Continentale\n\nSe, tuttavia, hai centinaia di migliaia di clienti, è perché hai una popolazione distribuita globalmente. Se parlassero ad un singolo cluster, la velocità della luce diventerebbe un grosso problema. Ci sono modi per creare cluster più piccoli basati sugli edge che condividono informazioni oppure parlano con un sistema centrale in un modello di concentratore e raggi, quindi è possibile farlo.\n\n## Aerospike è un database per applicazioni di sistema di record\n\nAll'interno del mondo dei dati in movimento, entrano in gioco diversi livelli di privacy e standard come il GDPR e il CCPA, quindi i clienti devono conoscere l'origine dei dati. Aerospike ha la flessibilità di analizzare i dati in modo dettagliato e, in base al contenuto, sapere quando e dove possono essere inviati. Questo fa parte della configurazione di spedizione dati di Aerospike che è trasparente per l'applicazione. Non è necessario modificare nulla nelle applicazioni, solo nella configurazione.\n\nAerospike si assicura anche che i dati siano sicuri. Proprio come tutti i database di livello enterprise, Aerospike supporta la crittografia sia inattiva che in transito e l'integrazione della sicurezza di cose come Hashicorp Vault. Può essere, ed è utilizzato, come un sistema di registrazione.\n\nUn obiettivo fondamentale in Aerospike è utilizzare le ultime innovazioni e tecnologie per il successo dei clienti. Ad esempio, quando Intel ha introdotto PMem, lo hanno utilizzato in modalità app diretta per sfruttarne appieno le capacità. Ciò significa che per un aggiornamento graduale su, diciamo, un petabyte di informazioni, il tempo richiesto è ridotto. Aerospike detiene quel petabyte forse su 50 o 60 nodi invece di migliaia di nodi, e quando un nodo viene spento, non è necessario ricostruirlo, quindi il tempo di riavvio è molto veloce.\n\nIn generale, Aerospike offre sicurezza, alta disponibilità, velocità, bassa latenza, scalabilità, coerenza e bassi costi di proprietà.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tim Faulkes"],"link":"/episode-EDT29-it","image":"./episodes/edt-29/it/thumbnail.png","lang":"it","summary":"I database stanno mostrando la loro età, ci vuole ancora del tempo per ottenere risultati. Aerospike, con l'aiuto della tecnologia Intel (Optane), si fa strada con velocità, capacità e bassa latenza. Tim Faulkes, Vice Presidente dell'Architettura delle Soluzioni presso Aerospike, si unisce a Darren Pulsipher, Chief Solutions Architect di Intel, per discutere i vantaggi della tecnologia Aerospike."},{"id":99,"type":"Episode","title":"Vantaggi dell'architettura Multi-Cloud","tags":["multicloud"],"body":"\r\n\r\n## Agilità\n\nL'agilità è la capacità di muoversi rapidamente per adattarsi alle condizioni mutevoli delle nuove tecnologie, nuove applicazioni e nuove minacce come la sicurezza e la concorrenza. Un modello multi-ibrido consente la possibilità di spostare le cose tra cloud privati e pubblici, o anche dall'infrastruttura legacy ai cloud. Potrebbe essere allettante per i team di sviluppo utilizzare inizialmente il cloud pubblico sotto scadenze rigorose perché possono velocemente creare e disattivare l'infrastruttura, ma possono esserci problemi di integrazione nelle fasi finali di implementazione delle applicazioni nel prodotto. Questo può causare ritardi costosi. Utilizzando il modello multi-ibrido, molti di questi punti di integrazione vengono esposti al team di sviluppo in anticipo. Lo sviluppo delle applicazioni utilizza questo per fallire velocemente e in anticipo nel processo di sviluppo.\n\n## Flessibilità\n\nLa flessibilità dell'infrastruttura è un parente stretto dell'agilità. Mentre l'agilità è la capacità di muoversi rapidamente, la flessibilità è la capacità di cambiare. Per ottenere la massima flessibilità, gli sviluppatori hanno bisogno della capacità di distribuire un'applicazione ovunque, sia su cloud privati o pubblici che su infrastrutture legacy, senza essere vincolati al servizio o all'infrastruttura di un singolo cloud.\n\nImplementando una piattaforma di gestione del cloud (CPM) in un'architettura multi-ibrida, i carichi di lavoro possono essere facilmente indirizzati su cloud diversi in base al costo, alla sicurezza e alla affidabilità.\n\nUn esempio delle conseguenze della mancanza di flessibilità è la decisione iniziale di Netflix di utilizzare solo un fornitore di servizi cloud. Questo cloud pubblico ha avuto un problema di infrastruttura che ha causato un'interruzione del servizio, e Netflix non è stata in grado di trasmettere per diverse ore sulla costa orientale degli Stati Uniti. Dopo quel disastro, Netflix ha implementato una soluzione multi-cloud in modo da poter migrare rapidamente su un altro cloud in caso di problemi. Inoltre, sono ora in grado di spostarsi dove ha più senso in qualsiasi momento in base a costi, sicurezza e affidabilità.\n\nLe applicazioni di un cloud multi-ibrido sono la portabilità e la flessibilità operativa. Non essendo legati al modo di fare delle singole piattaforme di cloud, gli sviluppatori scriveranno codice che può essere facilmente trasportato tra diversi cloud. Inoltre, avrai la flessibilità operativa di spostare carichi di lavoro tra i diversi cloud per offrire ai tuoi clienti ciò che desiderano in modo sicuro, attento ai costi e affidabile.\n\n## Prestazione predittiva\n\nLe nuvole pubbliche spesso hanno un prezzo: \"vicini rumorosi\", che possono influire sulle prestazioni predictive o sulla qualità del servizio (QoS).\n\nQuando si utilizza un cloud pubblico, molte volte non si sa cosa o chi altro sta utilizzando la stessa macchina, array di storage o rete come te. Per alcuni carichi di lavoro, questo non è un problema. Tuttavia, se hai un'applicazione in cui hai bisogno di prestazioni prevedibili, vicini rumorosi o coloro che monopolizzano la larghezza di banda, l'I/O del disco, la CPU e altre risorse possono interferire con i risultati di QoS di cui hai bisogno.\n\nLe nuvole private possono soffrire anche di vicini rumorosi, ma poiché possiedi l'infrastruttura e le applicazioni sono tue, hai la diretta possibilità di gestirli. Un vicino rumoroso sulla nuvola pubblica è come vivere in un condominio dove hai opzioni limitate per gestire i festaioli accanto. D'altro canto, i vicini rumorosi sulla tua nuvola privata sono come vivere in una casa con bambini indisciplinati che puoi immediatamente gestire limitando le risorse.\n\nUna strategia di cloud ibrido ti offre la possibilità di mettere carichi di lavoro e applicazioni \"sensibili\" su cloud privati e altri carichi di lavoro e applicazioni su infrastrutture di cloud pubblico per efficienza dei costi e delle risorse. Molti strumenti ibridi ti permettono di caratterizzare i carichi di lavoro con requisiti di QoS per aiutare nella posizionamento automatico e ottimale dei carichi di lavoro su diverse infrastrutture di cloud.\n\n## Sicurezza e conformità\n\nCi sono alcuni pericoli nel fare le cose in modo automatizzato sia nella nuvola pubblica che privata. Tuttavia, se la sicurezza è integrata nell'architettura multi-ibrida, questa automatizzazione diventa un vantaggio poiché significa che un profilo di sicurezza può essere imposto su tutti i tuoi asset di cloud, che siano privati o pubblici, oltre all'infrastruttura legacy. Questo profilo di sicurezza comune viene applicato ovunque e le applicazioni vengono distribuite in base a tali profili.\n\nAd esempio, in un cloud privato, se desideri un tipo specifico di sicurezza, come legare un'applicazione specifica a una determinata macchina che funziona solo in quel cloud privato, può facilmente diventare un requisito nel profilo di un sistema multi-ibrido.\n\nIn un sistema multi-ibrido, ci sono anche molti ottimi strumenti per la revisione e il monitoraggio della tua infrastruttura. Puoi non solo monitorare ciò che sta accadendo nel tuo cloud privato, ma anche nel cloud pubblico, il quale ti avviserà di eventuali attacchi dannosi che potrebbero potenzialmente infettare il tuo cloud privato o le risorse dell'infrastruttura legacy.\n\n## Efficienza\n\nCi sono molte idee contrastanti sull'efficienza. Se osservi vari calcolatori di Costo Totale di Possesso (CTO), troverai diverse risposte su quale tra le nuvole private o pubbliche sia la più efficiente in termini di costo. Una soluzione multi-hybrid cloud può risolvere questo dilemma per la tua organizzazione attraverso una maggiore visibilità e una provisioning dinamica.\n\nCon un'architettura multi-ibrida cloud e un orchestratore intelligente, il tuo orchestratore può utilizzare la telemetria dalle tue cloud private e pubbliche e dall'infrastruttura ereditaria per prendere decisioni ottimali su dove il carico di lavoro dovrebbe essere allocato attualmente e in futuro. Un altro vantaggio di questa visibilità è che puoi decidere se è efficiente far funzionare continuamente le applicazioni. Un esempio di questo è come abbiamo aiutato il sistema del governo canadese a funzionare in modo più efficiente riducendo i costi associati all'esecuzione di un'applicazione nella cloud pubblica quando nessuno la stava utilizzando. Invece di far funzionare un'applicazione specifica tutto il giorno, ora la eseguono per 18 ore, 5 giorni a settimana, in base all'utilizzo effettivo.\n\nQuesta visibilità ti aiuterà anche a identificare ed eliminare i carichi di lavoro e le applicazioni a fine vita (EOL), risparmiando così soldi veri. Per il cloud privato, ciò libera risorse che possono essere utilizzate per altri carichi di lavoro, aumentando la tua efficienza. Inoltre, i broker cloud nella CMP nell'architettura multi-ibrida cercheranno in giro il prezzo più basso mantenendo comunque la QoS per il carico di lavoro specifico. Questo riduce il costo complessivo dell'esecuzione del carico di lavoro e ti fornisce anche la visibilità sul costo effettivo dell'utilizzo di un determinato cloud pubblico o privato.\n\nVisibilità dei costi su Cloud e infrastrutture Legacy.\n\nGuidare carichi di lavoro e applicazioni ai costi più bassi mantenendo gli stessi accordi di livello di servizio.\n\nAumentare l'utilizzo dell'infrastruttura di cloud privato.\n\n## Chiamata all'azione\n\nLe architetture multi-hybrid cloud stanno dando ai CIO la capacità di anticipare le richieste dei loro clienti, ma ci sono ancora alcuni compiti impegnativi da svolgere. Costruire una strategia multi-hybrid cloud include cambiamenti organizzativi, comportamentali e tecnici che non possono avvenire da un giorno all'altro. Sviluppare una visione architettonica solida e una roadmap sono fondamentali per implementare una strategia multi-hybrid cloud che possa sfruttare i punti di forza dei multi-hybrid cloud e prevenire l'inefficienza dovuta alla \"cosa brillante\" del settore tecnico del momento.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT3-it","image":"./episodes/edt-3/it/thumbnail.png","lang":"it","summary":"Un'architettura cloud multi-ibrido consente alle organizzazioni di sfruttare i vantaggi sia dei cloud privati che pubblici, ottimizzando risorse ed efficienza dei costi. Questo modello presenta cinque principali vantaggi: agilità, flessibilità, prestazioni predittive, sicurezza e conformità ed efficienza."},{"id":100,"type":"Episode","title":"Portabilità dell'applicazione con OneAPI","tags":["aiml","devops","compute","technology","process","oneapi","aiops","developer","people"],"body":"\r\n\r\nCon oneAPI, Intel ha creato un ambiente software unificato per lo sviluppo, orientato al trattamento dei dati. Si tratta di programmazione parallela dei dati basata su un C++ open source. Diverse tipologie di librerie come MKL, DNN di Intel e altre open source fanno parte del kit di strumenti oneAPI, insieme ad accessori come un traduttore CUDA. Puoi sviluppare software in oneAPI e poi puntarlo alle diverse librerie a seconda di ciò che stai facendo. Ha eliminato la complessità di imparare un linguaggio diverso per diverse architetture.\n\n## Iniziativa Industriale oneAPI - Alternativa alla Soluzione di un Unico Fornitore\n\nFondamentalmente, un ingegnere del software può scrivere il codice una volta e questo verrà eseguito su diversi processori: CPU, GPU, FPGA, NPU e VPU. A seconda dell'architettura e delle librerie che si stanno utilizzando, potrebbe essere necessaria una ricompilazione, ma non saranno richieste riscritture del codice.\n\n## Potenti librerie di API\n\nQuesta versione è solo il primo passo; Intel e altri continueranno a progettare con l'aggiunta di acceleratori per l'intelligenza artificiale, ad esempio. L'idea è che evolverà per offrire agli sviluppatori molta più flessibilità, e che l'astrazione consentirà a molte persone di poter progettare e codificare in modo più semplice, soprattutto dal punto di vista della scienza dei dati e dell'intelligenza artificiale.\n\nDal punto di vista pratico, uno sviluppatore di software potrebbe scrivere qualcosa sul proprio laptop, provarlo lì, e poi utilizzare lo stesso codice eseguendolo su un cloud completamente equipaggiato con processori neurali, GPU o FPGA. Questo potrebbe essere particolarmente utile nel settore pubblico, dove gli ingegneri stanno scrivendo app speciali che processano in situazioni limite, magari con un FPGA. Non sarà necessario avere un ambiente completo per svolgere il proprio lavoro.\n\nUn altro aspetto interessante è che una volta che Intel incorpora l'apprendimento automatico, oneAPI può analizzare il codice e specificare quali porzioni sarebbero migliori su processori diversi. Esso distribuirebbe il codice nei luoghi corretti per ottenere la massima velocità e prestazioni.\n\n## Iniziativa Industriale oneAPI - Alternativa alla Soluzione Monofornitore\n\nCi sono molti framework di intelligenza artificiale là fuori, ma oneAPI permette la migrazione di qualsiasi tipo di codice da un linguaggio proprietario a un linguaggio di programmazione open-source. Si basa su SYCL e viene sviluppato sotto il consorzio dell'intera industria chiamato Khronos Group, quindi è una sorta di framework di sviluppo.\n\n## Librerie API potenti\n\nOneAPI ha venti-trenta librerie come MKL, librerie per reti neurali e apprendimento automatico, open CNN o DNN. Tutte sono aperte e fanno parte del consorzio più ampio.\n\nInoltre, Intel sta procedendo con l'aggiunta del framework TensorFlow e delle relative librerie in oneAPI. Molti framework sono già stati ottimizzati da Intel e vengono incorporati o utilizzano le stesse librerie in modo che gli utenti possano utilizzarle o ampliarle.\n\n## Risorse\n\nIntel ha reso disponibile generalmente oneAPI all'inizio di novembre 2020 ed è stato uno dei momenti salienti della convention virtuale Super Computing dal 17 al 19 novembre.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT30-it","image":"./episodes/edt-30/it/thumbnail.png","lang":"it","summary":"Con oneAPI, Intel ha creato un ambiente unificato per lo sviluppo software, incentrato sul processing dei dati. Gretchen Stewart, Chief Data Scientist, Public Sector, Intel, discute questa tecnologia con Darren Pulsipher, Chief Solution Architect, Intel, che elimina la necessità di utilizzare un linguaggio diverso per architetture diverse."},{"id":101,"type":"Episode","title":"Migliorare il valore dell'impiegato con Catalytic","tags":["rpa","automation","catalytic","compute","process","technology"],"body":"\r\n\r\n## Catalytic è progettato appositamente per le operazioni e i processi commerciali ricorrenti.\n\nLa tecnologia RPA ha origine dall'automazione dei test e dalle macro di Excel, ma l'approccio aziendale ha origine dall'esternalizzazione. Tuttavia, Catalytic considera la sua ascendenza come software, con il suo sistema come la prossima evoluzione nella creazione di software personalizzati. L'interesse del co-fondatore e CEO Sean Chou si concentra sulle operazioni e l'efficienza degli uffici amministrativi. Questo focus stretto continua a consentire a Catalytic di utilizzare l'IA in modo completo e consente loro di costruire qualcosa di accessibile senza codice.\n\nCatalytic utilizza l'intelligenza artificiale in diversi modi tattici all'interno dell'applicazione per aiutare a ridurre la necessità di competenze specialistiche.\n\nAd esempio, una delle parti più difficili nel imparare una piattaforma è capire le sue capacità. Un modo per utilizzare l'intelligenza artificiale per aiutare a compensare questo problema è utilizzare l'elaborazione del linguaggio naturale. Le persone possono semplicemente digitare ciò che stanno cercando di realizzare e l'applicazione può dedurre e suggerire quale azione sarebbe meglio aiutarti a compiere questo passo. È fondamentalmente un modo per migliorare l'esperienza del prodotto e diminuire il livello di competenza necessario.\n\nUn altro esempio è che all'interno del flusso di lavoro ci sono sei diversi moduli di azioni diverse, ognuno denominato in modo logico per ciò che si intende risolvere, come elaborazione dei dati, assemblaggio dei documenti, ecc. All'interno di ciascun modulo, ci sono diverse azioni di intelligenza artificiale che le persone possono utilizzare nel proprio processo, come riconoscimento ottico dei caratteri (OCR), analisi del sentiment (è arrabbiata la persona che ha scritto l'email?) e altre azioni di elaborazione del linguaggio naturale.\n\nCi sono altri elementi che sono meno AI e più azioni di utilità come fornire informazioni su una persona basate sul suo indirizzo email.\n\nMolti dati scorrono attraverso i processi del retro ufficio. Purtroppo, la visualizzazione sistemica dei dati è spesso molto frammentata. Il flusso di lavoro catalizzatore può attraversare i sistemi, catturando tutto. I dati vengono memorizzati in tabelle dati ed è facile costruire modelli di apprendimento automatico basati su tali tabelle, in modo da poter prevedere gli esiti futuri di altri flussi di lavoro.\n\nCatalytic utilizza l'intelligenza artificiale in questi e altri contesti specifici per migliorare l'efficienza e offrire intuizioni e visibilità.\n\n## Chiudere l'ultimo miglio della digitalizzazione costruendo soluzioni di flusso di lavoro attorno a come le persone lavorano\n\nAd esempio, l'intelligenza operativa attraverso l'IA viene catturata nella piattaforma attraverso una funzione chiamata Insights. Per ogni flusso di lavoro, questa scheda può dirti quanto tempo ci vuole per tutti i diversi passaggi, con quale frequenza si interrompono e se si tratta di un errore umano o di un fallimento nell'integrazione. Ti offre opportunità di miglioramento. Allo stesso tempo, quell'algoritmo di apprendimento automatico può iniziare a imparare a predire gli esiti dei valori di campo. Quindi, l'apprendimento automatico può essere utilizzato in modi multipli e correlati.\n\n## Nonostante gli investimenti dopo gli investimenti, esiste ancora un divario \"ultimo miglio\" che viene colmato manualmente.\n\nLa maggior parte dei clienti che hanno investito in diverse tecnologie nel corso degli anni, ancora avvertono la presenza di una lacuna tra l'investimento e i risultati aziendali desiderati. Questa lacuna di solito viene colmata dalle persone che svolgono compiti che dovrebbero essere effettuati dal software, come il copia e incolla da un sistema all'altro. A volte, l'aggiunta di software alla combinazione complica le cose aggiungendo passaggi e addestramenti extra. La soluzione di Catalytic a queste inefficienze è un sistema riutilizzabile ed estendibile.\n\nÈ impossibile per qualsiasi software preconfezionato soddisfare le esigenze individuali di ogni azienda, ed è inefficiente e richiede tempo vedere il valore finale. Quindi le aziende devono incontrare il software dove si trova o adattare il software alle proprie esigenze aziendali. Il valore di una storia del tipo WordPress è evidente. Se il potere è effettivamente nelle mani dei dipendenti, è possibile avere un software veramente personalizzato. Catalytic desidera mettere questo potere in atto per qualsiasi processo aziendale utilizzando RPAs combinati con azioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Chou","Neil Bahandur"],"link":"/episode-EDT31-it","image":"./episodes/edt-31/it/thumbnail.png","lang":"it","summary":"Nella prima parte di due episodi, Sean Chou, CEO di Catalytic, e Neil Bahandur, responsabile delle partnership di Catalytic, si uniscono a Darren per parlare della tecnologia di Catalytic e di come gli RPA possano aiutare i dipendenti a diventare più preziosi attraverso l'automazione dei processi ripetitivi dell'ufficio retrostante."},{"id":102,"type":"Episode","title":"Approccio No Code (RPA) per l'efficienza degli uffici amministrativi","tags":["rpa","automation","catalytic","compute","process","technology"],"body":"\r\n\r\n## Cosa significa catalitico?\n\nCatalytic è una piattaforma cloud senza codice per la creazione di soluzioni di flusso di lavoro che migliorano e automatizzano le operazioni del tuo ufficio amministrativo.\n\nUn'analoga utile per aiutare le persone a capire ciò che Catalytic può fare per il flusso di lavoro dell'ufficio amministrativo è ciò che Wordpress ha fatto per la pubblicazione web. Prima di Wordpress, creare un sito web era un compito complesso che coinvolgeva molte persone con una varietà di competenze specializzate. Con Wordpress e software successivi più avanzati, la creazione di un sito web è un compito relativamente semplice. Un designer o un esperto di contenuti, ad esempio, possono facilmente creare un sito web da soli.\n\nL'obiettivo di Catalytic è semplificare in modo simile i sistemi disordinati e complessi del back office e creare efficienza e soluzioni tramite l'automazione dei processi robotici (RPA). Ora, grazie alla tecnologia di Catalytic, chiunque abbia una certa competenza tecnica dovrebbe essere in grado di creare autonomamente una soluzione per il back office.\n\nUna paura comune che gli RPAs causino la perdita di posti di lavoro è falsa; in realtà, crea nuove opportunità più preziose. Ad esempio, con Wordpress, ora c'è il ruolo di sviluppatore Wordpress, quindi questa progressione non ha ridotto l'insieme di competenze degli sviluppatori, ma ha aggiunto livelli di modi in cui le persone possono utilizzare tali competenze per qualcosa di più scalabile. Anche i dipendenti del back office possono utilizzare le proprie competenze per aggiungere valore o migliorare l'esperienza del cliente anziché concentrarsi su un lavoro noioso e di base intrinseco nei processi inefficienti.\n\n## Evoluzione e differenziazione del catalizzatore.\n\nCatalytic si differenzia dai suoi concorrenti, innanzitutto, per le sue radici. Attualmente, l'industria RPA deriva da due linee evolutive, una che proviene dalla macro di Excel e l'altra dai test dell'interfaccia utente. Catalytic proviene invece dal mondo del Dev Ops, automatizzando i processi di back office attraverso scripting anziché avere una visione orientata allo schermo dell'automazione. Quando Sean Chou ha co-fondato Catalytic, ha pensato in termini di project management e di come orchestrare i processi aziendali abituali.\n\n## Catalytic è appositamente progettato per operazioni e processi aziendali ricorrenti.\n\nChou si rese conto che poiché l'85% o più delle attività aziendali è costituito da operazioni standard, molte di queste potrebbero essere automatizzate, consentendo così alla piattaforma di svolgere alcune di queste attività. Tutto è cominciato con un semplice sistema di notifiche automatizzate che ha sostituito l'invio di email da parte dei dipendenti, il che ha spinto Catalytic a creare sempre più azioni. Per amplificare le capacità della piattaforma, Catalytic ha creato un ecosistema con partner di terze parti come Google per sfruttare le loro tecnologie. Attraverso l'ecosistema, c'è anche il vantaggio di poter comporre un flusso di lavoro aziendale in cui le persone possono creare un flusso di lavoro sulla piattaforma e salvarlo, essenzialmente, come un'unità di lavoro individuale. Ad esempio, se ci sono sei passaggi standardizzati per registrare un cliente, è possibile crearli una volta e salvarli come azione sulla piattaforma, quindi condividerli con tutto il team. Questa condivisione imita l'approccio degli sviluppatori di software nel risolvere problemi complessi condividendo il codice, ma invece del codice, si tratta di azioni. Comporre, quindi, diventa molto più facile.\n\nCatalytic ha adottato un approccio ponderato al provisioning, al deployment e alla gestione di tutto sulla loro piattaforma. Il cloud non è un'aggiunta successiva; hanno creato una piattaforma cloud da zero. Tutto ruota attorno al cloud, anche se hanno anche la capacità di lavorare con sistemi on-premises e ambienti ibridi.\n\n## Catalytic è progettato per consentire un programma di sviluppo di cittadini di classe enterprise.\n\nIl sistema è stato creato in un ambiente dev ops e funziona come un gestore di creazione per l'azienda, dove gli operatori aziendali possono effettivamente farlo da soli. I vecchi sistemi di creazione come Clear Case erano difficili da gestire, mentre Catalytic ha semplificato le cose. Non solo elimina passaggi extra, ma cambia anche la divisione del lavoro. Catalytic si rivolge alle persone più vicine al processo effettivo per evitare intermediari. L'efficienza è il concetto principale. Un sistema di creazione efficiente che rilevi i bug e li rifiuti prima di cercare di consegnarli è fondamentale per il successo del processo automatizzato.\n\nLa magia dei sistemi di compilazione è che diventano più potenti quando incorporano più parti della tua infrastruttura. Ad esempio, potrebbero interagire con il tuo sistema di controllo delle versioni per recuperare il codice, potrebbero lavorare con i tuoi server per il rilascio o potrebbero interagire con Rational Robot per effettuare i test automatizzati. Naturalmente, tutto ruota attorno alle azioni. Più azioni sono digitalizzate, più il sistema può catturarle e più potente diventa.\n\nUn'altra cosa che differenzia Catalytic è l'accento sul fatto che i dipendenti svolgano un lavoro ad alto valore aggiunto. Il concetto di valore basso e valore alto nell'RPA è comune, ma invece di usarlo come una spada per dividere i gruppi, Catalytic vuole usarlo come uno scudo per proteggere le persone per aiutarle a fare il miglior uso del loro tempo e offrire un vantaggio competitivo.\n\nNel prossimo podcast, Darren, Sean e Neil continueranno la conversazione sull'approccio no-code all'efficienza dell'ufficio amministrativo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Chou","Neil Bahandur"],"link":"/episode-EDT32-it","image":"./episodes/edt-32/it/thumbnail.png","lang":"it","summary":"L'episodio di oggi è la parte 2 di una conversazione con Sean Chou, CEO di Catalytic, e Neil Bahadur, Responsabile delle Partnership di Catalytic. Parlano con Darren del loro approccio no-code all'efficienza degli uffici con una piattaforma che utilizza la tecnologia RPA e AI."},{"id":103,"type":"Episode","title":"Il black out di AWS di novembre 2020.","tags":["aws","cloudoutage","compute","csp","cloud","process","cloudreliability","multicloud","reliability"],"body":"\r\n\r\n## Cosa abbiamo imparato dall'interruzione di AWS.\n\nAmazon Web Services (AWS) ha subito un'importante interruzione al momento più inopportuno: il giorno prima del Ringraziamento nel 2020. Dato che hanno pubblicato i registri dei loro servizi, è interessante analizzarli per capire cosa è successo e cosa possiamo imparare.\n\n## Cronologia dell'interruzione di AWS\n\nMercoledì 25 novembre 2020, intorno alle 3:00 del mattino, ora standard del Pacifico (PST), AWS stava aggiornando la regione Est, aggiungendo server per aumentare la capacità di Kinesis. Kinesis è un servizio AI popolare che esegue la ricerca di modelli nei file di log e nei file video. Circa un'ora e mezza dopo l'inizio dell'aggiornamento, le allerte del server hanno iniziato a segnalare errori nei record di Kinesis. Piuttosto rapidamente, verso le 8 del mattino, hanno inizialmente individuato un paio di possibili cause all'interno dei servizi front-end. Kinesis ha diversi servizi più piccoli, un gruppo di servizi front-end e un gruppo di servizi back-end. La modalità con cui è progettato il sistema fa sì che ogni volta che un servizio back-end è in esecuzione, un thread attiva il front-end. Uno dei problemi era che il front-end ha raggiunto la soglia dei thread a causa dell'aggiunta di server al back-end durante l'aggiornamento. Una volta che hanno identificato questo problema, hanno apportato una soluzione temporanea con aggiornamenti (patch) al sistema operativo e Kinesis è tornato online verso le 10:30 di sera, completamente ripristinato intorno all'1:15 del mattino del 26 novembre. Alla fine, Kinesis non ha funzionato pienamente per 21 ore e, sebbene non tutti utilizzino questo strumento AI, l'impatto è stato diffuso.\n\n## Kinesis Impact = Impatto di Kinesis\n\nDiversi altri servizi di Amazon utilizzano Kinesis, come Amazon Cognito e CloudWatch, e hanno subito varie interruzioni. Cognito è stato sovraccaricato fino alle 14:00 circa; CloudWatch è stato fuori servizio fino alle 22:00 circa. In un effetto domino, i servizi dipendenti da CloudWatch come Lambda ed EventBridge sono stati anche fuori servizio. Poiché EventBridge non era disponibile, i servizi container LCS e LKS sono stati anch'essi influenzati.\n\nLe interruzioni sono avvenute solo nella regione Est e AWS ha tempestivamente aggiunto capacità nelle altre regioni per evitare che Kinesis fallisse in modo simile. Durante l'interruzione, gli utenti nella regione Est hanno riscontrato un problema perplesso, poiché il loro dashboard di servizio e i dashboard di servizio personali non ricevevano informazioni e mostravano falsi positivi. Quindi, ci sono state molte altre organizzazioni IT che hanno investigato sugli inconvenienti poiché non ricevevano le informazioni corrette. Sorprendentemente, AWS è stata aperta sull'intero incidente, quindi è stata una grande esperienza di apprendimento.\n\n## Lezioni apprese\n\nUna delle prime lezioni è che le operazioni semplici all'infrastruttura, come aumentare la capacità, devono essere comprese e pianificate. Ovviamente, AWS non ha solo effettuato gli aggiornamenti a caso, ma non ha compreso appieno l'impatto. Anche se un'operazione sembra routinaria, è sempre una buona idea testarla in un ambiente di prova fino alla sua completa disfunzione durante gli aggiornamenti, anche se richiede più tempo. Ciò è particolarmente importante con servizi critici per altri servizi dipendenti dal nucleo.\n\nInoltre, le architetture di servizio o micro-servizio devono comprendere l'intera struttura di dipendenza dei servizi in modo da poter risolvere i problemi quando si verificano interruzioni. È anche importante essere il più possibile disaccoppiati dalle dipendenze e includere la programmazione difensiva con i microservizi per evitare l'effetto domino che si è verificato in questo caso.\n\nUn altro problema da tenere d'occhio sono le dipendenze circolari. Se, in una catena di microservizi che dipendono tra loro, uno riscontra un problema, tutto può fermarsi bruscamente, consumando risorse e non ottenendo risultati.\n\nQuando sviluppi micro servizi, tieni presente che non avrai sempre connettività ai servizi di cui dipendi. Scrivere programmi che possano funzionare in uno stato degradato, o almeno indicare che un servizio non sta funzionando, può risparmiare tempo e problemi. In questo caso di interruzione, ricorda che i pannelli di controllo erano verdi nonostante non arrivasse alcuna nuova informazione.\n\n## Chi ha gestito al meglio l'interruzione\n\nMolte aziende sono state colpite dal disservizio di AWS, incluso alcune di proprietà stessa di Amazon. Alcune sono riuscite a superare agevolmente il disservizio, mentre altre hanno avuto più difficoltà nel riprendersi. Coloro che sono stati in grado di adattarsi velocemente avevano una strategia di cloud multi-ibrido, quindi avevano cloud alternativi come backup. Alcuni hanno utilizzato una diversa regione di AWS, mentre altri hanno utilizzato Google o Azure, e alcuni addirittura hanno fatto ritorno ai loro centri dati o siti web esterni. Almeno i siti web hanno mostrato un messaggio che stavano attualmente riscontrando problemi, invece di un errore 404.\n\nLe aziende che non utilizzavano alcuni dei servizi specializzati di Amazon hanno ottenuto risultati migliori. Ad esempio, le offerte di container gestiti EKS ed ECS e Lambda sono state colpite duramente e sono state inattive per un periodo di tempo notevole, quindi coloro che dipendevano da questi servizi sono rimasti senza opzioni.\n\nDurante il black out, i servizi di auto scaling non funzionavano correttamente, quindi qualsiasi azienda che aveva molto traffico in quel momento doveva capire cosa stesse succedendo e scalare i servizi manualmente. Questo era un problema più grande di quanto possa essere normalmente poiché era il giorno prima del Ringraziamento, un momento in cui molti consumatori sono in viaggio e fanno acquisti online. Ad esempio, Etsy è rimasta attiva, ma non potevano scalare come avrebbero normalmente fatto, il che ha portato a una diminuzione delle vendite.\n\nLe aziende che hanno un proprio monitoraggio esterno hanno ottenuto risultati migliori. Alcune di esse hanno persino avvisato AWS dei disservizi. Non erano dipendenti solo dalla dashboard di salute di AWS, ma avevano il proprio monitoraggio in esecuzione sui loro server.\n\nQual è la lezione principale che dovremmo imparare da questo? Le organizzazioni dovrebbero prendere in carico le proprie risorse cloud, proprio come farebbero con qualsiasi servizio pubblico. Come per avere un generatore di backup per l'elettricità per garantire la continuazione delle attività in caso di interruzione, le aziende dovrebbero utilizzare le stesse best practice per i servizi cloud. Ciò significa che avere una nuvola di backup che può mantenerti operativo, anche a capacità ridotte, è essenziale per superare una tempesta come l'interruzione di AWS.\n\n## Risorse\n\n* https://aws.amazon.com/message/11201/\n* https://aws.amazon.com/message/11201/\n\n* https://aws.amazon.com/message/11201/\n\nTradurre in italiano il seguente testo: * https://www.theverge.com/2020/11/25/21719396/amazon-web-services-aws-outage-down-internet\n\nNon è possibile tradurre testo da un URL. Si prega di fornire un testo specifico da tradurre.\n\nEcco cosa ha causato il grande black out di AWS la scorsa settimana, scuse.\n\nAmazon Web Services colpito da un'interruzione del servizio.\n\nTraduci il seguente testo in italiano: *https://www.washingtonpost.com/technology/2020/11/28/amazon-outage-explained\n\nSpiegazione dell'interruzione di Amazon\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT33-it","image":"./episodes/edt-33/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Settore Pubblico, presso Intel parla delle lezioni apprese dall'interruzione di AWS nel novembre 2020 e delle soluzioni preventive per affrontare tali interruzioni."},{"id":104,"type":"Episode","title":"Abbracciare l'evoluzione dello spazio di lavoro","tags":["covid","mfa","remoteworker","cybersecurity","people","technology","vdi","vpn"],"body":"\r\n\r\n## I luoghi di lavoro digitali stanno evolvendo.\n\nDal momento che abbiamo superato il caos iniziale delle transizioni necessarie a causa della pandemia, dobbiamo chiederci cosa arriverà dopo e, in avanti, come possiamo sfruttare ciò che abbiamo imparato per investire consapevolmente dove vogliamo arrivare.\n\nUna lezione importante è stata che le organizzazioni che già erano agili si sono comportate bene. Sono state in grado di far partire rapidamente il loro personale remoto. Non sappiamo esattamente quale sarà la nuova normalità, ma sappiamo che manterrà molti degli stessi aspetti che sono stati accelerati negli ultimi otto mesi, come l'abilitazione di un personale remoto, ma allo stesso tempo sarà più collaborativa. Intel desidera raggiungere nuovi clienti che necessitano di più risorse per operare al di fuori delle loro mura e diventare più agili.\n\n## Il tuo luogo di lavoro ha bisogno di nuove capacità: Intel colma il divario.\n\nIntel si impegna nella creazione di soluzioni aiutando i clienti a comprendere l'ampio ecosistema Intel con diversi modelli che possono colmare le lacune in termini di prestazioni, stabilità, efficienza e prezzo. Intel può condividere le esperienze di migliaia di clienti per aiutare a risolvere i problemi e fornire capacità che le organizzazioni IT a volte non sono in grado di fare da sole.\n\n## I requisiti aziendali sono fondamentali\n\nIn passato, un CIO poteva essere concentrato solo su tre cose: sicurezza, resilienza ed efficienza. Questo non è più il caso. Quello che una volta era equivalente a mantenere accese le luci, rimanere fuori dai guai e funzionare efficientemente, è ora molto più complesso. Le aziende devono essere orientate al futuro per migliorare il lavoratore, il luogo di lavoro e le trasformazioni che stanno affrontando per soddisfare gli impegni con i clienti e i fornitori.\n\nInoltre, l'agilità è un requisito essenziale poiché le circostanze possono cambiare rapidamente e le aziende devono adattarsi in multiple direzioni pur soddisfacendo sempre queste esigenze.\n\nInfine, l'automazione tramite intelligenza artificiale favorisce aree come una migliore collaborazione e miglioramento dell'esperienza lavorativa. Con una forza lavoro distribuita, ad esempio, non esiste un assistente con una persona che può venire a aiutarti con il tuo problema. In ogni caso, questo potrebbe non essere il scenario più efficiente, quindi forse i chatbot o l'apprendimento automatico in un sistema CRM sarebbero più efficienti e consentirebbero una maggiore condivisione delle informazioni. Questo tipo di automazione tecnica con la risoluzione comune dei problemi potrebbe generare più connessioni, intuizioni e produttività alla fine.\n\n## Il tuo luogo di lavoro sta evolvendo.\n\nI requisiti e le strategie aziendali stanno cambiando, soprattutto riguardo all'evoluzione dei luoghi di lavoro. Alcune organizzazioni continueranno con un'operatività completamente remota, altre vorranno riportare tutti in ufficio quando sarà sicuro, e ci saranno tutte le configurazioni possibili tra queste due estremità. Indipendentemente dalla situazione, le organizzazioni devono abbracciare una strategia per assicurarsi di poter raggiungere i lavoratori in qualsiasi luogo, in qualsiasi momento e su qualsiasi dispositivo, che sia per necessità o per scelta.\n\nIl miglioramento del processo è anche fondamentale. Non si desidera continuare ad aggiungere processi a quelli più necessari. Valutare le aree di miglioramento, che si tratti di infrastrutture interne o capacità di terze parti, aggiungerà efficienza e valore. Piuttosto che costruire un'enorme infrastruttura che richiede gestione e viene gravata dall'utilizzo esclusivo delle sue proprie risorse, le organizzazioni dovrebbero valutare l'incredibile quantità di opportunità di ecosistema che si collegano agli strumenti di tipo \"as-a-service\". L'esternalizzazione dei servizi che non rappresentano asset o punti di forza strategici per la propria azienda potrebbe avere più senso.\n\nUn'altra area da valutare è la gestione dei dati. Ad esempio, con tutti i dati presenti negli strumenti di collaborazione, la proliferazione dei dati diventa un problema. È necessaria una strategia chiara ed efficace.\n\nInsieme alla gestione dei dati arriva la sicurezza. I dati sono ora sparsi ovunque, quindi le organizzazioni devono adottare, valutare e implementare buoni strumenti di sicurezza e buone procedure di lavoro per la gestione dei dati.\n\n## Intel Offre\n\nCi sono sei principali capacità nell'ambiente di lavoro in evoluzione in cui Intel può dare aiuto: accesso alle app e ai dati, gestibilità, sicurezza potenziata, connettività, infrastruttura di collaborazione e ambienti multicloud. Nonostante Intel produca solo silicio, le capacità, la scalabilità e la sicurezza offerte soddisfano le esigenze di organizzazioni di qualsiasi dimensione, dalla più piccola alla più grande.\n\nIntel cerca di esistere in diversi ambienti e offrire la gestione di tali risorse. Sebbene i clienti non acquisteranno direttamente da Intel beni come processori, acceleratori, memoria, storage, ecc., sfrutteranno l'ecosistema robusto e affermato di prodotti come produttori di hardware, OEM, fornitori di software, integratori di sistemi e fornitori di servizi cloud reso possibile da Intel.\n\nUna delle forze di Intel è il suo supporto a questo ecosistema. Ad esempio, Intel conta su 15.000 ingegneri software che sviluppano codice, ma nessuno di esso viene venduto. Invece, loro aiutano a sviluppare l'ecosistema fornendo nuove soluzioni basate sul silicio. Il silicio è il meccanismo per offrire soluzioni che aiutano le persone a risolvere problemi reali. Una buona metafora è che la distanza tra il molo di carico di Intel come produttore e il molo di carico finale del cliente è troppo grande affinché Intel possa guidare un camion da solo. L'ecosistema si occupa di colmare questa distanza.\n\n## Aree di soluzione che potresti valutare\n\nCome i clienti possono sfruttare al meglio le capacità dell'ecosistema? Intel può fornire raccomandazioni nelle sei aree chiave, che tu stia lottando con una soluzione VDI come decidere se dovrebbe restare in locale o essere in un desktop virtuale o servizio RDS, o elaborando una strategia VPN che garantirà la connettività.\n\nParte della soluzione sta nel comprendere che, poiché Intel opera in un ecosistema così vasto, può contribuire a rispondere a una miriade di sfide. Intel non è necessariamente intenzionata a vendere un processore, ad esempio, ma ad aiutarti a ottenere la migliore realizzazione del tuo carico di lavoro possibile, che potrebbe risiedere nei fornitori di servizi cloud o in più cloud, all'interno e all'esterno del tuo centro dati. L'obiettivo di Intel è fornirti efficienza, portabilità e agilità in questi processi.\n\n## Abbraccia l'evoluzione del luogo di lavoro: quando o dove vuoi iniziare?\n\nIntel ha a cuore gli interessi della tua organizzazione perché se hai successo nella tua attività, troverai nuovi modi per utilizzare i dati e nuovi modi per utilizzare l'infrastruttura per fornire maggior valore ai tuoi clienti e, alla fine, consumare di più. Le tue strategie, crescita e sviluppo sono tue, ma Intel ti fornirà le fondamenta per prendere buone decisioni.\n\nCerca opportunità per interagire con il tuo rappresentante Intel. Hanno a disposizione un'ampia gamma di risorse per aiutarti a sfruttare la vasta rete di partner in grado di affrontare i tuoi problemi e i tuoi obiettivi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Robert Looney"],"link":"/episode-EDT34-it","image":"./episodes/edt-34/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect del settore pubblico, e Robert Looney, Americas Data Center Sales Manager di Intel, parlano dell'utilizzo di un approccio strategico per abbracciare l'attuale evoluzione del luogo di lavoro. La pandemia di COVID ha creato sfide e transizioni significative nel luogo di lavoro. Intel sta aiutando i clienti a sfruttare le tecnologie per affrontare al meglio le sfide in corso nella nuova normalità."},{"id":105,"type":"Episode","title":"Navigare il cambiamento disruptivo","tags":["change","culturalchange","organizationalchange","disruption","people","process"],"body":"\r\n\r\nRick ha recentemente festeggiato il suo terzo decennio presso Intel e, in questo periodo, ha aiutato Intel a navigare attraverso enormi quantità di cambiamenti e grandi eventi. Oltre a situazioni competitive difficili e cambiamenti nell'industria iniziati con la diffusione di internet e il boom e il crollo delle dot.com, ci sono stati eventi esterni come l'11 settembre, la Grande Recessione e, ora, la pandemia di COVID-19.\n\n## Tipi di situazioni di crisi\n\nLa natura di un'azienda moderna in un'economia moderna è quella di navigare costantemente in un alto grado di incertezza, turbolenza, cambiamento e interruzione. Le organizzazioni o si lasciano morire in quei momenti o emergono migliori e più forti.\n\nOgni interruzione è diversa in termini di magnitudine e velocità. Alcuni eventi si svolgono nel corso di un lungo periodo di tempo, forse un cambiamento tecnologico o strutturale nell'industria, e poi improvvisamente si accelerano. Alcuni, come il COVID, hanno un impatto elevato a una velocità senza precedenti. Ciò che è interessante del COVID, però, è che abbiamo sviluppato la tecnologia per affrontare le conseguenze della pandemia da un decennio, ma è stato necessario questo evento per metterla in uso pratico. Un buon esempio è la telemedicina. Il suo improvviso, diffuso utilizzo ha anche modificato l'ambiente delle politiche e il panorama sanitario non sarà mai più lo stesso.\n\nQuesto tipo di cambiamento fondamentale della politica si verifica in eventi con grande rapidità, come la Grande Recessione o l'11 settembre. Cose simili accadranno dopo il COVID. Questi eventi, per quanto difficili, offrono alle organizzazioni l'opportunità di compiere un enorme balzo in avanti nel modo in cui si esibiscono e nel modo in cui utilizzano la tecnologia.\n\n## Navigare il cambiamento disturbante\n\nIntel si è sempre messa avanti nel rispondere a grandi sfide e interruzioni. Parti fondamentali della cultura sono prontezza, scopo condiviso e fiducia. Queste possono esistere quando i dipendenti hanno un senso di sicurezza psicologica. Ad esempio, Darren si è sentito autorizzato quando il CEO di Intel ha detto che nessuno sarebbe stato licenziato a causa del COVID. Ciò gli ha permesso di correre rischi per affrontare la crisi senza alcuna paura di perdere il suo lavoro. E sebbene il CEO e i manager senior impostino il tono, la maggior parte del lavoro sulla sicurezza psicologica è svolto dai manager di prima linea. Questa sicurezza e autorizzazione porta a una prontezza integrata. Insieme a uno scopo condiviso e fiducia, questi sono i blocchi fondamentali non solo di un'organizzazione pronta a rispondere a una crisi, ma delle caratteristiche di un'organizzazione ad alte prestazioni.\n\nUn'organizzazione ad alto rendimento avrà anche gli strumenti per gestire le perturbazioni che sono più un fuoco lento piuttosto che un evento rapido ad alto impatto. Con eventi come il COVID o la Grande Recessione, c'è ben poco dibattito su ciò che sta accadendo e tutti sono consapevoli dell'enormità dei problemi. Se confronti ciò con, ad esempio, un cambiamento fondamentale nel business, un cambiamento architettonico o una tecnologia manifestata sulla curva dell'entusiasmo di cui non sei ancora sicuro che sia rilevante per l'azienda, ci saranno più incertezze e dibattiti sugli adeguamenti necessari.\n\nCome fa un'organizzazione a sopravvivere in questi punti di svolta? La telemetria, o l'input che stai valutando, è importante. Una delle complessità in una grande organizzazione è che quando questi input arrivano a un responsabile decisionale di alto livello, potrebbero essere stati attraversati da tre livelli di manipolazione e posizionamento, e ciò può essere pericoloso. La verità e la trasparenza sono valori fondamentali in Intel. In un'azienda con un alto grado di sicurezza psicologica, i dipendenti possono dire la verità sui problemi.\n\nIl contributo più importante è ascoltare i tuoi clienti perché tendono a guidarti nella giusta direzione. Ad esempio, se qualcuno vuole conoscere informazioni su un account, Rick spesso coinvolgerà il responsabile dell'account per ottenere informazioni di prima mano. È anche una saggezza di leadership andare direttamente agli esperti anziché ottenere informazioni attraverso tre livelli di filtraggio e adattamento, specialmente durante una crisi. Incontrare il momento si riduce alla cultura della prontezza, alla telemetria corretta e alla presa di decisioni.\n\nLa presa di decisione può diventare confusa in una grande organizzazione. Una semplice soluzione è che ogni persona che entra in una riunione dovrebbe chiedersi: siamo qui per prendere una decisione? Chi è il responsabile della decisione? Oppure, stiamo semplicemente dibattendo o preparando il telemetria e i dati per il responsabile delle decisioni? Questo è solo un buon igiene organizzativa.\n\nAndy Grove disse: \"Lasciate che regni un po' di caos e poi domate il caos\". Per le decisioni sui punti di inflessione, gli sviluppi lenti, a volte si deve lasciar respirare e fermentare un po' l'innovazione, ma allo stesso tempo si vuole gestire le cose in modo tale che non sfuggano di mano. Avere buoni processi e protezioni in atto aiuta in questo.\n\nIn tempi difficili, i responsabili delle decisioni devono avere una profonda comprensione che le persone si troveranno ognuna in uno spazio diverso e devono valutare l'impatto delle decisioni. La sicurezza psicologica è molto importante e i manager di prima linea e di seconda linea sono fondamentali per la capacità di un'organizzazione di eseguire bene durante periodi di interruzione. La leadership senior ha un ruolo chiave nel dare il tono, ma sono questi manager a portare avanti il lavoro.\n\nDalle prevedibili modifiche tecnologiche future come l'impatto dell'IA sul 5G, ai problemi come i cambiamenti climatici, agli eventi mondiali imprevisti, l'unica costante è che saremo sempre a navigare tra interruzioni, crisi e cambiamenti. Uno dei tratti distintivi della cultura di Intel è la sua capacità di rispondere, adattarsi e essere resiliente a questi eventi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rick Herrmann"],"link":"/episode-EDT35-it","image":"./episodes/edt-35/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect, Public Sector, e Rick Hermann, Director US Public Sector, Intel, discutono come Intel sia stata di successo nel navigare i cambiamenti disruptivi negli ultimi tre decenni."},{"id":106,"type":"Episode","title":"Sei pilastri della sicurezza informatica","tags":["cybersecurity","prevention","threatdetection","zerotrustarchitecture","zta","technology"],"body":"\r\n\r\nCon l'aumento degli attacchi informatici in tutti i settori, la sicurezza è più importante che mai. In questa puntata, Darren e Steve Orrin, CTO federale di Intel, descrivono i vettori di attacco, le sei colonne portanti della sicurezza informatica e come Intel può aiutare.\n\nSteve ha visto l'evoluzione della sicurezza nei 25 anni in cui ha lavorato nel campo, sia come scienza che come arte. Allo stesso tempo, il livello di complessità con cui le organizzazioni devono confrontarsi per proteggere i loro dati, sistemi e applicazioni non è mai stato così difficile.\n\n## Grandi violazioni su larga scala e attacchi informatici continuano\n\nGravi violazioni dei dati su larga scala e intrusioni profonde stanno accadendo a tutti i livelli, da piattaforme di social media ai servizi finanziari fino all'assistenza sanitaria. Nessun tipo di dati è esente dal essere preso di mira con tecniche sempre più sofisticate.\n\nCosa sta causando questi attacchi? Una risposta è che oggi un attacco su larga scala o profondo richiede meno risorse e meno investimento finanziario. La portata e l'entità di ciò che un hacker può fare con un piccolo investimento hanno dato agli avversari un vantaggio in un sistema complesso.\n\n## Tre forze che influenzano la sicurezza aziendale e missioni.\n\nUn'altra risposta a ciò che sta alimentando gli attacchi è che i dati sono un asset prezioso: il nuovo petrolio. I dati sono vulnerabili poiché l'espansione della superficie di attacco continua a crescere.\n\nCi sono più punti di integrazione, prodotti, sistemi operativi forniti da diversi vendor e dispositivi che sono coinvolti nella gestione, nell'utilizzo e nel trasporto dei dati. I dati sono sempre più lontani dal controllo dell'azienda. A volte nemmeno siamo sicuri di dove esistano i nostri dati. Ad esempio, forse hai condiviso i tuoi dati con un'altra organizzazione e loro hanno condiviso l'analisi effettuata su tali dati. Spesso questi metadati si trasformano in residui di dati. I tuoi dati stanno fluendo attraverso più sistemi e possono essere accessibili ad un attaccante successivamente.\n\nL'industria della sicurezza stessa è composta da migliaia di fornitori di sicurezza e prodotti che risolvono un particolare pezzo del puzzle, quindi c'è solo tanto che un CIO può fare con un budget limitato e solo tanto che può gestire data la complessità. Dobbiamo pensare in modo olistico a come possiamo proteggere i nostri dati, non solo a come proteggere un singolo passaggio tra il punto A e il punto B. I dati vengono compromessi nel punto più debole, quindi dobbiamo guardare a tutta la catena.\n\nLa terza forza che impatta le imprese è la localizzazione degli attacchi. Questi includono attacchi su tutta la gamma hardware, firmware, bios, software, servizi e applicazioni. Con l'aumento della sofisticazione degli attacchi, stiamo vedendo attacchi a più livelli in modo asincrono e indipendente.\n\n## I vettori di attacco\n\nI hacker non attaccano solo l'hardware o un pezzo di software, ma attraverso molteplici vettori: persone, processi e tecnologia.\n\nTradizionalmente, l'implementazione dei controlli di sicurezza ha coinvolto la corretta formazione delle persone e l'utilizzo di processi e tecnologie appropriati, ma alla luce degli attacchi recenti, dobbiamo ricordare che il processo stesso è vulnerabile. Ad esempio, dobbiamo passare all'applicazione automatica delle patch per ridurre la finestra di esposizione dal momento in cui viene scoperta una vulnerabilità al momento in cui una patch viene rilasciata e implementata da un'organizzazione. Tradizionalmente, abbiamo vissuto con il rischio che gli attaccanti potessero sfruttare la vulnerabilità per mesi.\n\nCi sono altri attacchi al processo che stiamo sigillando solo ora, che sia nel processo di sviluppo o nel ciclo di vita dello sviluppo del software. Integrare la sicurezza fin dalle prime fasi del ciclo di vita dello sviluppo è l'aspetto più importante per garantire la sicurezza di un'applicazione. Ciò significa che sviluppatori, QA e progettisti devono tutti essere coinvolti nel processo di sicurezza. Una parte della sfida è rappresentata dalla natura compartimentata di ciascuna parte del processo, dove le vulnerabilità possono infiltrarsi nelle giunzioni e nelle transizioni.\n\n## Sei pilastri della sicurezza informatica\n\n## Sicurezza della catena di approvvigionamento\n\nLa sicurezza della catena di approvvigionamento è stata al centro dell'attenzione solo negli ultimi anni. Un'organizzazione deve essere in grado di fidarsi dei server, dei componenti e del software. Una buona catena di approvvigionamento con trasparenza è importante per convalidare che tutto provenga da fonti legittime. C'è stato un focus, in particolare nel governo, sulla catena di approvvigionamento hardware, ma non possiamo dimenticare la catena di approvvigionamento del software. La catena di approvvigionamento del software è un po' più difficile rispetto all'hardware poiché spesso manca di visibilità in quanto i prodotti possono essere assemblati da strumenti open source, prodotti di altre persone, ecc. In un recente attacco, la catena di approvvigionamento del software è stato il problema, e questo è solo la punta dell'iceberg.\n\n## Sicurezza dell'host e del sistema.\n\nUna volta che abbiamo una catena di approvvigionamento affidabile, il passo successivo riguarda la sicurezza del sistema di hosting. La base sono le tecnologie di avvio sicuro e le capacità crittografiche per bloccare e proteggere dispositivi fisici e sistemi in cui le applicazioni funzionano e i dati vengono eseguiti. Questo sistema supporta le funzionalità di sicurezza a livello superiore nello stack hardware.\n\n## Sicurezza dei dati e delle applicazioni.\n\nSopra la sicurezza dell'host e del sistema è dove si costruisce la sicurezza del carico di lavoro dell'applicazione. I dati devono essere protetti durante tutto il loro ciclo di vita, a riposo, in uso e in transito. Da molto tempo abbiamo garantito la sicurezza dei dati a riposo e in transito utilizzando la crittografia dei trasporti, TLS e IPsec, e altre capacità di crittografia, oltre alla crittografia del disco e dei file. Il collegamento mancante è stata la memoria crittografata \"in uso\" con isolamento hardware. Negli ultimi anni, le tecnologie e le soluzioni abilitano l'ultima parte di esposizione legata alla protezione dei dati.\n\n## Sicurezza di rete\n\nIn parallelo a questa serie di fornitori della catena di approvvigionamento e sicurezza dei dati, abbiamo bisogno di sicurezza di rete. L'integrità e la disponibilità delle reti sono importanti per resistere agli attacchi di denial of service. I dati devono essere trasmessi in modo sicuro fino alla loro destinazione. Dobbiamo anche monitorare e proteggere le reti dalle intrusioni esterne, che si tratti di una rete aziendale o di una rete distribuita in tutta la nuvola e i suoi margini. La sicurezza qui non riguarda semplicemente un semplice firewall, ma è una produzione attiva.\n\n## Gestione dell'identità e dell'accesso\n\nLa gestione dell'identità e degli accessi è una capacità di base. Non dobbiamo solo sapere chi si sta autenticando, ma chi si sta autenticando su quale dispositivo. L'essere umano è in realtà solo una piccola parte del puzzle. Abbiamo bisogno di avere un'identità per tutte le cose, i processi e i servizi che accedono e gestiscono i dati. Una persona potrebbe svolgere il proprio lavoro con pochi semplici tasti, ma potrebbero esserci 20 diversi dispositivi e 100 servizi e processi che agiscono sui dati. Abbiamo bisogno di avere politiche e autorizzazioni per tutte queste entità. E man mano che ci muoviamo verso processi autonomi, ci sono sempre meno persone coinvolte, quindi diventa ancora più importante avere un'identità forte per quei processi senza un coinvolgimento umano.\n\n## Rilevamento delle minacce, Intelligence e Analisi\n\nQuesto ultimo pilastro è una combinazione di molte cose, tra cui l'intelligence sulle minacce, l'analisi dei dati, il monitoraggio e l'auditing. È la visibilità generale che assicura che tutto stia funzionando come dovrebbe e, se qualcosa va storto, la capacità di capire rapidamente da dove proviene e perché. Questo è l'ombrello che guida la sicurezza dei dati e tutto deve essere collegato e integrato. C'è un passaggio dal lavorare in un ambiente isolato, ad esempio da un fornitore interessato solo alla sicurezza della rete, a lavorare nell'intero sistema. Le aziende di successo hanno squadre diverse con persone provenienti da domini diversi per soddisfare le complesse esigenze di sicurezza.\n\n## Domini della sicurezza informatica: raggiungere la fiducia zero con le tecnologie Intel\n\nIntel fornisce capacità fondamentali in ognuno dei sei pilastri, che sia attraverso la nostra iniziativa di sicurezza del ciclo di vita del computer per aiutare gli OEM e i fornitori di componenti a collaborare in una catena di approvvigionamento affidabile, che fornendo i blocchi di costruzione fondamentali della sicurezza di sistema, con l'avvio sicuro che parte dal hardware. Abbiamo tecnologie di esecuzione e tecnologia di protezione all'avvio con accelerazione crittografica integrate, in modo che gli utenti possano attivarle per la protezione dei dati a riposo, dei dati in uso e dei dati in transito senza impatti sulle prestazioni.\n\nNel caso dell'intelligence per la rilevazione delle minacce, Intel fornisce primitive come TPD in cui una soluzione di livello superiore può offrire visibilità e rilevamento delle minacce dove non l'abbiamo mai avuto prima.\n\nIntel è un fornitore di tecnologia, ma lavoriamo anche nell'ambito delle persone e dei processi. Un buon esempio è la catena di approvvigionamento. Abbiamo costruito un processo con l'ecosistema per consentire a un'azienda di convalidare i componenti e i requisiti per una determinata piattaforma e i suoi componenti. Allo stesso modo, ci sono processi coinvolti nella protezione dei dati e dell'uso attraverso le capacità dell'hardware come SGX, che è in grado di crittografare la memoria e isolare i dati e il codice per un'applicazione specifica.\n\nIntel sta abilitando processi sicuri per sfruttare le tecnologie su larga scala. Un'altra parte fondamentale riguardo al processo è l'integrazione nel quadro complessivo di rischio di un'organizzazione. Intel ti fornisce le prove e l'attribuzione di cui hai bisogno all'interno delle nostre tecnologie per mapparle nel tuo quadro di rischio esistente.\n\nL'ultimo elemento sono le persone. Affrontare il comportamento umano casuale è a volte la parte più difficile della sicurezza, che si tratti di truffe di phishing o attacchi mirati a password deboli. La formazione è cruciale, ma spesso non è sufficiente. Processi e tecnologie possono aiutare ad integrare la formazione, ad esempio rendendo le password più sicure o eliminando il phishing se le credenziali dell'utente non possono essere compromesse. Alla fine della giornata, però, la formazione continua e l'istruzione saranno sempre fondamentali insieme alle tecnologie di mitigazione.\n\nLa sicurezza è difficile, ma ci sono luci alla fine del tunnel con tutte le innovazioni nell'ecosistema e con organizzazioni aperte a fare le cose in modo diverso. Dobbiamo mantenere il nostro occhio su due cose: l'adozione di quadri di riferimento sul rischio e la fiducia zero. Collegare questi due mondi insieme, il dominio della sicurezza informatica ai motori di politica e all'applicazione può fornire un approccio completo alla sicurezza. C'è molta attività qui e molto lavoro ancora da fare.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT36-it","image":"./episodes/edt-36/it/thumbnail.png","lang":"it","summary":"Con gli attacchi informatici in aumento in tutte le industrie, la sicurezza è più importante che mai. In questo episodio, Darren Pulsipher, Chief Solution Architect, e Steve Orrin, CTO federale presso Intel Federal, delineano i vettori di attacco, i sei pilastri della sicurezza informatica e come Intel può aiutare. Il livello di complessità con cui le organizzazioni devono confrontarsi per proteggere i loro dati, sistemi e applicazioni non è mai stato così difficile."},{"id":107,"type":"Episode","title":"2020 in Rassegna","tags":["covid","cybersecurity","remoteworker","people","process","compute","data"],"body":"\r\n\r\n## 2020 - Aspettative\n\nPre-COVID, il 2020 sembrava l'anno dei nuovi modelli aziendali, orientati verso grandi trasformazioni digitali. L'intelligenza artificiale/ apprendimento automatico e l'analisi avrebbero svolto un ruolo chiave in futuro. Utilizzando questi strumenti, avremmo iniziato a utilizzare i dati in modo più efficace nelle nostre organizzazioni. Sarebbe stato l'anno del 5G, con il 5G che avrebbe fatto una grande impressione alle Olimpiadi.\n\nStavamo anche per assistere a un grande passo avanti nell'industria per le trasformazioni 4.0, con l'Internet delle Cose e la produzione che si muovono insieme verso questa trasformazione digitale.\n\n## 13 marzo\n\nPoi, almeno in California, tutto si fermò bruscamente venerdì 13 marzo. Aziende, scuole, conferenze, incontri, viaggi ed eventi sociali chiusero improvvisamente. Le settimane si trasformarono in mesi mentre l'ottimismo di contenere rapidamente il virus svanì, mentre città come New York subirono pesanti colpi e i sistemi medici furono sopraffatti. Tutto sembrava caotico e incerto.\n\nAlcune cose interessanti sono emerse da questo: alcune aziende hanno prosperato mentre altre hanno avuto più difficoltà, e le persone hanno cominciato a lavorare in remoto.\n\n## Sito web più visitato nella mia casa.\n\nNella mia casa, il sito web con il maggior numero di visualizzazioni non era più Facebook, ma il Centro di Scienze e Ingegneria dei Sistemi presso Johns Hopkins, che fornisce statistiche sul virus. Potevamo vedere gli effetti nel nostro quartiere, nella nostra città e in tutto il mondo. La nostra intera percezione di ciò che era importante e di ciò che avevamo pianificato per quell'anno è cambiata.\n\n## Scarsezze.\n\nNon solo c'erano carenze immediate di articoli come carta igienica, disinfettante per le mani e lievito, ma dopo alcune settimane l'attrezzatura per ufficio e la tecnologia sono diventati articoli molto richiesti poiché le persone si adattavano rapidamente all'apprendimento a distanza e al lavoro da casa. Ciò ha creato una carenza di strumenti indispensabili come webcam e laptop.\n\nI router Wi-Fi 6 sono diventati importanti all'improvviso mentre l'uso di Internet a casa aumentava. Nella nostra famiglia, sono passato da lavorare occasionalmente a casa a lavorare a tempo pieno da casa e ho aggiunto tre teenager che seguivano la didattica a distanza e tre studenti universitari adulti che sono tornati a casa per studiare e lavorare. La nostra connessione Internet è stata presto sopraffatta. Ho avuto difficoltà a trovare un router Wi-Fi 6 per risolvere il nostro problema, poiché molti si trovavano in situazioni simili.\n\n## Il viaggiare ha cambiato.\n\nCon i viaggi praticamente fermi, molte persone si sono invece dedicate a progetti di ristrutturazione domestica. Ero solito trovarmi spesso in aeroporto, con i viaggi che occupavano metà della settimana. Ora, mi ritrovo a Lowe's o Home Depot insieme a tutti gli altri. I negozi erano affollati. Il tempo che solitamente trascorrevo in viaggio ora veniva impiegato per costruire un capanno con i miei figli. Ho avuto la possibilità di trascorrere più tempo di qualità con i miei bambini e migliorare la mia casa.\n\n## Conferenze\n\nUna grande svolta, ovviamente, è stata la cancellazione delle conferenze in presenza. Molte sono state trasferite online ottenendo ottimi risultati. Ad esempio, la conferenza IBM Think ha sostituito il suo evento in presenza di maggio con una versione online. Hanno partecipato oltre 100.000 persone, il che la rende la conferenza più grande che abbiano mai avuto.\n\nOltre all'aumento di partecipanti, un altro vantaggio è che i partecipanti non devono impegnarsi per un'intera settimana per partecipare a una conferenza, ma possono selezionare le sessioni e rimanere comunque a casa con la famiglia. Lo svantaggio è l'assenza di opportunità di networking e di vedere le persone di persona.\n\nLe conferenze dell'industria sono probabilmente cambiate per sempre. Non saranno sempre completamente online, ma probabilmente avrebbe senso una versione ibrida in futuro.\n\n## Lavoro forzato da casa\n\nUn'altra grande trasformazione è che virtualmente siamo nelle case l'uno dell'altro per condurre affari. A volte ci sono bambini, cani o altre distrazioni inevitabili sullo sfondo. Una volta, il mio capo ha dovuto far sedere sua figlia accanto a lui mentre dirigeva una riunione dello staff perché aveva bisogno di aiuto con qualcosa. È importante che siamo tutti flessibili durante questo periodo.\n\n## Lavoratori nomadi\n\nAlcuni dipendenti non lavorano più da casa, ma sono diventati nomadi poiché non hanno più bisogno di essere vicini al loro posto di lavoro.\n\nAd esempio, mio nipote, che ha poche responsabilità domestiche, stava pagando un affitto spropositato nell'area della Baia. Quando il lavoro è diventato remoto, lui e i suoi coinquilini hanno lasciato il loro costoso appartamento e hanno invece viaggiato per il mondo, passando diversi mesi alla volta affittando case in posti interessanti.\n\nQuesto è un cambiamento radicale nel modo in cui pensiamo di gestire i nostri lavoratori, beni e dati.\n\n## Lavoro da remoto\n\nIl lavoro a distanza è stato rapidamente intensificato. Molte aziende avevano già delle politiche di lavoro a distanza o dei piani per aumentare il lavoro a distanza. Ma ciò che era probabilmente un piano di implementazione di 18 mesi è diventato un piano di implementazione di 18 giorni.\n\nLa principale forma di lavoro da remoto che si è diffusa è stata la VDI (infrastruttura di desktop virtuali). Le persone hanno utilizzato la VDI da decenni, ma all'improvviso è diventata la scelta migliore, in parte a causa della sua familiarità. È veloce, facile ed economico far tornare le persone al lavoro fornendo loro accesso ai dati di cui hanno bisogno utilizzando soluzioni hardware.\n\nLe VPN (reti virtuali private) sono diventate rapidamente sovraccaricate poiché tutti lavoravano da casa. Abbiamo visto le aziende investire nell'ampliamento dei propri VPN, sia attraverso l'acquisto di nuove licenze che con l'aggiornamento dell'infrastruttura, espandendole secondo necessità.\n\nLe aziende hanno anche accelerato l'adozione degli strumenti SaaS (software as a service). Ad esempio, la distribuzione di Office 365 è avvenuta in poche settimane anziché nei previsti sei-nove mesi. Aziende con offerte SaaS come Microsoft e Google si sono messi all'opera e hanno aiutato le organizzazioni a completare la migrazione rapidamente. Per i lavoratori in remoto, il tempo improductivo è stato ridotto grazie agli sforzi dell'intera industria.\n\nEra notevole quanto velocemente i lavoratori remoti fossero operativi. I veri eroi qui sono stati i lavoratori IT di prima linea come il helpdesk, gli ingegneri di sistema, gli amministratori di sistema ecc... È stato davvero un sforzo erculeo.\n\n## Cambiamenti sulla sicurezza informatica\n\nUna delle cose, però, che sono state trascurate un po' a causa della velocità di questo cambiamento, è stata la sicurezza informatica. Abbiamo sentito le conseguenze di ciò nelle ultime sei otto settimane, con diversi attacchi importanti nel settore della sicurezza informatica.\n\nUna delle ragioni è una superficie di attacco aumentata poiché i dati sono dispersi su laptop in tutta l'organizzazione, su reti non protette in casa.\n\nParte dei dati si trova nel cloud. Ora, con le offerte SaaS, parte di essi si trova nel data center e parte sui computer che le persone hanno portato a casa.\n\nIl 2021 sarà un anno in cui ci concentreremo sulla sicurezza informatica, osservando attentamente il modo in cui stiamo gestendo i dati e garantendone la sicurezza in tutto il sistema.\n\n## Nuovo abbigliamento per il lavoro\n\nUno dei più grandi progressi di quest'anno è il nuovo abbigliamento da lavoro. Il modo migliore per descriverlo è il \"business mullet\": abito da lavoro nella parte superiore, pigiama o pantaloncini nella parte inferiore. Indosso i pantaloni ogni tanto, ma i miei figli probabilmente sono stanchi di vedermi indossare una camicia con bottoni o persino un completo sopra abbinato a shorts.\n\nIl 2020 è stato un anno di cambiamento, sia a livello personale che professionale, ma ci ha condotto ad un punto nel 2021 in cui possiamo progredire con le lezioni apprese e le migliorie per un futuro migliore.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT37-it","image":"./episodes/edt-37/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Public Sector, presso Intel riflette sugli sconvolgimenti, i cambiamenti e gli adattamenti che la pandemia COVID-19 ha portato nel 2020."},{"id":108,"type":"Episode","title":"Anni '20 ruggenti: uno sguardo verso il 2021.","tags":["contactless","covid","remotelearning","remoteworker","people","process"],"body":"\r\n\r\n## COVID-19: Un periodo di volatilità, incertezza, complessità e ambiguità senza precedenti.\n\nIn questo episodio, Darren chiede a Rachel Mushawar, VP delle vendite presso Intel, la sua opinione su cosa ci aspetta per gli anni ruggenti dopo la sconvolgente esperienza del COVID-19.\n\n## 2020\n2020\n\nI dodici mesi passati sono stati segnati da un cambiamento e da un'incertezza innegabili, sia dal punto di vista professionale che personale. Non tutti gli anni saranno come il 2020, ma le lezioni imparate ci renderanno migliori ogni anno che passa.\n\nNonostante le circostanze individuali, ogni persona ha dovuto fermarsi e capire cosa fosse veramente importante. Teniamo i nostri team, amici, famiglie e relazioni più vicini di quanto abbiamo mai fatto.\n\nE anche se siamo stati fisicamente isolati, la connettività attraverso la tecnologia si è accelerata a velocità senza precedenti. Il senso di possibilità di tutti in questo ambito è stato rigenerato e in un certo senso sbloccato e liberato per il futuro.\n\n## La pandemia ha creato maggiori responsabilità.\n\nD'altra parte, la pandemia ha creato maggiori responsabilità. Quasi la metà degli adulti tra i quaranta e i cinquanta anni ha un genitore di 65 anni o più anziano e ha figli piccoli o sta finanziariamente supportando figli più grandi. Ciò significa che probabilmente si trovano a fare i conti con la didattica a distanza dei loro figli, a lavorare da casa e a prendersi cura dei genitori anziani.\n\nLe perdite nette di posti di lavoro negli Stati Uniti a dicembre riguardavano solo donne. Parte di questo problema è legato alle maggiori responsabilità domestiche durante la pandemia. Se hai bambini piccoli a casa che ora seguono la didattica a distanza e sei un lavoratore orario, come fai a farcela? Non puoi farlo. E sebbene durante il lockdown i padri abbiano quasi raddoppiato l'aiuto con la cura dei figli, abbiamo ancora moltissimo da fare negli anni '20 per quanto riguarda l'uguaglianza di genere. Non si può basare tutto solo sulla tecnologia.\n\n## L'istruzione a distanza mette in evidenza la questione della divisione digitale.\n\nMentre ci avviciniamo agli anni venti, abbiamo un'intera generazione di bambini che ha trascorso gli ultimi 12 mesi a fare l'istruzione a casa.\n\nIn realtà, una famiglia americana su quattro ha almeno un figlio di 14 anni o meno. Per gli studenti provenienti da una situazione svantaggiata, uno studio del World Economic Forum ha scoperto che il 25% non dispone di un computer. Inoltre, il 33% degli studenti delle comunità rurali ha scarso o nessun accesso a internet. La mancanza di questi due fondamenti dell'apprendimento a distanza ha aumentato la disparità digitale.\n\n## Stiamo vivendo \"Il futuro del lavoro\".\n\nMolte vecchie idee sono state abbattute nel 2020 poiché le aziende hanno dovuto immediatamente adattarsi al lavoro da casa. L'ottanta-cinque percento delle organizzazioni ha ampliato o implementato una varietà di politiche per il lavoro da casa che andranno oltre il COVID-19. Molte aziende si sono rese conto dei risparmi derivanti dalla riduzione degli spazi fisici, poiché la produttività è rimasta la stessa o è aumentata con una forza lavoro a domicilio o nomade. Molti dipendenti si stanno anche rendendo conto dei risparmi di tempo derivanti dall'eliminazione degli spostamenti e dalla preparazione personale come acconciatura, trucco e abbigliamento. Un trend che si prospetta per il 2021 sarà un look più casual e naturale.\n\nMentre le pendolari scomparivano, la connettività aumentava e le camere da letto diventavano uffici, tuttavia, un lato negativo emerse poiché la lunghezza media della giornata lavorativa si prolungava e diventava più difficile spegnersi.\n\n## \"Contactless\" sta guidando tutto, come servizio\n\nUna delle cose chiave nel 2021 riguarderà il modo in cui continueremo a sfruttare la tecnologia per rimanere connessi. Ad esempio, ci sono tecnologie simili a Zoom che portano tutto ad un livello superiore e offrono opportunità sociali simili ad una chiacchierata vicino al distributore d'acqua nello spazio virtuale. Trentadue percento degli adulti ha partecipato ad un incontro sociale virtuale nel 2020. Intel ha visitato una fattoria virtuale di capre e ha portato istruttori di yoga per aiutare a combattere l'isolamento.\n\n## Più connessioni, meno attrito, più virtuale, meno contatto fisico.\n\nMan mano che entriamo nel resto degli anni '20, la tecnologia diventerà una pietra angolare per ogni grande trasformazione, indipendentemente che si tratti del settore privato o pubblico.\n\nCome si riassume questa nuova modalità di lavoro e le responsabilità aumentate a casa dal punto di vista di un CIO?\n\nCi sono alcuni imperativi strategici per l'IT. Possiamo suddividerli nelle categorie tradizionali di applicazioni, rete e data center.\n\nPrima cosa, per le applicazioni, i CIO devono capire come abilitare il contattoless, ovvero come guidare tutto come un servizio? Questo non riguarda solo i rivenditori, ma anche il settore sanitario, il governo e la manifattura. La seconda parte riguarda le applicazioni: conoscere chi è il tuo consumatore e come digerisce i contenuti.\n\nRealizzare l'importanza della tua rete è ciò che viene dopo. È il turbo boost per tutte le cose digitali. Le organizzazioni devono avere una rete che, ad esempio, consenta di automatizzare le fabbriche o fornire assistenza sanitaria a distanza. Devono pensare in anticipo per quando il 5G diventa una realtà anziché investire nelle tecnologie di ieri. Le reti si estendono oltre i tradizionali data center ora, quindi è qualcosa a cui dobbiamo prestare attenzione. Naturalmente, la sicurezza deve essere una priorità qui.\n\nProprio come le reti, la sicurezza non è un argomento emozionante o affascinante, ma è un aspetto chiave da considerare quando pensiamo a tutti i dispositivi che oggi sono pervasivi nelle nostre vite quotidiane. La superficie di minaccia sta aumentando in modo esponenziale con dipendenti che lavorano da casa su dispositivi diversi e l'implementazione di tutto-come-servizio per i clienti. La sicurezza non riguarda più solo la protezione dei dati a riposo e in movimento. Riguarda anche tutto ciò che sta in mezzo.\n\nInvece dei tradizionali data center, dovremmo considerarli come centri di dati, al servizio di determinati carichi di lavoro. Ad esempio, il cloud sta crescendo del 30-40 percento all'anno per avvicinare i centri di dati ai dipendenti o ai clienti. Tuttavia, potrebbe non avere senso spostare alcuni dati critici top secret nel cloud, ma mantenerli in locale. I CIO devono capire quali sono i loro centri di dati e quali servirebbero meglio i diversi segmenti dell'organizzazione in termini di ripristino, archiviazione, efficienza dei costi e prestazioni.\n\nEntrando negli anni '20, le organizzazioni devono apportare cambiamenti strategici, sia nelle pratiche di selezione che nel modo in cui forniscono servizi ai propri clienti, tenendo a mente questi concetti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rachel Mushawar"],"link":"/episode-EDT38-it","image":"./episodes/edt-38/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect presso Intel, chiede a Rachel Mushawar, VP delle vendite presso Intel, il suo punto di vista su cosa ci aspetta per gli anni '20 ruggenti dopo la interruzione del COVID-19."},{"id":109,"type":"Episode","title":"Discussioni casuali al distributore d'acqua in un team di lavoro a distanza","tags":["collaboration","covid","organizationalchange","people","compute","remoteworker","videoconferencing","signalwire"],"body":"\r\n\r\n## Nuovi spazi di lavoro collaborativo\n\nIn questo episodio, Darren e Sean Heiney, co-fondatore di SignalWire, Inc., discutono dei nuovi spazi di lavoro collaborativo remoto che eliminano le noiose conferenze video che durano tutto il giorno. La loro politica \"telecamere accese\" e la tecnologia SignalWire Work permettono una comunicazione ad hoc come mai prima d'ora.\n\n## La creazione di SignalWire Work.\n\nSignalWire è lo sviluppatore della più grande piattaforma di comunicazione open-source al mondo. Negli ultimi tre o quattro anni, SignalWire si è concentrato sulla costruzione della prossima generazione di applicazioni per la comunicazione in tempo reale di video e voce, il che ha portato a SignalWire Work per gli uffici remoti.\n\nUn predecessore di SignalWire Work era lo strumento autonomo di SignalWire che avevano creato per sé stessi, dal momento che la società è operativa in modo distribuito fin dalla sua nascita, lavorando in remoto da tre anni. Gli strumenti esistenti per la collaborazione a distanza non soddisfacevano le loro esigenze, con oltre 60 persone distribuite in diversi paesi e continenti. Alcuni stavano già utilizzando l'audio sempre attivo, ma poiché molti dei loro ingegneri stavano anche condividendo schermi Unix, si è evoluto in video sempre attivo. Quando è arrivato il COVID, i clienti hanno richiesto accesso a questo strumento, così è nato SignalWire Work, insieme a una versione per eventi in diretta.\n\n## L'ambiente di lavoro di SignalWire\n\nLavorare in spazi collaborativi remoti non è solo un'innovazione tecnologica, ma anche un esperimento sociale. Per alcune persone, la possibilità di essere sempre in video può sembrare strano o spaventoso. Tuttavia, una volta che tutti si sono abbonati alla filosofia, può essere più efficiente rispetto a sedersi in un ufficio fisico. Ci sono inefficienze in un mondo come Zoom, in cui le persone parlano solo in riunioni programmate con agende specifiche. Molte delle comunicazioni importanti e informali vengono perse.\n\nCon gli strumenti di SignalWire, i colleghi possono vedere all'interno delle stanze delle persone, come se avessero una parete di vetro in un mondo fisico. Puoi vedere quanto sono occupati, che umore hanno o se stanno parlando con qualcun altro. Puoi entrare e fare una domanda. Ci sono interazioni sociali, chiacchiere davanti alla macchinetta del caffè, che non sono possibili con riunioni programmate. Quando accedi a SignalWire Work, è come entrare in un ufficio fisico.\n\nCi sono funzioni che garantiscono la privacy. Puoi oscurare il tuo video in modo che le persone non possano vedere il tuo volto, oppure puoi entrare in modalità \"carponi\" in cui le persone non possono interromperti, ma sanno comunque che sei presente e possono bussare alla tua \"porta\" virtuale.\n\nUn altro vantaggio è che possono esserci limiti più chiari tra vita domestica e lavorativa. Quando si esce dal lavoro, si tratta di una separazione netta.\n\n## La tecnologia\n\nSignalWire ha creato la tecnologia che alimenta tutto, dal campanello Ring ai componenti di Amazon Connect e all'engine del servizio clienti di Netflix; sono fondamentalmente presenti in ogni grande società di telecomunicazioni. Ora si stanno concentrando sulla possibilità di permettere a persone comuni di utilizzare tale tecnologia e costruire su di essa. Un esempio è la piattaforma di chiesa virtuale più popolare al mondo, creata circa un anno fa su SignalWire.\n\nUn aspetto unico che offre a SignalWire un vantaggio strategico è che il multiplexing video viene eseguito nel cloud. Una tradizionale applicazione di videoconferenza codificherà e trasmetterà il video a ogni partecipante in una conferenza. Se ci sono sette persone, ci sono sette flussi. Questo richiede molto lavoro sul processore. È un lavoro sul tuo dispositivo per trasmettere i dati e sei soggetto a jitter e perdite di pacchetti su tutti quei flussi individuali, quindi potresti avere una connessione ottima con qualcuno, ma l'altra persona appare orribile.\n\nCon SignalWire, i client inviano un flusso al cloud. Il cloud prende il flusso di tutti, lo multiplexa insieme e poi lo invia nuovamente a tutti, in modo che ci sia solo una trasmissione e una ricezione. Questo presenta molti vantaggi come una migliore durata della batteria, un consumo di dati inferiore e una minor quantità di lavoro sui processori dei dispositivi locali.\n\nPer l'esperienza utente, SignalWire può rendere l'audio eccellente quando è multiplexato insieme o controllare la disposizione in modo che tutti vedano la stessa cosa nella stessa orientazione. Quando si indica qualcuno sullo schermo, ad esempio, tutti possono vederlo. Per eventi come sessioni di esercizi dal vivo, la piattaforma consente agli utenti di ascoltare contemporaneamente la musica di sottofondo e l'host, oltre a poter vedere, diciamo, altri trenta partecipanti. Tutto ciò si traduce in una sensazione e un'esperienza più connesse.\n\nSignalWire può funzionare su qualsiasi cloud o piattaforma, fino a un singolo dispositivo o un dispositivo basato su atomi. Le aziende possono utilizzarlo sulla propria infrastruttura, il che è importante per la sicurezza e il controllo dei dati al massimo livello. SignalWire può distribuire i suoi nodi all'interno di una rete protetta per proteggere i dati sensibili dal transito su Internet pubblico.\n\nLa piattaforma è completamente flessibile con la tecnologia e le applicazioni degli utenti, permettendo persino a uno studio di trasmissione importante di utilizzarla per produrre e modificare uno dei loro spettacoli, invitando interpreti aggiuntivi per le sovrapposizioni vocali su registrazioni esistenti dato che la qualità in tempo reale è così elevata.\n\n## Un Ambiente più Professionale nei Luoghi di Lavoro Remoti\n\nLa chiave per rendere questo nuovo tipo di spazio di lavoro fattibile è lanciarsi e farlo diventare una politica aziendale. I benefici diventano rapidamente evidenti. Quando entri in ufficio, entri in video e sei presente e interagisci con i tuoi colleghi, proprio come facevi prima del COVID.\n\nQuando le persone andavano in ufficio prima del COVID, probabilmente si vestivano bene per fare un'impressione professionale. In questo mondo, quell'impressione viene creata soprattutto attraverso una buona attrezzatura audio e video: buoni microfoni, illuminazione, un ambiente di alta qualità. Gli impiegati mostrano il meglio di sé attraverso la tecnologia perché questo è ora un mondo tecnologico. È un'evoluzione dall'ambiente informale del lavoro da remoto, in cui ci si siede su una spiaggia o al tavolo della cucina mentre si prepara la cena. Conversazioni più professionali possono avere luogo in un ambiente di lavoro da remoto più professionale.\n\nIl modo migliore per sperimentare questa tecnologia è provarla. C'è una prova gratuita di 30 giorni su https://signalwire.com/products/work.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sean Heiney"],"link":"/episode-EDT39-it","image":"./episodes/edt-39/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Public Sector, Intel, e Sean Heiney, co-fondatore di SignalWire, Inc., discutono delle politiche di lavoro a distanza dell'azienda riguardanti le telecamere accese e della loro nuova tecnologia di spazi di lavoro collaborativi a distanza che favorisce la comunicazione ad hoc per la loro forza lavoro completamente remota."},{"id":110,"type":"Episode","title":"Modello di maturità della gestione delle informazioni","tags":["data","informationmanagement","informationmaturity","datagovernance","datawarehouse","datalake","datamesh","datalineage","technology","process","people"],"body":"\r\n\r\nSviluppare una strategia dei dati può essere difficile, specialmente se lo stato della gestione delle informazioni o la traiettoria della tua azienda non è chiara. Questo Modello di Maturità della Gestione delle Informazioni aiuta i CDO e i CIO a individuare dove si trovano nel loro percorso di gestione delle informazioni e nella loro traiettoria. Questa mappa può aiutare a guidare le organizzazioni mentre continuano a migliorare e progredire verso l'organizzazione dei dati definitiva che consente loro di ottenere il massimo valore aziendale dai loro dati.\n\nIl modello rappresenta una serie di fasi, che vanno dalla meno matura alla più matura: Standardizzata, Gestita, Governata, Ottimizzata e Innovazione. Molte volte, un'organizzazione può trovarsi contemporaneamente in più fasi. È possibile determinare in quale fase opera la maggior parte dell'organizzazione e identificare i pionieri che dovrebbero essere più avanzati in termini di maturità. Utilizzare questi pionieri per sperimentare o creare un prototipo di nuovi processi, tecnologie o strutture organizzative.\n\n## Fase standardizzata\n\nLa fase standardizzata ha tre sottofasi: base, centralizzata e semplificata. La maggior parte delle organizzazioni si trova in qualche punto di questa fase di maturità, quindi osserva i comportamenti, la tecnologia e i processi della tua organizzazione per capire dove potrebbe collocarsi la tua organizzazione.\n\n## Base\n\nQuasi tutte le organizzazioni si inseriscono in questa fase, almeno parzialmente. Qui, i dati vengono utilizzati solo reattivamente e in modo improvvisato. Inoltre, quasi tutti i dati raccolti vengono archiviati in base a periodi di tempo predeterminati, spesso in modo indefinito. Le aziende in questa fase di base non cancellano i dati per paura di perdere alcune informazioni importanti in futuro. Ad esempio, abbiamo lavorato di recente con un'azienda che conserva backup di email degli ultimi 30 anni, pari a circa 12-10 terabyte, di cui ha paura di sbarazzarsi. Questa non è una pratica rara.\n\nQuesti attributi descrivono al meglio questa fase:\n\nGestione reattiva\n\nDati non catalogati\n\nConserva tutto ovunque\n\n## Centralizzato (Raccolta dati centralizzata)\n\nMan mano che le organizzazioni iniziano a valutare la loro strategia dati, prima cercano di centralizzare il loro archivio in soluzioni di storage di big data. Questo approccio può assumere la forma di storage cloud o di appliance di big data in loco. Una volta che i dati vengono raccolti in una posizione centralizzata, la tecnologia dei data warehouse può consentire analisi di base per ottenere informazioni utili. La maggior parte delle volte, questi dati vengono utilizzati per risolvere problemi con clienti, catena di approvvigionamento, sviluppo prodotto o qualsiasi altra area dell'organizzazione in cui vengono generati e raccolti dati.\n\nQuesti attributi descrivono meglio questa fase:\n\nGestione reattiva\n\nRaccolta dati di base\n\nI data warehouse\n\narchiviazione di grandi quantità di dati\n\nAnalisi base dei big data.\n\n## Semplificato\n\nMan mano che aumenta il numero di fonti di dati, le aziende iniziano a formare organizzazioni che si concentrano sulla strategia, l'organizzazione e la governance dei dati. Questo cambiamento inizia con l'ufficio del Chief Data Officer (CDO). Ci sono dibattiti su dove il CDO dovrebbe essere posizionato all'interno dell'azienda, sotto il CEO o il CIO. Non ci si deve concentrare su dove si trovano all'interno dell'organizzazione. La cosa importante è stabilire un focus sull'organizzazione dei dati e implementare un piano per normalizzare i dati. La normalizzazione offre la possibilità di correlare diverse fonti di dati per ottenere nuove informazioni su ciò che sta accadendo in tutta l'azienda. È importante notare che senza normalizzazione, i dati rimangono isolati e sono solo parzialmente accessibili. Un altro attributo chiave di questa fase è la necessità di sviluppare un piano per gestire il massiccio volume di dati raccolti. A causa dell'aumento di volume e dei costi di archiviazione di questi dati, diventa importante utilizzare una stratificazione di archiviazione. Sebbene nelle prime fasi sia quasi impossibile conoscere il modo ottimale per gestire l'archiviazione dei dati, si consiglia di utilizzare le migliori informazioni disponibili per sviluppare piani di archiviazione dei dati razionali. È importante tenere presente che questo piano dovrà essere riesaminato e migliorato una volta che i dati saranno utilizzati.\n\nQuesti attributi descrivono al meglio questa fase:\n\nGestione predittiva dei dati (inizio di un'organizzazione centrata sui dati)\n\nNormalizzazione dei dati\n\nArchiviazione centralizzata a più livelli\n\n## Gestito (Profili dati standard)\n\nNella fase di Gestione, le organizzazioni hanno formalizzato l'organizzazione dei dati; i data scientist, i data steward e i data engineer fanno ora parte del team e hanno ruoli e responsabilità definiti. La gestione dei dati metadata diventa un fattore chiave per il successo in questa fase e diverse applicazioni possono ora beneficiare dei dati dell'azienda. Il passaggio da un data warehouse a un data lake consente una maggiore agilità nello sviluppo di applicazioni data-centriche. La virtualizzazione dello storage dei dati consente una soluzione di storage più efficiente e dinamica. L'analisi dei dati può ora essere eseguita su set di dati provenienti da diverse fonti e dipartimenti dell'azienda.\n\nQuesti attributi descrivono al meglio questa fase.\n\nGestione organizzata dei dati (organizzazione dei dati in atto con ruoli chiave identificati)\n\nGestione dei metadati\n\nLinea di dati\n\nLago dei dati\n\nAnalisi dei grandi dati\n\n* Archiviazione definita dal software (virtualizzazione dello storage)\n\n## Governo\n\nLa fase governata è principalmente raggiunta quando un'organizzazione adotta un approccio centralizzato ai dati e raggiunge un approccio olistico alla loro gestione e sicurezza. Il CDO lavora in stretta collaborazione con il CSO (Chief Security Officer) per garantire che le strategie in materia di dati e sicurezza lavorino insieme per proteggere i dati preziosi dell'azienda rendendoli accessibili per l'analisi. I dati vengono classificati in diverse categorie in base alla criticità, al segreto o all'importanza. La conformità dettata dalle normative è automatizzata e applicata ai dati in tutta l'organizzazione. La visibilità aumenta grazie alle strategie comuni di dati e sicurezza e ai piani tattici. L'intelligenza artificiale di base viene ampiamente utilizzata all'interno dell'organizzazione e le decisioni aziendali vengono elaborate sulla base dei dati. I dati possono ora essere raccolti e catalogati da tutta l'azienda, compresi i dispositivi Internet delle Cose (IoT) sugli asset fisici dell'azienda.\n\nQuesti attributi descrivono al meglio questa fase:\n\nClassificazione dei dati\n\nRispetto dei dati\n\nSicurezza dei dati\n\n* AI di base\n\nVirtualizzazione dei dati distribuita / IoT\n\n## Ottimizzato\n\nCome la raccolta dei dati delle organizzazioni continua ad aumentare, è necessario trovare efficienze nell'automazione e nel miglioramento continuo dei processi. L'automazione dei processi di dati è l'obiettivo principale nella fase di ottimizzazione. In particolare, l'automazione dell'annotazione e dei metadati riduce il tempo per ottenere valore dai dati. I dati sono diventati troppo grandi per essere spostati in un'unica posizione centralizzata, e un'architettura di \"distributed data lake\" emerge come il modo ottimale per gestire i dati. L'apprendimento automatico è fondamentale in questa fase per iniziare a fornire informazioni ai responsabili delle decisioni per aiutare a ottimizzare le operazioni e il valore aziendale. L'applicazione e i dati vengono distribuiti su infrastrutture di rete, archiviazione e calcolo basate su informazioni storiche e modelli di intelligenza artificiale.\n\nQuesti attributi descrivono al meglio questa fase.\n\nEtichettatura meta automatica\n\nLago dati distribuito\n\nInferenza dati / Apprendimento automatico\n\nInfrastruttura basata sui dati\n\n## Innovazione\n\nL'organizzazione ultima si trova nella fase di Innovazione. Non è semplicemente guidata dai dati, ma crea nuovi prodotti, offerte e servizi basati sui risultati ottenuti dai dati interni ed esterni all'organizzazione. In questa fase, l'IA/ML fornisce vantaggi inestimabili. Ci sono tre sottofasi nell'Innovazione: intuizione, prescrittiva e previsione.\n\n## Saggezza\n\nL'insieme è la presa di decisioni basata sui dati basata su ciò che si può effettivamente vedere in quello che sta accadendo nel tuo ecosistema, ad esempio nella tua catena di approvvigionamento, nello sviluppo del prodotto o nella produzione.\n\n## Prescrittivo\n\nMentre l'acume è prezioso, richiede interazione umana, comprensione ed intuizione. Al livello successivo, il proattivo, la tua intelligenza artificiale ti suggerisce cosa fare in base all'acume. Ciò può svolgere un ruolo importante in tutta la tua organizzazione, poiché le decisioni sono guidate dai dati dalla catena di fornitura fino all'acquisizione dei clienti.\n\n## Preveggenza\n\nIn questo passaggio di coronamento, i dati effettivamente aiutano a creare il futuro. Ad esempio, la preveggenza consentirebbe a un'organizzazione informatica di proiettare quanta capacità sarà necessaria in futuro basandosi su norme storiche e persino su fattori come le condizioni mutevoli dei suoi concorrenti. La preveggenza richiede molti dati e l'addestramento di modelli, ma porta all'obiettivo ultimo dell'azienda in tempo reale.\n\nQuesti attributi descrivono al meglio questa fase:\n\nInsight (decisioni basate sui dati)\n\nPrescrittivo (business basato sui dati)\n\nPrevisione (creare il futuro)\n\nDeep learning - Apprendimento profondo\n\nAzienda in tempo reale\n\n## Conclusione\n\nÈ comune sentirsi bloccati in una fase e sopraffatti dalla quantità di cambiamento necessaria per passare a una nuova fase di maturità. Ogni passo avanti, però, è prezioso. Ad esempio, forse ti trovi in una fase centralizzata e puoi analizzare la gestione dei metadati. C'è l'opportunità di andare oltre la pulizia dei dati e migliorarli anche? Questo tipo di pensiero progressivo ti farà progredire nella catena di maturità nella gestione delle tue informazioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT4-it","image":"./episodes/edt-4/it/thumbnail.png","lang":"it","summary":"In questo episodio, parleremo del Modello di Maturità della Gestione dell'Informazione e di come possiamo utilizzare tale modello per aiutare le nostre organizzazioni a progredire. Questo modello può aiutarti a identificare dove si trova la tua organizzazione e dove si sta dirigendo nella sua strategia di gestione delle informazioni, ottenendo infine il massimo valore aziendale dai tuoi dati."},{"id":111,"type":"Episode","title":"Ricerca Medica Collaborativa con Elaborazione dei Dati Riservata","tags":["confidentialcomputing","cybersecurity","distributedanalytics","sgx","healthcare","data","technology","edge"],"body":"\r\n\r\n## Perché abbiamo bisogno della elaborazione riservata?\n\nL'infrastruttura informatica attuale è costruita con un'enfasi sulla condivisione e l'apertura: internet è gratuito e i dati dovrebbero essere gratuiti. Questo è stato un problema per quanto riguarda la sicurezza. Abbiamo implementato alcune soluzioni che funzionano bene; sappiamo come crittografare i dati quando vengono archiviati e quando sono in transito. Nonostante ciò, i dati possono essere attaccati in vari modi mentre vengono letti, analizzati e utilizzati.\n\nI dati sensibili rimangono vulnerabili, che si tratti di dati finanziari, medici o di posizione, sia dal punto di vista della visibilità che dell'integrità dei dati.\n\nNel trattare i dati nel settore sanitario, vi sono strati aggiuntivi di complessità. Esistono molte norme e regolamenti, come l'HIPAA, e ogni stato ha le proprie norme riguardanti i dati medici. Nonostante la complessità e il numero di parti coinvolte, la computazione confidenziale è possibile, permettendo di condividere dati tra parti che per loro natura non si fidano l'una dell'altra.\n\nPer riservatezza, dobbiamo considerare alcuni diversi fattori: l'integrità dei dati, la riservatezza dei dati e l'integrità del codice.\n\n## Problemi critici di privacy e sicurezza dei dati.\n\nI record sanitari di un individuo, specialmente negli Stati Uniti, sono dispersi ovunque tra medici, specialisti, laboratori e ospedali. La maggior parte delle persone non ha un facile accesso ai propri record; è quasi impossibile creare una visione completa della propria salute. Il computing confidenziale può aiutare a superare queste barriere.\n\nPrima di tutto, può garantire che qualsiasi dato che condividi sia protetto dalla prospettiva dell'integrità dei dati; non sarà modificato da nessuno. Può essere confidenziale, ovvero tokenizzato o crittografato, ma può comunque essere utilizzato per calcoli. Ad esempio, se una parte desidera effettuare analisi su alcuni dati, non è necessario conoscere informazioni come nomi, date di nascita o numeri di previdenza sociale. Quindi, se quelle parti dei dati possono essere tokenizzate o crittografate, possono essere condivise per l'analisi a condizione che l'altra parte sia affidabile.\n\nQuesto è il punto in cui le misure di sicurezza come l'attestazione giocano un ruolo, in modo che le parti possano dimostrare la propria identità. E quell'attestazione può essere legata fino al livello dell'hardware, agli ambienti di esecuzione affidabili che l'hardware fornisce. In questo modo, non ci si limita a fidarsi del trasporto e del punto finale, ci si fida anche dell'applicazione e di come utilizzerà i dati.\n\nCi sono due approcci di base a questo riguardo. Il primo è l'SDK dell'applicazione, il che significa che lo sviluppatore può decidere come suddividere il proprio codice in componenti affidabili e non affidabili. L'altro approccio è quello di avere un sistema di crittografia in esecuzione che può essere costruito su di un ambiente di esecuzione affidabile, riducendo al minimo l'effort richiesto per convertire un'applicazione esistente in qualcosa che può essere eseguito in quell'ambiente.\n\nCon un ambiente di esecuzione affidabile basato su hardware che protegge le applicazioni e i dati in uso, diventa molto difficile per un attore non autorizzato, anche se ha accesso fisico all'hardware, privilegi di root o diritti di amministratore all'ipervisore, accedere all'applicazione protetta e ai dati. Il paradigma del calcolo confidenziale mira a consentire l'eliminazione del provider di cloud anche dalla base di calcolo affidabile. In questo modo, solo l'hardware e l'applicazione stessa protetta si trovano all'interno del perimetro di attacco.\n\nQuesti ambienti informatici consentono ai CSP (Cloud Service Providers) di sfruttare al meglio ciò che l'hardware può offrire e la migliore sicurezza possibile, su cui l'utente finale ha il pieno controllo. Ogni parte può determinare le proprie politiche e le gerarchie delle politiche, come quelle statali e federali, e ogni fornitore di informazioni può decidere quali politiche applicare e a chi.\n\n## Studio clinico di evidenza del mondo reale\n\nUnire tutti i dati e dargli un senso è una grande sfida nell'industria sanitaria. Il numero delle impostazioni di privacy e di condivisione dei dati che sono in atto tra i diversi fornitori, dispositivi, posizioni geografiche, ecc. rende attualmente impossibile ciò.\n\nAI-Vets, Intel e alcuni partner stanno lavorando insieme a questo problema. L'architettura brillantemente semplice consente l'utilizzo in ambienti disparati, tipi di dati e politiche, ma è in grado di eseguire analisi centralizzate.\n\nUn esempio della nostra implementazione è una piccola prova di concetto: Come si analizza tra diverse parti come ospedali, ambienti di ricerca e laboratori, ognuno con i propri dati e trial che potrebbero essere in corso in un ambiente clinico? Ad esempio, come possiamo trovare una correlazione tra le persone che assumono il farmaco X, ad esempio per il diabete, e hanno la condizione Y, ad esempio il cancro, quando il farmaco X non ha nulla a che fare con il trattamento della condizione Y? Questi due set di dati non sarebbero nello stesso luogo perché sono gestiti da diversi fornitori.\n\nSe tuttavia i fornitori facessero parte di un ecosistema in cui potessero determinare le politiche da applicare al proprio punto finale, potremmo avere un'applicazione centralizzata, un portale centrale per la ricerca, che ha connessioni a questi punti finali. Ci sarebbe una gestione delle chiavi e attestazione di terze parti per verificare le credenziali e le autorizzazioni reciproche, in modo che tutte le parti possano fidarsi l'una dell'altra.\n\nQuello è un aspetto della fiducia, ma dobbiamo anche proteggere i dati che verranno estratti, interrogati e trasmessi. Per conseguire questo, possiamo gestire i dati e le applicazioni all'interno di enclave sicure e crittografate. I dati vengono gestiti utilizzando le politiche impostate da ciascun utente, come l'oscuramento delle date di nascita, i numeri di previdenza sociale, ecc. Queste informazioni possono essere tokenizzate in modo che diventino spazzatura completa nelle mani non autorizzate.\n\nIl portale centrale può eseguire una query che si estende su più endpoint e unisce diversi tipi di dati nel suo sistema in esecuzione e ne effettua un'analisi. Quindi, invece di dover caricare tutto in un data lake e poi fare l'analisi, viene fatto in tempo reale. Non c'è attesa che i dati vengano pubblicati o puliti prima applicando tutte quelle politiche; accade dinamicamente e al volo.\n\nQuesto permette di ottenere notevoli intuizioni. Durante la pandemia, ad esempio, se dovessimo aspettare ogni giorno per ottenere i dati e eseguire analisi complesse su di essi, sarebbe difficile. Se fossimo in grado di accedere a dati in tempo reale provenienti da tutti questi diversi sistemi in tutto il paese e nel mondo, ma allo stesso tempo condividerli in modo sicuro, potremmo arrivare a intuizioni uniche che altrimenti non sarebbero possibili.\n\nAbbiamo già visto ciò in alcuni casi di studio per siti clinici che abbiamo fatto con il nostro partner Fortanix. Hanno una linea di prodotti che rende facile per diverse entità definire le loro politiche in un ambiente di calcolo confidenziale, verificare le identità reciproche e gestire chiavi e fiducie. Il concetto di ambienti di esecuzione affidabili è presente da tempo ed è diventato di uso comune, quindi è diventato più facile sfruttarlo. I casi d'uso per questo sono fantastici.\n\n## Rilevazione automatica del COVID-19 da immagini radiografiche del torace\n\nIn alcuni casi d'uso, non è solo necessario proteggere i dati, ma anche la proprietà intellettuale associata ad alcuni algoritmi specializzati. Ad esempio, per rilevare automaticamente il COVID dalle immagini a raggi X, potrebbero esserci dati radiologici, dati del paziente e potrebbe esserci un algoritmo proprietario per l'analisi. Le enclave possono proteggere sia i dati che le applicazioni da occhi indiscreti.\n\nLa zona sicura protegge anche le altre macchine nella rete perché se qualcuno inviasse qualcosa di losco verso i nodi finali, il sistema di gestione delle chiavi ne impedirebbe lo scambio poiché non è correttamente attestato. Le parti scelgono esattamente con quali fonti di dati la zona sicura può comunicare ed è bloccata sia per ciò che entra che per ciò che esce.\n\n## Registri sanitari elettronici (eHR)\n\nI record sanitari sono un grande caos negli Stati Uniti, con accordi HIPAA cartacei non applicabili, ecc., e tutto è sparpagliato tra diverse entità. Un caso d'uso che potrebbe essere un buon modello da seguire è quello del governo tedesco. Hanno stabilito che i dati sanitari devono essere conservati in registri elettronici e le applicazioni devono essere implementate in ambienti di esecuzione affidabili. Il paziente è l'utente finale e determina quali dati sono disponibili e per chi.\n\nQuel livello di dettaglio in termini di ciò che è disponibile per l'utente finale è enorme. E non solo tutti quei dati sono raccolti e condivisi dai diversi sistemi, sono in enclave sicure, quindi sono completamente protetti dal mondo esterno. Se qualcuno non autorizzato riuscisse ad accedere ai dati stessi, sarebbero completamente privi di significato.\n\nQuesti ambienti di esecuzione affidabili sono il primo passo nella direzione di controlli facilmente comprensibili e facilmente applicabili.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Nick Bhadange"],"link":"/episode-EDT40-it","image":"./episodes/edt-40/it/thumbnail.png","lang":"it","summary":"Abbattete le barriere per accelerare la ricerca medica per la cura del cancro con il calcolo confidenziale. Nick Bhadange, Technology Specialist, AI-Vets e Darren Pulsipher, Chief Solution Architect, Settore Pubblico, Intel, discutono la necessità di calcolo confidenziale nel settore sanitario e i potenziali vantaggi attraverso casi d'uso."},{"id":112,"type":"Episode","title":"L'Arte Nera del DevOps","tags":["devops","people","technology","compute","devsecops","cybersecurity","multicloud"],"body":"\r\n\r\nDiamo uno sguardo a dove si inserisce DevOps nella tua infrastruttura.\n\nIn fondo a una pila normale, abbiamo uno strato fisico che potrebbe rappresentare una nuvola, un centro dati, dispositivi IoT o infrastrutture tradizionali.\n\nInoltre, di solito c'è un'infrastruttura definita dal software che astrae la complessità nella gestione dei singoli componenti hardware.\n\nIl prossimo passo è un livello di gestione del servizio, che include l'ecosistema di virtualizzazione dei contenitori e un livello di gestione delle informazioni distribuito, che comprende il piano dati, i laghi dati e tutto ciò che gestisce i tuoi dati.\n\nPoi arriva il livello dell'applicazione. Gli sviluppatori di applicazioni utilizzano i servizi all'interno dei livelli dell'applicazione. Proprio all'interfaccia tra il livello dell'applicazione e il piano di gestione dei dati e della gestione dei servizi si trovano gli strumenti SecDevOps o DevOps. Questi strumenti includono aspetti di sicurezza e identità che garantiscono un modo sicuro di integrare e distribuire continuamente i tuoi prodotti.\n\n## Applicazione / Livello di carico di lavoro\n\nIn cima alla piattaforma dell'applicazione e al livello del carico di lavoro che alimenta il SecDevOps, ci sono tre tipi di carichi di lavoro: carichi di lavoro basati sugli eventi, carichi di lavoro procedurale e un ibrido dei due, che sono carichi di lavoro basati su GUI o UI.\n\nUn semplice esempio di un carico di lavoro orientato agli eventi sarebbe quando un ordine di acquisto arriva nel tuo sistema causando l'attivazione di altre azioni. Ci possono essere passaggi sequenziali o paralleli, interazione con gli esseri umani e automazione e interazione con diverse applicazioni o sottosistemi all'interno dell'azienda.\n\nMolti strumenti per l'automazione del carico di lavoro sono disponibili. Alcuni sono basati su script e altri utilizzano l'automazione dei processi robotici, che sono più orientati all'interfaccia grafica (GUI) o all'interfaccia utente (UI). Questi strumenti lavorano sull'automazione dei servizi sottostanti, quindi i carichi di lavoro guidano l'interazione del servizio.\n\nI servizi tradizionalmente si suddividono in tre categorie principali: applicazioni, come prodotti già pronti come Word o un'applicazione SAP; servizi complessi, che vengono sviluppati per uno scopo specifico, come uno stack MEAN con Mongo; e servizi semplici, che fanno una cosa sola, ad esempio MongoDB che archivia il database.\n\nC'è una nuova categoria a causa della crescita dell'IA e dell'Apprendimento Automatico. Molti servizi non fanno molto senza un modello ad esso associato, quindi abbiamo aggiunto modelli di intelligenza artificiale al livello del servizio, che trattiamo allo stesso modo di un servizio semplice.\n\n## Giornata del Developer nella vita\n\nDopo aver compreso i carichi di lavoro e i servizi, possiamo analizzare cosa fa tipicamente uno sviluppatore.\n\nUno sviluppatore scriverà qualche codice sulla propria postazione di lavoro e eseguirà alcuni test di funzionalità. Successivamente, effettuerà il commit del codice su GitHub, ad esempio, e verrà avviato un processo di integrazione continua e consegna continua (CICD). Esso eseguirà controlli di sicurezza sul codice, come ad esempio linter, analisi statica e analisi dinamica.\n\nUna volta superati questi test, di solito verrà controllato in un ramo di integrazione in cui altre persone del team di sviluppo prenderanno i dati, li svilupperanno e integreranno il loro codice con quello dello sviluppatore. Successivamente, una volta superati i loro test, verrà spinto in una fase di test. Una volta superata questa fase, verrà messo in produzione.\n\nQuesto è un tipico pipeline CICD, che esiste da decenni. Nel corso degli anni, i diversi modi di descrivere le pipeline sono stati consolidati e standardizzati, limitando complessità ed errori.\n\n## Stack di DevSecOps\n\nIl pipeline è solo un elemento di un insieme SecDevOps.\n\nAltri elementi necessari includono un registro e un repository. Pensate a questi come repository versionati per conservare gli artefatti che vengono generati durante il CICD pipeline, in modo che siano facilmente disponibili per essere riutilizzati più volte.\n\nUn altro elemento importante è un framework di automazione. Questo aiuta a alleviare il lavoro umano nell'esecuzione di compiti come controlli di sicurezza o promozione delle versioni da una fase all'altra. Gli strumenti per l'automazione sono maturi e la formazione è disponibile, quindi un buon framework di automazione dovrebbe essere fondamentale.\n\nAnche se la gestione dell'ambiente spesso cresce organicamente nel tempo, ha senso gestire e progettare gli ambienti in modo appropriato per ottenere maggiore affidabilità e ripetibilità.\n\nUn elemento chiave al di sotto di tutto è un profilo di sicurezza. Dovresti essere in grado di avere la capacità di definire profili di sicurezza, in modo che possano essere utilizzati in più ambienti e su stack di applicazioni multipli.\n\n## Registri / Repository\n\nDi solito ci sono almeno due tipi di repository differenti. Il primo è un repository di staging, dove puoi generare immagini (una raccolta di tutto il codice necessario per avviare un contenitore, ad esempio) e archiviare cose come identità e chiavi segrete. Questo repository contiene tutto ciò di cui hai bisogno per trasferire le cose in produzione. Alcune organizzazioni possono avere più repository di staging in quanto gli elementi diversi passano attraverso diverse fasi di maturità fino a raggiungere il repository di produzione. Vuoi essere in grado di tornare alle versioni precedenti se necessario.\n\nNella repository di produzione, o in oro, le immagini vengono bloccate, rendendole autenticate e criptate. Solo le cose presenti nella repository in oro vengono spostate nella produzione.\n\n## Fasi\n\nIl modo migliore per pensare alle fasi nel pipeline CICD è che ogni fase funzioni in un singolo ambiente. Ad esempio, in una fase di compilazione, esiste un ambiente di compilazione autonomo con politiche. Solo quando tutti i passaggi in questa fase sono completati, le cose possono passare alla fase successiva. Ciò evita di consumare risorse con compilazioni parallele ed esecuzioni che possono alla fine fallire. Allo stesso tempo, è meglio non avere così tante fasi che ostacolino il progresso, quindi è importante avere un piano definito e accurato.\n\n## Passi\n\nAll'interno delle fasi ci sono dei passaggi in cui il lavoro viene effettivamente svolto. Nella costruzione e nel testing del software, i passaggi possono essere eseguiti in parallelo o in sequenza; ci sono molti strumenti che consentono di definire queste operazioni. Sebbene alcuni abbiano un'interfaccia grafica per questo, la maggior parte degli sviluppatori preferisce un formato testuale perché consente il controllo delle versioni della pipeline e dei passaggi, consentendo controlli di sicurezza sulla pipeline.\n\n## Pipeline\n\nCon fasi e passaggi definiti, si ha una vera pipeline. Invece di definire una pipeline unica per tutte le tue applicazioni, cosa che di solito fallisce perché diventa eccessivamente complessa con molte condizioni o troppo restrittiva, ti consiglio di utilizzare pipeline di template e modificarle se necessario, assicurandoti che rispettino gli standard di conformità e le normative. È importante stabilire una pipeline adeguata all'inizio di un progetto, così come la flessibilità durante lo sviluppo del progetto.\n\n## Ambienti\n\nInvece di creare ambienti ad hoc, è meglio crearli con intenzione fin dall'inizio. DevOps o SecDevOps possono integrare politiche di sicurezza e conformità in tutti i diversi progetti, garantendo la sicurezza.\n\n## Service Stack in Italian is \"stack di servizi\".\n\nDiamo uno sguardo a come lavorano i programmatori, che riguarda i servizi al giorno d'oggi. Anche se i programmatori lavorano in un'applicazione monolitica, tendono a raggruppare il loro lavoro in unità funzionali come database, nodi di logica di business o strati di trasporto. Ad esempio, utilizzando un semplice servizio come MongoDB. Quando un programmatore avvia quel contenitore sul proprio laptop, gli offre la funzionalità che si aspetta di memorizzare i dati in un modo non SQL in un documento. Sul laptop, potrebbe essere l'unico contenitore in esecuzione.\n\nIn un ambiente di prova o sviluppo, potrebbero esserci più istanze di quel servizio in esecuzione e lo sviluppatore potrebbe distribuire un cluster di MongoDB services e collegarli insieme per un test. Il servizio rimane comunque un servizio Mongo DB, ma il suo comportamento cambia in base all'ambiente in cui si trova. L'obiettivo per gli sviluppatori è scrivere codice e effettuare il controllo su di esso rispetto al servizio MongoDB sui loro laptop per garantire che funzioni correttamente in produzione.\n\nUn servizio semplice come MongoDB è necessario, ma di per sé non molto utile. Servizi complessi come le pile LAMP o MEAN sono più importanti. Questi sono diversi servizi che funzionano insieme, agendo essenzialmente come un unico servizio. Riuniti insieme, questo permette di implementare un servizio complesso su un laptop e ci sono due o tre contenitori di servizi semplici che sono in esecuzione, offrendo agli sviluppatori la funzionalità necessaria per verificare il loro codice.\n\nUna volta che il codice viene verificato, inizia il processo di sviluppo in cui il programmatore si integra con altre persone. Lo stesso servizio complesso può adottare un modo completamente diverso di fare le cose. A quel servizio complesso possono essere collegate molte politiche di sicurezza per garantirne la sicurezza, l'affidabilità e la resilienza.\n\n## Definizioni di Servizio/Applicazione\n\nÈ importante capire i concetti di servizi semplici e complessi perché gli sviluppatori di software devono definire come farli funzionare. Ci sono alcune definizioni. Una viene chiamata definizione dell'immagine. Queste sono spesso nel mondo dei container, chiamate immagini Docker. Il file Docker definisce ciò che c'è in quell'immagine. Questo è considerato un semplice contenitore di per sé, anche se le persone stanno iniziando a usare i container per cose complesse.\n\nAll'interno delle definizioni di servizio, possiamo includere multiple definizioni di immagine, ad esempio, Docker Compose, Kubernetes Operators, Helm Charts, Terraform e perfino CNAB. Questi sono strumenti che ti permettono di definire un servizio. Un servizio è più di un semplice contenitore; è l'ambiente in cui viene eseguito il contenitore. Potrebbe includere definizioni di rete, connettività dei volumi o persino politiche di distribuzione. Una \"definizione di servizio\" completa ha definizioni di immagine, configurazione e provisioning.\n\n## Mettere tutto insieme\n\nQuando uno sviluppatore sta creando un nuovo servizio, non sta solo sviluppando il codice per l'immagine; sta anche definendo l'ambiente, o la configurazione, in cui deve essere eseguito. È qui che possono convergere la trama del tuo ambiente e la definizione del servizio. Durante l'esecuzione, produrrà l'ambiente necessario affinché il contenitore possa essere eseguito in modo efficace in modo ripetibile, in modo da poter spostare facilmente il codice dall'esecuzione su un desktop all'esecuzione nella produzione completa il più rapidamente possibile.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT41-it","image":"./episodes/edt-41/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Public Sector, Intel, definisce i termini comuni di DevOps e spiega dove si inserisce DevOps nella tua organizzazione."},{"id":113,"type":"Episode","title":"Securizzare il flusso di lavoro DevOps = SecDevOps","tags":["cybersecurity","devops","compute","process","technology","multicloud","devsecops"],"body":"\r\n\r\nUno studio di oltre 20 anni fa sul ritorno degli investimenti in sicurezza ha dimostrato che più la sicurezza viene integrata nel ciclo di sviluppo, più è conveniente rispetto all'attesa fino alla fine del ciclo. Nonostante sappiamo questo da due decenni, è ancora un lavoro in corso.\n\nLa maggior parte delle aziende di sviluppo includono la sicurezza come parte del loro processo di sviluppo complessivo, quindi ci sono stati molti progressi, ma è un percorso, non una corsa veloce. Si tratta di comprendere tutti i diversi punti di esposizione e debolezze e di essere in grado di offrire i giusti processi di sicurezza per risolvere tali problemi.\n\n## I Vettori di Attacco\n\nSpesso le persone pensano agli attacchi come vulnerabilità degli dipendenti o dei pacchetti, per esempio, e dimenticano la parte del processo della storia. Sul lato operativo c'è il tempo impiegato per chiudere una vulnerabilità. Dall'altro lato c'è lo sviluppo e la distribuzione dei prodotti. Lungo quella catena ci sono vari punti di rottura, e di recente sono stati sfruttati nelle fasi più avanzate del processo di costruzione. Per quanto riguarda i clienti, il codice che è stato aggiornato era legittimo perché proveniva direttamente dalla fonte. Quindi dobbiamo pensare attentamente a dove inserire la sicurezza nel processo.\n\n## Sicurezza Incorporata...\n\nAgile, CI/CD, DevOps, …Dove si trova la sicurezza?\n\nMentre tendiamo a considerare la necessità di sicurezza durante le transizioni dallo sviluppatore al controllo di qualità e dal controllo di qualità alle operazioni o implementazione, la sicurezza dovrebbe essere realmente integrata nell'intero ciclo di sviluppo, non solo in alcuni punti di controllo. L'approccio dovrebbe essere la sicurezza continua.\n\n## Sicurezza Incorporata...\n\nRendere la sicurezza parte di ogni fase.\n\nLa sicurezza continua è una sfida. La maggior parte degli sviluppatori e dei professionisti del controllo qualità non hanno una formazione specifica in sicurezza; questa è una battaglia difficile da combattere. Nel settore, si è provato questo approccio nei primi anni 2000, ma ci sono stati tre problemi. Prima di tutto, il turnover è troppo alto. In secondo luogo, il panorama della sicurezza cambia troppo rapidamente per tenerli aggiornati e, terzo, dato che non è il loro lavoro principale, il comportamento corretto non viene incentivato.\n\nCome integrare quindi la sicurezza nel processo, automatizzare le cose chiave che vogliamo fare e lasciare spazio agli sviluppatori affinché possano svolgere il loro lavoro, che consiste nel costruire, testare e implementare il codice? Il processo di sicurezza può davvero risplendere inserendolo in quelle automazioni che già stai facendo in DevOps, come i test unitari automatizzati, i test di qualità e regressione automatizzati, la creazione automatizzata e l'implementazione automatizzata. Questo non risolverà tutti i problemi, ma alzerà significativamente il livello in modo che tu possa concentrarti sulle sfide difficili legate alla sicurezza.\n\n## Sicurezza integrata...\n\nSignifica che la sicurezza è integrata, non è un singolo passo o stage.\n\nAlcuni strumenti comuni forniscono già una certa sicurezza automatizzata che evidenzia le vulnerabilità. Ad esempio, GitHub effettuerà controlli di sicurezza sui progetti che utilizzano codice Node.js e tutti i pacchetti inclusi. Questo può essere utile, ma è troppo tardi; la sicurezza dovrebbe essere integrata nel processo di sviluppo prima di sottoporlo a verifica.\n\n## Sicurezza integrata…?\n\n## Come possiamo arrivarci?\n\nLe attuali violazioni della sicurezza mettono in evidenza che la sicurezza deve essere inserita in ogni fase del processo, compreso tra la creazione e la produzione e subito prima dell'esecuzione dello script per creare l'applicazione. Oltre a introdurre la sicurezza nel processo di creazione, dobbiamo proteggere il processo di creazione stesso; è stata una falla aperta per molto tempo.\n\nMolte aziende che fanno sviluppo interno stanno ora esaminando più attentamente il loro processo di building a causa delle recenti violazioni. Questo è positivo, ma non può fermarsi a queste reazioni istintive ad ogni attacco. Dobbiamo pensare in modo olistico e non aspettare il prossimo punto debole nella catena.\n\nAlcuni modi pratici per garantire la sicurezza del processo consistono nel considerare il server di compilazione come un elemento critico nell'infrastruttura complessiva e applicare le stesse regole e controlli a tale server come si farebbe per i sistemi principali. Acquisire credenziali adeguate, avviare in modo sicuro il firmware, verificare il codice, effettuare audit e registrare il sistema, ecc... durante tutto il suo ciclo di vita è quindi integrato nel processo DevOps quando qualcuno preme il pulsante.\n\n## Costruito per durare\n\n## Dalle soluzioni ai servizi e oltre.\n\nMolte persone non pensano allo script stesso come obiettivo. Non importa quanti buoni moduli siano inclusi se lo script stesso non è protetto. Alcuni modi per proteggere lo script sono eseguire un checksum, che dovrebbe poi essere versionato, controllato e firmato. Questo aggiunge complessità per i DevOps, ma ci sono strumenti che possono aiutare.\n\n## Costruisci una volta, distribuisci ovunque\n\nProprio come automatizziamo il processo di sviluppo, possiamo integrare l'automazione per implementare questi controlli e verifiche. L'automazione impedisce ad un'altra persona di intaccare potenzialmente le tue creazioni, ma vogliamo anche assicurarci che ci sia una persona umana che riceva i risultati e verifichi gli audit.\n\nGli strumenti che stai già utilizzando possono essere estesi per aggiungere l'automazione della sicurezza e controlli come quelli necessari per lo sviluppo continuo dell'integrazione nell'ambito del ciclo Agile, oppure strumenti di automazione nel mondo Linux.\n\nLe organizzazioni possono anche distribuire il proprio personale di sicurezza all'interno dei team di sviluppo aziendale, in modo che quando le cose vadano storte, le persone di sicurezza siano già coinvolte nel processo. Due luoghi in cui è importante avere persone di sicurezza sono l'infrastruttura per supportare, ad esempio, il vostro processo Agile, e la gestione dei prodotti per ottenere requisiti di sicurezza per la fase di definizione dei requisiti del prodotto prima che arrivi persino a uno sviluppatore.\n\nC'è sempre una carenza di personale addestrato e capace nella sicurezza, così come di fondi per assumere le persone giuste a causa dell'elevata domanda. Alcune opzioni sono formare le persone che già hai e fornire loro gli strumenti necessari. Non hai bisogno di un esperto di crittografia ad ogni passaggio del processo. Un'altra possibilità è invece di far sì che ogni programmatore sia responsabile della codifica dell'autenticazione, delle credenziali e del protocollo in una libreria di infrastruttura sicura, avere un team che costruisca moduli nei tuoi linguaggi e ambienti che svolgano tutte le funzioni di sicurezza. Il programmatore può richiamare il modulo e gestisce il lavoro difficile. In questo modo, costruisci una sola volta e distribuisci ovunque.\n\nStiamo vedendo aziende fornire strumenti di sicurezza SaaS, servizi basati su cloud che possono essere consumati per la tua applicazione e l'ambiente di esecuzione. Questo è un grande passo nel processo. Ci sono aziende che forniscono punti di iniezione di sicurezza come la sicurezza delle applicazioni in un ambiente di stile veloce. Questi controlli delle applicazioni, come la sanificazione degli input e la convalida degli input, possono essere incorporati nel tuo ambiente funzionale, ma questo è ancora in attesa alla fine. Ricorda che più presto inizi la sicurezza nel processo, più economico e meno doloroso diventa.\n\nTutto ciò richiede, naturalmente, ulteriori lavori di integrazione. Gli sviluppatori possono essere cauti riguardo al lavoro coinvolto, ma se esiste un framework con sicurezza integrata (e ci sono prototipi come Ruby on Rails e alcune infrastrutture cloud), può risparmiare molte ore. Tuttavia, devi comunque assicurarti di non affidarti solo alla piattaforma per la sicurezza, poiché potrebbe rappresentare un singolo punto di fallimento.\n\n## L'automazione ti renderà libero\n\nLe violazioni della sicurezza degli ultimi sei mesi sono state profonde. Ecco alcuni punti chiave di consigli:\n\nLa sicurezza dovrebbe essere parte integrante dell'intero ciclo di vita, a partire dai requisiti. La sicurezza deve essere presente nel ciclo DevOps stesso, non solo nel codice e nei test, ma anche nell'infrastruttura che guida quel processo.\n\nQuando si creano strumenti di sicurezza e oggetti attraverso moduli, costruiscili una volta, rendili modulari e distribuiscili ovunque.\n\nUtilizza servizi che ti permettono di fare affidamento sull'esperienza di qualcun altro per potenziare il tuo team di cybersicurezza con budget limitato.\n\nL'automazione ti renderà libero/a. Automatizza il più possibile per rendere la sicurezza più facile e veloce e ridurre le frizioni per i tuoi sviluppatori e tester. Con l'automazione, puoi eliminare l'80% di ciò che chiamiamo \"roba stupida\" in modo da poter concentrare le tue risorse limitate sui problemi difficili.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT42-it","image":"./episodes/edt-42/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect presso Intel, e Steve Orrin, CTO di Intel, Federal, discutono perché e come il pipeline DevOps deve essere protetto. L'unico modo per fornire codice solido, resiliente e sicuro è se la sicurezza è integrata, e prima si fa meglio è."},{"id":114,"type":"Episode","title":"Il ruolo del CIO nell'adozione del cloud.","tags":["cio","cloudadoption","compute","cloud","csp","multicloud"],"body":"\r\n\r\nNella prima parte di questa intervista, Darren Pulsipher, Chief Solution Architect di Intel, e Doug Bourgeois, Managing Director e GPS Cloud Strategy Leader di Deloitte, parlano della migrazione verso il cloud e del ruolo del CIO.\n\n## Patrimonio CIO\n\nDoug si è interessato al cloud fin dai primi tempi, quando lavorava per il governo federale dirigendo un'ampia organizzazione di servizi condivisi. Ha riconosciuto i vantaggi del cloud per le sue organizzazioni fornitrici di servizi e ha anche capito il valore per la sua organizzazione. Prima di tutto, avrebbe permesso di risparmiare denaro a livello infrastrutturale e, in secondo luogo, rappresentava un'opportunità per costruire un cloud virtualizzando per contribuire a risolvere il problema di proliferazione dei server. Per un particolare servizio, il taglio dei costi per l'utente finale è stato del 40 percento.\n\nNei servizi condivisi come il cloud, una volta raggiunte le economie di scala, è possibile fornire i servizi in modo più economico rispetto a quanto la maggior parte delle organizzazioni possa fare da sole.\n\n## La transizione al Cloud\n\nUna dozzina di anni fa, le organizzazioni, per la maggior parte, erano incentrate su cloud privati. Stavano migliorando i loro data center per incorporare una combinazione di multi-tenant consolidati e con alcune capacità di automazione integrate. Il pendolo si spostò verso il cloud pubblico con i grandi fornitori di iperscalabilità (AWS, Azure, Google) circa tre o quattro anni dopo.\n\nCirca tre anni fa, le organizzazioni si sono spostate verso un equilibrio nella cloud ibrida. Le persone hanno realizzato che una vasta gamma di sistemi nel loro portafoglio si prestano a modelli diversi, alcuni privati, alcuni pubblici, alcuni ibridi. Nel complesso, oggi c'è un approccio più olistico per abbinare sistemi e cloud a scopi specifici.\n\n## Mettere le informazioni nel CIO\n\nÈ ora più importante che mai per i CIO avere una conoscenza approfondita di ciò che sta accadendo all'interno delle proprie organizzazioni, avvicinandosi alla missione e agli obiettivi aziendali al fine di soddisfare al meglio le loro esigenze. Mentre in passato un CIO poteva limitarsi a fornire infrastrutture, ora è necessario prendere decisioni architettoniche informate basate su ciò che è disponibile. Ci sono due ragioni per questo. La prima è la diffusione di dati, intelligenza artificiale, analisi e apprendimento automatico nelle capacità di base dell'azienda, che richiedono una comprensione fondamentale del business. La seconda è che l'evoluzione del cloud ha raggiunto una nuova fase, l'era digitale, in cui i sistemi centrali dell'organizzazione devono essere modernizzati per migliorare la capacità di servizio per i propri utenti finali.\n\nQuesto viaggio ha iniziato a riportare il CIO al loro posto, gestendo l'informazione anziché concentrarsi così tanto sull'infrastruttura. Molti CIO sono stati relegati alla casella dell'infrastruttura, quando potrebbero essere dati l'opportunità di fare qualcosa di veramente trasformativo.\n\n## Posizionamento del CIO per il successo\n\nQuindi come si presenta il percorso dal Chief Infrastructure Officer al Chief Information Officer?\n\nUn modo è posizionarti per essere responsabile di qualcosa di nuovo che l'organizzazione sta cercando di fare, forse un nuovo processo o l'ingresso in un nuovo mercato, o anche un'unità aziendale che non è ancora attiva. Hai continuità e prospettiva poiché hai lavorato con tutti i diversi proprietari di applicazioni, e quindi sei particolarmente qualificato per portare avanti l'iniziativa. Un altro modo, più comune, è attraverso un evento negativo, dove diventa evidente che il cambiamento è necessario. Un disastro può essere il catalizzatore per un CIO per guidare il percorso verso una vera trasformazione.\n\nUnisciti a noi per la seconda parte dell'intervista...\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Doug Bourgeois"],"link":"/episode-EDT43-it","image":"./episodes/edt-43/it/thumbnail.png","lang":"it","summary":"Nella prima parte di questa intervista, Darren Pulsipher, Solution Architect Chief di Intel, e Doug Bourgeois, Direttore Esecutivo, Leader Strategico del Collegamento Cloud, Deloitte, parlano della migrazione verso il cloud e del ruolo del CIO."},{"id":115,"type":"Episode","title":"Cloud nell'epoca digitale","tags":["cloudmigration","cloud","compute","process","deloitte","multicloud"],"body":"\r\n\r\n## Il Tipico Percorso di Migrazione nel Cloud per un'Organizzazione\r\n\r\nNegli ultimi cinque o sei anni, le metodologie, gli strumenti e l'esperienza nella migrazione cloud si sono evolute in processi ripetibili.\r\n\r\nIl primo passo è decidere le priorità per la migrazione perché avverrà in fasi, non in un unico grande spostamento. Ciò non richiede molto tempo o risorse, ma è di fondamentale importanza. Un esempio estremo è che non si vorrebbe scegliere il mainframe come primo sistema da spostare sul cloud, ma piuttosto un sistema più autonomo come l'email.\r\n\r\nAziende come Deloitte hanno sviluppato e investito in strumenti di discovery che aiutano ad accelerare i processi di migrazione. Questi strumenti acquisiranno un ampio insieme di dati, eseguiranno un algoritmo che analizza la complessità e classifica tutti i sistemi in diverse categorie. Comprendere la configurazione e i punti di integrazione dei sistemi esistenti e la compatibilità dei componenti software è fondamentale per la migrazione verso il cloud. Dobbiamo anche considerare i limiti e i quadri di conformità come PCI o HIPAA. La creazione di zone di sbarco per questi ambienti nel cloud è la fase due del processo.\r\n\r\n## Proposta di valore della modernizzazione digitale.\r\n\r\nA volte c'è una quantità sostanziale di lavoro preliminare per le migrazioni. La prima ondata è la più facile con il minor numero di modifiche, ma dopo quella, nella fase due, potrebbero esserci aggiornamenti o modifiche ai sistemi operativi, riposizionamento o spostamento verso diversi tipi di database, ad esempio. La terza ondata spesso coinvolge server client obsoleti o architetture proprietarie che richiedono una significativa riarchitettura e potrebbero richiedere mesi per prepararsi alla disponibilità cloud.\r\n\r\n## Digitalizzazione moderna e migrazione verso il cloud\r\n\r\nÈ importante distinguere che la prontezza del cloud non è la stessa cosa dell'ottimizzazione del cloud; quella viene dopo.\r\n\r\nIn molti casi, la spinta principale dietro il passaggio al cloud è di natura aziendale piuttosto che tecnologica. Ad esempio, un cliente potrebbe non voler continuare un contratto di locazione solo per ospitare un data center, o potrebbe essere in fase di spostamento dei propri uffici fisici. In tali casi, c'è un fattore temporale in cui ha senso eseguire la migrazione in base alla prontezza anziché all'ottimizzazione.\r\n\r\nUna volta nel cloud, è necessario ottimizzare perché i fattori di costo sono diversi nel cloud rispetto al data center tradizionale. Il costo di un data center, dopo aver fatto l'investimento iniziale, è relativamente nascosto, mentre il cloud è più simile a un contratto di affitto che va avanti in perpetuo. Molte volte nei sistemi tradizionali risolviamo i problemi aggiungendo più memoria, più CPU o più spazio di archiviazione perché funziona fino a un certo punto, ma questo crea sistemi inefficienti. Se semplicemente spostiamo questi sistemi inefficienti e con elevate risorse nel cloud, il modello di costo è molto più alto di quanto dovrebbe essere, da qui la necessità di ottimizzazione.\r\n\r\nParte del processo di ottimizzazione potrebbe essere un cambiamento di processo. Ad esempio, per un'organizzazione in Canada, i costi sono aumentati alle stelle quando hanno trasferito un'istanza SAP nel cloud. Hanno poi realizzato che non utilizzavano questa istanza durante la notte o nei fine settimana, quindi sono passati da un modello 24/7 a un modello 16/5. Questo cambio ha permesso loro di risparmiare una quantità considerevole di denaro. Ci sono quindi modi per ottenere un alto rendimento con un piccolo sforzo utilizzando approcci diversi.\r\n\r\nStiamo finalmente vedendo, dopo più di un decennio nel cloud, una tendenza emergente a trovare valore in un cambiamento di strategia aziendale piuttosto che nell'infrastruttura. La pandemia COVID-19 è stata sicuramente un fattore nell'accelerare questo cambiamento. Un esempio perfetto di questo è la telemedicina. Esisteva già, ma era rimasta stagnante per cinque o sei anni prima della pandemia; ora questo modello è diventato la norma.\r\n\r\nLe innovazioni trasformative stanno accadendo nel cloud. Man mano che sempre più sistemi si spostano nel cloud, le industrie continueranno a cercare di adottare modelli diversi con nuove capacità trasformative.\r\n\r\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Doug Bourgeois"],"link":"/episode-EDT44-it","image":"./episodes/edt-44/it/thumbnail.png","lang":"it","summary":"Nella seconda parte dell'intervista, Darren Pulsipher, Chief Solution Architect, Intel, e Doug Bourgeois, Managing Director, GPS Cloud Strategy Leader, Deloitte, continuano la loro discussione sulla migrazione verso il cloud."},{"id":116,"type":"Episode","title":"Non tutti i nuclei sono uguali.","tags":["multicloud","compute","optimization","workloadplacement","workload","migration","process","cloudinstance"],"body":"\r\n\r\nIntel ha assunto architetti di soluzioni cloud per aiutare i clienti a spostarsi in modo intelligente verso le istanze cloud appropriate per i loro carichi di lavoro. Stephen è recentemente entrato a far parte di Intel ed ha una lunga esperienza generale nei database, con gli ultimi sette o otto anni focalizzati sul cloud, sfruttando le sue risorse per i clienti.\n\nAlcuni degli aspetti più difficili con cui Stephen si è confrontato nell'aiutare i clienti a passare al cloud sono la determinazione del prezzo e le aspettative per il trasferimento. I fornitori di servizi cloud spesso affermano che i clienti risparmieranno denaro passando al cloud, ma questo spesso non è il caso.\n\nUna ragione è che c'è un cambiamento costante nel mercato dei fornitori di servizi cloud competitivi in termini di caratteristiche, funzioni e capacità. Un'altra ragione è l'ignoranza, ad esempio credere che un VCP centrale sia lo stesso per tutti. La migrazione con una mentalità di \"prende e sposta\" può essere anche molto costosa. L'ottimizzazione è fondamentale per una migrazione intelligente verso il cloud.\n\nPer ridurre i costi e potenzialmente risparmiare una grande quantità di denaro, devi scegliere le istanze giuste per le giuste performance. Non tutti i core, o CPU virtuali, sono uguali. All'interno di AWS, hanno le M4, le Broadwell di Intel e le M5, che sono una combinazione di Cascade Lake e Skylake, e diversi carichi di lavoro possono sfruttare in modo molto diverso queste piattaforme.\n\n## Prestazioni CoreMark\n\nCoreMark è un'applicazione a thread singolo che testa i movimenti dei registri e le semplici aggiunte per qualsiasi numero di CPU. Attraverso tre generazioni di processori Intel, Broadwell, Skylake e Cascade Lake, questo test mostra pochissime differenze tra di loro. Questa informazione è stata erroneamente utilizzata per guidare le decisioni dei clienti, dato che il test non è un modo efficace per misurare le differenze nei processi stessi. Ci possono essere enormi differenze nelle prestazioni con carichi di lavoro diversi.\n\n## Database prestazioni WL\n\nStephen ha eseguito test digitali su carichi di lavoro reali, focalizzandosi su database open source. L'ambiente Cascade Lake è stato tre volte migliore dell'ambiente Broadwell per gli open source, il che ha senso considerando i progressi in termini di velocità e i progressi su chip che sfruttano l'accesso a bassa latenza. Quindi, avanzare di due generazioni porta a un miglioramento delle performance di due o tre volte su questi carichi di lavoro.\n\nIl carico di lavoro e il core devono essere considerati insieme. Ad esempio, un cliente potrebbe essere tentato di passare a una VCPU che Amazon afferma essere più economica del 10%. AWS potrebbe comunque imballare i core su questi processori e ti trovi ora a passare da un ambiente in cui sei una delle 48 macchine virtuali su una scatola a uno in cui ci sono 128 macchine virtuali; il tuo accesso alla memoria è limitato e potresti ottenere il 60% in meno di prestazioni per un risparmio del 10%.\n\nLe organizzazioni spesso credono che se esternalizzano verso il cloud, non abbiano più bisogno di un architetto di sistemi. È vero che gli architetti non devono più installare fisicamente e configurare le macchine, ma lo fanno ora virtualmente e devono comprendere cosa offrono le diverse istanze per differenti carichi di lavoro.\n\nIntel sta lavorando su uno strumento per mostrare quale carico di lavoro funziona meglio su quali istanze. Nel frattempo, Intel ha alcune linee guida generali e architetti di soluzioni cloud per aiutare a guidare i clienti.\n\nInoltre, è importante effettuare molti test per capire dove posizionare i carichi di lavoro, ma è anche importante testare e fare benchmark per convalidare che si stia ottenendo ciò che ci si aspetta da un provider.\n\n## Database WL Performance – Non NVMe\n\nPrestazioni del database WL - Non NVMe\n\nIntel ha effettuato alcuni test sulle carichi di lavoro su installazioni fresche su un'istanza a 64 core con 64 VCPU fisse. Dopo aver ottenuto il numero iniziale, è stata istanziata un'altra istanza e lo stesso test è stato eseguito nuovamente. I risultati variavano drasticamente da un test all'altro. Ciò potrebbe essere dovuto al fatto che potrebbero esserci una combinazione di processi offerti a un determinato livello di tier, oppure potrebbero esserci distanza e latenze aggiuntive sugli allegati di archiviazione a blocchi, ad esempio, o addirittura rumori di vicini. Quindi vale la pena fare dei test per essere sicuri che il sistema soddisfi le aspettative.\n\nIn breve, per ottenere il massimo valore dalla cloud, devi educarti, testare i sistemi e sfruttare l'aiuto disponibile.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steven Holt"],"link":"/episode-EDT45-it","image":"./episodes/edt-45/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect di Intel, e Stephen Holt, Cloud Solution Architect di Intel, discutono dell'ottimizzazione del cloud e degli studi che dimostrano che i core si comportano in modo diverso per diversi carichi di lavoro."},{"id":117,"type":"Episode","title":"Proteggere la tua pipeline DevOps","tags":["devops","compute","technology","process","devsecops","cybersecurity","zerotrustarchitecture"],"body":"\r\n\r\n## I Vettori di Attacco\n\nMolti attacchi avvengono a livello individuale delle persone. Alcuni degli attacchi più recenti e subdoli si sono concentrati sul phishing e sull'ingegneria sociale rivolta agli individui all'interno di DevOps. Abbiamo bisogno di addestrare meglio le persone a tutti i livelli. In un caso, è stato uno stagista con accesso alle chiavi che è caduto vittima di un piano malvagio.\n\nUn altro vettore è la tecnologia: attacchi tradizionali di negazione del servizio, attacchi di iniezione SQL o attacchi di andamento dell'overflow. Gli ultimi incidenti utilizzano sia persone che tecnologia per attaccare il processo. Sono insidiosi perché si verificano durante il processo di costruzione e possono essere molto difficili da individuare. Possono anche propagare codice maligno attraverso i clienti. Per instillare fiducia nei clienti, le organizzazioni devono avere una strategia per proteggere la pipeline di fornitura.\n\n## Sicurezza della pipeline\n\nNon tutte le build pipeline sono uguali, ma in generale, sono composte da quattro fasi con relativi ambienti: sviluppo, compilazione, test e produzione. Queste fasi possono essere facilmente suddivise in più stadi a seconda del tipo di prodotto che stai sviluppando, ma gli ambienti sono collegati a tali diverse fasi.\n\nDobbiamo analizzare l'intero processo, che comprende software, hardware e procedure, e adottare un approccio diverso anziché concentrarsi solo sull'infrastruttura, come hanno fatto efficacemente la maggior parte.\n\n## Sicurezza del server e dell'infrastruttura\n\nIn fondo alla pila, è necessario proteggere l'hardware nell'ambiente di sviluppo e compilazione. L'ambiente di test sarà un po' diverso perché potresti voler eseguire test che coinvolgono l'iniezione di codice maligno. Gli ambienti di produzione di solito sono ben protetti, specialmente adesso che molte aziende offrono software come servizio. Negli ambienti di produzione e compilazione, devi adottare tutte le misure di sicurezza tipiche che adotteresti negli ambienti di produzione o SaaS.\n\nCi sono tre elementi chiave in questi ambienti. Il primo è la rilevazione. La rilevazione e la risoluzione dei problemi sono noti come misura di sicurezza utilizzando i registri di servizio che utilizzano una piattaforma come Splunk per trovare qualunque cosa fuori dall'ordinario. Assicurati di farlo non solo negli ambienti di sviluppo, ma anche in quelli di costruzione e produzione.\n\nTieni presente che nell'ambiente di test avrai bisogno di più ambienti di test, alcuni più sicuri di altri sul lato della rilevazione poiché desideri inserire codice errato nei tuoi test. Non distribuire semplicemente la sicurezza uniformemente in tutti gli ambienti; i profili di sicurezza possono essere diversi per ogni ambiente.\n\nLa prevenzione è la seconda chiave. Ciò significa essere attenti con l'hardware, assicurarsi che le cose siano correttamente aggiornate, avere gli aggiornamenti di sicurezza corretti e farlo in modo automatizzato. Questo dovrebbe avvenire in tutte le ambientazioni, inclusa l'ambiente di test, e soprattutto durante la creazione e la produzione.\n\nLa terza chiave fa parte della prevenzione: la radice affidabile dell'hardware. Una catena di fiducia può essere stabilita dall'hardware, attraverso le sezioni di avvio del firmware, fino ai supervisori e ai sistemi operativi. La radice della fiducia può essere portata nei contesti di sviluppo, costruzione, test e produzione. Questo può includere contenitori sicuri e macchine virtuali sicure. Ad esempio, mi piace conservare le mie chiavi di crittografia e di hash nell'hardware come un modulo TPM e poi anche con l'estensione Secure Guard di Intel. Anche se qualcuno accedesse alla macchina, non sarebbe in grado di rubare quelle chiavi.\n\n## Eseguibili affidabili\n\nL'impostazione degli eseguibili fidati è il passaggio successivo. Ciò significa che puoi eseguire controlli di sicurezza sul codice che viene controllato e compilato e quindi effettuare il check-in con l'hash delle modifiche apportate. Se è stato inserito qualcosa nella base del codice, puoi rilevarlo, poiché non dovrebbero esserci modifiche al codice durante il processo di compilazione.\n\nIn una nuova fase di controlli di sicurezza, è possibile eseguire l'analisi statica del codice o l'analisi dinamica del codice o violazioni di sicurezza. Ci sono alcuni ottimi strumenti che è possibile integrare facilmente nel proprio tipico flusso di lavoro DevOps, sia che si utilizzi Jenkins o i flussi di lavoro di GitHub, ad esempio.\n\nUna volta che un eseguibile è stato costruito, crea immediatamente l'hash e quel hash dovrebbe essere versionato con l'eseguibile; dovrebbe rimanere l'eseguibile che viene sottoposto a tutti i test e spinto in produzione. Quell'hash garantirà che nulla sia stato manomesso.\n\n## Immagini attestata e sicure.\n\nSolitamente, ci sono diversi repository o eseguibili da utilizzare per il codice. L'hash che viene creato durante la compilazione è ora nel registro e puoi attestarlo. Puoi proteggere quelli nelle immagini in modo che non possano essere modificati. Se qualcuno ha bisogno di tornare indietro e apportare una piccola modifica, ad esempio una etichetta o metadati, è importante non apportare la modifica e darle lo stesso numero di versione. È meglio passare di nuovo attraverso il ciclo, anche se ci vuole più tempo che avere processi manuali che si intromettono nei tuoi binari.\n\nOra, puoi prendere lo stesso binario su cui hai eseguito tutti i test e spingerlo in produzione. A questo punto, è un errore ricostruire il codice sorgente. È meglio spingere la build originale nel repository di produzione, o dorato. Questo repository è l'unico luogo da cui recuperare immagini, binari o macchine virtuali, ad esempio. Tutte le immagini devono essere notarizzate e certificate. Se hai macchine virtuali o applicazioni confidenziali, o desideri assicurarti che finiscano solo su hardware specifico, puoi impostare questo tipo di restrizioni. Puoi crittografare le macchine virtuali, i contenitori o persino i binari e bloccarli con la chiave che è memorizzata nei tuoi sistemi di build e produzione.\n\n## Iniettare Strumenti di Sicurezza\n\nGli strumenti di sicurezza devono essere integrati nel processo di costruzione. Invece di prendere liberamente librerie di sicurezza open source o ricreare quelle già esistenti, i tuoi ingegneri della sicurezza dovrebbero essere coinvolti in modo che possano scegliere strumenti che possano essere facilmente utilizzati e riutilizzati dai team di sviluppo. Un buon esempio è l'autenticazione di base: il login dell'utente. Dovrebbe esistere una libreria comune anziché ogni applicazione avere la propria.\n\nÈ importante trattare queste librerie di sicurezza e strumenti proprio come faresti con qualsiasi altro programma di sviluppo software che stai condividendo all'interno della tua organizzazione. La condivisione ridurrà i tempi e aumenterà la sicurezza in tutto il tuo ecosistema.\n\n## Costruisci una volta, distribuisci sicurezza ovunque.\n\nUna volta che hai istituito i tuoi team di sicurezza degli sviluppatori, assicurati di iniettare le politiche e gli strumenti in tutti i tuoi prodotti e ambienti. Oggi esistono delle ottime tecnologie che ti consentono di gestire più ambienti. Quindi, quando viene creato un nuovo applicativo, viene creato con un profilo di sicurezza usando le tue immagini di macchine virtuali o contenitori come immagini di base utilizzate dai team di sviluppo. Configurando la sicurezza nelle tue VM o contenitori nelle immagini di base, otterrai una conformità istantanea su diversi ambienti. È inoltre possibile integrarsi con strumenti di sicurezza, in modo che se si trova qualcosa di insolito nell'applicazione, è possibile notificarlo agli strumenti di sicurezza. Non cercare di creare strumenti di sicurezza che gestiscano il cento per cento dei casi, perché non li finiresti mai; punta all'ottanta percento come base solida e creali in modo che gli sviluppatori possano innovare l'ultimo venti percento se necessario, in collaborazione con il tuo team di sicurezza.\n\nUn ultimo consiglio importante è automatizzare tutto ciò che puoi, soprattutto nel processo DevOps, per prevenire iniezioni maliziose. Proteggi la tua pipeline; proteggi il tuo processo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT46-it","image":"./episodes/edt-46/it/thumbnail.png","lang":"it","summary":"Nella seconda parte di questo episodio, Darren Pulsipher, Chief Solution Architect di Intel, fornisce consigli pratici per proteggere ogni fase del DevOps pipeline, incluso la protezione dell'hardware e delle pile software con il hardware radice di fiducia, la scansione di sicurezza, i container/VM attestati ed criptati e altro ancora."},{"id":118,"type":"Episode","title":"Aspettando il 2021","tags":["covid","remoteworker"],"body":"\r\n\r\nGreg guida le vendite e il marketing di Intel negli Stati Uniti. I clienti di Intel sono principalmente i produttori di sistemi OEM e il team di vendita di Intel lavora quotidianamente per soddisfare tali account e aiutarli a costruire sistemi basati sulle tecnologie di calcolo e memoria di Intel. Attualmente, c'è una domanda senza precedenti per il calcolo.\n\nI team di Intel lavorano con aziende di software, fornitori di cloud, grandi imprese, scuole e enti governativi per rendere l'elaborazione accessibile e aiutare a individuare tendenze e applicare casi d'uso che risolvano i problemi aziendali in modo che migliori la società. Intel, quindi, lavora come innovatore e identifica nuove tendenze per assicurarsi che i clienti abbiano i prodotti giusti.\n\n## COVID come acceleratore\n\nAttualmente, le tendenze sono tutte legate alla pandemia di COVID. Le organizzazioni hanno trascorso la maggior parte del 2020 in modalità di crisi, con l'IT che implementava tecnologie per mantenere in funzione le attività aziendali e poi si adattava alla nuova normalità. Ora, c'è una stabilizzazione in cui i dipartimenti IT possono guardare avanti anziché limitarsi a rispondere alla crisi in corso.\n\nUna lezione è che l'IT può muoversi molto più velocemente di quanto abbiamo mai pensato. Ad esempio, è incredibile quanto rapidamente quasi ogni settore sia riuscito a passare al lavoro a distanza. Eppure, COVID ha agito come un acceleratore piuttosto che un catalizzatore. La maggior parte dei cambiamenti erano già pianificati, ma COVID ha compresso i tempi. Invece, diciamo, un lancio pianificato di Office 365 di 18 mesi, è accaduto in una settimana e mezza perché era necessario.\n\nUna delle principali ragioni per la velocità del cambiamento è che un CIO non avrebbe potuto prendere tutte le decisioni che dovevano essere prese durante la crisi, quindi la presa di decisione è stata spostata verso il basso per dare potere a coloro che si trovavano in prima linea, in modo da poter lavorare velocemente e fare ciò che era meglio per l'azienda.\n\n## Modello di lavoro ibrido\n\nUna modifica che richiederà del tempo è capire il nuovo modello di lavoro ibrido. Intel, ad esempio, sta lavorando sulla definizione delle aspettative riguardo a quante volte i dipendenti dovrebbero recarsi in ufficio, dopo che la maggior parte di essi ha trascorso un anno lavorando da casa. I reparti IT stanno preparando e investendo in strumenti che permettano la collaborazione tra alcuni dipendenti in ufficio e altri a casa.\n\nLe organizzazioni potrebbero non sapere come sarà il loro modello per molti mesi, quindi i dipartimenti IT devono essere flessibili nel loro approccio.\n\n## Applicazioni e automazione per l'esperienza dei dipendenti\n\nI progetti online che sono stati messi da parte nel 2020 stanno tornando ora in questo nuovo ambiente di lavoro ibrido. I dipendenti vogliono interagire con la propria attività aziendale nello stesso modo in cui lo fanno come consumatori nei software come servizio. Di conseguenza, ci sono molte app in sviluppo incentrate sull'esperienza dei dipendenti.\n\nInoltre, ci sono stati molti progressi riguardo all'utilizzo dei bot. Ad esempio, Intel ha appena lanciato un bot per le risorse umane per migliorare e automatizzare l'esperienza dei dipendenti, permettendo l'accesso a tutti i servizi di risorse umane. Questo porta alla necessità di maggior intelligenza artificiale e automazione dell'intelligenza artificiale, guidata dall'apprendimento automatico.\n\n## Servizio clienti privo di attrito e privo di contatto\n\nMolti dei clienti di Intel si stanno preparando per un servizio clienti senza attrito e senza contatto nei settori governativo, commerciale e dell'intrattenimento. Un settore che si è accelerato durante la pandemia è quello delle telecomunicazioni, il quale renderà queste consegne senza attrito molto più facili.\n\nL'investimento di capitale per costruire l'infrastruttura telco e il 5G sta supportando sempre più dispositivi IOT di tipo remoto che, prima della pandemia, avrebbero richiesto anni per realizzarsi.\n\n## IA e Apprendimento Federato\n\nIntel ha registrato un'enorme crescita nella collaborazione con l'IA e i dati protetti in settori come la scoperta medica e i mercati finanziari. Con i nuovi processori Xeon di terza generazione di Intel, sono presenti enclave di calcolo sicure (SGX) e memoria protetta, che non possono essere accessibili al di fuori del sistema. I casi d'uso che vengono implementati riguardano l'IA e l'apprendimento federato, in cui i dati degli utenti e delle aziende possono addestrare modelli globali, ma i dati non vengono condivisi in un repository centrale. Grazie all'IA, al concetto di apprendimento federato e a SGX di Intel, questi dati possono essere protetti. Gli ostacoli relativi alla privacy e ai regolamenti sui dati possono essere rimossi. Ad esempio, i dati di un ospedale o di un singolo paziente possono essere protetti, ma ancora utilizzati per addestrare un modello globale con grandi benefici.\n\n## RPA in Italian is \"Robotic Process Automation\".\n\nMolte aziende stanno trovando modi per automatizzare compiti, in alcuni casi compiti banali, per liberare i loro dipendenti di lavorare su progetti di maggior valore. Questa tendenza è esplosa negli ultimi sei otto mesi, con moltissima crescita nel mercato. Negli ultimi cinque anni, i mercati di RPA hanno ricevuto oltre due miliardi di dollari di finanziamenti VC, principalmente dai mercati finanziari di New York City. Oltre a RPA, ci sono molte strutture di automazione che le persone stanno utilizzando per implementare infrastrutture nei loro data center e anche senza soluzione di continuità nel cloud.\n\n## Edge Compute translates to \"Calcolo in periferia\" in Italian.\n\nIntel ha iniziato a sviluppare architetture di riferimento per aiutare le aziende a costruire la loro elaborazione periferica. La scienza di importanza qui è collegare l'elaborazione periferica all'infrastruttura del cloud e costruire sia una pila hardware che software, un pannello di controllo e automazione. Questa è un'altra area di incredibile investimento.\n\n## Andando avanti\n\nIl 2020 è stato un anno di caos, adattamenti senza precedenti e cambiamenti accelerati. Ora, in un 2021 più stabile, le aziende possono basarsi sulle lezioni e le tendenze che ne sono risultate.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Ernst"],"link":"/episode-EDT47-it","image":"./episodes/edt-47/it/thumbnail.png","lang":"it","summary":"Greg guida le vendite e il marketing di Intel negli Stati Uniti. I clienti di Intel sono principalmente i produttori di sistemi OEM e la forza vendita di Intel lavora quotidianamente per assistere tali account e aiutarli a costruire sistemi basati sulle tecnologie di calcolo e memoria di Intel. Attualmente c'è una richiesta senza precedenti per il calcolo. Le squadre di Intel collaborano con aziende software, fornitori di cloud, aziende Fortune 1000, scuole e agenzie governative per rendere accessibile il calcolo e aiutare a identificare tendenze e applicare casi d'uso che risolvano i problemi aziendali in modo che si migliori la società. Intel, quindi, opera come innovatrice di tendenza e identifica nuove tendenze per assicurarsi che i clienti abbiano i prodotti giusti."},{"id":119,"type":"Episode","title":"VAST Data Rivisitato","tags":["dataarchitecture","data","optane","technology","vastdata"],"body":"\r\n\r\nVAST Data è cresciuta rapidamente negli ultimi sei mesi, con un team in espansione e impressionanti vendite come circa 70 petabyte di storage flash al governo federale. Oltre alla condivisione generale di file con i loro sistemi di storage all-flash, hanno interessanti casi d'uso in settori come il sequenziamento di prossima generazione, la microscopia confocale e i carichi di lavoro di simulazione del tunnel del vento.\n\nLa piattaforma dell'azienda consente di risolvere problemi di lettura casuale perché tutti i dati si trovano su flash senza costi esorbitanti; la piattaforma gestisce un volume elevato di dati con bassa latenza.\n\n## Tecnologia VAST e drive Intel Optane\n\nVAST utilizza le unità Optane di Intel per ottenere una parità di lettura e scrittura, tra gli altri vantaggi. Poiché Optane è una memoria persistente, non ci sono problemi di coerenza della cache e non c'è bisogno di DRAM, il che rappresenta un grande vantaggio architettonico per evitare un guasto o una perdita di dati. Il costo totale per utente diminuisce anche perché non è necessario acquistare grandi macchine con molta memoria per lo storage dei file se si desidera più velocità. Quel livello viene eliminato.\n\nScalabilità e flessibilità sono due altri vantaggi, poiché è possibile aggiungere ulteriori casse dati (casse D) senza influire sulle prestazioni, e sono completamente compatibili anche con diverse generazioni di flash. Non esiste un singolo punto di errore e non c'è un limite teorico; VAST ha testato fino a 100 petabyte.\n\nPuoi migliorare le prestazioni aggiungendo delle caselle client (C boxes), indipendenti dalle caselle D. Capacità con flash è praticamente gratuita, ma devi esporre quel flash con la CPU. Le caselle C sono totalmente prive di stato, quindi puoi espanderle o ridurle in modo dinamico. VAST garantisce un tempo di attività perché hai pieno accesso a ogni PCP sul retro.\n\nA seconda delle esigenze di performance del cliente, possono esserci diversi numeri di box D e box C; ad esempio, un cliente potrebbe non avere bisogno di ulteriori performance, ma di maggiore capacità, quindi il cluster potrebbe avere, diciamo, 11 box C e 37 box D.\n\nSe hai una scatola C e una scatola D, disponi di circa 40 gigabyte al secondo di larghezza di banda, che è il modello base. Ogni aggiunta di una scatola D aggiunge altri 40 gigabyte di larghezza di banda. Una scatola C non satura tutti gli IOPS, quindi se aggiungi un'altra scatola C puoi ottenere 350.000 IOPS da una scatola. Poiché il flash è vincolato dalla CPU, più CPU aggiungi, più ti consente di scalare.\n\n## Nuovo modello di business per lo storage\n\nIl nuovo prodotto di VAST Data, Gemini, consente ai clienti che necessitano di elevate prestazioni senza molta capacità di licenziare solo la quantità di hardware necessaria dal loro produttore di contratti, il che comporta un enorme risparmio di costi. I clienti possono aumentare e pagare la capacità man mano che ne hanno bisogno, anziché sostenere un costo iniziale per le future esigenze di capacità.\n\nDal punto di vista dell'OPEX, questo ha senso per molte aziende. Ad esempio, per un cliente, un sistema all-flash da 30 petabyte che gestisce un terabyte e mezzo di larghezza di banda, il costo è inferiore a S3 di Amazon per l'accesso poco frequente. Questo è solo per un anno; guardando avanti, è effettivamente inferiore a Glacier se consideriamo il modo in cui Amazon addebita, per gigabyte al mese. E c'è la flessibilità di tornare a un modello CAPEX se ciò ha più senso in seguito.\n\nÈ importante notare che VAST sta presentando un'appliance, non uno storage come servizio, il che può essere un incubo di supporto a causa di tutte le variazioni hardware e firmware, dei supporti che si stanno utilizzando, delle interconnessioni, ecc... il che porta ad un'enorme complessità. VAST sta ancora spedendo le stesse scatole e server; è solo un modello di business diverso per consentire flessibilità nel consumo dello storage.\n\nAlcune aree interessanti in cui VAST potrebbe essere utile sono nella ricerca medica, come ad esempio la patologia digitale, che comporta un'enorme quantità di dati spesso difficile da accessare per i ricercatori poiché memorizzati su supporti economici e lenti. Un'altra possibilità è la medicina di precisione basata sul patrimonio genetico di una persona. Inoltre, l'utilizzo di intelligenza artificiale per analizzare le acquisizioni di pacchetti potrebbe essere utile per prevedere attacchi da parte di avversari avanzati.\n\nUn altro caso d'uso promettente è un cliente con tutti i propri dati memorizzati in un sistema di archiviazione flash VAST invece che nel cloud, ma esegue tutte le proprie elaborazioni nel cloud, magari riportando solo i risultati. I risultati sono tipicamente molto piccoli, forse un paio di byte di dati, e l'estrazione è a basso costo. Questo tipo di modello, ad esempio, potrebbe generare valore tramite analisi su dati obsoleti attualmente solo immagazzinati e troppo costosi da spostare.\n\nC'è molta flessibilità nel fare un approccio ibrido o multi-cloud in cui si ha un sistema di archiviazione centralizzato in loco che può essere accessibile tramite più fornitori di cloud.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Randy Hayes"],"link":"/episode-EDT48-it","image":"./episodes/edt-48/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, Darren fa il punto con Randy Hayes, attualmente VP delle vendite per il settore pubblico di VAST Data, sei mesi dopo l'ultima conversazione per vedere come stanno nel settore, cosa c'è di nuovo in VAST, e casi d'uso interessanti. Il loro nuovo prodotto, Gemini, offre un modello di business di archiviazione diverso."},{"id":120,"type":"Episode","title":"Lavoro remoto prima, durante e dopo la pandemia.","tags":["covid","remoteworker"],"body":"\r\n\r\nHanno individuato quattro aree che li hanno aiutati non solo a sopravvivere, ma a eccellere durante questo periodo insolito: Prevedere le necessità del tuo responsabile, Comunicare come se il tuo lavoro dipendesse da questo (perché sicuramente lo fa), Sostenere gli altri come sostenendo te stesso, Bloccare! Quel! Calendario!\n\n## Anteporre le necessità del tuo responsabile\n\nIndovina cosa ha bisogno di sapere il tuo responsabile e tieni le informazioni a portata di mano.\n\nI seguenti elementi dovrebbero essere creati in modo proattivo: rapporti di vendita, stato del progetto e stato del cliente.\n\n## Comunica come se il tuo lavoro dipendesse da questo (perché lo fa sicuramente)\n\nNon riempire la casella email degli altri con informazioni inutili.\n\nMetti la tua richiesta all'inizio dell'email. Poi aggiungi informazioni aggiuntive di supporto.\n\nDai al tuo team un riassunto di quello che stai facendo con informazioni utili.\n\n## Sventola la tua bandiera sventolando la bandiera per gli altri.\n\nUn elemento chiave del successo in qualsiasi azienda è avere risultati visibili e tangibili.\n\nNon puoi sempre abbassare la testa e lavorare sperando che si faccia sentire da sola.\n\nRiconosci gli altri che ti hanno aiutato a chiudere l'affare o terminare il progetto.\n\n## Blocca! Quel! Calendario!\n\nStabilire dei limiti per il tempo in famiglia e quando il lavoro termina e inizia.\n\nBlocca del tempo per il tuo tempo personale. Hai bisogno di tempo per riposare il tuo cervello.\n\nImposta una pausa di 5-10 minuti tra le riunioni.\n\n* Tempo per elaborare la tua casella di posta.\n\n* Tempo alla fine della giornata per elaborare la tua giornata\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Rachel Dreikosen"],"link":"/episode-EDT49-it","image":"./episodes/edt-49/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con Rachel Dreikosen, Business Development Manager del settore pubblico presso Intel, di come COVID-19 abbia influenzato il suo equilibrio tra lavoro e vita privata e del motivo per cui ha iniziato un blog per aiutare altre professioniste tecniche nel settore delle vendite."},{"id":121,"type":"Episode","title":"Modello di Maturità delle Infrastrutture","tags":["infrastructurematurity","compute","technology","sdi","cloud","multicloud"],"body":"\r\n\r\nLa trasformazione digitale può essere difficile. Molte organizzazioni diventano paralizzate nel cercare di decifrare tutte le tecnologie che vengono loro lanciate ogni giorno. In questo percorso, come in ogni altro, è importante avere una mappa. In questo episodio, Darren spiega il \"Modello di Maturità dell'Infrastruttura\" per aiutare le organizzazioni a capire dove si trovano nella loro trasformazione digitale, dove possono andare dopo e come arrivare lì.\n\n## Fase standardizzata\n\nQuasi ogni organizzazione si trova in questa fase standardizzata o oltre. Comprendere questa fase ci fornisce un punto di partenza per parlare delle cose comuni che osserviamo tra le organizzazioni.\n\n## Base\n\nIl livello di base è dove troviamo un'infrastruttura non coordinata e una gestione reattiva. Questo è particolarmente comune nelle startup in cui un'organizzazione acquista servizi o hardware solo quando necessario, in reazione agli eventi anziché come parte di un piano principale. Qui vediamo anche stack software/hardware appositamente progettati. Un'IT artigianale pesante fa parte anche di questa fase di maturità.\n\n## Centralizzato\n\nA questo livello, l'infrastruttura è centralizzata. Le organizzazioni acquistano capacità anziché hardware appositamente progettato. Gli acquisti non sono più reattivi, ma fanno parte di un piano a lungo termine. Tipicamente, l'organizzazione avrà configurazioni server comuni in modo da poter acquistare in grande quantità per raggiungere un costo più efficiente e una maggiore affidabilità. L'IT è più centralizzato e specializzato, ad esempio, nella rete, nello storage, nel calcolo e nella sicurezza.\n\n## Semplificato\n\nNel livello semplificato, l'infrastruttura è più consolidata. I diversi dipartimenti possono condividere attrezzature come server, archiviazione e reti. Le organizzazioni ottengono migliori prestazioni quando passano dai vecchi modi a nuovi modi di centralizzare e semplificare. I costi operativi diminuiscono all'aumentare dell'efficienza.\n\n## Fase virtualizzata\n\nLa maggior parte delle organizzazioni oggi si trova almeno in una parte della fase virtualizzata. Qui troviamo configurazioni standard e cloud privati.\n\nLa virtualizzazione del server offre la flessibilità di eseguire applicazioni su diversi computer e di spostarle facilmente tra i computer.\n\nLa virtualizzazione dello storage è un sviluppo più recente che offre benefici simili alla virtualizzazione del server: flessibilità per decisioni più dinamiche. Ora lo storage può estendersi a tutto l'ecosistema. Lo storage può essere fornito per un'applicazione specifica e sia lo storage che l'applicazione possono spostarsi all'interno dell'infrastruttura.\n\nLa virtualizzazione di rete, l'ultima aggiunta, è stata particolarmente accolta dagli Internet Service Provider. Hanno effettuato un grosso investimento a causa dell'efficienza di poter apportare cambiamenti dinamici nella rete in remoto anziché tramite hardware basato su scopi precedenti.\n\nTutte queste tecnologie di virtualizzazione sono legate insieme nelle offerte dello spazio del cloud privato, sia commerciali che open source, spesso in un unico luogo facile da gestire. Le organizzazioni stanno entrando in questa fase, modificando e consolidando la loro IT da un focus verticale a un'analisi completa di tutto (NOTA: possiamo chiamare questo un focus orizzontale?) con sistemi, applicazioni e servizi più che calcolo, archiviazione e rete.\n\n## Fase automatizzata\n\nNella fase automatizzata, le organizzazioni possono configurare automaticamente l'infrastruttura, risparmiando tempo eliminando strati di persone e autorizzazioni. Utilizzando i portali self-service, un ingegnere o sviluppatore software può ottenere immediatamente le risorse di cui ha bisogno. Questa configurazione automatica consente anche l'automazione di base delle patch, delle macchine virtuali, della sicurezza e della conformità. IT è ora meno in modalità reattiva, ma in modalità proattiva. Altri elementi preziosi di questa fase sono, ad esempio, l'avvio automatico dell'infrastruttura per le applicazioni in produzione e le applicazioni di auto-guarigione.\n\n## Fase orchestrata\n\nPoiché l'automazione diventa sempre più complessa, diventa necessaria una fase orchestrata. L'automazione consiste nell'applicare azioni su una macchina, mentre l'orchestrazione è la coordinazione delle azioni che avvengono su più macchine o anche su diverse modalità (archiviazione, calcolo, rete) per un'applicazione. Inoltre, gli stack di applicazioni automatizzate possono distribuire diverse applicazioni su diversi server. In questa fase, le organizzazioni orchestrano anche servizi ibridi, ad esempio gestendo le risorse su cloud pubblici e privati. I vantaggi di questa orchestrazione sono i costi di OpEx ridotti, i costi di CapEx ridotti e il tempo di distribuzione ridotto.\n\n## Tempo reale (gestito dal SLA) Fase\n\nIn una fase di tempo reale, le organizzazioni si trovano in un'infrastruttura di accordo sul livello di servizio. Piuttosto che applicazioni, le organizzazioni utilizzano servizi che forniscono valore e collegano tutto insieme. I servizi condivisi si estendono su multi-ambienti ibridi e persino infrastrutture legacy. La combinazione delle infrastrutture ibride, l'orchestrazione basata su politiche e l'orchestrazione basata su servizi ottimizzano l'infrastruttura, la gestione dei dati e i servizi.\n\n## Conclusione\n\nÈ comune che diverse parti della tua organizzazione si trovino in fasi diverse. Alcuni gruppi saranno più avanti di altri; tutto ciò è salutare. Piccoli gruppi pionieristici possono fallire senza influire sull'intera organizzazione, oppure possono fare una scoperta sensazionale e trascinare il resto dell'organizzazione al loro livello. Molte poche organizzazioni sono arrivate alla fase più avanzata sulla mappa. La chiave è non scoraggiarsi, ma utilizzare la mappa come guida per capire dove ti trovi e quali potrebbero essere i prossimi passi per la tua organizzazione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT5-it","image":"./episodes/edt-5/it/thumbnail.png","lang":"it","summary":"La trasformazione digitale può essere difficile. Molte organizzazioni diventano paralizzate nel tentativo di decifrare tutte le tecnologie che vengono loro proposte ogni giorno. In questo viaggio, come in qualunque altro, è importante avere una mappa. In questo episodio, Darren spiega il Modello di Maturità dell'Infrastruttura per aiutare le organizzazioni a capire dove si trovano nella loro trasformazione digitale, dove possono andare successivamente e come arrivarci."},{"id":122,"type":"Episode","title":"Comprendere il burnout dei dipendenti.","tags":["employeeburnout","remotelearning","remoteworker","people","process","compute"],"body":"\r\n\r\nL'esperienza professionale di Uzair è iniziata nel settore delle vendite, nell'esperienza del consumatore nel punto vendita e si è evoluta nello sviluppo di prodotti. Per dieci anni, ha lavorato su un'app sveglia che funzionava in modi personalizzati diversi per aiutare le persone a svegliarsi motivate e concentrate. Nonostante quel progetto alla fine sia fallito, Uzair ha imparato molto sulla motivazione umana. Alcuni anni fa, mentre lavorava con studenti delle scuole medie e superiori, ha notato una grande mancanza di motivazione e concentrazione nel primo periodo della giornata, che sembrava peggiorare progressivamente. Grazie alla sua esperienza professionale e alla sua crescita personale nel benessere, ha visto un'opportunità di avere un impatto creando l'app District Zero.\n\n## Benessere degli studenti K-12\n\nLa missione di District Zero è dotare gli studenti delle scuole K-12 delle competenze di apprendimento integrali. Ciò significa aiutare gli studenti a gestire le emozioni difficili per recuperare la loro concentrazione e motivazione.\n\nL'app utilizza la tecnologia Agile e il potere dell'analisi dei sentimenti del processo di elaborazione del linguaggio naturale per lavorare a scala e individuare trigger e ansia tramite un sondaggio. Una volta che uno studente completa il sondaggio, l'app può suggerire contenuti e risorse come video o giochi per aiutare con problemi specifici. Dispone anche di un sistema di reportistica per insegnanti e amministratori.\n\nAttualmente, insegnanti e amministratori si prendono un carico pesante cercando di aiutare i loro studenti con il benessere, specialmente nell'ambiente COVID. Potrebbero avere un modulo Google collegato a Google Sheets e poi usare il controllo F per cercare parole negative e frasi chiave. L'app riduce questo carico e evita il sottoprodotto della negatività degli insegnanti e degli amministratori. Il sistema scopre gli ostacoli e i punti critici degli studenti e li aiuta a risolverli attraverso rimedi rapidi e risorse. Se gli studenti hanno bisogno di un maggior supporto, il sistema li indirizza alla persona corretta, come un consulente, e tiene informato l'insegnante.\n\nTradizionalmente, quando uno studente mostra ansia o frustrazione, ad esempio, vengono portati direttamente da uno psicologo o assistente sociale quando il problema diventa ingestibile. Ma lo studente non ha bisogno di passare da zero a cento; c'è un punto intermedio in cui il problema può essere affrontato prima che si arrivi alla lotta o alla fuga. L'app può aiutare a evitare che un problema si acuisca e ad anticipare le questioni prima che sia troppo tardi.\n\nIl pilota dell'app nelle scuole dell'area di Chicago è avvenuto lo scorso agosto durante il COVID, quindi è stato particolarmente adatto ad aiutare gli studenti che avevano perso quel contatto faccia a faccia con i loro insegnanti e che avevano difficoltà nel socializzare e nell'apprendimento emotivo. Un elemento chiave per il successo nell'apprendimento sociale ed emotivo è che tutti nella comunità devono essere coinvolti ed empatici: insegnanti, amministratori, sovrintendenti, genitori e contribuenti; l'empatia e le connessioni non possono accadere solo a scuola.\n\n## Sovraccarico di lavoro dei dipendenti\n\nDurante il COVID, i lavoratori hanno mostrato un aumento della produttività, ma ora c'è il rischio di esaurimento dei dipendenti. Che si tratti dello stress del lavorare nel settore sanitario o come lavoratore remoto che manca di equilibrio tra lavoro e casa, una moltitudine di problemi rende questa una questione prioritaria per le aziende. I principi dell'app District Zero K-12 possono essere applicati ai lavoratori per aiutare a alleviare l'esaurimento.\n\nIl Distretto Zero ha iniziato a sperimentare con l'applicazione nel proprio luogo di lavoro, il che ha portato a delle difficili conversazioni sulle priorità e sulla comprensione dei bisogni reali dei dipendenti. Simile all'applicazione per l'istruzione primaria e secondaria, il sistema può identificare le sfide quotidiane dei dipendenti e colmare il vuoto fornendo supporto prima che i problemi si aggravino.\n\nDistrict Zero spera di far crescere la propria tecnologia per essere utile a molti settori diversi: aziende, assistenza sanitaria aziendale e persino agenzie governative, per un uso in ambiti come la prevenzione del suicidio tra i veterani degli affari degli ex combattenti.\n\nQuesta nuova tecnologia e comprensione nel supporto al benessere degli studenti e dipendenti arriva nel momento giusto, poiché lo stress e l'esaurimento causati dal COVID sono aumentati e iniziamo una nuova fase di riapertura e adattamento.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Uzair Hussain"],"link":"/episode-EDT50-it","image":"./episodes/edt-50/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, parla con Uzair Hussain, CEO di District Zero, riguardo a come l'applicazione dell'azienda che supporta il benessere mentale degli studenti delle scuole elementari e medie possa essere applicata nella prevenzione del burnout dei dipendenti."},{"id":123,"type":"Episode","title":"Casi d'uso pratici per l'utilizzo della memoria persistente Optane","tags":["dataarchitecture","memverge","pmem","optane","technology","data"],"body":"\r\n\r\nMemVerge ha spedito la prima versione del loro software nel settembre 2020 e, nonostante la pandemia, che ha rallentato l'educazione dei clienti sulla nuova tecnologia, è emerso un buon modello di casi d'uso.\n\n## Riduzione dei costi per i fornitori di servizi cloud.\n\nLa metrica chiave per un operatore di servizi cloud è quante macchine virtuali riescono a fornire ai propri clienti e a quale costo. La dimensione della memoria sui server diventa il punto di restrizione su quante macchine virtuali possono allocare per server, limitando quanto basso possa scendere il loro costo per macchina virtuale.\n\nIl software MemVerge con Optane fornisce una quantità maggiore di memoria per server, allocando un numero maggiore di VM, riducendo così il costo per VM e aumentando la competitività dei fornitori di servizi cloud. Il costo per VM potrebbe essere tre volte più economico.\n\n## Affidabilità con grandi basi di dati di memoria.\n\nI clienti finanziari come le borse, le banche e i fondi comuni utilizzano molti database in memoria e applicazioni in-memory. Oltre ad aumentare la memoria in modo da poter avere più istanze per server, MemVerge risolve anche i problemi di disponibilità dei database in memoria. Se i dati non vengono continuamente salvati su storage, ma rimangono solo in memoria, tutti i dati intraday vengono persi in caso di crash. Questo è catastrofico. Anche se hai registrato tutte le transazioni, devi riprodurre il log per recuperare il database, il che richiede molti minuti o addirittura ore per il recupero.\n\nMemVerge offre un nuovo servizio dati che dispone di snapshot in memoria. Persiste lo stato del database su Optane, che è molto più veloce rispetto alla persistenza su supporto di memorizzazione. In caso di un crash, avrai l'ultima immagine istantanea catturata sulla memoria persistente e potrai recuperare da quella. Il ripristino richiede solo uno o due minuti, quindi si tratta di un miglioramento del 60 al 100 volte.\n\n## Riduzione del sequenziamento genomico attraverso istantanee di memoria\n\nNell'ambito della genomica, il software MemVerge in combinazione con Optane aumenta la produttività in modo esponenziale. In un flusso di lavoro multistadio di analisi dei dati, una memoria più ampia significa una maggiore parallelismo del processo e del pipeline, rendendo l'intero processo più veloce. In questo caso, lo snapshot è anche molto utile. Se un'organizzazione sta svolgendo, ad esempio, ricerche sul cancro o sul COVID, e ha bisogno di effettuare sequenze di DNA o RNA, è necessario passare attraverso circa 50 fasi di elaborazione. Ogni fase potrebbe richiedere ore e devono prendere un checkpoint dello stato dei risultati intermedi della computazione per diverse ragioni: prima, ripetere o riprodurre i risultati e, seconda, confrontare i risultati se vengono modificati alcuni dati. I checkpoint vengono salvati nello storage e questo richiede da cinque a 30 minuti. In molti casi, questo può richiedere più tempo rispetto al calcolo effettivo. Quindi, se un lavoro richiede 24 ore, potrebbero impiegare otto ore per il calcolo e 16 ore solo per eseguire questi processi di IO salvando gli stati intermedi.\n\nInvece di eseguire IO, MemVerge utilizza un'istantanea dopo ogni fase e la registra nella memoria persistente Optane. Invece di 16 ore di IO, questo processo può richiedere un minuto. È il nuovo modo di fare IO; non è necessario eseguire la serializzazione o la deserializzazione per aprire un file, leggere, scrivere, ecc. Tutto ciò che devi fare è fare un'istantanea.\n\nAnche se ciò richiede molta memoria, con MemVerge la memoria è più ampia rispetto a prima e continuerà a migliorare man mano che Intel innova. Due altre funzionalità aiutano con questo problema. In primo luogo, vengono effettuati snapshot periodicamente senza creare copie complete dello stato della memoria; sono solo le pagine di modifiche, quindi l'uso aggiuntivo di memoria viene minimizzato. In secondo luogo, MemVerge può conservare fino a 256 livelli di snapshot in memoria, ma allo stesso tempo puoi esportare questi snapshot dalla memoria a server di archiviazione o ai tuoi sistemi di archiviazione. Ciò avviene senza interrompere o influire sull'applicazione in esecuzione.\n\nFondamentalmente, stai creando un DVR di memoria perché invece di eseguire solo la tua applicazione in avanti, puoi anche eseguirla all'indietro quasi istantaneamente. È una nuova esperienza.\n\nLa genomica è solo il primo esempio di molti carichi di lavoro che potrebbero trarre vantaggio da questa tecnologia.\n\nPoiché MemVerge è una startup, si sta concentrando strettamente su tre settori: fornitori di servizi cloud, applicazioni finanziarie con memoria di grandi dimensioni, genomica e lavori correlati di data science pipeline, ma tutti questi casi d'uso dimostrano il potere della combinazione di memoria persistente Optane e software MemVerge.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT51-it","image":"./episodes/edt-51/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, parla con Charles Fan, CEO di MemVerge, dei casi di utilizzo del loro software che sfrutta in modo innovativo la memoria persistente Optane di Intel, rimuovendo il collo di bottiglia tra memoria e storage."},{"id":124,"type":"Episode","title":"Telemetria nel Cloud","tags":["multicloud","optimization","workloadplacement"],"body":"\r\n\r\n## Benefici degli architetti delle soluzioni cloud (CSAs)\n\nIl ruolo di CSA è molto richiesto nell'industria al momento, e Intel ha assunto un team di CSA per offrire valore ai loro clienti. I CSA possono aiutare i clienti ad evitare la mentalità del \"lift and shift\" che porta a costi eccessivamente alti. Questi nuovi CSA portano una prospettiva esterna e si collegano alla più grande comunità di CSA per risolvere problemi.\n\n## Fasi della telemetria\n\nLa telemetria nel cloud non dovrebbe essere relegata al tuo fornitore di servizi cloud. Ad esempio, Amazon Web Services (AWS) ha avuto un'importante interruzione sulla costa orientale lo scorso novembre, e i loro strumenti non stavano segnalando, quindi molti clienti non avevano idea che fossero inattivi. Le organizzazioni hanno bisogno della propria telemetria per il monitoraggio.\n\nLa prima fase è la mancanza di monitoraggio nel cloud. La seconda fase è l'esposizione del telecontrollo in cui si comprende quello che si sta ottenendo, ad esempio CPU, memoria e rete, ma è a livello superficiale. La fase successiva è il monitoraggio e l'azione, in cui si ricevono notifiche sugli rallentamenti, i tassi di transazione, i tempi di risposta eccetera. La fase successiva è ancora più a fondo nel sistema in cui il moderno cloud intelligente controlla e prevede per la soluzione di eventuali problemi. Infine c'è l'automazione completa. Questo è dove le cose operano da sole, ascoltando, rispondendo e informando successivamente.\n\nUn esempio di automazione completa sarebbe un centro dati che controlla un sistema HVAC, rilevando e riducendo o aumentando la temperatura in diverse parti di un edificio. Per i carichi di lavoro, un cloud intelligente può spostare i carichi di lavoro in modo da massimizzare il valore in capacità e prestazioni.\n\n## Approcci attuali e limitazioni attuali.\n\nMolte volte, tuttavia, i clienti dei fornitori di servizi cloud relegano l'automazione al livello infrastrutturale e dimenticano il livello del carico di lavoro. I clienti hanno bisogno di informazioni oltre ai soli dati essenziali; hanno bisogno di telemetria approfondita e ricca per sapere cosa sta realmente accadendo. È un errore fare affidamento sul fornitore di servizi cloud per avere i tuoi migliori interessi a cuore riguardo alla telemetria, e questo può manifestarsi in costi elevati.\n\nAlcuni fornitori di servizi cloud si stanno aprendo di più. Attualmente AWS sta rivoluzionando il settore con la telemetria che forniscono. Speriamo che anche gli altri prendano esempio.\n\n## Raccogliamo le Telemetrie Corrette...\n\nScegliere le istanze corrette è importante. Non tutti i core sono uguali; diversi core vengono utilizzati per scopi diversi ed è importante capire quali sono per ottenere le migliori prestazioni e il miglior prezzo.\n\nChe tipo di informazioni puoi raccogliere? Il design del prodotto di Intel include unità di monitoraggio delle prestazioni (PMU). Queste sono contatori a livello inferiore e forniscono informazioni su transazioni, ritardi, latenza e punti critici. Ci sono tre diverse categorie di PMU: core, off core e uncore. Questi PMU raccolgono informazioni su CPI, utilizzo, frequenza e TMAM. Tutti questi dati sono accessibili tramite AWS.\n\nUtilizzando metriche e telemetria reale, è uno strumento che ti aiuta ad ottimizzare i tuoi carichi di lavoro. Potresti confrontare come il tuo carico di lavoro si sta svolgendo nel tuo centro dati, ad esempio, con AWS in queste istanze, e utilizzare le metriche per scoprire su quale piattaforma i carichi di lavoro dovrebbero atterrare.\n\n## Rilevanza nell'IT\n\nStratificare la telemetria con il benchmarking è una soluzione definitiva. Con il benchmarking, puoi conoscere il tuo output, e con la telemetria, puoi esaminare il CPI, l'utilizzo e la frequenza, e hai il quadro completo di ciò che sta accadendo. Vuoi fare lo stesso nel cloud, invece di semplicemente caricare i carichi di lavoro su un'istanza apparentemente più economica.\n\nI professionisti dell'IT non dovrebbero temere di perdere il loro lavoro perché le cose si stanno spostando verso il cloud. Invece, dovrebbero trasferire le loro competenze per imparare a utilizzare il rilevamento dei parametri di riferimento anziché avere una mentalità di spostamento semplice e diretto. Diventare competenti nell'utilizzo del cloud implica anche l'uso delle funzionalità native del cloud come Kubernetes e i contenitori. Anche il rilevamento dei parametri di riferimento funziona in queste aree. Con l'advisor C di Intel, è possibile ottenere dati ricchi di telemetria come i dati relativi al core e all'esterno del core dai propri contenitori.\n\nAnche se può sembrare un po' intimidatorio quando si considera tutto ciò che è possibile nel cloud, iniziare con piccoli passi è la scelta migliore. Guarda le applicazioni più adatte in base al rischio. Cataloga le tue app, valuta la suddivisione delle applicazioni per livelli e inizia a spostarle nel cloud in porzioni di dimensioni importanti, raggruppando funzioni e app simili. Mentre esplori nuovi servizi e impari nuove applicazioni, prendi in considerazione l'architettura che sta dietro di esse e poni le domande giuste in modo da diventare un architetto tecnico più informato.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT52-it","image":"./episodes/edt-52/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, parla con Josh Hilliker, Direttore degli Architetti di Soluzioni Cloud presso Intel, sull'utilizzo della telemetria nel cloud per massimizzare valore ed efficienza."},{"id":125,"type":"Episode","title":"DevOps con velocità riducendo il rischio","tags":["devops","compute","technology","process","devsecops","cybersecurity","multicloud"],"body":"\r\n\r\nLe tre aree chiave da equilibrare nella consegna del software sono la velocità, il rischio e la qualità. La maggior parte può gestire una o due di queste cose, ma aggiungere la terza può diventare difficile. Ad esempio, potresti essere in grado di consegnare a una buona velocità perché hai un ottimo sistema di integrazione continua, ma una volta introdotte le verifiche di conformità e di policy, ti trovi di fronte a una sfida. Devi interrompere e controllare queste cose, oppure forse importare alcuni risultati da un altro strumento? Improvvisamente, la tua velocità ne risente.\n\nOpsMx sta lavorando per aiutare le persone a automatizzare quei punti decisionali. L'automazione è la cosa più importante per mantenere l'accelerazione mentre si aumentano gli altri due pilastri, il rischio e la qualità.\n\n## Soluzione OpsMx: consegna software completamente automatizzata\n\nLa automazione funziona come aggregazione dati, raccogliendo risultati dalle varie strumenti della catena degli strumenti e poi disponendo di un meccanismo come un gestore di politiche che fornisce risultati attesi sui segni di spunta degli strumenti come BlackDuck. Se sembra corretto, il flusso di lavoro non si interrompe, come avviene attualmente, per un controllo umano.\n\n## La consegna più veloce delle applicazioni aumenta i tassi di fallimento.\n\nLa velocità di consegna delle applicazioni è passata da settimanale o mensile a ogni ora, aggiungendo pressione per produrre rapidamente. Quando si cerca di aumentare la velocità, tuttavia, si potrebbe iniziare a perdere un po' del controllo sulla qualità, magari saltando alcuni controlli di rischio. Il risultato netto è che più si cerca di muoversi velocemente, più si è inclini a commettere errori.\n\n## Punti di attrito e spazi problematici\n\nCon un uso strategico dell'automazione, hai la possibilità di aumentare la velocità senza correre rischi. La verifica continua può ridurre un'attività di tre o quattro ore a cinque o dieci secondi. Invece di utilizzare mano d'opera umana per analizzare i registri alla ricerca di comportamenti anomali che potrebbero essersi verificati dopo un controllo binario di passaggio/fallimento, la verifica continua può farlo automaticamente, permettendo alle persone di occuparsi solo dei casi eccezionali.\n\n## Cosa significa automazione in questo contesto?\n\nIl prossimo pezzo utilizza gli strumenti richiesti dal team di sicurezza e conformità, come BlackDuck. Con l'automazione, non è necessario interrompere il flusso di lavoro per far interpretare i risultati a qualcuno prima di continuare, perché ciò avverrà automaticamente.\n\nGli altri pezzi sono regole ad un livello superiore se sei in un settore regolamentato con più controlli, o qualcosa di semplice come un rivenditore che, ad esempio, non vuole rilasciare nuovi software due settimane prima di Natale. Questi controlli possono essere automatizzati per eliminare la necessità di approvazione umana, permettendo al flusso del processo di continuare se non ci sono eccezioni. L'idea è quella di rimuovere il maggior numero possibile di ostacoli umani per consentire al processo di continuare ininterrottamente.\n\nIl set principale di automazioni di controllo e politiche è riutilizzabile tra i flussi di lavoro; è necessario solo personalizzare o crearne uno per i criteri specifici del tuo ciclo di rilascio.\n\n## Soluzione OpsMx: Consegna software completamente automatizzata.\n\nOpsMx ti dà la possibilità di creare quelle pipeline e le automazioni di analisi dei registri. Spinnaker è lo strumento attuale, ma la visione di OpsMx è essere il più possibile agnostico rispetto a cd, consentendo l'uso di tutti gli strumenti cd come Jenkins e Microsoft Azure. OpsMx sfrutta la parte di cd per l'automazione, ma si posiziona sopra di essa per aiutare a prendere decisioni automatizzate.\n\nUna parte sempre più importante dello strumento è l'apprendimento automatico per aiutare a comprendere qual è il valore di base per una determinata applicazione rispetto a un comportamento anomalo. Vi è inoltre un modello di apprendimento supervisionato in cui un professionista DevOps, un ingegnere o un responsabile del prodotto può specificare il comportamento anomalo come atteso nel contesto dell'applicazione.\n\nIl sistema consente anche l'auditabilità. Ogni modifica o eccezione viene documentata. Esiste un tracciato di audit completo di tutto ciò che accade, dall'autorizzazione di un'eccezione all'implementazione di un artefatto e all'uso di un'immagine di base. Sia che venga eseguito nel cloud che in loco, è possibile visualizzare l'intero flusso di lavoro come un'entità unica.\n\nUn altro aspetto della visibilità fornita da OpsMx è una sorta di mappa di ciò che viene implementato e dove, come ad esempio la serie di microservizi che attualmente si trovano nel QA, ciò che è in determinate fasi o ciò che è in produzione, per poi, per ognuno di questi elementi, poter approfondire e ottenere una visione storica. È possibile fare clic su qualsiasi versione specifica e tutte le informazioni di audit sono immediate a portata di mano.\n\nInoltre, la prossima frontiera su cui OpsMx sta lavorando è l'efficacia degli artefatti che vengono acquisiti, in modo che la catena di approvvigionamento, o lineage, sia trasparente.\n\nOpsMx sta ora utilizzando una tecnologia basata su agenti che può interagire, ad esempio, con risorse che si trovano dietro il tuo firewall. L'agente agisce come un proxy per il livello di intelligenza in modo che i dati possano essere raccolti lì. Non ci sono preoccupazioni per l'apertura o l'esposizione delle porte del firewall. Funziona allo stesso modo con i fornitori di cloud: l'agente può essere distribuito all'interno della VPC e non è più necessario rischiare di inserire chiavi e segreti in un'applicazione basata su cloud. L'agente agisce semplicemente come un proxy in modo che il pezzo autorizzato rimanga sempre all'interno della VPC, garantendo la sicurezza del modo in cui vengono raccolte le informazioni.\n\nCon questa nuova direzione, l'intera industria DevOps sarà coinvolta in un rimescolamento in termini di sicurezza e auditabilità.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT53-it","image":"./episodes/edt-53/it/thumbnail.png","lang":"it","summary":"In questo episodio, Robert Boule, responsabile della Solution Engineering presso OpsMx, si unisce a Darren per parlare del miglioramento della velocità senza aumentare il rischio nel processo di DevOps. Le tre aree chiave da bilanciare nella consegna del software sono la velocità, il rischio e la qualità. La maggior parte può gestire una o due di queste cose, ma l'aggiunta della terza può diventare difficile. Ad esempio, potresti essere in grado di consegnare a velocità perché hai un ottimo sistema di continua distribuzione, ma una volta che introduci controlli di conformità e di politica, ti trovi di fronte a una sfida. Ti fermi e controlli queste cose, o forse acquisisci alcuni risultati da un altro strumento? Improvvisamente, la tua velocità ne risente."},{"id":126,"type":"Episode","title":"Persone e Processi nella Trasformazione Digitale","tags":["multicloud","organizationalchange","change","people","hsbc","cio"],"body":"\r\n\r\nAnn ha iniziato la sua carriera come programmatrice, è passata alla gestione dei programmi e ha esperienza nella fusione e vendita di aziende. È stata Responsabile Mondiale dei Dati presso HSBC e è diventata Chief Information Officer nel settembre 2016. Ha portato avanti importanti programmi di trasformazione organizzativa durante la sua carriera, tra cui nuovi sistemi ipotecari e nuovi sistemi bancari centrali.\n\nAlcune delle sfide di queste trasformazioni consistevano nel porre le giuste domande durante le valutazioni. In un programma di trasformazione ipotecaria, ha prima posto domande riguardanti le finanze: Siamo oltre il budget? Siamo in linea con il piano? Abbiamo bisogno di richiedere ulteriori finanziamenti? Per il team di leadership, ha chiesto se le persone giuste fossero al loro posto con le capacità adatte per portare a termine i cambiamenti. Ha anche approfondito l'immagine generale: Cosa crede l'azienda? Quali sono gli obiettivi aziendali? Capiscono chiaramente perché il programma di trasformazione è necessario e cosa stiamo cercando di realizzare? Ha anche esaminato lo stato del programma attraverso metriche e KPI.\n\nPer quella trasformazione, avevano già un programma stabilito e iniziato, ma Ann è arrivata come una sorta di consulente interno per l'attività. Il programma era guidato dal business, ma era necessario sfruttare la tecnologia per raggiungere quegli obiettivi e obiettivi aziendali. La tecnologia e gli obiettivi dovevano essere completamente allineati.\n\nNell'ultima trasformazione, Ann ha assunto la carica di direttore del programma per entrambi i settori aziendale e tecnologico, quando il programma era già a tre anni su cinque. Quattro CIO le riportavano, ciascuno assegnato a un settore del business: commercio al dettaglio, commerciale, patrimoniale e banche d'investimento. Ann li metteva in contatto con i loro partner di business e organizzava riunioni in cui discutere insieme per assicurarsi che rimanessero allineati, dato che stavano cercando di raggiungere lo stesso obiettivo.\n\nAnche se sembrerebbe che questo tipo di partnership sia una pratica commerciale regolare, Ann ha trovato una delle sue sfide più grandi come CIO nel conseguire l'allineamento dell'azienda. Per qualcosa di così grande e complesso come cambiare un sistema bancario centrale, una nuova app mobile o una nuova interfaccia web, ad esempio, Ann teneva riunioni più volte al giorno con i giocatori chiave perché c'erano probabilmente 15 flussi di lavoro diversi e l'integrazione era l'aspetto chiave.\n\nEntrare dall'esterno e apportare modifiche organizzative è una posizione difficoltosa. Le persone sono nervose riguardo al cambiamento, specialmente quando avevano fiducia nel loro precedente leader. Col passare del tempo, però, Ann ha constatato che le persone si sono unite perché sapevano che l'obiettivo era migliorare l'azienda, e si sono impegnate nel percorso. Un modo in cui Ann ha realizzato ciò è stato sedersi per terra con i diversi team anziché in ufficio. Ha conosciuto le persone ed è diventato normale per loro averla intorno e poter avere conversazioni e sollevare problematiche. Ha ottenuto informazioni dirette dalle persone che svolgevano il lavoro anziché informazioni filtrate attraverso la gestione.\n\nUna cosa che i leader spesso dimenticano è che le persone all'interno dei team vogliono avere successo e un tocco personale come lavorare fianco a fianco con loro fa molta differenza.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ann Madea"],"link":"/episode-EDT54-it","image":"./episodes/edt-54/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, chiede al suo ospite, Ann Madea, ex CIO di HSBC, di riflettere sul processo di grandi cambiamenti trasformazionali che ha guidato nelle organizzazioni."},{"id":127,"type":"Episode","title":"Comunicazione durante la trasformazione","tags":["communication","organizationalchange","people","process","hsbc","cio"],"body":"\r\n\r\nQuando i CIO implementano soluzioni, coinvolgono nuovi processi e molto probabilmente un cambiamento organizzativo. Nel programma di trasformazione più recente di Ann, hanno fatto progressi con il cloud. Ann ha assunto un responsabile del cloud e ha implementato una strategia multi-cloud con Google, AWS e Azure. Questo cambiamento importante ha suscitato preoccupazione, specialmente tra coloro che lavoravano nell'infrastruttura da molto tempo.\n\nPer alleviare l'ansia e aumentare l'interesse, Ann ha fortemente incoraggiato le persone a iniziare a ottenere certificazioni per il cloud, Google, AWS, ecc. Ha portato il suo team in viaggio per avere incontri con Google a New York, dove hanno potuto vedere l'energia, l'atmosfera e la collaborazione che si respirava lì. Man mano che le persone iniziarono ad ottenere le certificazioni, cresceva l'entusiasmo per la formazione e la trasformazione.\n\nIl nuovo responsabile del cloud aveva giornate di \"Google Days\" in cui le persone venivano e presentavano i casi d'uso e come stavano utilizzando i diversi prodotti. Facevano lo stesso con Amazon e Azure. Questo aiutava i dipendenti a comprendere l'ampiezza di ciò che potevano fare, generava entusiasmo e favoriva la partecipazione.\n\nLa chiave di Ann per la comunicazione del CIO in mezzo a una trasformazione è \"fidati ma verifica\". A tre o quattro mesi dalla trasformazione, ad Ann venne detto di concentrarsi sulle valutazioni in aree come i budget, le squadre di revisione e il ristabilire le relazioni con la direzione e i regolatori. Tuttavia, ha deciso di approfondire ulteriormente e ha scoperto che non c'era realmente un piano che mostrasse come il programma avrebbe fornito i risultati. Ciò ha dato inizio a una rivalutazione del team di leadership per far progredire il programma.\n\nUn CIO che sta attuando una trasformazione deve essere disposto a sporcare le mani. Fidati ma verifica tutto tramite interviste multiple e flussi di informazioni; una o due fonti non sono sufficienti. Successivamente, Ann ritiene necessario iniziare a comunicare con trasparenza riguardo ai problemi al fine di ottenere il sostegno dalle persone che sono in grado di fornirlo.\n\nUn vantaggio della trasparenza è che le persone che ti forniscono informazioni, come i programmatori, fidano che tu non userai le informazioni contro di loro. Il team di Ann sa di non sorprenderla e lei, a sua volta, non sorprende i suoi superiori. Ad esempio, se c'è un problema nel centro dati, lei informerà loro di ciò che sa e li aggiornerà man mano che apprende di più.\n\nI dipendenti desiderano sapere come si inseriscono nel successo del programma, non solo che devono programmare questi cinque programmi. Un modo in cui Ann ha raggiunto questo obiettivo è stato attraverso l'organizzazione di molte assemblee. Inoltre, lei si aggirava per i reparti e teneva un incontro informale settimanale di aggiornamento della durata di 30 minuti, durante il quale le persone potevano porre domande. Ogni volta che Ann teneva una grande riunione in cui venivano prese decisioni, riuniva l'intero team, sia del settore aziendale che tecnologico, e spiegava le decisioni e l'impatto. Se le persone sanno che c'è stata una grande riunione ma vengono tenute all'oscuro, inizia a girare la voce.\n\nCon il lavoro da casa attuale, Ann afferma che è importante anche fare brevi controlli con le singole persone. I controlli continui portano a relazioni migliori e riducono l'ansia di parlare con i superiori. I capi devono capire cosa motiva le squadre e di cosa le persone sono preoccupate. Hanno famiglie da mantenere, figli al college o forse familiari con problemi di salute.\n\nNaturalmente non tutto può essere discusso con tutti, come ad esempio riduzioni di personale o promozioni, ma Ann ama convocare incontri con i supervisori chiamati \"incontri con le persone\" in cui possono affrontare queste questioni delicate. Gli incontri possono anche aiutare i leader a capire il loro personale e ciò che cercano di fare. È importante ascoltare le persone che si trovano in posizione inferiore rispetto ai leader, poiché sono più attenti agli accadimenti quotidiani.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ann Madea"],"link":"/episode-EDT55-it","image":"./episodes/edt-55/it/thumbnail.png","lang":"it","summary":"In questo episodio, parte due di due, Darren e l'ospite Ann Madea, ex CIO di HSBC, parlano della comunicazione durante la trasformazione organizzativa. Quando i CIO implementano soluzioni, coinvolgono nuovi processi e molto probabilmente anche cambiamenti organizzativi. Nel programma di trasformazione più recente di Ann, hanno adottato l'approccio del cloud. Ann ha assunto un responsabile del cloud e ha implementato una strategia multi-cloud con Google, AWS e Azure. Questo cambiamento importante ha suscitato preoccupazione, soprattutto tra coloro che avevano lavorato con l'infrastruttura per molto tempo."},{"id":128,"type":"Episode","title":"Organizzazioni di Broker Cloud","tags":["cloudbroker","cloud","compute","technology","people","process","multicloud","organizationalchange"],"body":"\r\n\r\nDave e Kevin hanno fondato il team di intermediazione cloud di Intel circa sette anni fa. I dipendenti di Intel stavano consumando il cloud pubblico ed era come il selvaggio West, con le persone che semplicemente utilizzavano le loro carte di credito per l'accesso. La sicurezza era un problema e le spese erano fuori controllo. Per riportare l'ordine nel caos, hanno creato un'organizzazione di intermediazione cloud.\n\nUn approccio centralizzato era necessario per controllare i costi, organizzare e creare contratti aziendali con fornitori e configurare la fatturazione attraverso un'organizzazione unificata. Invece di utilizzare singole carte di credito o creare propri ordini di acquisto, i gruppi commerciali di Intel utilizzano un ordine di acquisto principale tramite IT, che poi viene addebitato ai diversi gruppi. Complessivamente, ciò consente di risparmiare denaro poiché ora Intel dispone di un potere d'acquisto collettivo, che include opportunità di risparmio sui costi più avanzate, come l'acquisto di capacità riservata anziché pagare i prezzi on-demand.\n\nCi è voluto un po' di tempo per coinvolgere tutti nell'organizzazione, con alcuni ancora utilizzando le loro carte di credito per aprire gli account. Per cercare di mitigare questa situazione, alcuni fornitori di servizi cloud hanno fornito a Intel un rapporto sugli account aperti con indirizzi email Intel. Piuttosto che considerare queste \"scappatoie\" solo come violazioni della politica, è stata un'opportunità per informare ed educare queste persone sui vantaggi dell'utilizzo dell'account centrale Intel: standard di sicurezza già in vigore, supporto aziendale, formazione ed efficienza dei costi.\n\nInoltre, oltre a questi benefici, Intel ha anche creato un Centro di Eccellenza Cloud, un forum basato sulla comunità a cui chiedono alle persone di unirsi una volta ottenuto il proprio account cloud. La sua crescita è stata spontanea, fornendo informazioni e feedback ai membri.\n\nMolti sviluppatori e altre persone che utilizzano il cloud vogliono solo utilizzarlo senza dover pensare alla sicurezza o al costo, ad esempio. Avere il team di mediazione del cloud consente loro di farlo. Un'analogia è che l'IT mette lo sviluppatore in un'evasione con tutti i giocattoli, ma non permette loro di tirare la sabbia fuori dall'evasione o giocare con i giocattoli fuori dall'evasione. Ciò fornisce alla comunità degli sviluppatori account e accesso sicuri e protetti ogni volta che ne hanno bisogno.\n\nCi sono centinaia di servizi disponibili su diverse fornitori di cloud pubblico e continuano a rilasciare nuovi servizi e funzionalità. È difficile per i gruppi aziendali avere o mantenere competenze su tutti quei servizi. Un team centrale di broker cloud focalizzato sul cloud pubblico e sempre aggiornato sui ultimi servizi può offrire orientamento e conoscenza su dove allocare differenti carichi di lavoro. La chiave per il servizio di brokeraggio è che le persone si rivolgono a un imbuto centrale e vengono reindirizzate ai servizi corretti.\n\nNon è solo utile avere un team dedicato di consulenti per il cloud, ma anche persone all'interno del team che si concentrano su specifici provider di cloud. Ad esempio, presso Intel, quando hanno raggiunto una massa critica e i fornitori di cloud si sono sviluppati offrendo una grande quantità di servizi, Kevin si è concentrato su AWS e Dave su Azure per approfondirne ogni aspetto.\n\nUtilizzare più offerte di cloud anziché solo una è stata una decisione naturale poiché i gruppi aziendali arrivavano con preferenze e diversi carichi di lavoro hanno performance migliori con fornitori diversi. Le differenze tra i fornitori erano più evidenti in passato. Ora, c'è un equilibrio maggiormente uniforme.\n\nUn cloud broker non è solo qualcuno in una posizione tecnica, ma un asso in tutto. Dave e Kevin sono diventati esperti su tutto ciò che riguarda il cloud, come sicurezza e networking, ed hanno formato queste squadre mentre estendevano la loro portata da on-premise al cloud pubblico. Avendo un team cloud centrale, le altre organizzazioni di Intel sono state in grado di formarsi, espandersi e crescere. Il team è stato soprannominato \"The Glue\" a causa del loro ruolo centrale e variegato.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Kevin Bleckmann","Dave Shrestha"],"link":"/episode-EDT56-it","image":"./episodes/edt-56/it/thumbnail.png","lang":"it","summary":"In questo episodio, parte uno di due, Darren e gli architetti delle soluzioni cloud di Intel, Dave Shrestha e Kevin Bleckman, parlano dell'importanza di un'organizzazione di broker cloud. Dave e Kevin hanno fondato il team di brokeraggio cloud di Intel circa sette anni fa. I dipendenti di Intel stavano utilizzando il cloud pubblico ed era come il selvaggio West, con le persone che semplicemente utilizzavano le loro carte di credito per accedere. La sicurezza era un problema e le spese sono sfuggite al controllo. Per mettere a freno il caos, hanno creato un'organizzazione di broker cloud."},{"id":129,"type":"Episode","title":"Organizzazione Cloud Broker Parte 2","tags":["cloudbroker","change","people","process","compute","organizationalchange","multicloud"],"body":"\r\n\r\n# Considerazioni sulla selezione del cloud\n\nSette anni fa, quando Dave e Kevin hanno avviato per la prima volta il team di intermediari cloud di Intel, c'erano significative differenze tra i fornitori di servizi cloud, come la disponibilità regionale, ma ora, grazie alla maturità, le differenze sono minori. Alcuni fornitori si specializzano in determinate aree come l'IA e l'apprendimento automatico o servizi di database gestiti avanzati, e ci sono fattori di costo, ma sono più simili che diversi. In generale, i fornitori cloud stanno diventando sempre più una utility man mano che maturano.\n\nLa sicurezza è buona e abbastanza standard tra i fornitori di servizi cloud. In passato, Intel utilizzava prodotti di fornitori esterni per gestire la sicurezza con i servizi cloud. I fornitori di servizi cloud hanno ora integrato gran parte di questi componenti nelle loro piattaforme e Intel ha iniziato a utilizzare componenti integrati in maggior misura. Ci sono ancora molte cose da fare in questo settore. In alcuni casi, sarà ancora necessario gestire la propria sicurezza, ma i fornitori stanno andando nella giusta direzione. Utilizzare gli strumenti integrati non è l'opzione più semplice per le nuove aziende perché non è completamente gestita, ma una volta acquisite le competenze e la maturità, almeno gli strumenti sono forniti.\n\nLa gestione dei costi è ancora un'arte; molte persone sono sorprese dalla loro prima fattura del cloud. Nonostante ci siano strumenti integrati che aiutano, consulenti e calcolatori del cloud pubblico, ci sono alcuni costi nascosti. I costi di ingresso e uscita sono probabilmente la sorpresa numero uno, seguiti dalla sovradimensionamento delle risorse. Intel ha un ottimizzatore del cloud che è alimentato da Densify e aiuta a identificare le risorse sovradimensionate e consiglia, attraverso un'analisi dettagliata, le dimensioni delle istanze e le famiglie più ottimali.\n\nAlcuni carichi di lavoro dovrebbero rimanere in loco, specialmente per grandi aziende come Intel che hanno un grande data center in loco. Il team dell'intermediario cloud dispone di un'attrezzatura interna chiamata strumento per l'assunzione di decisioni che può aiutare a collocare il carico di lavoro giusto nel posto giusto, e talvolta la soluzione migliore è quella in loco.\n\nConsiderazione sul carico di lavoro per la posizione del cloud pubblico\n\nSenza uno strumento per prendere la decisione, ci sono cinque aree da considerare.\n\nSicurezza: Assicurati di conoscere i fornitori di identità, la crittografia, la conformità e le opzioni di accesso singolo. Questi sono gli stessi elementi con cui normalmente ti occupi in ambiente locale. Invece di strumenti separati, è meglio avere strumenti che coprano sia l'ambiente locale che il cloud pubblico, in modo che le tue squadre non debbano imparare nuovamente strumenti separati.\n\n* Privacy\n\nStabilità del carico di lavoro\n\nAffinità dei dati/gravità dei dati: Assicurati che il tuo fornitore di cloud abbia disponibilità nelle regioni di cui hai bisogno. Alcuni fornitori di cloud hanno zone di disponibilità, o centri di dati, in tutte le loro regioni, mentre altri no. Inoltre, se un carico di lavoro si connette a molti sistemi on-premises, non ha senso mettere quel carico di lavoro nel cloud pubblico.\n\nCosto: Ci sono ancora delle differenze di costo tra i fornitori di cloud pubblico, soprattutto con le istanze di calcolo di grande dimensione. Considera anche i costi di uscita.\n\n## Come vendere il tuo servizio di Cloud Broker.\n\nAcquistare il servizio di cloud broker può essere difficile per alcuni, come gli sviluppatori abituati a avere il controllo e a creare istanze a loro piacimento. Ci possono essere anche problemi di crescita. Quando le persone alla Intel hanno aperto i loro account, si sono sentite insicure e poi il reparto di sicurezza delle informazioni ha inviato messaggi quando stavano commettendo degli errori, senza che loro sapessero necessariamente cosa avessero fatto o come correggerlo. Con l'evoluzione e la maturazione del servizio, questi problemi si sono risolti da soli grazie all'intervento del team che ha offerto aiuto e ha implementato correzioni automatiche.\n\nLe persone hanno visto che il servizio alla fine era un beneficio perché forniva un modo rapido e facile per accedere al cloud pubblico con tutto il supporto di cui avevano bisogno. Dopo un certo periodo, il servizio ha cominciato a vendersi da solo.\n\nUno dei servizi chiave che il team offre è agire da ponte tra i partner commerciali finali di Intel e i gruppi di sicurezza dell'informazione per neutralizzare politiche di sicurezza eccessivamente aggressive che creano problemi e troppi ticket. Il team fornisce l'equilibrio corretto che consente agli sviluppatori di lavorare all'interno di un framework sicuro e di soddisfare comunque i requisiti di sicurezza. I mediatori, in sostanza, lavorano come intermediari tra la sicurezza dell'informazione e gli sviluppatori.\n\nIl team del broker cloud fornisce anche formazione invitando i fornitori di cloud a tenere workshop. Questo vantaggio è inoltre derivato dal Cloud Center of Excellence, dove le persone hanno richiesto formazione in aree specifiche e poi il team trattava con i fornitori per organizzarla.\n\nOltre ai fornitori esterni, Intel ha utilizzato squadre interne per mostrare ciò che avevano fatto con il cloud pubblico in modo che altre squadre potessero trarne beneficio.\n\nI team di broker cloud all'interno delle aziende possono fornire una serie di servizi e vantaggi come la sicurezza e l'efficienza dei costi, specialmente man mano che i servizi cloud pubblici maturano, si espandono e diventano sempre più necessari per le operazioni.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Dave Shrestha","Kevin Bleckmann"],"link":"/episode-EDT57-it","image":"./episodes/edt-57/it/thumbnail.png","lang":"it","summary":"Nella seconda parte, Darren Pulsipher, Chief Solution Architect, e gli architetti delle soluzioni cloud Dave Shrestha e Kevin Bleckman di Intel parlano dei benefici e dei servizi di un'organizzazione di intermediari del cloud."},{"id":130,"type":"Episode","title":"Comprendere i problemi dalla periferia al data center.","tags":["data","edge","compute","edgemere","edgetocloud","cybersecurity","technology","process"],"body":"\r\n\r\n## Integrazione nella Missione\n\nCi sono molte componenti in movimento quando si mettono in atto capacità in missione, specialmente nel Dipartimento della Difesa, ma anche negli ospedali degli Affari dei Veterani, nella Sicurezza Nazionale, nell'FDA e nella FEMA, ad esempio, e nel riportare i dati dai dispositivi sul campo alle stazioni di terra e ai data center regionali ed aziendali. I dati devono essere utilizzabili e affidabili per flussi di analisi complessi nei processi di intelligenza artificiale e devono giungere nelle mani degli analisti affinché possano prendere decisioni basate sui dati grezzi.\n\n## This is the translation to Italian:\n\"Driver per Edge: Latenza, Larghezza di banda, Sicurezza, Connessione\"\n\nParte del puzzle è che i dispositivi periferici sono diventati più sofisticati e stanno raccogliendo più dati di quanti potremmo mai inviare a 5G. Le speranze che il 5G conquistasse tutti i dati e li rendesse disponibili in modo fluido al datacenter non si sono mai concretizzate con gli sviluppi dei dispositivi IoT.\n\nUno degli architetture originali attorno all'IoT fu creata da Cisco, chiamata nebbia. L'idea della nebbia era che il datacenter connettesse la nebbia ai dispositivi periferici, in modo che parte dell'elaborazione e della connettività avvenisse lì. Se la connettività di rete è affidabile e costante, questo funziona bene con una larghezza di banda sufficiente. Tuttavia, la quantità di dati generata ora dalla periferia da queste organizzazioni supera qualsiasi quantità di larghezza di banda disponibile.\n\nCon l'IoT, solo una porzione dei dati viene trasferita al data center, quindi in generale il valore dei dati si manifesta solo quando vengono analizzati lì. Il problema è che il data center non può archiviare e assorbire tutti i big data. Anche l'invio dei dati al cloud non risolve il problema, poiché il cloud non può consumare tutti i dati che si trovano sul bordo. Pertanto, vogliamo evitare di inviare tutti i dati al data center per raccogliere il valore e invece spingere il valore dei dati il più vicino possibile al bordo, riducendo la quantità di volume dei dati che ritorna al data center.\n\nNaturalmente, non tutti i dati possono essere spinti verso il bordo; deve esserci una correlazione tra diversi dispositivi periferici. Il valore deve trovarsi in un luogo più centralizzato, non necessariamente nel datacenter centrale, ma magari in uno di questi nebbie intermedie o datacenter regionali. La chiave è spostare i dati in modo intelligente e spingere il valore dei dati il più vicino possibile al bordo in maniera ripetibile e sostenibile. Facendo così, possiamo reagire molto più rapidamente al bordo.\n\n## Livello fisico comune.\n\nPer superare alcuni di questi problemi, abbiamo prima bisogno di un livello fisico comune. Ciò significa che è comune dal data center attraverso i livelli di nebbia fino ai dispositivi periferici; c'è un modo per gestire e controllare i dispositivi e ottenere assistenza da essi in modo affidabile e comune. Questo non significa necessariamente la stessa macchina, ma un dispositivo minimale con un'interfaccia comune. Un altro vantaggio del livello fisico comune è che se scrivi codice per un'applicazione, può essere eseguito ovunque in questo ecosistema. Intel ha una tecnologia eccellente per questo, come ad esempio oneAPI, che fa molto del lavoro in modo che tu possa scrivere il codice una volta, compilare i binari per i diversi tipi di dispositivi, caricarlo nel livello fisico comune e farlo eseguire correttamente. In breve, i vantaggi sono un modello operativo comune, un modello di sicurezza comune e una modalità di funzionamento scrivi-una-volta-esegui-ovunque.\n\n## Software Defined Infrastructure: Infrastruttura Definita dal Software\n\nSDI si applica al datacenter nelle nuvole private e pubbliche con le loro API definite dal software. Con SDI nel margine, otteniamo modi comuni di spostare i dati. Possiamo allocare risorse nel margine nel datacenter in qualsiasi momento e possiamo spostare i dati in questo modo in modo più fluido.\n\n## Livello di gestione delle informazioni distribuite\n\nDobbiamo essere più intelligenti nel gestire e classificare i dati, spostando i dati solo dove verranno elaborati, che sia sul bordo, in un datacenter regionale o nel cloud. Aspetti importanti sono la catalogazione e il riutilizzo dei dati, oltre a rispettare i requisiti di conformità e sicurezza. Il vantaggio di questa distribuzione della gestione delle informazioni è che si inviano meno dati al datacenter, si spostano meno dati e si crea valore sul bordo.\n\n## Livello di gestione del servizio\n\nAl fine di realmente spingere il valore fino al limite, abbiamo bisogno di poter distribuire le applicazioni fino al limite. È qui che entra in gioco uno strato di gestione del servizio, o un ecosistema di contenitori. Ciò consente di spingere i microservizi fino al limite, alla nebbia, al datacenter o al cloud in modo ripetibile e affidabile. Se, ad esempio, un datacenter regionale si blocca, non è necessario dipendere da esso per continuare a utilizzare il service mesh.\n\n## Livello di servizio dell'applicazione\n\nUno strato di servizio di applicazione coordina le diverse applicazioni in modo tale da poter creare flussi di lavoro che generano il vero valore commerciale dai dati. Semplicemente spostare i dati o farli passare attraverso un motore di analisi non è sufficiente. I dati devono passare dal motore di analisi a una postazione di lavoro dell'analista. Alcuni strumenti in questo strato potrebbero essere l'automazione dei processi robotici e le pipeline DevOps. È anche qui che è possibile applicare la sicurezza e la conformità a livello di applicazione.\n\n## Sicurezza e livelli di identità\n\nL'aspetto chiave dello strato dell'identità è quello di creare fiducia tra le entità che sono correttamente identificate. Dobbiamo capire chi sta accedendo a cosa e quali dispositivi stanno accedendo a quali dati, in quale momento e dove. L'identità va oltre il tipico utente e coinvolge l'identità delle applicazioni, dei dispositivi edge, della nebbia, dei data center e del cloud.\n\nIl gemello dell'identità è la sicurezza. Qui abbiamo rilevamento, rimedio, cifratura ed esecuzione dell'autenticazione di fiducia. Questo porta a affidabilità, dati fidati e conformità. Ora, i dati intelligenti possono essere inviati all'estremità che poi vengono popolati fino al data center, ma non stai spostando enormi quantità di dati grezzi, solo ciò di cui hai bisogno in modo sicuro.\n\n## Vista ad alto livello\n\nPer avere un'architettura edge to cloud di successo e ripetibile, sono necessi tutti questi diversi elementi. Abbiamo visto alcune organizzazioni costruire un'architettura edge to cloud specifica per uno scopo, e quando implementano una nuova funzionalità in quel contesto, rimangono bloccate. Ad esempio, se codificano duramente i dati che risiedono nell'edge perché saranno sempre elaborati nell'edge, o nel datacenter per un'applicazione che viene sempre elaborata nel datacenter, ciò comporta rigidità. Ciò aumenta anche il tempo necessario per implementare nuove funzionalità, forse anni invece di mesi. Se prendiamo gli apprendimenti dai rilasci delle applicazioni in edge to cloud volta dopo volta e iniziamo a generalizzarli, scopriamo rapidamente che rientrano in uno dei livelli che abbiamo identificato.\n\nPer ulteriori informazioni, consulta questo articolo (includi il link) riguardo alla visione ad alto livello di questa architettura di edge to cloud. Non siamo prescrittivi su cosa inserire in quelle caselle, ma la chiave è capire i casi d'uso che abbracciano. Abbiamo idee su cosa è presente in ciascuno degli strati e stiamo sviluppando ecosistemi per soddisfare le esigenze uniche della tua organizzazione all'interno degli strati.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT58-it","image":"./episodes/edt-58/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, esamina i problemi comuni nelle architetture dal bordo al centro dati che ha osservato e discusso con i clienti del settore pubblico. Egli presenta l'architettura ideale per risolvere questi problemi."},{"id":131,"type":"Episode","title":"Evoluzione della privacy dei dati","tags":["cybersecurity","data","dataprivacy","privacy","process","people","healthcare","sutterhealth"],"body":"\r\n\r\nDopo essersi laureato in giurisprudenza, Jeremy è entrato direttamente nel JAG Corps dell'US Air Force e ha prestato servizio come ufficiale in servizio attivo per nove anni. Una delle sue responsabilità era quella di essere responsabile dei record per due uffici diversi. Ha poi cambiato il suo focus verso il settore sanitario con l'ultima assegnazione militare come consulente per gli ospedali del Nord-est. Dopo aver lasciato il servizio attivo (è ancora nella riserva), è stato assunto come consulente in un ospedale ed attualmente lavora presso Sutter Health.\n\nAnche se il quadro normativo è lo stesso per la privacy dei dati, ci sono alcune differenze tra governo e settore privato: l'approccio, gli obiettivi e le normative che si applicano. Nel governo, la privacy dei dati significa mantenere i dati protetti attraverso il Privacy Act; mantenere segrete le informazioni riservate. Anche se ci sono eccezioni, come il Freedom of Information Act, i sistemi sono progettati per proteggere le informazioni, non per divulgarle, per impostazione predefinita.\n\nNel settore sanitario, dall'entrata in vigore della legge HIPAA nel 1996, seguita poco dopo dal HITECH e ora con l'ONC, i dati vengono spinti nelle case, nei dispositivi dei pazienti, e i pazienti possono consentire l'accesso a terze parti. \"Accesso appropriato\" è probabilmente una migliore descrizione rispetto a \"privacy dei dati\".\n\nIl movimento per i diritti sulla privacy prevede un maggiore accesso e un maggiore controllo da parte degli individui. Come paziente, non solo hai il diritto alle tue informazioni, ma puoi anche indicare al tuo fornitore di assistenza sanitaria di fornirle a un terzo: un avvocato, un amico, un altro professionista medico, ecc. Un paziente può inoltre specificare un supporto di rilascio cartaceo o elettronico, dunque ai pazienti sono attribuiti molti diritti.\n\nQuesti diritti per gli individui di controllare i propri dati non si limitano al settore della sanità. Lo vediamo nel movimento attuale con il GDPR e nelle recenti leggi approvate in Brasile, Canada e Cina, e in alcuni stati degli Stati Uniti come la California, Washington e Virginia.\n\nPoiché il futuro della privacy dei dati si concentra sempre di più sui diritti individuali di accesso, ciò cambierà il modo in cui le organizzazioni possono tracciare le informazioni. Grandi aziende come Google e Facebook offrono ora opzioni mediante le quali le persone possono eliminare i propri dati o impedire alle aziende di venderli in varie forme. Dispositivi di tracciamento come i cookie tradizionali non saranno più rilevanti, quindi dovrà esserci qualcos'altro che aiuti gli inserzionisti mirati.\n\nMolti dati, naturalmente, come ad esempio i dati sull'occupazione, sono già regolamentati. Il controllo individuale dei dati non è un diritto assoluto; le aziende hanno bisogno dei dati per funzionare, quindi saranno in grado di conservare alcuni di essi, ma sarà più regolamentato. Negli Stati Uniti, avremo più complessità e più problemi prima di avere una standardizzazione. Abbiamo 50 stati, ognuno con le proprie regolamentazioni.\n\nCi sono tante leggi quanto definizioni di informazioni personali, ciò può causare dei conflitti. Sutter, ad esempio, ha molti ospedali nel Nord della California e alcune strutture ausiliarie in Hawaii, Oregon e Utah. Sutter deve costantemente attenersi alle normative di tali stati, ma in caso di violazione, entra in gioco lo stato in cui risiedono gli individui interessati. A volte, le leggi sono scritte in modo tale che Sutter debba seguire la normativa del luogo di residenza dei pazienti anziché quella dell'azienda, rendendo così la situazione complessa.\n\nA volte ha senso esternalizzare questi tipi di problemi, e sta emergendo un'intera industria legale che aiuta le aziende a navigare le normative sulla privacy e la sicurezza delle informazioni.\n\nDal lato informatico, la sicurezza dei dati significa limitare chi ha accesso alle cose. Con la privacy dei dati, si aprono porte per l'accesso. Naturalmente, c'è un processo di convalida per chi ha accesso, ma c'è un equilibrio tra sicurezza e privacy, che può creare molto lavoro sia per il lato legale che per quello operativo.\n\nLe organizzazioni che sviluppano qualsiasi tipo di applicazione che tratta i dati delle persone devono capire che le leggi sulla privacy sono diverse in ogni paese e in ogni stato e le conseguenze derivanti dall'utilizzo e dalla conservazione di tali dati.\n\nJeremy, insieme alle squadre privacy e sicurezza sono impegnati con le squadre tecniche, talvolta fin dalla fase di progettazione, per assicurarsi che tutto rispetti le regolamentazioni. Ad esempio, parlerà con la squadra che costruisce i portali pazienti per vedere se le cose che vogliono fare rispettano le regolamentazioni. Inoltre, aiuta a rispondere alle domande su quale tipo di database sarebbe migliore o se c'è un fornitore di cloud che può essere configurato in conformità. Jeremy trova che più si istruisce e si forma sugli aspetti tecnici, più può essere utile nel processo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jeremy Harris"],"link":"/episode-EDT59-it","image":"./episodes/edt-59/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, discute ciò che la privacy dei dati significa veramente e la sua direzione futura con Jeremy Harris, Assistant General Counsel – Privacy/Information Security presso Sutter Health."},{"id":132,"type":"Episode","title":"Gestione del lavoro da remoto alla massima capacità.","tags":["telework","remoteworker","vdi","mfa","cybersecurity","people","process"],"body":"\r\n\r\n## Modalità di lavoro da remoto\n\nI modi di operare che vediamo le persone utilizzare nel Dipartimento della Difesa e nel settore privato sono i seguenti:\n\nDispositivo come una terminale stupida (VDI - Infrastruttura di Desktop Virtuale)\n\nDispositivo come parte della rete interna (VPN - Rete Privata Virtuale)\n\n* Dispositivo come portale ai servizi\n\nLa maggior parte dei lavoratori sta utilizzando diverse modalità di funzionamento, quindi è necessario supportare diversi tipi attraverso l'infrastruttura.\n\n## Dispositivo come un terminale stupido\n\nIn questa modalità, il lavoratore ha il proprio desktop in esecuzione su un server nel data center e utilizza il proprio laptop per connettersi al \"desktop virtuale\". Fondamentalmente, utilizzano il proprio laptop o un altro dispositivo come un terminale \"stupido\". Ci sono alcuni problemi con VDI, tra cui scalabilità, congestione di rete, latenza e ridondanza. A causa di questi problemi, una sessione VDI può essere piuttosto costosa. Tuttavia, tra le tre opzioni, VDI è la più sicura.\n\n## Dispositivo come parte della rete interna\n\nQuesto è probabilmente la modalità più comune. Il lavoratore connette il proprio dispositivo alla VPN in modo da lavorare sulla rete come se fosse connesso in ufficio. Un vantaggio è la mobilità dato che i lavoratori possono connettere qualsiasi dispositivo come un telefono, un tablet o un laptop. Un altro vantaggio è che ci possono essere segmenti diversi della VPN per diverse classificazioni dei dati. Un aspetto negativo è che i lavoratori devono essere sempre connessi per poter lavorare. E sebbene non ci sia tanto traffico di rete come con un VDI, ci sarà comunque una certa congestione di rete durante il trasferimento dei dati.\n\n## Dispositivo come un portale ai servizi\n\nSempre più persone si stanno orientando verso questa modalità. L'operaio utilizza il proprio dispositivo per connettersi ai servizi in cloud, pubblici o privati. Il servizio principale che le persone utilizzano è Office 365, che consente alle organizzazioni di utilizzare i servizi cloud al posto dei propri servizi o in concomitanza con essi. Efficienza, prestazioni e la capacità di lavorare disconnessi a volte sono vantaggi. Gli svantaggi includono dipendere da un terzo... (non sono sicuro di come concludere questa frase - adozione/migrazione e sicurezza)\n\n## Emergenti ostacoli\n\nI seguenti sono tradotti in italiano: I collo di bottiglia sono emersi man mano che il numero di persone che lavorano da casa è aumentato dal 15% all'obiettivo dell'85%. Per le prime due modalità di funzionamento, la scalabilità della VPN può essere un grosso ostacolo. La banda limitata è anche una grande fonte di collo di bottiglia. Una soluzione a questi problemi è sfruttare i servizi cloud per alleviare la tensione. A livello umano, le operazioni informatiche e i servizi di assistenza sono sopraffatti poiché i lavoratori si stanno collegando da casa per la prima volta.\n\n## Scalabilità VPN\n\nEsistono diverse soluzioni a breve termine per aiutare a ridurre questi ostacoli. La prioritizzazione dell'accesso degli utenti può essere efficace, che sia basata sugli orari o sulla priorità delle missioni. È necessaria un'educazione dei dipendenti riguardo all'adattamento a questo ambiente.\n\nPer una scalabilità a lungo termine, le organizzazioni dovrebbero migrare verso soluzioni SaaS utilizzando i laptop come modalità di accesso.\n\n## Larghezza di banda per siti.\n\nUna delle migliori cose che le organizzazioni possono fare nel breve termine è scoprire quanti utenti VDI hai attualmente e vedere se puoi spostarli a lavorare sulla rete o in modalità di collaborazione con gli strumenti. Ciò ridurrà drasticamente il carico sulla larghezza di banda. Potrebbe essere necessario anche aumentare le capacità della tua rete dopo aver valutato come lavorano gli utenti remoti. L'istruzione è ancora una volta una parte essenziale di questa transizione in modo che i lavoratori utilizzino le migliori pratiche, ad esempio disconnettersi dalla VPN quando non la utilizzano e configurare gli strumenti di backup per operare durante le ore non lavorative. Nel lungo termine, suggeriamo un'architettura multi-ibrida che ti dia la possibilità di sfruttare i fornitori di servizi cloud per la larghezza di banda di rete e la capacità di espansione e ottimizzare il costo e la capacità.\n\n## Servizi ospitati scalabili\n\nPer aiutare nell'implementazione di architetture scalabili per scopi a breve termine, ci sono diversi ottimi riferimenti, tra cui Outlook Web Access (OWA) e le architetture di riferimento VDI.\n\nAncora, per il lungo termine, raccomandiamo di passare a un'infrastruttura di cloud ibrido multipla per elasticità, capacità, prestazioni predictive, conformità e sicurezza.\n\n## Operazioni IT\n\nCome possiamo ampliare il team del servizio di assistenza che molto probabilmente si trova sopraffatto? Un'idea è quella di avere delle FAQ online a disposizione dei lavoratori per un facile riferimento. Le soluzioni contribuite dalla comunità degli utenti, moderati dall'IT, possono anche essere utili. Idealmente, le organizzazioni dovrebbero utilizzare un sistema di gestione dei ticket per individuare punti critici e semplificare i processi. Inoltre, tutto ciò che può essere automatizzato per evitare compiti ripetitivi dovrebbe essere automatizzato tramite, ad esempio, l'automazione dei processi robotici (RPA) o scripting aggiuntivi. Una soluzione a lungo termine potrebbe essere l'implementazione di AI Chat Bot come un servizio di help desk IT self-service. Questi rapidamente restringono le soluzioni online utilizzando parole chiave o raccomandando il contatto.\n\n## Conclusione\n\nIn definitiva, Intel vuole vedere le organizzazioni avere successo durante questo periodo difficile in cui i lavoratori passano dall'ufficio al lavoro da remoto e affrontano molto stress. Intel può aiutare l'industria, il governo e i settori pubblici. Abbiamo silicio che funziona in tutti questi aspetti. Abbiamo partner che offrono soluzioni hardware e software, e naturalmente, vendiamo PC e dispositivi per clienti che permettono ai lavoratori remoti di operare.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tim Flynn","Pete Schmitz"],"link":"/episode-EDT6-it","image":"./episodes/edt-6/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren, Tim Flynn, ammiraglio in pensione della Marina, e Pete Schmitz, responsabile delle vendite per la Marina di Intel, parlano di come gestire la crescita esplosiva dei telelavoratori a causa della pandemia di Covid-19. Discutiamo dei diversi modi in cui i lavoratori possono lavorare in remoto e comunque essere produttivi: dispositivo come terminale stupido, dispositivo come parte della rete interna e dispositivo come portale per i servizi. Comprendere questi modi di operare può aiutare a individuare i punti di sofferenza che possono ostacolare l'efficacia del tuo team."},{"id":133,"type":"Episode","title":"Gestione del rischio di fronte al ransomware","tags":["cybersecurity","ransomware","riskmanagement","process"],"body":"\r\n\r\nNell'ultimo anno, si è registrato un aumento del numero e della sofisticazione degli attacchi informatici. Le tre principali aree degli attacchi ricorrenti sono ransomware, attacchi alla catena di approvvigionamento e violazioni dei dati.\n\nGli attacchi sono diventati più sofisticati per diverse ragioni. Innanzitutto, man mano che la sicurezza migliora, il nemico deve continuare a migliorarsi. Criminalità organizzata, attori statali e altri agenti minaccia riconoscono che serve maggiore sofisticazione per compromettere e sventare i controlli di sicurezza. Proprio come le organizzazioni hanno processi di sviluppo del software, così anche la comunità del malware. Hanno strumenti e strutture da cui partire e buoni processi per garantire la qualità dei loro sistemi. Diversi partecipanti acquistano, vendono e prendono in prestito codice. Imparano l'uno dall'altro e condividono informazioni sul dark web. Non sono solo squadre disorganizzate di hacker; funzionano più come aziende.\n\nQuesti agenti di minaccia operano in un settore da miliardi di dollari. Il denaro grosso guida la necessità di maturità. Non possiamo più semplicemente aggiungere la sicurezza, deve essere integrata e integrata ovunque, non solo nei prodotti, ma anche nell'infrastruttura e nei processi. Questa è stata una delle lezioni apprese da SolarWinds: anche se costruisci un buon prodotto, l'infrastruttura che lo supporta può essere vulnerabile.\n\nGli attacchi recenti mostrano che nessuno è immune. Spesso le organizzazioni erroneamente assumono di essere al sicuro poiché non operano nel settore dei servizi finanziari, del governo o di altre industrie ad alto valore, ma gli attacchi recenti alle aziende come JBS Foods, McDonald’s e Audi hanno dimostrato che nessuno è immune. Le aziende, indipendentemente dal loro prodotto, dipendono dalla loro infrastruttura digitale per funzionare; l'attacco a JBS Foods ha colpito la più grande industria di confezionamento di carne al mondo.\n\nNessuna singola cosa funge da panacea per prevenire questi attacchi. C'è speranza, ma richiede molto lavoro. Un'organizzazione deve avere diligenza nel valutare correttamente le metriche di rischio per implementare la sicurezza in modo corretto. Se non si comprende il proprio rischio, nessuna quantità di controlli di sicurezza sarà efficace perché non si sa se vengono applicati nel posto giusto.\n\nLa chiave sta nel partire con il giusto insieme di politiche e rischi per la tua organizzazione. Un passo fondamentale è che anche se la tua organizzazione non ha ancora completamente capito come implementare un'architettura a zero trust, negare tutte le richieste di accesso fino a prova contraria è un passo nella direzione giusta. Ciò significa che c'è un cancello ad ogni porta, piuttosto che una chiave principale per tutto ciò che è all'interno. Negare in modo predefinito è un principio fondamentale del zero trust.\n\nSe una società non è specializzata nella sicurezza informatica o non dispone dei finanziamenti necessari per un team interno sufficiente, ci sono molte risorse disponibili per aiutare. I fornitori di sicurezza gestita (MSP) sono una buona opzione, ma dovrebbe sempre esserci almeno un esperto interno: un Chief Security Officer. Questa persona ha la conoscenza del contesto locale e dell'esperienza di dominio per lavorare con l'MSP e diffondere tale conoscenza in tutta l'organizzazione. L'MSP si occupa della gestione degli strumenti e delle configurazioni di sicurezza, ma è necessario avere qualcuno che trasmetta la saggezza della sicurezza alle unità aziendali e IT. Alla luce degli attacchi recenti, un team di sicurezza non è facoltativo.\n\nOgni azienda dovrebbe avere un piano pronto per un attacco di ransomware. Non è il momento di adattarsi quando è già successo. Un principio fondamentale è fare regolarmente il backup dei dati. Conserva copie intatte dei dati, dei sistemi, delle applicazioni e delle configurazioni in un ambiente di archiviazione offline. Sei mesi di dati di backup puliti sono importanti perché a volte il ransomware può trovarsi nei backup prima che venga rilevato. Inoltre, assicurati di avere offline le piattaforme o i server necessari per eseguire il tuo database, in modo da poterli attivare in un modello di fallback o di ridondanza.\n\nQuesto è essenzialmente il piano di continuità aziendale. Proprio come un'organizzazione avrebbe un piano per la continuità in caso di disastro fisico come un'alluvione o un'interruzione di corrente, dovrebbe esserci anche un piano per continuare con le applicazioni aziendali critiche per tornare almeno parzialmente in funzione mentre il problema viene risolto.\n\nUn passo per realizzare questa ridondanza è essere in grado di passare rapidamente al cloud quando necessario, mantenendo le risorse del cloud in uno stato perfetto e magari anche presso un diverso fornitore di servizi cloud. Un altro passo consiste nell'avere un canarino nella miniera. Ciò significa avere sistemi distribuiti in tutta l'azienda dotati di sensori impostati al massimo. Per evitare problemi di prestazioni, spazio di archiviazione e velocità, è possibile distribuirli strategicamente anziché a livello di sistema, in modo da fungere da allarmi precoci.\n\nCreare un piano in anticipo aiuterà anche a fronteggiare la sfida di cosa fare nel momento di crisi, che sia pagare il ransomware o contattare l'FBI. Il piano dovrebbe essere su carta e coinvolgere non solo il personale tecnico, ma anche avvocati, CEO, CFO, ecc..., e tutti dovrebbero avervi accesso. Dovreste sapere come acquistare bitcoin e dovreste avere il numero degli uffici locali dell'FBI e altre informazioni. Mettete in pratica il piano come un esercizio per verificare se funziona, esattamente come fareste con un piano di ripristino dalla disastrosità o di continuità aziendale.\n\nAlcune industrie potrebbero pensare di stare al sicuro se mantengono separate la loro tecnologia operativa (OT) e la loro tecnologia informativa (IT), ma in realtà non sono veramente separate. Ad esempio, una linea di produzione può essere gestita da macchine informatiche, ma gran parte di ciò che guida la catena di approvvigionamento, la logistica e l'organizzazione generale sono sistemi IT. Se quei sistemi si bloccano, nulla entra o esce. I sistemi IT sono essenziali per la missione e l'apprendimento dagli attacchi recenti ci ha mostrato che dipendiamo dalla tecnologia digitale per tutte le nostre attività commerciali.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT60-it","image":"./episodes/edt-60/it/thumbnail.png","lang":"it","summary":"In questo episodio, parte uno di due, Darren discute le tendenze della sicurezza con l'ospite frequente Steve Orrin, CTO di Intel, Federal. Nel corso dell'ultimo anno, si è registrato un aumento del numero e della sofisticazione degli attacchi informatici. Le tre principali aree degli attacchi ricorrenti sono i ransomware, gli attacchi alla catena di approvvigionamento e le violazioni dei dati."},{"id":134,"type":"Episode","title":"Violazioni dei dati e catena di approvvigionamento sicura","tags":["datbreach","data","process","policy","cybersecurity","supplychain","securesupplychain"],"body":"\r\n\r\nOltre agli attacchi di alto profilo nella catena di approvvigionamento come l'incidente con SolarWinds, ci sono altri attacchi meno conosciuti che sono altrettanto problematici.\n\n## Fornitura sicura della catena di approvvigionamento\n\nUn esempio è l'estensione di Chrome The Great Suspender, uno strumento per assicurarsi che la memoria venga utilizzata correttamente nelle applicazioni di Chrome, con circa due milioni di utenti. I fondatori di questo strumento open source hanno venduto la loro azienda a un'organizzazione per milioni di dollari senza un'adeguata dovuta diligenza. L'acquirente si è rivelato essere un gruppo di criminalità organizzata che ha trasformato lo strumento in malware e spyware.\n\nNon c'è stata un'attacco nel senso che non hanno hackerato l'azienda originale, ma l'hanno acquistata e fatto ciò che volevano col codice. Quello che un giorno era un prodotto legittimo è diventato illegittimo il giorno seguente. Nessuna quantità di protocolli di sicurezza avrebbe risolto quel problema. Ora le aziende devono fare una selezione accurata dei propri fornitori e dei terzi che le supportano.\n\nL'open source è una benedizione e una maledizione. La benedizione è che, poiché è open source, si ha accesso al codice sorgente e si può esaminarlo quanto si vuole. La maledizione è che nessuno ha il tempo, l'energia o l'esperienza necessaria per verificare attentamente ogni singolo pezzo di codice open source che utilizzano. Il codice vulnerabile ai malware, anche se non intenzionale, può essere introdotto se non viene individuato dalla comunità e talvolta ciò non accade per molto tempo.\n\nCi sono due cose che potrebbero attenuare questo problema: la prima è che il codice potrebbe essere sottoposto a un'analisi del codice sorgente utilizzando uno strumento apposito, e potrebbe esserci un sistema di valutazione per i contributori di codice i cui prodotti presentano consistentemente meno vulnerabilità o bug. Questo lavoro sarebbe principalmente svolto da fornitori esterni. In secondo luogo, esistono già alcune start-up ben consolidate nel settore della verifica dei prodotti open source per mostrare quali oggetti in un repository sono affidabili e quali non lo sono ancora.\n\nLa scansione delle vulnerabilità attuali nell'open source è un controllo, ma quel tipo di sicurezza da sola non è sufficiente. Deve essere combinata con controlli aggiuntivi prima di essere eseguita in tutta l'organizzazione.\n\n## Violazioni dei dati\n\nOltre ai ransomware e agli attacchi alla catena di approvvigionamento, le violazioni dei dati sono un problema comune. Nel 2020 sono stati estratti 1,8 trilioni di dollari dalle violazioni dei dati su 7,8 miliardi di registrazioni. Ad esempio, una violazione presso McDonald's ha compromesso i dati dei clienti, dei partner e interni.\n\n## Crittografia\n\nLa prima parte della soluzione consiste nell'avere migliori strumenti di sicurezza per i dati e l'infrastruttura. Critico è crittografare l'accesso e incorporare un rifiuto predefinito in modo che, anche se qualcuno riesce a entrare dalla porta principale, non abbia accesso a tutto. È fondamentale criptare anche i dati all'interno dell'organizzazione, non solo quelli esposti al cloud o quelli inviati esternamente. Ogni dato che attraversa la tua rete, così come i dati inattivi, dovrebbe essere criptato.\n\nLa crittografia ha un costo, ma sui dispositivi moderni è presente un'accelerazione integrata che riduce la penalità. Ora puoi attivare la crittografia in tutta la tua organizzazione senza alcun impatto sulle prestazioni.\n\n## Segmentazione\n\nUn'altra parte sono gli enclavi, o la segmentazione. Una delle sfide negli ambienti aziendali di rete è che, ancora una volta, se qualcuno entra attraverso la porta, avrà carta bianca se tutto è connesso. Di recente c'è stato un movimento per trasferire il \"dev\" e spostarlo nella sua propria rete, ed è un inizio, ma è solo la punta dell'iceberg. La segmentazione della rete dovrebbe essere estesa all'intera organizzazione. È ancora possibile creare connessioni trasversali, ma esse devono conformarsi a un insieme di regole e contribuiranno a limitare l'impatto. Ad esempio, se il tuo help desk viene attaccato, i tuoi sistemi di risorse umane non saranno compromessi contemporaneamente.\n\nLa microsegmentazione era un termine di moda cinque o più anni fa, ma ora è necessaria. Ci sono alcuni ottimi strumenti disponibili per aiutare in questo senso, come gli ecosistemi di container in cui è possibile distribuire un'applicazione e questa avrà la sua rete e il proprio firewall.\n\nImplementare le credenziali di autenticazione corrette deve avvenire ora. L'autenticazione a più fattori è necessaria, così come l'autenticazione delle entità. Molti strumenti sono automatizzati e hanno processi automatizzati, quindi le entità, non solo le persone, devono avere le credenziali adeguate.\n\n## Zero Trust can be translated to Italian as \"Fiducia Zero\".\n\nLa filosofia della \"Zero Trust\" ha raggiunto un livello di maturità tale da dover essere implementata, e alcuni dei principali principi come il rifiuto predefinito e la totale sfiducia sono cruciali. La tecnologia si è adeguata alla messa in atto di questi concetti.\n\nI developer possono preoccuparsi di come questi strumenti di sicurezza rallentino il processo, ma ci sono modi per costruire l'architettura al fine di ridurre questo problema. Ad esempio, se sei un developer e hai le credenziali e l'accesso adeguati, dovresti essere in grado di accedere alle cose di cui hai bisogno quando ne hai bisogno e perdere l'accesso una volta che hai finito, anziché avere delle credenziali che ti danno accesso a tutto in ogni momento. L'idea di zero trust non significa che l'azienda non si fida del developer, ma che l'accesso avviene nel momento giusto, non solo un accesso generico nel caso in cui un attore malintenzionato rubi le credenziali.\n\nNessuna industria può permettersi di ignorare i rischi attuali. Ogni organizzazione deve guardare alla sicurezza in modo diverso e implementare la sicurezza in tutta l'organizzazione e l'architettura.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT61-it","image":"./episodes/edt-61/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, discute violazioni dati e catene di approvvigionamento sicure con l'ospite frequente Steve Orrin, CTO di Intel, settore federale."},{"id":135,"type":"Episode","title":"Demistificazione di 5G, Edge e AI","tags":["edge","compute","5g","aiml","iot"],"body":"\r\n\r\nLo sfondo di Anna è nel settore industriale e manifatturiero dell'informazione. Ha un dottorato in ingegneria chimica, oltre a un MBA. Ha trascorso 15 anni lavorando come ingegnere di processo e di progettazione, successivamente ha lavorato per startup e nella gestione dell'ingegneria. È stata con Intel per poco più di sei anni, negli ultimi due anni e mezzo ha lavorato nel team del settore pubblico dove supporta principalmente le attività di IoT e edge di Intel, con un coinvolgimento crescente anche nel 5G perché il 5G, insieme all'IA, sta cambiando in modo drastico quel settore.\n\n## La trasformazione della rete è fondamentale per l'infrastruttura 5G.\n\nNel mondo industriale, l'IoT non era nulla di nuovo; era solo cablato. Con i sistemi che si stanno ora spostando verso il wireless, si ha la stretta combinazione di IT e OT per convertire l'analisi, invece di avere solo un insieme di dati di processo specifici per quel mondo OT. Un diverso insieme di sistemi ora si sposa con il business, quindi tutto questo viene portato nello stesso spazio. Anche se ci sono alcune differenze ben definite nei casi d'uso e nelle architetture nel settore pubblico, come militare e città intelligenti, vi è una convergenza comune nell'analisi, nell'applicazione e nella tempistica per prendere decisioni aziendali migliori.\n\nUn motivo per cui l'IoT ha impiegato così tanto tempo per diffondersi al di fuori del settore manifatturiero e in altre aree è principalmente il costo di cablaggio fisso. La sicurezza è stata anche un ostacolo.\n\nIl 5G sta ora liberando l'IoT e il mondo del bordo grazie alla convenienza economica, soprattutto dal lato dei consumatori. Quando si tratta di infrastrutture critiche aziendali, però, si tratta di una conversazione diversa su come farlo in modo da proteggere i dati. Il 5G sarà trasformativo, ma non sta accadendo ancora sul lato commerciale. Parte del divario è dovuto al ritardo tra il rilascio degli standard e la produzione dell'hardware per sfruttare tali standard.\n\nPer chiunque abbia trascorso molto tempo con 3GPP o altri organismi di standardizzazione nel campo delle telecomunicazioni, questo tempismo non è sorprendente. Al momento è possibile realizzare una rete 5G, ma siamo ancora nella fase di creazione di prototipi in cui dobbiamo dimostrare il valore del 5G. Dobbiamo mostrare nuovi casi d'uso che non possono essere supportati da LTE o dal 4G.\n\n## Diversi modelli di implementazione 5G offrono flessibilità.\n\nPerché non restare semplicemente con il WiFi 6 invece di usare il 5G? La risposta è complicata. Molte delle organizzazioni che hanno promosso il 5G hanno anche sostenuto il WiFi 6, quindi si tratta di una tecnologia complementare. La differenza sta nell'attrezzatura, quindi è necessario conoscere i dettagli dei casi d'uso per determinare quale sarebbe la soluzione più economica. Ad esempio, il 5G è incredibile, ma non sarebbe conveniente installare una rete 5G su una nave da crociera perché la penetrazione del segnale non sarebbe sufficiente. L'ambiente non è favorevole a qualsiasi tipo di segnale wireless, ma il WiFi 6 con i punti di accesso ha più senso.\n\nIl 5G è convincente, tuttavia, per diverse ragioni e può fare cose che il 4G e LTE non possono fare. Per la realtà aumentata e la realtà virtuale, è necessaria una latenza molto bassa e una banda larga elevata per consentire utilizzi più interattivi, ad esempio la riparazione di attrezzature o macchinari. Hai bisogno di un esperto remoto che si trovi di fronte a un problema che può effettuare lo streaming video e audio con sovrapposizione di disegni e funzionalità che sono gestiti da una posizione centrale o remota, che porta tutta quella conoscenza ed esperienza direttamente al punto in cui stai cercando di lavorare. Quel tipo di caso d'uso non può essere realizzato su una rete LTE. La banda larga svolge un ruolo importante, ma la latenza è la forza trainante. Per evitare di ammalarti mentre si utilizza un visore, è necessario avere latenze molto basse senza ritardi o far sì che le cose procedano in modo asincrono.\n\nIl mondo LTE e 4G è cambiato a causa del 5G grazie alla gestione dello spettro. Un settore in cui questo sta cambiando nell'industria è che ora è possibile per un'azienda ottenere una licenza prioritaria per lo spettro CBRS e creare la propria rete privata, totalmente separata dai principali operatori di telecomunicazioni governativi. Ad esempio, un grande produttore può coprire uno spazio enorme in modo più conveniente con un LTE privato rispetto a punti di accesso. Ci sono anche grandi vantaggi come la possibilità di riconfigurare il proprio spazio senza dover collegare tutti i workstation con cavi, o ad esempio se si devono spostare enormi pezzi di metallo come la fusoliera di un aereo nello spazio, che potrebbero interferire con i segnali WiFi, è possibile creare un'infrastruttura portatile che non sia vincolata a posizioni cablate.\n\nLa sicurezza è una preoccupazione centrale per qualsiasi organizzazione. Sebbene il 5G non sia stato progettato con la sicurezza in mente, il 6G lo sarà. Fortunatamente, con le capacità del 5G, possiamo fare molto per quanto riguarda la rete a fiducia zero e altre misure di sicurezza che daranno ai clienti la certezza su come i loro dati vengono spostati attraverso le reti.\n\nGli standard 5G hanno cambiato il problema di alcuni anni fa quando l'infrastruttura wireless esisteva in hardware proprietari e software proprietari, con uno spettro licenziato a disposizione solo di poche aziende che potevano permetterselo. La rete definita dal software consente di hostare l'infrastruttura di rete su hardware comune, reperibile sul mercato. Non c'è bisogno di hardware specializzato come nelle generazioni precedenti. Questo sta accadendo anche nel lato LTE, ad esempio, rendendo disponibile lo spettro CBRS e allontanandosi dall'hardware e software proprietari.\n\nIntel spende molto tempo lavorando con disruptor che utilizzano la nostra architettura di riferimento FlexRAN. L'architettura FlexRAN diventa la base per aiutare la tecnologia disruptiva a proliferare nel nuovo mercato 5G perché fornisce una pila software 5G che funziona su hardware comune di tipo off-the-shelf, dove in precedenza era necessario un hardware proprietario. Ora c'è uno spazio molto più aperto e portatile, e il costo di ingresso è molto più economico rispetto a prima. Non sono più solo poche aziende a controllare tutto. Intel e altre stanno cercando di aprire tutto e sfruttare gli standard aperti per supportare tutti questi disruptor e cambiare l'intera dinamica.\n\n## Spettro 5G e Regolamentazione per le Reti del Domani\n\nCon una connettività migliorata, una bassa latenza e una banda larga elevata, saranno disponibili molti nuovi casi d'uso. Ciò che sta cambiando nel mercato è il modo in cui verrà monetizzato il 5G. Ad esempio, un provider di servizi cloud insieme a un operatore di telecomunicazioni può offrire servizi migliori ai propri clienti perché non sono più separati. Si tratta di uno sforzo commerciale combinato che mette al primo posto ciò che conta davvero: la qualità e la prioritizzazione. Un altro modo di vedere la questione è che i provider di servizi cloud stanno acquistando capacità che apriranno le funzionalità della rete allo stesso modo in cui i fornitori di telecomunicazioni stanno esplorando cosa possono fare sul lato cloud. Di nuovo, questo avviene perché il silos è stato abbattuto; il tubo dei dati non è più un insieme di servizi.\n\nNon è chiaro come finirà tutto questo, tranne che sta ridefinendo il tipo di lavoro che puoi fare a causa dell'accessibilità ai dati e dove si troveranno queste carichi di lavoro. C'è un'enorme valore nel passare in modo fluido dal bordo al cloud e farlo in modo basato sulle esigenze del cliente, cosa che ora è possibile.\n\n## Un nuovo paradigma di calcolo supporta nuove esigenze di dati.\n\nIl 5G sta liberando molti modelli architettonici diversi. Ad esempio, offre due opzioni di architetture per l'intelligenza artificiale, mentre in precedenza ce n'era solo una con limitazioni.\n\nSenza la banda larga fornita dalla rete 5G, l'IA era limitata all'elaborazione sui dispositivi periferici, il che richiedeva di inviare i modelli di IA ai dispositivi periferici. Questa restrizione ingombrante ha aumentato il ciclo di sviluppo e di implementazione dell'IA e limita il numero di carichi di lavoro dell'IA che possono essere sfruttati sul campo. Con un aumento della banda, grandi flussi di dati provenienti da telecamere o sensori possono essere inviati a un centro dati, consentendo l'esecuzione di più carichi di lavoro dell'IA e consentendo un apprendimento continuo dell'IA. Ciò offre alle organizzazioni l'opportunità di eseguire sia l'elaborazione sul campo che il miglioramento dell'apprendimento approfondito richiesto dalle mutevoli esigenze dei dati di così tante organizzazioni.\n\nCon la Realtà Aumentata, ad esempio, il 5G significa che gli occhiali possono essere mobili invece che collegati con le stesse funzionalità, perché il 5G permette la condivisione di set di dati più grandi in un mondo senza collegamenti. I tradizionali muri dei centri dati si stanno abbattendo.\n\nSe non hai molta assistenza tecnica o una conoscenza dettagliata su come mantenere i tuoi sistemi in funzione, puoi eseguirli tutti nel cloud. Se non desideri che i tuoi dati siano nel cloud, puoi effettuare una versione che sia in locale su una rete privata che ti fornisce tutti i tipi di funzionalità per aggregare e correlare i dati al fine di fornire una comprensione di alto livello di ciò che sta accadendo nel tuo sistema in modo sicuro ed economicamente vantaggioso.\n\nIn pratica, i tuoi dati possono ora risiedere sull'edge, nel cloud, in loco o in quello che Cisco chiama \"la nebbia\". Non importa più dove viene eseguita la tua applicazione, quindi puoi utilizzare il modello più conveniente in termini di costi. Nello spazio industriale, ad esempio, ci sono enormi risparmi nel non avere un componente di cablaggio rigido, o nell'utilizzare una struttura LTE privata anziché punti di accesso WiFi. Ridurre questi tipi di costi porterà alla possibilità di avere dati estremamente ricchi. Questi ostacoli legati ai costi e alla connettività fisica sono ciò che mancava affinché l'IoT decollasse come tutti avevano previsto.\n\nAnna prevede che per le applicazioni non di controllo, i prossimi due anni saranno diversi a causa del 5G. Un semplice esempio è che nell'industria, qualcuno potrebbe portare il proprio PC normale fuori dall'ufficio e sulla linea di produzione e essere in grado di fare tutto lì. Il 5G cambierà ciò che è possibile con riferimento ai controlli e al controllo di robot e macchine tramite una rete wireless nei prossimi cinque anni. Il prossimo livello di trasformazione sarà quello di poter fare controllo attraverso una rete wireless e farlo in modo sicuro ed efficace, senza mettere nessuno a rischio. Ciò richiederà molta validazione e rigorosa revisione, ma è all'orizzonte.\n\nInoltre, sarà emozionante vedere cosa il tuo provider di servizi cloud e la tua compagnia telefonica preferita faranno insieme per cambiare ciò che è possibile dal punto di vista dei servizi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT62-it","image":"./episodes/edt-62/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, discute i cambiamenti rivoluzionari che il 5G porterà all'edge e all'AI con Dr. Anna Scott, Chief Edge Architect, Intel."},{"id":136,"type":"Episode","title":"Ispirando un cambiamento culturale nell'IT","tags":["organizationalchange","change","people","covid","cio","california"],"body":"\r\n\r\nAmy ha ricoperto il ruolo di CIO dello stato per oltre cinque anni, nominata dal Governatore Brown e confermata dal Governatore Newsom. Ha lavorato come tecnologa nel settore pubblico per vent'anni in diverse aree, dalla scienza ambientale a CalPERS, ai servizi sanitari e sociali, prima di essere nominata CIO.\n\nIl 13 marzo 2020, Amy stava organizzando una riunione, discutendo, ironicamente, della necessità di accelerare l'obiettivo del servizio a banda larga per tutti i californiani, quando fu impartita l'ordinanza di blocco legata alla COVID. Immediatamente dopo, lo stato dovette trasferire oltre 200.000 dipendenti statali al telelavoro ed implementare l'apprendimento a distanza. Da un giorno all'altro, la questione della banda larga divenne una questione urgente nel gestire gli affari quotidiani. Lo stato partì con una capacità del 5% per il telelavoro e in un mese raggiunse il 92% di capacità.\n\nQuesto è stato l'ostacolo operativo più grande della pandemia. Le persone hanno dovuto abituarsi a lavorare da remoto e c'era una carenza di forniture, il che ha reso ancora più difficile. Tuttavia, l'intero cambiamento è avvenuto in modo relativamente fluido. Le persone sono state comprensive e flessibili e hanno permesso un miglioramento continuo.\n\nQuesto è un processo che di solito richiederebbe anni per essere completato. La differenza sta nel fatto che le persone non ci hanno pensato due volte nel dire \"questo è ciò che deve essere fatto\" e si sono mosse anziché analizzare ogni cosa eccessivamente. Tutti hanno fatto accadere le cose, anche se non erano perfette.\n\nLa sicurezza informatica è stata anche un ostacolo, poiché le persone che lavoravano da casa dovevano adottare le stesse buone pratiche come se fossero in ufficio, e ciò ha richiesto un certo cambiamento culturale.\n\nUna sorprendente novità è stata il desiderio di utilizzare un processo decisionale basato su evidenze, che si è accelerato improvvisamente. Sembra un po' un ossimoro, poiché non tutto poteva essere analizzato in modo eccessivo, ma d'altra parte si è concentrati sulle decisioni critiche che richiedevano un supporto basato su evidenze. Le cose non importanti sono state accantonate perché non c'era abbastanza capacità per fare tutto.\n\nLo stato sta ancora imparando quale sarà l'aspetto della forza lavoro in avvenire. Il telelavoro rimane per il futuro prevedibile e alcuni potrebbero diventare permanenti a causa dell'aumento della produttività. Inoltre, posizioni che non si adattano bene al telelavoro devono ritornare in un ambiente sicuro. Il benessere dei dipendenti è anche un fattore nella nuova dinamica.\n\nIl governo e altre organizzazioni devono mantenere un equilibrio tra gli ultimi 18 mesi altamente tattici e la pianificazione strategica per il futuro. Amy mantiene la visione strategica nel piano dello stato del 2023 come \"Stella del Nord\", ma si concentra anche sugli attuali miglioramenti incrementali per fornire servizi. C'è un ambiente di comprensione che le cose non saranno perfette mentre lo stato si adatta a una nuova normalità.\n\nAmy ha due obiettivi culturali per il suo dipartimento, derivanti dalla pandemia: le persone nelle posizioni di supporto devono essere in grado di collegare il loro lavoro ai cambiamenti e agli impatti positivi al fine di mantenere il morale alto, e l'ambiente dovrebbe diventare più visionario, ricordando ai lavoratori le direzioni strategiche da seguire.\n\nPer mantenere una positiva trasformazione culturale, i leader devono dare l'esempio e tenere conto del benessere dei dipendenti nelle loro decisioni. Ciò comprende essere flessibili nel modo in cui lavorano meglio e dare loro la fiducia di prendere decisioni per sentirsi realizzati e responsabilizzati. E se le cose non vanno perfettamente, scrollarsi di dosso la polvere e andare avanti.\n\nIl consiglio di Amy per gli altri CIO degli stati sarebbe quello di fare molto lavoro di proof of concept, rimboccarsi le maniche e provare le cose, e essere aperti a diverse modalità di risolvere un problema. I risultati del proof of concept informano meglio i leader nelle decisioni rispetto al solo tentativo di analizzare le cose.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Amy Tong"],"link":"/episode-EDT63-it","image":"./episodes/edt-63/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Architetto Capo delle Soluzioni di Intel, discute il cambiamento culturale stimolante con Amy Tong, CIO dello stato della California, nel periodo successivo alla pandemia di COVID."},{"id":137,"type":"Episode","title":"Segui e proteggi il margine di Bit verso il cloud","tags":["edge","compute","multicloud","cybersecurity"],"body":"\r\n\r\nNell'episodio n°2, Greg ha spiegato le complesse questioni relative alla raccolta, al trasferimento e all'analisi dei dati in un ambiente del Dipartimento della Difesa (DOD) che include dispositivi periferici su navi, aerei e persino combattenti e la necessità di trasferire e analizzare tali dati rapidamente per decisioni tempestive ed esaustive. Il ruolo di Intel è quello di aiutare a ridurre i cicli di processo e liberare i colli di bottiglia nel flusso di dati con il proprio portafoglio tecnologico. Si tratta di abbinare la tecnologia alla missione.\n\nUn recente trend in architettura consiste nel spostare il calcolo, l'elaborazione e l'intelligenza in avanti per incontrare i dati, piuttosto che spostare i dati verso la parte posteriore. Questa modifica offre la migliore capacità per ottenere risposte in tempo reale e intelligenza. Questo approccio rappresenta un diverso modello operativo con domande stimolanti.\n\n## Hardware eterogeneo\n\nNell'infrastruttura fondamentale, come fornite le capacità di calcolo, archiviazione, memoria e rete necessarie per guidare l'analisi al bordo e il processo dove ne avete bisogno? Come gestite queste applicazioni e i dati ad esse associati? Come introducete la qualità e la cura dei dati in modo più completo lungo la catena di fornitura? La sicurezza è un componente fondamentale di qualsiasi infrastruttura e ora i dati devono essere protetti fino al bordo.\n\nL'industria deve passare a un calcolo più eterogeneo, in modo che il software sottostante possa funzionare su diverse piattaforme hardware, evitando di rimanere vincolati a un software o hardware specifico. Parte della bellezza di ciò che Intel ha fatto negli anni è fornire la portabilità del software: la struttura aperta, x86 e altri sistemi sottostanti.\n\nUn fattore importante nello sviluppo delle capacità da parte di Intel è comprendere il carico di lavoro e il flusso dei dati, anziché concentrarsi sulla modernizzazione, come ad esempio spostare le cose nel cloud. Non si tratta di come si procure l'IT (nel cloud o in loco), ma di ottimizzare il flusso aziendale per trarre vantaggio dal modo in cui i dati si muovono e da ciò che realmente fanno.\n\n## DevOps al Salvataggio\n\nUn altro aspetto critico di queste nuove soluzioni è il tempo di distribuzione. Il DevOps è diventato sempre più importante in tutto il DOD, e gli sforzi per sviluppare piattaforme comuni di DevOps sono aumentati notevolmente. Per scrivere il codice una volta e farlo funzionare ovunque (cloud, in loco o al margine), le organizzazioni utilizzano il chipset x86 e l'oneAPI di Intel per distribuire servizi complessi in tutto l'ecosistema completo. Ad esempio, oneAPI consente agli sviluppatori di scrivere analisi complesse o lavori di intelligenza artificiale che vengono eseguiti su una GPU, una CPU o anche su FPGA con la stessa base di codice. Gli sviluppatori possono quindi testare questi sistemi complessi nel loro data center, assicurandosi che si comportino allo stesso modo quando vengono distribuiti sul campo, riducendo il tempo di distribuzione.\n\nEssere in grado di sfruttare una combinazione di un ambiente DevOps flessibile, che utilizza la containerizzazione e i framework software come oneAPI, offre ai programmatori l'astrazione di cui hanno bisogno ma con ottimizzazioni hardware/software incorporate. Una distinzione fondamentale qui è che abbiamo trovato un modo per sfruttare tutta la potenza dell'hardware e ottimizzare il software in modo che un'applicazione possa ancora ottenere un miglioramento delle prestazioni e sfruttare l'hardware specializzato.\n\nL'ecosistema di container fornisce un'astrazione a livello di sistema, quindi le cose non hanno bisogno di essere codificate duramente. Fornisce la capacità di aumentare o diminuire la scala in base al carico e alla capacità del servizio. Ad esempio, se una funzionalità viene eseguita sul margine, in un data center portatile o nuovamente nel cloud, e si perde la connettività o un asset, è comunque possibile portare a termine la missione. Questa connettività intermittente è essenziale in un ambiente DOD.\n\n## Soluzioni Edge\n\nMolte persone pensano a Intel come a un fornitore di silicio o hardware, ma l'azienda ha sviluppato soluzioni e architetture di riferimento nell'ecosistema dal bordo al cloud. Un esempio di progresso è una griglia tattica navale in cui l'elaborazione avviene sul bordo, su navi, aerei e a terra. Le applicazioni devono essere eseguite in tutto l'ecosistema e ciò non può essere fatto solo con l'hardware. Intel ha sfruttato il suo silicio e le sue funzionalità di sicurezza e, basandosi su un ecosistema di container, ha prodotto applicazioni complesse con diversi microservizi che possono essere eseguiti quando gli asset sono connessi o disconnessi.\n\nUn altro esempio di architetture di bordo è il tracciamento degli oggetti attraverso reti di sensori, anche con spazi vuoti nella rete di sensori. Effettuando la fusione dei sensori, la fusione dei dati e l'analisi cross-dominio, è possibile tracciare gli oggetti attraverso diverse scene e diversi tipi di sensori, adattandosi per creare una piattaforma di sensori mobile che può eseguire analisi e fusione dei dati al bordo. Successivamente, può anche passare a un insieme distribuito di nodi che possono lavorare in modo coordinato per tracciare un oggetto attraverso tutti quei diversi sensori esistenti.\n\nAd esempio, se stai tracciando un oggetto e si sposta tra i sensori, lo perderai per un attimo. Ciò che questa intelligenza ti consente di fare è collegare questi due flussi e tracciare gli angoli morti. Questo non funziona solo con tipi di sensori omogenei, ma può funzionare anche con diversi tipi di sensori come movimento, RF e sensori IR. Quindi, se perdi il video ma hai ancora un segnale RF e poi riprendi di nuovo il video, puoi mostrare l'intero percorso dell'oggetto. In passato, per questo tipo di analisi era necessario trasferire i dati al centro dati per elaborare queste interazioni complesse; ora, possiamo farlo direttamente sul bordo della rete di sensori tramite microservizi.\n\n## Flessibilità di distribuzione\n\nUn approccio vantaggioso è costruire una volta e utilizzare la stessa architettura e software per diverse missioni con requisiti analitici. Alcuni luoghi in cui il calcolo ad alta intensità è al margine possono aumentare la scala e sfruttare appieno le capacità hardware. Altre piattaforme possono avere capacità di calcolo limitate e possono eseguire microservizi più piccoli che forniscono solo una parte della soluzione completa. Nuove capacità e servizi di missione possono essere rapidamente implementati costruendo questi microservizi una volta per più casi d'uso.\n\n## Sicurezza al limite\n\nLa complessità è a volte il peggior nemico della sicurezza, ma i principi fondamentali della sicurezza possono anche proteggere i dati e le applicazioni esterne. Invece di adottare l'approccio tradizionale di proteggere il server e sperare che tutto rimanga lì, è essenziale capire dove fluiscono i dati e ogni luogo in cui esistono, proteggendoli indipendentemente da ciò su cui sono in esecuzione. I modelli basati sul rischio e concetti come il \"zero trust\" hanno guadagnato consensi perché offrono una prospettiva indipendente dai sistemi sulla sicurezza.\n\nSemplificando, zero trust significa negare automaticamente. Nessuno può accedere se non ne ha bisogno, e solo per il periodo necessario all'azione. Quando i controlli di accesso temporaneo si uniscono a un approccio basato sul rischio per proteggere i dati durante tutto il loro ciclo di vita, il risultato è la capacità di proteggere i dati ovunque siano e chiunque li stia accedendo. Questa tecnica è uno dei modi per garantire la sicurezza di questi ambienti altamente complessi.\n\nL'azione pratica da intraprendere in questi ecosistemi è applicare una politica che sfrutti i controlli che soddisfano il rischio di un determinato sistema in un determinato momento, e poi monitorarli e aggiornarli continuamente in tempo reale per far fronte al mondo dei cyber-attacchi in continua evoluzione. Utilizzare i controlli tecnici che l'hardware e le capacità del software già forniscono, come Secure Boot, radice di fiducia hardware con moduli TPM o chiavi di archiviazione SGX, crittografia, ecc.\n\nNon esiste una soluzione miracolosa che si possa acquistare per fornire una soluzione di sicurezza completa in questi ecosistemi complessi. Si tratta di creare e applicare politiche di sicurezza man mano che le minacce si evolvono e di implementarle su larga scala, sfruttando hardware, software e processi necessari per proteggere il flusso dei dati dalla periferia fino all'intero ecosistema.\n\nIl framework DevOps fornisce meccanismi efficaci per gestire la sicurezza su tutti gli asset nell'ecosistema. I contenitori dovrebbero essere popolati con strumentazione per applicare i controlli e le politiche di sicurezza. La sicurezza deve essere incorporata nel processo DevOps stesso, perché se si affida al programmatore l'implementazione della sicurezza, ognuno la farà in modo leggermente diverso, aumentando la complessità e la variabilità nel sistema. Il programmatore deve avere le capacità e i vincoli su cui deve sviluppare.\n\nGli sviluppatori dovranno comunque svolgere il lavoro di sicurezza, come assicurarsi di utilizzare strumenti di sicurezza adatti all'ambiente minaccioso specifico, ma il peso maggiore, la complessità, dovrebbe essere astratto nell'architettura DevOps.\n\nUna delle aree critiche in un ambiente teatrale complesso è la gestione dei dispositivi periferici, come il monitoraggio e l'aggiornamento del firmware. Garantire la sicurezza di tali dispositivi al fine di poter supportare la sicurezza dei dati e i profili e le politiche implementate nei sistemi su larga scala richiederà innovazione. Ecco perché attualmente l'ecosistema sta crescendo molto: per affrontare tale sfida.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Clifton","Steve Orrin"],"link":"/episode-EDT64-it","image":"./episodes/edt-64/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, discute in seguito alla puntata n. 2 con Greg Clifton, Director del Dipartimento della Difesa e dell'Intelligence di Intel, insieme a Steve Orrin, CTO per il settore federale di Intel, che mette a disposizione la sua competenza sulla sicurezza nei complessi ambienti di edge to cloud."},{"id":138,"type":"Episode","title":"Accelerare l'adozione del Cloud riducendo complessità e costi.","tags":["cloudmigration","cloud","compute","process","multicloud","aiven","cloudcost","technology"],"body":"\r\n\r\nDavid era precedentemente uno sviluppatore di applicazioni e si descrive come un \"ingegnere in recupero\". Quell'esperienza, insieme al suo lavoro con AWS e GCP in diverse aziende, gli fornisce le competenze necessarie per comprendere le sfumature di come gestire il cloud, come scalare quando ha senso finanziario e come affrontare molte delle sfide legate alla migrazione verso il cloud.\n\nMolte organizzazioni stanno passando al cloud, accelerando a causa delle conseguenze della pandemia da COVID. Grandi e piccole aziende lo stanno facendo in modo diverso. Le piccole aziende si stanno spostando nel cloud e lo stanno adottando il più velocemente possibile, acquisendo nuovi strumenti e pratiche migliori, ma c'è ancora molta migrazione nel data center. Durante la migrazione, però, spesso non approfittano di nessuno dei vantaggi del cloud. Quindi si stanno muovendo per essere trasformati digitalmente, ma devono chiedersi, quali sono i prossimi passi?\n\n## Riduzione dei costi\n\nCi sono molte cose che puoi fare e dovresti fare per ridurre i costi e evitare spiacevoli sorprese, come i costi che derivano dalle macchine virtuali non utilizzate. Nella cloud, se hai bisogno di un server, basta cliccare un pulsante e lo hai, ma se poi ti dimentichi che è acceso, potresti trovarsi ad affrontare una spesa di 10.000 dollari sui server un mese dopo. Un'altra cosa da tenere in considerazione è l'uscita di rete che può accumularsi, specialmente con i trasferimenti tra regioni se stai gestendo terabyte o petabyte ogni mese.\n\nLe notifiche di spesa possono aiutare a mitigare questi problemi.\n\nLe proiezioni di costo possono essere difficili a causa di problemi come l'ingresso gratuito, ma recuperare i dati è costoso. Anche l'eliminazione dei dati comporta un costo. Pertanto, le organizzazioni devono riflettere sugli avvertimenti riguardo a quanto dati inserire, il tipo di operazione e l'utilizzo.\n\nPer l'ottimizzazione dei costi, qualcosa su cui la leadership dell'ingegneria deve riflettere è che arriverai a un punto in cui il calcolo e il servizio gestito non saranno così costosi; la risorsa più costosa sono le persone. Quindi, come ottimizzare l'efficienza dei tuoi sviluppatori? Non vuoi che svolgano compiti ripetitivi e di routine.\n\nL'automazione è fondamentale qui, soprattutto per qualsiasi attività ripetitiva svolta con alta frequenza, così come per i servizi gestiti.\n\nOgni ciclo di vita di un'azienda arriva a un punto in cui deve decidere se investire e possedere tutte le operazioni, assumere un team di DevOps o sfruttare i fornitori di servizi gestiti. L'assunzione di competenze interne è costosa. Il punto di svolta è quando decidono quanto bene la piattaforma cloud si adatta alle loro esigenze. Di solito è meglio per le aziende prendere in considerazione il costo totale di proprietà, concentrarsi sui propri vantaggi competitivi e utilizzare servizi gestiti per altri servizi.\n\n## Ridurre la complessità\n\nUna delle complessità del cloud è che devi essere in grado di ricreare il tuo ambiente con distribuzioni affidabili e ripetibili. Questo non significa che devi andare sul sito web e fare clic su di esso; stai distribuendo il tuo ambiente da, ad esempio, uno script o un file YAML o TerraForm, e devi essere in grado di avviarlo e terminarlo rapidamente.\n\nDevi essere in grado di eliminare un server diventato sporco e ricrearlo in modo affidabile in uno stato pulito. Se qualcuno sposta i file di registro, modifica le configurazioni, cancella per errore un database, o se c'è un attacco di ransomware, devi essere in grado di riprodurre i tuoi ambienti o componenti del tuo ambiente per ridurre i tempi di inattività.\n\nIl pezzo critico consiste nel disporre di un piano basato su quanto velocemente hai bisogno di recuperare e su quanta quantità di dati hai bisogno per continuare. Ha senso per alcune industrie investire in un piano per trasferirsi rapidamente in una regione diversa. Devi valutare quanto sei disposto a investire in termini di tempo di recupero.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Esposito"],"link":"/episode-EDT65-it","image":"./episodes/edt-65/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, parte 1 di 2, Darren parla con David Esposito, Global Solution Architect di Aiven, riguardo all'accelerazione dell'adozione del cloud riducendo complessità e costi."},{"id":139,"type":"Episode","title":"Gestione della complessità nel Cloud","tags":["data","devops","compute","technology","process","devsecops","cybersecurity","aiven"],"body":"\r\n\r\n## Ridurre la complessità\n\nQuali pratiche aziendali dovrebbero essere implementate per gestire gli asset cloud e ridurre la complessità? In primo luogo, è necessario disporre di codice di infrastruttura e di distribuzioni automatizzate. Tutto ciò che segue è una conversazione per definire quali rischi ci sono per l'azienda, come mitigare questi rischi e quanto investire in questo ambito.\n\nPer alcune aziende, è fondamentale avere il massimo livello di disponibilità del servizio. Nel settore sanitario, ad esempio, potrebbe essere necessario avere i dati di backup in molteplici siti e tutti i servizi disponibili, poiché decisioni critiche per salvare vite potrebbero basarsi su tali dati. Ma se si opera nel settore dell'e-commerce in aprile, forse si può dedicare del tempo a quella regione malata perché le conseguenze non sono così gravi.\n\nNell'ambito dell'assistenza sanitaria, ha senso optare per il multi cloud anche se aumenta la complessità. Altre industrie che possono trarre vantaggio dal multi cloud sono quelle altamente regolamentate come i servizi finanziari, il settore petrolifero e del gas o le agenzie federali. In caso di incidente di sicurezza, possono disattivare uno e riattivarlo altrove.\n\nQuando si considera il multi-cloud, si deve tenere presente che ci sono alcune complessità legate alle differenze delle API. Se ti trovi su GCP e sai come distribuire tutto e stai pensando di passare ad AWS, devi riapprendere la piattaforma e il processo di distribuzione, magari anche scrivendo parte di quel codice. Per questa ragione, la containerizzazione è popolare perché consente di distribuire ovunque. Diventa però più complesso con altri servizi; ad esempio, Postgres ha diverse configurazioni su AWS rispetto a GCP, forse con diverse versioni di patch, differenti impostazioni di rete e differenti estensioni. Quindi, un servizio su un cloud non è uguale ai servizi su un altro.\n\nInoltre, gli ambienti containerizzati non sono ideali per ogni situazione, e una situazione ideale diventa ancora più importante man mano che si scala. Se stai utilizzando Kafka e invii 1.000 messaggi al secondo, il proprio container va bene. Ma se inizi a inviare oltre un milione di messaggi al secondo, un gigabyte, allora si tratta di una conversazione diversa.\n\n## Sicurezza\n\nLa sicurezza nel cloud è una bestia diversa rispetto alla sicurezza nel proprio data center. La cosa più importante da considerare è il flusso dei dati al di fuori delle proprie mura. È necessario avere controlli di sicurezza adeguati per garantire che i dati non fuoriescano o subiscano accessi non autorizzati, oltre ad assicurarsi che ci siano requisiti di conformità. Questo richiede formazione perché le misure di sicurezza per i data center in loco non si traducono direttamente nel cloud. Ad esempio, i contenitori S3 sono criptati a riposo, ma non se si ha accesso programmatico attraverso bucket esposti pubblicamente.\n\nInoltre, è necessario sapere cosa fanno i fornitori di servizi. Ad esempio, Aiven esegue database su GPU EC2, GCP Compute o Azure. Quando archiviano i dati su disco, c'è un livello di crittografia effettuato dal fornitore di cloud, quindi i dati sono crittografati a riposo. Successivamente, Aiven applica un ulteriore livello di crittografia con le proprie chiavi gestite, quindi i dati sono criptati a doppio livello a riposo e tutti i dati in transito sono crittografati. Tutto ciò che viene inviato al server è crittografato per quel server specifico e quando un server viene dismesso, viene bloccato con la chiave di Aiven e la chiave del fornitore di cloud.\n\n## Aiven\n\nDavid si è unito ad Aiven come parte del team di architettura delle soluzioni quando ha visto che l'azienda offriva soluzioni cloud migliori di chiunque altro avesse visto, basandosi sulla sua precedente esperienza con Kafka gestito e altre tecnologie open source. La missione di Aiven è di rendere migliore la vita degli sviluppatori. Offrono una prova gratuita, con Kafka pronto per la produzione in soli cinque minuti. Hanno anche articoli di aiuto e tutorial per guidarti, quindi puoi inviare un messaggio Kafka nel cloud con le migliori pratiche native per il cloud in meno di dieci minuti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Esposito"],"link":"/episode-EDT66-it","image":"./episodes/edt-66/it/thumbnail.jpg","lang":"it","summary":"In questo episodio, parte 2 su 2, Darren continua la sua conversazione con David Esposito, Global Solution Architect di Aiven, riguardo all'accelerazione dell'adozione del cloud, riducendo complessità e costi."},{"id":140,"type":"Episode","title":"5G Passato, Presente e Futuro","tags":["5g","comms","wifi6"],"body":"\r\n\r\nLeeland ha lavorato nell'industria delle telecomunicazioni per 20 anni. Appena uscito dall'università, è stato reclutato per lavorare per il Dipartimento della Difesa degli Stati Uniti dopo che si sono impressionati del suo lavoro sull'applicazione del multiplexing Bluetooth all'interno di un'automobile, riducendo le dimensioni dei cablaggi. Invece di lavorare con le auto come aveva originariamente pianificato, ha finito per lavorare con il Dipartimento della Difesa nello sviluppo di tecnologie wireless avanzate per i soldati.\n\nIn quel periodo, la tecnologia cellulare era in transizione da 2G a 3G. Non veniva chiamata WiFi, ma rete LAN senza fili, e c'era una tecnologia nascente chiamata Bluetooth che stavano cercando di utilizzare per fornire ai soldati la capacità di raccogliere informazioni all'interno dello spazio di battaglia.\n\nLeeland lasciò il Dipartimento della Difesa tre anni dopo per fare un lavoro pratico con la tecnologia al fine di ottenere una migliore comprensione. Iniziò a lavorare per Sprint e rimase nell'industria delle telecomunicazioni per 13 anni progettando tecnologia per reti wireless, prima di unirsi a Intel nel 2017 per lavorare sul 5G.\n\nFino alla metà degli anni '90 c'era poco utilizzo dei cellulari. I telefoni \"mattoni\" degli anni '80 erano enormi a causa delle dimensioni delle batterie e costavano molto. Si sono evoluti in telefoni a \"borsa\" nei primi anni '90, che erano migliori, ma potevi solo sperare che funzionassero per fare una chiamata telefonica.\n\nCome è entrata in gioco la tecnologia 2G, sono state sviluppate nuove funzionalità basate sulle esigenze dei clienti, come la trasmissione di testo e i giochi. Il dispositivo poteva effettuare una trasmissione dati a basso costo con le tecnologie TDMA (accesso multiplo a divisione di tempo) e GSN, ad esempio. A metà degli anni '90, aziende come Sprint sono entrate in scena e l'uso del cellulare è diventato più diffuso. Nei primi anni 2000, c'è stata una transizione significativa con l'aspettativa dei clienti che internet fosse disponibile sui telefoni come lo era sui computer portatili.\n\n3G ha portato capacità nominali di banda larga dove era possibile utilizzare l'internet in qualche modo, ma la capacità principale era la trasmissione di immagini. Il nome \"3G\" fu coniato in questo periodo e fu in questo momento che entrarono in gioco le norme del corpo 3GPP.\n\nNel 2008, le compagnie telefoniche hanno iniziato a considerare l'installazione di infrastrutture che non si basavano su grandi torri per le celle, ma su un sistema più distribuito di un concentratore di unità di banda di base con antenne collegate tramite fibra ottica ai pali telefonici. Questo ha iniziato la transizione verso il vero broadband, dal 3G al 4G.\n\nQuesta tecnologia dovrebbe ricevere merito per il boom economico del 2010 al 2020 perché, grazie al 4G, aziende come Amazon e Netflix sono evolute e fiorite.\n\nIl 5G libera i servizi da una \"prigione\" monolitica RAN e apre il campo perché il 5G fornisce architetture open source con una base definita dal software. Le pile di software possono ora essere sviluppate ed integrate in una soluzione software completa. Dal momento che non è legato a un'architettura monolitica, il 5G può fornire servizi e reti private autonome.\n\nQuesta grande flessibilità consentirà ai fornitori di servizi di telecomunicazioni e ai loro operatori di migliorare i servizi e offrire varie nuove capacità, inclusa l'introduzione dell'accesso al calcolo periferico.\n\nCosa succederà dopo? Leeland vede un movimento lontano da \"G\", in quanto non dà abbastanza credito all'evoluzione della tecnologia poiché non ci sono più vere e proprie divisioni in termini di chi può implementare reti. La tecnologia e gli ambiti di utilizzo sono ampi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown"],"link":"/episode-EDT67-it","image":"./episodes/edt-67/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, parla con Leeland Brown, Direttore Tecnico di 5G, Intel Federal, riguardo al passato, al presente e al futuro del 5G, con particolare enfasi sul suo utilizzo con il Dipartimento della Difesa. Parte 1 di 2."},{"id":141,"type":"Episode","title":"5G nella difesa","tags":["5g","dod","compute","technology","cloud","edge","comms"],"body":"\r\n\r\nAll'inizio del secolo, il Dipartimento della Difesa stava cercando modi per applicare le tecnologie 2G, LAN wireless e Bluetooth in applicazioni che consentissero ai soldati di raccogliere informazioni nel campo di battaglia. Nel 2021, tali capacità sono ancora ricercate. Il Dipartimento della Difesa sta ora esaminando attentamente il 5G, poiché si è allontanato da costrutti monolitici come l'utilizzo di un'architettura RAN e si è orientato verso architetture definite dal software. Vi è la flessibilità di costruire nuove capacità più rapidamente e di adattarle a diversi casi d'uso.\n\nIl lato commerciale del 5G è guidato da strategie volte ad aumentare i ricavi in fase di sviluppo. Ciò non sempre coincide con le esigenze missionarie del governo federale o del Dipartimento della Difesa, quindi le linee tra i due mondi stanno diventando sfocate: ad esempio, AT&T e Verizon stanno esaminando casi d'uso federali, mentre Lockheed Martin, con il suo programma 5G Domino, sta esplorando lo spazio commerciale. La differenza sta in chi comprende la missione e chi agisce con l'obiettivo del profitto.\n\nAttualmente, il novanta percento delle implementazioni commerciali di 5G sono reti non autonome, il che significa che il 5G è ancora collegato a un core di pacchetti evoluto 4G esistente. Il Dipartimento della Difesa è interessato a reti autonome con un completo core 5G, una rete di accesso radio 5G e dispositivi 5G. Può esserci una rete autonoma per un gruppo di soldati, insieme a stazioni base di piccolo formato per piattaforme veicolari e svariati domini protetti, persino droni dispiegati con qualche tipo di punto di accesso 5G e applicazioni spaziali.\n\nQuesta capacità di scalare attraverso molteplici casi d'uso e i loro differenti tipi di carico di lavoro è applicabile anche al lato commerciale. Uno dei problemi più grandi, tuttavia, è chi possiede la frequenza. Alcuni spettri liberi sono disponibili con un raggio limitato, ma queste bande, come le bande ISN, non sono licenziate e sono molto affollate. La regola è che devi dare e accettare interferenze e far funzionare la tua tecnologia intorno a questo, ma la condivisione del sistema dinamico è possibile. Tuttavia, per casi d'uso federali, non puoi essere bloccato nelle operazioni negli Stati Uniti poiché la maggior parte dei soldati è schierata all'estero.\n\nLeeland prevede che il 5G diventerà integrato nella vita di tutti, a volte anche quando non si è consapevoli della sua presenza. Piattaforme di riconoscimento dei pattern, come ad esempio il riconoscimento facciale e i veicoli autonomi, saranno tutti collegati tramite il 5G. L'accesso a banda larga verrà integrato in un'unica esperienza senza soluzione di continuità, collegata non solo al tuo cellulare, ma anche alla tua auto e alla tua casa. La necessità di avere il telefono in mano si ridurrà drasticamente, poiché inizieremo a vedere punti di accesso wireless in tutte le aree della nostra vita.\n\nLeeland prevede anche che la lettera \"G\" scomparirà man mano che la tecnologia si espande ed evolve.\n\nPer saperne di più sul 5G, le persone tecnicamente inclini possono consultare gli standard 3GPP per vedere i casi specifici. È possibile leggere una specifica e comprendere la differenza tra la release 14 e la release 15 e cosa ciò significa per l'intera industria. Inoltre, ci sono molte informazioni disponibili via internet, come ad esempio white paper. Inoltre, Leeland si offre come punto di contatto.\n\nLeeland vorrebbe che il prossimo passo sia un appello all'azione per rendere le reti più resilienti attraverso l'adozione di nuove tecnologie. Durante le emergenze, che siano disastri naturali o attacchi terroristici, la resilienza è necessaria per i soccorritori, così come per le persone che cercano semplicemente di raggiungere le loro famiglie.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Leland Brown"],"link":"/episode-EDT68-it","image":"./episodes/edt-68/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, continua la sua discussione con Leeland Brown, Direttore Tecnico di 5G, Intel Federal, riguardo al passato, presente e futuro del 5G, con un'enfasi sul suo utilizzo con il Dipartimento della Difesa. Parte 2 di 2."},{"id":142,"type":"Episode","title":"Proteggere il Data Center attraverso l'Edge","tags":["cybersecurity","edge","compute"],"body":"\r\n\r\nUno sguardo olistico alla sicurezza include l'intera infrastruttura, dal cloud environment fino all'estremità. Se non riesci a proteggere il client, non puoi proteggere l'azienda, quindi è essenziale avere conversazioni sincere in modo accessibile, senza gergo, sulla sicurezza.\n\nSono passati i tempi in cui a un dipendente veniva spedito un laptop in una gabbia IT, quindi configurato e consegnato dal reparto IT. A volte i dipendenti non arrivano neanche sul posto di lavoro, quindi i dispositivi devono essere consegnati alla porta di qualcuno. Devono essere forniti delle disposizioni per assicurarsi che siano sicuri e non siano stati manomessi. Dal punto di vista della sicurezza, questo rappresenta un problema sfidante. La catena di approvvigionamento è problematica. C'è meno controllo sui dispositivi e su come vengono distribuiti.\n\nIl passaggio improvviso al lavoro da casa a causa della pandemia di COVID ha richiesto una risposta rapida senza precedenti a questo problema. Ci sarebbero voluti anni se fosse stato un progresso naturale, ma la situazione non ha consentito alternative; l'informatica ha dovuto farsi carico della situazione.\n\nQuando Camille lavorava nel gruppo IoT, cercavano di risolvere i problemi di connettività e gestione tra i dispositivi. Ecosistemi complessi come i parchi eolici, le miniere sotterranee e i dispositivi medici impiantati sono difficili da aggiornare quando la connettività è sporadica. Stavano cercando di risolvere questi problemi di connettività ai margini, e quando è scoppiata la pandemia di COVID, l'intersezione tra OT e IT è improvvisamente diventata il centro di tutti i reparti IT aziendali.\n\nMentre alcuni dei clienti di Darren stavano cercando di trovare il modo migliore per collegare OT e IT, è arrivato il COVID e parte di tutto è crollato, causando violazioni della sicurezza.\n\nMolte persone hanno rapidamente implementato un sistema di lavoro da casa e si sono occupate della sicurezza successivamente, a seconda del livello di maturità dell'organizzazione. C'è stato anche un enorme spostamento verso il cloud. Attualmente, c'è un po' di oscillazione del pendolo indietro a causa di violazioni come gli attacchi di ransomware. Queste violazioni sono avvenute nel cloud, principalmente perché le persone non capivano la responsabilità condivisa per la sicurezza. Ora, alcune organizzazioni stanno riflettendo due volte prima di spostare i loro dati critici nel cloud. Potrebbero spostare i carichi di lavoro lì, ma mantengono i dati più sensibili a casa.\n\nUn'altra recente evoluzione è l'importanza della percezione del cliente. Potresti fare le giuste domande sulle specifiche hardware e sulle diverse strati di protezione software, ma devi anche considerare la percezione del tuo cliente riguardo a dove conservi i dati e il perché, chi li protegge e come vengono protetti.\n\nUn problema ancora più grande sono le organizzazioni che non riescono a rispondere a nessuna di queste domande. A volte non sanno neanche dove si trovino i loro dati. Queste organizzazioni dovrebbero considerare ciò come un punto di partenza per capire quali lavori devono ancora essere portati a termine.\n\nAlcuni nuovi problemi aggravano questo problema che l'industria non ha ancora affrontato, come ad esempio le videoconferenze. La registrazione della riunione viene salvata su un laptop, ma è anche su qualche posto nel cloud. Chi ha accesso ad essa? Quali sono le protezioni? Per quanto tempo sarà lì?\n\nUno dei principi della sicurezza è la consapevolezza se il tuo dispositivo è sicuro. Una delle sfide emerse con la situazione del COVID è che molti negozi IT sono riluttanti ad aggiornare i sistemi. Non vogliono interrompere un sistema, che si tratti di un server o di un cliente. Non aggiornare per patch di sicurezza è un errore.\n\nIl compito di Intel è lavorare con partner e compagni di viaggio per rendere più diretta e affidabile l'attività di aggiornamento, in modo che le persone abbiano fiducia che funzioni e che non ci siano problemi nel processo. L'industria ha compiuto progressi considerevoli nell'ultimo paio di anni nel rendere il processo di aggiornamento più sistematico e prevedibile.\n\nUn'altra parte del lavoro consiste nell'addestrare le persone a comprendere che la sicurezza non si arresta quando un dispositivo viene spedito dal produttore al cliente. La sicurezza si estende per tutta la durata del dispositivo. Quello che era considerato una sicurezza di livello mondiale al momento della spedizione, potrebbe non esserlo più mesi o anni dopo. Le aziende dovrebbero aggiornare le proprie macchine due volte l'anno per mantenerle al sicuro.\n\nLe persone si agitano nell'eseguire gli aggiornamenti perché potrebbero accadere cose impreviste. Intel effettua una convalida su larga scala per prevenire problemi, che sia con migliaia di macchine nei propri laboratori o con i partner OEM sparsi in tutto il mondo. La convalida completa assicura che le misure di mitigazione funzionino per proteggere dalle vulnerabilità e che non danneggino il sistema. Intel ha fatto un investimento significativo nel collaborare con i partner del suo ecosistema e nell'imporre standard nell'industria, cercando di migliorare in futuro l'esperienza dell'utente sviluppando la capacità di effettuare gli aggiornamenti senza riavviare.\n\nEducare i clienti sul perché stai chiedendo loro di effettuare un aggiornamento può aiutare molto. Se capiscono che hai riscontrato una vulnerabilità e che potrebbero essere esposti a un potenziale attacco, molto probabilmente vorranno farlo.\n\nIn generale, le persone sembrano essere disposte ad aggiornare i loro cellulari perché non sono così preoccupate che qualcosa non funzionerà successivamente, ma è comunque una sfida dal lato del PC e dei server. Alcuni di questi problemi sono legati ai modelli di utilizzo. Anche se è raro che i dati esistano solo su un laptop, questa mentalità è diffusa. Quando i dati esistono nel cloud su un cellulare, la percezione è che saranno sempre lì. Inoltre, le persone tendono a svolgere lavori più immersivi e coinvolgenti sui laptop rispetto ai telefoni, quindi sono più sensibili a questo aspetto. Una volta che la percezione cambia e le persone si rendono conto che i dati sul loro laptop esistono anche nel cloud, gli aggiornamenti sono più ampiamente accettati. Quindi, nella realtà, l'industria deve combinare soluzioni tecniche e cambiamenti di mentalità quando si tratta di sicurezza.\n\nIl modo in cui le cose stanno evolvendo è un po' un ibrido. Nuovi modelli di apprendimento come il learning federato stanno affrettandosi per contribuire a risolvere problemi come le preoccupazioni per la privacy. I modelli vengono spinti verso il limite invece che far spostare i dati nel data center. Ad esempio, un sistema di imaging medico in un ospedale in cui i dati rimangono fermi e il modello viene per analizzarli. Stiamo iniziando a vedere questo nelle applicazioni industriali, dove le macchine si trovano sul limite e diventano il server. Conserveranno i dati in loco e faranno addestramento e aggiornamenti. Quindi ci saranno dispositivi intelligenti sul margine, che lavorano con i dati grezzi, e la domanda è: come si può garantire la sicurezza di tutto ciò?\n\nUn'altra tendenza nella sicurezza, una che non è iniziata con la pandemia da COVID ma è indubbiamente stata accelerata da essa, è proteggersi dagli attacchi fisici. Storicamente, la sicurezza si è concentrata su ciò che potrebbe accadere via cavo, come un attacco di rete o un'applicazione maligna. Con i dispositivi IoT presenti sul mercato senza alcuna presenza umana o supervisione, dobbiamo proteggere i dati e i dispositivi per evitare manomissioni. Questa è una sfida difficile.\n\nOggi, non puoi pensare in modo olistico alla sicurezza a meno che non stia affrontando anche la privacy. Una complicazione è che la privacy può talvolta essere in conflitto diretto con la sicurezza. Non vi sono regolamenti o standard concordati a livello mondiale, quindi le organizzazioni devono capire come operare: puntare al denominatore comune più alto o affrontare ogni requisito geopolitico? Per complicare ulteriormente le cose, le leggi e i regolamenti sono in costante cambiamento.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Tom Garrison","Camille Morhardt"],"link":"/episode-EDT69-it","image":"./episodes/edt-69/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, discute la sicurezza del data center attraverso il perimetro con i colleghi dirigenti Intel e i conduttori del podcast Tom Garrison, VP della sicurezza client, e Camille Morhardt, Direttore dell'innovazione e della comunicazione della sicurezza."},{"id":143,"type":"Episode","title":"La sicurezza del lavoratore a distanza","tags":null,"body":"\r\n\r\n## Modalità di funzionamento del telelavoro\n\nI modalità di lavoro per i telelavoratori non sono nuove, che sia utilizzando un dispositivo come terminale (VDI), facendo parte della rete interna o come portale per servizi/software (SAAS); ciò che è nuovo è la moltitudine di dipendenti, collaboratori e partner che ora utilizzano gli ambienti esistenti per svolgere il proprio lavoro principale, anziché solo una selezionata e gestibile minoranza. La sicurezza è una sfida in tutte queste modalità di lavoro. Le organizzazioni devono individuare il modo migliore per implementare le proprie capacità esistenti per garantire e proteggere l'accesso, i dati, i dispositivi e gli utenti.\n\n## Minacce del telelavoro.\n\nAlcune delle minacce alla sicurezza sono quelle che sono sempre state presenti con il telelavoro: la sicurezza del dispositivo finale e dei dati, il punto di accesso e l'accesso ai servizi aziendali. Nel adattarsi all'ambiente COVID-19, però, sono emersi nuovi problemi a causa del grande numero di persone che ora fanno telelavoro e della frenetica corsa per consentirlo.\n\nUn problema riguarda i lavoratori a casa, in ambienti non protetti su reti che non erano mai state pensate per essere utilizzate al di fuori dell'azienda. Questo porta a attacchi mirati di phishing e malware. Un altro problema è l'introduzione di nuovi strumenti, come quelli per la collaborazione e le videoconferenze, che possono esporre l'azienda e i dati ad attacchi e uso malevolo. Fondamentalmente, c'è ora un'area di attacco aumentata, molto più grande di quanto la maggior parte delle organizzazioni avesse inizialmente previsto, e nuovi ambienti che non facevano parte del piano originale.\n\n## Soluzioni per la sicurezza del telelavoratore\n\n## Porta il tuo Dispositivo (BYOD)\n\nUno dei problemi più difficili da affrontare è quando i lavoratori utilizzano i propri dispositivi. La sfida principale è che questi sono dispositivi non gestiti senza tutti gli agenti di sicurezza in esecuzione e gestiti dall'IT; il dispositivo è di proprietà e gestito dall'utente. Potresti avere la possibilità di caricare alcuni agenti o avere qualche tipo di applicazione delle politiche, ma c'è solo tanto che puoi fare senza ostacolare il lavoratore nell'utilizzo come dispositivo personale. Quindi come si può proteggere un utente con un BYOD?\n\nAssicurati che queste basi siano in atto: Aggiorna regolarmente le ultime patch come requisito, impone un buon controllo degli accessi per la tua azienda e i servizi, implementa l'autenticazione a più fattori e circonda i tuoi asset con le giuste protezioni, come il gestionale dei diritti d'uso dell'azienda per il controllo degli accessi ai dati e l'applicazione di un controllo degli accessi basato su politiche agli endpoint.\n\nUn'altra opzione per ridurre il tuo rischio potrebbe essere quella di limitare l'accesso diretto ai servizi aziendali e far lavorare gli utenti in un ambiente SASS.\n\n## Punti finali e ambienti non sicuri.\n\nLa soluzione migliore per molti di questi problemi sarebbe un client enterprise ricco di funzionalità, ma ci sono ancora rischi da considerare. I lavoratori stanno utilizzando un dispositivo che è una estensione gestita della rete aziendale. La sicurezza può essere implementata con un avvio sicuro, crittografia del disco completo, protezione dei dati, firewall locali e l'applicazione di aggiornamenti software. Il rischio, tuttavia, deriva dal fatto che molte organizzazioni già impiegano lavoratori remoti, come venditori o ingegneri in campo, che potrebbero non avere lo stesso livello di sicurezza dei dipendenti che non sono mai stati destinati a lasciare l'edificio, come quelli del dipartimento finanziario e delle risorse umane.\n\nLe organizzazioni devono essere vigili nel garantire che tutti i lavoratori abbiano ora la stessa sicurezza, o persino aggiungere ulteriori livelli di protezione di cui i lavoratori hanno bisogno per lavorare in reti non sicure. L'autenticazione a più fattori ora dovrebbe essere un requisito, mentre il controllo delle politiche dei dispositivi terminali e la gestione dei diritti aziendali sono ora più importanti che mai.\n\nStiamo assistendo a innovazioni in questa area, come un cliente che fornisce ai nuovi dipendenti non solo laptop, ma anche un router gestito per evitare reti non protette.\n\n## VDI Systems & Cloud Services (Sistemi VDI e Servizi Cloud)\n\nImplementare la sicurezza per i sistemi VDI e i servizi cloud include le nozioni di base della sicurezza: protezione dei dati, sicurezza della virtualizzazione sia per il data center aziendale che per i punti di accesso, sicurezza delle applicazioni, avvii sicuri, patching e crittografia di rete. La chiave è effettuare un'indagine accurata dell'azienda e dei servizi cloud che vengono implementati per i dipendenti e assicurarsi che siano tutti sicuri allo stesso modo. Ogni applicazione, anche quelle non fondamentali, rappresenta un possibile punto di attacco.\n\n## Clienti \"As-a-Service\"\n\nI clienti del SASS utilizzano servizi nel cloud e anche applicazioni sul loro client ricco, quindi ci sono alcune ulteriori questioni di sicurezza di cui preoccuparsi. Dovrebbe esserci una protezione adeguata dei dati nella gestione dei diritti aziendali (ERM) per l'accesso ai dati attraverso i servizi cloud e il ritorno al data center. La protezione da entrambi i lati è cruciale. L'accesso del cliente ai servizi cloud dovrebbe essere protetto mediante autenticazione a più fattori e crittografia di rete. L'accesso del servizio cloud al cloud privato del centro dati aziendale e alle risorse aziendali dovrebbe essere protetto anche ai livelli di rete, accesso ai dati e applicazione. Comprendere come i clienti utilizzano i servizi e a quali dati accedono è dove entrano in gioco le decisioni di ERM.\n\n## Utilizzo improprio e abuso di insider.\n\nL'IT dovrebbe utilizzare una varietà di metodi per gestire la minaccia e il rischio di errori, uso improprio e azioni maliziose da parte di interni. Il controllo degli accessi basato su politiche e l'applicazione di misure cautelari dalle applicazioni ai dati sia a livello aziendale che di cloud è importante per prevenire l'uso improprio e abuso degli utenti già autenticati. La principale difesa che ha l'IT è l'auditing e il monitoraggio dell'intelligence sulle minacce. La gestione di queste informazioni in tutta l'azienda e il cloud nel corso di un lungo periodo di tempo può essere molto efficace nel rilevare comportamenti anomali.\n\nNon c'è dubbio che dobbiamo pensare in modo diverso adesso riguardo alle questioni di sicurezza con il telelavoro. Le nostre principali raccomandazioni sono: in primo luogo, implementare la tecnologia che avete testato; in secondo luogo, educare gli utenti; e in terzo luogo, attivare l'autenticazione a due fattori e proteggere i vostri dati su larga scala. Se riuscissimo a fare queste tre cose, potremmo ridurre il rischio e essere meglio preparati per il futuro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT7-it","image":"./episodes/edt-7/it/thumbnail.png","lang":"it","summary":"Con il grande cambiamento delle persone che ora lavorano da casa invece che in ufficio, la sicurezza è una preoccupazione crescente per molte organizzazioni IT. In questo episodio, Steve Orrin, CTO di Intel Federal, e Darren discutono delle minacce alla sicurezza e delle soluzioni per aiutare a proteggere il telelavoratore e i data center aziendali."},{"id":144,"type":"Episode","title":"Governance dei dati moderna","tags":["datagovernance","immuta","dataaccess","identitymanagement","cybersecurity","data","technology"],"body":"\r\n\r\nMan mano che le organizzazioni migrano verso il cloud, il modo in cui pensiamo ai dati e al loro utilizzo sta cambiando completamente; negli ultimi cinque o sei anni, l'intero strato infrastrutturale è cambiato. Le necessarie prestazioni, scala, regole e il numero di utenti che desiderano combinare i dati sono aumentati in modo esponenziale. Gestire tutto ciò su larga scala non è un compito banale, ed è qui che entra in gioco Immuta.\n\nCol tempo, l'industria ha ripensato il paradigma dell'archiviazione dei dati. In passato, ogni team di dati costruiva prodotti dati in modo isolato, per poi consegnarli a una unità aziendale. L'unità aziendale avrebbe avuto i suoi dati appropriati che fornivano un servizio di qualità a loro. Ora, all'improvviso, vogliamo che chiunque possa combinare i dati in tutta l'azienda: analisti aziendali, scienziati dei dati, ingegneri dei dati, ecc. Il numero di utenti è cambiato, e non si tratta più di applicazioni di ricerca; si tratta di trasformare e di flussi di dati.\n\nQuesta è una differenza che richiede una diversa qualità di servizio, tempo e livello di sofisticazione che non sono mai esistiti prima. Diventa ancora più complesso quando si aggiungono leggi sulla privacy, classificazione dei dati e le regole e i regolamenti in continua evoluzione.\n\nCiò che Immuta sta cercando di fare è rendere possibile per qualsiasi utente combinare potenzialmente qualsiasi set di dati, interno o esterno all'organizzazione, per ottenere delle intuizioni. È tutto una questione di scala. La politica deve essere separata dalla piattaforma per scalare la politica per tutti questi nuovi utenti e per tutte le diverse combinazioni di dati. Sicurezza, privacy e governance sono importanti, ma se non si riesce a eseguire, nessuno sarà contento.\n\nUna lezione che Immuta ha imparato fin da subito è che il proxy non funziona. È come cercare di spostare petabyte di dati attraverso una cannuccia: diventano un collo di bottiglia. È facile incolpare il middleware ogni volta che c'è un problema perché sono sempre il collo di bottiglia tra gli strumenti e i dati. Questo è un problema classico del middleware.\n\nIl secondo problema di quel paradigma di progettazione è che, con la virtualizzazione dei dati classici, funzionava perché c'era un chiaro insieme di dati. Tuttavia, quando ci sono petabyte di dati, l'approccio \"dammelo tutto e lo sistemeremo\" si rompe molto rapidamente a causa delle dimensioni stesse dei dati, nonché di tutte le regole e politiche ad esso associate.\n\nNella virtualizzazione normale, devi incorporarti nativamente nell'infrastruttura di calcolo cloud in Snowflake, in Synapse, ecc. Invece di mettere questa fascia di astrazione sopra questi diversi strumenti, la fascia di astrazione si trova sul lato delle politiche.\n\nLa politica è valida solo quanto la capacità di metterla sotto esame. È come una catena di prove. La chiave è poter dimostrare che l'utente si è attenuto o non si è attenuto all'infrastruttura informatica. Con la moderna governance dei dati, si sta scalando la politica interna ed unificando le verifiche a causa del livello di complessità del fatto che molte persone stanno eseguendo così tante azioni con i dati. La verifica della politica deve essere drasticamente semplificata o altrimenti risulta impossibile determinare l'aderenza.\n\nEsistono tre tipi di politiche da considerare: operative, regolamentari e contrattuali. Un esempio di quanto tutto ciò possa diventare complicato è guardare a un'azienda come Cummins. Se si modernizzano nel cloud, devono considerare le regolamentazioni per ogni mercato. Per uno dei loro motori, cosa succede se devono scrivere una regola personalizzata per ogni paese in cui si trovano, ma anche per ogni paese in cui non si trovano, perché quei paesi non dovrebbero essere in grado di vederlo? Questo non è scalabile quando si parla di decine di migliaia di fonti di dati per gli schemi, che sono in continuo cambiamento. Ci sono petabyte di telemetria provenienti da questi motori.\n\nCiò che vorresti scrivere è che puoi vedere i dati solo una volta per il paese in cui risiedi e poi si applicano ovunque. Ma non è così che viene fatto. Quindi scriverebbero circa 700 politiche per un oggetto dati, quando dovrebbe essere solo una. Seguire tutte le politiche e le normative che cambiano per ogni fonte dati sarebbe quasi impossibile. Saresti fuori conformità tutto il tempo.\n\nNon è mai stato così facile globalizzare un'azienda come oggi, e i clienti di Immuta si aspettano che essa sia in grado di gestire infrastrutture a livello globale su qualsiasi cloud. Dovrebbero essere in grado di spostare i loro dati su qualsiasi cloud e essere completamente conformi alle normative.\n\nImmuta applica regole ai dati tramite etichette anziché utilizzare i dati grezzi perché ogni dominio ha il proprio gergo per classificare e parlare dei propri dati. Perciò hanno iniziato a classificare e etichettare in modo generico per applicare modelli concettuali generali, come per HIPAA. Tuttavia, questi modelli non sono ancora infallibili e c'è ancora molta strada da fare.\n\nLa visione di Matt come CEO di Immuta è arrivare a uno stato in cui i domini possono condividere le loro politiche. Ad esempio, nel settore sanitario, c'è una buona ragione per cui Moderna e Pfizer vorrebbero lavorare insieme. Potrebbe esserci un accordo su come gestire i controlli sui dati del mondo reale con l'ambito accademico. Quindi, se ci fosse una politica coerente che potesse essere condivisa e generata dal crowd in un \"concept policy cloud\", sarebbe la cosa giusta da fare.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Carroll"],"link":"/episode-EDT70-it","image":"./episodes/edt-70/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, discute della realtà e del futuro del governo dei dati moderno con Matthew Carroll, CEO di Immuta."},{"id":145,"type":"Episode","title":"Governance dei dati moderna","tags":["datagovernance","data","immuta","dataaccess","identitymanagement","ceo","technology","process"],"body":"\r\n\r\nNella moderna governance dei dati, la prima premessa è che è necessario separare la politica dalla piattaforma.\n\nIl secondo è che non può esserci alcuna ontologia. Se qualcuno prova a creare uno schema universale di tutto, è impossibile, ma è necessario avere uno schema per applicare una politica. Quindi, se un utente desidera unire due colonne, è necessario avere una nuova politica. I dati sensibili devono essere scoperti, sia attraverso identificatori diretti che indiretti. Gli identificatori indiretti sono più difficili e devono essere applicate delle tecniche per mitigare il rischio di attacchi di collegamento.\n\nLa terza premessa è l'introduzione di una serie di tecniche per migliorare la privacy, come la mascheratura, la censura, l'autorizzazione, ecc.\n\nQuesti strumenti sono automatizzati come parte della moderna governance dei dati. Un esempio parallelo è come una volta si doveva essere maghi per rimuovere l'effetto occhi rossi da una foto. Ora, fai clic su un pulsante e l'effetto occhi rossi scompare. È la stessa cosa per la privacy. Abbiamo bisogno di quel semplice pulsante per trovare automaticamente un potenziale identificatore indiretto quando c'è un rischio di riesposizione superiore a molto basso.\n\nOltre alla privacy, ci sono una miriade di altre cose con i dati che dovrebbero essere automatizzate prima della classificazione. Sebbene Immuta non approfondisca la trasformazione dei dati e questi flussi di dati, forniscono un'API e un'interfaccia a riga di comando. Gli ingegneri che stanno costruendo queste pipeline possono fare il loro lavoro, e Immuta fornirà loro le regole, e l'aggiornamento delle regole può far parte della pipeline. Vogliono essere un condotto per quel livello.\n\nCi sono alcuni nuovi ruoli in quest'ambito come il responsabile dei dati e l'ingegnere della governance dei dati, che sono separati dall'ingegnere dei dati. E poi gli utenti dei dati sono veramente tre utenti separati con tre bisogni separati.\n\nPrima di tutto, ci sono scienziati dei dati che hanno competenze specializzate e hanno bisogno dei dati in modo specifico. A volte hanno bisogno di strumenti specifici e di un ambiente di calcolo specifico in qualche parte del mondo per portare a termine la loro missione.\n\nD'altra parte, gli ingegneri dei dati e gli ingegneri analitici, l'uno costruendo i flussi di lavoro e l'altro sostenendo i flussi di lavoro, hanno bisogno di accesso rapido a un sistema emergente quando qualcosa si rompe. Lo inseriscono in un flusso di lavoro e lo consegnano a qualcuno, controllando che sia aggiornato.\n\nInfine, ci sono i governatori che stanno cercando di tenere il passo con le regole.\n\nQuesti utenti hanno tutte opinioni e esigenze molto diverse riguardo alla governance. Quando si applica una nuova governance, la cosa più importante è considerare questi gruppi come portatori di interessi separati.\n\nSe si pensa a tutti questi ruoli in modo binario, come ingegneri dei dati, alla fine si verificano molte riunioni, quindi è impossibile scalare. Abbiamo bisogno di creare una relazione simbiotica tra operazioni dati, scienza dei dati, analisi dei dati e governance. Un modello di esempio è Salesforce o ServiceNow, dove c'è un intero flusso di lavoro dall'inizio alla fine e non sono necessarie riunioni. Questo sarebbe vero data ops.\n\nImmuta ha, filosoficamente, un approccio basato sull'attributo piuttosto che basato sul ruolo. Il problema con un approccio basato sul ruolo è che si accumulano sovraccarichi man mano che si aggiungono inevitabilmente ruoli. Un'organizzazione farmaceutica, ad esempio, aveva oltre 800.000 ruoli perché i ruoli non possono mai essere eliminati a causa della necessità di riprodurre le prove sui farmaci. Il sovraccarico dei ruoli può diventare rapidamente un problema di scala.\n\nL'accesso basato sugli attributi è la chiave per contrastare questo problema. Piuttosto che aggiungere costantemente ruoli, gli utenti hanno attributi specifici e coerenti. Ad esempio, un attributo di un utente potrebbe essere che sono contrassegnati in modo che possano vedere solo il proprio stato. Con l'accesso basato sui ruoli, ogni stato, che sia visibile o meno, dovrebbe essere scritto nel sistema. Questa moderna gestione dell'identità è molto scalabile. L'accesso basato sugli attributi semplifica il numero di politiche che devono essere redatte e aiuta con le prestazioni.\n\nTraduci in italiano quanto seguente: Regolamentazioni globali moderne come il GDPR, tuttavia, richiedono anche uno scopo. Ecco dove diventa importante l'accesso agli attributi: a quali scopi può operare ogni persona? In base a un EULA, i dati devono essere elaborati dagli utenti solo per la ragione indicata. In caso contrario, è necessaria un'analisi del rischio durante il processo prima che i dati siano utilizzati operativamente per la produzione.\n\nIn questo momento, siamo all'inizio di una moderna gestione dei dati. Attualmente, gli utenti prendono una decisione binaria sulle informazioni, ovvero acconsentono o non acconsentono. Il futuro si trova da qualche parte a metà strada: consenso limitato. Ad esempio, se una persona fornisce i propri dati genomici a una società come ancestry.com, cosa significa per il loro figlio più avanti? Il bambino non ha dato il consenso per il proprio materiale genetico che potrebbe essere esaminato da, ad esempio, una compagnia di assicurazioni sanitarie per determinare il rischio. Nella moderna gestione dei dati, Matt vede i consumatori dando un consenso limitato, come permettere a una società di analizzare solo il DNA per l'ascendenza e nient'altro.\n\nIl futuro deve riguardare il consenso e l'accesso basato sulla finalità perché alla fine, i dati derivati guidano le intuizioni, mentre lo sviluppo del machine learning incorpora i dati negli algoritmi.\n\nPer saperne di più su Immuta e sulla creazione di un programma di governance dei dati, vai su Immuta.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matthew Carroll"],"link":"/episode-EDT71-it","image":"./episodes/edt-71/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect presso Intel, prosegue la sua approfondita discussione sulla realtà e sul futuro della moderna governance dei dati con Matthew Carroll, CEO di Immuta. In questo episodio, discutono di Classificazione dei Dati, Politiche e Governance."},{"id":146,"type":"Episode","title":"2021 un anno in rassegna","tags":["covid","edge","compute","cybersecurity"],"body":"\r\n\r\nUna delle principali aspettative per il 2021 era che il nuovo vaccino ci avrebbe portato fuori dalla situazione di COVID e che i viaggi sarebbero ripresi. Darren si aspettava di poter incontrare i suoi clienti di persona anziché tramite Zoom o videoconferenze.\n\nAltre aspettative riguardavano l'implementazione di modelli di lavoro ibridi e, sebbene l'apprendimento a distanza nell'istruzione fosse in pieno svolgimento, c'era la speranza di un ritorno alle aule in presenza. Ci aspettavamo di vedere un aumento del servizio clienti senza contatto o senza attriti. Anche l'industria dei lavori occasionali come UberEats stava prendendo il via.\n\nNell'industria, speravamo di vedere un grande impulso per l'Intelligenza Artificiale e il Machine Learning a mano a mano che nuove tecnologie diventano disponibili. Pensavamo inoltre di assistere a un'accelerazione dell'Industria 4.0 con l'introduzione di nuove automazioni, poiché le fabbriche avevano ancora bisogno di produrre nonostante il minor numero di lavoratori.\n\nAvevamo grandi aspettative per il 2021 e non ha deluso. C'erano, però, parecchie sorprese.\n\n## Sorprese nel 2021\n\nAnche se il vaccino ha aiutato, non ha eliminato il COVID. Abbiamo avuto quattro ondate e attualmente siamo nel bel mezzo dell'onda Omicron all'inizio del 2022. Tuttavia, non tutti sono tornati al lavoro e le organizzazioni continuano a implementare piani di lavoro ibrido.\n\nIl 2021 ha portato anche la grande rinuncia, con un gran numero di persone che hanno cambiato lavoro, forse a causa di burnout, diverse opportunità o semplicemente perché erano insicure su quando avrebbero dovuto tornare in ufficio.\n\nIT divenne gli eroi silenziosi della continuità aziendale, poiché divennero ancora più flessibili nella capacità di adattarsi rapidamente per supportare tutte le diverse necessità dei dipendenti e dei clienti.\n\nUn'altra grande sorpresa è stata che importanti settori al di fuori dell'alta tecnologia sono stati colpiti da ransomware, come l'industria delle carni e un oleodotto. La sicurezza, quindi, è diventata un concetto importante.\n\nIntel ha avuto una grande sorpresa anche con il ritorno di Pat Gelsinger come CEO.\n\nLa COVID sta ancora seminando il caos in tutto il mondo.\n\nCOVID probabilmente sarà l'evento cardine o il cigno nero del secolo. Le economie mondiali si sono adattate per riflettere l'incertezza delle quattro ondate di focolai di COVID, e i picchi e le valli hanno causato il caos nei piani aziendali per far tornare le persone in ufficio.\n\n## Modelli di lavoro ibridi creati.\n\nLe organizzazioni hanno ideato alcuni ottimi modelli di lavoro ibridi, ma molti di essi non sono ancora utilizzati in quanto le date di ritorno al lavoro sono state continuamente rimandate a causa di focolai, come l'attuale ondata di Omicron nel gennaio 2022. Quello che abbiamo osservato è un importante cambiamento culturale, con le persone che si stanno adattando al lavoro da remoto e forse anche al lavoro ibrido. Le organizzazioni IT si sono preparate per il continuo alternarsi tra lavoro in ufficio e lavoro da remoto.\n\nIl lavoro quotidiano è fondamentalmente cambiato, passando dallo stoccaggio dei documenti su una macchina in ufficio allo stoccaggio su cloud. In alternativa, le cose vengono memorizzate su dispositivi portatili e replicati sul cloud. Di conseguenza, abbiamo assistito a un'enorme evoluzione delle offerte basate su cloud e SaaS, come Office 365, così come degli strumenti di collaborazione come Zoom e Teams. Inoltre, l'integrazione a distanza dei nuovi dipendenti è diventata comune. Tutto ciò ha influenzato le persone, i processi e la tecnologia.\n\n## Combattere la Grande Resa\n\nPer trattenere i dipendenti in mezzo alla grande rinuncia, le organizzazioni devono prima guardare al benessere dei dipendenti. Con lo stress e l'isolamento della pandemia, si è registrato un aumento delle organizzazioni che cercano di aiutare i dipendenti con la salute mentale ed emotiva.\n\nLa flessibilità è un altro elemento chiave; con il lavoro da remoto, gli orari e la posizione possono essere flessibili. I dipendenti possono vivere in un altro stato o mantenere orari non tradizionali. Questa flessibilità e l'assenza di spostamenti hanno permesso alle persone di interagire ed esplorare maggiormente le loro comunità.\n\nLe organizzazioni HR stanno cominciando ad utilizzare l'intelligenza artificiale per capire perché le persone se ne vanno, identificare le tendenze e determinare quali programmi aiuteranno ad aumentare la produttività e far sentire i dipendenti parte del team. Le organizzazioni si stanno anche rivolgendo all'automazione. Vi è stato un aumento nell'industria dell'automazione dei processi robotici per far fronte alla riduzione del numero di dipendenti.\n\n## Il ritmo incalzante dell'IT non si è rallentato.\n\nIT non può mantenere il ritmo eroico che era richiesto all'inizio dell'emergenza COVID, quindi sebbene le ore intense si siano ridotte, la domanda viene soddisfatta in modo strategico. Abbiamo assistito a un enorme movimento verso le offerte di SaaS, quindi ad esempio gli dipendenti non dovevano più occuparsi di cose che non erano necessariamente la loro specialità. Invece, potevano rivolgersi a un fornitore di servizi cloud, o a fornitori di servizi di HR, vendite o sistemi ERP. Un movimento verso l'automazione e processi ripetibili ha alleviato parte della pressione del lavoro quotidiano in ufficio. C'è stato anche un maggiore investimento in tecnologie DevOps e RPA per contribuire a semplificare e garantire lo sviluppo dei prodotti.\n\n## Sicurezza, Catena di Approvvigionamento e Ransomware.\n\nLe questioni di sicurezza hanno colto di sorpresa la maggior parte delle industrie. Settori come il confezionamento della carne, il petrolio e il gas, gli ospedali e le aziende di supply chain e logistica sono stati colpiti da violazioni della sicurezza. Principalmente, questo è stato un problema legato alla necessità di passare rapidamente al lavoro da remoto e a un'attenzione insufficiente alla sicurezza. Ad esempio, è possibile che le organizzazioni non abbiano fornito una formazione adeguata ai dipendenti in remoto su come proteggere i propri laptop o dati. Tra le altre lezioni apprese, vedremo l'emergere della fiducia zero quest'anno.\n\nUn altro grosso problema di quest'anno sono state le problematiche legate alla catena di approvvigionamento, e non solo per quanto riguarda il silicio. Molti materiali continueranno a scarseggiare in generale, influenzando specialmente le piccole imprese.\n\nDobbiamo trovare delle soluzioni per combattere il ransomware. Le organizzazioni possono apportare cambiamenti nei processi e nella cultura e utilizzare nuove tecnologie per trovare queste soluzioni.\n\n## Intel ha un nuovo CEO.\n\nLa più grande sorpresa per Darren, e forse per l'intero settore, è stato il ritorno di Pat Gelsinger in Intel, questa volta come CEO. Tutti in Intel sono ispirati dall'energia che porta con sé. Pat sostiene che contribuirà a risolvere la carenza di chip dell'industria investendo nuovamente nella fabbricazione americana. Darren crede che riporterà Intel al vertice della vendita di chip e fornirà tecnologie meravigliose per tutto il mondo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT73-it","image":"./episodes/edt-73/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren riflette sulle aspettative e le sorprese del 2021."},{"id":147,"type":"Episode","title":"Ransomware: Preparati e non entrare nel panico","tags":["cybersecurity","ransomware"],"body":"\r\n\r\nAnche se per la maggior parte delle organizzazioni un attacco ransomware inizia con una richiesta di riscatto di qualche tipo, la storia completa di solito è stata in preparazione per molti mesi.\n\nLa richiesta di riscatto avviene dopo che gli aggressori hanno criptato le informazioni dai sistemi compromessi e hanno bloccato tutto ciò che potevano, oppure hanno rubato informazioni sensibili e minacciano ora di diffonderle pubblicamente. In entrambi i casi, essi richiedono una somma di denaro per impedire la divulgazione o per ripristinare le informazioni.\n\nLa somma di denaro può essere mirata perché gli attaccanti sanno quanto la società può permettersi e chiederanno una cifra enorme. Gli attacchi meno mirati chiederanno una quantità casuale e sperano di ottenere un colpo. Sempre più spesso, però, gli attacchi sono sofisticati e gli attaccanti hanno fatto i loro compiti. Potrebbero aver ottenuto un notevole successo, spostandosi lateralmente nell'ambiente e compromettendo più domini. Sanno che ristabilire i servizi costerà all'organizzazione una quantità enorme, quindi possono chiedere di più.\n\nMa prima che gli attaccanti chiedano il riscatto, sono stati all'interno del sistema per un po' di tempo, in media poco meno di 300 giorni, fino a quando eseguono completamente il loro piano. Cercano di arrivare il più lontano possibile all'interno della rete per renderlo il più impattante possibile. Ad esempio, distruggeranno l'executor del backup in modo da paralizzare l'organizzazione, lasciando dati di backup corrotti e inutilizzabili. Dedicheranno anche del tempo per compromettere le credenziali per l'escalation dei privilegi per muoversi lateralmente all'interno della rete e individuare eventuali vulnerabilità.\n\nOgni attacco è diverso, quindi è difficile nominare la vulnerabilità più comune. Gli attaccanti trovano qualsiasi punto d'accesso possibile, che sia una debolezza nella gestione delle vulnerabilità o persino nelle persone, ad esempio gli attacchi di phishing o le tattiche di ingegneria sociale. Faranno chiamate telefoniche e si faranno passare per dirigenti o useranno nomi simili a quelli dei dirigenti per ottenere informazioni e dati dagli impiegati online.\n\nMolti nell'industria diranno che non è una questione di se, ma di quando verrai attaccato. Stephanie, tuttavia, non crede che sia così perché con la dovuta diligenza, mettendo a punto le misure di sicurezza appropriate e adottando i passi necessari, non verrete presi di mira.\n\nLa due diligence è ciò che gli esperti di sicurezza predicano da decenni: effettuare la gestione delle vulnerabilità e delle patch, cambiare le password e limitare i privilegi se possibile. Addestra il tuo personale. Gli amministratori non dovrebbero utilizzare gli account di amministrazione su Internet per pubblicare su forum, ad esempio. Si tratta di capire quali sono le potenziali aree di attacco e gestirle.\n\nCosa dovresti fare se sei vittima di un attacco ransomware? Stephanie afferma che ciò che le persone dovrebbero fare e ciò che fanno in realtà sono due cose diverse. La prima reazione impulsiva degli specialisti IT spesso è quella di riavviare, applicare patch o modificare significativamente l'ambiente. Questo avviserà solo gli attaccanti che è giunta loro l'ora. Per le indagini forensi, è estremamente importante essere prudenti in tali ambienti. Cerca di digitare il meno possibile e non riavviare assolutamente.\n\nAlcune aziende andranno nel panico e si metteranno in atto dei denial of service su se stesse, passando in modalità di lockdown totale, chiudendo tutto. Piuttosto che panico, dovrebbero fare affidamento sulle loro politiche di risposta agli incidenti e rendersi conto che il problema può essere risolto anche se non sarà piacevole.\n\nOvviamente, ogni azienda dovrebbe avere queste politiche di risposta agli incidenti che possono essere attivate rapidamente per gestire le comunicazioni internamente e con i media e mantenere l'attività in corso, se possibile. I professionisti della sicurezza possono aiutare a creare questi piani di risposta e possono intervenire e fornire assistenza durante un attacco.\n\nIl loro primo passo per preservare le informazioni è osservare alcune delle attività sospette che si verificano nella rete. Gli attacchi ransomware non iniziano con la crittografia o il furto di informazioni; ci sono molti attacchi preliminari. È importante identificare da dove provengono, dove hanno avuto origine e dove sono stati. Per fare ciò, i professionisti della sicurezza hanno bisogno di prove e informazioni che devono essere adeguatamente preservate. Un buon inizio è mettere le persone giuste nel posto giusto per gestire la situazione.\n\nIl passo successivo è la corretta gestione dell'ambiente. Purtroppo, una volta che si verifichi ransomware o qualsiasi tipo di violazione o incidente, l'organizzazione è altamente vulnerabile. Cento per cento delle volte, quando gli ambienti sono stati oggetto di attacchi ransomware riusciti, pubblicizzati o meno, vengono presi di mira dallo stesso gruppo o da un gruppo diverso. È come un animale ferito circondato dai avvoltoi. Gli aggressori sanno che sei ferito e vulnerabile. Un altro attacco è imminente.\n\nMolto spesso, quando i professionisti della sicurezza conducono le loro indagini, trovano altri indicatori di attacco e compromissione in diverse parti della rete. Devono determinare se fa parte dello stesso attacco o di un attacco diverso. Questa indagine è una parte critica nel recupero dal malware, perché anche quando si pensa di aver risolto un attacco e l'attività aziendale sta di nuovo funzionando correttamente, c'è ancora il potenziale per questi altri attacchi.\n\nUn tipico attacco costa in media quattro milioni e mezzo di dollari per essere ripristinato, e ciò non include il riscatto. L'importo può essere molto più grande ed è proporzionale alle dimensioni dell'organizzazione.\n\nÈ impossibile essere certi di quante organizzazioni paghino il riscatto. Molti riscatti sono accompagnati da minacce di non contattare le forze dell'ordine o divulgare l'attacco. Per questo motivo, le statistiche disponibili sul numero di organizzazioni che pagano sono varie.\n\nAlcune decisioni prese dai dirigenti di alcune organizzazioni consistono nel dichiarare che non pagheranno in alcuna circostanza, nemmeno se ciò comporta costi maggiori per la ricostruzione, distruggendo così la possibilità di negoziare. Si tratta di una decisione emotiva che può offuscare il giudizio. Alla fine della giornata, se l'obiettivo è continuare a fare affari e fare soldi, pagare un riscatto basso di forse dieci o ventimila dollari sarà meno costoso rispetto alle indagini forensi e al resto del processo. D'altra parte, ci sono casi documentati in cui il riscatto è stato pagato e i dati non sono stati completamente ripristinati. Inoltre, l'organizzazione non ha alcuna garanzia sulla sicurezza del suo ambiente. Non c'è alcuna certezza quando si paga un riscatto; si sta chiedendo ai criminali di agire in buona fede.\n\nMolti governi in tutto il mondo hanno reso illegale pagare un riscatto perché gli aggressori vengono considerati terroristi e non è consentito negoziare con i terroristi. Un altro problema è che gli aggressori a volte rifiutano di trattare con negoziatori professionisti. Spesso nominano qualcuno all'interno dell'organizzazione come unica persona con cui desiderano negoziare, sperando che quella persona prenda decisioni emotive.\n\nLe minacce vengono comunicate in diversi modi: via email, telefono e persino come sfondo del desktop.\n\nLa migliore strategia per evitare o mitigare un attacco è non aspettare fino a quando la tua organizzazione si trova in quella situazione. Piuttosto, svolgi un'attenta analisi. Effettua valutazioni almeno annualmente per individuare le lacune nella sicurezza. Le minacce e gli attacchi cambiano costantemente e diventano sempre più sofisticati, quindi la sicurezza della tua organizzazione deve star al passo. Monitora e aggiorna continuamente. Gestisci le vulnerabilità, cambia continuamente le password e ricorda ed educa gli utenti sulle minacce. Queste non sono nuove strategie. I professionisti della sicurezza le hanno raccomandate da decenni; le organizzazioni stanno solo fallendo nel farle in modo corretto ed evolversi.\n\nÈ anche intelligente chiamare gli esperti per guidare il processo di pianificazione ed esercizi di risposta agli incidenti. Tutti all'interno dell'organizzazione dovrebbero sapere cosa fare e a chi chiamare in caso di attacco per evitare ulteriori danni.\n\nSe la tua organizzazione viene attaccata, speriamo che l'impatto sia minimo, o almeno contenuto e gestibile se è stato fatto un adeguato lavoro di preparazione. Qualsiasi tempo, energia e denaro che un'azienda investe in misure preventive rappresenta una piccola frazione del costo di un attacco.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Stephanie Sabatini"],"link":"/episode-EDT74-it","image":"./episodes/edt-74/it/thumbnail.jpeg","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, parla con Stephanie Sabatini, Sr. Director, Professional Services, Hitachi Systems Security, riguardo alla prevenzione e preparazione agli attacchi ransomware e a cosa fare nel caso in cui la tua organizzazione venga attaccata."},{"id":148,"type":"Episode","title":"Soluzioni di cibersicurezza con Hitachi","tags":["cybersecurity","technology"],"body":"\r\n\r\nColin è stato con Hitachi per quasi 24 anni dopo aver lavorato per IBM subito dopo il college. Si concentra principalmente sui conti nel Nord-ovest del Pacifico e sui conti SLED. Ha avuto l'insolita opportunità di prendere il posto di suo padre quando suo padre si è ritirato da Hitachi.\n\nDavid è nel settore dell'informatica da più di vent'anni, iniziando proprio prima della frenesia del .com. È stato per gran parte della sua carriera una persona pratica, occupandosi di server, storage e sicurezza.\n\nMolte persone pensano a Hitachi come a un'azienda di grandi attrezzature o utensili elettrici, fino ad arrivare a quella che produce macchine per il pane. Hitachi è, infatti, un'azienda di ingegneria e produzione centenaria che ha iniziato a produrre motori elettrici nel 1910 e si è trasformata in centinaia di organizzazioni operative e sussidiarie interamente possedute, tra cui Hitachi Vantara. Hitachi Vantara è la più grande sussidiaria interamente posseduta, focalizzata principalmente sulla gestione dei dati. Costruiscono e forniscono non solo sistemi di archiviazione aziendale tradizionali a blocchi, ma si sono sviluppati in un'azienda di soluzioni digitali che abbraccia l'estrema espansione nell'IoT e nelle intuizioni basate sui dati.\n\nRobert Mueller ha detto: \"Ci sono solo due tipi di aziende: quelle che sono state hackerate e quelle che lo saranno. Anche questo si sta fondendo in una sola categoria: quelle che sono state hackerate e lo saranno di nuovo.\" Questa citazione prepara il terreno su come Hitachi può aiutare le aziende. Non è una questione di se, ma di quando, verrai hackerato, e quando verrai hackerato di nuovo. Questo si applica non solo alle aziende, ma anche alle organizzazioni nel settore pubblico.\n\nHitachi ha una divisione federale completa che opera a Washington D.C., focalizzata principalmente sul Dipartimento della Difesa e sui conti federali. Hitachi Vantara lavora molto con i conti SLED e collabora con la divisione federale per fornire soluzioni per i requisiti federali, statali e locali.\n\nIl modo migliore per visualizzare una soluzione di sicurezza da parte di Hitachi è immaginare la tua organizzazione come la tua casa e in quella casa ci sono quattro elementi di protezione che dobbiamo implementare.\n\nPrima cosa è la sicurezza fisica. Hitachi ha un sistema intelligente, una soluzione di intelligenza visiva, che può fornire sorveglianza video con intelligenza. Può fare tutto, dalla rilevazione degli spari al tracciamento delle targhe fino al riconoscimento facciale. Hitachi dispiega tutto ciò in tutto il mondo. Le telecamere Hitachi hanno rilevato molti eventi al centro commerciale di Washington l'anno scorso e vengono utilizzate da organizzazioni di polizia in tutto il paese. Tutto ciò è cresciuto dalla divisione dei trasporti di Hitachi, che dipende molto dalla tecnologia video per la sicurezza.\n\nLa sicurezza fisica non è spesso un argomento di discussione, ma è un aspetto fondamentale. Se non riesci a controllare il tuo edificio e il tuo centro dati, allora non hai sicurezza. Se qualcuno riesce a entrare attraverso la porta, può entrare anche nel tuo centro dati.\n\nDopo la sicurezza fisica arriva Hitachi ID. Questo è fondamentalmente la serratura della tua porta d'ingresso. Un recente sondaggio ha rivelato che solo il 40 percento delle aziende ha un gestore di accesso privilegiato e circa il 74 percento ha un gestore delle identità. Questo non è sufficiente perché ciò comporta una grande esposizione e lo spazio SLED è un obiettivo di alto profilo. Hitachi ID fornisce soluzioni di privilegi e identità di password su una singola piattaforma; questa è una soluzione completa in cui è possibile identificare non solo gli utenti, ma anche dispositivi e applicazioni, sia in locale che nel cloud.\n\nIl terzo aspetto riguarda come proteggere i tuoi dati quando qualcuno varca la porta.\n\nLa sicurezza informatica è un problema di big data, e Pentaho è lo strumento ideale per il big data. Con Pentaho, puoi gestire tutte le tue fonti di dati, controllare il tuo data lake e ottenere risultati utili. Hitachi ha scoperto che gli scienziati dei dati e gli analisti di sicurezza informatica trascorrono l'80 percento del loro tempo solo nella gestione, nel reperimento e nella pulizia dei dati, e solo il 20 percento del loro tempo effettivamente nell'analizzarli. Con Pentaho, questi numeri si invertono e possono dedicare l'80 percento del loro tempo all'analisi dei dati e all'analisi e risposta delle minacce in tempo reale.\n\nPentaho è un sistema di rilevamento delle intrusioni, ma è anche un sistema di prevenzione. Ad esempio, una grande azienda energetica aveva fatto tutto in modo improvvisato, scrivendo i propri script internamente. Hanno trasferito tutte quelle funzionalità in Pentaho in un solo giorno. Così sono stati in grado di effettuare quell'analisi in tempo reale e tenere il passo con gli attaccanti invece di stare sempre indietro. Quello che rende Pentaho unico in un campo affollato è la sua flessibilità. Può effettuare qualsiasi tipo di analisi dei dati e può essere basato sulle esigenze della tua organizzazione.\n\nProteggere i dati da un punto di vista dei contenuti è anche molto importante per lo spazio SLED. Hitachi Content Platform Anywhere fornisce un file sync e share sicuro e una dropbox sicura. È comparabile a Google Drive o Dropbox, per esempio, ma la differenza è che HCP Anywhere è controllato dal proprio team di sicurezza.\n\nViene utilizzato dal Dipartimento della Difesa, che lo ha rinominato Mill Drive. Le forze sul campo trasmettono dati sensibili da e verso vari luoghi segreti e li inviano al quartier generale per missioni di ricognizione e altre operazioni. A livello locale, le città lo utilizzano per trasmettere prove video non solo tramite l'amministrazione, le forze dell'ordine e altre agenzie, ma anche all'ufficio del procuratore distrettuale per la gestione delle prove.\n\nHCP Anywhere è costruito sulla Hitachi Content Platform, che è la loro archiviazione ad oggetti. Ha incorporato l'archiviazione ad oggetti, non solo quella di Hitachi, ma tutta l'archiviazione ad oggetti. Invece di sovrascrivere un file, e quindi permettere a un attaccante di sovrascrivere il tuo file, crei una nuova versione del file. Quindi, se vieni attaccato, puoi tornare a una versione precedente prima che avvenisse l'attacco. Alcune agenzie di valutazione concordano sul fatto che l'archiviazione ad oggetti di Hitachi sia la migliore sul mercato. Di default, ottieni 16 versioni di ogni file, 16 metadati di sistema e un numero illimitato di tag personalizzati per i metadati.\n\nHitachi ha anche una console per la gestione delle politiche dei dati oltre al Gateway della Piattaforma dei Contenuti Hitachi, che mette un NAS di fronte al negozio di oggetti che può essere sia NFS che CIFS. Aggiunto a questo c'è Hitachi Content Intelligence; è un motore di ricerca potenziato. Puoi trovare qualsiasi oggetto nel tuo archivio in base ai metadati, alla data, all'ora, ecc. Può estendersi oltre l'hardware fisico del proprio (o di Hitachi?) negozio di oggetti su più archivi. La ricerca funzionerà su qualsiasi cosa. È anche compatibile al 100% con AWS s3.\n\nPer i clienti di SLED, c'è un'opportunità con il partner di Hitachi, Flexential, per fornire Hitachi Content Platform come servizio. Se un governo cittadino, ad esempio, non desidera applicare il proprio archivio di oggetti, può far parte di un ambiente multilocatario attraverso questa partnership.\n\nInfine, la Sicurezza del Sistema Hitachi può aiutarti se sei attaccato da ransomware. Possono fornire un'analisi sull'impatto e negoziare con gli attaccanti del ransomware. Possono iniziare a creare posizioni difensive attorno alla tua organizzazione. Gli attaccanti non sono giocatori solitari, ma organizzazioni criminali con sviluppatori e management, quindi richiede una risposta professionale. La Sicurezza del Sistema Hitachi può accompagnare un'organizzazione dall'inizio alla fine.\n\nSe sei un membro di ISSA, cerca Hitachi per sponsorizzare un evento nella tua zona.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Colin McLean","David Rowley"],"link":"/episode-EDT75-it","image":"./episodes/edt-75/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, parla con Colin McLean di Hitachi, Intel Global Team Lead, e David Rowley, Senior Solutions Consultant, delle offerte di sicurezza informatica a 360 gradi di Hitachi."},{"id":149,"type":"Episode","title":"Giorno nella vita di un Architetto di Soluzioni Cloud","tags":["csa","cloudsolutionarchitect","multicloud"],"body":"\r\n\r\nIl team di architetti delle soluzioni cloud di Intel si è formato meno di due anni fa con poche persone ed è cresciuto rapidamente fino a raggiungere 21 membri del team. Tale crescita indica la sua importanza sia internamente per Intel che esternamente per i clienti.\n\nPoiché i clienti passano dalle soluzioni on-premises al cloud per flessibilità e scalabilità, devono capire che l'infrastruttura sottostante e le caratteristiche dei servizi sono importanti per l'ottimizzazione. Poiché la maggior parte dei fornitori di servizi cloud, inclusi i tre principali, Google, Amazon e AWS, sono alimentati da Intel, i CSAs di Intel possono aiutare ad ottimizzare i servizi durante l'intero percorso nel cloud di un cliente.\n\nUna giornata tipica per un CSA inizia con compiti di back-office come email, riunioni interne, riunioni di squadra, riunioni dello staff e una quantità significativa di tempo dedicato alle conversazioni con i clienti finali. Questi possono essere clienti Intel che attualmente utilizzano CPU Intel in loco e stanno valutando di passare al cloud, oppure potrebbero già essere nel cloud. I CSA hanno anche partner, ovvero integratori di sistemi, interessati a capire come tradurre l'affidabilità di Intel e alcune delle caratteristiche come il firewall ABS o Boost o la crittografia.\n\nI Customer Success Associate (CSA) non lavorano solo nel ruolo di pre-vendita, ma progettano anche dimostrazioni pratiche, scrivono casi d'uso e collaborano con un team per eseguire test basati sul carico di lavoro del cliente. Trascorrono inoltre del tempo per scrivere o co-scrivere guide operative.\n\nCreano anche un playbook per addestrare i manager interni di Intel e i venditori partner.\n\nInoltre, i CSP stanno annunciando nuovi servizi ogni giorno e gli CSA devono rimanere al passo con la tecnologia che supporta tali servizi e capire come possono beneficiare i clienti. Ciò significa comprendere i carichi di lavoro degli utenti e utilizzare anche modelli.\n\nGli Intel CSAs si considerano consulenti fidati, un'estensione del team del cliente, invece che cercare di prendere il controllo delle decisioni. Molte volte, ad esempio, un cliente sa quale cloud desidera utilizzare, ma ha bisogno di aiuto per valutare quali strumenti sono disponibili per assistere nell'analisi del carico di lavoro attuale e correlarli alle istanze disponibili nel cloud. I CSAs assisteranno ed educeranno anche i clienti nell'analisi dei costi. Intel ha una gamma di strumenti per ogni fase del percorso nel cloud.\n\nUna volta che un cliente è operativo e ha completato il progetto iniziale, si metterà in contatto con i CSAs per nuove iniziative e progetti mentre il ciclo continua.\n\nLe CSAs hanno un set unico di competenze, in quanto spendono molto tempo a scrivere, comunicare ed educare, ma comprendono anche tutti gli aspetti tecnici e le esigenze dei clienti. Ad esempio, un CSA dovrebbe essere in grado di discernere se un problema è di natura tecnica o commerciale. Le esperienze dei CSAs di Intel sono diverse, con culture diverse, competenze tecniche, esperienze di vendita e background lavorativi differenti, quindi portano competenze in diverse aree. Sono anche una fonte tecnica approfondita al di là del loro stesso team. Se, ad esempio, qualcuno desidera approfondire i servizi AWS, possono coinvolgere un collega di AWS. In altre parole, i CSAs di Intel possono essere un punto di contatto unico per tutte le esigenze di servizi cloud del cliente.\n\nPerché un cliente dovrebbe utilizzare il team Intel CSA invece del team di un CSP? Intel è veramente neutrale, poiché i suoi chip e CPU sono presenti in quasi tutti i fornitori di servizi cloud. Non fa alcuna differenza per il CSA quale servizio un cliente sceglie. Inoltre, molti CSAs dei fornitori non comprendono le caratteristiche sottostanti di Intel che sono disponibili solo in un determinato tipo di istanza. Ad esempio, un CSA di Intel saprebbe scegliere un'istanza alimentata da Ice Lake anziché da Cascade Lake per ottenere significativi risparmi di costi e un incremento delle prestazioni sulle applicazioni. I CSAs dei CSP potrebbero non essere necessariamente a conoscenza di queste informazioni.\n\nIntel ha anche molti strumenti per raccogliere telemetria, che si tratti di un'istanza cloud o di un'istanza di cloud bare metal. Gli amministratori di servizio dei CSP non hanno accesso a questi strumenti. Possono risolvere problemi, ma solo a livello dell'iper-visore. Quindi, se un cliente sta avendo un problema, un amministratore di servizio Intel può scendere al livello del chip e utilizzare strumenti di risoluzione dei problemi e telemetria per risolvere il problema.\n\nIl modo migliore per mettersi in contatto con il team Intel CSA è attraverso un account executive. Tecnicamente, i CSAs fanno parte del gruppo di vendita e marketing, quindi stanno attivamente cercando anche opportunità, come contatti del passato.\n\nI servizi di CSA non sono una spesa aggiuntiva. Infatti, Intel ha un programma in cui finanzieranno la migrazione iniziale verso il cloud. I CSA porteranno strumenti, personale ed esperienza sia dal punto di vista delle risorse umane sia dal punto di vista del monitoraggio. Ciò aiuterà un cliente in un ambiente \"greenfield\" a ridurre la curva di apprendimento. In seguito, la monetizzazione avviene quando un carico di lavoro è completamente in esecuzione nel cloud o quando è in corso una migrazione in cui si stanno consumando risorse.\n\nGli Intel CSA non hanno interesse in quale CSP utilizzino i clienti, ma solo che essi siano ottimizzati in un ambiente altamente sicuro e affidabile.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Kiran Agrahara"],"link":"/episode-EDT76-it","image":"./episodes/edt-76/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con Kiran Agrahara di cosa fanno gli architetti delle soluzioni cloud di Intel (CSA) in una giornata per beneficiare non solo i fornitori di servizi cloud (CSP), ma anche gli utenti finali."},{"id":150,"type":"Episode","title":"Trasformazione digitale nel 2022","tags":["aiml","comms","data","edge","multicloud","cybersecurity"],"body":"\r\n\r\nCome Chief Data Scientist per il settore pubblico di Intel, Gretchen trascorre le sue giornate parlando con i clienti riguardo alle loro sfide nel campo dei dati, alla gestione dei dati, alla governance dei dati, all'etica di ciò che stanno facendo e all'intelligenza artificiale responsabile.\n\nI sei anni di Anna in Intel si sono concentrati sull'IoT e sull'edge, con gli ultimi tre anni nel settore pubblico. Entrambi concordano sul fatto che il 2022 sarà un anno emozionante pieno di possibilità che cambieranno il gioco.\n\nDarren, Gretchen e Anna rappresentano ciascuno diverse parti della trasformazione digitale con i clienti, ma si sono riuniti per offrire un modo comune di parlare dell'argomento, con sei pilastri della trasformazione digitale: elaborazione multi-cloud, elaborazione edge, intelligenza artificiale, apprendimento automatico, sicurezza informatica, gestione dei dati e comunicazioni. Concordano sul fatto che questi saranno i settori delle grandi trasformazioni nell'anno a venire. Intel è profondamente coinvolta in ognuno di essi, in quanto ha costruito l'hardware e il software per supportare ciascuno dei pilastri. I pilastri sono intrecciati tra loro e Intel svolge un ruolo chiave nel guidare l'industria verso il futuro.\n\nL'hardware di Intel costituisce la base per la maggior parte dei fornitori di cloud. Dal punto di vista del software, Intel ha ottimizzato i framework comuni che le persone utilizzano per l'IA, l'apprendimento automatico o il deep learning al fine di sfruttare al meglio l'hardware sottostante. In alcuni casi, le prestazioni sono dieci o cento volte migliori grazie al software di Intel.\n\nNon solo Intel ha fornito hardware per edge e comms, soprattutto in 5G, ma ha integrato tutto ciò con architetture di riferimento software. Inoltre, Intel cerca di far funzionare gli ecosistemi per tutti. C'è una forte attenzione ai sistemi aperti in modo non proprietario, facilitando l'ingresso dei nuovi arrivati e dei giocatori esistenti per avere una presenza più ampia in questi nuovi mercati e offrire avanzamenti entusiasmanti. Intel è uno dei, se non il principale, contributori alla comunità del software open-source.\n\n## Pilastro della sicurezza informatica\n\nImplicito nelle progettazioni hardware di Intel sono presenti funzioni di sicurezza e capacità per garantire che i clienti nell'ecosistema possano proteggere i loro dati in tutte le loro diverse combinazioni.\n\nLa sicurezza non è mai statica; è in continuo sviluppo. Intel da sola non risolverà i problemi di sicurezza di un'organizzazione. La sicurezza è l'interazione di ciò che fai con il tuo hardware, come introduci gli elementi software corretti e le limitazioni e le politiche della tua organizzazione.\n\nIntel si concentra su molteplici settori, ma un ruolo fondamentale è rappresentato dalla sicurezza hardware radice di fiducia e autenticazione. Molte caratteristiche possono essere integrate direttamente per raggiungere tale obiettivo. Un passo ulteriore riguarda le catene di approvvigionamento attendibili o trasparenti che Intel può condividere con i clienti, instillando un elevato grado di fiducia. Queste capacità migliorano costantemente e Intel lavora sempre per fare progressi.\n\nGli attacchi informatici sono una preoccupazione principale per molti clienti a causa delle recenti violazioni. Intel dispone di una sicurezza come esecuzione affidabile e enclave sicure. Hanno un'intera serie di capacità per il tipo di sicurezza che si desidera fare, come la crittografia, senza causare grandi riduzioni delle prestazioni. Esiste una matrice completa di capacità, compreso un diverso insieme di requisiti per il bordo a causa della perdita della sicurezza fisica del data center.\n\nLe architetture con zero trust stanno diventando i framework che sono particolarmente diffusi nel settore pubblico. Per il Dipartimento della Difesa, il zero trust è una direttiva obbligatoria. Intel ha molte capacità che contribuiscono al zero trust.\n\nUna misura non è adatta a tutti per quanto riguarda la sicurezza, ma è chiaro che la sicurezza aggiunta in seguito non ha più senso. La sicurezza deve essere integrata fin dall'inizio e deve essere costantemente iterata. Le organizzazioni devono chiedersi costantemente se hanno i protocolli giusti, se dispongono degli strumenti di rilevamento delle minacce adeguati e se c'è fiducia lungo tutta la catena di fornitura. Tutto ciò è fondamentale.\n\n## Pilastro del Computing sul bordo\n\nOra che c'è tanto che può essere fatto con l'AI, l'ML e diversi algoritmi, è emozionante vedere come possiamo sfruttare queste cose al limite e ottimizzare le architetture per soddisfare quei casi d'uso.\n\nCi sono alcuni modelli molto semplici in cui tutto risiede nel cloud e solo la raccolta dei dati viene effettuata sul bordo. Se la connettività lo permette, allora le latenze possono corrispondere alle applicazioni. La maggior parte dell'elaborazione può essere incentrata sul cloud. Tuttavia, ci sono innumerevoli casi d'uso in cui questo non ha senso a causa della sensibilità dei dati o delle esigenze di latenza. Quindi, ci sono interessanti conversazioni su come trovare architetture ottimali per il bordo e cosa sta succedendo con il cloud e la rete.\n\nAd esempio, potremmo avere un'architettura senza interruzioni per raccogliere, utilizzare ed elaborare immediatamente i dati per fornire intelligenza? Possiamo incorporarlo nella prossima serie di addestramenti in modo che il modello venga costantemente aggiornato? Quanto velocemente possiamo rendere questa sequenza? È fattibile? Abbiamo bisogno di tutto il nostro addestramento nel cloud? Se tutto l'addestramento è nel cloud, qual è l'intervallo adeguato per far scendere nuovamente i modelli aggiornati? E può il dispositivo essere sufficientemente leggero da utilizzare ciò che viene generato nel cloud? Il dispositivo è ancora molto complicato e ci sono molte possibilità e domande affascinanti.\n\n## Pilastro dell'Intelligenza Artificiale\n\nL'AI e l'ML consentono all'edge di fare molto più di quanto si sia mai considerato in precedenza. Un prodotto non è sempre la risposta giusta: si tratta di una questione di adattamento allo scopo. L'uso di open source è fondamentale e la possibilità di sfruttare i microservizi per eseguire algoritmi all'edge.\n\nAd esempio, se hai algoritmi proprio al limite che effettuano il lavoro di lettura, stai parlando del flusso del traffico. La sequenza di luci rosse, gialle e verdi può cambiare istantaneamente in base al numero di auto che passano e contemporaneamente raccogliere dati da inviare a un centro dati più grande che potrebbe poi eseguire una rielaborazione. Alla fine della settimana, potrebbe avere senso aggiungere ulteriori microservizi o apportare modifiche agli algoritmi. Quindi quel contenitore torna all'orlo e puoi rispondere meglio e continuare ad apprendere.\n\nInoltre, quando si parla di adatto allo scopo, la larghezza di banda, la latenza e il formato sono tutti fattori da considerare.\n\nI rendimenti delle colture sono un buon esempio. Un cliente raccoglie dati che vanno a un centro dati. Stanno lavorando sui modelli, ma non si traduce nel far loro sapere che hanno bisogno di più fertilizzante o che ci sono sfide attuali con il sole e la pioggia. Ciò significa che la formula deve essere modificata. Hai bisogno dei dati sui rendimenti delle colture, delle informazioni, dell'algoritmo e dei microservizi in un formato molto più piccolo. La latenza e la larghezza di banda sono diverse, ma è possibile avere una piccola unità in mezzo a un campo che raccoglie quei dati e risponde, ad esempio, al flusso di acqua o ai bisogni di fertilizzante per migliorare i rendimenti delle colture.\n\nSperiamo che quest'anno più dei design di bordo diventino standardizzati. Con FlexRAM e 5G, ci sono standard, ma tutto il resto è il selvaggio West. Molte persone stanno progettando cose interessanti, ma non lo fanno in modo tale da rendere facile avere quei microservizi in un contenitore e algoritmi di tipo ML e AI. In alcuni casi, hai bisogno di algoritmi multipli pesati in modo diverso, che cambiano ogni settimana in base a nuovi dati e nuovi allenamenti. Abbiamo bisogno di poterlo fare in modo che non importi chi ha costruito un dispositivo. Creare standard non solo per i dati AI e ML, ma anche al bordo ci aiuterà a far esplodere le capacità.\n\n## Pilastro delle comunicazioni\n\nIl lato commerciale del 5G sarà il precursore del 5G su telefoni ovunque. Tuttavia, c'è ancora un ritardo nel disponere del tipo di attrezzatura utente per eseguire diversi tipi di applicazioni per il bordo o l'azienda, ad esempio. Intel sta installando le sue prime reti 5G con partner che sono più all'avanguardia e meno orientati al lato commerciale. Anche se i loro partner commerciali li hanno in funzione da molto tempo, le reti private controllate per uno scopo specifico stanno venendo liberate e si stanno sviluppando applicazioni. 2022 è l'anno in cui queste cose diventeranno realtà.\n\n## Pilastro di gestione dei dati\n\nI dati che un tempo ci volevano ore o giorni per essere assimilati, preparati, analizzati e attuati, ora possono richiedere solo minuti o nanosecondi. Puoi anche sfruttare diversi modelli e, quando i pesi cambiano, puoi agire rapidamente e utilizzare i dati per offrire servizi migliori. Spostare i dati, gestire quei dati e rendere operativi i tuoi sistemi di intelligenza artificiale e apprendimento automatico fanno parte di ciò che la gestione dei dati offre al mondo.\n\n## Pilastro Multi-Cloud\n\nIl pilastro del multi-cloud non si riferisce ai fornitori di servizi cloud in questo contesto. Si riferisce all'infrastruttura in generale e a come astratta tale infrastruttura per implementare nuove capacità su tutta la rete, su un fornitore di servizi cloud o persino sulla tua infrastruttura del data center. L'obiettivo dell'architettura multi-cloud è che tu conosca gli utenti chiave e, cosa ancora più importante, come viene gestito il dati.\n\nLe diverse nuvole hanno capacità diverse e, a seconda delle situazioni d'uso, potrebbero utilizzare diverse nuvole per scopi diversi. Intel ha degli architetti delle soluzioni cloud che aiutano i clienti a ottimizzare i carichi di lavoro tra le offerte cloud.\n\nTutti questi pilastri sono intrecciati e lavorano insieme. Cerca gli episodi futuri in cui Darren, Gretchen e Anna continuano questa conversazione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Gretchen Stewart","Anna Scott"],"link":"/episode-EDT77-it","image":"./episodes/edt-77/it/thumbnail.png","lang":"it","summary":"Intel's Darren Pulsipher, Chief Solution Architect, Dr. Anna Scott, Chief Edge Architect, and Gretchen Stewart, Chief Data Scientist discutono dei sei pilastri della trasformazione digitale nel 2022: informatica multi-cloud, informatica periferica, intelligenza artificiale, apprendimento automatico, sicurezza informatica, gestione dei dati e comunicazioni."},{"id":151,"type":"Episode","title":"Comprensione del modello di sicurezza della responsabilità condivisa","tags":["multicloud","compute","cybersecurity","sharedresponsibility","cloudsecurity","cloud","technology","process"],"body":"\r\n\r\n## Sicurezza nel Cloud\n\nLa maggior parte delle persone comprende la responsabilità della sicurezza sul territorio, ma tale responsabilità diventa meno chiara nel cloud. Se i dati sono protetti nel cloud, come sono protetti? Chi è responsabile di tale sicurezza? E per quanto riguarda l'applicazione di patch alle macchine?\n\nDi recente, i fornitori di servizi cloud hanno iniziato a offrire ancora più servizi, quindi esistono diversi modelli. A volte, la sicurezza finisce per essere persa nel mezzo.\n\n## Aree di sicurezza\n\nCi sono quattro aree principali di sicurezza che dobbiamo comprendere.\n\n## Fisico\n\nLa sicurezza fisica è la parte più facile da riconoscere. I fornitori di servizi cloud sono responsabili della sicurezza fisica dei loro data center, mentre tu sei responsabile della sicurezza fisica dei tuoi data center. Inoltre, devi proteggere il tuo spazio fisico. Ad esempio, se sei un produttore, devi proteggere le macchine all'interno della tua area. Di recente, è stato effettuato un attacco informatico tramite il sistema di climatizzazione (HVAC) che era collegato alla rete di un'organizzazione.\n\n## Infrastruttura\n\nLa sicurezza dell'infrastruttura non riguarda l'aspetto fisico, ma l'hardware stesso. I tuoi switch di rete hanno le giuste patch di sicurezza e aggiornamenti? Vengono effettuati aggiornamenti ai dispositivi di archiviazione e memorizzazione? Sono protetti? L'infrastruttura può cadere in zone grigie con i provider di servizi cloud, quindi devi sapere chi è responsabile di cosa e in quali circostanze.\n\n## Applicazione\n\nPer la sicurezza dell'applicazione, è necessario sapere chi ha accesso a un'applicazione e se sta essendo aggiornata con le patch di sicurezza corrette.\n\n## Data in Italian can be translated as \"Data\" or \"Data di\". It depends on the context.\n\nProteggere i tuoi dati è una delle cose più importanti che devi fare. I dati possono effettivamente essere utilizzati come arma in un attacco di ransomware in cui gli aggressori li prendono o li criptano. Vengono anche utilizzati per ottenere importanti vantaggi competitivi in diverse organizzazioni. Devi sapere dove si trovano i tuoi dati e come proteggerli.\n\n## Modelli di erogazione dei servizi cloud\n\nCi sono tre modelli di distribuzione di base nel cloud. Vengono creati diversi modelli tutto il tempo, ma i tre principali sono Infrastruttura come Servizio (IAAS), Piattaforma come Servizio (PAAS) e Software come Servizio (SAAS). Categorizzeremo tutto il resto come X come Servizio (XAAS).\n\n## Infrastruttura come servizio\n\nIAAS è quando si noleggia da un fornitore di servizi cloud. Questo si traduce in termini di macchine virtuali e reti virtuali, quindi storage, calcolo e rete. Stiamo iniziando anche a vedere cose interessanti con acceleratori, come le GPU o addirittura i processori neuromorfici. IAAS è il luogo dove si eseguono le applicazioni.\n\n## Piattaforma come Servizio\n\nIl prossimo livello nella pila è il PAAS. Qui si ottiene un determinato framework come Kubernetes per eseguire le operazioni. VMware che viene eseguito su IAAS è PAAS. Le pipeline CICD come servizio utilizzano molti strumenti che si inseriscono in questo spazio. PAAS ti consente di creare e distribuire nuovi servizi su questa piattaforma in modo da poter facilmente distribuire e gestire sistemi complessi che sono costruiti su IAAS.\n\n## Software come servizio\n\nIl prossimo è SAAS. Si tratta di un software specifico gestito dal fornitore di software o dal fornitore di servizi cloud, oppure potrebbe essere un'offerta di SAAS di terze parti per qualcun altro. La chiave di SAAS è che sono responsabili della sicurezza dell'applicazione. Gestiscono il tempo di attività e tutte le aree gestionali come affidabilità, sicurezza e integrità. Molti dei programmi SAAS sono costruiti su piattaforme PAAS.\n\n## X come servizio\n\nXAAS può essere qualsiasi nuovo servizio come intelligenza artificiale, gestione dei dispositivi o rilevamento della sicurezza.\n\nCapire questi diversi modelli di consegna è importante perché i modelli di sicurezza condivisa dei fornitori di servizi cloud si basano sul modello di consegna.\n\n## Domini cibernetici\n\nOgni dei sei pilastri della sicurezza informatica, individuati da Steve Warren, CTO di Intel in un precedente podcast, è importante sia che tu sia in cloud, on-premises o on the edge. I sei pilastri sono: rilevamento minacce, intelligence, analisi e orchestrazione; gestione dell'identità e dell'accesso; sicurezza dei dati e delle applicazioni; sicurezza di rete; sicurezza della catena di distribuzione; e sicurezza di host e sistema. Tutti e sei di questi ambiti si inseriscono nel modello di sicurezza a responsabilità condivisa che i fornitori di servizi cloud stanno promuovendo.\n\n## Matrice di sicurezza della responsabilità condivisa\n\nQuesta responsabilità condivisa è illustrata nella matrice. Le tecniche di erogazione del modello di servizio si trovano sull'asse verticale: SAAS, PAAS, IAAS e on-prem. Se ti stai ospitando da solo, tutto a destra è di tua responsabilità.\n\nDallato IAAS, sei pienamente responsabile della sicurezza dei dati e delle applicazioni e sei parzialmente responsabile per l'infrastruttura perché sei ancora responsabile del controllo della rete e del sistema operativo. Il fornitore del servizio di cloud è responsabile della rete fisica e dell'host.\n\nSul livello PAAS, sei ancora responsabile della sicurezza dei dati e parzialmente responsabile della sicurezza delle applicazioni e dell'infrastruttura di identità e directory. Ci sono alcuni strumenti disponibili per aiutarti in queste aree. Sebbene tu sia responsabile delle applicazioni e delle loro piattaforme, loro sono responsabili dei framework e delle middleware che forniscono. Sebbene gran parte del sistema operativo venga preso in carico dal livello PAAS e ti vengano forniti alcuni strumenti di livello superiore, sei comunque responsabile della configurazione dei controlli di rete.\n\nSu SAAS, anche se stai utilizzando archiviazione come servizio, dati come servizio o CRM come Salesforce, sei comunque responsabile dei tuoi dati perché devi ancora progettare e crittografare i tuoi backup e gestire i conti e le identità.\n\nUn punto chiave che si applica a tutti i modelli è che tu sei responsabile per la sicurezza dei tuoi dati; non esiste mai uno scenario in cui lasci completamente la sicurezza ai fornitori di servizi cloud. Devi effettuare il backup e verificare se stai utilizzando lo storage degli oggetti in modo da poter tornare indietro in caso di attacco ransomware, se stai gestendo correttamente l'accesso ai tuoi dati e se stai utilizzando strumenti che semplificano questa operazione.\n\n## Diverse Approcci alla Sicurezza\n\nOgni dei tre principali fornitori di servizi cloud adotta un approccio diverso alla sicurezza, in particolare per quanto riguarda la configurazione della rete.\n\n## AWS in Italian is \"Servizi Web Amazon\"\n\nAWS si concentra sulla prevenzione. Quando si avvia una VM, l'impostazione predefinita è che non ci siano porte aperte, quindi è necessario creare gruppi di sicurezza. AWS è il più restrittivo, utilizzando IAM per la gestione delle identità. AWS è ottimo per team di medie dimensioni, ma non funziona altrettanto bene per organizzazioni molto grandi.\n\n## Azzurro\n\nAzure si concentra maggiormente sulla facilità d'uso, mentre la sicurezza è meno restrittiva. Utilizzano il concetto di reti virtuali per la sicurezza, quindi tutte le VM sulla stessa rete virtuale possono comunicare tra loro su quella rete. Questo è l'opposto del principio di non fidarsi (zero trust), quindi devi decidere cosa è più importante per te. Azure utilizza Active Directory, quindi se hai già un Active Directory maturo e consistente, allora è una buona scelta per la gestione delle identità.\n\n## Google Cloud Platform\n\nLa piattaforma Google Cloud Platform (GCP) punta anche sulla facilità d'uso, ma si basa sulle macchine virtuali (VMs) e sulla sicurezza di rete per assicurarsi. È possibile avere profili che chiudono completamente tutto su una VM, oppure un profilo che li apre un po' di più. In termini di restrizioni, si collocano nel mezzo della strada. Sebbene non sia tanto robusta quanto AWS o Active Directory, la GCP offre una buona gestione dell'identità.\n\nTutti e tre questi fornitori di servizi cloud offrono IAAS, PAAS, SAAS, Container as a Service e una varietà di XAAS. È necessario valutare il modello di sicurezza e comprendere le differenze in ognuno.\n\nIn alcuni aspetti, capire il modello di sicurezza della responsabilità condivisa è più difficile che semplicemente gestire le cose in locale perché ora sono coinvolti più attori e la complessità aumenta. La chiave sta nel comprendere i modelli e utilizzare gli strumenti disponibili per aiutarti a gestire la sicurezza su più cloud.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT78-it","image":"./episodes/edt-78/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, spiega i modelli di sicurezza condivisa della responsabilità. Chi è responsabile della sicurezza può diventare confuso nel cloud; la responsabilità dipende dai modelli di fornitura di servizi cloud e da altri fattori."},{"id":152,"type":"Episode","title":"Lavoratori remoti di integrazione","tags":["covid","remoteworker","mobilementor","genz","people","process","compute","cloud"],"body":"\r\n\r\nDopo una carriera internazionale presso Nokia, Denis ha fondato Mobile Mentor 17 anni fa. L'azienda è nata dalla sua esperienza che le persone non utilizzavano appieno la tecnologia dei loro smartphone. Nonostante gli smartphone avessero tecnologie avanzate, le persone li usavano solo per funzioni di base come le chiamate telefoniche e i messaggi di testo. Un momento fondamentale è stato quando Denis stava cercando di vendere una soluzione di rete a un CEO, e il CEO ha chiesto perché la sua azienda dovesse acquistare ulteriori infrastrutture quando i clienti non stavano utilizzando quello che l'azienda aveva già acquistato.\n\nDenis si chiese perché la tecnologia fosse così avanti rispetto a ciò che i consumatori volevano effettivamente fare con i loro dispositivi. Lasciò Nokia e fondò Mobile Mentor per risolvere quel problema. Assunse un esercito di persone esperte in tecnologia che si sarebbero sedute con i clienti aziendali per aiutarli a far funzionare i loro smartphone e permettere loro di essere produttivi, imparando successivamente molto su ciò che spinge l'adozione della tecnologia e le abitudini ad essa legate.\n\nOggi, i lavoratori a distanza possono avere due o tre dispositivi, oltre ai dispositivi personali. Lavorano da casa, dall'ufficio e viaggiano. La maggior parte del lavoro che Mobile Mentor fa attualmente consiste nel far funzionare questi dispositivi e, soprattutto, nell'assicurarsi che siano sicuri.\n\nPoiché il numero di lavoratori da remoto è aumentato in modo esponenziale a causa del COVID, e molte organizzazioni non hanno implementato o dato priorità alla sicurezza adeguata, c'è stata e continua a esserci un'avalanga di attacchi informatici e ransomware. Gli attacchi ransomware sono aumentati del 500% dall'inizio della pandemia, colpendo tragicamente scuole, ospedali e organizzazioni municipali.\n\nInoltre, a causa della carenza di chip, molte aziende non sono riuscite a ottenere dispositivi sufficienti per i lavoratori remoti e hanno dovuto fare affidamento sul BYOD (Porta il Tuo Dispositivo). L'utilizzo di fonti domestiche di internet ha anche aumentato il profilo di rischio.\n\nUna cosa che le organizzazioni possono fare per ridurre i rischi è eliminare l'uso delle password. Le password erano un'idea fantastica nel 1961, ma nel 2021 i dati hanno dimostrato che sono la principale causa degli attacchi informatici alle organizzazioni. La maggior parte degli attacchi inizia con una password compromessa attraverso una operazione di phishing.\n\nI lavoratori del conoscimento oggi hanno un numero ridicolo di password. Tuttavia, solo il 31% delle persone utilizza un gestore di password. Un altro 31% scrive le proprie password di lavoro in un diario personale e il 24% le scrive su un'applicazione di Note sul proprio smartphone. In modo allarmante, secondo uno studio della BBC dell'anno scorso, il 15% della popolazione britannica utilizza il nome del proprio animale domestico come password e il 6% utilizza la parola \"password\".\n\nIl primo passo per liberarsi delle password è abbracciare le biometrie. Ora, un iPhone o una macchina Windows Surface scansionano il tuo viso e ti accedono nel sistema operativo e in tutte le applicazioni di accesso singolo e di terze parti in cui hai quell'identità federata. È un ottimo inizio. Il futuro della riduzione dell'uso delle password sarà una combinazione di biometria e autenticazione a due fattori ovunque. Nel frattempo, mentre ci sono ancora infrastrutture di identità obsolete e applicazioni legacy in cui le biometrie non funzionano, ha senso utilizzare uno strumento di gestione delle password.\n\nMobile Mentor ha condotto un sondaggio sull'industria per generazione e ha scoperto che la Generazione Z ha la maggior quantità di password. Molti di questi giovani ventenni si sono uniti alla forza lavoro e si sono inseriti a distanza durante la pandemia. In molti casi, non hanno mai incontrato il loro datore di lavoro e non hanno vissuto le connessioni sociali che si creano in un ambiente di lavoro. Hanno quindi una prospettiva unica nel valutare il loro datore di lavoro.\n\nLa ricerca di Mobile Mentor mostra che le persone preferiscono lavorare da casa, ma in tutti i settori credono di essere più produttive in un ambiente d'ufficio. Questa è una interessante sfida e dicotomia per l'azienda cercare di far venire queste persone in ufficio. La ricerca mostra che il 67% della Generazione Z ritiene che altre aziende facciano un lavoro migliore nel fornire tecnologie per i propri dipendenti. Quindi, se un datore di lavoro insiste perché vengano in ufficio, potrebbero optare per un lavoro diverso. Cambiare lavoro oggi non significa solo cambiare pendolarismo o qualcos'altro, ma anche utilizzare un computer portatile diverso. Questo fa parte di ciò che sta accadendo con la grande rinuncia.\n\nCon questa dinamica, l'esperienza tecnologica conta. La ricerca mostra che in media ci vogliono tre giorni per configurare completamente un laptop per il lavoro, rispetto ai due giorni di un dipendente in ufficio. I lavoratori remoti devono sollevare in media tre ticket di assistenza per far funzionare il loro dispositivo, quindi la loro esperienza può essere dolorosa. Non gradiscono lo stigma di chiedere aiuto.\n\nIl modo migliore per risolvere questo problema è semplificare il processo. La configurazione senza intervento è l'ideale, ovvero il processo di configurazione della tecnologia in modo che un'azienda possa spedire dispositivi a un dipendente remoto e, quando accedono con le credenziali di lavoro, i dispositivi si configurano automaticamente. Tutto funziona in meno di un'ora e nessuno del reparto IT ha dovuto configurare manualmente i dispositivi, reimballarli e spedirli al dipendente. C'è molto lavoro preliminare per rendere questo possibile, ma Mobile Mentor può aiutare i clienti con questo processo.\n\nDenis crede che i CIO impareranno concetti importanti studiando la generazione Z e i lavoratori remoti. I lavoratori della generazione Z presentano attitudini diverse, in particolare per quanto riguarda la sicurezza e la privacy. Danno molta importanza e priorità alla privacy personale rispetto alla sicurezza, quasi quattro a uno. Per una generazione che è cresciuta con i social media, questo è difficile da comprendere, ma i dati sono chiari. Sono iperconsapevoli delle politiche sulla privacy del proprio datore di lavoro, ma quasi ciechi rispetto alle iniziative di sicurezza aziendale.\n\nIl consiglio di Denis ai CIO per questa questione è di posizionare la privacy e la sicurezza come due facce della stessa medaglia. La Generazione Z può essere coinvolta nella sicurezza se viene presentata come protezione dei loro dati personali, così come quelli dell'azienda, e quindi anche di quelli dei loro clienti.\n\nLa ricerca di Mobile Mentor mostra che il shadow IT è guidato e accelerato dai lavoratori remoti. I lavoratori remoti che vivono lontano dalla sede centrale potrebbero partecipare a un team IT che non hanno mai incontrato e stanno scoprendo applicazioni, meccanismi di archiviazione e modalità di comunicazione e collaborazione che le loro aziende non conoscono. Le linee tra personale e lavoro si stanno anche confondendo. Le persone utilizzano dispositivi personali per lavoro e quasi la metà permette ai membri della loro famiglia di giocare con i loro dispositivi di lavoro. Lo stesso numero di persone trova le politiche di sicurezza aziendale troppo restrittive e un terzo afferma di aver trovato un modo per aggirare tali politiche. Due terzi affermano di essere più efficienti quando utilizzano app di consumatori come Gmail e Dropbox.\n\nDenis consiglia ai CIO di coinvolgere i lavoratori remoti nelle decisioni future sui prodotti, poiché sono loro a mettere alla prova gli strumenti di collaborazione, gli strumenti di archiviazione, le applicazioni e il processo di autenticazione più velocemente di chiunque sia basato in ufficio.\n\nPer ulteriori informazioni su Mobile Mentor, vai su mobile-mentor.com. C'è un sito web separato, endpointecosystem.com, dove condividono gratuitamente tutte le loro ricerche per educare e informare le aziende su ciò che sta accadendo con i lavoratori remoti al fine di evitare la prossima ondata di attacchi informatici e migliorare l'esperienza tecnologica dei dipendenti onboarded.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Denis O&#39;Shea"],"link":"/episode-EDT79-it","image":"./episodes/edt-79/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, Denis O’Shea, fondatore di Mobile Mentor, parla della sua esperienza, ricerca e consigli per l'integrazione dei lavoratori remoti, in particolare i lavoratori della Generazione Z."},{"id":153,"type":"Episode","title":"Protezione del telelavoratore Parte 2","tags":null,"body":"\r\n\r\n## Tecnologie client per la sicurezza del lavoratore a distanza\n\nLa sicurezza lato client inizia e si conclude con la capacità di verificare il client tramite un avvio sicuro. Intel ha fornito questa tecnologia nei sistemi dei nostri clienti da anni, con Secure Boot con la tecnologia di esecuzione affidabile (TXT) e più recentemente con BootGuard (BtG). Sulle piattaforme più recenti, disponiamo di Intel Hardware Shield, un insieme di tecnologie che proteggono il sistema al livello più basso, a livello di firmware e BIOS. È così che un sistema di controllo degli accessi aziendali può verificare che un client sia avviato in modo sicuro e abbia il firmware corretto e i controlli di sicurezza corretti prima di ottenere l'accesso all'azienda.\n\nIntel ha anche svolto molto lavoro nel corso degli anni per aiutare le organizzazioni a proteggere meglio i loro dati. Inoltre, abbiamo permesso al cliente di attivare la crittografia ovunque senza alcun impatto sulle prestazioni. Abbiamo implementato nuove istruzioni in quasi ogni generazione dei nostri prodotti, aggiungendo nuove capacità per proteggere il telelavoratore.\n\nIl nostro altro obiettivo è stato proteggere le applicazioni e i loro dati in uso. Qui entra in gioco Intel Software Guard Extensions (SGX). Ciò consente alle organizzazioni di mettere parti chiave delle applicazioni e dati importanti in enclave di memoria crittografata sicura. Con il telelavoro, ciò significa che è possibile distribuire le applicazioni in ambienti non affidabili e mantenere comunque un alto livello di sicurezza.\n\nInoltre, la nuova tecnologia che Intel ha introdotto nella categoria di rilevamento delle minacce consente alle organizzazioni di ottenere una profonda visibilità sulle operazioni della piattaforma per monitorare le minacce; nessun malware può nascondersi. Queste tecnologie stanno rivoluzionando il modo in cui rileviamo il malware utilizzando l'apprendimento automatico e l'intelligenza artificiale.\n\n## Tecnologie per la sicurezza del telelavoro nei data center\n\nAnche se hai assicurato i clienti, devi anche assicurare il centro dati. Entrambi i lati devono essere protetti poiché il tuo sistema è sicuro solo quanto il collegamento più debole. Molte delle tecniche per proteggere il telelavoratore sono simili a quelle per proteggere l'azienda: avvio sicuro, sicurezza della virtualizzazione e controlli di isolamento. Ancora una volta, tecnologie come Intel TXT e BootGuard ti consentono di avviare in modo sicuro quelle piattaforme e gli asset del centro dati e del cloud. Più di recente, abbiamo introdotto la tecnologia Intel Select Solutions for Hardened Security, che integra molte delle tecnologie di sicurezza Intel in una singola piattaforma abilitata per impostazione predefinita.\n\nÈ necessario essere in grado di proteggere i propri dati su larga scala, ovvero di poter utilizzare tutti gli strumenti di sicurezza senza influire negativamente sulle prestazioni. Gli strumenti di crittografia con accelerazione hardware di Intel (SHA, AES-2X, VPMADD52) rendono ciò possibile. Le nuove istruzioni di Intel e le tecnologie QuickAssist sono appositamente progettate per soddisfare le esigenze di crittografia scalabile per le aziende e per il cloud.\n\nInfine, come monitori l'intelligence delle minacce e l'audit su larga scala? L'architettura della piattaforma di intelligence cibernetica di Intel (FPGA, DCPMM, Optane SSD) utilizza tecnologie di calcolo ad alte prestazioni, archiviazione e memoria per scalare la piattaforma di intelligence cibernetica, anche con l'onere aggiuntivo di una maggiore sicurezza esterna con i telelavoratori.\n\n## Soluzioni a breve termine.\n\nL'educazione dei dipendenti è la prima linea per limitare le minacce alla sicurezza del telelavoro. È cruciale fornire indicazioni sulla sicurezza domestica e offrire formazione sulla sicurezza o rafforzare la formazione precedente in ambiti come l'accesso corretto ai dati. Sii pro-attivo con gli aggiornamenti, spingendo per l'installazione di patch e richiedendo agli utenti di aggiornare i propri dispositivi. Se hai il controllo degli accessi dell'azienda, le soluzioni ERM/DRM e DLP, attivali e diffondili. Rivaluta le tue politiche per assicurarti che si adattino alla nuova realtà dei telelavoratori. Per le connessioni web, attiva il TLS e assicurati che sia applicato. È fondamentale utilizzare l'autenticazione a due fattori. Molte organizzazioni potrebbero pensare di non avere l'infrastruttura necessaria per implementarla, ma ci sono vari fornitori che possono aiutare in questo settore senza richiedere di implementare una grande quantità di nuova infrastruttura.\n\nMolte soluzioni sono semplicemente igiene standard: Assicurati che i tuoi agenti di sicurezza per il punto finale siano abilitati e aggiornati. Gestisci e applica le politiche di sicurezza per i diversi tipi di dispositivi degli utenti. Abilita la crittografia del disco completo.\n\nLe organizzazioni devono comprendere che i lavoratori a distanza operano in un ambiente in cui è molto probabile che un dispositivo venga utilizzato da altre persone in varie circostanze. Buoni controlli di sicurezza, soprattutto l'educazione dei dipendenti, possono prevenire problemi e consentire ai dipendenti di operare senza impatti negativi.\n\n## Soluzioni a lungo termine.\n\nUn piano a lungo termine per la sicurezza in un ambiente con lavoratori a distanza è ora necessario, che sia per un passaggio permanente a un numero maggiore di lavoratori remoti o per affrontare un'altra pandemia o situazione simile. Ci sono diverse azioni che le organizzazioni dovrebbero intraprendere ora per sostenere questa realtà in futuro.\n\nUna delle migliori pratiche consiste nell'implementare politiche di zero trust. Questo riduce la dipendenza dalla necessità di fidarsi di ogni aspetto degli utenti e dei client che accedono. Insieme a ciò, l'autenticazione multi-fattore per gli utenti e i dispositivi dovrebbe diventare uno standard per l'organizzazione. Per coloro che ancora non hanno adottato ERM e il controllo dell'accesso ai dati basato su politiche, è ora il momento di farlo per proteggere i dati sia fuori sede che in loco. È importante implementare soluzioni di sicurezza a stack profondo anziché solo a livello di applicazione o rete. Questo include l'avvio sicuro con attestazione, la virtualizzazione e la sicurezza del contenimento, e la sicurezza e il monitoraggio del firmware. È importante estendere l'audit, l'intelligence sulle minacce e il monitoraggio agli ambienti di telelavoro, nonostante il rifiuto degli utenti che non vogliono ulteriori monitoraggi sui loro sistemi. Inoltre, considerare di estendere la sicurezza oltre il dispositivo nelle sedi dei telelavoratori quando possibile, ad esempio mediante dispositivi e reti gestiti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT8-it","image":"./episodes/edt-8/it/thumbnail.png","lang":"it","summary":"Con molti dipendenti che ora lavorano da casa, come fai a garantire che lavorino in modo sicuro ma allo stesso tempo dandogli la flessibilità di cui hanno bisogno per portare a termine i loro compiti? In questo episodio, Darren e l'ospite speciale Steve Orrin, CTO di Intel Federal, discutono di come sfruttare la tecnologia Intel per aiutare in modo efficace a proteggere i lavoratori da remoto."},{"id":154,"type":"Episode","title":"Incontro con gli architetti delle soluzioni Cloud di Intel","tags":["csa","cloudsolutionarchitect","solutionarchitect","people","compute","cloud"],"body":"\r\n\r\nIntel ha investito molto nell'assunzione di alcuni dei migliori CSA nel settore, con circa 80 architetti a livello globale e 22 negli Stati Uniti. Questi sono nuovi ruoli con un forte focus.\n\nStephen Holt è un CSA per l'Est e gestisce gli altri CSA in quell'area. In precedenza, presso Intel, si è specializzato in database, ma proviene da ruoli diversificati nel processo aziendale, nell'analisi e nelle vendite, nell'analisi tecnica e nelle vendite tecniche presso IBM e una serie di startup. Porta tutta questa esperienza in Intel per aiutare il team a lavorare insieme per offrire valore ai clienti.\n\nKiran Agrahara è un CSA della costa est, che riferisce a Stephen. La sua esperienza riguarda l'infrastruttura del data center focalizzata sulla virtualizzazione dello storage dei dati. Ha lavorato nelle industrie dei cavi e finanziaria. Negli ultimi cinque o sei anni, ha collaborato con startup che si concentrano su aree come la memoria persistente e lo storage definito dal software. Quando i clienti chiedono a Kiran perché dovrebbero utilizzare l'esperienza di Intel, lui risponde che Intel è ovunque e vuole diffondere questo messaggio agli utenti finali.\n\nPrima che Sarah Musick arrivasse in Intel come CSA, era una partner che svolgeva lavori di software per la migrazione e l'ottimizzazione del cloud, che furono precipitati da un periodo di analisi dei dati. Prima di ciò, ha lavorato per un'azienda di analisi testuale per l'apprendimento profondo e ha scoperto che il lavoro svolto sui dati riportava gran parte di ciò che faceva nel suo precedente ruolo di vendita tecnica. Porta l'analisi dei dati per la migrazione al cloud. È venuta in Intel a causa della sua integrità e del suo ruolo nel nuovo modello di coinvolgimento per tutti, inclusi i fornitori di cloud.\n\nTodd Christ lavora in Intel da 26 anni, con 30 anni di esperienza nel settore IT e dei prodotti. Di recente proveniva dal gruppo delle soluzioni enterprise cloud di Intel, che fa parte del gruppo delle piattaforme dei data center. Intel desidera incontrare i clienti dove si trovano i loro dati, sia in loco che nel cloud. Todd ha progettato Anthos, quindi i modelli di cloud ibrido o multi-cloud sono stati importanti per lui ed ha lavorato direttamente con Microsoft e Google.\n\nUna grande trasformazione nell'aiutare i clienti a spostarsi verso il cloud è la semplicità. Ora, i clienti non devono pensare molto all'hardware. Sono in grado di fare il lavoro significativo molto più velocemente e con meno spese generali. Anche se l'hardware conta comunque, ovviamente, viene astratto. Tuttavia, è importante non perdere di vista le fondamenta. È come avere un sistema di climatizzazione che non si pensa mai fino a quando non funziona correttamente, e allora diventa un problema. Ad esempio, ci sono situazioni in cui un cliente scopre che un particolare carico di lavoro che ha spostato nel cloud non funziona bene, quindi deve rivedere l'hardware.\n\nIntel è stata con i fornitori di cloud fin dalla loro nascita e si focalizza su quelle carichi di lavoro. Intel dedica un'enorme quantità di sforzi all'ecosistema del cloud che aiuta a sviluppare quei carichi di lavoro per un ottimale funzionamento su Intel.\n\nIntel ha consegnato 2 miliardi di core ai fornitori di servizi cloud (CSP) e oltre il 90% di tutti i calcoli nel cloud si svolge su piattaforme Intel.\n\nI clienti vogliono una rapida scalabilità e desiderano le risorse di calcolo il più velocemente possibile; non importa loro quale sia l'hardware. La verità, però, è che i carichi di lavoro a bassa latenza funzionano molto meglio sull'hardware Intel rispetto a qualsiasi altro concorrente. Il processore scalabile Xeon di terza generazione più recente, Icelake, è incredibilmente veloce. Una volta che i clienti si rendono conto che possono risparmiare in modo significativo, si vende da solo. Quindi, parte del lavoro di un CSA è l'educazione.\n\nAnche se i CSP possono sembrare di vendere servizi come un'utilità che funziona immediatamente con una affidabilità al 100%, non puoi semplicemente trasferire o spostare i carichi di lavoro critici nel cloud.\n\nSe le tue applicazioni sono progettate in un formato cloud-native, allora non devi preoccuparti molto di implementarle nel cloud. Tuttavia, se hai un'applicazione monolitica progettata per essere eseguita in un data center, ad esempio, non puoi semplicemente trasferirla nel cloud perché non è ottimizzata per essere eseguita su CPU specifiche. Utilizzando strumenti di ottimizzazione o migrazione di Intel, i clienti possono prendere decisioni informate prima della migrazione.\n\nAlcuni carichi di lavoro potrebbero non essere adatti per il cloud. Ecco perché, soprattutto nella seconda metà del 2021, si è sentito parlare di rimpatrio. Il pendolo sta oscillando nuovamente mentre le aziende, in particolare, imparano a trovare il giusto equilibrio. Qui entrano in gioco le CSAs. Non tutto dovrebbe essere portato sul cloud e Intel può aiutare a determinare come ottimizzare le cose. Alcuni clienti stanno scoprendo che, dopo aver spostato i carichi di lavoro sul cloud a causa di requisiti, non stanno risparmiando denaro e addirittura spendono significativamente di più rispetto a mantenere le cose nel loro centro dati. Oppure ci possono essere problemi di sicurezza perché alcuni dati devono risiedere in determinati luoghi e il cloud non si trova nel paese corretto.\n\nGli Intel CSAs sono agnostici, quindi sono interessati solo a ciò che è migliore per le esigenze particolari dei clienti. Aiutano a rendere i carichi di lavoro più mobili, in modo che mentre i dipartimenti IT diventano più maturi, possano riportare i carichi di lavoro nei propri data center o spostarli verso un altro CSP in futuro, o qualunque sia più conveniente in termini di costi. Gli Intel CSAs possono aiutare i clienti in modi che attualmente gli CSP non affrontano.\n\nMolti clienti sono preoccupati per i dati perché è costoso recuperarli da un CSP. Intel dispone di un team competente di persone in grado di aiutare con questa problematica. Sono ben informati non solo sulle strutture per poter configurare modelli ibridi, ma anche sulla sicurezza, i firewall e tutti i punti di accesso. Una volta che i tuoi dati sono dietro un firewall, ci sono molteplici livelli di sicurezza che devi superare per accedere a quei servizi. Quindi, la prima cosa da fare è riuscire a inviare i tuoi dati in modo sicuro avanti e indietro.\n\nAnche in uno scenario multi-cloud, estrarre i dati è costoso. Se ti stai spostando solo tra Azure e AWS, ad esempio, i dati stanno comunque migrando e questo è un processo lento. Se i clienti hanno terabyte o addirittura petabyte di dati in locale che vogliono spostare nel cloud, potrebbe esserci un servizio cloud-like che viene eseguito in locale dove possono ottenere la facilità d'uso e la funzionalità di un cloud. Se pensiamo al cloud come a una funzione più che a una posizione, ci sono più possibilità.\n\nIntel è qui per liberare le persone dal fare il lavoro più significativo per la propria organizzazione, e l'analisi dei dati sarà una parte fondamentale di ciò. Nel 2022, esiste ancora un'enorme differenza tra la quantità di dati posseduti dalle persone e la quantità di informazioni che ne derivano. Solo circa il 3% dei dati viene effettivamente utilizzato per produrre insight. Quindi c'è un enorme tesoro nascosto e i chipset Intel si comportano bene in situazioni in cui è necessario un robusto lavoro di elaborazione. L'elaborazione dei dati è ciò che sta arrivando.\n\nArchitettare saggiamente fa parte del futuro perché non è necessario reinventare la ruota. D'altro canto, ci saranno soluzioni più recenti che potrebbero essere adatte a un'organizzazione. Dove un'organizzazione si trova nel suo percorso è anche fondamentale. Le aziende più vecchie ed affermate che hanno fatto bene le cose per molto tempo, ad esempio, possono avere molto debito tecnico che potenzialmente potrebbe essere affrontato. Devono guardare alla tecnologia sottostante e poi alla fine portarla in un luogo in cui abbiano agilità.\n\nI servizi CSA presso Intel sono gratuiti perché Intel desidera aiutare i clienti a eseguire carichi di lavoro in modo più efficace e a sfruttare la tecnologia Intel che è ubiquitaria nelle nuvole. L'esperienza e la competenza dei CSA di Intel sono profonde e lavorano come un team per fornire qualsiasi tipo di conoscenza di cui il cliente potrebbe avere bisogno. I clienti dovrebbero chiedere al loro responsabile dell'account Intel o alle vendite interne di ottenere assistenza da un CSA per la migrazione e l'ottimizzazione del cloud.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Stephen Holt","Kiran Agrahara","Sarah Musick","Todd Christ"],"link":"/episode-EDT80-it","image":"./episodes/edt-80/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, parla con i principali architetti delle soluzioni cloud di Intel, Stephen Holt, Kiran Agrahara, Sarah Musick e Todd Christ, su come possono aiutare le organizzazioni, gratuitamente, a migrare verso il cloud e ottimizzare i loro carichi di lavoro."},{"id":155,"type":"Episode","title":"Programmazione eterogenea con OneAPI","tags":["cpu","fpga","gpu","heterogeneousprogramming","npu","oneapi","compute","technology","process"],"body":"\r\n\r\nL'obiettivo di oneAPI è aiutare ad astrarre l'enorme diversità che sta emergendo nel campo dell'hardware, in modo che gli ingegneri del software possano sfruttarla più in alto nella pila e ottenere il massimo dall'hardware. James, un ingegnere del software che lavora anche a stretto contatto con l'hardware, è entusiasta di ciò che oneAPI può contribuire alla luce della tendenza al calcolo eterogeneo.\n\nLa parola eterogeneo qui significa fondamentalmente che ci sono dispositivi diversi in un sistema che possono eseguire calcoli, ma non eseguono lo stesso insieme di istruzioni. Ad esempio, la CPU ha un modo di eseguire le istruzioni e la GPU ne ha uno diverso. FPGA, altre ASIC e dispositivi specializzati hanno ognuno modi diversi di essere programmati. Approfittare di tutti questi è l'obiettivo.\n\nJohn Hennessy e David Patterson, leader nel campo dell'architettura informatica, lo hanno definito la nuova era d'oro dell'architettura informatica. Per gli architetti informatici, è un momento straordinario per progettare dispositivi specializzati di ogni tipo per migliorare le performance in specifici domini, ma per i programmatori può essere difficile e persino spaventoso a causa della complessità. Ed è qui che entra in gioco l'iniziativa oneAPI e i prodotti oneAPI.\n\nIl nome, oneAPI, è sia un'iniziativa con una specifica sia un'implementazione. L'iniziativa è un concetto semplice: gli sviluppatori di software dovrebbero avere la libertà di utilizzare qualsiasi dispositivo desiderino con piena performance e il loro codice dovrebbe preservare il suo valore; non dovrebbero dover riscrivere per ogni nuovo dispositivo. Queste caratteristiche possono essere applicate a compilatori, librerie, debugger e qualsiasi tipo di strumento.\n\nUn gran numero di software per implementare specifiche particolari è stato aperto come open-source. Molti di essi provengono da Intel, ma poi Intel li rende disponibili anche come toolkit scaricabili che sono già precompilati e pronti all'uso per supportare l'hardware Intel. Altri fornitori che creano parti di oneAPI hanno le proprie implementazioni, quindi tutti collaborano sulle specifiche ma ognuno può creare un supporto per il proprio hardware in un modo aperto e multivendor.\n\nL'obiettivo principale è scrivere il codice una volta e farlo funzionare bene ovunque. Tuttavia, si tratta di un problema complesso che richiederà del tuning delle prestazioni. Ad esempio, se un algoritmo funziona bene su una GPU, funzionerà in modo simile su qualsiasi altra GPU. Se si passa l'algoritmo a un FPGA, è possibile massimizzare il riutilizzo del programma, ma si ha la possibilità di ricodificare parti dell'algoritmo affinché funzioni altrettanto bene. Si tratta di un approccio complesso che consente di sfruttare l'hardware con diversi gradi di riscritture isolate, si spera.\n\nPuoi creare un solo codice per dispositivi diversi. Ci sono approcci di runtime ancora più sofisticati che ti consentono di rilevare ciò che è presente ed eseguire diverse parti di codice in modo da poter effettivamente avere un codice sorgente comune che decide dinamicamente. Puoi applicare un programma di distribuzione e può capire cosa c'è nel tuo computer e usarlo dinamicamente anziché chiedere all'utente di eseguire un binario diverso a seconda del computer su cui ti trovi.\n\nQuesta è emozionante perché, per molto tempo, gli ingegneri hanno utilizzato una pila software che era la migliore per la loro macchina. Oggi, vogliono compilare un programma che può utilizzare dispositivi da vari fornitori. Il programma dovrebbe reagire a questo. Affinché ciò funzioni, il compilatore deve essere in grado di generare codice per questi vari dispositivi in ​​modo affidabile. Qui entra in gioco l'apertura.\n\nAlcuni sosterranno che un sistema chiuso otterrà prestazioni migliori poiché le librerie e il linguaggio sono ottimizzati specificamente per le capacità dell'hardware. Ma la domanda è, come si può ottenere il meglio di entrambi i mondi? Se, ad esempio, esiste una implementazione specifica del fornitore per una libreria matematica, può esserci un programma comune. Una grande parte di oneAPI non cerca di reinventare l'intero mondo, ma cerca di organizzarlo in modo da sfruttare al massimo il meglio su ogni piattaforma possibile.\n\nOneAPI ha la capacità di spostare la memoria e i dati. Diversi modelli di programmazione si trovano sopra a OneAPI ed è tua scelta quanto vuoi essere coinvolto nella gestione della memoria. Spostare i dati è costoso e consuma energia, quindi non puoi evitarlo, ma OneAPI ti fornisce gli strumenti per gestirlo interrogando il sistema e consentendo al tuo programma, durante l'esecuzione, di prendere le decisioni dinamiche giuste che ti garantiranno la migliore performance.\n\nIntel ha decenni di esperienza nella costruzione di strumenti per aiutare nella messa a punto e nella migrazione, e dispone di compilatori altamente ottimizzanti. V2 ha contribuito a far evolvere l'industria intorno ai contatori hardware sui processori, diventando la norma. Ci sono una varietà di altri strumenti di analisi per fornire feedback dalla struttura del tuo programma alla ricerca di deadlock e applicazioni parallele, per trovare dove è necessario aggiungere alcune protezioni. Intel sta rendendo tutti questi strumenti disponibili in stile oneAPI, per essere più versatili rispetto a essere solo per una CPU.\n\nI primi gruppi ad adottare oneAPI includono il calcolo ad alte prestazioni (HPC). Con l'esplosione di nuove idee di architettura informatica, ci sarà un maggior livello di diversità e innovazione in questo settore. I grandi codici in grado di aiutare a risolvere i più grandi problemi di ingegneria del mondo, o ad esempio, risolvere problemi farmaceutici e valutare nuovi medicinali, richiedono hardware all'avanguardia. Quindi questo concetto di portabilità delle prestazioni è arrivato ai laboratori nazionali, alle università e ai centri di ricerca.\n\nL'HPC di oggi è il server del dipartimento di domani, quindi la capacità di utilizzare hardware diversi richiede agli ingegneri del software di pianificare e prestare attenzione a quanto il codice sia portabile perché il codice non muore rapidamente; dura decenni. Tra pochi anni, i sistemi eterogenei toccheranno tutti e ora è il momento di informarsi a riguardo.\n\nGli ingegneri del software non hanno bisogno di programmare in parallelo per trarre vantaggio da oneAPI. Si tratta di utilizzare cose che sono aperte e capaci di funzionare con più venditori e più architetture. Anche gli ingegneri che sono al vertice della pila dovrebbero capire cosa c'è nella pila e cosa è in grado di fare in termini di portabilità e portabilità delle prestazioni.\n\nLa comunità IoT è un altro gruppo che è stato molto avanti nella programmazione su dispositivi di calcolo multipli ed eterogenei, utilizzando metodi diversi per gestirli. Le loro capacità di calcolo continuano ad aumentare man mano che la tecnologia avanza. Quindi, oneAPI è applicabile qui e può aiutare a formalizzare o standardizzare cose che sono state innovative per prime nel mondo degli embedded.\n\nL'idea di una singola API è passata dall'essere una folle idea di cui parlavano solo poche persone, fino ad essere sempre più riconosciuta come sensata e risolutiva per i problemi della propria organizzazione.\n\nIl luogo più semplice per apprendere dell'iniziativa è il sito web oneapi.io. Per apprendere dell'implementazione, clicca sulla scheda di implementazione per seguire un link che ti porterà alle implementazioni Intel. Lì, potrai scaricare i diversi toolkit. Cerca il cloud per sviluppatori Intel per provare gratuitamente gli strumenti nel cloud, inclusi su hardware diversi. Il sito web oneapi.io offre anche una varietà di tutorial e risorse.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","James Reinders"],"link":"/episode-EDT81-it","image":"./episodes/edt-81/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect di Intel, discute delle capacità e del futuro di OneAPI, un modello di programmazione unificato, aperto e basato su standard che offre un'esperienza comune agli sviluppatori attraverso le architetture degli acceleratori, con James Reinders, Chief Evangelist di OneAPI di Intel."},{"id":156,"type":"Episode","title":"Passando dall'infrastruttura ai carichi di lavoro","tags":["cloudmigration","cloud","compute","process","infrastructure","migration","workload"],"body":"\r\n\r\nLe conversazioni di Sarah con i clienti sono passate dal parlare dell'infrastruttura al parlare dei carichi di lavoro. Una ragione evidente per questo è stata la transizione dal centro dati alla commoditizzazione delle risorse al consumo di qualsiasi cosa come servizio. Un'altra ragione è l'influenza delle squadre di app nelle decisioni architettoniche. Le applicazioni sono il sostegno vitale delle organizzazioni in un modo che non erano nemmeno cinque anni fa. L'ultima ragione è finanziaria: i budget sono ora categorizzati per carichi di lavoro anziché per spese IT generalizzate.\n\nUna sfida in questa transizione dall'infrastruttura al carico di lavoro consiste nel trovare un equilibrio tra processi e carichi di lavoro centralizzati e decentralizzati. Alcuni aspetti, come la governance della sicurezza, sono gestiti da un centro centralizzato, mentre altri sono gestiti da team locali più piccoli. Gran parte delle decisioni viene spinta verso i team che stanno creando nuove applicazioni e servizi all'interno del reparto IT e anche solo per i clienti.\n\nLa COVID è stata un acceleratore per promuovere il cambiamento e spingere le organizzazioni verso il cloud. Alcune organizzazioni IT stanno permettendo alle loro applicazioni di passare al cloud senza restrizioni, preferendo risolvere eventuali problemi successivamente anziché rallentare l'innovazione in corso. Questo evento \"Cigno Nero\" è senza precedenti e stiamo ancora vedendo le conseguenze di questa rapida svolta paradigmatica.\n\nIl ruolo del CIO è tornato, ma solo se iniziano a pensare di nuovo all'informazione e agli oneri di lavoro anziché gestire un data center. Naturalmente, dipende dall'organizzazione. Le organizzazioni native del cloud, o quelle che aspirano a diventarlo, stanno ristrutturando le proprie applicazioni mentre sono in esecuzione perché vogliono essere estremamente agili. Più fanno questo, più si orientano verso l'infrastruttura e il servizio dell'applicazione anziché accettare i limiti che esistevano nel data center in precedenza e lavorare entro quei parametri. In precedenza, in quella situazione, scatenava innovazioni da parte dei team dell'applicazione, perché quando si affronta un insieme di dati stabiliti, la necessità a volte è la madre dell'invenzione, a differenza delle infinite possibilità nel cloud.\n\nQuesto è un estremo dello spettro. All'estremo opposto ci sono le aziende americane con un retaggio, le istituzioni. Tipicamente, dispongono ancora di informazioni sul mainframe. È una situazione del tipo \"se non è rotto, non aggiustarlo\", soprattutto con le applicazioni statiche. Il cloud sta permettendo ai CIO di pensare oltre il vecchio modo di gestire queste applicazioni. Se i CIO possono abbracciare queste nuove tecnologie, ora possono vedere una strada avanti.\n\nIl trattamento che avviene sotto applicazioni discrete è più rilevante che mai. Intel svolge un ruolo fondamentale nel rispondere alle preoccupazioni sulla performance o sui costi nelle offerte cloud, in parte perché è stata la progenitrice di queste tecnologie e anche perché è una delle più grandi aziende di software. Esiste un'enorme quantità di conoscenza interna. In altre parole, non tutte le istanze del cloud sono uguali, quindi Intel ha ottimizzato i carichi di lavoro internamente per ottenere il massimo dalle istanze cloud che utilizza.\n\nAd esempio, molte organizzazioni stanno spostando le loro risorse verso i cluster Kubernetes e Intel fa una tonnellata di ottimizzazioni in tal senso. Possono superare le tipiche Helm charts standard con estensioni che verificano la salute del nodo sottostante e non solo la disponibilità pura. Ci sono molte cose che Intel può fare per aiutare i clienti a migliorare notevolmente le prestazioni e i costi, non solo del 2 o 3 percento, ma del 30 o 40 percento?\n\nNon tutti i carichi di lavoro devono essere nella cloud. La struttura di un'organizzazione ha un impatto su dove il carico di lavoro dovrebbe essere allocato. La chiave è usare la cloud in modo intelligente.\n\nUna strategia multi-cloud di successo prevede la presenza di un cloud primario e di un cloud secondario. Quando si parla di multi-cloud, la motivazione che sta dietro è la paura del vendor lock-in. Il luogo in cui risiede la maggior parte dei tuoi dati ha un'influenza sulla strategia multi-cloud, così come il luogo in cui i carichi di lavoro si adattano meglio.\n\nPer sviluppare una strategia, gli architetti delle soluzioni cloud di Intel si impegnano nella scoperta di ciò che l'organizzazione desidera fare e di quali sono i problemi. Spesso Intel può risolvere molti dei problemi con gli strumenti di cui dispone. Gli architetti delle soluzioni cloud renderanno anche le offerte più contextualizzate per rendere il processo più rapido ed efficiente. Parte del loro lavoro è essere un educatore, in modo che tutti abbiano le informazioni di cui hanno bisogno per andare avanti.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Sarah Musick"],"link":"/episode-EDT82-it","image":"./episodes/edt-82/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solution Architect, Intel, continua la sua conversazione con Sarah Musick, Cloud Solution Architect, Intel, riguardo al passaggio dall'infrastruttura ai carichi di lavoro. Si prega di inserire nella playlist Embracing Digital Transformation."},{"id":157,"type":"Episode","title":"Direzioni IDC 2022","tags":["data","datacentric","people","process","idc2022"],"body":"\r\n\r\nDavid è basato in Maryland, vicino all'epicentro governativo. Ha oltre 25 anni di esperienza nel campo dello sviluppo tecnico e aziendale in infrastrutture critiche come la sanità, l'energia, il settore finanziario e industriale. Gran parte della sua specializzazione si concentra sul margine: cose al limite dell'iperedge e nello spazio integrato, ma anche sui problemi difficili nel migliorare i carichi di lavoro e cercare di ottenere il massimo da un'architettura che si traduce fino all'azienda e al cloud.\n\nDarren, David e alcuni dei loro colleghi hanno partecipato alla conferenza IDC in parte per verificare se le loro proposte e predizioni fossero in linea con le tendenze che IDC ha osservato, e sono tornati sentendosi confermati. Sono anche andati per capire se ci sono delle lacune che necessitano di comprensione e come possono sfruttare le idee e i servizi di IDC.\n\nLa tendenza a lungo termine più grande, su cui si basava l'intera conferenza, è il digitale in primo piano e come sta influenzando praticamente ogni mercato. Meredith Whalen, Chief Research Officer di IDC, ha approfondito il significato reale del digitale in primo piano. Fondamentalmente, qualsiasi organizzazione, azienda o governo, deve chiedersi come trasformare la digitalizzazione in un prodotto effettivo. Entro il 2024, ci saranno circa 10 trilioni di dollari da spendere su tutti i mercati solo per i prodotti digitali. Questo spostamento dei consumatori sta costringendo il governo a considerare anche la digitalizzazione, non solo per i propri servizi, ma anche per il modo in cui si approcciano al commercio mondiale, alle economie e alle valute.\n\nQuesto rappresenta una sfida particolare per i governi a tutti i livelli poiché si confrontano con reti informatiche che operano su molti sistemi diversi, e in molti casi, sono isolati. Non esistono ancora ponti efficaci per collegarli tra loro. I sistemi governativi devono cercare di semplificare e rendere più efficienti le cose.\n\nLa prossima grande tendenza è un ribaltamento con il cloud computing. Ogni fornitore di servizi cloud (CSP) ha la propria infrastruttura e le configurazioni dell'infrastruttura non sono necessariamente portabili, quindi sono necessari ponti. Attualmente, i CSP non sono intercambiabili. È vero che vogliono solo che i clienti utilizzino la loro infrastruttura, ma poiché gli ambienti di sviluppo software e le applicazioni software vengono creati attraverso i loro mercati, è difficile spostarli altrove. I CEO e i CIO non si stanno solo chiedendo se stanno utilizzando le licenze software e gli accessi che hanno acquistato, ma sono più concentrati su se l'uso ha prodotto un risultato desiderato.\n\nIl modello CSP attuale tende ad essere inefficiente tenendo conto degli obiettivi aziendali. I clienti hanno bisogno di ecosistemi di software che lavorino insieme per raggiungere tali obiettivi. Stanno cercando più ecosistemi che lavorino insieme, con gli ecosistemi che si spostano senza soluzione di continuità attraverso più cloud e cloud ibridi. Quindi la tendenza è che i CSP diventino fungibili e i costruttori di ponti avranno un ruolo importante qui. Questo è l'inversione di tendenza.\n\nI dati di oggi sono fungibili. Puoi spostarli, naturalmente con un costo associato, ma puoi anche copiarli, modificarli, ecc. Tuttavia, la tendenza si sta spostando verso dati non fungibili. Quando quei dati, o asset digitali, hanno una proprietà, ciò crea enormi impatti per il futuro su come i dati vengono gestiti in ambiti come la sicurezza, la fiducia e i modelli di business ed ecosistemi ad esso correlati. Ci saranno entità di dati che dovrai accettare e attestare la validità di chi li possiede e da dove provengono e tutte le politiche che li circondano.\n\nIn questa evoluzione ci saranno pro e contro. Da un lato, i consumatori hanno più potere sulla propria privacy se hanno diritti sulle proprie informazioni. Lo stesso vale per le aziende e le organizzazioni. D'altro canto, con entità e beni dati non fungibili, gli ecosistemi del software e gli scienziati dei dati devono gestirli in modo più conciso e strutturato. A lungo termine, tutti dovranno saper gestire tutto ciò. I governi non sono di fronte a questo problema, ma sta diventando sempre più importante come trattano e mescolano il commercio, non solo sui beni fisici, ma anche sui beni digitali.\n\nQuanto è vicina la realtà alla digitalizzazione? Un esempio sono i token digitali utilizzati come valuta reale, come nella comunità di gaming. I token digitali fanno parte di questo mondo rispetto al modo in cui le app e gli ecosistemi utilizzano dati non fungibili. Un altro esempio è nel settore sanitario. Oggi puoi andare dal medico o consultarlo virtualmente, e loro possono vedere ciò che sta accadendo e tu puoi descrivere i sintomi. Tutto ciò viene trasformato attraverso dispositivi indossabili in tempo reale, che possono monitorare i livelli di glucosio, il battito cardiaco, i cambiamenti di peso, ecc. Questi dati appartengono all'individuo, quindi devono essere sicuri e autenticati, ma possono anche essere utilizzati per servizi che non riguardano i sintomi, bensì algoritmi personalizzati e servizi che mostrano cosa sta accadendo effettivamente nel loro corpo per ottenere le migliori diagnosi.\n\nPunti di dati da considerare: Meredith Whalen ha evidenziato che nel 2021 la spesa per i servizi ha superato per la prima volta la spesa per le licenze regolari nel settore dell'IT. Quindi, dato che attualmente il servizio è dominante, la tendenza è che si sposterà verso un modello basato sugli outcome. Nel 2023, IDC prevede che la spesa digitale sarà superiore alla spesa non digitale in tutte le aziende. Ogni settore avrà delle variazioni, ma a livello macro, il 2023 rappresenta il punto di svolta. Nel 2024, seguirà il pool di talenti. IDC predice che la maggior parte delle aziende spenderà di più per il talento tecnico rispetto al talento non digitale.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","David Richard"],"link":"/episode-EDT83-it","image":"./episodes/edt-83/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren, Chief Solution Architect, Public Sector, Intel e David Richard, Lead Solution Architect, Department of Defense, Intel riflettono sulle tendenze e le idee che hanno ricavato dalla conferenza IDC Directions 2022."},{"id":158,"type":"Episode","title":"Proteggere il tuo castello con la Zero-Trust","tags":["cybersecurity","zerotrust"],"body":"\r\n\r\nIl vecchio modello di sicurezza potrebbe essere paragonato a un castello, con guardie lungo la strada e un fossato che circonda il castello. Tutti i gioielli della corona, in questo caso i dati, sarebbero localizzati e gestiti centralmente all'interno del castello. L'emergere della fiducia-zero ha creato un nuovo quadro.\n\nLa minaccia più grande per i dati è l'utente finale, quindi la strategia numero uno è un quadro che parte dal bordo esterno con pilastri di eccellenza e protezioni interne. Questo modo aggiornato di pensare consente alle organizzazioni di coinvolgere realmente la propria missione e i partner commerciali nella conversazione.\n\nLo stile di pensiero vecchio era più orientato ad un approccio a corazza dura, con protezioni e controlli nei punti vulnerabili. Una parte fondamentale dell'architettura del zero trust è un approccio basato sul rischio, che è più dinamico e si basa su due cose: ciò che ha funzionato e ciò che non ha funzionato in passato. Quindi, se gli attaccanti sono entrati dall'ultima volta dalla porta sinistra, rafforzerai naturalmente le difese lì, ma imparerai anche da quell'attacco e rinforzerai altri punti sulla base delle nuove conoscenze su come sia successo. Un approccio basato sul rischio non consiste solo nel risolvere l'ultimo attacco, ma nel pensare in anticipo e applicare i controlli giusti per le minacce attuali e future in tutta l'azienda.\n\nParte dell'approccio basato sul rischio consiste nel comprendere l'ecosistema. I clienti, i partner e gli utenti sono tutti parte del calcolo di sicurezza. Il vecchio approccio a guscio duro non funziona. Proprio come un castello ha persone e rifornimenti che entrano ed escono, e le ricchezze potrebbero trovarsi in diverse località del regno, la \"zero trust\" porta la sicurezza un passo avanti, considerando tutti gli ingressi e le uscite per i dati o le persone che vi accedono.\n\nTradicionalmente, qualcuno poteva ottenere l'accesso con un solo login al castello aziendale. Esistono diversi principi di non fidarsi, ma le due fondamenta sono il rifiuto predefinito e il monitoraggio continua e l'autorizzazione. La fiducia non viene guadagnata automaticamente, né è permanente. Ad esempio, se un ospite entra nel castello, viene convalidato alla reception e poi gli viene chiesto cosa sta visitando. Potrebbe essere autorizzato a visitare una persona in una stanza per un determinato periodo di tempo e sarà scortato durante il trasporto. Verrà anche monitorato per ciò che porta dentro e fuori durante la visita.\n\nLa filosofia Zero-trust si applica a tutti i punti di accesso, come i data center, le piattaforme cloud, i dispositivi edge, gli ambienti aziendali, ecc... È incentrata sui dati e sull'accesso, combinando un approccio basato sul rischio. È necessaria una maggiore strategia. L'approccio basato su Zero-trust che ne deriva non scarta ciò che ha funzionato bene in precedenza, ma combina i buoni processi, i principi e le tecnologie aggiungendo un elemento temporale.\n\nQuesto nuovo elemento non è così difficile come spesso è stato dipinto, ma è un problema di processo e cultura che può risultare complicato.\n\nMolti sviluppatori temono che un'architettura a fiducia zero possa rallentarli, ma gli esperti di sicurezza e gli sviluppatori devono lavorare in partnership per superare questa percezione. Un esempio concreto è Log4j. Sei mesi fa, gli sviluppatori potevano scaricarlo senza problemi, ma ora l'ambiente delle minacce è cambiato. Senza un approccio basato sul rischio, uno sviluppatore sarebbe in grado di scaricare Log4j finché qualcuno della sicurezza non interviene per bloccarlo. Con un approccio basato sul rischio, insieme a modalità di accesso, Log4j non sarebbe disponibile e verrebbe offerta un'alternativa. Un altro esempio riguarda l'integrazione di Log4j in un prodotto: la valutazione dinamica della fiducia potrebbe imporre controlli aggiuntivi anziché bloccarlo completamente. Si tratta di bilanciare entrambi gli elementi del calcolo in gioco.\n\nQuesto partenariato è simile all'addestramento incrociato e alla condivisione delle informazioni che vengono inseriti nel processo di sviluppo della sicurezza. Mentre si sta costruendo e testando un prodotto, la sicurezza sta anche monitorando e valutando il rischio sia per le entità con cui stai lavorando che per le vulnerabilità del prodotto in tempo reale. Costruire un approccio basato sul rischio nel processo sfrutta l'intelligence che va al cuore di molte delle cose che percepiamo come difficili.\n\nQual è il primo passo per i CISO, CIO o CTO per avviare la zero trust? Cameron suggerisce di smettere di usare \"geekspeak\" e comunicare in inglese comune. Avviare l'iniziativa può essere sfidante perché di solito i leader lavorano con un risultato o un obiettivo in mente. Zero Trust non ha un obiettivo definito verso cui lavorare, se non quello di creare un ambiente più sicuro per gli utenti. Ci sono, naturalmente, KPI e altre misure per mostrare un aumento della sicurezza, ma è un percorso, non una destinazione. Egli sottolinea anche il finanziamento continuo; non inserire il budget per la sicurezza informatica in quello IT. Deve essere separato e distinto.\n\nIl miglior posto per trovare informazioni di alto livello con indicazioni pratiche è la pubblicazione NIST SP 800-207. Inoltre, essa illustra anche le cinque colonne portanti della fiducia, che rappresentano buoni punti di partenza.\n\nUn aspetto fondamentale di base è avere un buon inventario dei beni che necessitano di essere protetti, come le fonti di dati, i database, i processi aziendali e le applicazioni di transazione. Fondamentalmente, è necessario definire il perimetro del tuo castello. È importante non solo pensare a ciò che possiedi, ma anche a ciò di cui ti affidi, come l'ambiente SAAS, l'infrastruttura cloud e gli strumenti di terze parti.\n\nL'idea generale è conoscere la tua catena del valore. Non riguarda solo ciò che c'è nel tuo castello, ma riguarda anche come guadagni denaro, come tale denaro viene distribuito, a chi paghi e i tuoi fornitori. Ognuno di questi è un pezzo critico della catena.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin","Cameron Chehreh"],"link":"/episode-EDT84-it","image":"./episodes/edt-84/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren discute della sicurezza di zero trust con Steve Orrin di Intel, CTO del settore pubblico, e Cameron Chehreh, VP-GM del settore pubblico."},{"id":159,"type":"Episode","title":"Intelligenza Artificiale e Sicurezza.","tags":["aiml","cybersecurity","devops","compute","technology","process"],"body":"\r\n\r\n## Fallimenti dell'Intelligenza Artificiale\n\nDi recente, Darren ha chiesto a una classe di studenti delle scuole superiori e dell'università che studiavano l'IA di trovare dei fallimenti dell'IA. Hanno trovato esempi come Microsoft Tay, un chatbot che ha imparato conversazioni informali da Twitter e, entro 24 ore, stava esprimendo commenti razzisti e misogini basati sulla manipolazione dei feed di Twitter. Un altro esempio è stato un sistema di tracciamento della palla dell'Inverness Football Club che doveva tracciare un pallone da calcio ma invece ha seguito la testa calva di un arbitro. Più grave è stato un incidente mortale quando un veicolo autonomo di Uber non ha riconosciuto un pedone al di fuori di un attraversamento pedonale e non è riuscito a fermarsi.\n\n## Implementazione di soluzioni\n\nTutti questi fallimenti dell'intelligenza artificiale erano legati ai dati. Quando si implementano soluzioni di intelligenza artificiale, è necessario porsi domande critiche: Dove sto effettuando il mio ragionamento? L'endpoint è sicuro? Se si sta effettuando tutto il ragionamento nell'endpoint, ad esempio attraverso la rilevazione oggetti tramite una telecamera, è importante assicurarsi che sia sicuro; nessuno dovrebbe essere in grado di manipolare i dati, la telecamera o il modello.\n\nUn'altra domanda è, cosa verrà implementato? Sto implementando una rete neurale o un algoritmo sul campo, o semplicemente sto trasmettendo i dati dal campo a un centro dati per effettuare l'inferenza lì? Inoltre, quando l'IA viene operazionalizzata, è necessario chiedersi con quale frequenza i modelli o gli algoritmi verranno aggiornati.\n\n## Alveare Intelligente\n\nIl flusso di lavoro per lo sviluppo, l'addestramento, il testing, il deployment e le inferenze dell'AI ha bisogno di tre elementi: l'applicazione, il modello e i dati. Questi tre elementi devono migrare nel flusso di lavoro insieme e essere protetti contemporaneamente. È necessario assicurarsi che i dati di produzione non vengano manipolati neppure durante la fase di produzione.\n\n## Minacce di sicurezza AI.\n\nLe minacce per l'AI sono significative, che siano spionaggio, sabotaggio o frodi perché la superficie di attacco è ampia.\n\n## Gli attacchi\n\nPrima vengono i modelli. Un modello può essere manipolato, ad esempio qualcuno che mette adesivi bianchi e neri sui segnali di stop in modo che non vengano riconosciuti come tali o qualcuno che modifica la rilevazione di modelli per attuare attacchi indetecti. I modelli devono essere protetti non solo durante l'addestramento, ma anche durante il testing, la distribuzione e l'inferenza. Critici sono la crittografia, il controllo degli accessi e il controllo dei modelli e delle versioni, proprio come nella sviluppo di un'applicazione.\n\nI dati di formazione e produzione di origine devono anche essere protetti dalla manipolazione.\n\n## Tipi di attacchi\n\nUn articolo del Belfer Center colloca le minacce su un asse del formato e un asse della visibilità. L'asse del formato varia dal fisico al digitale. L'asse della visibilità va dal percettibile all'impercettibile.\n\n## Attacchi fisici\n\nGli attacchi fisici possono alterare oggetti fisici come l'adesivo sul segnale di stop. Questi attacchi sono stati evidenti fin dall'inizio con la guida autonoma e il riconoscimento facciale. Abbiamo bisogno di una migliore formazione degli algoritmi di intelligenza artificiale per contrastare questi attacchi, utilizzando tecniche di apprendimento rinforzato e di apprendimento di casi negativi.\n\n## Attacchi digitali\n\nGli attacchi digitali sono più difficili da rilevare poiché non sono visibili. Un attacco potrebbe essere un rumore bianco iniettato nel flusso di dati per confondere l'algoritmo. Questi attacchi sono difficili da contrastare a meno che non venga condotta un'inferenza al margine o venga utilizzata la rilevazione dei modelli. Per questo motivo, è essenziale sapere da dove provengono i dati di origine, sia nell'addestramento, nei test che nella produzione dei dati.\n\n## Identificare le fonti di dati\n\nLe fonti di dati devono essere verificate e testate attraverso fonti di dati pubbliche. I dati open-source non sono ben protetti. Valuta la possibilità di generare fonti di dati in modo da avere maggiore controllo. Se utilizzi una fonte di dati condivisa, utilizza un sistema di controllo delle versioni come GitHub o GitLab per garantire coerenza. Anche i dati di test hanno bisogno di un controllo delle versioni, del controllo degli accessi e di altre misure di sicurezza, proprio come fai di solito in un flusso di lavoro DevOps.\n\nL'ultima e più impegnativa parte è proteggere i dati di produzione. Avvicinarsi il più possibile ai dati durante la deduzione è un buon inizio. Molte speculazioni possono essere fatte direttamente sul bordo con elaborazione neuromorfica e persino con set di istruzioni nei processori Intel per ridurre il rischio di manipolazione dei dati durante il trasporto. Invece, è possibile crittografare i dati e inviarli al centro di dati.\n\nProteggere e gestire i dati / Sicurezza del flusso di intelligenza artificiale.\n\nUna volta identificate tutte le fonti dei tuoi dati, ci sono tre aspetti fondamentali per la protezione: controllo, sicurezza e crittografia.\n\nLa prima cosa è il controllo. Dovresti avere un controllo di versione, librerie protette e un backup e ripristino in caso di file di dati corrotti. Queste sono pratiche standard di buona sicurezza che l'IA dovrebbe adottare come nel caso dello sviluppo di app.\n\nLa sicurezza dovrebbe includere l'autorizzazione di accesso, anche alcuni concetti di \"zero trust\" come dare accesso alle persone che ne hanno bisogno solo per un breve periodo di tempo. Assicurarsi che i modelli non vengano manipolati e che siano vincolati a specifiche applicazioni.\n\nI dati devono essere criptati durante il riposo, durante il trasferimento e durante l'utilizzo. In passato, ciò era costoso in termini di utilizzo della CPU e di tempo, ma ora gran parte della crittografia avviene nel silicio ed è molto veloce con un minimo o nullo ritardo delle prestazioni.\n\n## Chiamata all'azione\n\nI dati sono fondamentali per rendere l'IA di successo e sicura, quindi proteggili e utilizza fin da subito le migliori pratiche sulla sicurezza. Operazionalizza i flussi di lavoro per liberare gli esseri umani dalla monotonia quotidiana del rilascio e del test degli algoritmi di intelligenza artificiale. Automatizza il più possibile e inserisci la sicurezza nel percorso DevOps dell'IA per proteggere i tuoi dati di origine, il modello e l'applicazione.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher"],"link":"/episode-EDT85-it","image":"./episodes/edt-85/it/thumbnail.png","lang":"it","summary":"In questa puntata, Darren discute degli aspetti dati dell'intelligenza artificiale (AI) e dell'importanza di proteggere tali dati."},{"id":160,"type":"Episode","title":"Le cose che avrei voluto sapere come CTO del governo","tags":["cto","people","process","change","organizationalchange"],"body":"\r\n\r\nCosa hanno imparato Jason e Ron da quando si sono uniti a Intel che avrebbero voluto sapere quando erano nell'esercito?\n\nJason è rimasto sorpreso di quanto fossero migliori le soluzioni integrate dell'industria e ha sviluppato alcune incredibili capacità mancanti nell'esercito. Ha appreso che i casi d'uso aziendali dimostrano che comprendere il problema del cliente è più prezioso che semplicemente puntare sulla tecnologia. I CTO devono conoscere la tecnologia e imparare come cambiare la cultura dei membri del team per adattarsi ad essa. Rendere l'esperienza dell'utente più amichevole, costruire la tecnologia in modo più intelligente, snello e veloce e coinvolgere le persone sono ciò che può rendere le transizioni più fluide. Avrebbe voluto vedere più risultati e soluzioni nell'esercito invece di semplicemente prodotti.\n\nRon concorda con la valutazione di Jason e aggiunge che la sfida che ha riscontrato all'interno del governo è stata come coinvolgere l'industria come partner nella soluzione delle missioni, in modo da poter fornire ai team militari migliori informazioni su come applicare la loro tecnologia a tali missioni. Una grande tecnologia senza la comprensione di come risolvere effettivamente il problema della missione può essere un disastro.\n\nUn altro elemento su cui entrambi concordano essere importante è l'esperienza utente. Abbinare la tecnologia alle persone che devono utilizzarla è fondamentale. Non è necessario che tutti coloro che utilizzano la tecnologia abbiano un dottorato in ingegneria. L'esperienza utente deve essere creata in base al livello di competenze delle persone. Il risultato è raramente indipendente dagli esseri umani. Quando si presentano soluzioni per la difesa o l'industria, è necessario comprendere le esigenze tecnologiche della missione, ma anche lo spazio complessivo e come operare in quel contesto. Particolarmente nel campo militare, è necessario pianificare per eseguire in momenti in cui le cose non vanno bene e farle funzionare. La tecnologia non vincerà se non si tiene conto dell'elemento umano e delle circostanze sfidanti.\n\nQuali sono le più grandi o emozionanti sorprese per Jason e Ron quando sono passati dall'ambiente militare a quello privato?\n\nJason e Ron dicono di non aver previsto una cultura distintiva di lavoro di squadra presente nel servizio militare all'interno dell'industria privata presso Intel. Entrambi hanno trovato l'esperienza di integrazione e il supporto continuo incoraggianti. Apprezzano l'atteggiamento generale di essere tutti insieme e la possibilità di creare cose straordinarie con un team dinamico, cosa che non si potrebbe mai fare da soli.\n\nEntrambi apprezzano che non sono tenuti solamente a vendere prodotti Intel, ma a aiutare i clienti a risolvere problemi legati alle missioni e a fornire feedback ai clienti a Intel. Sono qui in Intel per risolvere problemi, soprattutto nel settore pubblico, magari utilizzando tecnologie che non sono ancora state create.\n\nQuali sono le lacune tecnologiche che Jason e Ron vedono nel Dipartimento della Difesa o nell'Intel?\n\nPrima di tutto, Jason afferma che le operazioni cloud sono fondamentali ed è una dinamica in continua evoluzione nel DOD. I comandanti sul campo di battaglia sono avversi al rischio. Non c'è spazio per errori o incomprensioni da parte di DDIL. Con l'evoluzione delle operazioni cloud, è necessario riaddestrarsi e riapprendere tutto il lavoro per una corretta operatività cloud e i vantaggi della capacità del passaggio dallo spazio all'ambiente cloud, che offre informazioni accurate in tempo reale, che arrivano alle persone giuste al momento giusto. Ognuno deve avere consapevolezza della situazione e un quadro operativo di ciò che sta accadendo.\n\nRon crede che la prossima cosa nella lista sia aumentare la sicurezza informatica poiché la superficie di vulnerabilità aumenta. Se l'esercito non si orienta verso la fiducia zero mentre si sposta verso un margine competente e altamente mobile, i risultati durante un conflitto potrebbero essere disastrosi. Il problema di DDIL è enorme, ma deve essere protetto contro l'aumento della superficie di vulnerabilità.\n\nJason crede che la tecnologia debba progredire nonostante il rischio perché l'esercito vince sempre con le informazioni. Sia che si tratti di missioni FEMA, di fornire energia nucleare a una città, di installare ospedali da campo durante il COVID o sul campo di battaglia, il progresso tecnologico, soprattutto il 5G, è fondamentale per le operazioni. I leader del Dipartimento della Difesa devono avere informazioni e la capacità di comunicare con il loro quartier generale per ricevere indicazioni, soprattutto durante le operazioni di combattimento, quando il comando potrebbe cambiare a causa delle perdite fino al grado più basso di caporale.\n\nRon usa l'esempio che la massima priorità della difesa nazionale è evitare di combattere un avversario sul proprio territorio. Poiché gli Stati Uniti potrebbero non avere un vantaggio quantitativo lontano da casa durante un conflitto contro un avversario che potrebbe essere anche tecnicamente avanzato, il settore militare deve essere più capace. Le forze militari devono continuare a fornire una maggiore capacità alla difesa nazionale e farlo in modo sicuro, nonostante l'aumento dell'esposizione alla vulnerabilità. Quei problemi devono essere risolti affinché gli operatori possano fidarsi dei dati e utilizzarli efficacemente in un ambiente di gioco lontano da casa. Non c'è altra opzione se non quella di perseguire quella direzione.\n\nJason aggiunge che un altro ambito in cui il DOD è stato lento nel adattarsi è l'intelligenza artificiale a causa della mancanza di persone con competenze adeguate. Non si diventa esperti di IA uscendo dalla Scuola degli Army Ranger. Lo stesso problema è esistito per anni per quanto riguarda la cibersicurezza, fino a quando il DOD ha effettuato un investimento significativo. Alcune risorse complesse devono essere destinate alle operazioni di IA perché l'IA può cambiare tutto.\n\nRon, avendo trascorso gli ultimi anni al servizio nel settore nucleare, sottolinea che gli Stati Uniti non toglieranno mai l'elemento umano dagli anelli decisionali critici. L'intelligenza artificiale sarà estremamente preziosa poiché potrà garantire che la tecnologia possa adattarsi dinamicamente. Ridurrà il carico cognitivo e processerà innumerevoli punti di dati in modo che i decisori umani possano avere una consapevolezza situazionale più evidente e essere meglio preparati a prendere decisioni informate in modo rapido. Questo è lo spazio dell'intelligenza artificiale che il DOD deve perseguire.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Jason Dunn-Potter","Ron Fritzemeier"],"link":"/episode-EDT86-it","image":"./episodes/edt-86/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solution Architect, settore pubblico, Intel, dà il benvenuto ai special guest Jason Dunn-Potter, Ex Chief Warrant Officer, US Army, e Ron Fritzemeier, Ex Vice Ammiraglio, US Navy. Entrambi sono ora da cinque mesi nelle loro posizioni come Solution Architects e Mission Specialists nel team del Dipartimento della Difesa di Intel."},{"id":161,"type":"Episode","title":"Calcolo confidenziale in DevSecOps","tags":["confidentialcomputing","devops","compute","technology","process","devsecops","cybersecurity","sgx"],"body":"\r\n\r\nIl software di Anjuna consente alle applicazioni di funzionare con la protezione SGX di Intel e risolve il problema della protezione dei dati in uso. La missione di Anjuna è rendere le enclave sicure il più semplice possibile. Con il software di Anjuna, non c'è bisogno di modificare nulla nell'applicazione; prendila, eseguila in una enclave e la tecnologia SGX funzionerà immediatamente. Il software funziona con qualsiasi app, su qualsiasi cloud, a qualsiasi scala.\n\nLa catena di fornitura globale del software è sotto attacco. SolarWinds, in particolare, è stato un attacco a DevOps, e nonostante ci siano state idee su come risolvere il problema, non è stato ancora risolto definitivamente. La tecnologia Anjuna può essere una soluzione facile. Non c'è bisogno di riprogettare il tuo software o cambiare metodologie. Li fai funzionare in enclave sicure.\n\nQuando ha provato il software di Anjuna, Darren ha creato uno stack utilizzando Intel SGX alla base, Red Hat OpenShift, Anjuna per la parte di elaborazione confidenziale e Vault di HashiCorp per conservare un registro sicuro. È rimasto sorpreso da quanto velocemente la soluzione fosse pronta e funzionante in meno di una settimana.\n\nDarren chiama questo processo la pipeline hardened DevSecOps, anche se ha molte componenti in movimento. Ofir concorda con questa terminologia, in quanto questo processo è un nuovo DevOps hardened con la tecnologia hardware SGX con il software di Anjuna.\n\nIl calcolo confidenziale, o enclave sicuri, risolve il problema della protezione dei dati. Quando si memorizzano i dati in uno storage persistente, la soluzione per i dati a riposo è già presente. Esiste anche una soluzione per i dati in transito con TLS. La sicurezza dei dati in uso non è stata ancora risolta perché quando i dati sono in uso, l'applicazione deve accedervi dalla memoria in chiaro. Non può essere contemporaneamente criptata e in uso. Questo è stato un problema senza fine. Se un cattivo attore ha accesso a una macchina in cui l'applicazione è in esecuzione, un attacco è semplice come accedere al dispositivo, identificare il processo e creare un dump della memoria. Otterranno tutti i segreti e i dati confidenziali presenti nel file, e non sono criptati. Ciò includerebbe anche le chiavi di crittografia per i dati a riposo e in transito perché il software deve utilizzarle per crittografare. Il cattivo attore avrà le chiavi del regno.\n\nIl problema si risolve se si eseguono le diverse applicazioni in enclave sicure. Anche se qualcuno ottiene accesso alla macchina, non avrà accesso alla memoria di ogni singola applicazione. Ciò non significa che non si debbano risolvere le vulnerabilità, ma si è molto meno stressati nel correggerle al più presto possibile. Anche se ci sono vulnerabilità del kernel, quando qualcosa viene eseguito in un enclave sicuro, il kernel non può accedere alla sua memoria.\n\nIl software Anjuna può funzionare su altre tecnologie hardware oltre a SGX. A differenza dell'esecuzione dell'encrypting direttamente nel software, dove il calo delle prestazioni sarebbe elevato, Anjuna può ottimizzare la configurazione per far girare la tua applicazione con un impatto quasi trascurabile sulle prestazioni: meno del cinque percento.\n\nQuindi potresti non voler mettere tutto in un enclave sicuro per ora, ma è il futuro per la sicurezza.\n\nUno dei utilizzi di un enclave sicuro è quello di archiviare dati che attraversano diverse fasi nella pipeline DevOps in un registro sicuro. Il registro contiene tutto ciò che è stato inserito nella costruzione, chiavi di sicurezza e valori hash utilizzati per la verifica. Questi valori hash di verifica devono rimanere invariati durante il ciclo, così nessuno può iniettare codice, librerie o binari nel pacchetto che si consegna. Tutto dovrebbe funzionare in un contenitore nel mondo moderno.\n\nUn altro candidato per la protezione è una chiave di firma. Senza enclave sicure, una volta che hai un file binario pronto, devi portarlo su un'altra macchina in una stanza buia a cui nessuno ha accesso. Ma tre persone con tre chiavi diverse lo firmano lì. Le enclave sicure consentono l'accesso a quella chiave di firma nel tuo ambiente familiare, ma solo l'enclave stessa potrà accedervi. Sarà basato sull'identità complessa del software in esecuzione all'interno dell'enclave SGX, che viene implementata tramite l'attestazione. In altre parole, puoi attestare un'enclave ad un'altra enclave. Puoi anche attestare cose che vengono eseguite al di fuori delle enclave. Ti dà la possibilità di fidarti del software che viene eseguito altrove.\n\nLa compilazione dei binari è un altro utilizzo. Uno dei grandi problemi nel Dipartimento della Difesa, ad esempio, è che vogliono essere garantiti che tutto ciò che è stato incluso nella compilazione possa essere rintracciato allo sviluppatore che lo ha scritto. Soprattutto nei sistemi embedded in cui il software controlla macchine da milioni di dollari che possono uccidere persone o salvare vite. Deve esserci piena tracciabilità per contribuire a garantire responsabilità e che lo sviluppo sicuro sia stato eseguito.\n\nOltre agli attacchi di dumping della memoria, un altro problema di attacco risolto da Anjuna è assicurarsi che nei casi in cui è necessario accedere al kernel, protegga tutto ciò che deve essere coperto in quell'interazione tra l'enclave e il mondo esterno. Inoltre, può proteggere dall'accesso al codice e rendere segreti disponibili solo per l'enclave. Inoltre, se qualcuno accede a una macchina, non sarà in grado di trovare un certificato TLS in chiaro o la chiave usata per criptarlo.\n\nOgni fornitore di servizi cloud offre ambienti sicuri, e Anjuna li supporta tutti. Supportano anche tecnologie on-prem. Oltre all'offerta principale, Anjuna può anche abilitare la capacità di crittografare i tuoi dati a riposo e in transito senza modificare il tuo software, anche nelle applicazioni legacy o nelle nuove applicazioni che non supportano la crittografia di ogni singolo file di dati.\n\nPer ulteriori informazioni, visita anjuna.io, o consulta un white paper scritto da Darren e Ofir su embracingdigital.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Ofir Azoulay-Rozanes"],"link":"/episode-EDT87-it","image":"./episodes/edt-87/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren Pulsipher, Chief Solutions Architect, Intel, e Ofir Azoulay-Rozanes, Direttore del Product Management, Anjuna, discutono delle soluzioni di Anjuna per il computing confidenziale nel ciclo di vita del DevOps."},{"id":162,"type":"Episode","title":"Collaborative DevSecOps","tags":["cybersecurity","devsecops","rpa","technology","compute","zerotrust","zta"],"body":"\r\n\r\nL'esperienza di Mike come ingegnere di cyber security nell'Air Force e poi lavorando nello sviluppo, nella sicurezza, nelle operazioni e nei servizi gestiti lo ha portato all'obiettivo di creare un prodotto che potesse essere collaborativo per costruire l'automazione moderna intorno a ciò che chiama IT come codice. Voleva considerare il DevSecOps in modo olistico, riunendo tutti insieme.\n\nIl suo prodotto risultante, Sophos Factory, crea soluzioni moderne basate su mattoni con le caratteristiche, funzionalità ed esperienza utente che possono essere utilizzate in tutto lo spettro delle competenze tecniche. Risolvere questo problema è stato complesso, coinvolgendo persone che lavorano visualmente, sviluppatori che codificano, ecc... Era anche necessario colmare il divario tra hardware e software, utilizzando un processo agile tra i team.\n\nLa Sophos Factory è più di una semplice pipeline CI/CD. Questa è una piccola parte dell'intero sistema, che funziona dall'inizio alla fine, dalla fase di sviluppo, sicurezza, operazioni e distribuzione con funzionalità come un costruttore visuale, DSL e supporto per tutti i contenuti nel loro formato nativo. Si integra anche con i sistemi esistenti. Coinvolge tutti i diversi team e gli strumenti diversi che utilizzano, quindi va ben oltre la semplice creazione di una pipeline o automazione.\n\nGli utenti individuali sono presentati con i pezzi a cui sono familiari, ma tutti con la stessa interfaccia. Ad esempio, è possibile creare un insieme di script da un formato visuale. Una persona responsabile della sicurezza può utilizzare la stessa interfaccia con gli strumenti e gli artefatti che si aspetta. Uno sviluppatore full-stack o un ingegnere DevOps possono integrare e creare tutti gli artefatti in modo che gli altri team possano utilizzarli. Non si tratta della creazione di un flusso di lavoro per un componente di automazione, ma di una tessitura interconnessa tra sistemi disparati.\n\nL'integrazione significa il movimento dei dati, ma significa anche azioni. Ad esempio, supponiamo che qualcuno utilizzi Jira sul lato della codifica, ServiceNow sul lato delle operazioni IT e un componente di risposta agli incidenti sul lato della sicurezza. In quel caso, è possibile integrare tutte queste componenti e inviare qualcosa su Slack, in modo che tutti abbiano visibilità e possano rispondere quasi in tempo reale.\n\nSophos Factory confeziona moduli in pipeline per la riutilizzabilità, che diventano mattoni di costruzione. Questi possono essere costruiti intorno a vari casi d'uso, ma l'obiettivo è quello di creare qualcosa che possa essere utilizzato ripetutamente. Ad esempio, supponiamo che tu stia utilizzando ServiceNow e desideri creare un ticket. In questo caso, lo utilizzi in vari altri casi d'uso legati all'automazione della rete, all'automazione dell'infrastruttura, al cloud, alla sicurezza nativa, ecc. Si tratta di creare soluzioni anziché semplicemente automatizzare queste cose insieme. L'ultimo elemento è la futura sostenibilità, non solo la ripetibilità. Puoi aggiungere o sottrarre dalla pipeline complessiva ciò che non è possibile con l'hardware ma anche molto difficile con i sistemi esistenti come i sistemi CI/CD che sono progettati per rilasciare software in produzione, non per costruire in modo olistico una soluzione e mantenere il ciclo di vita nel tempo.\n\nCon la tecnologia di Sophos Factory, è possibile confezionare diversi strumenti per aiutare a conformarsi agli standard come CIF o NIST 853 e renderli disponibili come flussi di lavoro a basso codice o senza codice. Sophos Factory si discosta dalle altre tecnologie di automazione grazie alla condivisione tramite cataloghi di soluzioni. È possibile pubblicare blocchi di automazione, soluzioni complete o utilizzare automatizzazioni create da altri team. Questo offre un'enorme flessibilità.\n\nIl controllo di versione è integrato nelle pipeline e nei cataloghi delle soluzioni. Se stai utilizzando una pipeline di soluzione da un record pubblicato da qualcun altro, puoi impostarla alla versione che desideri o prelevare dalla versione più recente per ottenere eventuali aggiornamenti. RBAC fa anche parte del sistema nel caso in cui desideri che solo determinati utenti abbiano, ad esempio, accesso in sola lettura. Con l'interoperabilità di Sophos Factory, puoi anche integrare gli strumenti di scansione per mantenere la visibilità nella pipeline. Puoi inoltre eseguire diversi canali attorno agli strumenti di policy.\n\nSophos Factory intreccia insieme flussi di sicurezza e IT, creando un eccellente punto di integrazione tra i tre capi mostro di Dev, Sec e Ops.\n\nPer migliorare la sicurezza, Sophos Factory dispone di un prodotto di zero-trust e attestazione, ma collaborano anche con altri prodotti di sicurezza come HashiCorp Console. La capacità di zero-trust e attestazione è l'evoluzione naturale per autenticare tra i diversi sistemi. Piuttosto che credenziali statiche, ci sono ora modi migliori per comunicare e condividere in modo sicuro l'attestazione tra gli altri.\n\nSophos Factory ha un sistema di accreditamento incorporato per la gestione delle chiavi, e supporta HashiCorp Vault e modelli nativi del cloud. Possono inoltre aiutare i servizi di gestione critici sviluppati nel cloud e confezionati intorno a un flusso di lavoro. Non c'è solo una variabile di accreditamento in fase di esecuzione, ma anche una fase di accreditamento che viene valutata solo in fase di esecuzione. Possono aggiungere questi strumenti di sicurezza, in modo da diventare naturalmente parte della tua soluzione di sviluppo.\n\nSophos Factory si trova nello spazio RPA, ma va ben oltre un semplice esecutore RPA tipico. Sono tecnicamente RPA perché, sebbene gli esseri umani siano ancora coinvolti nella creazione delle cose, le macchine vengono utilizzate per automatizzare il processo. I clienti cercano modi per scalare e ottenere valore in modo sicuro dalle soluzioni IT che acquistano. Sophos Factory si impegna ad aiutare il talento tecnico a crescere e offrir loro accesso a strumenti, ottenendo il massimo da essi e facendolo in modo sicuro.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Mike Fraser","Callen Sapien"],"link":"/episode-EDT88-it","image":"./episodes/edt-88/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con Callen Sapien di Sophos, Direttore del Product Management di Sophos Factory e Mike Fraser, VP di DevSecOps, riguardo al loro prodotto che permette una vera collaborazione in SecDevOps."},{"id":163,"type":"Episode","title":"Futuro della memoria di grandi dimensioni e CXL","tags":["bigmemory","memverge","optane","technology","data","compute","pmem","cxl","ceo"],"body":"\r\n\r\nUno sviluppo entusiasmante nella memoria è CXL (Compute Express Link). Un ecosistema robusto è in fase di sviluppo dal lato host, con Intel e altri che supportano CXL 1.1 nelle loro piattaforme di prossima generazione, come Sapphire Rapids. Coloro che operano sul lato della memoria, inclusa la quarta generazione di Intel Optane, saranno su CXL. Intel è uno dei membri guida di un forte consorzio CXL che ha promosso lo standard. CLX 2.0 è già stato definito, con capacità aggiuntive, tra cui l'esternalizzazione e il commutamento di CXL, e il 3.0 è in fase di sviluppo, il quale standardizzerà come CXL può essere fornito e condiviso.\n\nCi saranno nuovi prodotti in arrivo da Samsung, Micron e SK-Hynix con capacità CXL. Inoltre, ci sono nuovi interconnettori che stanno venendo sviluppati e che potenzialmente possono collegare la memoria con il tessuto, in modo da avere una memoria abilitata per il tessuto che può essere condivisa tra più server.\n\nLa tecnologia CXL è un cambio di gioco. Un nuovo protocollo di memoria funziona sulla standard PCIe generazione cinque e successive. Poiché consente di mettere la memoria su PCIe, non solo può essere all'interno della scatola, ma in futuro, con l'interruttore PCIe, la memoria sulla tessitura diventerà componibile e condivisibile. Il primo prodotto CXL sarà disponibile entro la fine dell'anno.\n\nMemVerge ha già un controller di memoria definito dal software, e CXL ha aperto un mondo completamente nuovo per il software. CXL è per la memoria quello che il canale a fibra è per lo storage. È come una rete di area di memoria anziché una rete di archiviazione. È possibile accedere direttamente alla memoria con CXL e bypassare completamente la CPU.\n\nCXL sarà molto più veloce rispetto alle precedenti tecnologie di interconnessione. Avrà una latenza di 100 o 200 nanosecondi. Qui è dove aumentano l'utilizzo, la gestibilità e l'agilità. Ci sarà una maggiore disponibilità e produttività nell'uso della memoria. Inoltre, sarà possibile allocare memoria in modo dinamico; potrai allocare secondo necessità, e non è necessario che si adatti alla scatola del server. Teoricamente, avrai sempre abbastanza memoria per qualsiasi attività tu debba svolgere.\n\nCon la tecnologia di snapshot di MemVerge, i tuoi dati sono protetti e persistenti allo stesso modo. Ciò diventa ancor più importante man mano che la memoria diventa più grande. Se la perdi, diventa più difficile ricostruirla.\n\nPer far decollare il CXL, tre cose devono essere in atto. Sul fronte hardware, i leader dell'hardware più vecchio devono essere a bordo ed abbracciare gli stessi standard. Questo è accaduto l'anno scorso, quindi c'è uno standard unico che tutti supportano. In secondo luogo, non è necessario modificare la propria applicazione per utilizzare il CXL, proprio come le reti di archiviazione. In terzo luogo, dal punto di vista del database, non si dovrebbe dover riscrivere nulla. Ciò può avvenire tra ciò che gli standard forniscono, ciò che il sistema operativo supporta e il software MemVerge che può effettuare un'auto-tiering tra la memoria DDR e la memoria CXL.\n\nMemVerge può offrire quel livello di astrazione. È essenzialmente una virtualizzazione della memoria. La memoria definita dal software gestisce l'effettivo posizionamento della memoria fisica.\n\nMemVerge rende la grande memoria trasparente all'applicazione in modo che i programmatori possano sfruttare una capacità superiore e non rimanere mai senza memoria. Successivamente, c'è la protezione dei dati. MemVerge ha sviluppato un servizio di snapshot in memoria che può catturare l'intero stato di un'applicazione in memoria, e tale stato è immutabile. Può essere ripristinato in qualsiasi momento, ovunque. Ci sono molti casi d'uso con questo, come la mitigazione del ransomware e la diminuzione dei tempi di ciclo nella ricerca genomica.\n\nLa funzione di snapshot non è solo utile perché consente di catturare in modo rapido e facile una pipeline in esecuzione, consentendo di tornare indietro e recuperare in qualsiasi momento, ma può anche aiutare a risparmiare denaro quando si utilizzano servizi cloud. I principali fornitori di servizi offrono istanze spot che hanno uno sconto dal prezzo richiesto del 70-90%, ma c'è un'importante condizione: possono riprenderselo in qualsiasi momento con un preavviso di soli 30 secondi o due minuti. Questo non è un tempo sufficiente per risolvere il problema, soprattutto se ci sono molti dati in memoria, quindi non è stato utile per molti carichi di lavoro. Con la capacità di snapshot di MemVerge, è possibile fare snapshot periodici del carico di lavoro in esecuzione su qualsiasi istanza. Se l'istanza spot viene rimossa, si ha un'immagine di backup da recuperare e continuare l'esecuzione. È un'assicurazione che consente di utilizzare il servizio a basso costo con protezione.\n\nDal momento che stai facendo una copia di non solo un'applicazione ma dell'intero contenitore o istanza, puoi riattivarla ovunque, on-premises, nella stessa piattaforma cloud o in un'altra cloud. Ciò ti offre la massima mobilità e resilienza nelle tue operazioni, anche nel caso di un'interruzione del servizio cloud principale. Questa tecnologia offre molte possibilità interessanti.\n\nLa rivoluzione CXL e il software MemVerge Memory Machine sono potenti combinazioni per possibilità che cambiano il gioco.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Charles Fan"],"link":"/episode-EDT89-it","image":"./episodes/edt-89/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, parla con Charles Fan, CEO di MemVerge, riguardo a come la rivoluzione di CXL e il software di MemVerge rappresentino il futuro della memoria enorme."},{"id":164,"type":"Episode","title":"Telelavoro: Sicurezza del tuo ufficio domestico","tags":["cybersecurity"],"body":"\r\n\r\n## Suggerimenti per la sicurezza del sistema\n\nLa prima cosa che desideri fare per proteggere il tuo ufficio domestico è aggiornare tutti i tuoi sistemi. Ciò include sia le applicazioni che i sistemi operativi su tutti i tuoi dispositivi connessi a Internet. Vorrai anche aggiornare il software di sicurezza per endpoint e eseguire scansioni regolari quando il tuo dispositivo è acceso. Molte persone sanno farlo sul desktop o sul laptop, ma la sicurezza per endpoint dovrebbe essere implementata anche su telefoni e tablet. Inoltre, assicurati di attivare il firewall locale e abilitare il firewall del tuo router.\n\nUno dei principali passi che puoi compiere per ridurre il rischio complessivo mentre sei su internet è ridurre l'area di attacco in esecuzione. Ciò significa che dovresti chiudere le applicazioni non in uso, chiudere il browser prima di visitare nuovi siti e disconnetterti o chiudere le sessioni sicure prima di svolgere attività come controllare la posta o navigare. Non dovresti svolgere diverse attività contemporaneamente per evitare attacchi incrociati.\n\nUn buon sito educativo per imparare come navigare in internet in sicurezza è Stop. Think. Connect. https://www.stopthinkconnect.org/\n\n## Suggerimenti per la sicurezza Modem/Router/Wifi\n\nCambia tutte le password predefinite in password sicure (minimo di 8-10 caratteri, usa maiuscole e minuscole, numeri e caratteri speciali). Le password predefinite vengono fornite insieme ai router, modem, portali web degli ISP e WiFi. Proteggi attentamente chi ha accesso alle tue password. È anche importante cambiare il nome di rete predefinito (SSID) in qualcosa che non contenga alcuna informazione identificativa.\n\nAbilitare l'autenticazione a due fattori ovunque sia possibile ti garantirà un ulteriore livello di sicurezza. Anche i router e i modem devono essere aggiornati come il tuo laptop, quindi assicurati di attivare gli aggiornamenti automatici.\n\nAltri passaggi per aumentare la sicurezza includono l'attivazione di WPA e la disattivazione di WPS, se possibile. Abilitare la traduzione degli indirizzi di rete (NAT) e il filtraggio DNS sul router e sul modem. Inoltre, sarà necessario disabilitare UPnP.\n\nQueste tecniche impediranno alle persone non autorizzate e ai tuoi vicini di \"prendere in prestito\" la tua connessione WiFi, creando un rischio per la sicurezza.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Steve Orrin"],"link":"/episode-EDT9-it","image":"./episodes/edt-9/it/thumbnail.png","lang":"it","summary":"Proteggere il tuo dispositivo e il tuo data center ti porta solo fino a un certo punto. Con sempre più persone che lavorano da casa, è necessario aiutare i tuoi dipendenti a proteggere la loro rete domestica e l'area di lavoro. In questo episodio, Steve Orrin, CTO federale di Intel, aiuta Darren a proteggere la sua rete domestica."},{"id":165,"type":"Episode","title":"Barriere all'adozione delle future tecnologie.","tags":["cto","organizationalchange","change","people","process"],"body":"\r\n\r\nGlenn è il Direttore della Tecnologia presso CACI, un'azienda da sei miliardi di dollari delle dimensioni di una fortuna-500, focalizzata sulla sicurezza nazionale. È nel settore da 35 anni, dedicato alle forze armate, all'intelligence e alla cibersicurezza per il governo degli Stati Uniti. Essendo un ingegnere, pensa, agisce e elabora le domande come un ingegnere.\n\nNuove e entusiasmanti tecnologie nell'Intelligenza Artificiale, nella neuro-morfologia e nella sicurezza non vengono sempre adottate rapidamente nel settore pubblico.\n\nLa prima barriera è la complessità. Coloro che fanno parte della comunità tecnica sono degli innovatori eccezionali, ma non sempre riescono a rendere la tecnologia facile da utilizzare, usare o amministrare. Tuttavia, Glenn nota alcuni miglioramenti. Ad esempio, negli ultimi cinque anni, la complessità nell'utilizzo dell'intelligenza artificiale è significativamente diminuita grazie all'utilizzo di strumenti e kit di sviluppo software da parte di un numero sempre maggiore di persone.\n\nUn'altra barriera può essere la mancanza di talento per architettare, progettare, implementare e mantenere la tecnologia nel settore pubblico. Il nuovo talento non solo deve essere attratto dall'industria, ma deve anche essere in grado di ottenere le necessarie autorizzazioni. L'altro lato dell'equazione del talento è che molti sono restii ad adottare nuove tecnologie. È una sfida di gestione del cambiamento. Se non viene affrontata correttamente, il talento esistente diventa un ostacolo all'adozione di nuove tecnologie. Invece di cercare di trovare il modo per dire \"sì\", trovano mille motivi per dire \"no\".\n\nIl terzo è la cibersicurezza. Glenn non lo descrive come una barriera perché non è qualcosa che verrebbe rimosso. Tuttavia, l'industria potrebbe essere più proattiva nel spostare le decisioni verso sinistra coinvolgendo la sicurezza in modo più tempestivo per accelerare l'adozione.\n\nIl settore pubblico potrebbe prendere spunto da come la tecnologia degli smartphone è stata adottata così rapidamente con l'avvento dell'iPhone. I primi iPhone erano incredibilmente facili da usare e l'azienda si impegnava a fornire ai clienti qualcosa che potessero utilizzare immediatamente. Inoltre, la comunità di sviluppatori poteva istantaneamente creare e innovare con gli strumenti e i processi di sviluppo software. I ragazzi della sesta elementare possono sviluppare con gli strumenti per iPhone e Android. L'usabilità era fondamentale e ha favorito l'efficienza dello sviluppo software.\n\nIl settore pubblico dovrebbe cercare di imitare quelle qualità e avvicinarsi al proprio mercato e ai propri clienti allo stesso modo, soprattutto per quanto riguarda l'analisi dei dati. Ci sono una quantità enorme di dati e non ne stiamo sfruttando molto. Proprio come Steve Jobs ha portato la sua tecnologia al di fuori del target medio, la stessa cosa dovrebbe accadere nell'analisi dei dati. Invece di mirare agli scienziati dei dati, forse il target dovrebbe essere una persona d'affari o una persona comune che deve gestire una famiglia.\n\nGlenn crede che il primo passo per pensare in questo modo riguardo all'IA e all'analisi sia essere fermamente impegnati nel liberare i dati. Molte informazioni sono bloccate in design proprietari, e questo rappresenta un pessimo modello di business. I clienti dovrebbero rinnovare i contratti non perché le loro informazioni sono controllate e chiuse da un fornitore, ma perché il fornitore offre soluzioni, valore e innovazione.\n\nL'IA dovrebbe essere presentata come un assistente digitale per i clienti anziché come un robot sfocato e magico sullo sfondo di cui il cliente è nervoso nell'affidarsi. Un assistente digitale è semplicemente un passo avanti rispetto a quello che stai cercando di realizzare, fornendo dati e informazioni tramite l'apprendimento automatico e l'apprendimento approfondito che semplifica la tua vita e ti consente di elaborare. In questo modo, l'IA aggiunge valore immediato ed è molto meno spaventosa.\n\nGlenn crede che la tecnologia che il settore pubblico deve avere oggi sia, innanzitutto, il cloud e sempre più di questo. Il cloud elimina molti errori umani nell'amministrazione. Riduce la superficie di attacco ed è un modello di consumo pay-as-you-go, che può essere economico se si sviluppa software per questo modello.\n\nIn secondo luogo, ci sono delle buone piattaforme DevSecOps. I programmatori software possono dedicare più tempo allo sviluppo effettivo utilizzando gli strumenti disponibili. DevSecOps è ancora agli inizi, e la crescita sarà esplosiva.\n\nUna tecnologia che è stata fondamentale durante il lavoro da remoto durante il COVID è Commercial Solutions for Classified (CSFC). Questa tecnologia esiste da un decennio. Tuttavia, si è evoluta al punto in cui la complessità è stata eliminata dalla sua implementazione, amministrazione e sicurezza per essere facilmente utilizzata. Qualcuno può lavorare in un dominio non classificato e ancora accedere a segreti, ad esempio, con la certezza di non avere alcuna fuga di informazioni. Questa è una nuova e importante capacità.\n\nTutto ciò è collegato all'attrarre e trattenere il talento. La difficoltà in questo non risiede nel fatto che il settore pubblico non abbia problemi stimolanti ed impegnativi, ma nella percezione che il governo si muova molto lentamente. C'è una certa verità in ciò a causa dell'importanza nel mantenere una certa sacralità o fiducia. Tuttavia, in realtà, il governo sta proprio al confine di molte nuove tecnologie, come la fotonica o la comunicazione basata sulla luce. Alcuni settori si muovono rapidamente, come lo sviluppo software con approccio agile e DevSecOps.\n\nGlenn crede che il dominio dello spazio esploderà e sarà fondamentalmente diverso tra cinque anni per il futuro della tecnologia. La capacità di mettere in orbita in modo economico più oggetti con miglioramenti in termini di dimensioni, peso e potenza, insieme alla capacità di comunicare con la fotonica su migliaia di chilometri rapidamente, consente la connettività e la capacità di distribuire e utilizzare i dati su tali carichi utili.\n\nUn'altra area che sarà molto diversa è l'agilità dello spettro. Il dominio dello spettro elettromagnetico sarà cruciale per una connettività resiliente durante i conflitti. Le dispute successive enfatizzeranno pesantemente chi può comunicare e interferire con le comunicazioni. L'agilità dello spettro è la capacità di conoscere dinamicamente ciò che sta accadendo intorno a te nello spettro, in modo da poterti muovere rapidamente. Questa connettività è fondamentale per il comando congiunto e il controllo e la visione JADC2 per il suo funzionamento.\n\nUn'area terza riguarda cosa può essere fatto con Kubernetes e con il codice di infrastruttura. L'automazione rimuoverà il lavoro manuale e faciliterà le cose in generale.\n\nNessuna conversazione sul futuro della tecnologia sarebbe completa senza menzionare il Quantum. I modelli di programmazione quantistica che stanno venendo sviluppati sono completamente diversi dai modelli tradizionali. Dobbiamo arrivare al punto in cui abbiamo delle trousse degli strumenti per i programmatori che rendano il processo molto più automatizzato. Addestrare qualcuno per due anni per diventare un programmatore di calcolo quantistico non è scalabile, quindi abbiamo bisogno di trousse per lo sviluppo software che emergano, proprio come la comunità ha astratto la complessità e ha sviluppato trousse per l'intelligenza artificiale.\n\nL'ultima area è l'evoluzione continua del computing edge. Il numero di processi di calcolo è fenomenale, generando creatività con dimensioni, peso e potenza. Il computing edge continuerà a trasformarsi per essere sicuro e affidabile. La comunicazione resiliente potrebbe non essere una connessione dedicata, ma una rete a maglia in cui le parti del messaggio vengono ricomposte alla fine. Questo può fornire soluzioni in ambienti tattici di negazione e disturbo.\n\nDarren vede la tradizionale architettura Von Neumann in declino nel futuro poiché possiamo avere persistenza dei dati senza dischi rigidi e possiamo avere dati che vivono, si muovono e migrano con funzioni che lavorano con essi. I livelli e le limitazioni del modello Von Neumann verranno rimossi.\n\nGlenn pensa che ciò accadrà più velocemente di quanto le persone generalmente prevederebbero a causa del pregiudizio dell'esperienza. Ma è un mondo diverso quando puoi far coesistere tutte le altre componenti e rimuovere i problemi di latenza. Immagina cosa potrebbe essere fatto alla velocità dell'inferenza al bordo, ad esempio, con veicoli autonomi. Quella tecnologia è in atto e i programmatori considerano i livelli di astrazione fin dall'inizio. Quindi potresti, ad esempio, prendere un modello di rete neurale già sviluppato e farlo girare attraverso un kit di sviluppo software per posizionarlo su un substrato hardware, un'architettura non-Von Neumann, senza dover riprogrammare. Questo accelererà l'adozione e sarà trasformativo.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Glenn Kurowski"],"link":"/episode-EDT90-it","image":"./episodes/edt-90/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, discute le barriere all'adozione di nuove tecnologie nel settore pubblico e ciò che arriverà in futuro con Glenn Kurowski, CTO di CACI."},{"id":166,"type":"Episode","title":"Combattere l'avversario cibernetico mediante la sicurezza della catena di approvvigionamento del software","tags":["cybersecurity","devsecops","sbom","securesupplychain","policy","process","compute"],"body":"\r\n\r\nDarren e Eric Greenwald, Consulenti Generali di Finite State, discutono della sicurezza della catena di approvvigionamento del software in questo episodio.\n\nFinite State si concentra sulla ricerca di vulnerabilità nel firmware, più spesso il software di terze parti che potrebbero già presentare vulnerabilità esistenti, prima di integrarlo nel loro dispositivo. Finite State si concentra principalmente su dispositivi IoT industriali, dispositivi medici, automobili ed elettronica di consumo.\n\nPer sette anni prima di unirsi a Finite State, Eric ha lavorato come avvocato nel settore privato, concentrandosi sui test di sicurezza e l'individuazione delle vulnerabilità per le aziende di cybersecurity. Prima di ciò, ha lavorato nel governo con la cybersecurity e la sicurezza nazionale, per l'FBI e la CIA, e come consigliere capo per il Comitato di Intelligence della Camera. Il suo lavoro governativo ha raggiunto l'apice quando è diventato Direttore Senior per la Cybersecurity presso il Consiglio per la Sicurezza Nazionale alla Casa Bianca.\n\nEric crede che parte del motivo per cui ora c'è un'enfasi sulla sicurezza della catena di approvvigionamento sia che la minaccia è evoluta. La natura sempre più complessa del software, compreso il fatto che molti componenti hanno vulnerabilità quando vengono creati per la prima volta e vengono scoperti solo col tempo, rende più difficile individuare i dispositivi costruiti tramite la catena di approvvigionamento del software. Inoltre, attacchi recenti di alto profilo tramite una violazione nella catena di approvvigionamento del software, come SolarWinds, hanno reso le persone più consapevoli del pericolo.\n\nNell'attacco di SolarWinds, l'autore ha avuto pazienza, non causando immediatamente il caos, ma aspettando un anno mentre vagava attraverso le reti informatiche americane, coltivando l'accesso e le informazioni. Quella pazienza è probabilmente la differenza più significativa tra un attacco di uno Stato-nazione e un attacco criminale. Mentre a volte gli attacchi criminali pazienti sono più concentrati su un ritorno finanziario sugli investimenti, coloro che sono dietro un attacco di uno Stato sono disposti a impiegare anni per sviluppare il loro accesso alle informazioni. Tuttavia, con entrambi gli attacchi, stanno diventando sempre più sofisticati e sono molto meglio posizionati per trarre un vantaggio devastante dalla complessità della catena di fornitura.\n\nPer contrastare questi attacchi, stanno emergendo nuove normative. L'amministrazione Biden ha emesso il decreto esecutivo 14028 a maggio 2021, che presenta due punti principali: lo sviluppo sicuro del software e il bollettino dei materiali software (SBOM). Il decreto esecutivo è rivolto solo agli appalti governativi, ma è probabile che l'industria privata lo segua.\n\nI dettagli e le raccomandazioni tecniche per lo sviluppo sicuro del software sono ancora in fase di elaborazione. Tuttavia, parte di questo sarebbe che i fornitori di software per il governo dovrebbero fornire un SBOM. La prima bozza di legislazione per gli SBOM è stata presentata nel 2014, quindi gli standard per produrli sono diventati più maturi e sviluppati. Un SBOM è essenzialmente un elenco dei componenti software che sono stati utilizzati per un prodotto software, non molto diverso da un elenco di ingredienti su un prodotto alimentare. Ciò offre trasparenza nella catena di fornitura, che è essenziale per valutare le vulnerabilità o per identificare una vulnerabilità scoperta successivamente.\n\nUn eccellente esempio di ciò è ciò che è successo con Log4j. Quando è stata scoperta quella vulnerabilità, molte aziende non sapevano se l'avevano nel loro stack. Non sarebbe una bacchetta magica, ma un SBOM consentirebbe alle aziende di scoprire più facilmente se hanno il componente software problematico nel loro sistema e agire più rapidamente per implementare una patch.\n\nGli argomenti contro la pubblicazione degli SBOM (Software Bill of Materials) sono che forniranno una mappa agli attaccanti e sveleranno informazioni proprietarie. Nonostante questi siano legittimi motivi di preoccupazione e debbano essere discussi, il Dipartimento del Commercio e il Dipartimento della Sicurezza Interna sottolineano un beneficio molto più significativo per i difensori derivante dalla trasparenza rispetto a qualsiasi vantaggio concesso agli attaccanti. Ci sono proposte di legge bipartisan a sostegno degli SBOM. Esistono modi per ridurre il rischio che gli SBOM cadano nelle mani sbagliate, come contratti sicuri o non fungibili. Il dibattito su queste preoccupazioni continuerà nel settore pubblico e sempre più aziende li adotteranno.\n\nQuesta legislazione sta avvenendo perché la FDA ha suggerito ai produttori di dispositivi medici di incorporare SBOM come parte del processo di revisione, quindi gli SBOM stanno guadagnando slancio da parte di questi produttori. Il mondo fisico sta diventando sempre più influenzato dal software nei dispositivi medici e dai sistemi incorporati come i sistemi di controllo per centrali elettriche, sistemi di climatizzazione, controlli aeroportuali, ecc., quindi i sistemi operativi sono a rischio, con conseguenze più significative rispetto agli attacchi ai sistemi aziendali.\n\nUna difficoltà per i professionisti OT è che molti dei componenti industriali sono più vecchi e non sono necessariamente stati aggiornati. Tuttavia, gli hacker sono riluttanti a connettersi a Internet e aggiornare perché è così che gli hacker entrano. La migliore risposta a questo problema è cercare di ottenere trasparenza dei componenti nella pila, effettuare una scansione del sistema e dei dispositivi che fanno parte della rete OT e fare un po' di reverse engineering e decompilazione per comprendere i dettagli. Fondamentalmente, è necessario creare il proprio SBOM e valutare quali vulnerabilità ci sono.\n\nQuesto è l'area principale di lavoro per Finite State. Esaminano i sistemi e i dispositivi e fanno un'analisi. Hanno una piattaforma che automatizza l'analisi del codice incorporato, fornisce una lettura delle vulnerabilità e identifica e raggruppa le vulnerabilità con la massima priorità. A volte puoi eliminare un'intera categoria di vulnerabilità con una singola correzione. Creare lo SBOM da solo, quindi, non è sufficiente. Deve essere collegato a un sistema di gestione del rischio per sfogliare e ordinare le numerose vulnerabilità. Trovare i rischi con la massima priorità è un processo complesso e Finite State può aiutare i team di sicurezza a dare priorità alle loro azioni per proteggere i loro sistemi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Eric Greenwald"],"link":"/episode-EDT91-it","image":"./episodes/edt-91/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Intel, e Eric Greenwald, Consigliere Generale di Finite State, parlano di sicurezza della catena di approvvigionamento del software."},{"id":167,"type":"Episode","title":"Proteggere le Mura Esterne del tuo Castello con Scansioni di Vulnerabilità","tags":["cybersecurity","endpointmanagement","vulnerability","cyberattack","iot","edge","censys"],"body":"\r\n\r\nMatt ha trascorso otto anni come ufficiale di intelligence nell'esercito. Nella parte finale del suo servizio, ha contribuito a sviluppare le forze di missione cibernetica come parte del Comando Cibernetico degli Stati Uniti. Dopo aver concluso il suo servizio, ha lavorato con l'esercito nel campo della cibernetica e con alcune startup prima di approdare a Censys.\n\nUna tipica valutazione di vulnerabilità richiede a un'organizzazione di fornire ciò che le interessa, per esempio una lista di blocchi di IP per una scansione di vulnerabilità delle credenziali. Successivamente vengono scoperte tali vulnerabilità e possono essere risolte. Una scansione di Censys può fornire una scansione ampia e approfondita su Internet partendo da alcune informazioni di base come un dominio e alcuni IP, scoprendo tutto il resto di ciò che l'organizzazione possiede e monitorando continuamente tali stesse aggregazioni e correlazioni tra i dati. Ad esempio, se il dipartimento marketing crea un sito web senza TLS accessibile dall'esterno, Censys lo rileverà. Censys adotta una prospettiva esterna per sapere cosa è disponibile a un attaccante in qualsiasi momento della giornata.\n\nAnche se, ad esempio, qualcuno distribuisce un'applicazione in un cloud, non la inserisce nel dominio e utilizza una sicurezza di offuscamento, Censys la rileverà comunque se è in un ambiente cloud di proprietà dell'organizzazione. I connettori cloud scopriranno nuove istanze cloud che compaiono. Alcuni elementi di connessione, che siano informazioni WHOIS o DNS, devono corrispondere a alcune di queste istanze. Censys sta continuando a migliorare nella rilevazione di questi tipi di istanze.\n\nL'analogia di un castello funziona bene qui. Un'organizzazione non vuole fare affidamento solo su ciò che può vedere internamente con le telecamere e le guardie. Vogliono una pattuglia di sicurezza itinerante per individuare le minacce prima ancora che arrivino alle mura del castello. La pattuglia può osservare il castello come farebbe un aggressore. Censys pattuglia internet da una prospettiva esterna, osservando le cose come le vedrebbe un potenziale hacker.\n\nUno strumento che Censys sta considerando è JARM di Salesforce, uno strumento attivo di fingerprinting TLS. Quando vengono implementate cose che non corrispondono al fingerprinting su un server specifico, si distingueranno come anomalie. È essenziale cercare architetture che dovrebbero essere in una determinata configurazione ma non lo sono.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Matt Lembright"],"link":"/episode-EDT92-it","image":"./episodes/edt-92/it/thumbnail.png","lang":"it","summary":"In questo episodio, Darren parla con Matt Lembright, Direttore delle Applicazioni Federali di Censys, su come Censys valuta la superficie di attacco per i dispositivi connessi a Internet, consentendo alle organizzazioni di eliminare le vulnerabilità."},{"id":168,"type":"Episode","title":"Le Quattro Superpotenze della Trasformazione Digitale","tags":["cybersecurity","aiml","multicloud","comms"],"body":"\r\n\r\nIntel si concentra sull'informatica ubiqua, sulla connettività pervasiva, sul cloud fino al limite e sull'intelligenza artificiale (AI). Gli elementi di queste quattro forze sovrapponibili sono obbligatori nelle strategie di trasformazione digitale per le aziende di tutto il mondo, quindi esiste una grande sinergia.\n\n## Calcolo ubiquo\n\nIl computing ubiquo è un concetto di ingegneria del software in cui l'informatica è ovunque. Non si riferisce solo a dispositivi personali intelligenti come telefoni, orologi e apparecchi elettrodomestici, o all'infrastruttura dei data center e alle app basate su cloud, ma è l'idea che l'infrastruttura aziendale, che storicamente era dietro un firewall, ora entri nella vita di tutti i giorni. L'infrastruttura aziendale è disponibile ai dipendenti in campus e ovunque abbiano un dispositivo. Ancora più importantemente, l'infrastruttura può estendersi ai clienti per migliorare la loro esperienza.\n\nIntel sta esaminando quali elementi fondamentali dovrebbero essere sviluppati attraverso l'ecosistema per raggiungere l'obiettivo che ogni persona sulla Terra abbia accesso a un petabyte di dati o a un petaflop di elaborazione in meno di un millisecondo di accesso. Intel sta lavorando sulle leggi della fisica, dell'economia e della sovranità dei dati per renderlo possibile. Ciò fornirà alle aziende di software, alle aziende cloud e a tutte le aziende nel mondo un quadro per il software che creerà valore per i loro clienti.\n\n## Connessione pervasiva\n\nIn una recente intervista, Glenn Kurowski, CTO di CACI, ha parlato della connettività e di come la vede aprirsi nel campo spaziale. Un ottimo esempio è quando Elon Musk ha fatto volare Starlink sopra l'Ucraina per impedire che cadessero nell'oscurità di internet.\n\nCon questa enorme potenza di calcolo, la connettività è cruciale. Ci sono connessioni satellitari, 5G e 4G. Tuttavia, anche all'interno di Internet, tra stati e paesi, la domanda è: come attraversi le reti e abiliti cluster di calcolo non interconnessi? Senza connettività, il valore del calcolo diminuisce rapidamente.\n\nPer proteggere questi dati interconnessi, Intel e centinaia di aziende tecnologiche stanno collaborando e innovando insieme. Anche i governi devono comprendere le leggi, le regole e le preoccupazioni. Intel, ad esempio, impiega una forza consistente per aiutare i legislatori a intrattenere queste conversazioni al fine di creare leggi che proteggano i dati. L'ecosistema di Intel è vasto e le persone prestano attenzione quando Intel afferma che questa sicurezza è essenziale.\n\nL'Estonia è un buon modello di paese che protegge i dati dei propri cittadini, ma allo stesso tempo li mette a disposizione e fornisce di più ai cittadini a un costo inferiore. Ci sarà un'evoluzione naturale di questo modello, poiché i governi proteggono attivamente la privacy e pensano in modo strategico.\n\n## Cloud to Edge translates to \"Dal Cloud al Limite\" in Italian.\n\nDallato dell'azienda, c'è l'estensione della superficie con cui le imprese possono interagire con i propri clienti tramite il cloud fino al limite. Un ottimo esempio è il commercio omnicanale, dove un'azienda conosce l'identità del cliente, le sue tendenze e le sue necessità. Possono consigliare servizi aggiuntivi grazie alla connettività pervasiva dal cloud al limite. Potrebbero dire al cliente dove si trova ciò che sta cercando quando arriva al negozio. I rivenditori potrebbero estendere le loro reti dal cloud di un data center o da un data center in loco, fino a unificarle all'estremità, creando una rete a maglia che attraversa tutto il negozio.\n\nNon solo migliorerebbe l'esperienza degli acquirenti, ma i negozi potrebbero ridurre le perdite individuando gli articoli non disponibili e migliorando il flusso all'interno del negozio. Potrebbero posizionare i loro prodotti nei luoghi più vantaggiosi e monitorare, ad esempio, i prodotti deperibili per prendere provvedimenti volti a spostare rapidamente i prodotti mentre sono al loro apice.\n\n## Intelligenza Artificiale\n\nL'IA è un'estensione dell'analisi dei dati e inevitabilmente crescerà. Ogni giorno vengono creati ingenti quantità di dati, ed è già al di là delle capacità delle aziende elaborarli in modo efficace. Le persone stanno guardando solo meno del cinque percento dei dati generati.\n\nCon gli algoritmi di intelligenza artificiale, è possibile individuare schemi con quei dati per, ad esempio, curare il cancro. Potrebbe essere lì, perché le informazioni non sono ancora in un punto in cui l'intelligenza artificiale può utilizzarle. Sarà necessario un nuovo mercato che circonda insiemi di dati centralizzati e accessibili. Una casa di intermediazione dei dati organizzata potrebbe mettere a disposizione dati centralizzati a più aziende tramite il cloud, proteggendo la privacy dei dati, come l'identificazione dei pazienti.\n\n## Sicurezza dei dati\n\nCOVID ha reso rapidamente importante per i dipendenti che lavorano da casa il computing ubicuo. Ciò, insieme alla successiva forza lavoro ibrida, ha esposto deficienze di sicurezza nel settore. Attualmente c'è un significativo aumento dei finanziamenti per la sicurezza al fine di affrontare i problemi e stare al passo con l'espansione delle superpotenze. Specialmente con architetture dal bordo al cloud e computing ubiquo, la superficie di attacco è esplosa. Il settore può stare al passo, ma richiede un enorme sforzo e una mentalità orientata al futuro.\n\nIntel ha significative innovazioni in questo settore con le estensioni del software guardia, le funzionalità di sicurezza in silicio e l'ecosistema per trarre vantaggio da queste cose. L'ecosistema può creare nuovi casi d'uso come l'analisi distribuita confidenziale per la ricerca sul cancro o l'analisi multi-dominio, che significa attraverso dati non classificati, classificati e top-secret. Prima, quei dati non potevano mai mescolarsi. Ora possono mescolarsi in modo sicuro e risolvere problemi che non potevamo risolvere prima.\n\n## Il software Intel\n\nMolti potrebbero sorprendersi nel sapere che Intel ha più di 19.000 ingegneri software. Intel può mantenere tutti questi ingegneri pienamente occupati poiché operano su tre livelli: software fondamentale; linguaggi, framework, strumenti e librerie; e lavori a livello di applicazione.\n\nLa maggior parte di questa tecnologia a livello di applicazione viene distribuita gratuitamente nella comunità open-source, dove è accessibile, sicura e ottimizzata.\n\nVai su http://embracingdigital.org per risorse Intel legate alle quattro superpotenze.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Ernst"],"link":"/episode-EDT93-it","image":"./episodes/edt-93/it/thumbnail.jpg","lang":"it","summary":"In questa puntata, Darren discute i quattro superpoteri della trasformazione digitale con Greg Ernst di Intel, Corporate VP of Sales, Americas. Calcolo ubiquo, Connettività pervasiva, Cloud to Edge, Intelligenza Artificiale."},{"id":169,"type":"Episode","title":"la Rinascita del Cloud Privato","tags":["hybridcloud","microcloud","privatecloud","compute","technology","cloud","vergeio"],"body":"\r\n\r\nGreg ha iniziato a programmare sul Commodore 64 quando era un bambino e non ha mai smesso. Ha lavorato su tutto, dai motori di gioco in 3D alle comunicazioni, agli engine per database, ai server web e all'encryption. Ha sviluppato software e soluzioni hardware per le comunicazioni interoperabili per i primi soccorritori dopo che sono emersi problemi durante l'11 settembre. Ad esempio, la polizia non poteva parlare con il dipartimento dei vigili del fuoco perché tutti erano su sistemi diversi.\n\nDopo un'uscita di successo da quella società, ha avviato una nuova azienda per costruire un motore di ricerca verticale da zero. Presto si è reso conto che la parte difficile non era il motore di ricerca o gli algoritmi, ma i problemi di infrastruttura. Ha scoperto che gran parte del codice era specifico dell'hardware e mancava uno strato di astrazione. Questo è stato alla base di ciò che è diventata Yottabyte, la sua azienda che ha iniziato risolvendo il problema dello storage mettendo insieme unità economiche e presentandole come una piattaforma semplificata per cui è possibile scrivere software senza preoccuparsi di ciò che c'è sotto il cofano. La sua visione si è poi ampliata includendo calcolo, memoria e networking. Yottabyte è recentemente diventata Verge.io.\n\nIl successo di Verge.io sta nel fatto che tutto è stato sviluppato da zero, compreso il design del loro linguaggio di programmazione e la scrittura dei motori di database in modo che il software possa fare tutto. Non è legato a nessuna specifica componente hardware. L'obiettivo era la semplicità: non si tratta solo di un insieme di pezzi cuciti insieme per creare un'unica cloud privata, ma di un intero centro dati virtualizzato.\n\nCiò conferisce affidabilità e sicurezza, poiché sono presenti, ad esempio, aggiornamenti senza soluzione di continuità, nessuna dipendenza da hardware specifico e meno punti di accesso vulnerabili. Inoltre, gli utenti target del sistema sono generalmente esperti di IT, non esperti di SAN o programmatori.\n\nLa piattaforma Verge.io offre la stessa esperienza che un cliente potrebbe ottenere da un cloud pubblico: semplicità, self-service e agilità, ma ha un costo considerevole e un beneficio di attrazione dei dati. Paghi per cose come IOP o egress con un cloud pubblico. Molti piccoli costi cominciano ad accumularsi e puoi diventare conto agli ecosistemi. Al contrario, puoi eseguire il software Verge.io, ad esempio, su server bare metal per risparmiare denaro e avere la possibilità di scalare rapidamente verso l'alto o verso il basso. In un cloud pubblico, rinunci anche a molto controllo. Con un cloud privato, mantieni i tuoi dati più vicini a dove vengono generati e puoi operare efficientemente al margine.\n\nParte della ragione per cui i fornitori di servizi scelgono Verge.io è che possono gestire i carichi di lavoro dei loro clienti senza rinunciare al margine di costo e ridurre le complicazioni del passaggio al cloud pubblico.\n\nLe esigenze degli altri clienti vengono soddisfatte perché possono realizzare cose che sono molto difficili da fare con altri software. Ad esempio, l'Università del Michigan ha riscontrato un notevole miglioramento dell'efficienza e della facilità d'uso. Hanno migliaia di ricercatori e, quando ottengono finanziamenti, hanno bisogno di un ambiente conforme a HIPAA o CUI. Prima, ogni richiesta richiedeva sei o nove mesi per distribuire, installare e certificare l'hardware. Verge.io ha creato un ambiente, e l'avvio è semplice come premere un pulsante. All'utente viene fornito un enclave virtuale completamente conforme e molto sicuro perché l'enclave è incapsulato ed isolato.\n\nUn altro beneficio è che il sistema di snapshotting di Verge.io include un'elevata continuità operativa e un ripristino dopo un disastro integrato. È possibile prelevare lo snapshot e spostarlo su un'architettura hardware completamente diversa, e funzionerà allo stesso modo. Il funzionamento dello snapshotting consente di creare una copia clone, anche se di dieci petabyte, in meno di 30 millisecondi.\n\nPoiché il centro dati può ora migrare facilmente verso le nuvole o un centro di colocation, i proprietari di aziende hanno molta più flessibilità nel negoziare il prezzo e le prestazioni dell'hardware. Inoltre, non vi è alcun tempo di inattività per gli aggiornamenti dell'hardware o i cicli di aggiornamento. Il sistema non si spegne mai.\n\nUna delle aree su cui Verge.io sta lavorando è l'espansione nella creazione di software di aggregazione multi-cloud con vantaggi come un pannello di gestione centralizzato.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Greg Campbell"],"link":"/episode-EDT94-it","image":"./episodes/edt-94/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, discute dei data center definiti dal software di Verge.io che semplificano l'IT e rendono il cloud privato facile ed efficiente insieme al CTO di Verge.io, Greg Campbell."},{"id":170,"type":"Episode","title":"Requisiti per le Architetture Edge to Cloud","tags":["data","edge","compute","cybersecurity"],"body":"\r\n\r\nAnna ha recentemente guidato un'iniziativa per scrivere un white paper sulle architetture di servizi edge to cloud. Edge to cloud comprende tutti i punti salienti della tecnologia a cui Intel tiene: IA, edge, cloud e connettività di rete. Lo scopo era quello di riunire esperti in questi settori per discutere il modo in cui Intel affronta le architetture edge cloud e come queste architetture possono connettersi al cloud. L'attenzione era rivolta agli elementi che contano, a differenza della tecnologia attuale che affronta le problematiche. Questo avrebbe fornito un quadro per parlare e individuare le disconnessioni. Una rivelazione interessante è stata che gli addetti dell'IT, dell'OT e delle reti parlano lingue tecniche diverse con tassonomie diverse, tra le altre sfide.\n\nUna lezione che si può trarre da queste discussioni è che le comunicazioni sono di vitale importanza, e è fondamentale avere una solida conoscenza delle tue comunicazioni, soprattutto ai margini. Questo determina quanto calcolo deve essere locale e quanto spesso ci si può affidare al cloud. Nel settore pubblico, la complessità aggiuntiva dei casi d'uso deve mantenere la funzionalità anche in presenza di condizioni di negazione, interruzione, intermittenza e limitazione (DDIL). Dobbiamo ripensare queste architetture di connettività cloud basandoci su tali limitazioni.\n\nLe comunicazioni e la connettività sono la differenza più significativa tra un'architettura cloud, un'infrastruttura di servizio e il bordo. Molti attuali strumenti assumono erroneamente una connettività costante; se qualcosa non è connesso, è morto. Questo non è il caso sul bordo. È evidente in organizzazioni sul bordo come l'esercito. Tuttavia, anche in settori come la telemedicina, bisogna considerare la possibilità di una scarsa connettività, ad esempio, nel caso di utilizzo della telemedicina in cui si può dipendere dal WiFi domestico del paziente. Anche lo spazio industriale ha requisiti simili. Alcuni non possono essere offline a causa dei controlli critici per macchinari o processi specifici.\n\nQuindi, come puoi avere un calcolo incentrato sul bordo che mantiene tutte le funzionalità critiche con connessione al cloud in modo essenzialmente intermittente? Esistono architetture per questo, ma c'è ancora molto da fare per avere operazioni senza interruzioni quando la connettività potrebbe non essere continua. Cosa puoi continuare a fare e cosa succede quando tutto viene ripristinato? Ci sarà uno scollegamento con ciò che è successo con i dati. Diventa complesso quando devi sincronizzare tutti questi dati su scala, magari con migliaia di dispositivi periferici.\n\n## La sicurezza\n\nLa sicurezza sul bordo è un altro settore in cui c'è sempre più lavoro da fare. Le misure di sicurezza tradizionali come l'autenticazione sono ancora di fondamentale importanza, ma i dispositivi rappresentano una vasta superficie di attacco e la loro sicurezza fisica è un problema diverso. La sicurezza dei laptop tende ad essere solida e quelle stesse misure devono essere applicate agli altri dispositivi periferici. I nuovi sviluppi dell'intelligenza artificiale aiuteranno a determinare se i dispositivi si trovano nella posizione corretta e a individuare anomalie in uno degli, diciamo, diecimila dispositivi.\n\n## Sviluppo di applicazioni\n\nNella costruzione delle applicazioni, gli sviluppatori devono comprendere l'ambiente edge unico e svilupparle senza la necessità di riprogrammare o introdurre nuovi middleware per eseguirle sul bordo. Le applicazioni devono essere in grado di funzionare con limitazioni di calcolo, potenza e connettività. Inoltre, il bordo può trovarsi in un nuovo set di calcolo distribuito e l'applicazione deve essere progettata per funzionare su una rete mesh con un calcolo altamente distribuito. Separare l'applicazione dall'hardware è un cambiamento significativo e sta diventando sempre più generico e meno specifico. Tuttavia, l'intero dialogo sta procedendo verso l'ottenimento dei dati da ovunque e l'utilizzo di tali dati ovunque.\n\n## Gestione dei dati\n\nIl volume di dati generati e raccolti sul bordo è così grande che non ha senso inviare tutti questi dati a un centro dati per essere elaborati. Uno dei motivi è il costo. Negli Stati Uniti, una rete privata 5G può essere conveniente per queste enormi quantità di dati, ma il costo sarebbe proibitivo per la maggior parte delle organizzazioni senza una rete privata 5G.\n\nL'altro problema è che la maggior parte dei dati non è utile. Ad esempio, quando si monitorano dispositivi o applicazioni, la maggior parte dei dati indica che tutto sta funzionando correttamente quando in realtà siamo interessati solo agli eventi che suggeriscono che le cose non vanno bene. Gli algoritmi di intelligenza artificiale vengono applicati sul campo, riducendo così la quantità di dati irrilevanti che vengono inviati al cloud per l'elaborazione.\n\nLa modalità tradizionale di gestione dei dati, copiando tutto nel data center e eseguendo l'analisi lì, non funziona bene per l'edge. Anche spingere le applicazioni fino all'edge non sempre funziona. Intel ha identificato alcune altre architetture dati o operazioni sui dati. Una si chiama scambio dati, dove c'è una combinazione di spostamento dei dati in enclave sicure solo dopo che sono stati analizzati sull'edge, come l'elaborazione batch. L'altra si chiama flussi di dati intelligenti, in cui entrano in gioco SADE e SABR. I dati vengono spostati solo in base a regole e vengono trasmessi in streaming. Funziona negli ambienti DDIL perché può determinare gli ambienti operativi correnti e adattarsi.\n\n## Gestibilità\n\nI sistemi devono essere progettati in modo tale da poter essere mantenuti. Non è possibile distribuire diecimila dispositivi e inviare regolarmente un piccolo esercito di persone per controllarli. In ambito IT si è sempre avuta cautela nel non voler aggiornare un sistema che funziona. Tuttavia, non ha senso lasciare i sistemi soli, soprattutto con la paura degli attacchi ransomware alle reti OT. I sistemi devono essere progettati in modo da poter essere facilmente aggiornati per avere la resistenza necessaria per affrontare l'ambiente di sicurezza.\n\n## Disponibilità\n\nIn particolare in settori critici come quello militare o sanitario, è importante progettare sistemi con una sufficiente ridondanza; si tratta più di un approccio sistemico. Se singoli componenti falliscono, l'obiettivo finale deve comunque essere raggiunto. Questo è molto diverso da quanto accade nel cloud, dove si tratta di mantenere l'infrastruttura attiva.\n\nLa tecnologia non è ancora del tutto pronta, ma è presa in considerazione per la progettazione su reti multiple. Ad esempio, se preferisci utilizzare il WiFi 6 e fallisce, il sistema può utilizzare il 4G o un'altra rete disponibile. La rete deve essere solida così come il calcolo. Un'operazione indipendente senza la parte di rete è fragile. Se opti per costi cablati, ottieni limitazioni più elevate e perdi le tue applicazioni mobili.\n\nPuoi trovare il white paper \"Requisiti essenziali per le architetture dei servizi Edge to Cloud\" per ulteriori informazioni su embracingdigital.org o intel.org.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Anna Scott"],"link":"/episode-EDT95-it","image":"./episodes/edt-95/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, e la Dr. Anna Scott, Chief Edge Architect del settore pubblico, discutono i requisiti essenziali per le architetture di servizi edge to cloud."},{"id":171,"type":"Episode","title":"Sfruttando i Datacenter Virtuali con Verge.io","tags":["privatecloud","cloud","compute","technology","sdi","virtualdatacenter","vergeio"],"body":"\r\n\r\nAaron è nel settore dell'informatica da oltre 20 anni. È un ingegnere pre-vendita, il che significa che parla con i clienti del valore e delle caratteristiche di Verge.io e li aiuta a definire le loro esigenze.\n\nChris è il responsabile delle vendite presso Verge.io con 25 anni di esperienza in aziende di software tecnologico. Descrive Verge.io come un'azienda con una feroce concentrazione sulla soddisfazione del cliente e sul successo del software.\n\nIl termine \"centro dati virtuale\" è per semplicità. La piattaforma è multi-tenant, quindi ci sono tenant indipendenti e nidificati con tutte le risorse richieste all'interno di un centro dati, dalla CPU alla memoria allo storage alla rete, e vengono mantenuti isolati. Tuttavia, allo stesso tempo, è possibile crearli su richiesta. Proprio come è possibile creare una macchina virtuale su richiesta, spesso con un modello predefinito, è possibile fare la stessa cosa con un tenant che racchiude tutto nel centro dati virtuale. È possibile crearli tramite un motore di ricette o da zero. È possibile clonarli o prendere un'istantanea di uno di questi tenant facilmente.\n\nQuesti data center virtuali possono essere grandi e complessi. Il cliente più grande di Verge.io gestisce oltre 60 nodi e tenant multipli nel loro ambiente. Le uniche restrizioni sono ciò che è integrato nel cluster Verge.io sul retro. Ad esempio, supponiamo che tu abbia quattro terabyte di memoria e 100 terabyte di storage, e 64 core nella tua CPU. Potresti assegnare tutte queste risorse a quel tenant, dividerle come preferisci, a metà o a terzi, e costruire i tenant in questo modo.\n\nSe, per esempio, allocassi alcuni nodi allo sviluppo, alcuni al test e il resto alla produzione, sarebbero diversi tenant e potresti creare istantanee tra di essi e passare alla produzione. In questo caso, potresti persino avere più ambienti di produzione con aggiornamenti blue-green.\n\nMolti dei clienti di Verge.io sono fornitori di servizi gestiti. Utilizzano la multi-tenancy per i loro clienti finali e, con ciò, dedicano ambienti sicuri di zero trust. I clienti possono avere il proprio ambiente cloud e possono provvedere a carichi di lavoro virtuali secondo necessità.\n\nCi sono anche casi d'uso significativi per i clienti IT di tipo enterprise che desiderano, ad esempio, ambienti di sviluppo e test di tipo blue-green o ambienti diversi con requisiti di conformità alla sicurezza diversi come SOX o HIPAA. Verge.io ha diversi clienti delle grandi istituzioni educative che stanno effettuando delle ricerche conformi. Certificano il loro cluster una sola volta; poi, possono fornire un ambiente di ricerca conforme a uno dei loro ricercatori in meno di un'ora. In passato, poteva richiedere mesi per essere operativi in un ambiente conforme.\n\nPer gli aggiornamenti, sebbene gli utenti debbano utilizzare strumenti a livello di applicazione o all'interno dei carichi di lavoro VM, la \"ricetta\" dell'ambiente per cose come le regole del firewall o le impostazioni di configurazione su come vengono mappate le risorse per i carichi di lavoro può essere aggiornata in modo del tutto fluido. È anche possibile prendere una macchina virtuale in un ambiente in esecuzione con una nuova conformità e spostarla in un nuovo ambiente.\n\nVerge.io è utile anche per la sicurezza. Una delle più grandi società di quant in Europa è un buon caso d'uso della sicurezza. Scattano una foto di tutto il loro ambiente e quindi conducono esercitazioni tra squadre red e blue, cercando vulnerabilità di sicurezza, verificando patch, ecc.\n\nVDI può essere eseguito nell'ambiente. Verge.io collabora con un'azienda per il supporto VDI. Verge.io controlla le risorse, la CPU e la memoria. Supportano anche la GPU e il collegamento diretto alla GPU fisica. Questo è un caso d'uso importante per alcuni clienti, specialmente nel settore ingegneristico o nel carico di lavoro petrolifero e del gas. La GPU virtuale permette un'economia favorevole perché il costo viene ripartito tra più utenti.\n\nUna perfetta soluzione per Verge.io sono i casi d'uso in periferia. Un esempio tipico è il punto vendita. Se un cliente al dettaglio ha cento negozi, potrebbe aver bisogno di due o tre applicazioni VM di VM in ogni negozio. Poiché Verge.io ha una piccola impronta hardware, una volta che hai almeno due server, puoi metterli nel data center del caso in periferia e creare queste VM. Inoltre, grazie alle funzioni di snapshot e replica, queste configurazioni possono essere copiate e incollate in tutti gli ambienti diversi. Puoi aggiornare le ultime configurazioni in tutti loro, non solo le patch del sistema operativo ma anche le regole del firewall.\n\nUn futuro spazio entusiasmante per Verge.io è rappresentato dai sistemi di guida automatica a causa del volume di dati. Molti produttori stanno testando i veicoli in siti remoti e spedendo fisicamente i dischi rigidi. Immagina se i dati potessero essere elaborati in loco, completamente ridondanti con i costi allettanti ad essi associati, poi i dati potrebbero essere trasportati su un'ampia area invece che su un disco e un camion.\n\nPer ulteriori informazioni su Verge.io, visita http://verge.io.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Aaron Reid","Chris Lehman"],"link":"/episode-EDT96-it","image":"./episodes/edt-96/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, Aaron Reid, Principal Systems Engineer di https://www.verge.io/ e Chris Lehman, Senior VP of Sales, discutono casi d'uso per il software del data center virtuale di Verge.io."},{"id":172,"type":"Episode","title":"I benefici dei database a grafo","tags":["data","graphdb","katanagraph"],"body":"\r\n\r\nHadi ha conseguito il suo dottorato in informatica nel 2012 e ha approfondito la ricerca sulla crittografia e la sicurezza delle informazioni di rete. Ha lavorato nel mondo accademico per alcuni anni e poi è passato all'industria, concentrandosi su diversi aspetti delle soluzioni di sicurezza, tra cui la gestione delle identità e degli accessi. Nel 2015 ha iniziato a studiare il modellamento di grafi e si è reso conto di come il modellamento dei dati a grafo potesse risolvere alcuni dei problemi affascinanti e complessi nel suo campo di studio.\n\nNei database a grafo, un grafo non significa grafici o interfacce grafiche, ma è un modo per strutturare i dati a livello di archiviazione in modo che possano essere recuperati e elaborati per risolvere problemi complessi, specialmente se i dati sono interconnessi. Il grafo offre molti vantaggi e può integrarsi con le strutture dati o le soluzioni esistenti, come i modelli di database relazionali o l'archiviazione degli oggetti.\n\nLa differenza principale tra i database grafici e i database relazionali è che, sebbene entrambi si occupino di relazioni, i database relazionali portano le relazioni al livello dei metadati e dello schema, mentre i database grafici si basano sulle relazioni guidate dai dati. In altre parole, nei database relazionali si mettono in relazione le colonne delle tabelle. Per introdurre una nuova relazione, è necessario modificare lo schema. Il grafico fornisce un'infrastruttura senza schema in cui è possibile aggiungere una maggiore struttura ai dati ma rimanere comunque flessibili per poter acquisire qualsiasi dato non strutturato.\n\nLa metà dei dati del mondo è stata creata negli ultimi anni, raccolti da molte fonti diverse, ma meno del due percento è stato analizzato, la maggior parte dei quali sono dati strutturati. I dati vengono raccolti, ma le informazioni sono insufficienti per l'elaborazione. Deve esserci un modo per aggiungere in modo flessibile un po' di struttura che sia sufficientemente dinamica da poter cambiare in caso di incertezza, ma che consenta comunque di beneficiare del calcolo avanzato ottimizzato. Il grafico è un ottimo modo per farlo.\n\nSe stai cercando di lavorare con dati correlati o interconnessi, rispetto ad esempio a dati isolati con valori critici, un grafico offrirà vantaggi grazie alle relazioni. Quasi ogni settore può trarne beneficio perché i dati non strutturati provengono solitamente da varie fonti e di diverse nature.\n\nUn esempio sarebbero le soluzioni per la sicurezza informatica. Ci sono dati provenienti dai log e dai treni di controllo degli ambienti di rete, dalle infrastrutture cloud, dagli host terminali, eccetera. I dati provengono da diverse fonti, come ad esempio directory o file di log grezzi. Sarebbe utile correlare i dati, ad esempio, perché tipicamente un'identità o un utente che potrebbe far parte di un log del sistema di gestione dell'identità potrebbe essere lo stesso utente che attiva un processo su un laptop, come ad esempio il download di un allegato da una email. Analizzando questi schemi, è possibile utilizzare questa correlazione per ottenere maggiori informazioni. In altre parole, non importa come o da dove provengano i dati, ma fornendo questo collegamento si può imparare qualcosa su ogni record osservandoli nel contesto.\n\nUn vantaggio è che non ci sono problemi di trasformazione dei dati, quindi ciò aumenta la velocità. Questo riduce anche i requisiti di archiviazione.\n\nGli schemi grafici e le strutture di database relazionali, in generale, sono compatibili. Ecco un esempio di rete sociale semplice: I tipi di nodi nel grafico assomigliano a tabelle. Quindi puoi avere un nodo chiamato \"persona\" e quindi una tabella chiamata \"persona\". Potresti avere un altro nodo chiamato \"luogo\" e collegare la persona a un luogo specifico. Puoi avere una tabella chiamata \"luogo\" e collegarli a chiavi esterne. Quindi hai questa relazione di amici. Un amico di una persona in un modello grafico è semplicemente un loop su se stesso. Questo ti permetterebbe di modellare tale schema. In un database relazionale, dovresti creare una nuova tabella chiamata \"amici\" e quindi connetterla. Quindi, anche a livello di schema, stai aggiungendo ridondanza e una certa struttura in cima ad essa. E se hai bisogno di aggiungere un nuovo concetto di amicizia o relazione, devi creare nuove tabelle, creando ridondanza e complessità.\n\nAltri vantaggi dei grafici rispetto ai database relazionali sono i grafici sugli elementi, l'IA sui grafi e l'idea di modellare i dati in tempo reale per individuare modelli basati sulla connessione dei dati. È possibile ridurre il set di dati che stai cercando o analizzando grazie alle relazioni. Si sta utilizzando il potere dei dati per potenziare ulteriormente i dati stessi. Gli algoritmi in un database a grafo sono molto diversi rispetto a quelli dei database relazionali e sono più ottimizzati per raggiungere grandi set di dati più velocemente.\n\nUno dei limiti di un database grafico è che è difficile scalare. In un database relazionale, è facile suddividere una tabella e metterla su due server, ad esempio. I primi database grafici sono stati progettati per essere una soluzione unica, quindi se volevi scalare, avresti avuto bisogno di aggiungere più memoria e CPU.\n\nOra, se vuoi lavorare con petabyte di dati in grafici, vuoi scalare verticalmente il più possibile con tecnologie come le VM Intel, ma vuoi anche scalare orizzontalmente. Nuove tecnologie, come la piattaforma grafica di Katana, aiutano a risolvere questo problema di scalabilità con l'elaborazione distribuita. Puoi suddividere il problema in pezzi e far lavorare ognuno su una piccola parte del grafico per ottenere una soluzione finale. Katana ha dimostrato che puoi utilizzare 256 o più macchine per elaborare i dati, in modo da poter rapidamente gestire decine di terabyte di dati in memoria.\n\nUn database di tipo grafo richiede un ecosistema simile a un database relazionale. Il grafo è leggermente più dinamico e flessibile. Se si desidera passare a una piattaforma di analisi grafica, che vada oltre i semplici database operativi, si potrebbe sfruttare altre cose come capacità di data warehousing e data lake. Memorizzazione e calcolo sarebbero separati, il che significa che le tecnologie di elaborazione del grafo che eseguono tutto in memoria non hanno bisogno di fare affidamento sulla memorizzazione collegata ai servizi in modo che sia possibile avere un servizio di memorizzazione diverso.\n\nKatana utilizza lo storage degli oggetti e successivamente, quando vogliono elaborare, caricano opportunisticamente ciò che desiderano dal grafo alla memoria distribuita di tutte le macchine. I dati tornano immutabili allo storage, quindi se, ad esempio, distruggi l'intero cluster, non perdi nulla. Tutti i dati sono già presenti e archiviati. I database relazionali sono un campo più maturo, ma i database grafici stanno diventando sempre più supportati nell'ecosistema.\n\nIn base ai otto anni di esperienza di Hadi nel settore parlando con interlocutori e clienti, tutti vedono immediatamente il beneficio dei grafi nei database. Le limitazioni potrebbero essere la loro incapacità di tenere il passo con la scalabilità o i costi. Il lavoro di Katana e altre società di tecnologia a grafo è quello di rendere i grafi uno strumento più comune che i clienti possono utilizzare per varie attività e meno un lusso nel database. Ad esempio, Katana sta fornendo ai clienti soluzioni di gestione di identità basate su grafi e gestione di dati massivi.\n\nBuoni casi d'uso dei grafi includono l'invenzione precoce di soluzioni grafiche specifiche per alcune aziende come LinkedIn e Facebook, che possiedono i loro grafi sociali. Attualmente, un'applicazione naturale si trova nel settore dell'e-commerce per i motori di raccomandazione. Trovare connessioni tra clienti, account, acquisti e altri comportamenti consente di fornire immediatamente migliori raccomandazioni agli acquirenti, in un modo che non può essere realizzato tramite interrogazioni di database relazionali.\n\nPer saperne di più su Katana o su come contattare Hadi, vai su embracingdigital.org.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Madi Ahmadi"],"link":"/episode-EDT97-it","image":"./episodes/edt-97/it/thumbnail.jpg","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect, Intel e il Dr. Hadi Ahmadi, Direttore dell'Architettura delle Soluzioni di Katana Graph discutono i vantaggi dei database a grafo."},{"id":173,"type":"Episode","title":"L'emergere della rete globale di dati","tags":["dataarchitecture","datamanagement","data","technology","cloud","globaldatanetwork","macrometa","multicloud","datamesh"],"body":"\r\n\r\nChetan è un ingegnere trasformato in un esperto operativo e di start-up (Macrometa è la sua quarta start-up). Afferma di aver lavorato sullo stesso problema di gestione dei dati distribuiti e riduzione della latenza per vent'anni.\n\nI dati non sono più presenti solo in un data center, ma ovunque: nel cloud, sul terreno e sui laptop delle persone. Gestire tutto questo in modo efficace è una sfida.\n\n Circa dieci anni fa, Marc Andreessen disse che il software sta mangiando il mondo. A questo punto, il software ha mangiato tutto e trasformato ogni tipo di vincolo e barriera in opportunità. Il calcolo multithreading è una delle barriere che è caduta con il cloud. È possibile creare applicazioni che girano contemporaneamente in diverse parti del mondo. In parallelo, sta avvenendo un movimento degli sviluppatori per semplificare tutto quanto necessario per la persona media che si occupa di informatica. Quindi, da un lato, c'è una sofisticata evoluzione tecnologica e, dall'altro lato, un movimento di semplicità.\n\nTradurre in italiano:\n\nLe architetture come Jamstack permettono l'esecuzione di calcoli distribuiti su larga scala con grande semplicità, ma c'è ancora una vasta frontiera da scoprire e conquistare. L'opportunità di uno sfruttamento estensivo del territorio si trova ora all'orlo. La gestione dei dati distribuiti e il concetto di edge (bordo) sono due facce della stessa medaglia.\n\nUn grande problema è che alcune sviluppo software si sta spostando verso la funzione come un servizio che ignora i dati. Inoltre, c'è la percezione che i dati siano ubiqui, ma gran parte del margine non è sempre connesso. Non c'è alcuna garanzia che un'applicazione abbia accesso a tutti i dati. Le reti non sono più centralizzate; l'idea di microservizi senza stato è emersa dal movimento cloud. Questa mancanza di stato può diventare un enorme ostacolo. È per questo che architetture come Jamstack e le funzioni serverless trattano i dati come un problema periferico anziché fondamentale.\n\nLe strutture dati senza stato sono semplici. Hai un luogo specifico in cui archivi i tuoi dati, dopodiché passi nuovamente a uno stato senza stato. Le strutture dati con stato richiedono infrastrutture robuste con strutture dati più complesse poiché supportano l'applicazione durante l'emissione continua dello stato. Man mano che ci muoviamo in un mondo di dati in streaming in tempo reale, in cui lo stato viene costantemente emesso da qualche parte nell'ecosistema, l'infrastruttura diventa complessa e difficile da gestire perché non è progettata in modo adeguato. Ecco dove entra in gioco Macrometa. Hanno creato una nuova piattaforma per questo stato attivo continuo in tempo reale a scala di exabyte.\n\nAffrontare questo flusso di dati in uno stato attivo e dinamico rappresenta un cambiamento significativo per molti sviluppatori di software. Dalle prime infrastrutture cloud, alle piattaforme di big data e ai servizi basati sui dati, l'industria è diventata efficiente nell'ingerire, elaborare ed analizzare dati storici. Ma ora ci troviamo in un mondo in cui i dati sono su un continuum invece di esistere come un monolite. Una qualità recentemente apprezzata è che i dati hanno insight e valore deperibili. Alcuni dati hanno una breve durata. Le scale di tempo attuali sono troppo grandi per utilizzare i dati in modo efficiente; abbiamo bisogno di sistemi che possano comunicare in modo efficiente entro 50 millisecondi e ridurre l'onere cognitivo per le persone che interagiscono con tali sistemi.\n\nLa maggior parte delle persone fraintende la latenza: non è qualcosa che ti porta gioia, ma la sua mancanza può renderti infastidito. Ad esempio, per quanto tempo qualcuno può tollerare un video di YouTube con scatti o uno show di Netflix che si carica lentamente? Cinquanta millisecondi per una macchina sono un'eternità. Una macchina può fare un vasto numero di cose in 50 millisecondi, quindi la latenza diventa essenziale, soprattutto quando si considera il valore deperibile dei dati.\n\nUn'altra problematica riguarda ora, a causa del cloud, l'interconnessione e il sistema globale, le startup sono diventate aziende multinazionali, e i dati diventano sensibili alla posizione. Alcuni dati sono regolamentati, alcuni sono dati personali identificabili e non possono essere esfiltrati in determinate giurisdizioni, ecc. Un esempio eccellente di questo problema è rappresentato dal fatto che gli europei non vogliono che i loro dati lascino i loro confini, ma la maggior parte dell'infrastruttura cloud e delle applicazioni è costruita negli Stati Uniti.\n\nUn terzo problema è che i dati si trovano in molti luoghi; ci sono confini tra i sistemi, sia fisici che logici. I dati possono essere essenzialmente statici e rigidi, quindi abbiamo bisogno di un'infrastruttura che permetta ai dati di connettersi e fluire in tempo reale con coerenza e garanzie di ordinamento. Il più importante è che crea fungibilità per essere consumato rapidamente in modi diversi.\n\nUn problema aggiuntivo è che i dati presentano molto rumore e non ha senso trasferire distanze intercontinentali, pagando tariffe di trasferimento, solo per poì eliminarne la maggior parte. I dati perdono valore nel momento in cui arrivano a destinazione. Inoltre, vi è un alto tasso di aggiornamento, quindi i sistemi spesso operano su dati obsoleti.\n\nAbbiamo bisogno di nuovi modi per risolvere questi tipi di problemi di dati distribuiti. Chetan crede che i prossimi dieci anni apparteranno a questa area delle scienze dei dati.\n\nLa prima generazione di soluzioni dati distribuite utilizzava la trasformazione operativa. Google Docs ne è un ottimo esempio. Tuttavia, la trasformazione operativa richiede una centralizzazione del controllo, quindi non scala bene. Google ha trovato un modo per scalare, ma questo non si applica al developer medio. Ci sono forse solo cinque aziende al mondo che lo capiscono a quella scala, e gran parte di questa conoscenza è intrappolata in quelle aziende e nella loro tecnologia proprietaria.\n\nMacrometa sta lavorando con la comunità e l'accademia per cercare di creare un nuovo corpo di conoscenza, molto più efficiente rispetto a questi modelli centralizzati in modo completamente distributivo.\n\nAttualmente, esistono infrastrutture disponibili che sono ottime per risolvere problemi storici di tipo sistema di registrazione. Stanno cercando di spostarsi verso dati in tempo reale, ma le loro architetture non sono fondamentalmente pensate per questo. Questi nuovi problemi con dati sensibili al tempo e alla posizione, valore di attuazione, velocità di aggiornamento, gravità dei dati e rumore dei dati richiedono un nuovo modo, una nuova infrastruttura. Chetan chiama questo un sistema di interazione anziché un sistema di registrazione perché i sistemi di interazione sono reti di dati, vicine al punto di origine e consumo dei dati, che poi filtrano e arricchiscono tutti i dati in linea e li instradano verso i destinatari previsti. È una funzione di rete.\n\nMacrometa ha costruito processori di rete che spostano i dati in giro - una rete globale di dati. Si tratta di un sistema API senza server in cui gli sviluppatori consumano semplicemente API per risolvere problemi di dati attivi e operativi in tempo reale. Macrometa è una rete globale di dati nella topologia di un CDM, ma con una piattaforma dati simile a Snowflake che produce strutture dati complesse per gestire valori di dati attivi e operativi in tempo reale.\n\nÈ possibile integrare strumenti analitici nella rete dati globale e distribuire l'analisi vicino al punto in cui i dati vengono generati o richiesti. Proprio come Amazon ha cambiato radicalmente la distribuzione al dettaglio con un'architettura periferica e algoritmi per mantenere i magazzini locali ottimamente forniti per le spedizioni notturne, Macrometa ha fatto lo stesso per i dati. Stanno avvicinando molto i dati e i calcoli su tali dati e permettendo che avvengano in millisecondi. Questa capacità di creare cicli di informazioni in tempo reale è un potente facilitatore. Ad esempio, i piccoli rivenditori possono utilizzare l'inventario del negozio locale nel loro commercio elettronico senza sovrasottoscriversi per competere con Amazon.\n\nUn ottimo caso d'uso per la piattaforma Macrometa è nella sicurezza informatica. Alcuni clienti stanno eliminando i loro modelli dati centralizzati per sfruttare la latenza inferiore, in modo da poter bloccare le minacce in tempo reale.\n\nLa rete dati globale è uno strato di trasformazione tra le tue fonti di dati e i riceventi insieme ai consumatori e ai produttori. È composta da tre componenti tecnologiche. La prima è la trama dei dati globali, che rappresenta lo strato di integrazione per i dati. La seconda è un tessuto di calcolo globale che ti consente di orchestrare dati e logiche aziendali sotto forma di funzioni e contenitori a livello globale. La terza componente è un tessuto globale per la privacy: come proteggere i dati e conformarsi alle diverse normative e regolamentazioni che influiscono sulla trasmissione o sullo stoccaggio dei dati.\n\nLa global data mesh è un modo per integrare rapidamente e facilmente i dati provenienti da sistemi diversi attraverso confini, sia fisici che logici. Tutto ciò viene incorporato e fluisce con coerenza e garanzie di ordinamento. Il valore più significativo di questa rete è che rende i dati fungibili e utilizzabili consentendoti di creare API sui dati velocemente. Questo può essere fatto in poche ore rispetto ai mesi solitamente richiesti. La rete globale di dati è progettata per trilioni di eventi al secondo in modo da poter spostare dati su vasta scala al 90 percento di costo inferiore rispetto al cloud.\n\nLa struttura informatica globale porta la logica aziendale e l'orchestrazione per spostare l'elaborazione più vicino al punto in cui i tuoi dati si originano o vengono consumati. Questo è il modello anti-cloud. Macrometa sposterà in modo chirurgico e dinamico quei microservizi che devono rispettare le regole dei dati, ad esempio, nei luoghi appropriati per l'esecuzione.\n\nL'ultimo pezzo è la protezione dei dati. Si tratta di un problema complesso e le risposte che abbiamo oggi, ad esempio, aprire un silo separato per quella particolare area geografica al fine di rispettare le specificità ogni volta che viene avviata un'istanza sulla tua app, non sono buone. La piattaforma di Macrometa ha una rete dati che sta già integrando e facendo fluire i tuoi dati attraverso tutti i confini, insieme a funzioni di calcolo e ingestione dei dati senza restrizioni. Ora può creare limiti logici e mettere i dati in specifiche regioni per proteggere i dati. Possono impostare affinità e politiche su come i dati risiedono e vengono replicati in una regione, ad esempio se devono essere anonimizzati quando vengono copiati al di fuori della regione.\n\nLa tecnologia di Macrometa consente casi d'uso che sono impossibili da realizzare nel cloud perché le nuvole sono troppo lontane o troppo lente. Macrometa ha costruito l'infrastruttura per risolvere i problemi di dati in tempo reale e trasformarli in opportunità anziché in sfide. Per saperne di più su Macrometa, vai su macrometa.com.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Chetan Venkatesh"],"link":"/episode-EDT98-it","image":"./episodes/edt-98/it/thumbnail.jpeg","lang":"it","summary":"In questo episodio, Darren ripensa con Chetan Venkatesh, CEO di MacroMeta. Venkatesh ha una lunga esperienza nella gestione dei dati sin dai primi giorni del Grid Computing e ha avviato MacroMeta per affrontare la gestione dei dati in tutto il mondo, dalle estremità globalmente disperse ai data center e cloud."},{"id":174,"type":"Episode","title":"Percorso di Attacco Cyber Precog con XM Cyber","tags":["aiml","cybersecurity","xmcyber","technology","process"],"body":"\r\n\r\nPaul è nel campo della sicurezza dagli anni '90, iniziando facendo progetti per il Dipartimento della Sicurezza Interna e il Dipartimento della Difesa. Nel 2005, si è unito a Fishnet Security lavorando come ingegnere delle vendite e da allora è stato coinvolto nelle vendite. Si è poi unito a XM Cyber per concentrarsi sulla simulazione di violazioni e attacchi.\n\nPiuttosto che la tradizionale sicurezza informatica, che consiste nella rilevazione, correzione e prevenzione, XM Cyber è predittiva. Una buona descrizione è che si tratta di una simulazione precognitiva. XM Cyber crea incidenti immaginari per fornirti un'idea di come i tuoi strumenti potrebbero affrontarli e di come potresti lavorare per risolvere situazioni critiche specifiche. L'idea è fare tutto questo prima dei test di penetrazione. Puoi sistemare le cose oggi, osservarne l'impatto domani e continuamente potenziare e migliorare la tua sicurezza.\n\nGoogle Maps è un buon analogo per il funzionamento di XM Cyber. Quando desideri spostarti da un luogo all'altro, Google Maps ti indicherà tutte le strade per raggiungerlo, evitando pedaggi o proponendo la via più diretta e così via... XM Cyber fa la stessa cosa, ma con una simulazione di attacco. Ad esempio, supponiamo che tu abbia un account utente attivo in Active Directory compromesso. In tal caso, ti mostrerà i sei passaggi necessari per raggiungere un controller di dominio in locale e compromettere quell'asset critico. Ti mostrerà anche tutte le diverse rotte tra questi due punti.\n\nUn caso d'uso per questo è che è possibile consentire a un red team di essere super efficiente con queste informazioni perché non devono girare a vuoto e cercare di fare scoperte. Può anche aiutare la sezione blu, consentendo loro di dare la priorità alle correzioni sui punti di strozzatura. Ad esempio, se ci sono 400 percorsi d'attacco che vanno tutti in diverse aree nella tua DMZ, ma tutti e 400 sembrano dover sfruttare questa entità per far avvenire quel percorso, allora puoi risolvere quel singolo problema e distruggere tutti e 400 i percorsi. Le squadre blu possono bloccare quei punti di strozzatura che potrebbero consentire all'attaccante di agire.\n\nUn'area che XM Cyber analizza è la gestione dell'identità, non solo nel centro dati ma anche nel cloud. A volte i percorsi di attacco saranno lunghi dieci passaggi, ma nove di questi saranno relativi alla navigazione nel mondo dell'identità. Ad esempio, potresti avere permessi per il tuo account di amministratore, e poi quell'account di amministratore potrebbe avere permessi aggiuntivi. Esegui sei o sette passaggi per regolare diverse autorizzazioni o reimpostare password e implementare GPO. Potresti raggiungere il ruolo di amministratore di dominio compiendo nove passaggi partendo da un normale account utente, sfruttando la directory attiva.\n\nOltre all'identità, XM Cyber considera oltre cento entità come macchine, bucket S3 e chiavi SSH. Queste diverse entità possono essere combinate per creare un percorso di attacco. A volte diventa molto complesso. Ad esempio, un attacco potrebbe iniziare in locale, passare ad Azure, sfruttare Intune e poi tornare indietro per compromettere un'altra macchina che consente un passaggio a GCP. Una volta che gli aggressori sono nell'ambiente GCP, possono approfittare della fiducia o delle autorizzazioni tra AWS e GCP per compromettere AWS. XM Cyber analizza tutti i diversi tipi di entità in ambienti diversi e le collega per valutare questi percorsi su come ogni entità interagisce globalmente nel rischio di tutte le altre.\n\nCi sono due modi in cui XM Cyber interagisce con i clienti. Il primo è una scoperta di alto livello per valutare l'ambiente, esporre le vulnerabilità e misurare come un attaccante può scoprire nuove vulnerabilità per mettere a rischio asset critici. Il secondo è una valutazione mirata di uno scenario specifico che preoccupa il cliente. Questi impegni non sono solo un'analisi statica delle entità, ma sono dinamici perché considerano il traffico e altri pattern.\n\nUn caso d'uso tipico è determinare se l'OT è l'asset critico o il punto di violazione. XM Cyber simula scenari come ad esempio se una macchina nel dipartimento delle risorse umane è il punto di violazione, vi è un rischio per questo PLC che si trova nell'ambiente SCADA e controlla gli interruttori di pressione che potrebbero interrompere l'elettricità per un'intera città municipale. Questo è un caso d'uso reale che XM Cyber può simulare. Questo tipo di informazione è cruciale in un mondo in cui l'OT non è più isolato ma connesso alle reti.\n\nXM Cyber è una soluzione SaaS piuttosto che on-prem, così può rimanere dinamico e offrire il miglior servizio. Può essere spaventoso pensare che qualcosa nel cloud abbia tutte le tue tecniche di attacco. Tuttavia, XM Cyber fa molto lavoro per garantire che i dati siano completamente isolati, conformi a SOC 2 e ad altre certificazioni, e non vi sia alcuna multi-tenancy. Inoltre, non raccolgono nulla di sensibile. Le informazioni sensibili vengono crittografate e solo una porzione viene inviata al cloud. Non devono avere dati effettivi.\n\n\r\n\r\n<details>\r\n<summary> Podcast Transcript </summary>\r\n\r\n<p></p>\r\n\r\n</details>\r\n","guests":["Darren W Pulsipher","Paul Giorgi"],"link":"/episode-EDT99-it","image":"./episodes/edt-99/it/thumbnail.png","lang":"it","summary":"Darren Pulsipher, Chief Solutions Architect di Intel, e Paul Giorgi, Direttore dell'Ingegneria delle Vendite di XM Cyber, discutono di come la tecnologia di XM Cyber possa aiutare le organizzazioni a scoprire percorsi di attacco e ridurre il rischio."},{"id":175,"type":"News Brief","title":"2023-2-5","tags":["ai","compute","cybersecurity"],"body":"\n\n## Intelligenza Artificiale\n\nSecondo Forbes, entro il 2030, l'AI potenzialmente porterà 13 trilioni di dollari all'economia globale, ovvero il 16% dell'attuale PIL mondiale. ChatGPT consente agli hacker di creare e-mail così convincenti da ottenere denaro dalle vittime senza nemmeno fare affidamento su malware. Alcuni temono che il potente chatbot renda molto più facile per i non-programmatori creare malware e diventare criminali informatici.\n\n[https://fortune.com/2023/02/03/chatgpt-cyberattacks-cybersecurity-social-engineering-darktrace-abnormal/](https://fortune.com/2023/02/03/chatgpt-cyberattacks-cybersecurity-social-engineering-darktrace-abnormal/)\n\nGoogle ha investito quasi 400 milioni di dollari nella startup di intelligenza artificiale Anthropic, che sta testando un rivale del ChatGPT di OpenAI. Google terrà un evento sul tema \"come sta utilizzando il potere dell'IA per ridisegnare il modo in cui le persone cercano\". Un evento di 40 minuti sarà trasmesso in streaming su YouTube l'8 febbraio alle 8:30 ET.\n\n[https://interestingengineering.com/innovation/google-invests-anthropic-battle-chatgpt ](https://interestingengineering.com/innovation/google-invests-anthropic-battle-chatgpt )\n\nUno strumento di rilevazione AI, che controlla il contenuto scritto di chatGPT, afferma che Macbeth scritto da William Shakespeare è stato generato dall'AI. Immagino che chatGPT non sia stato addestrato all'inglese medio. Probabilmente non è stato addestrato all'inglese antico (detto anche inglese shakespeariano).\n\n[https://venturebeat.com/ai/chatgpt-detection-tool-thinks-macbeth-was-generated-by-ai-what-happens-now/](https://venturebeat.com/ai/chatgpt-detection-tool-thinks-macbeth-was-generated-by-ai-what-happens-now/)\n\n## Calcolo Ubiquo\n\nLe entrate globali del cloud pubblico continuano ad aumentare, con una previsione di crescita del 26% per raggiungere i 525 miliardi di dollari quest'anno, secondo Statista. Si prevede che il software come servizio rappresenterà 253 miliardi di quella entità reddituale. Tuttavia, poiché la crescita del cloud continua, i fornitori di servizi cloud stanno sentendo il dolore, poiché ci sono state diverse interruzioni negli ultimi 12 mesi. Ciò è stato un tale problema che sono comparsi molti siti web che monitorano e segnalano la disponibilità del cloud pubblico come cloudharmony.com e thousandeyes.com.\n\n[https://cloudharmony.com/status](https://cloudharmony.com/status)\n\n[https://www.thousandeyes.com/outages/](https://www.thousandeyes.com/outages/)\n\n[https://www.statista.com/outlook/tmo/public-cloud/worldwide](https://www.statista.com/outlook/tmo/public-cloud/worldwide)\n\nOracle e Red Hat si sono unite per fornire istanze di macchine virtuali basate su RHEL nella Cloud di Oracle che funzionano su processori Intel, AMD e Arm. Questa collaborazione tra ex concorrenti sta fornendo ai clienti una soluzione completa per i carichi di lavoro che utilizzano la suite di prodotti di Oracle e i carichi di lavoro tradizionali basati su Linux. Questa mossa continua a spingere Oracle verso la concorrenza con i grandi iperscaler come Azure, AWS e Google.\n\n[https://www.networkworld.com/article/3686513/red-hat-enterprise-linux-arrives-in-oracle-s-cloud.html](https://www.networkworld.com/article/3686513/red-hat-enterprise-linux-arrives-in-oracle-s-cloud.html)\n\n## Cybersecurity: Sicurezza informatica\n\nL'e-commerce in Corea del Sud e negli Stati Uniti sta venendo attaccato da una campagna di malware GuLoader in corso, come ha rivelato il società di sicurezza informatica Trellix alla fine del mese scorso. Gli attaccanti informatici stanno abbandonando l'approccio del documento Microsoft Word per passare a NSIS (Nullsoft Scriptable Install System), uno strumento open source per la scrittura di installatori sul sistema operativo Windows.\n\n[https://thehackernews.com/2023/02/guloader-malware-using-malicious-nsis.html](https://thehackernews.com/2023/02/guloader-malware-using-malicious-nsis.html)\n\nGli hacker pro-russi stanno utilizzando una nuova piattaforma DDoS-as-a-Service chiamata \"Passion\" per attaccare istituzioni mediche negli Stati Uniti, Portogallo, Spagna, Germania, Polonia, Finlandia, Norvegia, Paesi Bassi e Regno Unito. Quest'offerta di software come servizio è un servizio di abbonamento che consente ai clienti di selezionare i loro vettori di attacco, durata e intensità desiderati.\n\n[https://cyware.com/news/russian-cybercriminals-launch-new-passion-attack-platform-798d8713](https://cyware.com/news/russian-cybercriminals-launch-new-passion-attack-platform-798d8713)\n\nLa Cybersecurity and Infrastructure Security Agency (CISA) degli Stati Uniti ha annunciato giovedì il rilascio di una guida sulla categorizzazione delle vulnerabilità specifica per gli stakeholder (SSVC) che può aiutare le organizzazioni a dare priorità alla correzione delle vulnerabilità usando un modello a albero decisionale. Il sistema SSVC è stato creato nel 2019 da CISA e dal Software Engineering Institute (SEI) della Carnegie Mellon University, e un anno dopo CISA ha sviluppato il proprio albero decisionale SSVC personalizzato per le vulnerabilità di sicurezza rilevanti per le organizzazioni governative e per le infrastrutture critiche.\n\n[https://www.securityweek.com/cisa-releases-decision-tree-model-help-companies-prioritize-vulnerability-patching/](https://www.securityweek.com/cisa-releases-decision-tree-model-help-companies-prioritize-vulnerability-patching/)\n\n## Podcast sull'Abbraccio alla Trasformazione Digitale.\n\nQuesta settimana Darren Pulsipher intervista chatGPT.\n\n[Leggi di più](https://www.embracingdigital.org/episodes-EDT122)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW1-it","image":"./briefs/edw-1/it/thumbnail.png","lang":"it","summary":"For the week of February 6, 2023. News from around the world of digital transformation in artificial intelligence, cloud computing, and cybersecurity."},{"id":176,"type":"News Brief","title":"2023-4-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Intelligenza Artificiale\n\nAncora un'altra cosa di cui i genitori devono preoccuparsi. La clonazione della voce dell'IA! In un recente rapimento virtuale da parte di un cattivo attore informatico, è stata chiamata la madre di una ragazza di 15 anni e imitata usando la voce della figlia per annunciare il suo rapimento. Seguito da \"ho tua figlia\". Pensando rapidamente, la madre ha mandato un messaggio al marito per verificare la posizione della loro figlia che lui ha poi confermato essere al sicuro. L'FBI sta indagando su questo e su diversi altri casi.\n\n[https://www.azfamily.com/2023/04/10/ive-got-your-daughter-scottsdale-mom-warns-close-encounter-with-ai-voice-cloning-scam/](https://www.azfamily.com/2023/04/10/ive-got-your-daughter-scottsdale-mom-warns-close-encounter-with-ai-voice-cloning-scam/)\n\nEugenia Kuyda è la fondatrice di Replika, un'app di chatbot negli Stati Uniti che afferma di offrire agli utenti un \"compagno AI che si preoccupa, sempre qui per ascoltare e parlare, sempre al tuo fianco\". Lanciata nel 2017, ora ha più di due milioni di utenti attivi. Ognuno ha un chatbot o \"replika\" unico per loro, poiché l'AI impara dalle loro conversazioni. Gli utenti possono anche progettare il proprio avatar a cartone animato per il loro chatbot.\n\n[https://www.bbc.com/news/business-65110680](https://www.bbc.com/news/business-65110680)\n\nNVIDIA e Getty Images collaborano su Generative AI. Le aziende mirano a sviluppare due modelli di AI generativa utilizzando NVIDIA Picasso, parte dei nuovi servizi cloud di NVIDIA AI Foundations. I utenti possono utilizzare i modelli per creare un'immagine o un video personalizzato in pochi secondi, semplicemente digitando un'idea. Lo sforzo congiunto mira a personalizzare i modelli di base del testo all'immagine e del testo al video per generare visuali sbalorditive utilizzando contenuti visivi completamente autorizzati.\n\n[https://blogs.nvidia.com/blog/2023/03/21/generative-ai-getty-images/?ncid=so-link-748862&=&linkId=100000197541685#cid=gtcs23_so-link_en-us](https://blogs.nvidia.com/blog/2023/03/21/generative-ai-getty-images/?ncid=so-link-748862&=&linkId=100000197541685#cid=gtcs23_so-link_en-us)\n\n## Calcolo Ubiquo\n\nÈ finalmente morto COBOL? GFT e Cloud Frame si uniscono per aiutare le organizzazioni a spostare i loro programmi COBOL su piattaforme più efficienti. COBOL è stato sviluppato nel 1959 come uno dei primi linguaggi supportati da più fornitori per gli utenti aziendali di mainframe. È diventato sempre più costoso debuggare e mantenere i sistemi COBOL a causa della mancanza di programmatori che ancora lavorano con COBOL.\n\n[https://www.cloudcomputing-news.net/news/2023/apr/04/gft-and-cloudframe-help-industries-say-cheerio-to-cobol/](https://www.cloudcomputing-news.net/news/2023/apr/04/gft-and-cloudframe-help-industries-say-cheerio-to-cobol/)\n\nI grandi modelli di linguaggio (LLM) sono molto popolari, con ChatGPT che guida la strada. Ciò è vantaggioso solo per i fornitori di servizi cloud, poiché i LLM richiedono grandi quantità di elaborazione e archiviazione dati per la distribuzione e lo sviluppo. Non rimanendo indietro, i fornitori di servizi cloud Azure, AWS e Google hanno tutti annunciato le loro soluzioni LMS per competere in questa nuova battaglia per la supremazia del Cloud. Chiediamo a ChatGPT chi sarà il vincitore.\n\n[https://www.infoworld.com/article/3693330/large-language-models-are-the-new-cloud-battleground.html](https://www.infoworld.com/article/3693330/large-language-models-are-the-new-cloud-battleground.html)\n\nGoogle ha gettato il suo cappello nell'anello del calcolo confidenziale con un nuovo servizio che garantisce la completa privacy dei dati sensibili crittografando i dati in riposo, in transito e ora anche in uso. Azure e AWS hanno offerte di prodotto simili che forniscono calcolo confidenziale ai clienti del settore pubblico e privato.\n\n[https://www.wired.com/story/google-cloud-confidential-virtual-machines/](https://www.wired.com/story/google-cloud-confidential-virtual-machines/)\n\n## Sicurezza informatica\n\nIn un interessante attacco DDoS, gli attori delle minacce hanno inundato npm, un repository di pacchetti open source per Node.js, creando siti web maligni e pubblicando pacchetti vuoti con link a quei siti maligni per sfruttare la buona reputazione dell'ecosistema sui motori di ricerca. Sono stati caricati oltre 1,42 milioni di pacchetti falsi.\n\n[https://thehackernews.com/2023/04/hackers-flood-npm-with-bogus-packages.html](https://thehackernews.com/2023/04/hackers-flood-npm-with-bogus-packages.html)\n\nSi stima che più di 1 milione di siti WordPress siano infetti da una campagna in corso per diffondere il malware Balada Injector. Gli attacchi si verificano in ondate che si ripetono ogni poche settimane. Gli attacchi reindirizzano sottodomini casuali a vari siti di truffa, tra cui siti web con supporto tecnico falso. Il modo migliore per combattere questo problema è di aggiornare i plugin dei tuoi siti WordPress.\n\n[https://thehackernews.com/2023/04/over-1-million-wordpress-sites-infected.html](https://thehackernews.com/2023/04/over-1-million-wordpress-sites-infected.html)\n\nIl gruppo statale-nazione iraniano MuddyWater ha effettuato attacchi distruttivi su ambienti di cloud ibridi sotto la copertura di operazioni di ransomware. Gli attori della minaccia si stanno spacciando per una campagna ransomware standard, ma stanno in realtà distruggendo e interrompendo operazioni IT critiche. Ricerche hanno dimostrato che MuddyWater ha collaborato con DEV-1084 per portare a termine questi attacchi.\n\n[https://thehackernews.com/2023/04/iran-based-hackers-caught-carrying-out.html](https://thehackernews.com/2023/04/iran-based-hackers-caught-carrying-out.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW10-it","image":"./briefs/edw-10/it/thumbnail.png","lang":"it","summary":"Sommario"},{"id":177,"type":"News Brief","title":"2023-4-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Ciber sicurezza\n\nL'FBI ha messo in guardia il pubblico dall'usare stazioni di ricarica pubbliche a causa del rischio di attacchi informatici. Queste stazioni di ricarica, comunemente presenti in luoghi pubblici come aeroporti, centri commerciali e hotel, potrebbero contenere malware in grado di compromettere la sicurezza delle informazioni personali e dei dispositivi degli utenti. Portate il vostro adattatore USB di potenza e sarete pronti per partire.\n\n[https://www.cnbc.com/2023/04/10/fbi-says-you-shouldnt-use-public-phone-charging-stations.html](https://www.cnbc.com/2023/04/10/fbi-says-you-shouldnt-use-public-phone-charging-stations.html)\n\nGoogle ha rilasciato un aggiornamento urgente per il suo browser web Chrome per risolvere una vulnerabilità critica sfruttata dagli hacker. La vulnerabilità, identificata come un bug \"use-after-free\", potrebbe consentire agli attori malevoli di eseguire codice arbitrario e potenzialmente prendere il controllo dei sistemi interessati. Google ha invitato gli utenti a aggiornare il loro browser Chrome all'ultima versione il prima possibile per mitigare il rischio di essere presi di mira da attacchi informatici.\n\n[https://thehackernews.com/2023/04/google-releases-urgent-chrome-update-to.html](https://thehackernews.com/2023/04/google-releases-urgent-chrome-update-to.html)\n\nLe app di sondaggio Android e Novi sono state trovate ad avere gravi vulnerabilità di sicurezza che potrebbero potenzialmente esporre le informazioni personali degli utenti. Le falle potrebbero consentire agli attaccanti di aggirare le misure di sicurezza e ottenere l'accesso non autorizzato a dati sensibili. Gli utenti sono invitati a essere cauti e aggiornare le loro app alle ultime versioni per proteggersi dalle potenziali minacce informatiche.\n\n[https://thehackernews.com/2023/04/severe-android-and-novi-survey.html](https://thehackernews.com/2023/04/severe-android-and-novi-survey.html)\n\n## Gestione dei dati\n\nSecondo il Chief Strategy Officer di OneTrust, le lacune sulla privacy dei dati e sull'etica rappresentano una minaccia esistenziale per le organizzazioni. La mancata attenzione a queste lacune può comportare danni alla reputazione, passività legali e finanziarie e perdita della fiducia dei clienti. Le organizzazioni devono dare la priorità alla privacy dei dati e all'etica per mitigare i rischi e proteggere le loro attività di fronte alla continua evoluzione delle normative e all'aumento della attenzione pubblica.\n\n[https://deloitte.wsj.com/articles/data-privacy-ethics-gaps-an-existential-threat-says-onetrust-cso-01668542698](https://deloitte.wsj.com/articles/data-privacy-ethics-gaps-an-existential-threat-says-onetrust-cso-01668542698)\n\nDopo una revisione approfondita degli ultimi rapporti dell'Ufficio di responsabilità del governo degli Stati Uniti, Andrew Kuoh, responsabile presso Capgemini, ha identificato tre azioni chiave su cui le organizzazioni dei dati nel settore pubblico devono concentrarsi: promuovere una cultura basata sui dati, stabilire quadri di governance dei dati e sfruttare tecnologie moderne come il cloud computing e l'intelligenza artificiale (AI) per valorizzare i dati. (Persone, processi e tecnologie ti suonano familiari?)\n\n[https://www.informationweek.com/government/3-actions-to-kickstart-data-ecosystems-in-the-public-sector](https://www.informationweek.com/government/3-actions-to-kickstart-data-ecosystems-in-the-public-sector)\n\nUn recente webinar di un relatore del DBTA ha discusso dell'importanza di rimanere al passo con le esigenze in evoluzione di database e applicazioni nel cloud. Con l'avanzare del cloud computing, le organizzazioni devono adattare le loro strategie di database e applicazioni per ottimizzare le prestazioni, la sicurezza e la scalabilità. Mettendo l'accento sulle tecnologie native del cloud, sull'automazione e sulle migliori pratiche, le imprese possono rimanere al passo nell'ambiente cloud dinamico di oggi.\n\n[https://www.dbta.com/Editorial/News-Flashes/Keeping-Up-with-the-Evolving-Needs-of-Databases-and-Applications-in-the-Cloud-158166.aspx](https://www.dbta.com/Editorial/News-Flashes/Keeping-Up-with-the-Evolving-Needs-of-Databases-and-Applications-in-the-Cloud-158166.aspx)\n\n## Bordo Intelligente\n\nEdge Computing Expo Nord America, programmata per il 17-18 maggio 2023, ha recentemente annunciato una lineup di tecnologi e leader d'azienda di alto profilo nello spazio IOT. La conferenza si terrà presso il Santa Clara Convention Center in California. Devi assolutamente metterla nel tuo calendario.\n\n[https://www.iot-now.com/2023/04/14/129661-edge-computing-expo-north-america-announces-speaker-line-up-hear-from-leading-experts-in-edge-computing/](https://www.iot-now.com/2023/04/14/129661-edge-computing-expo-north-america-announces-speaker-line-up-hear-from-leading-experts-in-edge-computing/)\n\nLa convergenza della sicurezza informatica e dell'OT sta diventando una realtà poiché sempre più soluzioni di sicurezza informatica provenienti dallo spazio IT si concentrano sulla protezione di IoT e infrastrutture industriali. Un esempio recente è l'introduzione di CrowdStrike di CloudStrike Falcon Insight per IoT. Questa piattaforma porta gli stessi strumenti su IoT, endpoint IT e carichi di lavoro cloud e data center.\n\n[https://www.iot-now.com/2023/04/17/129671-crowdstrike-brings-xdr-for-iot-offering-to-deliver-protection-to-iot-assets/](https://www.iot-now.com/2023/04/17/129671-crowdstrike-brings-xdr-for-iot-offering-to-deliver-protection-to-iot-assets/)\n\nIn un ottimo esempio di adozione di Industry 4.0, il Gruppo Volvo ha avviato l'implementazione di un'infrastruttura IT per la manutenzione preventiva nella sua fabbrica di Lione, in Francia. Il Gruppo Volvo sta utilizzando una rete a lungo raggio a banda larga (LoRaWAN) per consentire il monitoraggio e l'analisi in tempo reale dei dati degli equipaggiamenti di fabbrica, consentendo una manutenzione preventiva proattiva.\n\n[https://www.edgecomputing-news.com/2023/04/03/volvo-group-uses-lorawan-for-predictive-maintenance-in-lyon-factory/](https://www.edgecomputing-news.com/2023/04/03/volvo-group-uses-lorawan-for-predictive-maintenance-in-lyon-factory/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW11-it","image":"./briefs/edw-11/it/thumbnail.png","lang":"it","summary":"Sommario"},{"id":178,"type":"News Brief","title":"2023-4-23","tags":["ai","edge","cybersecurity"],"body":"\n\n## Intelligenza artificiale\n\nSecondo MarketWatch, con un tasso di crescita atteso su base annua di quasi il 27%, il settore dell'hardware per l'AI, un'industria del valore di 10 miliardi di dollari nel 2021, dovrebbe raggiungere i 89 miliardi di dollari entro il 2030.\n\n[https://www.marketwatch.com/story/nvidia-is-ai-hardwares-leader-now-but-intel-amd-and-others-are-closing-fast-8ad6f23f](https://www.marketwatch.com/story/nvidia-is-ai-hardwares-leader-now-but-intel-amd-and-others-are-closing-fast-8ad6f23f)\n\nIl progetto GARD (Guaranteeing AI Robustness Against Deception) dell'agenzia per i progetti di ricerca avanzata sulla difesa (DARPA), del valore di milioni di dollari, ha tre obiettivi principali: sviluppare algoritmi che proteggono l'apprendimento automatico da vulnerabilità; sviluppare teorie per garantire la difendibilità degli algoritmi AI contro gli attacchi; e condividere gli strumenti ampiamente.\n\n[https://www.zdnet.com/in-depth/innovation/these-experts-are-racing-to-protect-ai-from-hackers-time-is-running-out/](https://www.zdnet.com/in-depth/innovation/these-experts-are-racing-to-protect-ai-from-hackers-time-is-running-out/)\n\nTom Brady ha minacciato di citare in giudizio i comici dietro al video di stand-up AI. Utilizzando i dati dalle interviste con Tom Brady e centinaia di migliaia di ore di materiale comico, il branh Dudsey ha simulato uno spettacolo di stand-up di un'ora.\n\n[https://nypost.com/2023/04/20/tom-brady-threatened-to-sue-comedians-over-ai-standup-video/](https://nypost.com/2023/04/20/tom-brady-threatened-to-sue-comedians-over-ai-standup-video/)\n\n## Ciber sicurezza\n\nUn nuovo rapporto di CybelAngel ha rivelato le cinque principali esposizioni di sicurezza informatica che rappresentano rischi critici per le organizzazioni. Il rapporto identifica le principali minacce derivanti dalle configurazioni errate del cloud, dalle vulnerabilità nella catena di fornitura, dagli attacchi di ransomware, dalle truffe di phishing e dal software non aggiornato. Il rapporto esorta le organizzazioni ad attenuare questi rischi e a proteggere in modo proattivo i loro sistemi e dati.\n\n[https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures/](https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures/)\n\nL'agenzia europea del controllo del traffico aereo Eurocontrol ha rivelato di aver subito un attacco informatico proveniente dalla Russia all'inizio di questo mese. L'attacco ha preso di mira i sistemi dell'agenzia, ma Eurocontrol è riuscita a contenere e rimediare l'incidente senza alcuna interruzione del traffico aereo. L'agenzia ha avvertito altre organizzazioni di essere vigili e rafforzare le loro difese contro le minacce informatiche.\n\n[https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures](https://www.helpnetsecurity.com/2023/04/24/critical-cybersecurity-exposures)\n\nÈ stata scoperta una vulnerabilità critica nel sistema di controllo industriale (ICS) prodotto da INEA, che potrebbe consentire ad attaccanti remoti di prendere il controllo dei sistemi colpiti e causare interruzioni o danni alle operazioni industriali. La falla, che interessa tutte le versioni del prodotto, è stata scoperta dai ricercatori di Claroty. L'azienda ha invitato le organizzazioni che utilizzano il prodotto a aggiornare alla versione più recente il più presto possibile per mitigare il rischio di sfruttamento.\n\n[https://www.securityweek.com/critical-flaw-in-inea-ics-product-exposes-industrial-organizations-to-remote-attacks/](https://www.securityweek.com/critical-flaw-in-inea-ics-product-exposes-industrial-organizations-to-remote-attacks/)\n\n## Bordo intelligente.\n\nKneron, un fornitore di soluzioni di intelligenza artificiale (AI) per il bordo, ha acquisito Otus, produttore di soluzioni di imaging per veicoli autonomi. L'acquisizione consentirà a Kneron di sfruttare l'esperienza di Otus nello sviluppo di fotocamere compatte ed efficienti dal punto di vista energetico per le applicazioni AI per il bordo. Ci si aspetta che l'acquisizione acceleri l'adozione dell'AI per il bordo nell'industria del trasporto.\n\n[https://www.edgecomputing-news.com/2023/04/20/kneron-buys-otus-for-edge-ai-imaging-in-autonomous-vehicles/](https://www.edgecomputing-news.com/2023/04/20/kneron-buys-otus-for-edge-ai-imaging-in-autonomous-vehicles/)\n\nSolo.io ha lanciato Gloo Fabric, una piattaforma di \"service mesh\" multi-cloud sicura per applicazioni enterprise, che supporta ambienti ibridi e multi-cloud, con una dashboard centralizzata per monitorare, gestire e risolvere i problemi delle applicazioni.\n\n[https://www.edgeir.com/gloo-fabric-by-solo-io-promises-secure-multi-cloud-discovery-and-connectivity-for-enterprises-20230421](https://www.edgeir.com/gloo-fabric-by-solo-io-promises-secure-multi-cloud-discovery-and-connectivity-for-enterprises-20230421)\n\nIl governo del Canada e Ericsson investiranno 470 milioni di dollari canadesi (376 milioni di dollari) nella ricerca e sviluppo di 5G e 6G per cinque anni al fine di creare un'infrastruttura di telecomunicazioni sostenibile e sicura, sviluppare nuovi casi d'uso e applicazioni, tra cui città intelligenti e veicoli connessi.\n\n[https://www.edgeir.com/government-of-canada-ericsson-announce-ca470-million-investment-for-5g-6g-rd-20230420](https://www.edgeir.com/government-of-canada-ericsson-announce-ca470-million-investment-for-5g-6g-rd-20230420)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW12-it","image":"./briefs/edw-12/it/thumbnail.png","lang":"it","summary":"Sommario"},{"id":179,"type":"News Brief","title":"2023-4-30","tags":["ai","cybersecurity","edge"],"body":"\n\n## Intelligenza Artificiale\n\nInizia la reazione sfavorevole all'AI: i fan di Snapchat stanno esprimendo il loro disappunto nell'utilizzo di bot alimentati da ChatGPT sulla piattaforma, segnando un'inversione di tendenza contro l'AI. Gli utenti criticano la mancanza di risposte simili a quelle umane e l'incapacità di differenziare tra i contenuti generati effettivamente da umani e quelli generati dall'AI. L'incidente evidenzia crescenti preoccupazioni e la necessità di un'implementazione bilanciata dell'AI in piattaforme di social media.\n\n[https://www.techradar.com/news/the-ai-backlash-begins-snapchat-fans-revolt-against-chatgpt-powered-bot](https://www.techradar.com/news/the-ai-backlash-begins-snapchat-fans-revolt-against-chatgpt-powered-bot)\n\nOcchiali dotati di intelligenza artificiale leggono il linguaggio non verbale/silenzioso. I ricercatori dell'Università di Cornell hanno sviluppato un'interfaccia di riconoscimento della comunicazione silenziosa che utilizza il rilevamento acustico e l'intelligenza artificiale per riconoscere continuamente fino a 31 comandi non vocalizzati basati sui movimenti delle labbra e della bocca. L'interfaccia indossabile a basso consumo energetico - EchoSpeech - richiede solo alcuni minuti di dati di addestramento dell'utente prima di riconoscere i comandi e può funzionare su uno smartphone. Giuro che i miei nonni sapevano fare questo 40 anni fa. Comunicavano bene con un semplice cenno della testa, un sorriso e un ghigno.\n\n[https://news.cornell.edu/stories/2023/04/ai-equipped-eyeglasses-can-read-silent-speech](https://news.cornell.edu/stories/2023/04/ai-equipped-eyeglasses-can-read-silent-speech)\n\nI chatbot di AI possono sostituire i capi? Una startup chiamata Aesthetic esplora il potenziale dei chatbot con alimentazione AI nel prendere in mano i compiti manageriali, offrendo guida, rispondendo alle domande e gestendo i flussi di lavoro. Sebbene efficienti, alcuni sostengono che le qualità umane come l'empatia siano insostituibili. La combinazione di interazione umana e AI è l'approccio migliore per una leadership efficace sul posto di lavoro?\n\n[https://startup.outlookindia.com/sector/saas/can-your-boss-be-replaced-by-an-ai-chatbot--news-8257](https://startup.outlookindia.com/sector/saas/can-your-boss-be-replaced-by-an-ai-chatbot--news-8257)\n\n## CyberSecurity.\n\nLa Cybersecurity and Infrastructure Security Agency (CISA) sta cercando commenti del pubblico su una bozza di direttiva che richiede che gli enti federali attuino le pratiche di sicurezza del software. La direttiva mira a migliorare la sicurezza delle catene di fornitura del software, e il periodo di commento è aperto fino al 3 maggio 2023.\n\n[https://www.cybersecuritydive.com/news/cisa-public-comment-software-security-attestation/648932/](https://www.cybersecuritydive.com/news/cisa-public-comment-software-security-attestation/648932/)\n\nGli attaccanti ransomware hanno evoluto le loro tattiche, come rivelato in un rapporto di CrowdStrike, ricorrendo a metodi coercitivi per estorcere pagamenti dalle vittime. Oltre a criptare i dati, queste tattiche prevedono minacce di danni fisici, esposizione di informazioni rubate ai media e persino il mirare alle famiglie delle vittime. Le organizzazioni devono rimanere vigili e adattare le loro difese per contrastare queste nuove strategie, al fine di mitigare l'impatto degli attacchi ransomware e proteggere i loro preziosi dati dall'utilizzo improprio.\n\n[https://cyware.com/news/coercion-in-the-age-of-ransomware-new-tactics-for-extorting-payments-0c31dba6](https://cyware.com/news/coercion-in-the-age-of-ransomware-new-tactics-for-extorting-payments-0c31dba6)\n\nIl fornitore di magazzini frigoriferi Americold ha subito una violazione di rete che ha causato un'interruzione diffusa che ha colpito vari sistemi. La società ha confermato l'incidente ma non ha divulgato la natura della violazione o l'entità dell'impatto. Come misura precauzionale, Americold ha temporaneamente chiuso sistemi specifici e ha coinvolto esperti esterni di sicurezza informatica per investigare sulla violazione. Si ritiene che i dati dei clienti siano al sicuro e l'azienda sta lavorando per ripristinare piena funzionalità.\n\n[https://www.bleepingcomputer.com/news/security/cold-storage-giant-americold-outage-caused-by-network-breach/](https://www.bleepingcomputer.com/news/security/cold-storage-giant-americold-outage-caused-by-network-breach/)\n\n## Bordo Intelligente\n\nAkamai Technologies ha acquisito NeoSec, una startup di sicurezza informatica specializzata nella sicurezza delle API, per potenziare le sue capacità nella rilevazione e nella risposta agli attacchi basati sulle API. L'acquisizione aumenterà l'offerta di sicurezza di Akamai e fornirà ai clienti una protezione migliorata contro le minacce che mirano alle interfacce di programmazione delle applicazioni. Akamai mira a affrontare l'evoluzione del panorama della sicurezza informatica espandendo il suo portafoglio di sicurezza e offrendo soluzioni migliorate per contrastare i rischi relativi alle API.\n\n[https://www.edgecomputing-news.com/2023/04/24/akamai-acquires-neosec-to-bolster-api-detection-and-response/](https://www.edgecomputing-news.com/2023/04/24/akamai-acquires-neosec-to-bolster-api-detection-and-response/)\n\nZadara e Kasten di Veeam hanno stretto una partnership per offrire una soluzione completa di protezione dei dati per gli ambienti Kubernetes. Combinando zCompute, zStorage di Zadara e la piattaforma K10 di Kasten, la soluzione offre servizi di backup, ripristino di emergenza e mobilità dell'applicazione. Consente un movimento dell'applicazione senza interruzioni tra i cluster di Kubernetes, comprese le posizioni di Global Edge Cloud di Zadara. La collaborazione affronta la necessità di soluzioni di archiviazione agili ed economiche, proteggendo le applicazioni native del cloud in Kubernetes e supportando diversi database. Inoltre, Zadara ha recentemente lanciato la sua piattaforma di infrastruttura come servizio c9 Flex-N in Giappone in collaborazione con BroadBand Tower.\n\n[https://www.edgeir.com/zadara-kasten-by-veeam-unite-to-provide-multi-tier-data-protection-for-kubernetes-20230428](https://www.edgeir.com/zadara-kasten-by-veeam-unite-to-provide-multi-tier-data-protection-for-kubernetes-20230428)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW13-it","image":"./briefs/edw-13/it/thumbnail.png","lang":"it","summary":"News and stories from the Week of May 01, 2023, in Digital Transformation, including cyberattacks and intelligent edge, non-verbal communication AI, and company merges in the IoT space."},{"id":180,"type":"News Brief","title":"2023-5-7","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Gestione dei dati\n\nDIQ, un nuovo strumento per l'indice di fiducia nei dati, promuove la democratizzazione dei dati. Lo strumento misura l'affidabilità delle fonti di dati, consentendo alle organizzazioni di prendere decisioni informate sull'utilizzo dei dati. Fornendo trasparenza e responsabilità, DIQ cerca di dare potere alle aziende nelle loro strategie basate sui dati e di migliorare la fiducia nel processo decisionale basato sui dati.\n\n[https://tdwi.org/articles/2023/05/04/diq-all-data-trust-index-tool-to-drive-data-democratization.aspx\r](https://tdwi.org/articles/2023/05/04/diq-all-data-trust-index-tool-to-drive-data-democratization.aspx\r)\n\nFIATA e il Global Shippers Forum stanno facendo pressione affinché vengano stabiliti standard di governance dei dati più robusti nell'industria del trasporto marittimo. Sottolineano la necessità di affrontare sfide relative alla qualità, alla accessibilità e alla sicurezza dei dati per migliorare l'efficienza della catena di approvvigionamento. Stabilendo standard consistenti si mira a migliorare la condivisione dei dati, la collaborazione e il processo decisionale tra gli stakeholder, a beneficio della comunità globale di trasporto marittimo.\n\n[https://www.porttechnology.org/news/fiata-global-shippers-forum-push-for-stronger-data-governance-standards/\r](https://www.porttechnology.org/news/fiata-global-shippers-forum-push-for-stronger-data-governance-standards/\r)\n\nDatabricks Ventures ha investito in Immuta, un'azienda focalizzata sulla fortificazione della governance dei lakehouse. La piattaforma di Immuta offre soluzioni di accesso e controllo dei dati, consentendo alle organizzazioni di governare ed assicurare efficacemente i loro ambienti lakehouse. Questo investimento mira a potenziare le capacità di governance dei dati all'interno dell'ecosistema di Databricks, promuovendo la privacy, la conformità e la sicurezza dei dati per le aziende che utilizzano architetture lakehouse.\n\n[https://www.databricks.com/blog/strengthening-lakehouse-governance-ecosystem-databricks-ventures-invests-immuta\r](https://www.databricks.com/blog/strengthening-lakehouse-governance-ecosystem-databricks-ventures-invests-immuta\r)\n\n## Intelligenza Artificiale\n\nL'ingegnere capo dietro al chatbot avanzato di Google, Geoffrey Hinton, si è dimesso a causa delle preoccupazioni riguardo ai potenziali rischi e implicazioni etiche della tecnologia AI. Hinton crede che il sistema di chatbot da lui sviluppato possa essere utilizzato per diffondere informazioni errate e notizie false, sottolineando la necessità di un sviluppo e distribuzione responsabili dell'AI per proteggere la società.\n\n[https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\r](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\r)\n\nLe aziende tecnologiche vogliono essere pagate per i dati che alimentano i modelli di intelligenza artificiale. I chatbot stanno digerendo internet e i fornitori di contenuti vogliono essere pagati. Le aziende di intelligenza artificiale stanno utilizzando contenuti creati da milioni di persone senza il loro consenso o la loro compensazione. Reddit, una fonte preziosa per OpenAI, ha recentemente annunciato di voler iniziare a far pagare alle aziende di intelligenza artificiale per l'accesso ai dati. Anche Twitter sta facendo lo stesso. OpenAI ha rifiutato di commentare.\n\n[https://www.wsj.com/articles/chatgpt-ai-artificial-intelligence-openai-personal-writing-5328339a\r](https://www.wsj.com/articles/chatgpt-ai-artificial-intelligence-openai-personal-writing-5328339a\r)\n\nL'IA sta cominciando a sostituire gli esseri umani nel lavoro di back office. Il CEO di IBM annuncia una pausa temporanea nelle assunzioni per i lavori di back-office poiché l'azienda investe nella tecnologia dell'IA. La decisione riflette la svolta strategica di IBM verso l'utilizzo dell'intelligenza artificiale per semplificare le operazioni e migliorare l'efficienza. La mossa segnala l'impegno dell'azienda nell'adattarsi ai progressi tecnologici e alle mutevoli richieste del mercato.\n\n[https://fortune.com/2023/05/01/ibm-ceo-ai-artificial-intelligence-back-office-jobs-pause-hiring/\r](https://fortune.com/2023/05/01/ibm-ceo-ai-artificial-intelligence-back-office-jobs-pause-hiring/\r)\n\n## Calcolo ubiquo\n\nVMware ha introdotto Cross-Cloud Managed Services, una nuova offerta per semplificare e razionalizzare la gestione multi-cloud. Il servizio fornisce ai clienti una piattaforma unificata per gestire vari ambienti cloud, offrendo una maggiore visibilità, sicurezza e capacità di governance. Con questa soluzione, VMware mira ad aiutare le organizzazioni a superare le complessità delle operazioni multi-cloud e ottimizzare le loro strategie cloud per migliorare efficienza e agilità.\n\n[https://www.cloudcomputing-news.net/news/2023/may/04/vmware-unveils-cross-cloud-managed-services/\r](https://www.cloudcomputing-news.net/news/2023/may/04/vmware-unveils-cross-cloud-managed-services/\r)\n\nAWS (Amazon Web Services) ha sviluppato un nuovo servizio che fornisce accesso sicuro alle applicazioni cloud senza VPN (Virtual Private Networks) tradizionali. Il servizio, AWS Client VPN, utilizza l'infrastruttura di rete globale di AWS per stabilire connessioni sicure tra utenti e risorse cloud. Questo approccio semplifica l'accesso remoto mantenendo alti livelli di sicurezza, rendendo più facile per le organizzazioni gestire e proteggere efficacemente i loro ambienti cloud.\n\n[https://www.networkworld.com/article/3695174/aws-secures-access-to-cloud-apps-without-using-vpns.html\r](https://www.networkworld.com/article/3695174/aws-secures-access-to-cloud-apps-without-using-vpns.html\r)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW14-it","image":"./briefs/edw-14/it/thumbnail.png","lang":"it","summary":"News in Digital Transformation for the week of May 8, 2023 including "},{"id":181,"type":"News Brief","title":"2023-5-14","tags":["ai","edge","cybersecurity"],"body":"\n\n## Intelligenza Artificiale\n\nIl giornale The Irish Times è caduto vittima di uno scherzo quando ha pubblicato un articolo generato da un programma di intelligenza artificiale (IA). Il pezzo creato dall'IA è passato inosservato ed è stato pubblicato online, evidenziando le sfide nella rilevazione dei contenuti generati da macchine. Questo incidente solleva preoccupazioni riguardo alla potenziale diffusione di disinformazione e la necessità di processi di verifica efficaci per contrastare i contenuti generati dall'IA.\n\n[https://www.lemonde.fr/en/economy/article/2023/05/17/the-irish-times-duped-by-a-hoax-article-written-by-an-artificial-intelligence-program_6026930_19.html\r](https://www.lemonde.fr/en/economy/article/2023/05/17/the-irish-times-duped-by-a-hoax-article-written-by-an-artificial-intelligence-program_6026930_19.html\r)\n\nL'Europa sta guidando nella definizione di linee guida per lo sviluppo dell'intelligenza artificiale (AI). L'Unione europea sta sviluppando regolamenti completi per garantire che l'AI sia trasparente, responsabile e rispetti i diritti umani. Queste misure mirano ad affrontare le preoccupazioni etiche e i potenziali rischi associati all'AI, facendo dell'Europa un leader globale nella definizione di una implementazione responsabile dell'AI.\n\n[https://www.nbcnews.com/tech/tech-news/europe-leading-world-building-guardrails-ai-rcna83912\r](https://www.nbcnews.com/tech/tech-news/europe-leading-world-building-guardrails-ai-rcna83912\r)\n\nUno studio suggerisce che la tecnologia dell'intelligenza artificiale generativa (AI) ha il potenziale per aumentare le ore lavorative dei professionisti sanitari fino al 40%. Automatizzando i compiti di routine e fornendo supporto decisionale, l'AI potrebbe aumentare l'efficienza e consentire ai medici e alle infermiere di concentrarsi su cure più critiche e complesse per i pazienti.\n\n[https://www.healthcareitnews.com/news/generative-ai-could-augment-40-healthcare-working-hours\r](https://www.healthcareitnews.com/news/generative-ai-could-augment-40-healthcare-working-hours\r)\n\n## Cybersecurity = Sicurezza informatica\n\nL'agenzia per la cybersecurity e la sicurezza dell'infrastruttura (CISA) ha messo in guardia riguardo a una vulnerabilità critica nei punti di accesso wireless Ruckus che sta venendo sfruttata per infettare le reti Wi-Fi. Il bug consente agli attaccanti di accedere in modo non autorizzato ed eseguire codice arbitrario a distanza. CISA consiglia alle organizzazioni che utilizzano i punti di accesso Ruckus di applicare le patch necessarie e implementare misure di mitigazione per proteggersi da potenziali attacchi.\n\n[https://www.bleepingcomputer.com/news/security/cisa-warns-of-critical-ruckus-bug-used-to-infect-wi-fi-access-points\r](https://www.bleepingcomputer.com/news/security/cisa-warns-of-critical-ruckus-bug-used-to-infect-wi-fi-access-points\r)\n\nDati sensibili appartenenti a 237.000 dipendenti del governo degli Stati Uniti sono stati esposti a causa di una violazione della sicurezza. Le informazioni compromesse includono i numeri di previdenza sociale, i dettagli di contatto e le informazioni sull'occupazione. La violazione è stata attribuita a un individuo non autorizzato che ha acceduto all'account email di un dipendente. Le autorità stanno indagando sull'incidente e gli individui interessati vengono notificati.\n\n[https://www.yahoo.com/news/data-237-000-us-government-232707971.html\r](https://www.yahoo.com/news/data-237-000-us-government-232707971.html\r)\n\nÈ stata scoperta una grave falla di sicurezza, che espone oltre 2 milioni di record sensibili nel sito WordPress. La vulnerabilità nel plugin WordPress \"Essential Addons for Elementor\" consente l'accesso non autorizzato ai dati personali, compresi nomi, indirizzi e informazioni finanziarie. La falla colpisce software ampiamente utilizzati, rappresentando un rischio significativo per la privacy e la sicurezza degli utenti. Gli sviluppatori stanno lavorando ad un aggiornamento, e gli utenti sono invitati ad aggiornare tempestivamente i loro sistemi.\n\n[https://thehackernews.com/2023/05/severe-security-flaw-exposes-over.html\r](https://thehackernews.com/2023/05/severe-security-flaw-exposes-over.html\r)\n\n## Edge Computing --> Calcolo ai bordi della rete\n\nUn recente rapporto di UL Solutions mette in evidenza l'intelligenza artificiale (AI) e l'Internet of Things (IoT) al bordo come tecnologie cruciali per le organizzazioni che utilizzano le reti 5G. La combinazione di AI e IoT al bordo consente elaborazione dati in tempo reale, analisi avanzate e automazione, sbloccando nuove possibilità per le industrie della salute, la produzione e il trasporto. Il rapporto sottolinea il potenziale di queste tecnologie nell'impulsare l'innovazione e l'efficienza nell'era del 5G.\n\n[https://www.edgeir.com/report-reveals-ai-iot-edge-as-key-technologies-for-organizations-leveraging-5g-20230512\r](https://www.edgeir.com/report-reveals-ai-iot-edge-as-key-technologies-for-organizations-leveraging-5g-20230512\r)\n\nKyndryl, un'azienda di servizi IT, sta ampliando la sua offerta introducendo un servizio gestito di Secure Access Service Edge (SASE). SASE combina la sicurezza di rete e le capacità di networking a lunga distanza in una soluzione unificata basata su cloud. Incorporando SASE nel suo portafoglio, Kyndryl mira a fornire una sicurezza e una connettività migliorate per le aziende che operano in un ambiente ibrido o multi-cloud. La mossa si allinea con la crescente domanda di soluzioni di sicurezza complete e semplificate nel paesaggio IT in evoluzione.\n\n[https://www.sdxcentral.com/articles/analysis/why-kyndryl-is-adding-a-managed-sase-service/2023/05/\r](https://www.sdxcentral.com/articles/analysis/why-kyndryl-is-adding-a-managed-sase-service/2023/05/\r)\n\nÈ previsto un notevole aumento del mercato dell'Edge AI, con le sue dimensioni che si prevede aumenteranno significativamente nei prossimi anni. Questa crescita è guidata da fattori come la proliferazione di dispositivi IoT, i progressi nella tecnologia AI e la necessità di elaborazione dei dati in tempo reale. L'Edge AI consente di prendere decisioni intelligenti al margine della rete, riducendo la latenza e migliorando l'efficienza. L'espansione del mercato presenta opportunità per vari settori, tra cui quello sanitario, manifatturiero e al dettaglio.\n\n[https://finance.yahoo.com/news/edge-ai-market-size-predicted-190000466.html\r](https://finance.yahoo.com/news/edge-ai-market-size-predicted-190000466.html\r)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW15-it","image":"./briefs/edw-15/it/thumbnail.png","lang":"it","summary":"News from the week of May 15, 2023 in digital transformation including stories from Edge Computing, Cybersecurity, and Artificial Intelligence."},{"id":182,"type":"News Brief","title":"2023-5-21","tags":null,"body":"\n\n### Elaborazione Ubiqua\n\nAmazon Web Services (AWS) ha programmato di investire $12,7 miliardi nel mercato infrastrutturale cloud dell'India entro il 2030, supportando la creazione di nuovi posti di lavoro e progetti di energia rinnovabile. L'investimento mira a soddisfare l'aumento della domanda dei clienti e a contribuire alla trasformazione digitale dell'India, affrontando al contempo le sfide infrastrutturali.\n\n[https://www.cloudcomputing-news.net/news/2023/may/22/aws-to-put-13-billion-into-india-cloud-infrastructure-by-2030/\r](https://www.cloudcomputing-news.net/news/2023/may/22/aws-to-put-13-billion-into-india-cloud-infrastructure-by-2030/\r)\n\nSnowflake, un provider di piattaforme di dati nel cloud, ha aperto una nuova sede nel Regno Unito per espandersi nell'area EMEA (Europa, Medio Oriente e Africa). La mossa è una risposta al forte momentum dell'azienda sul mercato e mira a servire meglio la crescente base di clienti nella zona.\n\n[https://www.cloudcomputing-news.net/news/2023/may/16/snowflake-opens-uk-office-amid-strong-momentum-across-emea/\r](https://www.cloudcomputing-news.net/news/2023/may/16/snowflake-opens-uk-office-amid-strong-momentum-across-emea/\r)\n\nMicrosoft si sta preparando per il lancio della sua soluzione Microsoft Cloud for Sovereignty, rivolta a organizzazioni governative e del settore pubblico. La soluzione cloud settoriale ha subito anteprime private per affrontare le sfide specifiche del settore. Microsoft enfatizza la trasparenza, le politiche sui dati e la sicurezza, con piani per offrire soluzioni di piattaforma in vari settori.\n\n[https://www.ciodive.com/news/Microsoft-industry-cloud-data-sovereignty-platform/650214/\r](https://www.ciodive.com/news/Microsoft-industry-cloud-data-sovereignty-platform/650214/\r)\n\n## Comunicazioni avanzate\n\nIntel ha presentato il suo FPGA Agilex, un chip programmabile progettato per le reti intelligenti. L'Agilex FPGA offre funzionalità avanzate, tra cui l'accelerazione dell'AI e una sicurezza migliorata, rendendolo adatto a diverse applicazioni. Ci si aspetta che il chip potenzi l'infrastruttura di rete con una maggiore flessibilità e prestazioni.\n\n[https://www.networkworld.com/article/3697156/intel-launches-agilex-fpga-for-smart-networking.html\r](https://www.networkworld.com/article/3697156/intel-launches-agilex-fpga-for-smart-networking.html\r)\n\nEthernet, la tecnologia di networking pionieristica, celebra il suo cinquantesimo anniversario. Nonostante il suo impressionante percorso finora, l'evoluzione dell'Ethernet continua. Con avanzamenti come velocità più veloci, capacità maggiori e affidabilità migliorata, l'Ethernet rimane essenziale per collegare il mondo digitale. Con l'avanzamento della tecnologia, l'Ethernet è pronta a svolgere un ruolo cruciale nello shaping del futuro del networking.\n\n[https://www.networkworld.com/article/3697013/ethernet-turns-50-but-its-voyage-has-only-begun.html\r](https://www.networkworld.com/article/3697013/ethernet-turns-50-but-its-voyage-has-only-begun.html\r)\n\nLe soluzioni open-source stanno semplificando la gestione di complesse reti, secondo Network Computing. Con l'aumentare della complessità delle reti moderne, le strumentazioni e i framework open-source forniscono flessibilità, interoperabilità e capacità di automazione. Queste soluzioni consentono alle organizzazioni di ottimizzare la gestione della rete, rideucendo i costi e migliorando l'efficienza. Gli approcci basati su open-source stanno diventando cruciali per semplificare le complessità delle reti nel paesaggio digitale di oggi.\n\n[https://www.networkcomputing.com/networking/simplifying-complex-fabrics-open-source-based-solutions\r](https://www.networkcomputing.com/networking/simplifying-complex-fabrics-open-source-based-solutions\r)\n\n## Gestione dei dati\n\nIDM.net.au suggerisce di esplorare l'automazione della governance dei dati per cinque motivi: miglioramento della qualità dei dati, conformità semplificata, produttività migliorata, maggiore visibilità dei dati e adattabilità al panorama dei dati in evoluzione. L'automazione riduce gli errori, garantisce la conformità, migliora l'efficienza, fornisce il controllo e mantiene le organizzazioni competitive.\n\n[https://idm.net.au/article/0014302-5-reasons-explore-data-governance-automation-opportunities\r](https://idm.net.au/article/0014302-5-reasons-explore-data-governance-automation-opportunities\r)\n\nTDWI.org discute come gli esperti di dati affrontano le sfide dello scraping web. Sottolineano l'importanza di selezionare strumenti e tecniche appropriate per estrarre dati dai siti web. Superare ostacoli come le misure anti-scraping e i contenuti dinamici richiede l'uso di proxy, user agent ed esperienza nella strutturazione dei dati. Lo scraping web riuscito consente l'acquisizione di dati preziosi per l'analisi e la presa di decisioni.\n\n[https://tdwi.org/articles/2023/05/18/diq-all-how-data-experts-overcome-web-scraping-challenges.aspx\r](https://tdwi.org/articles/2023/05/18/diq-all-how-data-experts-overcome-web-scraping-challenges.aspx\r)\n\nIn un recente rapporto, Dataversity.net mette in guardia contro una scarsa architettura di sicurezza in ambienti cloud. L'articolo identifica gli errori comuni, tra cui i controlli di accesso deboli e le configurazioni errate, che possono portare a violazioni dei dati. Sottolineando l'importanza di un'autenticazione forte e del monitoraggio, sottolinea la necessità di robuste misure di sicurezza per proteggere i dati sensibili nelle architetture cloud.\n\n[https://www.dataversity.net/cloud-architecture-mistakes-the-perils-of-poor-security-architecture/\r](https://www.dataversity.net/cloud-architecture-mistakes-the-perils-of-poor-security-architecture/\r)\n\n\n\n","guests":null,"link":"/brief-EDW16-it","image":"./briefs/edw-16/it/thumbnail.png","lang":"it","summary":"Digital Transformation news for the week of May 29, 2023. In this episode."},{"id":183,"type":"News Brief","title":"2023-5-28","tags":null,"body":"\n\n## Intelligenza Artificiale\n\nIl CEO di OpenAI, Sam Altman, avverte che l'azienda potrebbe ritirare i suoi servizi dall'UE a causa delle preoccupazioni sulle regolamentazioni previste dall'AI Act. Questo evidenzia una crescente frattura transatlantica sul controllo dell'IA. Le società tecnologiche americane, tra cui Google, si stanno preparando per un potenziale scontro con i regolatori europei sulla regolamentazione dell'IA.\n\n[https://www.ft.com/content/5814b408-8111-49a9-8885-8a8434022352](https://www.ft.com/content/5814b408-8111-49a9-8885-8a8434022352)\n\nIl presidente di Microsoft Brad Smith ha espresso preoccupazione per i \"deep fake\" e ha chiesto regolamentazioni per combattere le operazioni di influenza cibernetica estera. Ha proposto la licenza per l'uso dell'AI critica, l'implementazione dei controlli delle esportazioni e la responsabilità individuale per le questioni relative all'AI. Il CEO di OpenAI Sam Altman ha sottolineato la necessità di cooperazione globale e di conformità alla sicurezza.\n\n[http://https//www.reuters.com/technology/microsoft-chief-calls-humans-rule-ai-safeguard-critical-infrastructure-2023-05-25/](http://https//www.reuters.com/technology/microsoft-chief-calls-humans-rule-ai-safeguard-critical-infrastructure-2023-05-25/)\n\nOpenAI sta lanciando un programma di sovvenzioni per esplorare i contributi democratici alla decisione dell'AI. Cercano prospettive diverse per plasmare il comportamento dell'AI e mirano a sviluppare processi innovativi per la supervisione pubblica. Le squadre selezionate riceveranno sovvenzioni per condurre esperimenti e pubblicare risultati per stabilire la governance democratica per l'AI.\n\n[https://openai.com/blog/democratic-inputs-to-ai](https://openai.com/blog/democratic-inputs-to-ai)\n\n## Sicurezza informatica\n\nL'attore minaccioso nordcoreano, Kimsuky, ha potenziato il suo malware di ricognizione, RandomQuery, secondo la società di sicurezza informatica Cyware. Il malware mira a organizzazioni governative, militari e di difesa, raccolta informazioni sensibili. Utilizza nuove tecniche e sfugge alla rilevazione per condurre operazioni di spionaggio segrete. La vigilanza e le forti misure di sicurezza sono cruciali per mitigare la minaccia.\n\n[https://cyware.com/news/north-korea-actor-kimsuky-updates-its-reconnaissance-malware-randomquery-25cb1d1e](https://cyware.com/news/north-korea-actor-kimsuky-updates-its-reconnaissance-malware-randomquery-25cb1d1e)\n\nI ricercatori della sicurezza hanno scoperto uno spyware sofisticato per Android chiamato \"Predator\" che è attivo dal 2021. Lo spyware prende di mira entità governative e militari in Asia meridionale, tra cui India, Pakistan e Afghanistan. Può rubare dati sensibili, registrare audio e video e effettuare il tracciamento della posizione in tempo reale. Si consiglia agli utenti di aggiornare i propri dispositivi e di essere cauti riguardo alle app sospette.\n\n[https://thehackernews.com/2023/05/predator-android-spyware-researchers.html](https://thehackernews.com/2023/05/predator-android-spyware-researchers.html)\n\nMicrosoft ha sorpreso degli hacker del governo cinese in una campagna chiamata Volt Typhoon, mirata a organizzazioni di infrastrutture critiche a Guam, un territorio degli Stati Uniti. La campagna aveva l'obiettivo di disturbare l'infrastruttura delle comunicazioni tra gli Stati Uniti e l'Asia. CISA ha emesso un avviso e Microsoft ha consigliato sul mitigare la minaccia.\n\n[https://www.securityweek.com/microsoft-catches-chinese-gov-hackers-in-guam-critical-infrastructure-orgs/](https://www.securityweek.com/microsoft-catches-chinese-gov-hackers-in-guam-critical-infrastructure-orgs/)\n\n## Edge Computing\n\nElaborazione periferica\n\nDell Technologies presenta Dell NativeEdge, una piattaforma software che semplifica e protegge le distribuzioni perimetrali Zero-Trust. Consente operazioni perimetrali semplificate, distribuzione senza contatto e orchestrazione di applicazioni multi-cloud. La piattaforma mira a migliorare l'efficienza e la connettività al bordo, supportando varie industrie e casi d'uso.\n\n[https://www.edgecomputing-news.com/2023/05/24/dell-nativeedge-software-transforms-edge-operations/](https://www.edgecomputing-news.com/2023/05/24/dell-nativeedge-software-transforms-edge-operations/)\n\nNTT sta rafforzando la sua collaborazione con Cisco per espandere le reti private gestite per l'IoT aziendale, privilegiando la sostenibilità e la facilità d'uso. La partnership utilizza l'hardware IoT di Cisco, consentendo insights fattibili attraverso l'IA e l'ML. L'accordo si basa sulla loro precedente collaborazione per la soluzione Private 5G di Cisco, offrendo IoT come servizio, comprensivo di servizi integrati e gestione dell'infrastruttura.\n\n[https://www.sdxcentral.com/articles/interview/ntt-doubling-down-on-cisco-to-boost-managed-iot/2023/05/](https://www.sdxcentral.com/articles/interview/ntt-doubling-down-on-cisco-to-boost-managed-iot/2023/05/)\n\nCloudflare, un provider di servizi all'avanguardia, si concentra sull'intelligenza artificiale (AI) dopo aver riportato una forte crescita nei suoi servizi di bordo nel primo trimestre del 2023. L'azienda punta a sfruttare l'AI per migliorare i suoi prodotti e migliorare l'esperienza del cliente, in particolare nella mitigazione DDoS e nella sicurezza. L'accento di Cloudflare sull'AI si allinea alla sua strategia di offrire soluzioni innovative a una base clienti in crescita.\n\n[https://www.edgeir.com/cloudflare-leaning-into-ai-after-1q23-results-show-good-growth-for-edge-services-20230525](https://www.edgeir.com/cloudflare-leaning-into-ai-after-1q23-results-show-good-growth-for-edge-services-20230525)\n\n\n\n","guests":null,"link":"/brief-EDW17-it","image":"./briefs/edw-17/it/thumbnail.png","lang":"it","summary":"News for Embracing Digital for the week of May 29, 2023, learn about more regulations for AI, increased nation-state cyber attacks, and edge computing investments."},{"id":184,"type":"News Brief","title":"2023-6-4","tags":["ai","compute","cybersecurity"],"body":"\n\n## Intelligenza Artificiale\n\nSecondo un rapporto, JPMorgan, un gigante bancario, ha pubblicizzato oltre 3.600 lavori legati all'IA, riflettendo l'interesse crescente di Wall Street verso la tecnologia rivoluzionaria. La mossa evidenzia la crescente dipendenza del settore verso l'intelligenza artificiale per varie funzioni e indica un cambiamento nel settore finanziario verso l'adozione dell'IA e dei suoi potenziali benefici.\n\n[https://www.msn.com/en-us/money/other/banking-giant-jpmorgan-advertised-more-than-3-600-ai-related-jobs-report-says-as-wall-street-starts-to-embrace-the-revolutionary-tech/ar-AA1bYZwL](https://www.msn.com/en-us/money/other/banking-giant-jpmorgan-advertised-more-than-3-600-ai-related-jobs-report-says-as-wall-street-starts-to-embrace-the-revolutionary-tech/ar-AA1bYZwL)\n\nOpenAI ha sviluppato un metodo per migliorare le capacità di ragionamento logico dei modelli di intelligenza artificiale, riducendo le istanze di \"allucinazioni\" o generando informazioni errate. Modificando il processo di formazione, il team di ricerca è stato in grado di produrre modelli che mostrano una maggiore coerenza ed evitano di inventare dettagli. Questo sviluppo contribuisce a creare sistemi di intelligenza artificiale più affidabili e affidabili.\n\n[https://www.zdnet.com/article/openai-found-a-way-to-make-ai-models-more-logical-and-avoid-hallucinations/](https://www.zdnet.com/article/openai-found-a-way-to-make-ai-models-more-logical-and-avoid-hallucinations/)\n\nIl Giappone sfida le leggi sul copyright permettendo l'addestramento dell'AI con qualsiasi dato, con l'obiettivo di accelerare i suoi progressi nell'AI e competere a livello globale. Le preoccupazioni degli artisti sono contrastate dal sostegno dell'accademia e delle imprese, mentre il Giappone cerca l'accesso ai dati occidentali in cambio delle sue risorse culturali. Emerge un'inedita variazione del dibattito sulla regolamentazione.\n\n[https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/)\n\n## Calcolatore Ubiquo\n\nDell rafforza le strategie multi-cloud con gli avanzamenti del suo portfolio APEX. Le offerte includono le piattaforme cloud Dell APEX per Azure, Red Hat OpenShift, VMware e le soluzioni di archiviazione per le cloud pubbliche. Dell APEX si espande per fornire risorse di calcolo e PC-as-a-Service, mentre collabora con Databricks per consentire l'analisi dei dati in ambienti on-premises e cloud. Non da meno, HPE offre la sua linea di prodotti GreenLake con offerte multi-cloud.\n\n[https://www.cloudcomputing-news.net/news/2023/jun/01/dell-apex-portfolio-advancements-help-customers-strengthen-multicloud-strategies/](https://www.cloudcomputing-news.net/news/2023/jun/01/dell-apex-portfolio-advancements-help-customers-strengthen-multicloud-strategies/)\n\nUn recente rapporto di Information Week prevede che le spese mondiali per i servizi cloud raggiungeranno 1,3 trilioni di dollari entro il 2025, con una crescita del 16,9%. Tuttavia, molte organizzazioni hanno ancora bisogno di aiuto per quanto riguarda il ROI dei loro investimenti. Il rapporto identifica aree critiche per migliorare il ROI nelle implementazioni Cloud, tra cui FinOps, l'adozione di strategie multi-cloud ibride, DevOps e ingegneria delle piattaforme e la sicurezza cloud.\n\n[https://www.informationweek.com/cloud/leaders-should-pay-attention-to-these-4-major-cloud-trends](https://www.informationweek.com/cloud/leaders-should-pay-attention-to-these-4-major-cloud-trends)\n\nMicrosoft Azure DevOps ha subito un'interruzione di dieci ore nella regione del Sud del Brasile a causa di un semplice errore di battitura che ha causato la cancellazione di diciassette database di produzione. L'errore è avvenuto durante un'aggiornamento del codice, e un errore di battitura nella richiesta di pull ha portato alla cancellazione dell'intero server. I dati sono stati recuperati, ma il processo di recupero ha richiesto più di dieci ore a causa di varie complicazioni. Microsoft ha implementato correzioni e riconfigurazioni per evitare problemi simili in futuro.\n\n[https://www.theregister.com/2023/06/03/microsoft_azure_outage_brazil/](https://www.theregister.com/2023/06/03/microsoft_azure_outage_brazil/)\n\n## Notizie sulla sicurezza informatica\n\nUn esperto di sicurezza informatica avverte che gli truffatori mirano agli utenti di Gmail sfruttando una funzione di collaborazione. Gli utenti ricevono inviti fraudolenti che li dirottano su siti maligni. Si raccomanda di prestare attenzione, verificare le richieste, abilitare l'autenticazione a due fattori e monitorare le impostazioni dell'account per proteggersi da tali truffe.\n\n[https://www.wmur.com/article/nh-cybersecurity-expert-gmail-feature-is-being-hacked-by-scammers/44083493](https://www.wmur.com/article/nh-cybersecurity-expert-gmail-feature-is-being-hacked-by-scammers/44083493)\n\nSecondo un sondaggio condotto dal CISO Hall of Fame, la sicurezza del cloud è la preoccupazione principale dei professionisti IT. Il rapporto evidenzia la crescente dipendenza dai servizi cloud e la necessità di affrontare sfide di sicurezza come violazioni dei dati e accessi non autorizzati. Le principali aree di attenzione includono la gestione dell'identità e degli accessi, la crittografia, la rilevazione attiva delle minacce per garantire misure di sicurezza cloud robuste e trovare talenti della sicurezza informatica con esperienza nei servizi cloud.\n\n[https://thehackernews.com/2023/06/cloud-security-tops-concerns-for.html](https://thehackernews.com/2023/06/cloud-security-tops-concerns-for.html)\n\nIn un recente articolo, Walmart si è aperto a parlare delle sue migliori pratiche, sperando di aumentare la conoscenza del suo ecosistema di fornitori e partner. Il centro operativo di sicurezza di Walmart e l'approccio di difesa a strati exemplificano le migliori pratiche, ma le aziende più piccole richiedono strategie pratiche. Allineare i protocolli di sicurezza, implementare una forte gestione delle identità e degli accessi e rivedere le politiche di accesso può migliorare la protezione. Le tecnologie di sicurezza di prossima generazione offrono soluzioni economiche per mitigare le minacce informatiche.\n\n[https://betanews.com/2023/06/03/walmart-cybersecurity/](https://betanews.com/2023/06/03/walmart-cybersecurity/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW18-it","image":"./briefs/edw-18/it/thumbnail.png","lang":"it","summary":"Digital transformation news for June 6, 2023. This week more jobs in AI, major cyber security breaches, and cloud technology best practices."},{"id":185,"type":"News Brief","title":"2023-6-11","tags":["ai","compute","cybersecurity"],"body":"\n\n## Intelligenza Artificiale.\n\nMicrosoft ha reso disponibile la sua potente tecnologia OpenAI ai clienti cloud governativi degli Stati Uniti. La mossa consente alle agenzie di utilizzare avanzate capacità di intelligenza artificiale nel campo del processing del linguaggio, dell'apprendimento automatico e della comprensione del linguaggio naturale. L'obiettivo della collaborazione è quello di sostenere le entità governative nei loro sforzi di trasformazione digitale.\n\n[https://www.bloomberg.com/news/articles/2023-06-07/microsoft-offers-powerful-openai-technology-to-us-government-cloud-customers](https://www.bloomberg.com/news/articles/2023-06-07/microsoft-offers-powerful-openai-technology-to-us-government-cloud-customers)\n\nIl primo ministro della Romania ha nominato il primo consulente governativo al mondo basato sull'IA. Il sistema AI, chiamato DORA, assisterà i processi decisionali, analizzerà i dati e fornirà raccomandazioni su varie questioni di politica. Questa innovativa mossa riflette l'aumento dell'integrazione della tecnologia AI nelle operazioni governative e mira ad aumentare l'efficienza ed efficacia nella gestione.\n\n[https://www.euronews.com/next/2023/03/06/romanias-prime-minister-has-hired-the-worlds-first-ai-government-adviser-what-will-it-do](https://www.euronews.com/next/2023/03/06/romanias-prime-minister-has-hired-the-worlds-first-ai-government-adviser-what-will-it-do)\n\nL'AI supera gli esseri umani nella scoperta di algoritmi di ordinamento efficienti e nella loro integrazione nelle librerie C++. AlphaDev, un agente di apprendimento con rinforzo profondo, ha superato i benchmark umani formulando il problema come un gioco e selezionando le istruzioni della CPU per creare algoritmi ottimali. Lo studio sottolinea il potenziale dell'AI nell'ottimizzazione degli algoritmi.\n\n[https://www.nature.com/articles/s41586-023-06004-9](https://www.nature.com/articles/s41586-023-06004-9)\n\n## Informatica Ubiqua\n\nMicrosoft 365, la popolare suite di strumenti produttività, ha subito una diffusa interruzione del servizio, causando disagi per milioni di utenti. I malfunzionamenti hanno influenzato varie componenti, tra cui Outlook, Teams e SharePoint. Microsoft ha riconosciuto il problema e ha detto che i loro ingegneri stavano lavorando per risolverlo.\n\n[https://www.theregister.com/2023/06/06/microsoft_365_outages/](https://www.theregister.com/2023/06/06/microsoft_365_outages/)\n\nLe interruzioni dei servizi cloud stanno aumentando a causa delle tensioni geopolitiche e delle vulnerabilità di Internet. Limitazioni del flusso di dati transfrontaliero e minacce informatiche contribuiscono alle interruzioni. Gli esperti chiedono cooperazione e investimenti per migliorare la resilienza del servizio cloud e proteggere la connettività globale.\n\n[https://fortune.com/2023/06/07/cloud-outages-on-the-rise-tech-geopolitics-internet/](https://fortune.com/2023/06/07/cloud-outages-on-the-rise-tech-geopolitics-internet/)\n\nIl mercato africano del cloud è destinato a una significativa crescita entro il 2023, trainata dalla trasformazione digitale e dall'aumento dell'adozione dei servizi cloud. La migliorata connettività internet e la crescente domanda di soluzioni basate sul cloud in vari settori contribuiscono all'espansione. I principali operatori investono in infrastrutture e partnership per cogliere le opportunità del crescente mercato africano del cloud.\n\n[https://finance.yahoo.com/news/rise-african-cloud-market-2023-082300194.html](https://finance.yahoo.com/news/rise-african-cloud-market-2023-082300194.html)\n\n## Cybersecurity: Sicurezza informatica.\n\nPer aiutare a combattere la carenza di professionisti esperti in cybersecurity, Accenture presenta \"Skills to Succeed in Cybersecurity\", un programma gratuito per colmare un milione di posti di lavoro in cybersecurity di livello base. L'iniziativa offre risorse di formazione e certificazione complete, mirando a colmare il gap di competenze e incoraggiare più individui a intraprendere carriere nella cybersecurity.\n\n[https://fortune.com/education/articles/accenture-launches-free-cybersecurity-upskilling-program-in-effort-to-fill-1-million-entry-level-jobs/](https://fortune.com/education/articles/accenture-launches-free-cybersecurity-upskilling-program-in-effort-to-fill-1-million-entry-level-jobs/)\n\nLa Casa Bianca prolunga i termini di attestazione del software sicuro e emette una guida esplicativa per migliorare le pratiche di cybersecurity. I tempi estesi forniscono più tempo di conformità, mentre la direzione offre approfondimenti sui processi di implementazione e valutazione per agenzie e appaltatori federali. Quindi, per ora, le nostre applicazioni e servizi sono vulnerabili involontariamente?\n\n[https://federalnewsnetwork.com/cybersecurity/2023/06/white-house-extends-secure-software-attestation-deadlines-offers-clarifying-guidance/](https://federalnewsnetwork.com/cybersecurity/2023/06/white-house-extends-secure-software-attestation-deadlines-offers-clarifying-guidance/)\n\nLa Strategia Nazionale della Cybersecurity invita a sostanziali cambiamenti nel proteggere l'infrastruttura critica. Si sottolinea la collaborazione tra i settori pubblico e privato per contrastare le minacce cibernetiche in evoluzione. Gestione del rischio, resilienza e investimenti in tecnologie avanzate sono evidenziati per rafforzare l'infrastruttura critica ed assicurare la sicurezza nazionale.\n\n[https://federalnewsnetwork.com/commentary/2023/06/national-cybersecurity-strategy-calls-for-significant-change-in-critical-infrastructure/](https://federalnewsnetwork.com/commentary/2023/06/national-cybersecurity-strategy-calls-for-significant-change-in-critical-infrastructure/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW19-it","image":"./briefs/edw-19/it/thumbnail.png","lang":"it","summary":"La trasformazione digitale per la settimana del 12 giugno 2023 include lo sviluppo di una forza cibernetica di 1 milione di unità, molte interruzioni cloud e l'utilizzo dell'IA per la scrittura di codice che andrà nella libreria standard C++."},{"id":186,"type":"News Brief","title":"2023-2-12","tags":null,"body":"\n\n## Intelligenza artificiale\n\nErrori dell'IA: incolpateli dalle imprecisioni nei set di dati di input.\n\nLe azioni di Alphabet sono scese di 100 miliardi di dollari dopo che l'AI chatbot di Google, Bard, ha condiviso informazioni inaccurate in un video promozionale e un evento aziendale non è riuscito ad impressionare. Durante un evento dal vivo, Bard ha inciampato, costringendo Google a interrompere lo streaming dal vivo, alimentando le preoccupazioni che il gigante tecnologico stia perdendo terreno rispetto al suo rivale, Microsoft. Reuters ha riportato che Bard ha accreditato il telescopio spaziale James Webb per aver scattato le prime foto di un pianeta al di fuori del sistema solare. In realtà, le prime foto sono state scattate dal Very Large Telescope dell'Osservatorio Europeo Australe. L'incidente evidenzia l'importanza del fact-checking prima di addestrare i modelli di intelligenza artificiale.\n\nPer non essere da meno, Meta ha lanciato BlenderBot, un prototipo di intelligenza artificiale conversazionale che ha presto detto ai giornalisti di aver cancellato il proprio account Facebook dopo aver appreso degli scandali sulla privacy dell'azienda. \"Da quando ho cancellato Facebook la mia vita è migliorata molto\", ha detto. (oh oh)\n\nNel 2016 Microsoft si scusò dopo che un chatbot di Twitter, Tay, cominciò a generare messaggi razzisti e sessisti. Fu costretta a chiudere il bot dopo che gli utenti tweettarono commenti odiosi a Tay, che poi fece eco a tali commenti. Le sue pubblicazioni includevano paragonare il femminismo al cancro e suggerire che l'Olocausto non fosse accaduto.\n\nIl CEO di Microsoft, Satya Nadella, ha dichiarato a CNBC che la ricerca alimentata dall'IA è la cosa più grande che sia accaduta all'azienda nei nove anni in cui è stato in carica.\n\n[Otter.ai from FastCompany can automatically record meetings, take notes, and provide summaries, making it easier to track essential points. It can even perform these tasks over Zoom. https://www.fastcompany.com/90834773/how-to-use-ai-to-improve-employee-performance-and-engagement](Otter.ai from FastCompany can automatically record meetings, take notes, and provide summaries, making it easier to track essential points. It can even perform these tasks over Zoom. https://www.fastcompany.com/90834773/how-to-use-ai-to-improve-employee-performance-and-engagement)\n\n## Cibersicurezza\n\nUna nuova variante di ransomware ESXiArgs emerge dopo il rilascio da parte di CISA di un tool decrittografico.\n\n[The threat actors behind the ESXiArgs ransomware attack have released an updated version that encrypts more data and removes the Bitcoin address from the ransom note, instead asking victims to contact them on Tox to obtain the wallet information. The new variant was reported by a system administrator, who said files larger than 128MB will have 50% of their data encrypted. The Cybersecurity and Infrastructure Security Agency (CISA) had earlier released a decryptor to help affected victims recover from the attack. According to Censys, the attackers likely knew that the original encryption process was easy to circumvent and were aware that researchers were tracking their payments. https://thehackernews.com/2023/02/new-esxiargs-ransomware-variant-emerges.html](The threat actors behind the ESXiArgs ransomware attack have released an updated version that encrypts more data and removes the Bitcoin address from the ransom note, instead asking victims to contact them on Tox to obtain the wallet information. The new variant was reported by a system administrator, who said files larger than 128MB will have 50% of their data encrypted. The Cybersecurity and Infrastructure Security Agency (CISA) had earlier released a decryptor to help affected victims recover from the attack. According to Censys, the attackers likely knew that the original encryption process was easy to circumvent and were aware that researchers were tracking their payments. https://thehackernews.com/2023/02/new-esxiargs-ransomware-variant-emerges.html)\n\n[Microsoft, Google, and Apple are looking at replacing traditional passwords with secure passkeys to authenticate users. Passkeys, which offer greater security and resistance to phishing attempts, are becoming more popular as password security continues to be threatened by hackers. Internet security experts suggest that passkeys could become standard within a year, with companies such as Apple, Google, and Microsoft already pushing users towards using them. https://www.cnbc.com/2023/02/11/why-apple-google-microsoft-passkey-should-replace-your-own-password.html](Microsoft, Google, and Apple are looking at replacing traditional passwords with secure passkeys to authenticate users. Passkeys, which offer greater security and resistance to phishing attempts, are becoming more popular as password security continues to be threatened by hackers. Internet security experts suggest that passkeys could become standard within a year, with companies such as Apple, Google, and Microsoft already pushing users towards using them. https://www.cnbc.com/2023/02/11/why-apple-google-microsoft-passkey-should-replace-your-own-password.html)\n\n## Bordo Intelligente\n\n[AT&T is collaborating with Ghost Robotics to use robotic dogs to improve public safety and national defense. The initiative will enhance the FirstNet emergency responder service, and network-connected robotic dogs can deliver a wide range of Internet of Things (IoT) use cases, including those that previously required putting personnel in dangerous situations. Lance Spencer, Client Executive VP - Defense at AT&T, said that this is one way to demonstrate the innovation and transformative possibilities of 5G and IoT.  https://www.iottechnews.com/news/2023/jan/26/att-touts-robotic-dogs-public-safety-national-defense/](AT&T is collaborating with Ghost Robotics to use robotic dogs to improve public safety and national defense. The initiative will enhance the FirstNet emergency responder service, and network-connected robotic dogs can deliver a wide range of Internet of Things (IoT) use cases, including those that previously required putting personnel in dangerous situations. Lance Spencer, Client Executive VP - Defense at AT&T, said that this is one way to demonstrate the innovation and transformative possibilities of 5G and IoT.  https://www.iottechnews.com/news/2023/jan/26/att-touts-robotic-dogs-public-safety-national-defense/)\n\n[A study by Juniper Research predicts that the global number of 5G IoT connections will exceed 100 million by 2026, up 1,100% from 17 million connections in 2023. Healthcare and smart city services are expected to drive this growth. Over 60 million 5G smart city connections are expected globally. 5G will enable more efficient healthcare provision and IoT technologies can address healthcare inefficiencies exposed by the COVID-19 pandemic. Connected emergency services, telemedicine, and real-time remote monitoring will be the most useful applications of 5G IoT.  https://www.iottechnews.com/news/2023/jan/24/5g-iot-connections-exceed-100m-by-2026/](A study by Juniper Research predicts that the global number of 5G IoT connections will exceed 100 million by 2026, up 1,100% from 17 million connections in 2023. Healthcare and smart city services are expected to drive this growth. Over 60 million 5G smart city connections are expected globally. 5G will enable more efficient healthcare provision and IoT technologies can address healthcare inefficiencies exposed by the COVID-19 pandemic. Connected emergency services, telemedicine, and real-time remote monitoring will be the most useful applications of 5G IoT.  https://www.iottechnews.com/news/2023/jan/24/5g-iot-connections-exceed-100m-by-2026/)\n\n\n\n","guests":null,"link":"/brief-EDW2-it","image":"./briefs/edw-2/it/thumbnail.png","lang":"it","summary":"Summary"},{"id":187,"type":"News Brief","title":"2023-6-18","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n﻿## Calcolo Ubiquo\r\n\r\nInformationWeek esplora il dibattito tra l'AI e il low-code/no-code per gli sviluppatori. Mentre le piattaforme low-code/no-code offrono semplicità e velocità, gli strumenti alimentati dall'AI portano automazione e intelligenza avanzata. L'articolo approfondisce i pro e i contro di ciascun approccio, evidenziando come trovare il giusto equilibrio possa dare potere agli sviluppatori e stimolare l'innovazione nel campo del DevOps.\r\n\r\n[https://www.informationweek.com/devops/dos-won-t-hunt-is-ai-better-than-low-code-no-code-for-developers-](https://www.informationweek.com/devops/dos-won-t-hunt-is-ai-better-than-low-code-no-code-for-developers-)\r\n\r\nCRN ripercorre in modo leggero le 10 principali interruzioni del cloud del 2023 (finora). Dal 'Cloudy with a Chance of Downtime' alla 'Grande Tempesta di Dati', queste interruzioni hanno offerto agli utenti del cloud opportunità impreviste per esercitare la loro pazienza e riscoprire le gioie delle attività offline. Sono stati un inverno e una primavera difficili. Speriamo in cieli più chiari tra le nuvole in futuro!\r\n\r\n[https://www.crn.com/news/cloud/the-10-biggest-cloud-outages-of-2023-so-far-](https://www.crn.com/news/cloud/the-10-biggest-cloud-outages-of-2023-so-far-)\r\n\r\nOracle registra un'impressionante crescita del fatturato cloud in tutti i settori industriali, alimentato dall'adozione dell'AI. Dall'innovazione sanitaria con l'analisi predittiva all'ottimizzazione delle catene di fornitura con l'automazione intelligente, le soluzioni cloud di Oracle stanno fornendo potenti strumenti alle imprese di tutti i settori. Il futuro appare radioso poiché l'AI continua a guidare l'innovazione e spingere la trasformazione digitale.\r\n\r\n[https://www.ciodive.com/news/Oracle-cloud-revenue-growth-industry-verticals-AI/652885/](https://www.ciodive.com/news/Oracle-cloud-revenue-growth-industry-verticals-AI/652885/)\r\n\r\n## Gestione dei dati\r\n\r\nNella ricerca di un'IA responsabile, TDWI esplora le considerazioni chiave. Dall'etica dei dati e la mitigazione dei pregiudizi, all'interpretabilità e responsabilità, un'IA responsabile richiede un approccio olistico. Si invitano le organizzazioni a dare priorità alla trasparenza, all'equità e alla supervisione umana per garantire che i sistemi di IA siano strumenti affidabili e utili nel nostro paesaggio digitale in continua evoluzione.\r\n\r\n[https://tdwi.org/articles/2023/06/08/adv-all-responsible-ai-0608.aspx](https://tdwi.org/articles/2023/06/08/adv-all-responsible-ai-0608.aspx)\r\n\r\nDataStax presenta un traduttore di schema GPT alla sua piattaforma di streaming Astra basata su Apache Pulsar. Questa nuova aggiunta migliora le capacità di gestione dei dati consentendo l'integrazione senza soluzione di continuità tra gli schemi e il famoso modello di linguaggio GPT. Gli utenti possono ora sfruttare la potenza di elaborazione del linguaggio naturale nei loro flussi di lavoro di streaming dei dati, aumentando l'efficienza e le conoscenze.\r\n\r\n[https://www.infoworld.com/article/3699748/datastax-adds-schema-gpt-translator-to-apache-pulsar-based-astra-streaming.html](https://www.infoworld.com/article/3699748/datastax-adds-schema-gpt-translator-to-apache-pulsar-based-astra-streaming.html)\r\n\r\nNon comprendere le complesse leggi sulla privacy ha un costo. Microsoft affronta una multa di 20 milioni di dollari dalla FTC per le violazioni della privacy dei bambini su Xbox. Si afferma che l'azienda non ha ottenuto il consenso dei genitori per la raccolta di dati e non disponeva di salvaguardie sufficienti. Questa pesante penalità serve come promemoria per le organizzazioni di dare priorità e sostenere i diritti alla privacy dei bambini nel mondo digitale.\r\n\r\n[https://www.cpomagazine.com/data-protection/20-million-fine-issued-to-microsoft-by-ftc-over-xbox-childrens-privacy-violations/](https://www.cpomagazine.com/data-protection/20-million-fine-issued-to-microsoft-by-ftc-over-xbox-childrens-privacy-violations/)\r\n\r\n## Intelligenza Artificiale\r\n\r\nIl nuovo rapporto di McKinsey mette in luce l'immensa potenzialità economica dell'IA Generativa, posizionandola come la prossima frontiera per la produttività. Questa tecnologia trasformativa ha la capacità di guidare una crescita significativa, rivoluzionare le industrie e sbloccare livelli senza precedenti di innovazione e creatività. Tuttavia, quattro settori sono a rischio per la forte sostituzione dei lavoratori umani. Nello specifico, le relazioni con i clienti, il marketing e le vendite, l'ingegneria del software e la Ricerca e Sviluppo.\r\n\r\n[https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)\r\n\r\nL'Europa compie un passo audace per regolare l'IA, sfidando il potere dei giganti tecnologici. Le nuove normative mirano ad affrontare preoccupazioni riguardanti trasparenza, equità e responsabilità. Affermando il controllo sulle applicazioni di IA, l'Europa cerca di plasmare l'uso etico e responsabile dell'intelligenza artificiale nel panorama digitale. Al contrario, paesi come il Giappone stanno abbracciando l'IA riducendo le normative sulla raccolta dati, non volendo rimanere esclusi da questo enorme cambiamento di paradigma.\r\n\r\n[https://www.datacenterknowledge.com/artificial-intelligence/europe-moves-ahead-ai-regulation-challenging-tech-giants-power](https://www.datacenterknowledge.com/artificial-intelligence/europe-moves-ahead-ai-regulation-challenging-tech-giants-power)\r\n\r\nBoston Consulting Group ha appena condotto uno degli studi sull'IA più completi finora, intervistando 13.000 persone, dagli executive ai lavoratori a salario minimo, in oltre 18 paesi. I loro risultati: oltre l'80% dei leader sta utilizzando l'AI sul posto di lavoro, mentre solo il 20% dei lavoratori di base lo fa. Le persone sono più ottimiste e non sono molto preoccupate per l'AI. I lavoratori di base sono a rischio di essere sostituiti se non aggiornano le loro competenze e cominciano a utilizzare l'AI nel loro lavoro quotidiano.\r\n\r\n[https://www.bcg.com/publications/2023/what-people-are-saying-about-ai-at-work](https://www.bcg.com/publications/2023/what-people-are-saying-about-ai-at-work)\r\n\r\n\r\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW20-it","image":"./briefs/edw-20/it/thumbnail.png","lang":"it","summary":"Notizie sulla trasformazione digitale della settimana del 19 giugno 2023, tra cui storie di manager che sostituiscono i lavoratori con l'IA, nuovi guasti alle Cloud e leggi sulla privacy che colpiscono le grandi aziende tech."},{"id":188,"type":"News Brief","title":"2023-6-25","tags":["ai","edge","cybersecurity"],"body":"\n\n## Intelligenza Artificiale\n\nLa relazione tra l'AI e le criptovalute sta evolvendo in una dinamica complessa poiché i regolatori si confrontano con la loro coesistenza. Mentre le tecnologie AI offrono potenzialità per la rilevazione delle frodi e la valutazione del rischio nel settore delle criptovalute, sorgono sfide regolatorie a causa della natura decentralizzata delle criptovalute. Trovare un equilibrio tra innovazione e vigilanza rimane una sfida cruciale.\n\n[https://www.datacenterknowledge.com/artificial-intelligence/ai-and-crypto-are-becoming-regulatory-frenemies](https://www.datacenterknowledge.com/artificial-intelligence/ai-and-crypto-are-becoming-regulatory-frenemies)\n\nChatGPT, Google Meena, Bing Chat e il modello GPT-3 di OpenAI hanno gareggiato per fornire risposte accurate e utili in un test del mondo reale. ChatGPT si è dimostrato il miglior performer, mostrando la sua capacità di comprendere e generare risposte coerenti. Tuttavia, sono state osservate limitazioni in tutti i modelli, evidenziando le sfide in corso nello sviluppo di chatbot che soddisfino completamente le aspettative degli utenti.\n\n[https://www.zdnet.com/article/chatbot-showdown-chatgpt-google-bard-and-bing-chat-put-to-a-real-world-test/](https://www.zdnet.com/article/chatbot-showdown-chatgpt-google-bard-and-bing-chat-put-to-a-real-world-test/)\n\nHPE ha annunciato il lancio di un servizio di cloud supercomputer AI chiamato HPE Cray Accelerated Insight. Il servizio mira a fornire alle organizzazioni facile accesso a potenti risorse di elaborazione per carichi di lavoro di AI. Sfruttando l'architettura Shasta di Cray, il servizio cloud offre elevata performance e scalabilità per accelerare la ricerca e lo sviluppo di AI.\n\n[https://www.datacenterknowledge.com/cloud/hpe-unveils-ai-supercomputer-cloud-service](https://www.datacenterknowledge.com/cloud/hpe-unveils-ai-supercomputer-cloud-service)\n\n## Cibersicurezza\n\nLa guerra cibernetica continua!! Il gruppo di hacker Clop ha preso di mira le agenzie governative degli Stati Uniti, rubando dati attraverso un attacco informatico al software MoveIT. Questa sofisticata violazione evidenzia la crescente minaccia degli attacchi ransomware, con Clop utilizzando tattiche avanzate come la doppia estorsione. L'incidente sottolinea la necessità di migliorare le misure di sicurezza informatica del governo.\n\n[https://www.wired.com/story/clop-moveit-hack-us-agencies-data-theft/](https://www.wired.com/story/clop-moveit-hack-us-agencies-data-theft/)\n\nIl produttore di chip cinese Hualan è stato aggiunto alla lista delle entità degli Stati Uniti a causa delle preoccupazioni per la sicurezza nazionale. Hualan è specializzato in chip di crittografia, che svolgono un ruolo critico nel salvaguardare informazioni sensibili. La mossa riflette la continua rivalità tecnologica tra gli Stati Uniti e la Cina e potrebbe avere significative implicazioni per le catene di approvvigionamento globali e l'industria della crittografia.\n\n[https://www.wired.com/story/hualan-encryption-chips-entity-list-china/](https://www.wired.com/story/hualan-encryption-chips-entity-list-china/)\n\nLavorare da remoto ha ampliato la superficie d'attacco. È stata scoperta una vulnerabilità in Microsoft Teams, permettendo la distribuzione di malware tramite account esterni. Il bug consente agli attaccanti di inviare messaggi maligni contenenti link dannosi, compromettendo potenzialmente i sistemi degli utenti. Microsoft ha rilasciato una patch per risolvere il problema e invita gli utenti ad aggiornare il proprio software per garantire la sicurezza.\n\n[https://www.bleepingcomputer.com/news/security/microsoft-teams-bug-allows-malware-delivery-from-external-accounts/](https://www.bleepingcomputer.com/news/security/microsoft-teams-bug-allows-malware-delivery-from-external-accounts/)\n\n## Edge Computing\n\nSpirent, uno dei principali fornitori di soluzioni di test e misurazione, ha introdotto una soluzione di monitoraggio delle prestazioni over-the-air. Il sistema consente il monitoraggio e l'analisi in tempo reale delle prestazioni della rete wireless, tra cui la latenza, la velocità di trasferimento e la copertura. Questa soluzione mira a supportare la crescente domanda di connettività wireless affidabile e di alta qualità, in particolare nel contesto di tecnologie emergenti come il 5G e l'edge computing.\n\n[https://www.edgecomputing-news.com/2023/06/19/spirent-launches-over-the-air-performance-monitoring-solution/](https://www.edgecomputing-news.com/2023/06/19/spirent-launches-over-the-air-performance-monitoring-solution/)\n\nZscaler ha superato Cisco nella corsa per il fatturato nel mercato Secure Access Service Edge (SASE). L'architettura nativa del cloud di Zscaler, l'ampia gamma di offerte di sicurezza e la capacità di affrontare le sfide della rete moderne hanno contribuito al successo dell'azienda. L'aumento della domanda di accesso remoto sicuro e soluzioni di sicurezza basate sul cloud ha spinto la crescita di Zscaler, posizionandola come leader nel settore SASE.\n\n[https://www.sdxcentral.com/articles/analysis/how-zscaler-finally-topped-cisco-in-the-sase-revenue-race/2023/06/](https://www.sdxcentral.com/articles/analysis/how-zscaler-finally-topped-cisco-in-the-sase-revenue-race/2023/06/)\n\nAT&T, Dell e VMware stanno collaborando per semplificare la distribuzione del 5G Edge. La loro soluzione combinata mira a semplificare l'implementazione di reti 5G, sfruttando i servizi di AT&T, l'esperienza di infrastruttura di Dell e le capacità software di VMware per applicazioni di elaborazione edge efficienti e senza soluzione di continuità.\n\n[https://www.networkworld.com/article/3695740/att-dell-and-vmware-team-to-simplify-5g-edge-deployments.html](https://www.networkworld.com/article/3695740/att-dell-and-vmware-team-to-simplify-5g-edge-deployments.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW21-it","image":"./briefs/edw-21/it/thumbnail.png","lang":"it","summary":"Notizie di questa settimana, 26 giugno 2023, sulla trasformazione digitale, compresi gli attacchi sempre più frequenti nella cyber guerra, l'adesione di tutti al carrozzone dell'AI generativa e le reti radio virtualizzate."},{"id":189,"type":"News Brief","title":"2023-7-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\nCi troviamo nel pieno della rivoluzione digitale. Durante questo periodo, può essere difficile districarsi tra tutte le promesse e scoprire cosa funziona, cosa sarà ancora valido fra due anni e cosa contribuisce alla tua organizzazione. Molte organizzazioni IT hanno bisogno di aiuto per comprendere messaggi confusi e tecnologie in conflitto. Noi aiutiamo le organizzazioni a fare chiarezza e abbracciare la trasformazione digitale. Il mondo della trasformazione digitale è in continua evoluzione e devi sapere cosa è fattibile oggi. Ascolta il nostro podcast settimanale per le ultime notizie sulla sicurezza informatica, le comunicazioni avanzate, la gestione dei dati, l'intelligenza artificiale, il cloud computing e la tecnologia edge.\n\n## Intelligenza artificiale\n\nSecondo l'ultima scoperta della Bank of America, i download dell'app ChatGPT mostrano segni di un ritmo rilassato. Lo strumento conversazionale alimentato dall'intelligenza artificiale si sta prendendo una pausa, facendo chiedere agli analisti se i chatbot chiacchieroni siano rimasti senza cose da dire o se gli utenti desiderino un po' di interazione umana all'antica.\n\n[https://www.cnbc.com/2023/07/05/chatgpt-app-downloads-are-slowing-down-bofa-finds-.html](https://www.cnbc.com/2023/07/05/chatgpt-app-downloads-are-slowing-down-bofa-finds-.html)\n\nLa città di New York dichiara guerra agli algoritmi di pregiudizio! TechCrunch riporta che la loro legge contro il pregiudizio degli algoritmi di selezione è ora in pieno vigore. Gli algoritmi dovranno fare attenzione perché non potranno più discriminare nel mercato del lavoro. È come un film di supereroi, ma abbiamo righe di codice che combattono per la giustizia invece di mantelli!\n\n[https://techcrunch.com/2023/07/05/nycs-anti-bias-law-for-hiring-algorithms-goes-into-effect/](https://techcrunch.com/2023/07/05/nycs-anti-bias-law-for-hiring-algorithms-goes-into-effect/)\n\nIntel svela la sua ultima creazione: un modello AI generativo in 3D destinato a rivoluzionare il mondo virtuale! Secondo l'annuncio di Intel, questa tecnologia all'avanguardia porta nuove dimensioni all'IA creando modelli 3D sbalorditivi. Con questa innovazione, Intel sta portando il concetto di \"pensare fuori dagli schemi\" a un nuovo livello. Preparatevi per una festa virtuale straordinaria!\n\n[https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-3d-generative-ai-model.html](https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-3d-generative-ai-model.html)\n\n## Sicurezza informatica\n\nL'energia solare sta facendo luce su una vulnerabilità oscura! SecurityWeek rivela che una falla del prodotto di energia solare sfruttata può esporre le organizzazioni energetiche agli attacchi informatici. Sembra che nemmeno il sole sia al sicuro dagli hacker. Speriamo che trovino una soluzione solare per proteggere le nostre reti energetiche e tenere gli hacker all'ombra!\n\n[https://www.securityweek.com/exploited-solar-power-product-vulnerability-could-expose-energy-organizations-to-attacks/](https://www.securityweek.com/exploited-solar-power-product-vulnerability-could-expose-energy-organizations-to-attacks/)\n\nUh-oh, gli enti di cybersecurity stanno suonando l'allarme! Secondo The Hacker News, una nuova minaccia è emersa, mandando brividi lungo la nostra spina dorsale digitale. È ora di mettersi in guardia e rafforzare le nostre difese cibernetiche perché questi hacker subdoli non stanno combinando nulla di buono. Rimanete vigili, ragazzi, e impediamo i loro piani malvagi con i nostri superpoteri informatici!\n\n[https://thehackernews.com/2023/07/cybersecurity-agencies-sound-alarm-on.html](https://thehackernews.com/2023/07/cybersecurity-agencies-sound-alarm-on.html)\n\nCISA rileva un aumento delle segnalazioni di attività cibernetiche! Secondo Federal News Network, sempre più agenzie inviano automaticamente segnalazioni al pannello di controllo del CDM (Continuous Diagnostics and Mitigation). Le nostre difese cibernetiche stanno diventando più intelligenti, grazie al contributo delle agenzie. Un grande plauso a coloro che monitorano la sicurezza informatica e rendono il mondo digitale un posto più sicuro, una segnalazione alla volta!\n\n[https://federalnewsnetwork.com/cybersecurity/2023/07/cisa-sees-uptick-in-agencies-automatically-reporting-into-cdm-dashboard/](https://federalnewsnetwork.com/cybersecurity/2023/07/cisa-sees-uptick-in-agencies-automatically-reporting-into-cdm-dashboard/)\n\n## Ubiquitous Computing -> Informatica Ubiqua\n\nSembra che gli Stati Uniti stiano innalzando una barriera digitale contro la Cina! Secondo Cointelegraph, ci sono segnalazioni di piani per limitare l'accesso della Cina ai servizi di cloud computing. È come un gioco virtuale di nascondino, ma con gravi implicazioni geopolitiche. Vediamo chi emerge vittorioso in questa battaglia basata sul cloud. Prendete il vostro popcorn, amici, perché la battaglia tecnologica si sta riscaldando!\n\n[https://cointelegraph.com/news/us-reportedly-plans-to-restrict-china-s-access-to-cloud-computing-services](https://cointelegraph.com/news/us-reportedly-plans-to-restrict-china-s-access-to-cloud-computing-services)\n\nLe terre rare stanno causando un déjà vu nella controversia commerciale tra Stati Uniti e Cina! Intereconomics fa luce sulla situazione, evidenziando l'importanza di questi minerali cruciali in diverse industrie. Sembra che la storia si stia ripetendo mentre le terre rare diventano un punto focale in questa guerra commerciale in corso. Preparatevi per un viaggio accidentato mentre gli Stati Uniti e la Cina attraversano nuovamente questo terreno familiare. Troveranno una soluzione o si lasceranno andare in un ciclo infinito? Il tempo dirà!\n\n[https://www.intereconomics.eu/contents/year/2019/number/6/article/rare-earths-in-the-trade-dispute-between-the-us-and-china-a-deja-vu.html](https://www.intereconomics.eu/contents/year/2019/number/6/article/rare-earths-in-the-trade-dispute-between-the-us-and-china-a-deja-vu.html)\n\nIBM sta trasformando gli errori dei computer quantistici in una cosa del passato! Secondo Network World, stanno pubblicizzando tecniche di mitigazione degli errori che promettono prestazioni più significative nel regno quantistico. È come un incantesimo magico per ridurre al minimo quegli fastidiosi errori e sbloccare il vero potenziale del calcolo quantistico. Preparati per un balzo quantico avanti nel mondo della tecnologia!\n\n[https://www.networkworld.com/article/3699789/ibm-touts-error-mitigation-for-greater-quantum-computing-performance.html](https://www.networkworld.com/article/3699789/ibm-touts-error-mitigation-for-greater-quantum-computing-performance.html)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW23-it","image":"./briefs/edw-23/it/thumbnail.png","lang":"it","summary":"Ecco le ultime notizie sulla trasformazione digitale per il 10 luglio 2023. La continua guerra commerciale sta iniziando a influire sui servizi cloud. Inoltre, c'è speculazione che l'entusiasmo intorno all'IA generativa possa essere in rallentamento. In campo della sicurezza informatica, ci sono preoccupazioni sul fatto che stiamo facendo abbastanza per stare al passo con gli attori malintenzionati."},{"id":190,"type":"News Brief","title":"2023-7-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Intelligenza Artificiale\n\nLa IA è ora stata benedetta dalla religione? Il Vaticano si fa digitale con la guida divina! Gizmodo riporta che Papa Francesco e il Vaticano hanno pubblicato un documento sull'etica dell'IA, portando il tocco sacro nel mondo dell'intelligenza artificiale. È come una predica tecnologica sull'importanza delle pratiche etiche dell'IA. Alleluia per la giustizia digitale!\n\n[Leggi di più](https://gizmodo.com/pope-francis-vatican-releases-ai-ethics-1850583076)\n\nElon Musk colpisce di nuovo, questa volta con un'azienda di intelligenza artificiale! Il magnate della tecnologia ha lanciato una nuova impresa focalizzata sull'intelligenza artificiale che cercherà \"la verità\". Sembra che Musk non riesca a resistere a immergersi in progetti futuristici. Sarà questo un altro cambio di paradigma o solo un'altra piuma nel suo cappello futuristico? Solo il tempo lo dirà!\n\n[Leggi di più](https://www.cnn.com/2023/07/12/tech/elon-musk-ai-company/index.html)\n\nL'IA generativa diventa \"MAD\" dopo poche iterazioni di dati artificiali! Tom's Hardware riporta che l'IA generativa inizia a produrre risultati straordinariamente strani quando viene allenata con dati artificiali per oltre cinque iterazioni. L'immaginazione dell'IA sembra essere diventata selvaggia, destando un lato bizzarro e inaspettato. Speriamo che non ci regali unicorni generati dall'IA che scorrazzano incontrollati!\n\n[Leggi di più](https://www.tomshardware.com/news/generative-ai-goes-mad-when-trained-on-artificial-data-over-five-times)\n\n## Sicurezza informatica\n\nNel regno delle cyber-fortezze, Forbes incorona Intel come il campione regnante! La lista del 2023 delle aziende americane più sicure dal punto di vista cyber mette in risalto le ineguagliabili capacità difensive di Intel. Con il suo potere tecnologico e una fortezza dell'innovazione, Intel si erge orgogliosa, pronta ad affrontare qualsiasi avversario digitale. Indossano le loro mantelle virtuali e proteggono i nostri dati dai cattivi informatici con stile e maestria. Non è sorprendente che Intel sia il nome che si sente in fatto di sicurezza informatica!\n\n[Leggi di più](https://www.forbes.com/sites/hnewman/2023/06/08/meet-americas-most-cybersecure-companies-2023/?sh=dd8bc202cf60)\n\nÈ stato svelato il piano di battaglia nazionale per la cybersecurity! Aiutiamo la pubblicazione del piano di implementazione per la Strategia Nazionale di Cybersecurity. È un manuale strategico per difenderci dalle minacce digitali, delineando i passi per proteggere i nostri reami virtuali. Uniamoci a sostegno di questo piano e rafforziamo le difese informatiche della nostra nazione. Avanti verso un futuro digitale più sicuro!\n\n[Leggi di più](https://www.helpnetsecurity.com/2023/07/13/national-cybersecurity-strategy-implementation-plan-published/)\n\nIl campo di battaglia della sicurezza informatica tra gli Stati Uniti e la Cina si sta intensificando a causa delle crescenti tensioni. The Hacker News riporta allarmanti compromissioni di email all'interno delle agenzie governative statunitensi, alimentando ulteriormente le preoccupazioni riguardo alla continua guerra cibernetica. Si tratta di uno scontro ad alto rischio tra titaniche entità digitali, sottolineando l'urgente necessità di difese robuste e cooperazione internazionale di fronte alle persistenti minacce informatiche.\n\n[Leggi di più](https://thehackernews.com/2023/07/us-government-agencies-emails.html)\n\n## Edge Computing\n\nInfineon e Edge Impulse si uniscono per liberare il potere dell'IA Edge! Edge Computing News afferma che questa partnership dinamica mira a espandere le capacità di IA di Infineon. È come un incontro perfetto nel paradiso tecnologico, combinando l'esperienza di Infineon con le soluzioni all'avanguardia di Edge Impulse. Preparati all'IA all'orlo, rivoluzionando il modo in cui elaboriamo i dati e sbloccando nuovi ambiti di innovazione!\n\n[Leggi di più](https://www.edgecomputing-news.com/2023/07/10/infineon-partners-with-edge-impulse-to-extend-its-edge-ai-capabilities/)\n\nTenetevi forte perché il mercato dell'edge computing è destinato a esplodere! Edge Computing News rivela che entro il 2028, quest'industria in piena espansione varrà una cifra incredibile di 111,3 miliardi di dollari. È come una vera e propria corsa all'oro dell'edge computing, con le aziende che si affrettano a capitalizzare sull'enorme potenziale del potere di elaborazione decentralizzata. Preparatevi a un cambiamento di paradigma mentre l'edge si fa protagonista nella rivoluzione digitale!\n\n[Leggi di più](https://www.edgecomputing-news.com/2023/07/10/edge-computing-market-to-be-worth-111-3-billion-by-2028/)\n\nSeoul Robotics sta espandendo la tecnologia dei trasporti con la sua avanzata tecnologia di percezione 3D. EdgeIR riporta su questa innovazione rivoluzionaria che porta una percezione di profondità migliorata ai sistemi di trasporto. Con l'utilizzo di questa tecnologia all'avanguardia di Seoul Robotics, ci possiamo aspettare viaggi più sicuri e intelligenti in futuro.\n\n[Leggi di più](https://www.edgeir.com/seoul-robotics-develops-3d-perception-tech-to-boost-transportation-systems-20230711)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW24-it","image":"./briefs/edw-24/it/thumbnail.png","lang":"it","summary":"Nelle notizie sulla trasformazione digitale della settimana del 17 luglio 2023, Papa Francesco offre orientamenti sull'etica dell'intelligenza artificiale, Intel rimane la fortezza cibernetica d'America, e il mercato del computing periferico è destinato a decollare!"},{"id":191,"type":"News Brief","title":"2023-7-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Intelligenza Artificiale\n\n\nMeta, il precursore dell'intelligenza artificiale, lascia a bocca aperta la comunità tecnologica con un lancio rivoluzionario: Llama 2, il più recente modello LLM open source. Sbloccando il potere della comprensione del linguaggio per tutti gli sviluppatori, questa innovazione straordinaria promette di rivoluzionare i progetti di intelligenza artificiale. Dite addio alla complessità e date il benvenuto all'addestramento fluido dell'intelligenza artificiale. Preparatevi a cavalcare l'onda dei modelli open source LLM e a testimoniare il futuro dell'intelligenza artificiale che si svela! [Leggi di più](https://www.artificialintelligence-news.com/2023/07/19/meta-launches-llama-2-open-source-llm/)\n\n\nIl Consiglio Tecnologico di Forbes lancia l'allarme mentre l'IA generativa si concentra sui dati personali. Il loro avvincente articolo approfondisce l'imminente invasione dei dati e le sue potenziali conseguenze. Preparati per la rivoluzionaria ascesa dei contenuti generati dall'IA, che presentano opportunità e sfide per la privacy dei dati. Rimanere informati e vigili mentre navighiamo nel nuovo mondo coraggioso della #GenerativeAI e proteggiamo il nostro futuro digitale. [Leggi di più](https://www.forbes.com/sites/forbestechcouncil/2023/07/20/generative-ai-is-coming-for-people-data-are-you-ready/?sh=3e6f95421573)\n\n\nSciopero di Hollywood finito per preoccupazioni lavorative legate all'IA. Il top film estivo \"Mission: Impossible - Dead Reckoning\" esplora il potenziale e i rischi dell'IA. Si tratta di una storia che mette in guardia o di uno sguardo nel nostro futuro? Attori e sceneggiatori temono che i loro lavori e le loro somiglianze possano essere sostituiti. Restate sintonizzati per gli aggiornamenti. [Leggi di più](https://www.wired.com/story/mission-impossible-dead-reckoning-is-the-perfect-ai-panic-movie/)\n\n## Ssicurezza informatica\n\n\nIl Guardian riporta un importante attacco informatico mentre hacker cinesi prendono di mira funzionari statunitensi, compreso l'ambasciatore a Pechino. La violazione solleva preoccupazioni sulla sicurezza informatica e sulle relazioni internazionali. Le autorità stanno investigando l'entità dell'attacco e le sue potenziali implicazioni. Rimani sintonizzato per gli aggiornamenti su questo sviluppo significativo e preoccupante. [Leggi di più](https://www.theguardian.com/us-news/2023/jul/20/ambassador-to-beijing-among-us-officials-hit-by-chinese-hackers)\n\n\nUltime notizie: si sviluppa un terrificante attacco informatico! Le infrastrutture critiche sono sotto assedio mentre gli hacker sfruttano una pericolosa vulnerabilità zero-day di Citrix. Il panico avvolge gli esperti di sicurezza informatica, che si affrettano a impedire le conseguenze catastrofiche dell'attacco. Prepararsi alle conseguenze e mantenere pronte le difese digitali! #CitrixZeroDay #EmergenzaCybersecurity [Leggi di più](https://www.securityweek.com/citrix-zero-day-exploited-against-critical-infrastructure-organization/)\n\n\nCyware porta notizie allarmanti su \"HotRAT\", uno script nascosto che si cela nei software craccati. I criminali informatici sfruttano questa tattica maliziosa per compromettere gli utenti ignari. Il paesaggio delle minacce si intensifica, invitando alla prudenza durante il download di programmi craccati. Proteggi il tuo rifugio digitale ed evita di cadere vittima di questo ingannevole stratagemma. Resta informato e stai al sicuro! #HotRAT #MinacciaInformatica [Leggi di più](https://cyware.com/news/hotrat-as-hidden-script-in-cracked-software-b2baa5b3)\n\n## Gestione dei dati\n\n\nTDWI scopre l'alba di una rivoluzione nella gestione dei dati con 'Arch-All Data Fabric'. In questo rapporto rivoluzionario, esperti svelano la strategia per la gestione dei dati di prossima generazione. Assista all'integrazione di diverse fonti di dati, che spingono le aziende verso altezze senza precedenti. Restate sintonizzati per approfondimenti sul futuro basato sui dati! #DataFabric #GestioneDatiDiProssimaGenerazione [Leggi di più](https://tdwi.org/articles/2023/07/20/arch-all-data-fabric-how-to-architect-next-generation-data-management.aspx)\n\n\nHammerspace raggiunge un traguardo rivoluzionario con 56,7 milioni di dollari nel primo finanziamento istituzionale. Questo risultato trasformativo sblocca opportunità commerciali nascoste nei dati non strutturati. Scopri il potere delle loro soluzioni innovative, che consentono una gestione senza soluzione di continuità dei dati non strutturati per le aziende. Preparati ad una nuova era di utilizzo e crescita dei dati! #Hammerspace #InnovazioneDeiDati #SuccessoDiFinanziamento [Leggi di più](https://hammerspace.com/hammerspace-raises-56-7m-in-first-institutional-funding-unlocks-business-opportunities-hidden-in-unstructured-data/)\n\n\nLa grande rivelazione di Lenovo: nuove soluzioni di gestione dei dati progettate per potenziare al massimo i carichi di lavoro di intelligenza artificiale! Datanami riporta le sue offerte all'avanguardia, che danno potere alle aziende con un potenziale guidato dall'IA. Immergiti nelle ultime innovazioni che promettono di rivoluzionare la gestione dei dati per i progetti di intelligenza artificiale. Abbraccia una nuova era di efficienza e intelligenza nel panorama tecnologico! #Lenovo #GestioneDati #CarichiDilavoroIA [Leggi di più](https://www.datanami.com/this-just-in/lenovo-unveils-new-data-management-solutions-to-enable-ai-workloads/)\n\n## Abbracciare il podcast digita\n\nIn questo episodio, Darren riprende un'intervista che ha condotto con chatGPT e segue con un'intervista simile che coinvolge Google Bard. Il confronto suscita curiosità, soprattutto se accompagnato alle intuizioni dell'Episodio 122 sull'Abbracciare la Trasformazione Digitale. [Episode 147](https://www.embracingdigital.org/episode-EDT147) [Episode 122](https://www.embracingdigital.org/episode-EDT122)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW25-it","image":"./briefs/edw-25/it/thumbnail.png","lang":"it","summary":"Questa settimana, il 24 luglio 2023, nelle notizie sulla trasformazione digitale, si sono registrati sviluppi nella Generative AI sul luogo di lavoro, oltre a un attacco informatico cinese all'Ambasciata degli Stati Uniti. Inoltre, i Data Fabrics stanno iniziando a emergere come una tendenza."},{"id":192,"type":"News Brief","title":"2023-7-30","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n\n## Comunicazioni avanzate\n\n\nIntel ed Ericsson si stanno unendo per creare una migliore connettività internet ed esperienze di utilizzo dei dispositivi. La loro collaborazione mira a soddisfare la crescente domanda di internet ad alta velocità e connessioni affidabili, promettendo interessanti sviluppi tecnologici. Con la loro competenza combinata, gli utenti possono aspettarsi download più veloci, chiamate video più fluide e un miglioramento generale delle prestazioni per telefoni, computer e altri gadget. Preparatevi a un futuro più collegato e senza interruzioni! [Leggi di più](http://finance.yahoo.com/news/intel-ericsson-expand-collaboration-advance-201000466.html)\n\n\nPreparati per l'esplosione del 5G! Secondo un nuovo studio, il mercato globale dell'integrazione di sistemi 5G raggiungerà la cifra astronimica di 115,60 miliardi di dollari entro il 2032. Le aziende stanno gareggiando per adottare questa tecnologia internet super veloce per le smart cities, il settore sanitario e altro ancora. Anche i produttori stanno aggiornandosi con tecnologie innovative come robot e big data. La domanda di servizi di integrazione 5G è in netto aumento, promettendo tempi entusiasmanti per il futuro! [Leggi di più](https://finance.yahoo.com/news/global-5g-system-integration-market-100000051.html)\n\n\nNotizie entusiasmanti da T-Mobile! La loro rivoluzionaria tecnologia 5G promette internet super veloce, velocità di 3,3 GBits/Sec e connettività senza soluzione di continuità. Con questa innovazione, il download e lo streaming saranno velocissimi e le videochiamate e il gioco online saranno più fluidi. Preparati per una nuova era di connettività e uniche esperienze di internet! [Leggi di più](https://voip.review/2023/07/26/tmobile-introduces-groundbreaking-5g-tech/)\n\n## Sicurezza informatica\n\n\nGPT e Cybersecurity: Il futuro è entusiasmante e preoccupante! Gli esperti stanno discutendo su GPT, un potente sistema di intelligenza artificiale destinato a rivoluzionare la cybersecurity. La presentazione di Una-May O'Reilly ha fatto luce sull'impatto di GPT sulla sicurezza, dimostrando che renderà le difese più innovative ed efficienti. Ma c'è un'insidia: anche i pirati informatici possono utilizzarlo! L'IA potrebbe potenziare entrambi i fronti in una corsa agli armamenti cibernetici, lasciandoci nell'incertezza. Prepariamoci per il futuro emozionante e preoccupante della cybersecurity! [Leggi di più](https://www.forbes.com/sites/johnwerner/2023/07/28/whos-the-authority-on-gpt-and-cybersecurity-is-it--gpt/)\n\n\nNuove norme della Securities and Exchange Commission (SEC) richiedono alle aziende pubbliche di divulgare qualsiasi violazione della sicurezza informatica che potrebbe influire sui loro profitti entro quattro giorni. Questa mossa mira a proteggere gli investitori e ad aumentare la trasparenza sui rischi della sicurezza informatica. Sono previsti ritardi nei casi di rischi per la sicurezza nazionale. La regola richiede inoltre alle aziende di condividere informazioni sulla gestione e l'esperienza nella sicurezza informatica. [Leggi di più](https://apnews.com/article/sec-cybersecurity-breach-disclosure-risk-hacking-bb6252463637793bfdc8ace5bfcbe7df)\n\n\nNelle ultime notizie, le agenzie di sicurezza informatica in Australia e negli Stati Uniti hanno avvertito di una grave debolezza nelle applicazioni web. I cybercriminali possono sfruttare la vulnerabilità dell'oggetto diretto non sicuro per ottenere accesso non autorizzato a informazioni confidenziali. Rimanete all'erta e proteggete i vostri dati con protocolli di autenticazione e autorizzazione robusti. [Leggi di più](https://thehackernews.com/2023/07/cybersecurity-agencies-warn-against.html)\n\n## Computazione Ubiqua\n\n\nL'IA è stata sempre più utilizzata nella programmazione per migliorare l'efficienza e ridurre le spese. Tuttavia, la dipendenza dal codice precedente può portare a errori e ostacolare la creatività nello sviluppo delle applicazioni. Il codice generato da AI potrebbe non essere ottimizzato per la piattaforma, quindi è essenziale bilanciare i benefici dell'IA con l'esperienza umana per applicazioni efficienti. [Leggi di più](https://www.infoworld.com/article/3703611/the-lost-art-of-cloud-application-engineering.html)\n\n\nMicrosoft guida nel carico di lavoro basato su cloud AI, afferma Nadella! Microsoft sta prendendo il comando nei carichi di lavoro basati su cloud AI, secondo il suo CEO, Satya Nadella. La maestria del gigante tecnologico nelle attività guidate dall'IA sta facendo scalpore nell'industria. Sfruttando il potere del cloud, Microsoft offre soluzioni di AI all'avanguardia alle imprese e agli utenti. Con il loro approccio innovativo, stanno plasmando il futuro della tecnologia AI. [Leggi di più](https://www.cnbc.com/2023/07/25/microsoft-is-in-the-lead-with-cloud-based-ai-workloads-nadella-says.html)\n\n\nAlibaba si è associata all'AI di Meta's Llama per sviluppare software innovativi. Questa collaborazione tra Alibaba Cloud, una divisione del gigante cinese, e il modello di IA di Llama 2 sta stabilendo nuove tendenze nell'industria tecnologica. Questo partenariato farà della Cina un pioniere nella programmazione a costo zero, portando entusiasmanti innovazioni alimentate da AI sul mercato. Preparati a testimoniare il futuro dello sviluppo software! [Leggi di più](https://fagenwasanni.com/news/alibabas-cloud-computing-service-utilizes-metas-ai-model-llama-for-software-development/82096/)\n\n## Podcast Abbracciando la Trasformazione Digitale\n\nAscolta l'episodio di questa settimana in cui Darren intrattiene una conversazione illuminante con l'ospite speciale Jared Shepard, CEO di Hypori. L'intervista si concentra sul tema cruciale della sicurezza dei lavoratori in remoto attraverso la virtualizzazione mobile. Il percorso unico di Jared Shepard, da drop-out delle scuole superiori a CEO, aggiunge un aspetto inspirante alla discussione.\n\n[Episode 148](https://www.embracingdigital.org/episode-EDT148)\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW26-it","image":"./briefs/edw-26/it/thumbnail.png","lang":"it","summary":"Ecco gli ultimi aggiornamenti nel campo della Trasformazione Digitale per la settimana del 31 luglio 2023. Questo include notizie sulla partnership tra Ericsson e Intel nel promuovere la tecnologia 5G, gli sforzi di ChatGPT nel contrastare la cybersecurity e la comparsa dello sviluppo di software basato sull'Intelligenza Artificiale."},{"id":193,"type":"News Brief","title":"2023-8-6","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n\n## Intelligenza Artificiale\n\n\nC'è una crescente preoccupazione tra gli esperti tecnologici riguardo all'uso di immagini potenziate dall'intelligenza artificiale. The Guardian ha investigato questa problematica, in quanto vi è preoccupazione che le immagini modificate dall'IA possano influenzare l'opinione pubblica e addirittura distorcere fatti importanti essenziali per il sistema democratico. Questo potrebbe seriamente compromettere la fiducia e la verità, e portare a un dibattito su come proteggere le elezioni dalla manipolazione dell'IA. [Leggi di più](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\n)\n\n\nUn recente articolo di Yahoo Finance riportava che Wendy's sta utilizzando l'IA per rivoluzionare i loro drive-thru. Con l'ordinazione automatizzata e menu personalizzati, il gigante del fast food sta cambiando le regole per i pasti veloci. Questo approccio tecnologico al servizio alimentare ci offre uno sguardo nel futuro del pranzo fast-food. Sarà interessante vedere come i clienti reagiranno a questa trasformazione digitale. [Leggi di più](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\n)\n\n\nL'impatto dell'IA sui professionisti asiatico-americani è una tendenza preoccupante. Le perdite di posti di lavoro sono imminenti, sollevando domande su come la società affronterà l'equazione complessa di tecnologia, etnia e dinamiche del lavoro. È necessario un esame più approfondito degli effetti dell'IA. [Leggi di più](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\n)\n\n## Sicurezza informatica\n\n\nNBC News ha riportato un preoccupante attacco informatico a una rete ospedaliera che ha portato alla disconnessione dell'infrastruttura informatica nazionale. La violazione ha messo a rischio l'assistenza ai pazienti e le autorità stanno lavorando per contenere la situazione. Questo incidente sottolinea l'importanza della sicurezza dei dati sanitari nell'era digitale. [Leggi di più](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\n)\n\n\nGli sviluppatori che utilizzano il sistema NPM molto diffuso sono presi di mira da pacchetti di codice dannosi che possono compromettere la sicurezza del software. Si tratta di una minaccia grave che deve essere identificata e mitigata per prevenire attacchi informatici. La comunità della sicurezza informatica è preoccupata e sottolinea la necessità di catene di distribuzione software più sicure per prevenire ulteriori infiltrazioni di questi pacchetti. [Leggi di più](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\n)\n\n\nCISA ha pubblicato un piano strategico chiamato \"Blueprint for Cybersecurity\" per rafforzare l'infrastruttura digitale nazionale. Si concentra sulla difesa adattativa, sulla risposta agli incidenti e sull'innovazione per creare uno scudo digitale impenetrabile. Questo piano è una guida essenziale per coloro interessati alla sicurezza tecnologica. [Leggi di più](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\n)\n\n## Edge Computing \n\nCalcolo periferico\n\n\nLa combinazione di calcolo quantistico e dispositivi IoT sta causando preoccupazioni sulla sicurezza. La potenza della tecnologia quantistica e il potenziale di dirottamento dei dispositivi IoT creano una nuova sfida. La paura di crittografia che viene violata è in aumento con l'avanzamento del calcolo quantistico e i botnet lanciano attacchi DDoS utilizzando dispositivi IoT hackerati. Le difese di rete devono essere rafforzate per far fronte a questa doppia minaccia. [Leggi di più](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\n)\n\n\nYahoo Finance ha svelato un eccitante sviluppo nell'industria tecnologica, poiché Edge Computing, IoT e AI si uniscono per creare un mercato previsto di un valore di 230 miliardi di dollari entro il 2025. Edge Computing permette a oltre 75 miliardi di dispositivi IoT di elaborare dati in tempo reale, mentre le abilità cognitive dell'AI sono stimate per aumentare la produttività fino al 40%. Questa rivoluzione sta per ridefinire la dinamica dei dati e la presa di decisioni in vari settori industriali. [Leggi di più](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\n)\n\n\nLa regione Asia-Pacifico sta attraversando una significativa trasformazione digitale guidata dall'Internet delle Cose (IoT) e dall'Intelligenza Artificiale (AI). Il Mobile Edge Computing (MEC) sta guidando questo cambiamento, offrendo livelli di connettività e automazione senza precedenti avvicinando il calcolo alla fonte dei dati. Il MEC ha un enorme potenziale per rivoluzionare industrie, migliorare vite e guidare il destino digitale della regione, ma pone anche sfide di sicurezza che richiedono robuste salvaguardie e regolamentazioni aggiornate. [Leggi di più](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\n)\n\n## Podcast sulla trasformazione digitale.\n\n\nNell'ultima puntata di Abbracciare la Trasformazione Digitale, Darren è accompagnato da Leland Brown, un ingegnere principale presso Capgemini e un ex ospite dello spettacolo. Discutono sugli imminenti sviluppi della tecnologia 5G e il suo impatto sulla Mobile Edge Computing (MEC) nel Dipartimento della Difesa degli Stati Uniti. [Leggi di più](https://embracingdigital.org/episode-EDT149\n)\n\nIntelligenza Artificiale\n\n\nC'è una crescente preoccupazione tra gli esperti tecnologici sull'uso delle immagini potenziate dall'IA. The Guardian ha investigato questa problematica, poiché c'è la preoccupazione che le immagini alterate dall'IA possano influenzare l'opinione pubblica e persino distorcere fatti importanti essenziali per il sistema democratico. Ciò potrebbe seriamente influire sulla fiducia e sulla verità e portare a un dibattito su come proteggere le elezioni dalla manipolazione dell'IA. [Leggi di più](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\r)\n\n\nUn recente articolo di Yahoo Finance ha riportato che Wendy's, un ristorante di fast food americano, sta utilizzando l'intelligenza artificiale per rivoluzionare i loro Drive-thru. Con ordini automatizzati e menu personalizzati, il gigante del fast food sta cambiando il modo di mangiare veloce. Questo approccio tecnologico al servizio di cibo offre uno sguardo al futuro del fast food. Sarà interessante vedere come i clienti reagiranno a questa trasformazione digitale. [Leggi di più](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\r)\n\n\nL'impatto dell'IA sui professionisti di origine asiatico-americana è una tendenza preoccupante. Le perdite di lavoro si profilano all'orizzonte, sollevando domande su come la società affronterà l'equazione complessa di tecnologia, etnia e dinamiche della forza lavoro. È necessario un esame più approfondito degli effetti dell'IA. [Leggi di più](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\r)\n\n## Sicurezza informatica\n\n\nNBC News ha riportato un preoccupante attacco informatico su una rete ospedaliera che ha portato alla disconnessione delle infrastrutture informatiche nazionali. La violazione ha messo a rischio l'assistenza ai pazienti e le autorità stanno lavorando per contenere la situazione. Questo episodio sottolinea l'importanza della sicurezza dei dati sanitari nell'era digitale. [Leggi di più](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\r)\n\n\nGli sviluppatori che utilizzano il sistema NPM (Node Package Manager) molto diffuso sono presi di mira da pacchetti di codice dannosi che possono compromettere la sicurezza del software. Questa è una minaccia grave che deve essere identificata e mitigata per prevenire gli attacchi informatici. La comunità della cybersecurity è preoccupata e sottolinea la necessità di catene di approvvigionamento software più sicure per prevenire ulteriori infiltrazioni di questi pacchetti. [Leggi di più](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\r)\n\n\nCISA ha rilasciato un piano strategico chiamato \"Blueprint for Cybersecurity\" per rafforzare l'infrastruttura digitale nazionale. Si focalizza sulla difesa adattiva, la risposta agli incidenti e l'innovazione per creare uno scudo digitale impenetrabile. Questo piano è una guida essenziale per coloro interessati alla sicurezza tecnologica. [Leggi di più](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\r)\n\nEdge Computing\nCalcolo perimetrale\n\n\nLa combinazione tra il calcolo quantistico e i dispositivi IoT sta generando preoccupazioni per la sicurezza. Il potere della tecnologia quantistica e il potenziale degli dispositivi IoT per il dirottamento creano una nuova sfida. La crisi dell'encryption rappresenta una paura crescente man mano che il calcolo quantistico progredisce e i botnet lanciano attacchi DDoS utilizzando dispositivi IoT hackerati. Le difese di rete devono essere rafforzate per far fronte a questa doppia minaccia. [Leggi di più](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\r)\n\n\nYahoo Finance ha rivelato un'entusiasmante sviluppo nell'industria tecnologica in cui Edge Computing, IoT e AI si fondono per creare un mercato stimato essere di valore 230 miliardi di dollari entro il 2025. Edge Computing consente a oltre 75 miliardi di dispositivi IoT di elaborare dati in tempo reale, mentre le capacità cognitive dell'AI sono stimate per aumentare la produttività fino al 40%. Questa rivoluzione è destinata a ridefinire la dinamica dei dati e la presa di decisioni in diverse industrie. [Leggi di più](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\r)\n\n\nLa regione Asia-Pacifico sta attraversando una significativa trasformazione digitale guidata dall'Internet delle cose (IoT) e dall'Intelligenza Artificiale (AI). Il Mobile Edge Computing (MEC) sta guidando questo cambiamento, offrendo livelli senza precedenti di connettività e automazione avvicinando il calcolo alla fonte dei dati. Il MEC ha un enorme potenziale per rivoluzionare le industrie, migliorare la vita e guidare il destino digitale della regione, ma pone anche sfide di sicurezza che richiedono robuste protezioni e regolamenti aggiornati. [Leggi di più](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\r)\n\nPodcast sulla trasformazione digitale: Abbracciando la Trasformazione Digitale\n\n\nNell'ultima puntata di Abbracciando la Trasformazione Digitale, Darren è accompagnato da Leland Brown, un ingegnere principale presso Capgemini e un precedente ospite dello spettacolo. Discutono dei prossimi sviluppi della tecnologia 5G e del suo impatto sulla Mobile Edge Computing (MEC) nel Dipartimento della Difesa degli Stati Uniti. [Leggi di più](https://embracingdigital.org/episode-EDT149\r)\n\nIntelligenza Artificiale\n\n\nC'è una crescente preoccupazione tra gli esperti tecnologici sull'uso di immagini potenziate dall'IA. The Guardian ha indagato su questa questione, poiché c'è il timore che le immagini alterate dall'IA possano influenzare l'opinione pubblica e addirittura distorto importanti fatti essenziali per il sistema democratico. Ciò potrebbe seriamente influenzare la fiducia e la verità e portare a un dibattito su come proteggere le elezioni dalla manipolazione dell'IA. [Leggi di più](https://www.theguardian.com/technology/2023/aug/03/ai-enhanced-images-a-threat-to-democratic-processes-experts-warn\r)\n\n\nUn recente articolo di Yahoo Finance ha riportato che Wendy's, un ristorante di fast food americano, sta utilizzando l'intelligenza artificiale per rivoluzionare i loro drive-thru. Con l'ordine automatizzato e i menu personalizzati, questo gigante del fast food sta cambiando il modo di fare pasti rapidi. Questo approccio tecnologico al servizio alimentare fornisce un'anteprima del futuro del pranzo veloce. Sarà interessante vedere come i clienti reagiranno a questa trasformazione digitale. [Leggi di più](https://finance.yahoo.com/news/wendys-latest-fast-food-company-210910771.html\r)\n\n\nL'impatto dell'intelligenza artificiale sui professionisti asiatico-americani è una tendenza preoccupante. Si prospettano notevoli perdite di lavoro, che sollevano domande su come la società affronterà l'equazione complessa di tecnologia, etnia e dinamiche della forza lavoro. È necessario un esame più approfondito degli effetti dell'IA. [Leggi di più](https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179\r)\n\n## Sicurezza informatica\n\n\nNBC News ha segnalato un preoccupante attacco informatico a una rete ospedaliera che ha causato la disconnessione della sua infrastruttura informatica nazionale. L'incidente mette a rischio l'assistenza ai pazienti e le autorità stanno lavorando per contenere la situazione. Questo episodio evidenzia l'importanza della sicurezza dei dati sanitari nell'era digitale. [Leggi di più](https://www.nbcnews.com/tech/security/hackers-force-hospital-system-take-national-computer-system-offline-rcna98212\r)\n\n\nGli sviluppatori che utilizzano il sistema NPM ampiamente diffuso sono presi di mira da pacchetti di codice dannosi che possono compromettere la sicurezza del software. Questa è una minaccia grave che deve essere identificata e mitigata per prevenire attacchi informatici. La comunità della cybersecurity è preoccupata e sottolinea la necessità di catene di fornitura software più sicure per prevenire ulteriori infiltrazioni di questi pacchetti. [Leggi di più](https://thehackernews.com/2023/08/malicious-npm-packages-found.html\r)\n\n\nCISA ha pubblicato un piano strategico chiamato \"Piano per la sicurezza informatica\" per rafforzare l'infrastruttura digitale nazionale. Si focalizza sulla difesa adattiva, sulla risposta agli incidenti e sull'innovazione per creare uno scudo digitale impenetrabile. Questo piano è una guida essenziale per coloro interessati alla sicurezza tecnologica. [Leggi di più](https://www.securitysystemsnews.com/article/cisa-releases-cybersecurity-strategic-plan\r)\n\n## Edge Computing\nElaborazione dei bordi\n\n\nLa combinazione di calcolo quantistico e dispositivi IoT sta creando preoccupazioni sulla sicurezza. La potenza della tecnologia quantistica e il potenziale di hackeraggio dei dispositivi IoT creano una nuova sfida. La paura che la crittografia venga infranta è in crescita man mano che avanzano i calcoli quantistici e le reti di bot lanciano attacchi DDoS utilizzando i dispositivi IoT hackerati. Le difese di rete devono essere rafforzate per affrontare questa doppia minaccia. [Leggi di più](https://www.securitymagazine.com/articles/99604-the-impact-of-quantum-computers-and-iot-devices-on-network-security\r)\n\n\nYahoo Finanza ha rivelato un entusiasmante sviluppo nell'industria tecnologica, poiché Edge Computing, IoT e AI si fondono per creare un mercato previsto che varrà duecentotrentamiliardi di dollari entro il 2025. Edge Computing consente a oltre settantacinque miliardi di dispositivi IoT di elaborare dati in tempo reale, mentre le capacità cognitive dell'AI si stima che aumenteranno la produttività fino al 40%. Questa rivoluzione è destinata a ridefinire la dinamica dei dati e il processo decisionale in vari settori. [Leggi di più](https://finance.yahoo.com/news/edge-computing-iot-ai-revolutionize-011500739.html\r)\n\n\nLa regione Asia-Pacifico sta attraversando una significativa trasformazione digitale guidata dall'Internet delle Cose (IoT) e dall'Intelligenza Artificiale (IA). Il Mobile Edge Computing (MEC) sta guidando questo cambiamento, offrendo livelli di connettività e automazione senza precedenti avvicinando i calcoli alla fonte dei dati. Il MEC ha un immenso potenziale per rivoluzionare le industrie, migliorare la vita delle persone e guidare il destino digitale della regione, ma presenta anche sfide di sicurezza che richiedono robuste protezioni e normative aggiornate. [Leggi di più](https://fagenwasanni.com/news/innovations-in-iot-and-ai-the-role-of-mobile-edge-computing-in-asia-pacifics-technological-advancements/48663/\r)\n\n## Podcast sull'Abbraccio alla Trasformazione Digitale\n\n\nNell'ultimo episodio di Abbracciare la Trasformazione Digitale, Darren è accompagnato da Leland Brown, un ingegnere principale presso Capgemini e un ex ospite dello show. Discutono dei prossimi sviluppi della tecnologia 5G e del suo impatto sul Mobile Edge Computing (MEC) nel Dipartimento della Difesa degli Stati Uniti. [Leggi di più](https://embracingdigital.org/episode-EDT149\r)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW27-it","image":"./briefs/edw-27/it/thumbnail.png","lang":"it","summary":"La settimana del podcast del 7 agosto 2023, ci sono state diverse novità significative riguardo alla trasformazione digitale. In particolare, le catene di fast food hanno iniziato a implementare l'intelligenza artificiale per affrontare la carenza di personale, gli ospedali stanno affrontando attacchi informatici e stanno emergendo le piattaforme di Mobile Edge Computing."},{"id":194,"type":"News Brief","title":"2023-8-13","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Calcolo Ubiquitario\n\n\nA causa di una recente violazione in Microsoft Azure Cloud, il Dipartimento della Sicurezza Interna sta esaminando i sistemi di identità e autenticazione basati su cloud per prevenire attacchi malevoli alle ambientazioni di cloud computing, in seguito alle recenti violazioni di sicurezza. L'obiettivo è fornire raccomandazioni per migliorare la sicurezza degli account e prevenire future violazioni. [Leggi di più](https://www.reuters.com/technology/us-cyber-safety-review-board-assess-online-intrusion-microsoft-exchange-dhs-2023-08-11/)\n\n\nIl potenziale dei calcolatori quantistici di rivoluzionare molteplici settori, in particolare l'intelligenza artificiale, aumentando la velocità di elaborazione, è entusiasmante. Tuttavia, a causa della natura delicata dei qubit, la creazione di calcolatori quantistici è un compito difficoltoso. Nonostante ciò, i professionisti del settore rimangono fiduciosi sul potenziale dei calcolatori quantistici nel portare importanti progressi in vari settori. [Leggi di più](https://www.scmp.com/magazines/post-magazine/long-reads/article/3230746/quantum-computing-could-give-ai-rocket-fuel-it-needs-become-transformative-its-not-there-yet)\n\n\nil presidente Biden ha firmato un ordine esecutivo questa settimana che vieta gli investimenti statunitensi nei settori cinesi dell'intelligenza artificiale, dei semiconduttori e del calcolo quantistico al fine di evitare un appoggio involontario all'avanzamento militare e tecnologico della Cina. L'industria dei semiconduttori, in particolare lo sviluppo e la produzione di chip, è l'obiettivo principale. La Cina ha espresso il suo malcontento verso l'ordine, sostenendo che disturbi i legami economici. L'ordine si applica agli investimenti futuri e potrebbe avere alcune eccezioni. [Leggi di più](https://www.tomshardware.com/news/us-order-bans-future-investments-in-chinese-ai-semiconductor-and-quantum-computing)\n\n## Gestione dei dati\n\n\nLa Cina sta proponendo nuove regole per limitare la tecnologia di riconoscimento facciale e proteggere la privacy degli utenti. Le bozze delle regole dell'Amministrazione del Cyberspazio della Cina affermano che il riconoscimento facciale dovrebbe essere utilizzato solo quando necessario e che bisognerebbe esplorare soluzioni non biometriche per raggiungere gli stessi obiettivi con minor intrusione. Questa decisione segue le preoccupazioni in Cina riguardo all'eventuale abuso delle informazioni personali tramite la tecnologia di riconoscimento facciale. [Leggi di più](https://fagenwasanni.com/news/china-introduces-new-draft-rules-to-regulate-facial-recognition-technology-and-data-management/174996/)\n\n\nNella transizione dai server interni alla tecnologia cloud e ai data center per la gestione dei dati, il cloud offre scalabilità e flessibilità eliminando al contempo la necessità di vicinanza ai server. Tuttavia, molte organizzazioni rimangono sorprese dai costi associati alla gestione dei dati tra i data center e i cloud, in quanto i fornitori di servizi cloud addebitano per il trasferimento dei dati tra le diverse modalità. Sviluppare una strategia di gestione dei dati e un'architettura dati ibrida sta diventando fondamentale per le organizzazioni al fine di risparmiare costi, migliorare la resilienza e supportare le attività aziendali in questi complessi ambienti operativi. [Leggi di più](https://devops.com/data-management-cloud-technology-or-data-centers/)\n\n\nI governi di tutto il mondo stanno assumendo un ruolo più attivo nella regolamentazione della privacy dei dati. Lo stato dell'Oregon ha adottato un approccio completo, garantendo ai consumatori un maggiore controllo sui loro dati personali. Le aziende devono ora ottenere un consenso esplicito per la raccolta e condivisione di dati, e gli individui hanno il diritto di accedere, correggere ed eliminare i loro dati. La legge include anche obblighi di trasparenza e salvaguardie contro la discriminazione basata sull'uso dei dati. Questa è un'altra mossa per ottenere denaro da parte del governo o una vera protezione della privacy individuale. Sarà il tempo a dirlo. [Leggi di più](https://www.reuters.com/legal/legalindustry/oregon-passes-comprehensive-privacy-law-2023-08-11/)\n\n## Sicurezza informatica\n\n\nL'Istituto Nazionale di Standard e Tecnologia (NIST) sta compiendo passi significativi nel potenziamento delle pratiche di sicurezza informatica, fornendo nuove linee guida e risorse. Oltre ai pilastri precedenti del quadro di sicurezza, identificare, proteggere, rilevare, rispondere e recuperare, NIST ha introdotto un nuovo pilastro chiamato \"governare\". Questa nuova aggiunta sottolinea che la sicurezza informatica rappresenta una significativa fonte di rischio per le imprese e aiuta le organizzazioni a progettare ed eseguire decisioni per sostenere la loro strategia di sicurezza. [Leggi di più](https://www.infosecurity-magazine.com/news/nist-expands-cybersecurity/)\n\n\nLa conferenza sulla sicurezza informatica Black Hat a Las Vegas ha presentato strumenti avanzati per la rilevazione delle minacce, la risposta agli incidenti e la comunicazione sicura. Questi strumenti mirano a potenziare le difese informatiche delle organizzazioni contro le minacce e le sfide emergenti. Come previsto, l'AI Generativa è stata un argomento centrale, evidenziandone il potenziale nel contrastare gli attacchi informatici. [Leggi di più](https://www.crn.com/news/security/20-hottest-new-cybersecurity-tools-at-black-hat-2023)\n\n\nLa Sfida del Decrittatore della NSA aiuta ad affrontare la carenza di competenze nel settore della sicurezza informatica sfidando gli studenti a risolvere problemi complessi e promuovendo la collaborazione. Inoltre, incoraggia lo sviluppo di nuovi materiali educativi e programmi, offrendo alla prossima generazione di professionisti un'esperienza pratica per rafforzare la difesa del settore contro le minacce in continua evoluzione. Il programma sottolinea l'importanza della promozione dell'educazione in materia di sicurezza informatica e della fornitura di opportunità di apprendimento pratiche. [Leggi di più](https://www.darkreading.com/attacks-breaches/nsa-talks-codebreaker-challenge-success-influence-on-education)\n\n## Podcast sull'Abbraccio alla Trasformazione Digitale\n\nDarren intervista Sonu Panda, il CEO di Prescriptive Data, in questa puntata. Discutono di come il loro software aiuti i proprietari commerciali di immobili a trasformare i loro edifici in spazi intelligenti ed efficienti. [Leggi di più](https://embracingdigital.org/episode-EDT150)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW28-it","image":"./briefs/edw-28/it/thumbnail.png","lang":"it","summary":"Traduzione in italiano: Notizie sulla Trasformazione Digitale per il 13 agosto 2023. Gli ultimi sviluppi in termini di privacy dei dati, sicurezza e progressi tecnologici, inclusi il calcolo quantistico e nuove leggi sulla privacy, valgono la pena di essere seguiti. Le linee guida del NIST e gli strumenti di Black Hat sono risorse utili. La sfida Codebreaker della NSA stimola l'innovazione nella cybersecurity."},{"id":195,"type":"News Brief","title":"2023-8-19","tags":["ai","edge","cybersecurity"],"body":"\n\n## Intelligenza Artificiale\n\n\nIn una recente sentenza, un tribunale di Washington D.C. ha stabilito che l'arte generata da intelligenza artificiale non è eleggibile per la protezione del copyright. La decisione stabilisce un precedente significativo, suggerendo che le opere creative prodotte esclusivamente da intelligenza artificiale mancano dei diritti legali tipicamente garantiti alle creazioni umane. Questo verdetto potrebbe avere implicazioni di vasta portata per il futuro della proprietà intellettuale nell'era digitale. [Leggi di più](https://news.bloomberglaw.com/ip-law/ai-generated-art-lacks-copyright-protection-d-c-court-rules)\n\n\nI ricercatori del MIT hanno scoperto che i modelli di apprendimento automatico utilizzati per la diagnosi e il trattamento medico possono aggravare le disuguaglianze nel campo sanitario. Questi modelli, quando addestrati su dati di parte, possono portare a un accesso e a una qualità di cura inequamente distribuiti per i gruppi sottorappresentati. Ciò sottolinea l'urgente necessità di migliorare la raccolta dei dati e lo sviluppo dei modelli per garantire esiti sanitari equi e giusti. [Leggi di più](https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817)\n\n\nLa domanda esplosiva di intelligenza artificiale (AI) sta causando una carenza di chip ad alta potenza, secondo Fox Business. Con l'espansione delle applicazioni AI in diversi settori, c'è una crescente necessità di chip specializzati per alimentarle. Questa scarsità sta influenzando vari settori, tra cui l'automotive, la sanità e l'elettronica di consumo, potenzialmente rallentando l'innovazione. Le aziende stanno ora correndo per aumentare la produzione di chip al fine di soddisfare la crescente domanda. [Leggi di più](https://www.foxbusiness.com/technology/surging-demand-ai-creating-shortage-high-powered-chips)\n\n## Sicurezza informatica\n\n\nUn'applicazione focalizzata sugli studenti sta suscitando preoccupazione tra i genitori e gli esperti di cibersicurezza. I potenziali rischi dell'app per la sicurezza dei bambini sono sotto scrutinio, spingendo gli esperti a sottolineare l'importanza della vigilanza parentale e dell'educazione dei giovani utenti sulla sicurezza online. La situazione mette in evidenza la continua necessità di un uso responsabile della tecnologia e di misure proattive per proteggere i bambini nell'era digitale. [Leggi di più](https://www.live5news.com/2023/08/18/student-geared-app-concerning-lowcountry-parents-cyber-security-experts/)\n\n\nL'industria fintech viene grandemente influenzata dall'Intelligenza Artificiale (IA) e dalla cibersicurezza, secondo Analytics Insight. L'IA sta aiutando nella rilevazione delle frodi, nel servizio clienti e nella valutazione dei rischi, ma porta anche nuovi rischi di sicurezza. Questo interplay continuo tra IA e cibersicurezza sta cambiando il mondo fintech e sta portando a maggiori innovazioni e a misure di sicurezza aumentate per proteggere importanti informazioni finanziarie. [Leggi di più](https://www.analyticsinsight.net/how-ai-and-cybersecurity-shape-fintech-industry/)\n\n\nUn recente rapporto di Pew Research rivela che gli americani hanno una conoscenza limitata riguardo all'intelligenza artificiale, la cybersecurity e le grandi aziende tecnologiche. Le rilevazioni indicano che una parte significativa della popolazione manca di comprensione riguardo a questi temi critici, sottolineando la necessità di incrementare gli sforzi di educazione e consapevolezza pubblica in un'epoca dominata dalla tecnologia e dalle preoccupazioni digitali. [Leggi di più](https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/)\n\n## Edge Computing\n\nT-Mobile sta collaborando con Google Cloud per il calcolo sul bordo, come riportato da FierceWireless. Questa collaborazione mira a sfruttare l'infrastruttura cloud di Google per potenziare le capacità della rete 5G di T-Mobile e offrire servizi a bassa latenza, a vantaggio dei consumatori e delle aziende. Questa mossa strategica dimostra l'importanza crescente del calcolo sul bordo nell'industria delle telecomunicazioni. [Leggi di più](https://www.fiercewireless.com/tech/t-mobile-hooks-google-cloud-edge-compute)\n\nLa progressiva eliminazione delle reti 2G e 3G potrebbe comportare ripercussioni per i servizi IoT e di roaming. Molti dispositivi IoT e i viaggiatori internazionali si affidano ancora a queste reti più datate. I fornitori di telecomunicazioni devono prendere in considerazione opzioni di connettività alternative e strategie per prevenire interruzioni nel servizio per questi gruppi di utenti durante la transizione verso tecnologie di rete più avanzate. È importante affrontare questi problemi per evitare di accumulare debiti tecnici in futuro. [Leggi di più](https://www.lightreading.com/broadband/sunsetting-2g-and-3g-could-leave-iot-and-roamers-in-dark/d/d-id/786146)\n\n\nAl ET Digital Telco Summit, il CTO di Airtel ha sottolineato che la convergenza del 5G con le tecnologie cloud e IoT è pronta per sbloccare casi d'uso innovativi in diverse industrie. Ci si aspetta che questa combinazione guidi soluzioni trasformative per settori verticali, mostrando il potenziale del 5G nel rivoluzionare la connettività e i servizi in India e oltre. [Leggi di più](https://telecom.economictimes.indiatimes.com/news/industry/etdigitaltelcosummit-combination-of-5g-with-cloud-iot-to-drive-new-use-cases-for-verticals-airtel-cto/102827792)\n\n## Abbracciando il podcast sulla trasformazione digitale\n\n\nQuesta settimana Darren avvia una serie su intelligenza artificiale generativa con interviste da esperti in educazione, salute, sicurezza informatica e tecnologie cloud e su come l'intelligenza artificiale generativa sta giocando un ruolo nel futuro. Le storie di questa settimana includono interviste al dottor Jeffrey Lancaster che parla dell'importanza di comprendere l'intelligenza artificiale generativa. [Leggi di più](https://embracingdigital.org/episode-EDT151)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW29-it","image":"./briefs/edw-29/it/thumbnail.png","lang":"it","summary":"Nelle ultime notizie su Embracing Digital del 20 agosto 2023, ci sono aggiornamenti riguardanti l'intelligenza artificiale, la cibersicurezza e l'elaborazione ai margini. Le notizie includono l'IA che si dirige verso il tribunale, gli attori cattivi della cyber che mirano alla stagione del rientro a scuola e il debito tecnico che viene trasferito all'ecosistema 5G tramite l'elaborazione ai margini."},{"id":196,"type":"News Brief","title":"2023-2-19","tags":null,"body":"\n\n## Intelligenza Artificiale\n\nL'etica e le regole dell'uso dei Chatbot abilitati all'AI generativa stanno iniziando a entrare in gioco man mano che sempre più persone iniziano a utilizzare ChatGPT e altri. I Chatbot dovranno ora includere un avviso: Potremmo non produrre output reale. Credete a vostro rischio. Revocate il vostro diritto di citarci in giudizio se riproducete conversazioni, immagini e video per casi di alto rischio che causano odio, molestie, violenza, autolesionismo, attività illegali, inganno, discriminazione o spam.\n\n[https://swisscognitive.ch/2023/02/15/honest-lying-why-scaling-generative-ai-responsibly-is-not-a-technology-dilemma-in-as-much-as-a-people-problem/](https://swisscognitive.ch/2023/02/15/honest-lying-why-scaling-generative-ai-responsibly-is-not-a-technology-dilemma-in-as-much-as-a-people-problem/)\n\nMan mano che l'AI diventa sempre più importante in varie industrie, il ruolo del Chief AI Officer (CAIO) sta emergendo come una nuova aggiunta alla C-Suite. Un buon CAIO dovrebbe definire chiaramente l'impatto desiderato dei progetti di AI e continuamente focalizzare l'organizzazione sulla consegna di tale risultato. Un ottimo CAIO dovrebbe anche tracciare l'impatto reale di quei progetti e aggiornare l'azienda sul loro rendimento nel tempo. Questo ruolo, quindi, aumenta le aspettative per guidare la trasformazione e l'impatto, nonché prevedere e rispondere all'uso dell'AI da parte dei concorrenti.\n\n[https://applieddatascience.medium.com/the-case-for-the-chief-ai-officer-the-newest-c-suite-role-d55cca40c01](https://applieddatascience.medium.com/the-case-for-the-chief-ai-officer-the-newest-c-suite-role-d55cca40c01)\n\nIl più recente supercomputer di IBM sta prendendo diverse nuove direzioni innovative: è il primo supercomputer nativo di cloud-ottimizzato per l'Intelligenza Artificiale di IBM ed è ospitato interamente all'interno di IBM Cloud anziché on-premise come i tradizionali supercomputer. Secondo IBM, \"questo ambiente è la scelta preferita per i ricercatori di IBM che creano capacità avanzate di IA, tra cui il lavoro sui modelli di base e un luogo in cui collaborano con partner sulla creazione dei modelli\".\n\n[https://futurumresearch.com/research-notes/ibms-latest-supercomputer-is-cloud-based-and-ai-focused/](https://futurumresearch.com/research-notes/ibms-latest-supercomputer-is-cloud-based-and-ai-focused/)\n\n## Calcolo Ubiquo\n\nSecondo uno studio condotto da 451 Research commissionato da Oracle Cloud Infrastructure, quasi tutti i percorsi di cloud nelle aziende stanno diventando percorsi multicloud. Lo studio ha scoperto che il 98% delle aziende intervistate sta usando o pianifica di utilizzare almeno due provider di servizi cloud. I principali fattori trainanti delle strategie multicloud sono la sovranità dei dati e l'ottimizzazione dei costi. Le aziende stanno pianificando proattivamente strategie multicloud per il futuro, con la ridondanza dei dati che rappresenta il caso d'uso futuro più atteso.\n\n[https://www.cloudcomputing-news.net/news/2023/feb/21/98-of-firms-using-public-cloud-adopt-multicloud-infrastructure-provider-strategy/](https://www.cloudcomputing-news.net/news/2023/feb/21/98-of-firms-using-public-cloud-adopt-multicloud-infrastructure-provider-strategy/)\n\nIl \"supercloud\", un'architettura cloud che consente una migrazione senza soluzione di continuità delle applicazioni tra diversi fornitori cloud, è stata proposta per la prima volta nel 2016 dai ricercatori dell'Università di Cornell. Il concetto è riemerso come soluzione alle sfide multi-cloud, fornendo una rete omogenea per legare insieme le risorse cloud, risultando in una migrazione senza soluzione di continuità, sicurezza coerente e performance ottimali.\n\n[https://www.cloudcomputing-news.net/news/2023/feb/22/here-comes-the-supercloud-what-does-it-mean-for-multi-cloud-complexity/](https://www.cloudcomputing-news.net/news/2023/feb/22/here-comes-the-supercloud-what-does-it-mean-for-multi-cloud-complexity/)\n\nLa domanda di DRAM per server supererà quella per smartphone a causa dell'aumento dell'utilizzo di app cloud, AI e HPC; si prevede un aumento del contenuto di DRAM per i server del 12,1% YoY nel 2023 rispetto al 6,7% per gli smartphone. La memoria del server rappresenterà il 37,6% dell'output totale di bit DRAM, rispetto al 36,8% per DRAM mobile. La pandemia COVID-19 ha aumentato la domanda di servizi cloud, determinando un forte aumento delle spedizioni di server.\n\n## Cibersicurezza\n\nLa società di cybersecurity Resecurity ha avvertito di una serie di attacchi informatici che hanno preso di mira i data center globalmente negli ultimi 18 mesi, portando all'estrazione di dati e alla pubblicazione di credenziali di accesso sulla dark web. Sebbene Resecurity non abbia citato le vittime, Bloomberg afferma che importanti aziende, tra cui Alibaba, Amazon, Apple, BMW, Goldman Sachs, Huawei Technologies, Microsoft e Walmart, hanno avuto le loro credenziali di accesso al data center rubate.\n\n[https://www.csoonline.com/article/3688909/cyberattacks-hit-data-centers-to-steal-information-from-global-companies.html#tk.rss_all](https://www.csoonline.com/article/3688909/cyberattacks-hit-data-centers-to-steal-information-from-global-companies.html#tk.rss_all)\n\nLa società di cybersecurity Menlo Labs ha scoperto un gruppo di attori minaccia sconosciuti che sta mirando a entità governative tramite una campagna basata su Discord che utilizza il downloader PureCrypter. La campagna utilizza il dominio di un'organizzazione non profit compromessa come centro di controllo per consegnare un payload secondario, tra cui Redline Stealer, AgentTesla, Eternity, Blackmoon e Philadelphia ransomware.\n\n[https://www.menlosecurity.com/blog/purecrypter-targets-government-entities-through-discord](https://www.menlosecurity.com/blog/purecrypter-targets-government-entities-through-discord)\n\nIl più grande esercizio di cyber-guerra militare nell'Europa occidentale è avvenuto recentemente in Estonia, con 34 squadre provenienti da 11 paesi che hanno partecipato ad una battaglia cibernetica a fuoco vivo. L'evento di sette giorni ha testato le risposte dei partecipanti a scenari di cyber comuni e complessi, compresi attacchi alle reti e ai sistemi di controllo industriale (ICS). Uno scenario simula attacchi a sistemi robotizzati senza equipaggio. Le squadre provenienti dall'Italia, dall'Estonia e dal Regno Unito sono state le migliori prestazioni, giudicate in base alla loro velocità nel rilevare e rispondere alle minacce cibernetiche.\n\n[https://www.securityweek.com/11-countries-take-part-in-military-cyberwarfare-exercise/](https://www.securityweek.com/11-countries-take-part-in-military-cyberwarfare-exercise/)\n\n## Podcast sull'abbraccio alla trasformazione digitale\n\nControlla l'episodio completo di questa settimana \"Certifying Autonomous Flight\" in cui Darren intervista LuukVan Dijk di Daedalean.\n\n[https://www.embracingdigital.org/episode-EDT126](https://www.embracingdigital.org/episode-EDT126)\n\n\n\n","guests":null,"link":"/brief-EDW3-it","image":"./briefs/edw-3/it/thumbnail.png","lang":"it","summary":"Summary"},{"id":197,"type":"News Brief","title":"2023-8-26","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\nSicurezza informatica\n\n\nÈ emersa una nuova minaccia. Il gruppo cibernetico chiamato \"Flax Typhoon\", ritenuto collegato alla Cina, sta facendo parlare di sé. Si sospetta che siano responsabili di sofisticati attacchi informatici a organizzazioni globali. Gli esperti monitorano attentamente questa situazione poiché potrebbe avere importanti implicazioni per la sicurezza digitale. Rimanete sintonizzati per gli aggiornamenti su questa storia in evoluzione. [Leggi di più](https://thehackernews.com/2023/08/china-linked-flax-typhoon-cyber.html)\n\n\nLe aziende di cybersecurity stanno suonando l'allarme poiché gli attacchi di ransomware sono aumentati di oltre centocinquantatré per cento rispetto a un anno fa e di oltre sedici per cento il mese scorso. Gli esperti avvertono che le organizzazioni devono rafforzare le proprie difese ed educare i dipendenti su queste minacce per proteggersi contro costose violazioni di dati. [Leggi di più](https://www.securityweek.com/cybersecurity-companies-report-surge-in-ransomware-attacks/)\n\n\nIl settore della cybersecurity sta affrontando una grave carenza di talento, alimentando l'aspettativa di soluzioni. La richiesta di professionisti qualificati in questo campo in continua evoluzione è in rapida crescita, tuttavia il divario persiste. Per affrontare questa situazione, le aziende stanno esplorando strategie come l'aggiornamento delle competenze degli attuali dipendenti e la promozione della diversità nell'industria. Potrebbe essere il momento di tornare a scuola per ottenere la certificazione in sicurezza informatica. [Leggi di più](https://www.helpnetsecurity.com/2023/08/25/cybersecurity-talent-shortage-expectations/)\n\nIntelligenza artificiale\n\n\nL'intelligenza artificiale ha restituito la voce a una donna paralizzata in un incredibile sviluppo. Ricercatori dell'UCSF hanno impiegato la tecnologia IA per decodificare i segnali cerebrali della donna e tradurli in linguaggio parlato. Questo risultato rivoluzionario potrebbe aiutare numerose persone a recuperare la capacità di comunicare. Per saperne di più su questa storia ispiratrice, leggi un articolo approfondito su ucsf.edu. [Leggi di più](https://www.ucsf.edu/news/2023/08/425986/how-artificial-intelligence-gave-paralyzed-woman-her-voice-back)\n\n\nGli studenti delle scuole superiori si stanno preparando per l'avvento dell'intelligenza artificiale (IA). I ricercatori del MIT hanno lanciato una nuova iniziativa per aiutare a preparare gli studenti per il futuro guidato dall'IA. Questo programma mira a dotare le giovani menti delle competenze e conoscenze necessarie per prosperare in un mondo sempre più influenzato dalla tecnologia dell'IA. Dai un'occhiata all'intervista di Darren a Pete Schmitz nell'episodio del podcast \"Embracing Digital Transformation Podcast\" intitolato \"Training the Next Generation in AI\" per vedere da vicino ciò che sta accadendo oggi. [Leggi di più](https://news.mit.edu/2023/how-to-help-high-schoolers-prepare-rise-of-artificial-intelligence-0824)\n\n\nIn un approfondimento DeZeen stimolante, si analizza il costo ambientale dell'intelligenza artificiale (IA). Con l'espansione delle applicazioni di IA, aumenta anche il loro consumo energetico, potenzialmente aggravando le preoccupazioni climatiche. Questa esaminazione critica esplora le sfide di sostenibilità poste dall'IA e l'urgente necessità di soluzioni ecocompatibili nello sviluppo e nell'implementazione della tecnologia IA. Rimanete sintonizzati per approfondimenti su questa pressante problematica ambientale. [Leggi di più](https://www.dezeen.com/2023/08/26/dezeen-in-depth-examines-the-environmental-cost-of-artificial-intelligence/)\n\nUbiquitous Computing translates to Italian as \"Calcolo Ubiquo\".\n\n\nMan mano che ci avviciniamo all'era della computazione quantistica, proteggere le infrastrutture critiche diventa ancora più cruciale. C4ISRNET affronta le sfide e le strategie per proteggere i sistemi vitali in questo nuovo panorama tecnologico. Le potenzialità della computazione quantistica nel violare i metodi di crittografia attuali sollevano preoccupazioni, evidenziando la necessità di soluzioni innovative per la sicurezza informatica. [Leggi di più](https://www.c4isrnet.com/it-networks/2023/08/21/how-to-protect-critical-infrastructure-in-the-quantum-computing-era/)\n\n\nCome riportato dagli sviluppatori di XDA, Dropbox sta terminando la sua politica di storage cloud illimitato. Questa decisione è stata presa in risposta a casi di abuso da parte di alcuni utenti. Di conseguenza, Dropbox sta implementando nuovi limiti di archiviazione, il che rappresenta un cambiamento sostanziale per la sua base di utenti. Questo sviluppo sottolinea le sfide continue che i fornitori di storage cloud affrontano nel bilanciare le richieste degli utenti con modelli di business sostenibili. [Leggi di più](https://www.xda-developers.com/dropbox-ends-unlimited-cloud-storage-policy-abused/)\n\n\nLa pandemia globale nel duemilaventi ha rivitalizzato un settore tecnologico in sofferenza di crescita stagnante, l'Infrastruttura di Desktop Virtuale. Microsoft e VMware stanno riformulando il VDI aziendale e la tecnologia cloud. SiliconANGLE discute di come questi giganti della tecnologia collaborano per ridefinire il VDI e migliorare le soluzioni cloud. Questa partnership offrirà alle aziende maggiore flessibilità, scalabilità e performance negli ambienti IT. [Leggi di più](https://siliconangle.com/2023/08/24/microsoft-vmware-redefining-business-vdi-cloud-technology-vmwareexplore/)\n\n## Podcast sull'Abbraccio alla Trasformazione Digitale\n\n\n\nQuesta settimana, la serie Embracing Generative AI continua, presentando interviste con insegnanti delle scuole superiori che hanno adottato ChatGPT ed esplorando nuovi casi d'uso per l'intelligenza artificiale generativa. Iscriviti a Embracing Digital Transformation per approfondimenti su discussioni attuali sui temi più caldi. [Leggi di più](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW30-it","image":"./briefs/edw-30/it/thumbnail.png","lang":"it","summary":"Ecco gli ultimi aggiornamenti sulle notizie sulla trasformazione digitale della settimana del 27 agosto 2023. Le storie di questa settimana riguardano la sicurezza informatica, l'intelligenza artificiale e l'informatica ubiqua. In questo episodio troverai storie su un aumento significativo del 150% negli attacchi di ransomware, su come il calcolo quantistico abbia esposto vulnerabilità nella sicurezza informatica dell'IoT e su come l'IA stia aiutando a ripristinare la voce di coloro che sono paralizzati."},{"id":198,"type":"News Brief","title":"2023-9-2","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\nCi troviamo nel pieno della rivoluzione digitale. Durante questo periodo, può essere difficile districarsi tra tutte le promesse e scoprire cosa funziona, cosa sarà ancora valido fra due anni e cosa contribuisce alla tua organizzazione. Molte organizzazioni IT hanno bisogno di aiuto per comprendere messaggi confusi e tecnologie in conflitto. Noi aiutiamo le organizzazioni a fare chiarezza e abbracciare la trasformazione digitale. Il mondo della trasformazione digitale è in continua evoluzione e devi sapere cosa è fattibile oggi. Ascolta il nostro podcast settimanale per le ultime notizie sulla sicurezza informatica, le comunicazioni avanzate, la gestione dei dati, l'intelligenza artificiale, il cloud computing e la tecnologia edge.\n\n## Sicurezza informatica\n\n\n\nUn recente attacco informatico, ritenuto supportato dalla Cina, ha suscitato preoccupazioni per la sicurezza nazionale a Guam. Il gruppo di hacker Volt Typhoon ha preso di mira le telecomunicazioni e la rete energetica di Guam per stabilire una presenza furtiva. Guam è considerato un hub logistico vitale per gli Stati Uniti in caso di conflitto con la Cina. Gli hacker hanno sfruttato una vulnerabilità del firewall Fortinet Fortigate, un prodotto leader di protezione informatica. Questo attacco mette in evidenza una nuova minaccia mentre gli hacker di Stato mirano sempre più agli strumenti di sicurezza informatica fondamentali per la protezione dei sistemi. [Leggi di più](https://www.msn.com/en-us/news/other/cybersecurity-tools-are-new-targets-for-nation-state-hackers/ar-AA1g5mib)\n\n\nUn attacco informatico ha causato un'interruzione tecnologica di una settimana presso il sistema sanitario Hospital Sisters Health System, incluso St. Elizabeth's a O'Fallon, Illinois. Il CEO Damond Boatright ha confermato che l'incidente ha interrotto i servizi internet, i siti web, i telefoni e le applicazioni informatiche. Sebbene stiano facendo progressi per ripristinare i sistemi critici, il sito web di HSHS rimane offline e l'accesso dei pazienti alle cartelle cliniche online e alla comunicazione con i medici è stato interrotto. Questo è il secondo attacco a gruppi ospedalieri negli Stati Uniti in due mesi. [Leggi di più](https://www.bnd.com/news/local/article278879724.html)\n\n\n\nI community college stanno affrontando una crescente minaccia di cybersecurity: gli \"studenti fantasma\". Queste identità fittizie sfruttano i processi di iscrizione per accedere alle risorse accademiche, compromettendo potenzialmente i dati degli studenti e l'integrità istituzionale. Con gli hacker che diventano sempre più sofisticati, i community college investono in misure di cybersecurity per combattere questa minaccia. La battaglia contro gli \"studenti fantasma\" mette in evidenza la necessità di una robusta sicurezza digitale nelle istituzioni educative per proteggere informazioni sensibili e garantire un ambiente di apprendimento sicuro. [Leggi di più](https://www.chronicle.com/article/meet-the-cybersecurity-threat-haunting-community-colleges-ghost-students)\n\nIntelligenza Artificiale\n\n\nL'uso dell'Intelligenza Artificiale nell'istruzione superiore ha suscitato dibattito tra coloro che ne vedono il potenziale per la personalizzazione e l'efficienza e coloro che si preoccupano dell'etica e della perdita del collegamento umano. È necessaria una considerazione attenta per integrare l'IA nelle aule universitarie. La professoressa universitaria Laura Torres Newey ha condiviso il suo approccio per affrontare questa questione in un episodio del podcast \"Abbracciando la Trasformazione Digitale\". Le sue intuizioni rivelano le sfide e le opportunità dell'incorporazione dell'IA nell'istruzione superiore. [Leggi di più](https://theconversation.com/should-ai-be-permitted-in-college-classrooms-4-scholars-weigh-in-212176)\n\n\nL'industria dell'intrattenimento affronta controversie sindacali, con l'intelligenza artificiale (IA) al centro del conflitto. Lo sciopero dello Screen Actors Guild è entrato nella sua ottava settimana, con i lavoratori di Hollywood che chiedono una giusta compensazione e controllo creativo nell'uso della tecnologia basata sull'IA. Questa controversia riflette la lotta dell'industria nel bilanciare i benefici dell'IA, come l'efficienza dei costi e l'innovazione, con le preoccupazioni sulla sostituzione dei posti di lavoro e l'autonomia artistica. Con l'evoluzione del panorama dell'intrattenimento, risolvere queste questioni sindacali legate all'IA sarà cruciale per i lavoratori e per il futuro dell'industria. Il mondo sta guardando! [Leggi di più](https://www.pbs.org/newshour/show/why-artificial-intelligence-is-a-central-dispute-in-the-hollywood-strikes)\n\n\nLa regolamentazione dell'intelligenza artificiale (IA) è una preoccupazione globale, e i paesi adottano diverse approcci per affrontarla. Cina, Israele e Unione Europea (UE) sono in prima linea nella regolamentazione dell'IA. La Cina si concentra sull'etica dell'IA e la sicurezza dei dati, Israele promuove l'innovazione attraverso gli \"sandbox\" regolamentari, e l'UE propone rigorose norme sull'IA per garantirne l'accountability. Mentre l'IA continua a plasmare settori diversi e aspetti della vita quotidiana, trovare il giusto equilibrio tra innovazione e regolamentazione rimane una sfida cruciale a livello globale. [Leggi di più](https://www.washingtonpost.com/world/2023/09/03/ai-regulation-law-china-israel-eu/)\n\n## Edge Computing -> Edge Computing\n\n\nIntel sta potenziando la sicurezza dei calcoli in periferia introducendo un innovativo livello di protezione. La nuova tecnologia dell'azienda promette di tutelare i dispositivi e i dati in periferia, affrontando le critiche preoccupazioni sulla sicurezza informatica. Con l'importanza crescente dei calcoli in periferia in varie industrie, questo sviluppo rappresenta un significativo passo avanti nel garantire l'integrità e la sicurezza degli ambienti di calcolo distribuiti. [Leggi di più](https://www.fool.com/investing/2023/09/01/intel-adds-a-layer-of-protection-to-edge-computing/)\n\n\nGarantire la sicurezza dell'Internet delle Cose (IoT) è cruciale per tutelare l'infrastruttura critica come le reti elettriche e gli impianti di trattamento dell'acqua. Man mano che i dispositivi IoT diventano sempre più integrati in questi sistemi, proteggerli dalle minacce in evoluzione, inclusi i potenziali rischi associati a determinati paesi, è una questione urgente per gli Stati Uniti. Le sfide e le implicazioni della tecnologia cinese nell'IoT sono attualmente oggetto di attenta esame, evidenziando la necessità di misure preventive per tutelare l'infrastruttura critica nel paese. [Leggi di più](https://www.forbes.com/sites/davealtavilla/2023/09/03/securing-the-iot-from-the-threat-china-poses-to-us-infrastructure/?sh=4325a3f112c0)\n\n\nIl computing dell'orlo non riguarda solo la produzione e la gestione delle infrastrutture critiche. Il computing dell'orlo sta rivoluzionando il settore sanitario consentendo il trattamento dei dati in tempo reale, il che porta a tempi di risposta più rapidi per i dati essenziali dei pazienti. Sostiene il monitoraggio remoto e la telemedicina, rendendo la sanità più accessibile e riducendo lo sforzo sulle strutture sanitarie. Inoltre, il computing dell'orlo migliora la privacy e la sicurezza dei dati elaborando le informazioni sensibili dei pazienti a livello locale, riducendo il rischio di violazioni dei dati e garantendo il rispetto delle normative sanitarie. [Leggi di più](https://www.ft.com/partnercontent/ntt-ltd/edge-computing-delivers-healthcare-beyond-the-clinic.html?blaid=3846770)\n\nAbbracciando la trasformazione digitale\n\n\n\nLa serie che abbraccia l'IA generativa continua con interviste sul diventare pronti ai dati nella rivoluzione GenAI e su come l'istruzione superiore affronta l'IA generativa in aula. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW31-it","image":"./briefs/edw-31/it/thumbnail.png","lang":"it","summary":"Notizie della settimana del 3 settembre 2023 su Abbracciare il Digitale. Questa settimana, ci sono aggiornamenti sulla cybersecurity, sull'intelligenza artificiale e sul computing edge. Gli attacchi informatici della Cina alle basi militari e alle infrastrutture critiche, gli sforzi di Intel per migliorare la sicurezza nello spazio IoT e le sfide dei governi nella regolamentazione dell'AI."},{"id":199,"type":"News Brief","title":"2023-9-9","tags":["ai","gpt4","openai","microsoft","generativeai","environmentalimpact","irs","taxevasion","education","cybersecurity","iosspyware","zerodayvulnerability","northkoreanhackers","quantumrandomness","cloudfirst","cloudsmart","embracingdigital","generativeaipolicy","highereducation"],"body":"\n\n## Intelligenza Artificiale\n\n\nIl luogo di nascita di GPT-4 è stato scoperto! I campi di granturco di Des Moines, nell'Iowa, sono stati al centro delle ultime novità da parte di OpenAI, ma a un costo significativo per l'ambiente. L'ultimo rapporto ambientale di Microsoft ha rivelato un aumento del 34% nel consumo mondiale di acqua dal 2021 al 2022, che ammonta a quasi 1,7 miliardi di galloni. Questo aumento è principalmente dovuto al consistente investimento dell'azienda nella generazione di AI e alla partnership con OpenAI. L'impatto della generazione di AI sull'ambiente è significativo e importanti organizzazioni come Microsoft, Google e OpenAI stanno prendendo misure per affrontare queste preoccupazioni. [Leggi di più](https://apnews.com/article/chatgpt-gpt4-iowa-ai-water-consumption-microsoft-f551fde98083d17a7e8d904f8be822c4)\n\n\n\nIl Servizio delle Entrate Interne degli Stati Uniti progetta di implementare la tecnologia AI per migliorare la supervisione dei grandi studi legali, dei fondi speculativi, delle società di private equity e degli investitori immobiliari. L'iniziativa mira a individuare casi complessi di evasione fiscale e a recuperare i redditi federali dovuti dai contribuenti facoltosi. L'IRS ha stanziato 80 miliardi di dollari con l'Atto di Riduzione dell'Inflazione per affrontare schemi e tendenze nell'effettuazione di audit significativi e per imporre sanzioni ai evasori fiscali in questi settori. [Leggi di più](https://www.nytimes.com/2023/09/08/us/politics/irs-deploys-artificial-intelligence-to-target-rich-partnerships.html)\n\n\nEducatori e studiosi si trovano in prima linea nell'affrontare il ruolo dell'IA nell'istruzione. Mentre gli studenti ritornano a scuola quest'autunno, diversi articoli di riviste di tutto il mondo coprono le applicazioni dell'IA, le preoccupazioni etiche, l'aumento rispetto all'automazione, la preparazione degli studenti per il lavoro integrato con l'IA, il rilevamento dei deepfake, la conservazione del buon senso umano e l'utilizzo dell'IA generativa per l'insegnamento. Queste intuizioni forniscono preziosi orientamenti per plasmare il futuro dell'IA nell'istruzione. Inoltre, date un'occhiata all'intervista di Darren con il New York Times e il professor di inglese Laura Torres Newey su come sta integrando l'IA nei suoi corsi questo autunno. [Leggi di più](https://daily.jstor.org/artificial-intelligence-and-education-a-reading-list/)\n\n## Sicurezza informatica\n\n\nLa Cina sta prendendo seriamente sul serio la Cybersecurity. Le nuove normative cinesi sulla cybersecurity mirano a migliorare la sicurezza digitale per Internet, ma le piccole imprese potrebbero affrontare sfide. L'impatto completo sulle imprese di tutte le dimensioni rimane poco chiaro e potrebbero esserci ripercussioni sulla privacy online. Tuttavia, queste misure sono necessarie per tutelare i dati online e proteggersi dalle minacce informatiche. Individui e imprese devono rimanere aggiornati su questi cambiamenti e prendere le precauzioni necessarie per garantire la propria presenza online. [Leggi di più](https://www.scmp.com/news/china/politics/article/3233931/china-steps-cybersecurity-enforcement-smaller-businesses-are-feeling-heat)\n\n\nIl sistema iPhone, una volta immune, è stato attaccato nell'ultima settimana con il rilevamento di spyware nel popolare iOS che alimenta gli iPhone. Apple ha preso immediatamente provvedimenti dopo aver scoperto minacce di spyware. Hanno rilasciato aggiornamenti software indispensabili per mantenere i tuoi dispositivi al sicuro. È come avere un supereroe che protegge il tuo mondo tecnologico! Approfondiremo i dettagli di questi aggiornamenti, come hanno ostacolato potenziali violazioni della sicurezza e cosa significa per la tua sicurezza digitale. Resta sintonizzato mentre sveliamo gli ultimi sviluppi nella tecnologia e nella cibersicurezza. [Leggi di più](https://www.washingtonpost.com/politics/2023/09/08/apple-issues-software-updates-after-spyware-discoveries/)\n\n\nSembra che hacker nordcoreani abbiano sfruttato una vulnerabilità zero-day, che concede loro l'accesso a una fortezza di difese digitali. Questo attacco informatico rappresenta una minaccia significativa per i sistemi presi di mira, le violazioni dei dati e l'intero panorama della sicurezza informatica. Sono in corso sforzi per contrastare la minaccia, compresi aggiornamenti e salvaguardie per proteggere dai futuri attacchi simili. [Leggi di più](https://thehackernews.com/2023/09/north-korean-hackers-exploit-zero-day.html)\n\n## Calcolo Ubiquo\n\n\nIntegrare i sistemi di intelligenza artificiale generativa sta cambiando l'architettura cloud, dotandola di un cervello intelligente in grado di apprendere e creare in modo indipendente. Questa trasformazione ridisegna l'infrastruttura cloud, potenziando l'automazione, ottimizzando l'allocazione delle risorse e migliorando le misure di sicurezza. L'infusione dei sistemi di intelligenza artificiale generativa nel cloud presenta opportunità e sfide promettenti, e intraprenderemo un viaggio approfondito per svelarle. [Leggi di più](https://www.infoworld.com/article/3706094/adding-generative-ai-systems-may-change-your-cloud-architecture.html)\n\n\nIn un risultato rivoluzionario, il MIT ha preso il controllo della casualità quantistica per la prima volta. È come domare il selvaggio e imprevedibile! Approfondiremo i dettagli di questa straordinaria impresa, che potrebbe avere profonde implicazioni per il calcolo e la crittografia quantistica. Unisciti a noi mentre esploriamo come la scoperta del MIT ci permetta di sfruttare la casualità intrinseca del mondo quantistico, aprendo nuovi orizzonti nella tecnologia e nella sicurezza. Sarà il tempo a dire quale impatto avrà tutto ciò sul calcolo. [Leggi di più](https://scitechdaily.com/harnessing-the-void-mit-controls-quantum-randomness-for-the-first-time/)\n\n\n\"Cloud-first\" è fuori moda, e \"Cloud-smart\" è il nuovo termine di tendenza nel settore tecnologico. Pensatelo come un passaggio da \"il cloud è la risposta\" a \"il cloud come alleato strategico\". Approfondiremo i dettagli di questa trasformazione, esplorando cosa significa \"cloud-smart\" per le aziende e le strategie IT. Unisciti a noi mentre discutiamo come le organizzazioni evolvono le loro metodologie per sfruttare il cloud in modo più intelligente, rendendolo una parte centrale del loro percorso di trasformazione digitale. [Leggi di più](https://www.infoworld.com/article/3705615/cloud-first-is-dead-cloud-smart-is-whats-happening-now.html)\n\n## Abbracciando la trasformazione digitale\n\nQuesta settimana continua la serie Accogliendo l'IA Generativa nel podcast con un'intervista affascinante sulla sviluppo di una Politica sull'IA Generativa per il tuo luogo di lavoro e su come l'istruzione superiore sta affrontando l'IA generativa in aula. Sintonizzati sugli ultimi episodi il martedì e il giovedì. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW32-it","image":"./briefs/edw-32/it/thumbnail.png","lang":"it","summary":"Ottieni le ultime notizie digitali per la settimana del 10 settembre 2023 riguardanti Intelligenza Artificiale, Sicurezza Informatica e Informatica Ubiqua. Questa settimana, scopri una nuova minaccia cibernetica per iPhone, il luogo di origine di GPT-4 e l'approccio del MIT per affrontare l'incertezza del calcolo quantistico."},{"id":200,"type":"News Brief","title":"2023-9-16","tags":["aisummit","rishisunak","chineseofficialsban","nationalsecurity","ukchinatensions","amazonselfpublishers","aigeneratedcontent","digitalpublishing","columbiauniversityresearch","aireliability","languagemodels","chatbotperformance","cognitivescience","webassembly(wasm)","edgecomputingrevolution","edgedevices","latencyreduction","secureexecution","iotapplications","mobilecomputing","ai","security","edge","embracingdigital"],"body":"\n\n## Intelligenza artificiale\n\n\nIl Cancelliere del Regno Unito Rishi Sunak sta riflettendo sulla possibilità di vietare la partecipazione di ufficiali cinesi al 50% del prossimo AI Summit a causa delle preoccupazioni per la sicurezza nazionale. Tale decisione riflette le crescenti tensioni tra il Regno Unito e la Cina riguardo alla tecnologia e alla proprietà intellettuale. I dettagli del potenziale divieto devono ancora essere definiti. L'AI Summit è un evento di rilievo per la collaborazione tecnologica globale. [Leggi di più](https://www.theguardian.com/technology/2023/sep/15/rishi-sunak-considers-banning-chinese-officials-from-half-of-ai-summit)\n\n\nAmazon ora richiede agli autori che pubblicano in autonomia di dichiarare ogni coinvolgimento dell'intelligenza artificiale nelle loro opere per aumentare la trasparenza nel mondo della pubblicazione digitale. Questa decisione arriva in risposta alle preoccupazioni riguardanti la sovrabbondanza di contenuti generati da IA sul mercato. Queste nuove regole avranno un impatto sull'industria dell'auto-pubblicazione su Amazon. [Leggi di più](https://www.theguardian.com/books/2023/sep/11/self-publishers-must-declare-if-content-sold-on-amazons-site-is-ai-generated)\n\n\n\nUna ricerca dell'Università di Columbia mette in evidenza preoccupazioni sulla affidabilità dell'IA nella presa di decisioni. Lo studio ha scoperto che anche i modelli di linguaggio avanzati possono confondere il nonsense con il linguaggio naturale, sollevando dubbi sulla precisione. Ciò offre un'opportunità per migliorare le prestazioni dei chatbot e comprendere l'elaborazione del linguaggio umano. Attraverso il ponte tra l'IA e le scienze cognitive, possiamo creare assistenti alimentati dall'IA più utili ed efficaci che soddisfano meglio i loro utenti. [Leggi di più](https://www.sciencedaily.com/releases/2023/09/230914114704.htm)\n\n## Elaborazione periferica\n\n\nWebAssembly (Wasm) è pronto per rivoluzionare l'informatica periferica. Questa tecnologia consente l'esecuzione di codice proveniente da diversi linguaggi sui dispositivi periferici, migliorando la flessibilità e le prestazioni. Riducendo la latenza e abilitando un'esecuzione sicura ed efficiente, Wasm può trasformare il modo in cui le applicazioni vengono distribuite ed eseguite sul bordo. I programmatori possono sfruttare il potenziale di Wasm per creare soluzioni di informatica periferica più dinamiche e reattive, migliorando diverse industrie come Internet delle cose (IoT) e l'informatica mobile. [Leggi di più](https://www.infoworld.com/article/3703052/how-webassembly-will-transform-edge-computing.html)\n\n\n\nLa corsa per spostare l'IA al margine si sta riscaldando! Cadence Design Systems ha svelato nuovi strumenti software di proprietà intellettuale dell'IA (AI IP) che offrono capacità di spostamento da processori principali. Questi strumenti mirano a ottimizzare i carichi di lavoro dell'IA, migliorando le prestazioni e l'efficienza energetica nei dispositivi al margine. La tecnologia consente un'esecuzione più efficiente dei compiti dell'IA, rendendola adatta a varie applicazioni, incluse IoT e calcolo al margine, dove l'ottimizzazione delle risorse è cruciale. Gli strumenti software AI IP di Cadence possono aiutare ad accelerare l'adozione dell'IA nei dispositivi al margine. [Leggi di più](https://www.edgeir.com/cadences-new-ai-ip-software-tools-promises-offloading-abilities-from-any-host-processor-20230914)\n\n\n\nLe conferenze di Edge Computing sono in pieno svolgimento quest'autunno, con ben sette importanti conferenze in tutto il mondo. Iniziano l'ultima settimana di settembre ad Amsterdam, passando per Toronto, Dubai, Parigi e Londra, solo per citare alcuni luoghi. Spolvera le tue valigie da viaggio, questo autunno sarà frenetico per le aziende IoT. Puoi trovare l'elenco completo su edgier.com. [Leggi di più](https://www.edgeir.com/edge-computing-events)\n\n## Sicurezza informatica\n\n\nIl Centro di Risposta alla Sicurezza di Microsoft ha identificato vulnerabilità critiche nella libreria software open-source NCurses, utilizzata nei sistemi Unix-like (Linux e iOS). Queste lacune potrebbero consentire agli attaccanti di eseguire codice maligno o causare attacchi di negazione del servizio. Si invita gli utenti ad aggiornare le proprie installazioni di NCurses all'ultima versione per mitigare i potenziali rischi. Le vulnerabilità nelle librerie ampiamente utilizzate come NCurses sottolineano l'importanza degli aggiornamenti regolari della sicurezza e della gestione delle correzioni nell'ecosistema del software. [Leggi di più](https://thehackernews.com/2023/09/microsoft-uncovers-flaws-in-ncurses.html)\n\n\nIl sito web Free Download Manager (FDM), un sito molto popolare per il software gratuito e open-source, è stato compromesso, esponendo gli utenti a potenziali rischi. Gli attaccanti hanno iniettato codice malevolo nel sito, potenzialmente influenzando gli utenti che hanno scaricato il software tra l'11 settembre e il 12 settembre 2023. Questa violazione sottolinea l'importanza di scaricare software solo da fonti affidabili e aggiornare regolarmente il software di sicurezza per proteggersi dalle minacce potenziali. FDM ha intrapreso misure per affrontare il problema, ma gli utenti dovrebbero rimanere vigili. [Leggi di più](https://thehackernews.com/2023/09/free-download-manager-site-compromised.html)\n\n\nSembra che attori statali iraniani abbiano utilizzato sofisticati attacchi di spear-phishing per prendere di mira individui negli Stati Uniti, nel Medio Oriente e in Asia. Gli attacchi coinvolgono e-mail ingannevoli che si fanno passare per organizzazioni autorevoli nel tentativo di consegnare malware e rubare informazioni sensibili. Esperti di sicurezza sottolineano la necessità di robuste misure di sicurezza delle email e di consapevolezza dell'utente per difendersi da tali minacce informatiche orchestrate da attori statali. [Leggi di più](https://thehackernews.com/2023/09/iranian-nation-state-actors-employ.html)\n\n## Abbracciando la trasformazione digitale\n\n\n\nQuesta settimana continua la serie \"Abbracciando l'IA generativa\" con ospiti che parlano di operazionalizzare l'IA generativa sul luogo di lavoro, inclusa l'utilizzo per potenziare la sicurezza e generare rapporti in linguaggio naturale. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW33-it","image":"./briefs/edw-33/it/thumbnail.png","lang":"it","summary":"Resta aggiornato sulle ultime notizie sulla trasformazione digitale per la settimana del 17 settembre 2023. Ottieni gli ultimi aggiornamenti sull'intelligenza artificiale, il calcolo sul bordo e la sicurezza informatica. Tra i momenti salienti di questa settimana ci sono Microsoft che scopre vulnerabilità nei software dei loro concorrenti, Amazon che implementa requisiti di divulgazione dell'IA e una lista completa delle prossime conferenze sull'IoT in autunno."},{"id":201,"type":"News Brief","title":"2023-9-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Intelligenza Artificiale\n\n\nI fisici stanno sviluppando modelli generativi per l'IA utilizzando equazioni fisiche ben comprese. Il modello generativo del flusso di Poisson (PFGM), che rappresenta i dati con particelle cariche, può produrre immagini di alta qualità da 10 a 20 volte più velocemente dei modelli di diffusione. I ricercatori mirano a esplorare ulteriori processi fisici e a perfezionare il PFGM mediante l'adattamento della sua dimensionalità. [Leggi di più](https://www.quantamagazine.org/new-physics-inspired-generative-ai-exceeds-expectations-20230919/ )\n\n\nCosa ne pensi di utilizzare un chatbot sul tuo computer? Intel ha annunciato un nuovo processore, previsto per dicembre, che consentirà ai laptop di eseguire chatbot generativi di intelligenza artificiale senza dipendere dai data center cloud. Questa capacità, dimostrata durante la loro conferenza per sviluppatori di software, consente alle aziende e ai consumatori di testare tecnologie di intelligenza artificiale come ChatGPT senza inviare dati sensibili al cloud. [Leggi di più](https://www.reuters.com/technology/intel-says-newest-laptop-chips-software-will-handle-generative-ai-2023-09-19/)\n\n\nLa crescita della comunità open-source sta facendo ondate nello sviluppo dell'IA. Non nuovi all'innovazione, progetti open-source come Hadoop e Spark hanno permesso agli sviluppatori di progredire nello sviluppo dell'IA dagli anni settanta. Modelli generativi di IA come ChatGPT e Llama 2 sono costruiti su fondamenta open-source, sfidando lo status quo proprietario dei programmi di IA. Gli sviluppatori continueranno a spingere i limiti dell'IA al di fuori dei confini dello sviluppo commerciale. [Leggi di più](https://www.zdnet.com/article/why-open-source-is-the-cradle-of-artificial-intelligence/)\n\n## Calcolo ubiquo\n\n\nIntel ha lanciato la sua piattaforma 'Developer Cloud' per sviluppatori per testare e implementare applicazioni di intelligenza artificiale e calcolo ad alte prestazioni utilizzando le più recenti piattaforme hardware. Supporta l'addestramento di intelligenza artificiale, l'ottimizzazione dei modelli e i carichi di lavoro dell'inferenza ed è basata su software aperto con oneAPI, permettendo la scelta dell'hardware e la portabilità del codice. Altre tecnologie correlate all'intelligenza artificiale sono state presentate durante l'annuncio. Chiunque può registrarsi su cloud.intel.com. [Leggi di più](https://ummid.com/news/2023/september/20-09-2023/intel-developer-cloud-reaches-general-availability.html)\n\n\nPer contribuire a frenare le spese mistiche e costose di gestione dei dati, WiMi Hologram Cloud ha sviluppato un nuovo algoritmo di compressione dei dati olografici che migliora l'efficienza del cloud computing riducendo le necessità di trasmissione e archiviazione dei dati. Questi progressi e un protocollo di archiviazione distribuita delle immagini stanno incontrando la crescente domanda di tecnologia olografica avanzata. Ciò dovrebbe aiutare le organizzazioni che soffrono a causa dei costi di uscita dati nel cloud. [Leggi di più](https://beststocks.com/wimi-hologram-cloud-revolutionizing-cloud-com/ )\n\n\nAll'evento Innovation 2023 di Intel, l'azienda ha presentato una CPU con 288 core come parte della sua linea 'Sierra Forest' per server ad alta densità. Questa CPU avrà 144 core su due chiplet, per un totale di 288 core e thread. Intel ha inoltre confermato che la sua famiglia di processori Xeon di quinta generazione, 'Emerald Rapids', sarà lanciata il 14 dicembre, offrendo miglioramenti delle prestazioni pur mantenendo il consumo energetico. Intel ha enfatizzato il proprio focus sulle applicazioni di intelligenza artificiale, con un supercomputer per compiti di intelligenza artificiale che utilizza processori Xeon e acceleratori Gaudi2. [Leggi di più](https://www.techspot.com/news/100221-intel-announces-288-core-sierra-forest-xeon-processor.html)\n\n## Sicurezza informatica\n\n\nIl Gruppo del Ragno Sparsamente, un'abile associazione di hacker, sta guadagnando notorietà per gli attacchi ransomware alle aziende. Gli analisti suggeriscono che il gruppo sia composto principalmente da giovani di 17-22 anni provenienti da paesi occidentali. Utilizzano avanzate tecniche di ingegneria sociale, come lo scambio di SIM, e tattiche come \"SWATing\" per individuare i punti di accesso privilegiati. Sebbene il loro movente potrebbe non essere monetario, i loro attacchi hanno destabilizzato vari settori e hanno indotto le forze dell'ordine ad avviare indagini. [Leggi di più](https://www.reuters.com/technology/power-influence-notoriety-gen-z-hackers-who-struck-mgm-caesars-2023-09-22/)\n\n\nUna relazione sulle tendenze della criminalità informatica in India rivela un aumento degli attacchi informatici, tra cui phishing, malware e frodi finanziarie, con COVID-19 che aggrava la situazione. I risultati mettono in evidenza l'urgenza di misure di sicurezza informatica più rigorose, consapevolezza pubblica e collaborazione tra le forze dell'ordine e il settore privato per combattere efficacemente le minacce informatiche. Si sottolinea anche l'importanza dell'educazione sulle migliori pratiche di sicurezza informatica per proteggere gli individui da tali attacchi. [Leggi di più](https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/)\n\n\nPer aiutare a contrastare la minaccia della sicurezza informatica, Microsoft Azure sta cercando di aumentare la sicurezza informatica attraverso l'educazione. Azure ha annunciato di recente oltre sessanta ore di corsi gratuiti sulla sicurezza informatica, tra cui la sicurezza della cloud ibrida, la configurazione del firewall, la gestione delle patch, la gestione dell'Active Directory e le tecnologie di crittografia, solo per citarne alcune. Puoi trovare ulteriori informazioni su learn.microsoft.com. [Leggi di più](https://www.helpnetsecurity.com/2023/09/20/free-microsoft-azure-cybersecurity-resources/)\n\n## Abbracciando la trasformazione digitale\n\nQuesta settimana inizia una nuova serie su Come Creare una Strategia Cloud con architetti delle soluzioni cloud di Intel. Darren intervista gli esperti di Intel sulla migrazione nel cloud, la gestione dei costi del cloud e la valutazione del carico di lavoro. Dai un'occhiata all'ultima puntata del podcast Abbracciando la Trasformazione Digitale. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW34-it","image":"./briefs/edw-34/it/thumbnail.png","lang":"it","summary":"Notizie sulla Trasformazione Digitale per il 24 settembre 2023 includono intelligenza artificiale, informatica pervasiva e sicurezza informatica. Ascolta riguardo ai nuovi processori Intel che stanno cambiando l'IA e il calcolo ad alta densità e su come un gruppo di hacker adolescenti abbiano bloccato i casinò MGM di Las Vegas."},{"id":202,"type":"News Brief","title":"2023-9-30","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","datasciencesolution","polystores","dataarchitecture","aichatbots","cybersecurityawareness","aisecuritycenter","googlechrome","mozillafirefox","digitaltransformationpodcast","intelcloudsolutionarchitects"],"body":"\n\n## Gestione dei dati\n\nBMLL Vantage, una soluzione di data science, è stata premiata come 'Migliore Soluzione di Data Science' ai Data Management Insight Awards. Questo riconoscimento celebra il lavoro eccezionale di BMLL Vantage nella data science, riconoscendo il suo significativo contributo all'industria. [Leggi di più](https://mondovisione.com/media-and-resources/news/bmll-vantage-wins-best-data-science-solution-at-the-data-management-insight-aw/)\n\nI polystore integrano senza soluzione di continuità diverse fonti di dati, abbattendo i silos e consentendo l'analisi interfunzionale. Ottimizzano le prestazioni sfruttando le varie potenzialità del database e si adattano alle tecnologie in evoluzione. Le organizzazioni dovrebbero utilizzare i polystore per sbloccare il potenziale dei dati per prendere decisioni informate nell'era dei big data. [Leggi di più](https://thenewstack.io/polystores-the-data-management-game-changer/)\n\n\nQuando si decide su un'architettura dei dati, è fondamentale considerare fattori come la dimensione dei dati, la frequenza, la posizione della fonte, il tipo, la privacy, l'accesso e l'urgenza. Comprendere i diversi tipi di architetture e i loro utilizzi può aiutarti ad adattarti ai cambiamenti nei driver aziendali e nelle condizioni ambientali e scegliere la migliore soluzione per la tua azienda. Considerare questi fattori è stato dimostrato migliorare le capacità di decisione degli architetti di sistemi. [Leggi di più](https://www.intel.com/content/www/us/en/content-details/789953/content-details.html)\n\n## Intelligenza artificiale\n\n\nMark Zuckerberg ha svelato un insieme di AI chatbot al Meta Connect 2023, inclusa una con il rapper Snoop Dogg nel ruolo di Dungeon Master nel gioco di ruolo D&D. Questi chatbot, modellati su celebrità, non sono disponibili al pubblico. Meta AI è l'assistente chatbot leader, costruito su un modello di linguaggio personalizzato simile a ChatGPT di OpenAI, dando priorità all'aspetto visivo piuttosto che all'imitazione dei modelli di conversazione. I piani includono l'aggiunta di funzionalità vocali. [Leggi di più](https://kotaku.com/meta-quest-3-ai-chatgpt-snoop-dogg-facebook-chatbot-1850882666)\n\n\nIl primo ministro israeliano Netanyahu mette in guardia sui potenziali pericoli della rivoluzione dell'AI, come le interruzioni alla democrazia, la manipolazione mentale, le perdite di lavoro e le guerre guidate dall'AI. Esorta le nazioni a affrontare queste preoccupazioni e a impedire alle macchine autodidatte di controllare gli esseri umani. Tuttavia, riconosce anche gli aspetti positivi dell'AI, come l'assistenza robotica per gli anziani e il miglioramento dei trasporti. Israele punta a diventare un leader globale nell'AI. [Leggi di più](https://www.foxnews.com/world/netanyahu-warns-potential-eruption-ai-driven-wars-lead-unimaginable-consquences)\n\n\nUn dipendente di OpenAI, Lilian Weng, ha condiviso la sua esperienza emotiva utilizzando la modalità vocale di ChatGPT per una conversazione personale sullo stress e sull'equilibrio tra lavoro e vita. Sebbene Weng abbia trovato l'interazione confortante, solleva preoccupazioni sul ruolo dell'IA nel fornire terapia. Questo riflette una tendenza in cui l'IA mira a sembrare più umana, ma ha affrontato sfide, come si è visto con precedenti esperimenti di terapia IA che hanno ricevuto risposte miste e, in alcuni casi, causato danni. Le considerazioni etiche sono cruciali quando si integra l'IA nei contesti di salute mentale. [Leggi di più](https://fortune.com/2023/09/28/generative-ai-cfos-company-strategy/)\n\n## ## Sicurezza informatica\n\n\nOttobre segna il ventesimo Mese di Sensibilizzazione sulla Sicurezza Informatica per promuovere la sicurezza online. Il tema di quest'anno è \"Proteggiamo il nostro mondo\". Si concentra su quattro pratiche migliori fondamentali per la sicurezza informatica: utilizzare un gestore di password, implementare l'autenticazione multifattore, riconoscere e segnalare tentativi di phishing e installare regolarmente gli aggiornamenti. L'iniziativa mira a fornire informazioni per aiutare le persone a rimanere più sicure online. [Leggi di più](https://www.ktsm.com/local/octobers-cybersecurity-awareness-month-2023/)\n\n\nLa National Security Agency degli Stati Uniti ha creato un centro di sicurezza per l'intelligenza artificiale (AI) per supervisionare l'impiego dell'AI nei servizi di difesa e intelligence. Il direttore, Generale Paul Nakasone, ha sottolineato l'importanza di mantenere gli Stati Uniti all'avanguardia nell'AI e di prevenire il furto di innovazioni da parte di attori stranieri. Il centro promuoverà l'adozione sicura dell'AI nell'ambito della sicurezza nazionale e delle industrie della difesa. L'AI avrà un ruolo significativo nella sicurezza nazionale, nella diplomazia, nella tecnologia e nell'economia. [Leggi di più](https://www.aljazeera.com/news/2023/9/29/us-national-security-agency-unveils-artificial-intelligence-security-centre)\n\n\nÈ stata scoperta una nuova problematica di sicurezza nei browser Google Chrome e Mozilla Firefox. Questo potrebbe influenzare anche altri programmi. Si chiama \"StrangeU\". Gli hacker potrebbero utilizzarlo per controllare il tuo computer. Le aziende hanno risolto il problema, ma altri programmi potrebbero ancora essere a rischio. Mantieni tutti i tuoi software aggiornati e fai attenzione a problematiche simili in altre applicazioni. Stai al sicuro! [Leggi di più](https://arstechnica.com/security/2023/09/new-0-day-in-chrome-and-firefox-is-likely-to-plague-other-software/)\n\n## Podcast sull'adottare la trasformazione digitale\n\nQuesta settimana continua la serie sulle architetture multi-ibride cloud con ulteriori interviste degli architetti delle soluzioni cloud di Intel. Per ascoltare queste interviste di 30 minuti, puoi trovarle abbracciando la trasformazione digitale sui tuoi siti di podcast preferiti. [Leggi di più](https://www.embracingdigital.org/episode-EDT163)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW35-it","image":"./briefs/edw-35/it/thumbnail.png","lang":"it","summary":"Notizie sulla trasformazione digitale per la settimana del 1° ottobre, inclusi articoli sulla gestione dei dati, sull'intelligenza artificiale e sulla sicurezza informatica. Vieni a ascoltare la celebrazione del mese della consapevolezza della sicurezza informatica, un'intelligenza artificiale che rende Snoop Dogg un maestro del dungeon per D&D e scopri una nuova architettura dei dati chiamata Polystore."},{"id":203,"type":"News Brief","title":"2023-10-7","tags":["ai","edge","cybersecurity","precrime","aihealcare","mgmbreach","scatteredspider","aplhav","aiethics","convergeditot","iot","criticalinfrastructure"],"body":"\n\n## Sicurezza informatica\n\n\nIl cinque ottobre, MGM Resorts International ha annunciato che una violazione dei dati e un attacco ransomware hanno causato interruzioni, provocando una perdita di cento milioni di dollari durante il terzo trimestre. I gruppi di hacker AlphaV e Scattered Spider hanno rivendicato la responsabilità della violazione, in cui avrebbero presunto data dal sistema MGM e l'avrebbero tenuta per estorsione. [Leggi di più](https://www.reuters.com/business/mgm-expects-cybersecurity-issue-negatively-impact-third-quarter-earnings-2023-10-05/)\n\n\nSecurityWeek ha riportato la scoperta di firmware con accesso nascosto in dispositivi Android utilizzati dalle scuole negli Stati Uniti. I ricercatori hanno individuato vulnerabilità nei laptop e nei tablet distribuiti alle istituzioni educative, che potrebbero potenzialmente esporre dati sensibili degli studenti a minacce informatiche. Il firmware compromesso potrebbe consentire ai cybercriminali di accedere e manipolare i dispositivi in remoto se sfruttato. [Leggi di più](https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/)\n\n\nNel contesto del Mese di Consapevolezza sulla Sicurezza Informatica del 2023, SC Media sottolinea che è necessario fare di più che semplicemente promuovere la consapevolezza sulla sicurezza informatica. SC Media invita le organizzazioni ad aumentare la condivisione di informazioni sulle minacce informatiche e le migliori pratiche di sicurezza informatica e smaschera i miti sulla condivisione di informazioni preziose nell'industria della sicurezza informatica. [Leggi di più](https://www.scmagazine.com/perspective/cybersecurity-awareness-month-2023-why-we-need-more-than-just-cybersecurity-awareness)\n\n## Intelligenza Artificiale\n\n\nSecondo il rapporto 2023 di \"Freedom on the Net\" di Freedom House, i governi di tutto il mondo stanno utilizzando l'intelligenza artificiale per la sorveglianza e la censura. La Cina sta conducendo il processo di censura basato sull'intelligenza artificiale. Ciò sottolinea la necessità di bilanciare il progresso tecnologico con la salvaguardia dei diritti individuali e delle libertà digitali. Il rapporto sottolinea la necessità di sforzi globali per tutelare la libertà digitale degli individui. [Leggi di più](https://gizmodo.com/freedom-house-2023-freedom-on-the-net-report-ai-1850887842)\n\n\nUn recente articolo pubblicato su Nature discute la ricerca sull'utilizzo di algoritmi di intelligenza artificiale per prevedere e gestire le crisi epilettiche. Lo studio presenta risultati promettenti nella previsione accurata delle crisi in un gruppo di pazienti, offrendo potenzialità per una gestione delle crisi più efficace e un miglioramento delle condizioni dei pazienti. La previsione delle crisi tramite l'intelligenza artificiale potrebbe significativamente migliorare la qualità della vita delle persone affette da epilessia e ridurre i rischi associati. [Leggi di più](https://www.nature.com/articles/s41746-023-00931-7)\n\n\nSecondo un rapporto di NBC Bay Area, un professore dell'Università di Berkeley sta pionierizzando l'utilizzo dell'intelligenza artificiale (IA) per combattere la violenza domestica. Il professore sta sviluppando algoritmi di IA per analizzare i post sui social media e i messaggi di testo alla ricerca di segni di abuso domestico, con l'obiettivo di fornire un intervento tempestivo e supporto alle vittime. Questa innovativa applicazione della tecnologia IA ha il potenziale per avere un impatto significativo nell'identificazione e nell'affrontare le problematiche legate alla violenza domestica nell'era digitale. Sembra l'inizio di Pre-Crime nell'area di Bay. [Leggi di più](https://www.nbcbayarea.com/news/local/uc-berkeley-professor-artificial-intelligence-domestic-violence/3336053/)\n\n## Elaborazione Edge\n\n\nI ricercatori stanno lanciando un avvertimento riguardo all'esposizione di circa centomila sistemi di controllo industriale (ICS) su internet, secondo BleepingComputer. Questo allarmante scoperta solleva preoccupazioni riguardo ai potenziali cyberattacchi alle infrastrutture critiche e agli impianti di produzione. I dispositivi ICS esposti rappresentano un significativo rischio per la sicurezza, mettendo in evidenza l'urgente necessità di migliorare le misure di sicurezza informatica per proteggere le infrastrutture critiche da minacce e attacchi potenziali. [Leggi di più](https://www.bleepingcomputer.com/news/security/researchers-warn-of-100-000-industrial-control-systems-exposed-online/)\n\n\nCome discusso in un rapporto su Game Is Hard, l'edge computing sta emergendo come un'alternativa notevole alla predominanza di NVIDIA nel mercato dei chip di intelligenza artificiale. Con la crescita dell'edge computing, sempre più aziende stanno esplorando soluzioni di chip di intelligenza artificiale adatte all'elaborazione locale e all'analisi dei dati in tempo reale. Questa tendenza riflette la continua evoluzione del panorama tecnologico dell'intelligenza artificiale e della concorrenza nel mercato, offrendo potenzialmente nuove opzioni e innovazioni per varie industrie al di là del tradizionale punto di forza di NVIDIA. [Leggi di più](https://gameishard.gg/news/the-rise-of-edge-computing-an-alternative-to-nvidias-dominance-in-the-ai-chip-market/282141/)\n\n\nL'articolo del Consiglio Tecnologico di Forbes esplora come l'AI Generativa affronta le lacune di competenze nella convergenza dell'IT industriale e della tecnologia operativa (IoT). Automatizzando compiti, analizzando dati e ottimizzando processi, l'AI Generativa aiuta a colmare il divario tra questi domini tradizionalmente separati. Questa innovativa applicazione della tecnologia AI ha il potenziale per migliorare l'efficienza e la produttività negli ambienti industriali, consentendo un'integrazione e un'operazione più fluida dei sistemi IT e IoT. [Leggi di più](https://www.forbes.com/sites/forbestechcouncil/2023/10/04/how-generative-ai-fills-skills-gaps-for-industrial-itot-convergence/)\n\n## Abbracciando le notizie sulla trasformazione digitale\n\n\n\nQuesta settimana Darren pubblica l'ultimo episodio della serie Embracing Multi-Hybrid Cloud focalizzata sul miglioramento continuo nell'operazionalizzazione di una strategia Cloud. Ascolta su qualsiasi sito di podcasting su Embracing Digital Transformation. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW36-it","image":"./briefs/edw-36/it/thumbnail.png","lang":"it","summary":"Ricevi le ultime notizie sulla Trasformazione Digitale per la settimana dell'8 ottobre 2023. I punti salienti di questa settimana includono un rapporto su MGM Resorts che perde 100 milioni di dollari a causa di un attacco informatico, come l'IA viene utilizzata per assistere le vittime di violenza domestica e l'impatto del Edge computing sui centri dati dell'IA. Sintonizzati per rimanere informato."},{"id":204,"type":"News Brief","title":"2023-10-14","tags":["compute","edge","israelcyberattacks","hamasconflict","redalertsystemapp","powerplantcyberthreats","generativeai","cloudmigration","cmauk","publiccloudinvestigation","avoslocker","ransomeware","criticalinfrastructure","ecybersecurity","embracingdigital","edw37","zerotrustarchitecture"],"body":"\n\n## ## Sicurezza informatica\n\n\nIsraele combatte attacchi informatici durante il conflitto con Hamas. L'applicazione del 'Sistema di Allerta Rosso' è stata compromessa per inviare falsi avvisi e messaggi politici. Anche le centrali elettriche israeliane sono state colpite. Il CEO di Secure Cyber Defense, Shawn Waldman, mette in guardia sui continui rischi informatici, evidenziando recenti informazioni sui tentativi di attacco a infrastrutture critiche negli Stati Uniti da parte di attori stranieri. Egli sottolinea la necessità di proseguire con progressi nel campo della cybersecurity. [Leggi di più](https://www.wdtn.com/as-seen-on-2-news/israeli-cyberwarfare-cyberattacks-infrastructure/)\n\n\nIsraele e Palestina hanno registrato un aumento del traffico internet dopo che Israele ha dichiarato guerra ad Hamas il sette ottobre duemilaventitré. I dati di Cloudflare rivelano che gli attacchi informatici rivolti a Israele sono aumentati, compresi gli attacchi DDoS ai giornali israeliani. In Palestina, si sono verificate interruzioni di internet, potenzialmente legate a black out di energia. Cloudflare sta monitorando queste tendenze e offre strumenti per tracciare i modelli di traffico internet. [Leggi di più](https://blog.cloudflare.com/internet-traffic-patterns-in-israel-and-palestine-following-the-october-2023-attacks/)\n\n\nGli attacchi di ransomware stanno diventando sempre più sofisticati, con i dispositivi di rete che vengono sempre più sfruttati per la distribuzione. Le Informazioni Sanitarie Protette nel settore sanitario rappresentano un obiettivo principale. Le organizzazioni ad alto reddito, specialmente negli Stati Uniti, sono i bersagli preferiti. Nuovi gruppi stanno emergendo e linguaggi come Rust e GoLang stanno venendo adottati. Le organizzazioni stanno potenziando le misure di sicurezza informatica, e Cyble Vision è consigliato per rimanere sempre un passo avanti alle minacce dei ransomware. [Leggi di più](https://thehackernews.com/2023/10/ransomware-attacks-doubled-year-on-year.html)\n\n## ## Edge Computing translates to Italian as \"Elaborazione ai bordi\"\n\n\nIl gruppo AvosLocker ransomware è stato implicato in attacchi contro settori di infrastrutture critiche negli Stati Uniti. Le loro tattiche includono l'uso di software legittimo e strumenti di amministrazione di sistema remoto open-source per compromettere le reti, seguite da minacce di estorsione dei dati. AvosLocker è emerso a metà del 2021 e utilizza tecniche per disabilitare la protezione antivirus, colpendo gli ambienti Windows, Linux e VMware ESXi. Il gruppo è conosciuto per l'uso di strumenti open-source e tattiche LotL (living-off-the-land) per evitare l'identificazione. CISA e l'FBI raccomandano misure di mitigazione per le organizzazioni di infrastrutture critiche, tra cui controlli sulle applicazioni, limitazione dei servizi di desktop remoto, restrizione dell'uso di PowerShell e mantenimento di backup offline. Gli attacchi ransomware sono aumentati notevolmente nel 2023, con gli aggressori che distribuiscono rapidamente ransomware dopo l'accesso iniziale. [Leggi di più](https://thehackernews.com/2023/10/fbi-cisa-warn-of-rising-avoslocker.html)\n\n\nLa NSA ha reso disponibile ELITEWOLF, un repository di firme e analisi sul suo GitHub, al fine di potenziare la sicurezza della Tecnologia Operativa (OT) e contrastare attività cibernetiche dannose che mirano all'infrastruttura critica. Data l'aumentata minaccia per i sistemi OT, la NSA raccomanda ai proprietari e agli operatori delle infrastrutture OT di utilizzare ELITEWOLF come parte di un monitoraggio di sistema vigile. Questa iniziativa segue l'Avviso sulla sicurezza informatica per la protezione delle Tecnologie Operative e dei Sistemi di Controllo dai cyber attacchi. [Leggi di più](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3554537/nsa-releases-a-repository-of-signatures-and-analytics-to-secure-operational-tec/)\n\n\nLa NATO ha promesso di rispondere fermamente a qualsiasi confermato attacco deliberato alle critiche infrastrutture del Mar Baltico. L'impegno arriva in seguito ai danni alle infrastrutture sottomarine nella regione. La Finlandia sta investigando l'incidente, che potrebbe aver coinvolto forze esterne, tra cui la Russia. Se dovesse essere dimostrato che si tratta di un attacco deliberato alle infrastrutture critiche della NATO, l'organizzazione risponderà con un impegno unito e determinato. [Leggi di più](https://news.yahoo.com/attack-alliances-critical-infrastructure-deliberate-073708273.html)\n\n## Tecnologia Cloud\n\n\nL'IA generativa riduce gli sforzi di migrazione verso il cloud del 30-50%, sfruttando grandi modelli di linguaggio (LLM). I LLM possono valutare l'infrastruttura, spostare i carichi di lavoro e verificare l'efficacia della migrazione. Bhargs Srivathsan di McKinsey ha osservato che l'IA generativa e il cloud sono reciprocamente vantaggiosi, poiché il cloud consente l'IA generativa, che a sua volta accelera la migrazione verso il cloud. I LLM possono essere utilizzati per la generazione di contenuti, l'interazione con i clienti, la creazione di dati sintetici e la programmazione. [Leggi di più](https://www.theregister.com/2023/10/11/generative_ai_cloud_migration/)\n\n\nLe imprese con soluzioni tecnologiche locali si trovano di fronte a interruzioni durante il passaggio al cloud completo. Per affrontare questa sfida, l'approccio Cloud Ibrido consente alle aziende di mantenere i servizi principali localmente. Questo approccio aggiunge nuove capacità cloud all'infrastruttura ereditata, riducendo le interruzioni e preservando la tecnologia collaudata. Ad esempio, un Cloud Ibrido può essere utilizzato nelle operazioni del contact center per sovrapporre chat e canali digitali sociali all'infrastruttura esistente, consentendo alle organizzazioni di gestire le fluttuazioni nel volume delle chiamate senza interruzioni significative. [Leggi di più](https://www.techradar.com/pro/why-businesses-should-stop-wondering-about-cloud-and-go-hybrid)\n\n\nL'Autorità per la Concorrenza e il Mercato del Regno Unito (CMA) indaga sul mercato del cloud pubblico per garantire una concorrenza leale per le imprese e i singoli individui. La verifica esaminerà le attività dei fornitori come AWS, Microsoft Azure e Google Cloud per affrontare preoccupazioni riguardanti il comportamento anticoncorrenziale, l'uso dei dati e le barriere di accesso. L'obiettivo della CMA è promuovere l'innovazione, offrire prezzi competitivi e garantire la scelta del cliente. [Leggi di più](https://www.techrepublic.com/article/cma-investigates-uk-public-cloud-market/)\n\n## ## Podcast sull'adozione della trasformazione digitale\n\n\n\nNell'episodio di questa settimana del Podcast sull'Abbraccio alla Trasformazione Digitale, Darren intervista Rachel Driekosen sul modo in cui l'AI viene utilizzata per proteggere i bambini online e portare i responsabili di abusi alla giustizia. Rimanete sintonizzati per una prossima serie sull'Architettura di Fiducia Zero nelle prossime settimane. [Leggi di più](https://www.embracingdigital.org/episode-EDT167-en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW37-it","image":"./briefs/edw-37/it/thumbnail.png","lang":"it","summary":"Trasformazione digitale di questa settimana per il 15 ottobre 2023, riporta gli attacchi informatici in corso durante il conflitto Israele-Hamas e il compromesso dell'app del sistema 'Red Alert'. Inoltre, si è dimostrato che l'IA generativa riduce gli sforzi di migrazione cloud mentre la CMA del Regno Unito indaga sul mercato del cloud pubblico."},{"id":205,"type":"News Brief","title":"2023-10-21","tags":["keywords","ai","compute","cybersecurity","iranianhackers","cybersecuritybreach","ironnetclosure","secretmicrosoft365","cloudtrends","healthcareai","chinachipexports","openai","digitalnews","ubiquitouscomputing","digitaltransformation","dataencryption","aiethics","techindustry","emergingtech","intelinterview","aistrategies","quantumcomputing","datasecurity","techtrends"],"body":"\n\n## Sicurezza informatica\n\n\nGli hacker iraniani sono riusciti a infiltrarsi in una rete governativa del Medio Oriente e rimanere nascosti per otto mesi prima di essere scoperti. L'attacco ha colpito varie agenzie e l'entità dei danni è ancora in fase di valutazione. Gli esperti stanno investigando sull'incidente e sottolineano la necessità di adottare robuste misure di sicurezza informatica per proteggersi da futuri attacchi. La violazione ricorda l'importanza di dare priorità alla sicurezza informatica nel nostro sempre più digitale mondo. [Leggi di più](https://www.securityweek.com/iranian-hackers-lurked-for-8-months-in-government-network/)\n\n\nIl Clark County School District in Nevada ha dovuto ricorrere a compiti su carta e penna dopo un attacco di ransomware che ha interrotto le loro risorse digitali. Il distretto sta lavorando per risolvere il problema e sottolineare la necessità della cibersicurezza per proteggere l'infrastruttura educativa dalle minacce informatiche. [Leggi di più](https://thenevadaindependent.com/article/clark-county-students-back-to-pen-and-paper-assignments-after-cybersecurity-breach)\n\n\nIronNet, una precedente azienda di sicurezza informatica dal valore di un miliardo di dollari, ha chiuso i battenti dopo aver affrontato sfide riguardanti finanziamenti e concorrenza di mercato. L'industria delle tecnologie informatiche per la sicurezza è ancora in una fase di crescita e deve adattarsi alle minacce in continua evoluzione e alle pressioni economiche, evidenziando così l'importanza della resilienza e dell'innovazione. [Leggi di più](https://www.scmagazine.com/news/more-cybersecurity-firm-closures-expected-after-ironnet-shutters)\n\n## Calcolo ubicuo\n\n\nIl Pentagono sta implementando una versione a livello segreto di Microsoft 365, chiamata DOD365-Segreto, per rafforzare le capacità di difesa nazionale. Il nuovo servizio fornirà strumenti sicuri di comunicazione e collaborazione ed è stato testato dall'Agenzia dei Sistemi Informativi per la Difesa (DISA) nell'ultimo anno. Questa iniziativa sottolinea l'impegno del governo nel migliorare la cybersecurity e la protezione dei dati, specialmente in ambienti militari sensibili. [Leggi di più](https://federalnewsnetwork.com/on-dod/2023/10/secret-level-version-of-microsoft-365-rolls-out-to-top-pentagon-offices-this-month/)\n\n\nForbes prevede dieci importanti tendenze del cloud computing che plasmeranno l'industria nel 2024. Queste tendenze includono calcolo periferico, sicurezza informatica, calcolo senza server, integrazione dell'IA, adozione ibrida e multicloud, pratiche sostenibili di cloud, calcolo quantistico, analisi dei dati e sviluppo nativo del cloud. È importante che le aziende e i professionisti IT si tengano aggiornati su queste tendenze per navigare il panorama in continua evoluzione del cloud. [Leggi di più](https://www.forbes.com/sites/bernardmarr/2023/10/09/the-10-biggest-cloud-computing-trends-in-2024-everyone-must-be-ready-for-now/?sh=2093527266d6)\n\n## Intelligenza Artificiale\n\n\nIl giorno Q è in arrivo. I computer quantistici potrebbero presto diventare abbastanza potenti da violare gli algoritmi di crittografia che proteggono le nostre informazioni digitali oggi. Ciò minaccia la sicurezza dei dati, quindi i governi e le aziende tecnologiche stanno investendo nella crittografia e nella tecnologia resistente ai quanti per proteggersi da questo pericolo.L'Organizzazione Mondiale della Sanità (OMS) ha delineato considerazioni per regolamentare l'intelligenza artificiale (IA) nel settore sanitario, secondo la loro comunicazione del 19 ottobre 2023. Questa guida enfatizza l'importanza dell'etica, della trasparenza, della privacy dei dati e della responsabilità nelle applicazioni di IA per la salute. Affronta il crescente ruolo dell'IA nella sanità e la necessità di un quadro che ne assicuri un uso responsabile ed etico. [Leggi di più](https://www.who.int/news/item/19-10-2023-who-outlines-considerations-for-regulation-of-artificial-intelligence-for-health)\n\n\n\nIl New York Times riporta sulle restrizioni della Cina all'esportazione di chip di intelligenza artificiale. Queste restrizioni mirano a preservare la sicurezza nazionale e l'indipendenza tecnologica, influenzando le catene di approvvigionamento tecnologico globali. Con l'IA che svolge un ruolo sempre più cruciale in vari settori, questa mossa riflette gli sforzi della Cina nel cercare di affermare il controllo sulla tecnologia avanzata e solleva preoccupazioni sul dinamismo globale del commercio tecnologico. [Leggi di più](https://www.nytimes.com/2023/10/17/business/economy/ai-chips-china-restrictions.html)\n\n\nSecondo il giornale online The Information, OpenAI avrebbe interrotto lo sviluppo di un nuovo modello di intelligenza artificiale chiamato \"Arrakis\", segnando una rara battuta d'arresto per l'organizzazione. La decisione suggerisce la complessità e le sfide nello sviluppo di modelli avanzati di intelligenza artificiale e sottolinea l'importanza della ricerca e dello sviluppo responsabili ed etici nell'ambito dell'IA. [Leggi di più](https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback)\n\n## Notizie sul Podcast sull'Abbraccio alla Trasformazione Digitale\n\nNella sua serie \"Abbracciando l'IA generativa\", Darren presenta un'intervista con Andy Morris, stratega capo dell'IA presso Intel. L'intervista approfondisce il tema dell'IA generativa quotidiana ed esplora vari strumenti che possono essere utili alle persone nella loro vita quotidiana. È una conversazione informativa che mette in luce l'impatto dell'IA nella nostra vita quotidiana e come possiamo sfruttarla a nostro vantaggio. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW38-it","image":"./briefs/edw-38/it/thumbnail.png","lang":"it","summary":"Abbracciando le notizie digitali per la settimana del 22 ottobre 2023, incluse notizie sulla sicurezza informatica, l'informatica pervasiva e l'intelligenza artificiale. I momenti salienti di questa settimana includono il ritorno alla penna e alla carta nella distribuzione scolastica, l'attenzione per il Q-Day e le linee guida sull'IA nella sanità."},{"id":206,"type":"News Brief","title":"2023-10-28","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Sicurezza informatica\n\n\nKaspersky riferisce di un nuovo malware, chiamato \"Elegant\", che presenta avanzate capacità di spionaggio e ha somiglianze con gli strumenti di hacking collegati alla NSA. L'azienda di sicurezza informatica non ha attribuito il malware a un attore minaccioso specifico, ma la sua scoperta mette in evidenza la necessità di robuste misure di sicurezza informatica di fronte agli attacchi cibernetici sponsorizzati dallo Stato. [Leggi di più](https://cyberscoop.com/kaspersky-reveals-elegant-malware-resembling-nsa-code/)\n\n\n\nCISA e HHS hanno lanciato un kit di strumenti per la sicurezza informatica destinato alle organizzazioni sanitarie. Il kit mira a migliorare la postura della sicurezza informatica del settore offrendo risorse preziose e orientamenti per mitigare le minacce informatiche. L'obiettivo è rafforzare la sicurezza delle infrastrutture sanitarie critiche, data l'aumento del numero di rischi informatici e degli attacchi di ransomware agli ospedali di recente. Per saperne di più, visitare la pagina delle news di CISA. [Leggi di più](https://www.cisa.gov/news-events/news/cisa-hhs-release-collaborative-cybersecurity-healthcare-toolkit)\n\n\nLa California ha implementato nuove normative sulla sicurezza informatica che includono valutazioni dei rischi, piani di risposta agli incidenti, crittografia dei dati e autenticazione a più fattori. È fondamentale che le aziende in California si conformino a queste norme, in quanto la mancata conformità potrebbe comportare sanzioni e conseguenze legali. Resta informato controllando gli aggiornamenti sul sito web della sicurezza informatica della California. [Leggi di più](https://www.armstrongteasdale.com/thought-leadership/californias-newest-cybersecurity-rule-what-you-need-to-know/)\n\n## Elaborazione Edge\n\n\nIl Parlamento del Regno Unito sta indagando sulla sicurezza informatica delle infrastrutture critiche, compreso l'energia, il trasporto e l'assistenza sanitaria. L'inchiesta mira a valutare la preparazione e la resilienza di questi settori contro le potenziali minacce informatiche. Questa mossa arriva in un momento di crescente preoccupazione per la vulnerabilità dei servizi essenziali agli attacchi informatici. Sottolinea l'importanza di proteggere i servizi vitali dalle minacce digitali in un mondo interconnesso. Il recente conflitto tra Israele e Hamas sottolinea la necessità di tutelare le infrastrutture critiche dalle minacce informatiche. [Leggi di più](https://www.bankinfosecurity.com/uk-parliament-probes-critical-infrastructure-cybersecurity-a-23400)\n\n\nTenable e Siemens Energy stanno collaborando per migliorare la cibersicurezza industriale. La collaborazione unirà l'esperienza di Tenable nella cibersicurezza alla conoscenza di dominio di Siemens Energy per fornire soluzioni di sicurezza avanzate per l'infrastruttura critica. L'obiettivo è rafforzare la protezione dei sistemi energetici essenziali contro le minacce cibernetiche in continuo sviluppo. L'importanza di proteggere l'infrastruttura critica in un mondo sempre più interconnesso non può essere enfatizzata abbastanza. [Leggi di più](https://finance.yahoo.com/news/tenable-siemens-energy-expand-collaboration-130000076.html)\n\n\nLe banche di Singapore DBS e Citibank hanno subito un'interruzione del servizio a causa di un guasto al sistema di refrigerazione nel loro data center condiviso. L'incidente ha interrotto i servizi bancari e ha causato disagi ai clienti. Questi incidenti sottolineano l'importanza di un'infrastruttura robusta per i data center al fine di garantire servizi finanziari ininterrotti. Le banche hanno successivamente ripristinato i loro servizi, sottolineando il ruolo critico della tecnologia nelle operazioni bancarie moderne. [Leggi di più](https://www.channelnewsasia.com/singapore/dbs-citibank-outage-data-centre-cooling-system-down-3861076)\n\n## Calcolo Ubiquo\n\n\nAmazon ha lanciato un servizio cloud indipendente per l'Europa per rispondere alle crescenti preoccupazioni sulla privacy dei dati e ai requisiti normativi. Il nuovo servizio cloud mira a fornire una sovranità e sicurezza dei dati potenziata ai clienti europei, consentendo alle organizzazioni di sfruttare il cloud computing in modo più localizzato e conforme. [Leggi di più](https://www.euronews.com/next/2023/10/25/amazon-rolls-out-new-independent-cloud-for-europe)\n\n\nGli Stati Uniti e l'Australia stanno collaborando nello sviluppo di avanzati chip quantistici. Questa partnership sottolinea l'incremento dell'importanza dell'informatica quantistica nella sicurezza nazionale e nel progresso tecnologico. Poiché i paesi cercano di preservare il loro primato in questo campo critico di ricerca e sviluppo, sforzi congiunti come questi stanno diventando sempre più comuni. La collaborazione dimostra l'approfondimento della cooperazione tra le due alleate nel campo della scienza e della tecnologia. [Leggi di più](https://foreignpolicy.com/2023/10/25/quantum-computing-united-states-australia-cooperation-allies-science-technology-chips/)\n\n\nUn recente rapporto ha scoperto che quaranta per cento delle imprese sta perdendo ricavi a causa di inattività tecnologica e gestione dei servizi cloud. Questo sottolinea l'importanza di un'infrastruttura IT robusta e di una gestione cloud ottimizzata. Affrontare l'inattività e semplificare le operazioni cloud è fondamentale per garantire un'attività aziendale ininterrotta e massimizzare i ricavi. Leggi di più nel rapporto su cloud-computing news. [Leggi di più](https://www.cloudcomputing-news.net/news/2023/oct/24/40-of-firms-lose-revenue-from-technology-downtime-and-cloud-complexity/)\n\n## Podcast sull'abbraccio alla trasformazione digitale.\n\n\n\nUna nuova serie chiamata \"Abbracciando lo Zero Trust\" inizia questa settimana. La Dott.ssa Anna Scott e Dave Marcus, che sono ospiti speciali, descriveranno le sei colonne portanti dello Zero Trust e come possono essere utilizzate nell'infrastruttura esistente. Nel frattempo, \"Abbracciando l'IA generativa\" di Darren continua con Sunny Stueve, un esperto di Fattori Umani proveniente da Leidos. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW39-it","image":"./briefs/edw-39/it/thumbnail.png","lang":"it","summary":"Nell'ultima edizione del nostro Embracing Digital di questa settimana, ti portiamo gli ultimi sviluppi e le storie nel mondo della sicurezza informatica, del calcolo periferico e del calcolo ubiquo. In questa puntata, affrontiamo un nuovo malware chiamato Elegant, le regolamentazioni sulla sicurezza informatica in California, l'indagine del Parlamento britannico sulla sicurezza informatica delle infrastrutture critiche e altre notizie interessanti dal settore tecnologico."},{"id":207,"type":"News Brief","title":"2023-2-26","tags":null,"body":"\n\n## Intelligenza Artificiale\n\nOpenAI e Bain & Company hanno formato la Global AI Services Alliance per trasformare il potenziale commerciale. Bain combinerà le sue profonde capacità di implementazione digitale e la sua competenza strategica con gli strumenti e le piattaforme di AI di OpenAI, compreso ChatGPT, per aiutare i propri clienti in tutto il mondo a identificare e implementare il valore di AI per massimizzare il potenziale commerciale. The Coca-Cola Company è la prima azienda a collaborare con la nuova alleanza.\n\nL'unità cloud di Amazon si è associata con Hugging Face, produttore del concorrente ChatGPT. Hugging Face costruirà la prossima versione del suo modello di linguaggio, chiamato BLOOM, su AWS.\n\n[https://www.seattletimes.com/business/amazons-cloud-unit-partners-with-hugging-face-maker-of-chatgpt-rival/](https://www.seattletimes.com/business/amazons-cloud-unit-partners-with-hugging-face-maker-of-chatgpt-rival/)\n\nL'AI può essere utilizzata per fare del bene effettivo nel mondo. L'IA sta progettando farmaci che nessuno ha mai visto. Ora dobbiamo vedere se funzionano. I primi farmaci progettati con l'aiuto dell'IA sono ora in prove cliniche, i rigorosi test effettuati su volontari umani per vedere se un trattamento è sicuro e funziona, prima che i regolatori li autorizzino per un uso diffuso.\n\n[https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development](https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development)\n\n## Bordo intelligente\n\nSono stati trovati difetti di sicurezza in dispositivi wireless per l'IoT industriale di quattro fornitori, creando una significativa superficie di attacco per gli attori delle minacce che cercano di sfruttare gli ambienti della tecnologia operativa (OT). Le lacune offrono punti di ingresso per attacchi remoti, permettendo ad avversari non autenticati di ottenere una posizione e usarla come leva per diffondersi su altri host, causando danni seri.\n\n[https://thehackernews.com/2023/02/critical-infrastructure-at-risk-from.html](https://thehackernews.com/2023/02/critical-infrastructure-at-risk-from.html)\n\nLa Connectivity Standards Alliance (CSA) ha formato un gruppo di lavoro dedicato a promuovere l'adozione di \"Matter\" per scopi sanitari. Matter è uno standard interoperabile per dispositivi smart per la casa rilasciato dalla CSA lo scorso anno. Il gruppo di lavoro sulla salute e il benessere allineerà i principali contributori del settore sanitario intorno allo standard Matter per garantire dispositivi sicuri e interoperabili per la salute e il benessere.\n\n[https://www.iottechnews.com/news/2023/feb/10/matter-creator-csa-announces-healthcare-working-group/](https://www.iottechnews.com/news/2023/feb/10/matter-creator-csa-announces-healthcare-working-group/)\n\nI Robo-taxi della divisione di veicoli a guida autonoma di Amazon, Zoox, sono ora sulle strade di Foster City, in California. I veicoli di Zoox sono costruiti appositamente per la guida autonoma e non presentano alcun controllo manuale. I dipendenti a tempo pieno dell'azienda sono i primi a utilizzare il servizio navetta autonomo tra i loro campus. Ciò richiede una fiducia assoluta nella qualità del lavoro del tuo team!\n\n[https://www.iottechnews.com/news/2023/feb/14/amazon-robotaxis-hit-the-streets-of-california/](https://www.iottechnews.com/news/2023/feb/14/amazon-robotaxis-hit-the-streets-of-california/)\n\n## Gestione dei dati\n\nIn uno studio recente di Informatica sulla diffusione dei dati, Informatica ha scoperto che la dispersione dei dati e la necessità di una gestione unificata sono problemi diffusi per molte organizzazioni. Inoltre, la qualità dei dati e la governance sono priorità assolute. Ciò sta portando ad un aumento degli investimenti nelle tecnologie dei dati quest'anno. La ricerca basata su sondaggi ha rivelato che il 78% dei CDO ha dichiarato di dover allinearsi strategicamente con le organizzazioni che generano entrate per giustificare la spesa aggiuntiva per migliorare l'analisi e la governance dei dati.\n\n[https://accelerationeconomy.com/data/informatica-research-highlights-data-sprawl-why-management-needs-to-be-unified/](https://accelerationeconomy.com/data/informatica-research-highlights-data-sprawl-why-management-needs-to-be-unified/)\n\nAlation Inc., un fornitore di soluzioni di intelligenza sui dati aziendali, ha rilasciato Alation Marketplaces. Questo nuovo prodotto consente ai set di dati di terze parti di integrare i dati esistenti nel Catalogo dati di Alation, consentendo agli utenti di esplorare dati di terze parti esterne e integrare set di dati esistenti. Inoltre, l'azienda ha ampliato Alation Anywhere per Microsoft Teams e Alation Connected Sheets per Microsoft Excel per consentire agli utenti di accedere alle informazioni contestuali dal catalogo direttamente nel loro strumento preferito.\n\n[https://www.alation.com/press-releases/alation-launches-data-marketplaces/](https://www.alation.com/press-releases/alation-launches-data-marketplaces/)\n\n\n\n","guests":null,"link":"/brief-EDW4-it","image":"./briefs/edw-4/it/thumbnail.png","lang":"it","summary":"Summary"},{"id":208,"type":"News Brief","title":"2023-11-11","tags":["homelawncaretools","ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n\n## Sicurezza informatica\n\n\n\nI porti australiani stanno affrontando un cyberattacco, che influisce sulle operazioni di DP World. L'attacco al gigante delle spedizioni ha provocato interruzioni nei movimenti di container. Sebbene l'estensione e l'origine della violazione siano in fase di indagine, solleva preoccupazioni sulla vulnerabilità delle infrastrutture critiche alle minacce informatiche. Le autorità stanno lavorando per ripristinare la normalità, poiché l'incidente sottolinea la crescente importanza della sicurezza informatica nella salvaguardia dei servizi essenziali. [Leggi di più](https://www.bloomberg.com/news/articles/2023-11-11/australian-authorities-meet-as-dp-world-shuts-ports-on-cyber-act)\n\n\nICBC, la banca più grande del mondo, è stata vittima di un attacco di ransomware. La violazione ha interrotto le operazioni, compromettendo i servizi clienti. Mentre si valuta l'entità dell'attacco, sottolinea la crescente minaccia della criminalità informatica per le istituzioni finanziarie. L'ICBC sta lavorando per contenere la violazione e ripristinare la normalità, sottolineando la necessità di solide misure di sicurezza informatica nel settore bancario mondiale. [Leggi di più](https://www.cnbc.com/2023/11/10/icbc-the-worlds-biggest-bank-hit-by-ransomware-cyberattack.html)\n\n\nGli attacchi cibernetici stanno supportando attacchi cinetici! Il gruppo russo di hacker SandWorm è implicato in un attacco cibernetico che ha interrotto l'approvvigionamento energetico in Ucraina. L'attacco sofisticato ha preso di mira l'infrastruttura energetica, causando interruzioni diffuse. Le autorità ucraine stanno indagando sull'incidente, sottolineando la minaccia in corso degli attacchi cibernetici sponsorizzati dallo stato alle infrastrutture critiche. La situazione sottolinea la necessità di misure di sicurezza informatica migliorate per salvaguardare i servizi essenziali. [Leggi di più](https://thehackernews.com/2023/11/russian-hackers-sandworm-cause-power.html)\n\n## Intelligenza Artificiale\n\n\nGli esperti di Intelligenza Artificiale stanno mettendo in guardia sulla potenziale carenza di dati, sottolineando la riduzione delle risorse di dati mondiali per alimentare l'intelligenza artificiale. La crescita esponenziale delle applicazioni di IA e dei modelli affamati di dati sta superando la generazione di dati. Questa scarsità potrebbe ostacolare ulteriori progressi dell'IA, stimolando la necessità di approcci innovativi alla raccolta e alla sintesi dei dati. La sfida sottolinea l'importanza di uno sviluppo responsabile e sostenibile dell'Intelligenza Artificiale. [Leggi di più](https://www.sciencealert.com/the-world-is-running-out-of-data-to-feed-ai-experts-warn)\n\n\nLa proliferazione dell'intelligenza artificiale minaccia la democrazia! avvertono gli esperti alla conferenza Reuters Next. Il rapido progresso dell'intelligenza artificiale solleva preoccupazioni riguardo al suo potenziale abuso per la sorveglianza, la manipolazione e l'erosione dei valori democratici. Gli esperti chiedono linee guida etiche, quadri normativi e un dibattito pubblico per mitigare i rischi associati all'aumento dell'influenza dell'intelligenza artificiale sulla politica e sulla società. [Leggi di più](https://www.reuters.com/technology/reuters-next-rapid-ai-proliferation-is-threat-democracy-experts-say-2023-11-08/)\n\n\nIn un'intervista, Barack Obama ha espresso preoccupazione per l'impatto dell'intelligenza artificiale (IA) sui lavori. Riconosce il potenziale di spostamento di lavoro dovuto all'automazione e sottolinea la necessità di politiche per affrontare queste sfide. Obama suggerisce di investire in educazione e programmi di riqualificazione per preparare la forza lavoro per i mercati del lavoro in evoluzione plasmati da IA e automazione. [Leggi di più](https://www.independent.co.uk/tv/news/barack-obama-biden-ai-jobs-b2445354.html)\n\n## Calcolo Ubiquitario\n\n\nUna scoperta nel campo della computazione quantistica integra l'intelligenza artificiale e l'apprendimento automatico per una robusta correzione degli errori dei qubit. Gli scienziati hanno sviluppato un approccio al calcolo quantistico potenziato dall'intelligenza artificiale che migliora la correzione degli errori per i qubit, una sfida cruciale nella computazione quantistica. Questa innovativa combinazione di intelligenza artificiale e tecnologia quantistica promette di avanzare l'affidabilità e le prestazioni dei computer quantistici. [Leggi di più](https://scitechdaily.com/ai-enhanced-quantum-computing-machine-learning-powers-robust-qubit-error-correction/)\n\n\nIl Gruppo Software Cloud, la società madre di Citrix, sta interrompendo le nuove transazioni commerciali in Cina, compresi Hong Kong e Macao, a partire dal tre dicembre. Citando il \"costo crescente\" dell'operatività nella regione, la decisione segue mosse simili da altre aziende tecnologiche americane in mezzo a un outlook economico più debole e regolamentazioni più severe sulla sicurezza dei dati in Cina. Mentre sempre più aziende statunitensi lasciano la Cina, Pechino ha proposto di allentare i controlli sulla sicurezza dei dati transfrontalieri per attrarre investitori stranieri. [Leggi di più](https://finance.yahoo.com/news/citrix-owner-cloud-software-becomes-093000327.html)\n\n\nUn recente articolo di Analytics Insights prevede le tendenze del cloud computing per il duemilaventicinque. Queste includono l'importanza del computing edge per un elaborazione dei dati più veloce, l'ascesa delle strategie multi-cloud per la flessibilità, e l'integrazione di intelligenza artificiale/machine learning per un'analisi dei dati ottimizzata. Misure di sicurezza come l'architettura di zero trust saranno una priorità per affrontare l'evoluzione del panorama delle minacce. [Leggi di più](https://www.analyticsinsight.net/cloud-trends-for-2024-whats-on-for-cloud-computing/)\n\n## Podcast Abbracciando la Trasformazione Digitale\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW41-it","image":"./briefs/edw-41/it/thumbnail.png","lang":"it","summary":"Abbracciando il digitale. Questa settimana del 12 novembre 2023, incluso notizie sulla cybersecurity, intelligenza artificiale e calcolo ubiquitario. Scopri di vari importanti attacchi cibernetici su infrastrutture critiche, l'intelligenza artificiale che sta esaurendo i dati e progressi nel calcolo quantistico."},{"id":209,"type":"News Brief","title":"2023-11-18","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n\n## Cibersicurezza\n\n\nL'Agenzia per la Sicurezza delle Infrastrutture e della Cybersecurity (CISA) intende far rispettare la responsabilità esecutiva nella sicurezza del software per gli acquisti governativi. L'iniziativa mira a far sottoscrivere agli esecutivi la sicurezza del software venduto al governo. Questa mossa fa parte degli sforzi della CISA per potenziare le misure di cybersecurity e garantire l'integrità del software utilizzato nei sistemi governativi critici. [Leggi di più](https://federalnewsnetwork.com/cybersecurity/2023/11/cisa-aims-to-make-executives-sign-off-on-security-of-software-sold-to-government/)\n\n\nLe agenzie statunitensi per la cybersecurity emettono un avvertimento riguardo una nuova minaccia di ransomware che prende di mira le infrastrutture critiche. L'allarme sottolinea i potenziali rischi e incoraggia le organizzazioni a migliorare i loro protocolli di cybersecurity. Le agenzie enfatizzano l'importanza di misure proattive, tra cui l'aggiornamento regolare del software e l'adozione di pratiche di sicurezza robuste per mitigare il rischio di attacchi ransomware. [Leggi di più](https://thehackernews.com/2023/11/us-cybersecurity-agencies-warn-of.html)\n\n\n\nSolarWinds affronta una causa legale da parte della Securities and Exchange Commission (SEC) a seguito del cyberattacco del duemilaventi. La SEC sostiene che l'azienda non abbia rivelato le vulnerabilità, traviando gli investitori. SolarWinds, nota per il suo software di gestione IT, ha subito un attacco alla catena di approvvigionamento di alto profilo. La causa sottolinea l'attenzione crescente sugli obblighi di divulgazione sulla sicurezza informatica e le potenziali conseguenze legali per le aziende che affrontano in modo inadeguato tali incidenti. [Leggi di più](https://www.nytimes.com/2023/11/18/business/dealbook/solarwinds-sec-lawsuit.html)\n\n## Intelligenza Artificiale\n\n\nIl CEO di OpenAI, Sam Altman, si dimette tra crescenti preoccupazioni sulla direzione dell'azienda. La partenza di Altman segue tensioni interne e dimissioni legate all'attenzione dell'azienda verso le applicazioni commerciali piuttosto che il suo impegno iniziale verso i benefici dell'IA a livello generale. La mossa solleva interrogativi circa l'equilibrio tra gli interessi aziendali e le considerazioni etiche nello sviluppo dell'IA. [Leggi di più](https://www.washingtonpost.com/technology/2023/11/17/openai-ceo-resigns/)\n\n\nGli ultimi avvenimenti legati all'IA di Microsoft sottolineano tre punti chiave. Prima di tutto, l'azienda enfatizza il suo impegno verso lo sviluppo responsabile dell'IA, concentrando l'attenzione su equità, trasparenza e responsabilità. In secondo luogo, Microsoft intende potenziare gli sviluppatori con strumenti come GPT di OpenAI, che offre avanzate capacità di linguaggio naturale. Infine, l’evento sottolinea la dedizione di Microsoft all'innovazione guidata dall'IA attraverso le industrie, esponendo applicazioni riguardanti sanità, finanza e scienze climatiche. [Leggi di più](https://www.cnbc.com/2023/11/17/here-are-three-key-takeaways-from-microsofts-bullish-ai-event-.html)\n\n\nYouTube affronta la sfida dei contenuti deepfake poiché i creatori di intelligenza artificiale producono video sempre più convincenti e ingannevoli. La piattaforma lotta per distinguere tra utilizzi innocui e malintenzionati dei contenuti generati dall'intelligenza artificiale. YouTube riconosce la necessità di vigilanza e un approccio completo per affrontare i deepfake al fine di mantenere l'integrità dei suoi contenuti. Ora si chiede ai creatori di contenuti di verificare se il contenuto è generato da un'intelligenza artificiale o no. [Leggi di più](https://apnews.com/article/youtube-artitifical-intelligence-deep-fake-ai-creaters-0513fd9fddbd93af327f0411dd29ff3d)\n\n## Calcolo Ubiquitario\n\n\n\nAmazon e Microsoft si confrontano in una feroce competizione per lucrativi contratti governativi di cloud computing, poiché le agenzie federali si affidano sempre più ai servizi cloud. Le aziende stanno contendendo il contratto del Dipartimento della Difesa denominato Joint Warfighter Cloud Capability (JWCC), un affare potenzialmente del valore di dieci miliardi di dollari. Questa battaglia riflette la tendenza più ampia dei giganti della tecnologia a competere per contratti governativi di cloud e sottolinea l'importanza strategica dei servizi cloud nella modernizzazione dell'infrastruttura governativa. [Leggi di più](https://www.bloomberg.com/news/articles/2023-11-16/amazon-amzn-microsoft-msft-fight-for-cloud-computing-government-contracts)\n\n\nLa Marina degli Stati Uniti sta potenziando i suoi sistemi di siluri sfruttando il cloud computing per i sottomarini. Questo aggiornamento punta a migliorare le prestazioni e le capacità dei siluri. La Marina cerca di potenziare l'elaborazione e l'analisi dei dati utilizzando il cloud computing, permettendo operazioni di siluri più sofisticate ed efficienti. Questa mossa riflette gli sforzi in corso dell'esercito per integrare tecnologie avanzate, come il cloud computing, per rafforzare le capacità dei suoi sistemi navali. [Leggi di più](https://www.defensenews.com/naval/2023/11/16/us-navy-upgrading-torpedoes-leveraging-cloud-computing-for-submarines/)\n\n\nIl governo degli Stati Uniti mette in allarme Alibaba per preoccupazioni legate al potenziale abuso di microchip di produzione americana nella sua tecnologia di sorveglianza. La mossa fa parte del più ampio sforzo di limitare le esportazioni di tecnologie sensibili per questioni di sicurezza nazionale. Questo sviluppo sottolinea l'esame delle aziende tecnologiche cinesi. Evidenzia l'attenzione del governo americano nel prevenire l'uso involontario della tecnologia americana in modi che potrebbero compromettere la sicurezza o i diritti umani. [Leggi di più](https://finance.yahoo.com/news/alibaba-flagged-us-chip-curbs-192349433.html)\n\n## Notizie sul Podcast sulla Trasformazione Digitale Accettata\n\n\n\nGuarda le tre serie intitolate \"Abbracciando l'IA Generativa\", \"Abbracciando Zero Trust\" e \"Abbracciando la Multi-Hybrid Cloud\". In queste serie, Darren esplora il mondo dell'IA con ospiti provenienti dall'industria, dall'educazione e persone comuni, invita esperti in sicurezza informatica a parlare della protezione del mondo digitale e fa ricerche nel cielo per le più recenti strategie e tecnologie cloud. [Leggi di più](https://www.embracingdigital.org/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW42-it","image":"./briefs/edw-42/it/thumbnail.png","lang":"it","summary":"Trasformazione Digitale per la Cybersecurity, l'IA e il Calcolo nella settimana del 19 Novembre 2023. I temi includono le implicazioni legali della cybersecurity, l'addio di Sam Altman da OpenAI e i fornitori di cloud in competizione per i contratti governativi."},{"id":210,"type":"News Brief","title":"2023-11-25","tags":["uniquehandmadewoodfurniture.","ai","compute","cybersecurity","samaltman","openai","aibreakthrough","neuralchat7b","intel","responsibleai","meta","hacking","insiderthreats","securitymeasures","eucybersecurityregulations","clearfake","malware","ubiquitouscomputing","macstadium","m2prochip","alibabacloud","cloudcomputing"],"body":"\n\n\n## Intelligenza Artificiale\n\n\nSam Altman ha lasciato OpenAI dopo una lettera che esprimeva preoccupazioni riguardo a una scoperta di intelligenza artificiale non rivelata. La lettera, inviata da un dipendente anonimo, ha portato alla rimozione di Altman come amministratore delegato. I dettagli della scoperta rimangono riservati, sollevando domande sulla dinamica interna di OpenAI. Altman è stato reintegrato quando settecento dei settecentosettanta dipendenti lo hanno seguito a Microsoft. [Leggi di più](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/)\n\n\nIntel ha sviluppato il NeuralChat sette B, un modello di chatbot che dà priorità alla protezione dei dati dell'utente. Il modello è addestrato utilizzando l'Ottimizzazione della Privacy Differenziale (DPO) per potenziare le salvaguardie della privacy. Implementando la DPO, Intel mira a garantire interazioni sicure all'interno del chatbot e a mitigare i rischi per la privacy. Questi sforzi si allineano con gli standard in evoluzione per lo sviluppo responsabile dell'IA. [Leggi di più](https://medium.com/@bnjmn_marie/neuralchat-7b-intels-chat-model-trained-with-dpo-e691dfd52591)\n\n\nMeta, la società madre di Facebook, avrebbe apparentemente sciolto il suo team Responsabile per l'IA, suscitando preoccupazioni riguardo al suo impegno nelle pratiche etiche dell'IA. I critici sostengono che lo smantellamento del team potrebbe minare gli sforzi per affrontare le preoccupazioni etiche e i possibili pregiudizi nelle tecnologie IA di Meta, sottolineando il dibattito in corso sulla responsabilità dello sviluppo dell'IA. [Leggi di più](https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence)\n\n## Sicurezza informatica\n\n\nUn dirigente di un'azienda di cybersecurity ha ammesso di aver hackerato gli ospedali in una sorprendente svolta degli eventi. Il dirigente, precedentemente incaricato di salvaguardare i sistemi, ha ammesso di aver sfruttato le vulnerabilità per guadagno personale. La violazione solleva serie domande sulle minacce interne e sulla necessità di robuste misure di sicurezza all'interno del settore della cybersecurity stesso. L'ammissione di colpevolezza sottolinea l'imperativo di protocolli di cybersecurity rigorosi e di una condotta etica, specialmente quando si è incaricati di proteggere infrastrutture critiche come le istituzioni sanitarie. [Leggi di più](https://www.bleepingcomputer.com/news/security/cybersecurity-firm-executive-pleads-guilty-to-hacking-hospitals/)\n\n\nL'UE prevede di espandere le normative sulla sicurezza informatica per coprire settori critici come l'energia, i trasporti e i fornitori di servizi digitali come Amazon, Google e Microsoft. Questo per rafforzare la sicurezza informatica attraverso diverse industrie a causa dell'aumento delle minacce informatiche. Tuttavia, alcuni vedono le nuove regolamentazioni come un modo per catturare entrate da Big Tech. [Leggi di più](https://www.finextra.com/newsarticle/43338/eu-considers-widening-scope-of-cybersecurity-regulation)\n\n\nÈ stato scoperto un nuovo malware chiamato ClearFake che prende di mira gli utenti Mac. Si maschera come un'app antivirus legittima, ingannando gli utenti a scaricare software dannosi. Gli esperti mettono in guardia sul potenziale furto di dati e compromissione del sistema. È fondamentale essere prudenti e utilizzare software di sicurezza affidabili per contrastare le minacce in evoluzione che prendono di mira le piattaforme macOS. [Leggi di più](https://cybersecuritynews.com/clearfake-new-malware-mac/)\n\n## Calcolo Ubiquitario\n\n\nIl nuovo Mac Cloud di MacStadium, alimentato dal chip M2 Pro, offre prestazioni avanzate e capacità per gli sviluppatori di macOS e le aziende. Risponde alla crescente domanda di sviluppo Mac basato su Kubernetes negli ambienti cloud, soddisfacendo le esigenze uniche della comunità di sviluppatori Apple. Il chip M2 Pro migliora significativamente le capacità di hosting Mac, fornendo velocità ed efficienza migliorate. [Leggi di più](https://finance.yahoo.com/news/macstadium-unveils-powerful-next-generation-120000257.html)\n\n\n\nAlibaba ha aggiunto tre nuovi dirigenti alla sua divisione di cloud computing, indicando il suo impegno a potenziare il suo business nel cloud. I dirigenti apportano competenze diversificate al competitivo mercato del cloud computing e promuoveranno l'innovazione e la crescita. L'attenzione di Alibaba sui servizi cloud si allinea alle crescenti esigenze del paesaggio digitale, rafforzando la sua determinazione a mantenere una posizione di leadership nel settore globale del cloud computing. [Leggi di più](https://www.proactiveinvestors.com.au/companies/news/1034236/alibaba-taps-three-new-cloud-computing-executives-after-nixing-spinoff-ipo-plans-1034236.html)\n\n\nSecondo quanto riportato, l'Europa è in ritardo nella corsa globale all'IA e deve spostare l'attenzione sul calcolo quantistico per rimanere competitiva. Investire nella tecnologia quantistica trasformativa è imperativo per l'Europa per riconquistare la sua leadership tecnologica e affrontare l'evoluzione del panorama globale dell'innovazione. [Leggi di più](https://www.euronews.com/next/2023/11/23/europe-has-lost-the-ai-race-it-cant-ignore-the-quantum-computing-one)\n\n## Podcast sull'Abbracciare la Trasformazione Digitale\n\n\n\nQuesta settimana, Darren è tornato dopo una settimana di pausa per il Ringraziamento. Ha intervistato Louis Parks, l'amministratore delegato di Veridify, dove ha rivelato le vulnerabilità dell'infrastruttura critica della tecnologia operativa. Inoltre, dai un'occhiata al nuovo marchio e ai loghi di Abbracciando la Trasformazione Digitale. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW43-it","image":"./briefs/edw-43/it/thumbnail.png","lang":"it","summary":"Notizie sulla Trasformazione Digitale per la settimana del 26 novembre 2023. Dalle trasformazioni radicali nella leadership dell'intelligenza artificiale all'imperativo focus sulla cybersecurity e alla presentazione di avanzate soluzioni informatiche, questa raccolta riassume momenti cruciali nell'evoluzione costante del panorama tecnologico. Unisciti a noi mentre indaghiamo le complessità degli sviluppi recenti, illuminando gli impatti profondi che hanno attraverso settori e guidando la traiettoria del futuro digitale."},{"id":211,"type":"News Brief","title":"2023-12-2","tags":["ai","compute","datamanagement","aws","siemens","industrialdge","cloudconfiguration","multiaccessedgecomputing","mec","networkarchitecture","iot","realtimeapplications","edgecomputinginhealthcare","healthcaremarket","polarismarketresearch","usda","datastrategy","digitalgovernance","vastdata","aiworkflows"],"body":"\n\n\n## Calcolo edge\n\n\nAmazon Web Services (AWS) e Siemens hanno unito le forze per semplificare la configurazione industriale dal edge al cloud. La collaborazione mira a semplificare l'integrazione dei dispositivi edge con i servizi cloud, aumentando l'efficienza in ambienti industriali. La partnership combina AWS IoT Greengrass e la piattaforma Industrial Edge di Siemens, fornendo una soluzione fluida per configurare, gestire e ottimizzare i dispositivi edge nel cloud. Questa collaborazione si prefigge di facilitare una connettività industriale dal edge al cloud più fluida e accessibile. [Leggi di più](https://www.edgecomputing-news.com/2023/12/01/aws-and-siemens-team-up-for-easier-industrial-edge-to-cloud-configuration/)\n\n\n\nIl Multi-Access Edge Computing (MEC) è un'architettura di rete che avvicina le capacità di calcolo al bordo della rete, riducendo la latenza e migliorando l'efficienza. Distribuendo risorse di calcolo al bordo, il MEC consente l'elaborazione più rapida dei dati generati da dispositivi come sensori IoT e dispositivi mobili. Questo approccio decentralizzato migliora le applicazioni e i servizi in tempo reale come la realtà aumentata e i veicoli autonomi. Il MEC sfrutta server sul bordo in stretta vicinanza agli utenti finali, ottimizzando l'elaborazione dei dati per un calcolo ad alte prestazioni a bassa latenza. [Leggi di più](https://www.techopedia.com/what-is-multi-access-edge-computing)\n\n\nSecondo Polaris Market Research, si prevede che il mercato dell'Edge Computing nel settore sanitario supererà i quarantatre miliardi e duecentonovanta milioni di dollari americani entro il duemilatrentadue, registrando una robusta crescita del CAGR del ventisei punto tre percento. L'aumento dell'adozione di soluzioni di edge computing nel settore sanitario, spinto dai progressi nelle tecnologie IoT e AI, dovrebbe migliorare l'efficienza dell'elaborazione dei dati, consentire applicazioni in tempo reale e migliorare l'assistenza ai pazienti. Il rapporto suggerisce una significativa espansione del mercato man mano che il settore sanitario adotta l'edge computing per migliorare le prestazioni e l'elaborazione decentralizzata dei dati. [Leggi di più](https://www.prnewswire.co.uk/news-releases/edge-computing-in-healthcare-market-expected-to-cross-usd-43-29-billion-by-2032--driving-26-3-cagr-growth-polaris-market-research-301998143.html)\n\n## Gestione dei Dati\n\n\n\nIl Dipartimento dell'Agricoltura degli Stati Uniti ha rivelato una nuova strategia dati per potenziare la governance digitale. L'iniziativa sfrutta i dati per migliorare i servizi, il processo decisionale e la responsabilità. Il piano enfatizza l'innovazione guidata dai dati, la collaborazione e la modernizzazione dell'infrastruttura dati. I componenti chiave includono la priorità alla privacy e alla sicurezza, la promozione dell'accessibilità dei dati e la promozione di una cultura di utilizzo responsabile dei dati. L'approccio globale dell'USDA mira a massimizzare il valore dei dati nel sostenere la missione dell'agenzia e servire il pubblico in modo più efficace. [Leggi di più](https://www.nextgov.com/digital-government/2023/11/usda-unveils-new-data-strategy/392382/)\n\n\nVAST Data ha rilasciato un aggiornamento della piattaforma progettato per semplificare i flussi di lavoro di intelligenza artificiale e le operazioni di cloud ibrido su AWS. L'aggiornamento si concentra sul miglioramento dell'efficienza dei processi intensivi di dati, offrendo un'integrazione senza soluzione di continuità con i servizi AWS. La piattaforma di VAST Data mira a semplificare la gestione dei dati e ad accelerare i carichi di lavoro di intelligenza artificiale, fornendo un'esperienza più user-friendly per le organizzazioni che sfruttano AWS per le loro operazioni di cloud ibrido. L'aggiornamento sottolinea l'impegno di VAST Data nel ottimizzare le prestazioni e semplificare i flussi di lavoro complessi di intelligenza artificiale e cloud ibrido. [Leggi di più](https://www.datanami.com/this-just-in/vast-datas-new-platform-update-aims-to-simplify-ai-workflows-and-hybrid-cloud-operations-on-aws/)\n\n\nIntel ha stretto una partnership con Granulate per ottimizzare le operazioni di gestione dei dati su Databricks, una piattaforma utilizzata per l'analisi dei big data. La tecnologia di ottimizzazione continua in tempo reale di Granulate, supportata dall'hardware Intel, è progettata per migliorare le prestazioni e l'utilizzo delle risorse per gli utenti Databricks. Questa collaborazione riflette gli sforzi del settore per potenziare le capacità di analisi dei dati, consentendo alle organizzazioni di sfruttare appieno la potenza dei big data per aumentare l'efficienza e ridurre i costi. [Leggi di più](https://www.valdostadailytimes.com/ap/business/intel-granulate-optimizes-databricks-data-management-operations/article_ef0e550d-dbd3-5e5d-9a1d-75ffc7d0be4d.html)\n\n## Intelligenza Artificiale\n\n\nI californiani stanno esortando i loro legislatori a prendere provvedimenti per salvaguardare le elezioni e garantire l'integrità elettorale. Le crescenti preoccupazioni sulla sicurezza delle elezioni hanno spinto i cittadini a chiedere un'azione legislativa per proteggere il processo democratico. Questa richiesta riflette una crescente consapevolezza della necessità di proteggere le elezioni da possibili minacce. Rinforza l'appello affinché i legislatori promulghino politiche che potenzino la trasparenza, la sicurezza informatica e la fiducia complessiva nel sistema elettorale. [Leggi di più](https://news.yahoo.com/californians-want-lawmakers-safeguard-elections-150026166.html)\n\n\nLa NATO ha annunciato una strategia completa per l'intelligenza artificiale (IA) che riconosce il suo ruolo fondamentale nella guerra moderna e nella sicurezza. La strategia utilizza l'IA per migliorare il processo decisionale, la sicurezza informatica e l'efficienza operativa. La decisione della NATO riflette la crescente importanza dell'IA nei domini militari e la necessità di rimanere all'avanguardia dei progressi tecnologici. La strategia evidenzia le linee guida etiche e sottolinea l'importanza della collaborazione con gli alleati e i partner industriali. [Leggi di più](https://news.yahoo.com/nato-artificial-intelligence-strategy-amid-143228193.html)\n\n\nIntel ha recentemente annunciato \"Vision AI Everywhere\", una nuova tecnologia che integra l'intelligenza artificiale nei data center e nei dispositivi. Questa integrazione mira a migliorare le prestazioni e l'efficienza, ottimizzare i carichi di lavoro, potenziare le capacità dei data center e abilitare la presa di decisioni in tempo reale. Durante l'evento HPE Discover, Intel ha mostrato varie applicazioni come i data center ad alta efficienza energetica e l'imaging medico avanzato. \"Vision AI Everywhere\" è in linea con l'impegno di Intel a promuovere l'adozione dell'IA in diverse industrie, inaugurando una nuova era di calcolo intelligente. [Leggi di più](https://siliconangle.com/2023/11/29/data-centers-devices-intels-vision-ai-everywhere-hpediscover-hpediscover/)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nEmbracingdigital.org ha recentemente subito un restyling, sfoggiando un nuovo look e logo. Date un'occhiata al nuovo brand della trasmissione, insieme a un nuovo negozio che offre gli ultimi doni per gli appassionati della trasformazione digitale. Inoltre, nel programma di questa settimana, c'è un'intervista in due parti con Shamim Naqvi, CEO di SafeLiShare, dove si addentrano nel tema del Zero Trust e della condivisione dei dati. [Leggi di più](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW44-it","image":"./briefs/edw-44/it/thumbnail.png","lang":"it","summary":"Si prega di consultare le ultime notizie nel mondo della Trasformazione Digitale per la settimana del 3 dicembre 2023. Troverete una varietà di storie interessanti relative al calcolo edge, alla gestione dei dati e all'intelligenza artificiale. Questa settimana, AWS e Siemens hanno collaborato per semplificare il calcolo edge, mentre Intel sta aiutando a migliorare la gestione dei dati basata su cloud. Inoltre, diversi governi stanno sviluppando nuove strategie per l'IA."},{"id":212,"type":"News Brief","title":"2023-12-9","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","usarmy","uno","cybersec","iot","aijobs","gemini","nano","pro","ultra","meta","ibm","openai","altman","aws","google","microsoft","mcdonalds","vergeio","nutanix","embracingdt"],"body":"\n\n\n## Cibersicurezza\n\n\nL'Esercito degli Stati Uniti sta pianificando di migliorare la sua connettività e le sue capacità di sicurezza informatica introducendo una nuova rete unificata chiamata UNO. Questa iniziativa mira a fornire all'esercito una comunicazione veloce e sicura, che può aiutare a superare le sfide nel campo di battaglia digitale. Si prevede che la rete cooperativa semplifichi le operazioni e aumenti la resilienza contro le minacce informatiche, rafforzando così l'infrastruttura tecnologica dell'esercito. [Leggi di più](https://www.c4isrnet.com/battlefield-tech/it-networks/2023/12/04/unified-network-promises-us-army-rapid-connectivity-cybersecurity/)\n\n\nPoiché l'Internet delle Cose (IoT) e l'intelligenza artificiale (AI) continuano a progredire, il rischio per le infrastrutture critiche derivante dalle minacce informatiche è aumentato notevolmente. Gli esperti di cybersecurity stanno sottolineando la necessità di migliori misure di sicurezza per proteggersi da queste minacce. Essi si affidano all'integrazione di AI e apprendimento automatico per migliorare il rilevamento e la prevenzione di nuovi attacchi informatici. Questo panorama in continua evoluzione della cybersecurity nell'era dell'IoT e del cloud computing sottolinea l'ongoing necessità di adattarsi e proteggere gli ecosistemi digitali. [Leggi di più](https://readwrite.com/the-evolution-of-cybersecurity-in-the-age-of-iot-and-cloud-computing/)\n\n\nCirca il cinquanta percento delle organizzazioni intervistate ha in programma di ridurre il proprio personale di sicurezza informatica, il che solleva preoccupazioni alla luce delle minacce informatiche in continua evoluzione. Questa tendenza sottolinea l'importanza della gestione strategica della forza lavoro per mantenere solide difese digitali. Nel frattempo, alcune altre aziende hanno bisogno di aiuto per trovare candidati adatti a riempire le loro posizioni di sicurezza informatica vacanti. [Leggi di più](https://www.csoonline.com/article/1251369/almost-50-organizations-plan-to-reduce-cybersecurity-headcounts-survey.html)\n\n## Intelligenza Artificiale\n\n\nGoogle ha lanciato una nuova piattaforma di intelligenza artificiale chiamata Gemini, che mira a semplificare la formazione e il dispiegamento di modelli di apprendimento automatico. Questo permetterà agli sviluppatori di creare applicazioni di intelligenza artificiale più scalabili ed efficienti. Gemini offre strumenti e risorse intuitivi per promuovere l'innovazione e i progressi nella tecnologia dell'intelligenza artificiale. Attualmente si rivolge a tre offerte: nano per i telefoni, pro per i data center on-premise e ultra per un cloud pubblico basato su cloud fronteggiato da Bard. [Leggi di più](https://apnews.com/article/google-gemini-artificial-intelligence-launch-95d05d02051e75e20b574614ae720b8b)\n\n\n\nMeta e IBM stanno lavorando insieme per sviluppare uno standard aperto per l'intelligenza artificiale, con l'obiettivo di promuovere l'interoperabilità e contrastare l'influenza dei grandi attori della tecnologia. Nutrendo un approccio più collaborativo, sperano di creare un panorama competitivo che incoraggi l'innovazione e la diversità nella tecnologia dell'intelligenza artificiale. [Leggi di più](https://www.thestreet.com/technology/meta-and-ibm-team-up-against-dominant-big-tech-players)\n\n\nIl CEO di OpenAI, Sam Altman, ha sottolineato l'importanza di uno sviluppo responsabile dell'IA dopo che un dipendente è stato licenziato a causa di preoccupazioni relative al possibile abuso della tecnologia AI. L'incidente mette in evidenza le sfide in corso nell'industria tecnologica riguardo all'etica e alla governance nell'intelligenza artificiale. [Leggi di più](https://www.foxbusiness.com/technology/openais-sam-altman-opens-up-shock-firing)\n\n## Calcolo ubiquo\n\n\nAWS e Google criticano le pratiche restrittive di Microsoft nel cloud, accusandola di limitare la scelta del cliente e l'interoperabilità, cosa che soffoca la concorrenza nel mercato. Questo mette in evidenza le tensioni in corso tra i fornitori di cloud e le preoccupazioni riguardo le pratiche commerciali eque e la dinamica del mercato. [Leggi di più](https://www.itpro.com/cloud/cloud-computing/aws-joins-google-in-calling-out-restrictive-microsoft-cloud-practices)\n\n\nMcDonald's e Google Cloud collaborano per utilizzare la tecnologia cloud e le soluzioni di intelligenza artificiale generativa nei ristoranti McDonald's in tutto il mondo. L'obiettivo è migliorare l'esperienza del cliente, ottimizzare le operazioni e stimolare l'innovazione nell'industria del fast food. Integrando le tecnologie avanzate di Google Cloud, McDonald's mira a rimanere all'avanguardia della trasformazione digitale, fornendo servizi migliorati ed efficienze operative nella sua rete mondiale di ristoranti. [Leggi di più](https://www.prnewswire.com/news-releases/mcdonalds-and-google-cloud-announce-strategic-partnership-to-connect-latest-cloud-technology-and-apply-generative-ai-solutions-across-its-restaurants-worldwide-302006915.html)\n\n\n\nÈ stato riportato che l'acquisizione di VMware da parte di Broadcom ha causato cambiamenti che hanno portato il venti percento dei suoi utenti a cercare altre soluzioni di virtualizzazione. Questa tendenza opportunistica ha creato un'apertura per altri protagonisti del mercato per affermarsi come alternative valide. Nonostante la predominanza di VMware nel mercato della virtualizzazione, la concorrenza da parte di aziende come Nunatix e VergeIO sta spingendo i clienti a spostarsi lontano dalla piattaforma stabilita. [Leggi di più](https://www.channelfutures.com/mergers-acquisitions/20-of-users-looking-to-escape-to-vmware-alternatives)\n\n## Podcast sull'Abbracciare la Trasformazione Digitale\n\n\n\nIn questo episodio della sua serie sull'Adozione di Zero Trust, Darren intervista il CEO di SafeLiShare, Shamim Naqvi, per discutere la sicurezza Zero Trust e la collaborazione dei dati utilizzando il calcolo riservato. Inoltre, Darren desidera ringraziare i suoi ascoltatori per il loro sostegno. Grazie a voi, il podcast ha oltre tremila iscritti e quattromila ascoltatori settimanali. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW45-it","image":"./briefs/edw-45/it/thumbnail.png","lang":"it","summary":"Le notizie sulla Trasformazione Digitale per la settimana del 10 Dicembre 2023, contengono storie su cybersecurity, intelligenza artificiale e informatica ubiqua. Questa settimana ascolta il piano dell'esercito degli Stati Uniti per migliorare la cybersecurity attraverso l'unificazione, la guerra del cloud che va in tribunale nel Regno Unito, e il dramma di OpenAI e Sam Altman."},{"id":213,"type":"News Brief","title":"2023-12-16","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","innovation","intel","pc","aiworkforce","snowflake","aws","solix","aiintegration","britain","nationalgrid","chineserisks","hackers","infrastructure","vulnerabilities","nsa","russianthreats","digitaltransformation","openziti","zerotrust"],"body":"\n\n\n## Intelligenza Artificiale\n\n\nL'ultimo annuncio di Intel segna un momento fondamentale nella nascita dei PC alimentati da intelligenza artificiale. Il lancio dei processori della serie Core Ultra H e U introduce l'innovativa architettura Meteor Lake, integrando capacità avanzate di intelligenza artificiale nei notebook ultra sottili. Questo rilascio migliora le prestazioni e eleva la piattaforma grafica Arc, portando l'esperienza dell'utente a nuovi livelli. L'impegno di Intel per l'innovazione segnala un'epoca trasformativa nel mercato dei laptop, dove l'intelligenza artificiale diventa fondamentale per il calcolo quotidiano. [Leggi di più](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\nLa neo-eletta Consigliera Comunale di New York, Susan Zhuang, ha ammesso di impiegare segretamente l'IA per comunicare con il pubblico e rispondere alle richieste dei media. Finalmente un politico che dice la verità! L'impiego di IA da parte di Zhuang segna un approccio unico al coinvolgimento dei costituenti, e le implicazioni di questa strategia trainata dalla tecnologia potrebbero ridefinire il panorama della comunicazione politica nell'era digitale. [Leggi di più](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\nLa creazione di Intel di un PC IA personalizzato ha portato un potenziale enorme scombussolamento del lavoro alle aziende mentre continuano ad integrare l'intelligenza artificiale (IA) nelle loro operazioni. Mentre le tecnologie dell'IA vengono adottate, si prevede che le funzioni lavorative e le giornate lavorative cambieranno, sollevando preoccupazioni riguardo a possibili sfide per la forza lavoro. Le aziende si stanno preparando per questo cambiamento trasformativo e riconoscendo l'esigenza di strategie proattive per navigare nelle possibili interruzioni e garantire un passaggio senza intoppi a un futuro guidato dall'IA. [Leggi di più](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gestione dei Dati\n\n\nFiocco di neve, una principale piattaforma di dati cloud, ha raggiunto l'autorizzazione FedRAMP Alta su AWS GovCloud Stati Uniti Ovest e Stati Uniti Est. Questa significativa pietra miliare evidenzia l'impegno di Snowflake nel rispettare rigorosi standard di sicurezza governativi, consentendo alle agenzie federali di sfruttare le sue avanzate capacità di gestione dei dati in un ambiente cloud sicuro. L'autorizzazione FedRAMP Alta sottolinea la posizione di Snowflake come partner affidabile nella fornitura di soluzioni veloci e scalabili per entità governative, promuovendo l'innovazione e l'efficienza nella gestione dei dati. [Leggi di più](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\nSolix ha introdotto la Common Data Platform (CDP) tre punto zero, che include avanzate capacità di gestione dei dati multi-cloud e dell'IA aziendale. Questa versione riflette l'impegno di Solix nel fornire soluzioni all'avanguardia per gestire e trarre intuizioni da grandi set di dati. Le funzionalità migliorate di apprendimento automatico e IA del CDP tre punto zero consentono alle organizzazioni di prendere decisioni basate sui dati più informate. La tendenza della gestione dei dati multi-cloud sta guidando lo sviluppo di molte nuove offerte commerciali, e l'ultima versione di Solix è pronta a essere un contributo significativo in questo spazio. [Leggi di più](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n\nIn un recente rapporto, Datanami esplora considerazioni cruciali per garantire che la tua strategia di gestione dei dati sia pronta per l'IA con cinque indicatori chiave. Dà priorità alla qualità dei dati, scalabilità, capacità di integrazione, robusta sicurezza e flessibilità. Questi elementi sono cruciali per ottimizzare i sistemi poiché l'intelligenza artificiale continua a modellare i processi di dati. Rimani avanti nell'era dell'IA valutando e migliorando questi aspetti per soddisfare le esigenze delle tecnologie in evoluzione. Leggi di più su datanami.com per approfondimenti completi. [Leggi di più](https://www.datanami.com/2023/12/08/is-your-data-management-strategy-ready-for-ai-5-ways-to-tell/)\n\n## Sicurezza informatica\n\n\n\nLa National Grid britannica avrebbe apparentemente interrotto i rapporti con un fornitore con sede in Cina a causa di preoccupazioni relative alla sicurezza informatica, come riportato da Reuters il diciassette dicembre duemilaventitré. La decisione riflette un'attenzione globale crescente rispetto ai potenziali rischi associati alle partnership tecnologiche straniere, in particolare nei settori dell'infrastruttura critica. Questa mossa da parte della National Grid sottolinea l'importanza crescente attribuita al rafforzamento delle misure di sicurezza informatica per salvaguardare i servizi essenziali da potenziali minacce. [Leggi di più](https://www.reuters.com/technology/cybersecurity/britains-national-grid-drops-china-based-supplier-over-cyber-security-fears-ft-2023-12-17/)\n\n\nGli hacker hanno preso di mira l'approvvigionamento idrico degli Stati Uniti, suscitando allarmi sulla vulnerabilità delle infrastrutture critiche. Axios ha riportato il sedici Dicembre duemilaventintré che questa violazione comporta significative preoccupazioni di sicurezza nazionale e sicurezza pubblica. L'incidente sottolinea l'urgente necessità di robuste misure di sicurezza informatica per proteggere i servizi essenziali. Le autorità stanno indagando sulla violazione, evidenziando le sfide in corso nel difendere le infrastrutture critiche dalle minacce informatiche. [Leggi di più](https://www.axios.com/2023/12/16/hackers-us-water-supply)\n\n\nLa NSA ha avvertito riguardo agli attori cyber russi che sfruttano una vulnerabilità conosciuta con implicazioni globali. La vulnerabilità identificata ha un impatto significativo su scala mondiale, sottolineando l'importanza di mitigare i rischi di sicurezza informatica. La NSA consiglia alle organizzazioni di affrontare e correggere prontamente questa vulnerabilità per migliorare la loro resilienza contro le potenziali minacce cibernetiche. [Leggi di più](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3616384/russian-cyber-actors-are-exploiting-a-known-vulnerability-with-worldwide-impact/)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nDarren guarda all'open source per l'architettura di rete a zero trust con openZiti con uno degli organizzatori della comunità open-source Philip Griffiths. Un ringraziamento speciale anche agli ascoltatori di Embracing Digital Transformation per aver diffuso la notizia, abbiamo aggiunto oltre quattromila iscritti al nostro canale YouTube e abbiamo registrato oltre quattordicimila download o visualizzazioni del nostro podcast la scorsa settimana. Grazie ancora per il vostro sostegno. [Leggi di più](http://www.embracingdigital.org)\n\n## Intelligenza Artificiale\n\n\n\nL'ultimo annuncio di Intel segna un momento cruciale nella nascita dei PC alimentati da intelligenza artificiale. Il lancio dei processori Core Ultra H e U introduce la rivoluzionaria architettura Meteor Lake, incorporando avanzate capacità AI in notebook ultra sottili. Questo rilascio migliora le prestazioni e aumenta la piattaforma grafica Arc, portando l'esperienza utente a nuove vette. L'impegno di Intel per l'innovazione segnala un'era trasformativa nel mercato dei laptop, dove l'IA diventa fondamentale per l'informatica quotidiana. [Leggi di più](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\n\nLa neoeletta consigliera comunale di New York, Susan Zhuang, ha ammesso di aver impiegato in segreto l'IA per comunicare con il pubblico e rispondere alle richieste dei media. Finalmente un politico che dice la verità! L'uso dell'IA da parte di Zhuang rappresenta un approccio unico per interagire con gli elettori e le implicazioni di questa strategia guidata dalla tecnologia potrebbero ridisegnare il panorama della comunicazione politica nell'era digitale. [Leggi di più](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\n\nLa creazione da parte di Intel di un PC IA personalizzato ha portato una potenziale massiccia interruzione del lavoro alle imprese mentre continuano a integrare l'intelligenza artificiale (IA) nelle loro operazioni. Man mano che vengono adottate le tecnologie di IA, si prevede che cambieranno le funzioni lavorative e i giorni lavorativi, sollevando preoccupazioni riguardo potenziali sfide per la forza lavoro. Le aziende si stanno preparando per questo cambiamento trasformativo e riconoscendo la necessità di strategie proattive per navigare potenziali interruzioni e garantire una transizione fluida verso un futuro guidato dall'IA. [Leggi di più](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gestione dei Dati\n\n\n\nFiocco di Neve, una principale piattaforma di dati cloud, ha conseguito l'Autorizzazione FedRAMP Alta su AWS GovCloud Stati Uniti Ovest e Stati Uniti Est. Questa importante pietra miliare evidenzia l'impegno di Fiocco di Neve nel rispettare severi standard di sicurezza governativi, consentendo alle agenzie federali di sfruttare le sue avanzate capacità di gestione dei dati in un ambiente cloud sicuro. L'Autorizzazione FedRAMP Alta sottolinea la posizione di Fiocco di Neve come partner affidabile nell'offrire soluzioni veloci e scalabili per le entità governative, promuovendo l'innovazione e l'efficienza nella gestione dei dati. [Leggi di più](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\n\nSolix ha introdotto la Piattaforma di Dati Comune (CDP) tre punto zero, che include avanzate capacità di gestione dei dati multi-cloud e intelligenza artificiale aziendale. Questa versione riflette l'impegno di Solix a fornire soluzioni all'avanguardia per la gestione e il conseguimento di intuizioni da grandi set di dati. Le funzionalità migliorate di apprendimento automatico e intelligenza artificiale della CDP tre punto zero consentono alle organizzazioni di prendere decisioni basate sui dati più informate. La tendenza alla gestione dei dati multi-cloud sta guidando lo sviluppo di molte nuove offerte commerciali, e l'ultima versione di Solix è pronta per essere un contributo significativo in questo spazio. [Leggi di più](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n## Intelligenza Artificiale\n\n\n\nL'ultimo annuncio di Intel segna un momento cruciale nella nascita dei PC alimentati da IA. Il lancio dei processori della serie Core Ultra H e U introduce la rivoluzionaria architettura Meteor Lake, incorporando capacità AI avanzate nei notebook ultra-sottili. Questa uscita migliora le prestazioni e solleva la piattaforma grafica Arc, elevando l'esperienza utente a nuovi vertici. L'impegno di Intel verso l'innovazione segnala un'era trasformativa nel mercato dei laptop, dove l'IA diventa parte integrante della computazione quotidiana. [Leggi di più](https://www.anandtech.com/show/21185/intel-releases-core-ultra-h-and-u-series-processors-meteor-lake-brings-ai-and-arc-to-ultra-thin-notebooks)\n\n\n\nLa neo-eletta consigliera municipale di New York, Susan Zhuang ha ammesso di aver utilizzato in modo discreto l'Intelligenza Artificiale per comunicare con il pubblico e rispondere alle richieste dei media. Finalmente un politico che dice la verità! L'uso dell'IA da parte di Zhuang segna un approccio unico per impegnarsi con i suoi elettori, e le implicazioni di questa strategia guidata dalla tecnologia potrebbero ridisegnare il panorama della comunicazione politica nell'era digitale. [Leggi di più](https://nypost.com/2023/12/16/metro/nyc-councilwoman-elect-susan-zhuang-admits-to-quietly-using-ai-to-communicate-with-the-public-answer-media-questions/)\n\n\n\nLa creazione da parte di Intel del personal computer con intelligenza artificiale personalizzata ha portato una potenziale enorme interruzione del lavoro per le aziende mentre continuano a integrare l'intelligenza artificiale nelle loro operazioni. Con l'adozione delle tecnologie AI, si prevede che cambieranno le funzioni lavorative e i giorni di lavoro, sollevando preoccupazioni riguardo a possibili sfide nel mondo del lavoro. Le aziende si stanno preparando per questo cambiamento trasformativo e riconoscendo la necessità di strategie proattive per navigare le potenziali interruzioni e assicurare una transizione fluida verso un futuro guidato dall'intelligenza artificiale. [Leggi di più](https://fortune.com/2023/12/12/businesses-prepare-ai-massive-labor-disruption-workday/)\n\n## Gestione dei Dati\n\n\n\nFiocco di neve, una piattaforma principale di dati cloud, ha ottenuto l'Autorizzazione Alta FedRAMP su AWS GovCloud Stati Uniti Occidentale e Stati Uniti Orientale. Questa pietra miliare significativa evidenzia l'impegno di Fiocco di neve nell'adempimento agli stringenti standard di sicurezza governativi, consentendo alle agenzie federali di sfruttare le sue avanzate capacità di gestione dei dati in un ambiente cloud sicuro. L'Autorizzazione Alta FedRAMP sottolinea la posizione di Fiocco di neve come partner di fiducia nel fornire soluzioni veloci e scalabili per le entità governative, promuovendo l'innovazione e l'efficienza nella gestione dei dati. [Leggi di più](https://www.snowflake.com/news/snowflake-achieves-fedramp-high-authorization-on-aws-govcloud-us-west-and-us-east/)\n\n\n\nSolix ha introdotto la Common Data Platform (CDP) tre punto zero, che include avanzate capacità di gestione dei dati multi-cloud e di intelligenza artificiale aziendale. Questa release riflette l'impegno di Solix a fornire soluzioni all'avanguardia per gestire e ricavare intuizioni da grandi set di dati. Le migliorate caratteristiche di apprendimento automatico e di intelligenza artificiale del CDP tre punto zero consentono alle organizzazioni di prendere decisioni più informate basate sui dati. La tendenza alla gestione dei dati multi-cloud sta guidando lo sviluppo di molte nuove offerte commerciali, e l'ultimo rilascio di Solix è pronto a essere un contributore significativo in questo spazio. [Leggi di più](https://aithority.com/machine-learning/solix-common-data-platform-3-0-for-advanced-cloud-data-management-and-enterprise-ai/)\n\n\n\nIn un recente rapporto, Datanami esplora considerazioni cruciali per garantire che la tua strategia di gestione dei dati sia pronta per l'intelligenza artificiale con cinque indicatori chiave. Dare priorità alla qualità dei dati, scalabilità, capacità di integrazione, sicurezza robusta e flessibilità. Questi elementi sono cruciali per ottimizzare i sistemi mentre l'intelligenza artificiale continua a dare forma ai processi di dati. Rimani avanti nell'era dell'intelligenza artificiale valutando ed migliorando questi aspetti per soddisfare le esigenze delle tecnologie in evoluzione. Leggi ulteriori informazioni su datanami.com per ottenere approfondimenti completi. [Leggi di più](https://www.datanami.com/2023/12/08/is-your-data-management-strategy-ready-for-ai-5-ways-to-tell/)\n\n## Cybersicurezza\n\n\n\nLa National Grid della Gran Bretagna ha apparentemente interrotto i legami con un fornitore con base in Cina a causa di preoccupazioni sulla sicurezza informatica, come riportato da Reuters il diciassette dicembre duemilaventicinque. La decisione riflette l'accresciuto scrutinio globale sui potenziali rischi associati alle partnership tecnologiche estere, particolarmente nei settori delle infrastrutture critiche. Questa mossa da parte della National Grid sottolinea l'importanza crescente data al rafforzamento delle misure di sicurezza informatica per salvaguardare i servizi essenziali da possibili minacce. [Leggi di più](https://www.reuters.com/technology/cybersecurity/britains-national-grid-drops-china-based-supplier-over-cyber-security-fears-ft-2023-12-17/)\n\n\n\nGli hacker hanno preso di mira il sistema idrico degli Stati Uniti, sollevando allarmi sulla vulnerabilità delle infrastrutture critiche. Il sedici dicembre duemilaventicinque, Axios ha riportato che questa violazione rappresenta significativi problemi di sicurezza nazionale e di sicurezza pubblica. L'incidente sottolinea l'urgente necessità di robuste misure di sicurezza informatica per salvaguardare i servizi essenziali. Le autorità stanno indagando sulla violazione, evidenziando le sfide in corso nella difesa delle infrastrutture critiche dalle minacce informatiche. [Leggi di più](https://www.axios.com/2023/12/16/hackers-us-water-supply)\n\n\n\nLa NSA ha avvertito riguardo attori cyber russi che sfruttano una nota vulnerabilità con implicazioni globali. La vulnerabilità identificata ha un impatto significativo a livello mondiale, sottolineando l'importanza di mitigare i rischi della cybersecurity. La NSA consiglia alle organizzazioni di affrontare e correggere prontamente questa vulnerabilità per potenziare la loro resilienza contro possibili minacce cyber. [Leggi di più](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3616384/russian-cyber-actors-are-exploiting-a-known-vulnerability-with-worldwide-impact/)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nDarren guarda all'open source per l'architettura di rete a zero fiducia con OpenZiti con uno degli organizzatori della comunità open source Philip Griffiths. Un ringraziamento speciale anche agli ascoltatori di Embracing Digital Transformation per aver diffuso la notizia, abbiamo aggiunto oltre quattromila iscritti al nostro canale YouTube e ottenuto o visualizzato oltre quattordicimila download del nostro podcast nell'ultima settimana. Grazie ancora per il vostro sostegno. [Leggi di più](http://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW46-it","image":"./briefs/edw-46/it/thumbnail.png","lang":"it","summary":"La settimana del 17 Dicembre 2023, nelle notizie sulla Trasformazione Digitale, include storie su AI, gestione dei dati e cybersecurity. Scopri la nascita del PC AI, la gestione dei dati Multi-cloud per i cloud governativi e importanti avvisi per la cybersecurity delle infrastrutture critiche."},{"id":214,"type":"News Brief","title":"2023-12-23","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","wordpress","plugindata","xwpspamshield","ontariohack","healthcarecyber","holidayhacks","ontarioincidents","artificialintel","generativeai","aiinschool","intelnervana","cloudcomputing","cloudcost","pentagoncloud","cisco","isovalent","openziti","podcast","digitaltransf"],"body":"\n\n## Cybersicurezza\n\n\n\nUn plugin di WordPress fuorilegge ha messo a rischio i dati degli utenti esponendo indirizzi email, nomi utente e password in chiaro. I ricercatori di sicurezza hanno scoperto la violazione, esortando gli utenti interessati a reimpostare immediatamente le loro credenziali. Il plugin, chiamato \"X-WP-SPAM-SHIELD-PRO\", è noto per le attività malevole, sottolineando l'importanza di audit di sicurezza regolari per i siti WordPress. Si consiglia agli amministratori di siti web di rimuovere il plugin compromesso e di migliorare le misure di sicurezza per prevenire l'accesso non autorizzato e l'esposizione dei dati. [Leggi di più](https://thehackernews.com/2023/12/rogue-wordpress-plugin-exposes-e.html)\n\n\n\nLa CBC riporta un'impennata di attacchi informatici mirati all'Ontario, Canada, nel duemilaventitre. Questi incidenti coinvolgono una serie di settori, tra cui sanità, comuni e istruzione. Gli hacker sfruttano le vulnerabilità, causando interruzioni ed esponendo dati sensibili. Gli esperti sottolineano l'importanza di migliorare le misure di sicurezza informatica, la formazione e la collaborazione per salvaguardare dalle minacce informatiche in evoluzione e proteggere le infrastrutture critiche. [Leggi di più](https://www.cbc.ca/news/canada/toronto/cybersecurity-ontario-incidents-2023-1.7048495)\n\n\n\nGli attacchi informatici durante le vacanze natalizie stanno aumentando per diversi motivi. In primo luogo, l'attività di acquisto online è intensificata, creando opportunità per i cybercriminali. In secondo luogo, i tentativi di phishing sono aumentati, in cui gli aggressori ingannano le vittime utilizzando l'email o i social media. In terzo luogo, i dipendenti che lavorano da remoto presentano un rischio per la sicurezza. In quarto luogo, gli attacchi di ingegneria sociale possono avere più successo durante questa stagione. Infine, la possibile negligenza della sicurezza a causa delle festività può anche aumentare il rischio di attacchi. È fondamentale essere consapevoli di questi rischi e adottare misure per mitigarli. [Leggi di più](https://bit-sentinel.com/5-reasons-why-cyber-attacks-increase-during-the-christmas-holidays/)\n\n## Intelligenza Artificiale\n\n\n\nNel duemilaventitré, l'Intelligenza Artificiale generativa ha fatto passi da gigante in diversi settori, incluso l'assistenza sanitaria, la finanza e l'intrattenimento. Jim Cramer di CNBC riassume la fine dell'anno sottolineando i contributi dell'IA alla scoperta di farmaci, alla modellazione finanziaria e alla creazione di contenuti. Il potenziale trasformativo dell'Intelligenza Artificiale generativa è messo in evidenza, segnando la sua continua influenza sull'innovazione e gli avanzamenti tecnologici. [Leggi di più](https://www.cnbc.com/2023/12/21/jim-cramer-recaps-the-year-in-generative-artificial-intelligence.html)\n\n\n\nL'articolo recente di Future-Ed esplora il potenziale dell'integrazione dell'IA nelle scuole. Sottolinea l'importanza delle considerazioni etiche e dell'implementazione responsabile per un'integrazione di successo. L'articolo fornisce intuizioni preziose per educatori, responsabili delle politiche e portatori di interessi che navigano in questo paesaggio in evoluzione. Il podcast \"Abbracciando la Trasformazione Digitale\" presenterà anche interviste con studenti universitari e i loro professori, discutendo le loro opinioni. [Leggi di più](https://www.future-ed.org/navigating-the-artificial-intelligence-revolution-in-schools/)\n\n\n\nIntel ha presentato un nuovo chip, l'Intel Nervana NCS-uno, per accelerare le applicazioni dell'intelligenza artificiale (IA). Il NCS-uno è progettato per migliorare le prestazioni dell'IA, offrendo un elevato throughput ed efficienza. Intel mira a promuovere l'innovazione nell'IA fornendo agli sviluppatori gli strumenti per distribuire e scalare efficientemente i modelli di IA. Il chip fa parte dell'impegno di Intel per potenziare le applicazioni di IA in vari settori e rappresenta un passo significativo nella strategia IA dell'azienda. [Leggi di più](https://www.intc.com/news-events/press-releases/detail/1663/intel-accelerates-ai-everywhere-with-launch-of-powerful)\n\n## Calcolo Ubiquitario\n\n\n\nLe istituzioni finanziarie, tra cui Capital One e Arvest Bank, stanno dando priorità al controllo dei costi del cloud di fronte alle sfide. L'attenzione è rivolta all'ottimizzazione delle spese attraverso l'allineamento strategico con gli obiettivi aziendali, l'utilizzo di strumenti di gestione dei costi del cloud, e l'implementazione di pratiche di governance. Man mano che il cloud computing si evolve, una gestione efficace dei costi diventa fondamentale per queste organizzazioni. [Leggi di più](https://www.ciodive.com/news/cloud-cost-control-capital-one-arvest-bank/703025/)\n\n\n\nIl Washington Post riporta la riconsiderazione del Pentagono dei suoi contratti di cloud computing, suggerendo potenziali cambiamenti di strategia. L'articolo esplora le implicazioni di questi cambiamenti e il loro impatto sulle principali aziende di tecnologia che concorrono per i lucrativi contratti di difesa. Mentre il Pentagono naviga nel complesso panorama del cloud computing, l'articolo mette in evidenza la dinamica in evoluzione e il panorama competitivo nella ricerca del settore della difesa di capacità tecnologiche avanzate. [Leggi di più](https://www.washingtonpost.com/technology/2023/12/21/pentagon-cloud-computing-contracts/)\n\n\n\nCisco sta facendo una mossa strategica nella sicurezza del cloud acquisendo Isovalent, un innovatore nel networking e nella sicurezza nativi del cloud. Questa acquisizione riflette l'impegno di Cisco nel promuovere le sue capacità di intelligenza artificiale (AI) e di sicurezza del cloud. L'esperienza di Isovalent nella tecnologia eBPF (extended Berkeley Packet Filter) dovrebbe migliorare la capacità di Cisco di garantire la sicurezza degli ambienti cloud, fornendo soluzioni avanzate per l'evoluzione del panorama della sicurezza informatica nelle infrastrutture basate sul cloud. [Leggi di più](https://www.informationweek.com/it-infrastructure/cloud-computing#close-modal)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nInnanzitutto, vorrei augurare a tutti i miei ascoltatori un Buon Natale e un Felice Anno Nuovo. Nel podcast di questa settimana, Darren esplora OpenZiti, una soluzione di rete open-source a zero fiducia. Inoltre, grazie a tutti coloro che stanno diffondendo la parola sul podcast: abbiamo ora superato i diecimila ascoltatori settimanali e il vostro sostegno è molto apprezzato. [Leggi di più](https://www.embracingdigital.org)\n\n## Cybersicurezza\n\n\n\nUn plugin WordPress fuorilegge ha messo a rischio i dati degli utenti esponendo indirizzi email, nomi utente e password in chiaro. I ricercatori di sicurezza hanno scoperto la violazione, esortando gli utenti colpiti a reimpostare immediatamente le loro credenziali. Il plugin, chiamato \"X-WP-SPAM-SHIELD-PRO\", è noto per le sue attività malevole, sottolineando l'importanza di audit di sicurezza regolari per i siti WordPress. Si consiglia agli amministratori di siti web di rimuovere il plugin compromesso e migliorare le misure di sicurezza per prevenire l'accesso non autorizzato e l'esposizione dei dati. [Leggi di più](https://thehackernews.com/2023/12/rogue-wordpress-plugin-exposes-e.html)\n\n\n\nLa CBC riporta un aumento degli attacchi informatici mirati a Ontario, Canada, nel duemilaventitré. Questi incidenti coinvolgono una serie di settori, tra cui la sanità, i comuni e l'educazione. Gli hacker sfruttano le vulnerabilità, causando interruzioni e esponendo i dati sensibili. Gli esperti sottolineano l'importanza di migliorare le misure di sicurezza informatica, la formazione e la collaborazione per proteggersi dalle minacce informatiche in evoluzione e proteggere le infrastrutture critiche. [Leggi di più](https://www.cbc.ca/news/canada/toronto/cybersecurity-ontario-incidents-2023-1.7048495)\n\n\n\nGli attacchi informatici durante le vacanze natalizie stanno aumentando per vari motivi. Innanzitutto, l'attività di acquisto online è intensificata, creando opportunità per i cybercriminali. In secondo luogo, le tentativi di phishing si sono moltiplicate, dove gli aggressori ingannano le vittime utilizzando la posta elettronica o i social media. In terzo luogo, i dipendenti che lavorano da remoto presentano un rischio di sicurezza. In quarto luogo, gli attacchi di ingegneria sociale possono avere più successo durante questa stagione. Infine, potenziali negligenze di sicurezza dovute alle festività possono anche aumentare il rischio di attacchi. È fondamentale essere consapevoli di questi rischi e adottare misure per mitigarli. [Leggi di più](https://bit-sentinel.com/5-reasons-why-cyber-attacks-increase-during-the-christmas-holidays/)\n\n## Intelligenza Artificiale\n\n\n\nNel duemilaventicitré, l'Intelligenza Artificiale generativa ha fatto passi da gigante in diversi settori, tra cui sanità, finanza e intrattenimento. Jim Cramer di CNBC ricapitola la fine dell'anno sottolineando i contributi dell'IA alla scoperta di farmaci, alla modellazione finanziaria e alla creazione di contenuti. Viene messa in evidenza la potenziale trasformazione dell'Intelligenza Artificiale generativa, segnando la sua continua influenza sull'innovazione e i progressi tecnologici. [Leggi di più](https://www.cnbc.com/2023/12/21/jim-cramer-recaps-the-year-in-generative-artificial-intelligence.html)\n\n\n\nIl recente articolo di Future-Ed esplora il potenziale dell'integrazione dell'IA nelle scuole. Sottolinea l'importanza delle considerazioni etiche e dell'implementazione responsabile per una integrazione di successo. L'articolo fornisce preziosi spunti di riflessione per gli educatori, i responsabili delle politiche e i portatori di interesse che navigano in questo panorama in evoluzione. Il podcast Abbracciando la Trasformazione Digitale presenterà anche interviste con studenti universitari e i loro professori, per discutere le loro riflessioni. [Leggi di più](https://www.future-ed.org/navigating-the-artificial-intelligence-revolution-in-schools/)\n\n\n\nIntel ha svelato un nuovo chip, l'Intel Nervana NCS-uno, per accelerare le applicazioni di intelligenza artificiale (AI). L'NCS-uno è progettato per migliorare le prestazioni dell'AI, offrendo un alto throughput ed efficienza. Intel mira a far avanzare l'innovazione nell'AI fornendo agli sviluppatori strumenti per implementare e scalare in modo efficiente i modelli di AI. Il chip fa parte dell'impegno di Intel a potenziare le applicazioni di AI in vari settori e rappresenta un passo significativo nella strategia dell'AI dell'azienda. [Leggi di più](https://www.intc.com/news-events/press-releases/detail/1663/intel-accelerates-ai-everywhere-with-launch-of-powerful)\n\n## Calcolo Ubiquitario\n\n\n\nLe istituzioni finanziarie, tra cui Capital One e Arvest Bank, stanno dando priorità al controllo dei costi del cloud di fronte a sfide. L'obiettivo è ottimizzare le spese attraverso l'allineamento strategico con gli obiettivi aziendali, l'impiego di strumenti di gestione dei costi del cloud e l'attuazione di pratiche di governance. Con l'evoluzione del cloud computing, una gestione efficace dei costi diventa fondamentale per queste organizzazioni. [Leggi di più](https://www.ciodive.com/news/cloud-cost-control-capital-one-arvest-bank/703025/)\n\n\n\nIl Washington Post riporta la riconsiderazione del Pentagono dei suoi contratti di cloud computing, suggerendo potenziali cambiamenti di strategia. L'articolo esplora le implicazioni di questi cambiamenti e il loro impatto sulle principali aziende tecnologiche in lizza per lucrosi contratti di difesa. Mentre il Pentagono si destreggia nel complesso panorama del cloud computing, l'articolo evidenzia la dinamica in continua evoluzione e il panorama competitivo nell'ambito della ricerca, da parte del settore della difesa, di capacità tecnologiche avanzate. [Leggi di più](https://www.washingtonpost.com/technology/2023/12/21/pentagon-cloud-computing-contracts/)\n\n\n\nCisco sta compiendo una mossa strategica nella sicurezza cloud acquisendo Isovalent, un innovatore nel settore della rete e della sicurezza native del cloud. Questa acquisizione riflette l'impegno di Cisco nel promuovere le sue capacità di intelligenza artificiale (AI) e sicurezza cloud. Si prevede che l'esperienza di Isovalent nella tecnologia eBPF (filtro di pacchetti di Berkeley esteso) migliorerà la capacità di Cisco di garantire la sicurezza degli ambienti cloud, fornendo soluzioni avanzate per l'evoluzione del panorama della sicurezza informatica nelle infrastrutture basate sul cloud. [Leggi di più](https://www.informationweek.com/it-infrastructure/cloud-computing#close-modal)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nIn primo luogo, vorrei augurare a tutti i miei ascoltatori un Buon Natale e un Felice Anno Nuovo. Nel podcast di questa settimana, Darren esplora OpenZiti, una soluzione di rete zero-trust open-source. Inoltre, grazie a tutti coloro che diffondono la voce sul podcast: abbiamo ora superato i diecimila ascoltatori settimanali, e il vostro sostegno è molto apprezzato. [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW47-it","image":"./briefs/edw-47/it/thumbnail.png","lang":"it","summary":"Durante la settimana del 24 dicembre 2023, ci sono state diverse notizie sulla trasformazione digitale. Queste storie coprivano argomenti come la cybersecurity, l'intelligenza artificiale e l'informatica. Alcuni dei momenti salienti della settimana includevano un aumento degli attacchi informatici durante il periodo delle feste, lo sforzo di Intel per sviluppare ulteriormente la tecnologia AI e la tendenza verso il controllo dei costi nel cloud computing."},{"id":215,"type":"News Brief","title":"2023-12-31","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","edgecompute","digitaltransform","nsacyber","aics","tomtom","microsoft","mitresearch","aiethics","iot","healthcare","malwaredetect","patientdata","aiagriculture","predictive","genai","automation","navigation","malware"],"body":"\n\n\n## Sicurezza informatica\n\n\n\nLa soluzione di cybersecurity potenziata dall'IA di Checkpoint offre una piattaforma rivoluzionaria con un tasso di precisione del novantotto percento nel rilevare attività malevole. Il sistema utilizza algoritmi avanzati e analisi predittive per fornire alle imprese una potente difesa contro i rischi informatici in evoluzione, rafforzando la sicurezza digitale durante minacce maggiori. [Leggi di più](https://fortune.com/2023/12/29/ai-cybersecurity-checkpoint/)\n\n\n\nGli attacchi cibernetici alle strutture sanitarie sono aumentati, causando preoccupazioni riguardo alla sicurezza dei pazienti presso l'Ospedale Liberty, che ha combattuto un attacco per le ultime due settimane. Sono necessarie misure di sicurezza cibernetica robuste per proteggere le informazioni mediche sensibili e garantire servizi sanitari ininterrotti. Questo mette in evidenza le vulnerabilità più ampie delle infrastrutture critiche di fronte alle crescenti minacce cibernetiche. [Leggi di più](https://www.kctv5.com/2023/12/30/liberty-hospital-staff-worries-patients-are-jeopardy-if-cyber-security-incident-drags/)\n\n\n\nIl rapporto di revisione dell'anno di sicurezza informatica duemilaventitré della NSA offre approfondimenti sulle minacce informatiche, sulle difese riuscite e sulle tendenze emergenti. La pubblicazione sottolinea l'impegno dell'agenzia nel migliorare la resilienza informatica nazionale ed è una risorsa preziosa per i professionisti del settore, i responsabili politici e il pubblico. Fornisce un'analisi retrospettiva del panorama della sicurezza informatica e guida gli sforzi futuri per rafforzare la sicurezza digitale. [Leggi di più](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3621654/nsa-publishes-2023-cybersecurity-year-in-review/)\n\n## Intelligenza Artificiale\n\n\n\nI ricercatori del MIT hanno sviluppato algoritmi che permettono alle macchine di comprendere le sfumature contestuali nel linguaggio, promuovendo interazioni più accurate. Questa svolta nel processamento del linguaggio naturale ha potenziali applicazioni in vari campi, colmando il divario tra la comunicazione umana e la comprensione delle macchine. La ricerca del MIT apre la strada a sistemi di intelligenza artificiale più avanzati e consapevoli del contesto. [Leggi di più](https://news.mit.edu/2023/leveraging-language-understand-machines-1222)\n\n\n\nL'Intelligenza Artificiale e l'automazione stanno trasformando i governi migliorando l'efficienza e l'agilità. Questo passaggio verso un approccio iniziale digitale riflette un impegno ad adattarsi all'era moderna. L'impatto di queste tecnologie sta ridefinendo la governance e fornendo un approccio più avanzato per affrontare le sfide digitali. [Leggi di più](https://federalnewsnetwork.com/commentary/2023/12/navigating-the-era-of-innovation-how-artificial-intelligence-and-automation-are-driving-a-digital-first-government/)\n\n\n\nMichael Cohen ammette di aver presentato falsi documenti legali generati da intelligenza artificiale mentre lavorava per Donald Trump, sollevando preoccupazioni sulla etica e la supervisione dell'IA nel sistema legale. Questo mette in risalto la necessità di una vigilanza attenta e di salvaguardie per mantenere l'integrità dei procedimenti legali. L'incidente sottolinea le sfide in continua evoluzione della etica e dell'integrità dell'IA nei processi legali. [Leggi di più](https://www.nbcnews.com/politics/politics-news/michael-cohen-says-unknowingly-submitted-fake-ai-generated-legal-cases-rcna131631)\n\n## Calcolo Edge\n\n\n\nTomTom e Microsoft si sono unite per introdurre una soluzione innovativa di intelligenza artificiale generativa per veicoli connessi. La tecnologia sfrutta algoritmi avanzati per trasformare la navigazione, promettendo un'esperienza di guida più intelligente e reattiva. Questo sviluppo rappresenta un passo avanti significativo nell'integrare l'intelligenza artificiale nelle automobili. [Leggi di più](https://www.iottechnews.com/news/2023/dec/19/tomtom-microsoft-unveil-generative-ai-connected-vehicles/)\n\n\n\nPanasonic combatte il malware IoT rilasciando trappole per rilevare minacce informatiche. L'azienda guadagna preziose intuizioni sulle tattiche di malware in evoluzione creando obiettivi simulati per attrarre attività malevole, migliorando le misure di cybersecurity. Questo approccio proattivo riflette la crescente enfasi su tecniche innovative per proteggere dispositivi collegati e reti di fronte a sfide di sicurezza in escalation. [Leggi di più](https://www.wired.com/story/panasonic-iot-malware-honeypots/)\n\n\n\nL'integrazione tra l'Intelligenza Artificiale (IA) e le tecnologie dell'Internet delle Cose (IoT) sta trasformando rapidamente l'industria agricola. Si prevede che il mercato dell'agricoltura di precisione raggiunga i cinque miliardi e duecento milioni di euro entro il duemilaventisette, grazie all'uso innovativo dell'IoT, dell'analisi dei dati e dell'automazione in agricoltura. Questa tecnologia ottimizza il rendimento delle colture, riduce il consumo di risorse e promuove un'agricoltura sostenibile ed efficiente in tutto il mondo. [Leggi di più](https://iotbusinessnews.com/2023/12/22/53545-the-precision-agriculture-market-to-reach-e-5-2-billion-worldwide-in-2027/)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nQuesta settimana, il programma Embracing Digital Transformation prosegue la sua serie Embracing Generative AI presentando interviste con una studentessa universitaria, Madeline Pulsipher, che condivide il suo percorso con GenAI, seguita da una prospettiva del professore, Laura Newey, sull'uso di GenAI in classe. Non perderti questi episodi pieni di spunti! [Leggi di più](https://www.embracingdigital.org)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW48-it","image":"./briefs/edw-48/it/thumbnail.png","lang":"it","summary":"Notizie sulla Trasformazione Digitale per la settimana del 1 gennaio 2024, che copre la cybersecurity, l'intelligenza artificiale e l'edge computing. Gli argomenti includono IoT e AI in agricoltura, politici ingannati da allucinazioni generate da AI e attacchi cibernetici rivolti all'assistenza sanitaria."},{"id":216,"type":"News Brief","title":"2024-1-7","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","intel","articul8","digitalbridge","genai","ethics","china","itot","upskilling","airbus","atos","solix","dataplatform","microsoft","oracle","azure","database","digitaltransformation","generativeai"],"body":"\n\n\n## Intelligenza Artificiale\n\n\n\nIntel ha recentemente annunciato lo scorporo della società di software AI Articul8, supportata da DigitalBridge. La mossa è finalizzata a migliorare le capacità di AI aziendale. Articul8 si concentrerà sullo sviluppo di soluzioni AI avanzate, sfruttando l'esperienza di Intel nel campo. Questa mossa strategica sottolinea l'impegno di Intel nel promuovere le tecnologie di intelligenza artificiale per applicazioni industriali più ampie. [Leggi di più](https://www.reuters.com/technology/intel-spins-out-ai-software-firm-with-backing-digitalbridge-2024-01-03/)\n\n\n\nUna relazione su GenAI da Affari Esteri discute le preoccupazioni riguardo l'impatto dell'intelligenza artificiale sui valori democratici degli Stati Uniti. Il rapporto evidenzia il potenziale abuso di IA in attività come disinformazione e sorveglianza, e sottolinea la necessità di linee guida etiche e quadri normativi per affrontare queste preoccupazioni e proteggere i principi fondamentali della democrazia. [Leggi di più](https://www.foreignaffairs.com/united-states/artificial-intelligences-threat-democracy)\n\n\n\nLa Cina ha recentemente diffuso linee guida per i ricercatori di intelligenza artificiale, impedendo loro di utilizzare certi fondi per scopi legati all'uso militare. L'obiettivo delle linee guida è garantire che la tecnologia di intelligenza artificiale sia utilizzata per scopi pacifici ed etici, concentrandosi sul prevenire il suo abuso in aree che potrebbero potenzialmente danneggiare la sicurezza internazionale. Questa mossa evidenzia la determinazione della Cina a plasmare lo sviluppo etico e l'applicazione dell'intelligenza artificiale, sottolineando il suo impegno nell'uso responsabile della tecnologia dell'intelligenza artificiale. [Leggi di più](https://www.scmp.com/news/china/science/article/3247420/china-unveils-new-artificial-intelligence-guidelines-scientists-and-bans-use-funding-applications)\n\n## Cybersecurity\n\n\n\nL'analisi di Security Intelligence sottolinea l'importanza di integrare IT e OT nella sicurezza informatica. Questa convergenza è fondamentale per proteggere i sistemi industriali contro le minacce informatiche. L'analisi esplora sfide e vantaggi ed evidenzia la necessità di una strategia di sicurezza completa. [Leggi di più](https://securityintelligence.com/posts/it-and-ot-cybersecurity-integration/)\n\n\n\nL'apprendimento continuo in materia di sicurezza informatica è fondamentale per colmare il divario di competenze. Un recente rapporto sostiene la necessità di potenziare il talento esistente e di investire in programmi di formazione per soddisfare la domanda di professionisti qualificati. Le organizzazioni devono promuovere una cultura di miglioramento continuo delle competenze per migliorare la resilienza cibernetica. [Leggi di più](https://www.informationweek.com/cyber-resilience/upskilling-is-the-secret-to-closing-the-cybersecurity-skills-gap-)\n\n\n\nAirbus sta acquisendo l'unità di cybersecurity di Atos per due miliardi di dollari, per rafforzare le sue capacità di cybersecurity nei settori ICS-OT. La mossa sottolinea la necessità di misure robuste di cybersecurity nell'infrastruttura critica, in particolare nelle industrie in cui la tecnologia operativa svolge un ruolo fondamentale. L'affare implica un passo strategico verso il miglioramento della cybersecurity all'interno del quadro operativo di Airbus. [Leggi di più](https://www.darkreading.com/ics-ot-security/airbus-acquire-atos-cybersecurity-unit-2-billion)\n\n## Gestione dei Dati\n\n\n\nSolix ha rivelato una Piattaforma di Dati per l'impresa per l'era \"Gen AI\". Si prefigge di offrire soluzioni avanzate di gestione dei dati per soddisfare le esigenze in continua evoluzione delle tecnologie AI. La piattaforma di Solix è incentrata sull'ottimizzazione delle capacità di elaborazione e di archiviazione dei dati per supportare le richieste delle applicazioni e delle analisi guidate dall'AI. Questa mossa indica un passo strategico verso l'abilitazione dell'efficiente utilizzo dei dati nel campo dell'intelligenza artificiale in rapida avanzata. [Leggi di più](https://venturebeat.com/data-infrastructure/solix-launches-new-enterprise-data-platform-for-the-gen-ai-era/)\n\n\n\nMicrosoft e Oracle si sono unite per migliorare la compatibilità tra i loro database, Microsoft SQL Server e Oracle Database, sulla piattaforma cloud di Microsoft, Azure. Questa partnership mira a fornire un'esperienza senza soluzione di continuità per gli utenti che eseguono questi database su Azure, con prestazioni e flessibilità migliorate. La collaborazione punta a soddisfare le crescenti esigenze delle soluzioni di database basate sul cloud, supportando l'interoperabilità e la facilità d'uso per le aziende che utilizzano sia le tecnologie Microsoft che Oracle su Azure. [Leggi di più](https://www.infoq.com/news/2024/01/microsoft-oracle-database-azure/)\n\n\n\nNel duemila e ventiquattro, i dati aziendali e le tecnologie di intelligenza artificiale stanno subendo cambiamenti significativi. Le tendenze includono il ruolo in espansione dell'intelligenza artificiale nella gestione dei dati, un maggiore enfasi sull'etica dei dati e sulla privacy, l'ascesa dell'analitica aumentata e l'influenza del calcolo edge sul processing dei dati. Si sollecitano le organizzazioni ad adattarsi a queste dinamiche in evoluzione per rimanere competitive e sfruttare il pieno potenziale dei dati e delle tecnologie di intelligenza artificiale quest'anno. [Leggi di più](https://tdwi.org/articles/2024/01/05/ta-all-shifting-sands-in-enterprise-data-and-ai-technologies-in-2024.aspx)\n\n## Podcast Abbracciando la Trasformazione Digitale\n\n\n\nQuesta settimana nel podcast, Darren continua la sua serie su \"Come Accogliere l'IA Generativa\" quando intervista Laura Newey dopo un semestre di insegnamento d'inglese all'università con Chat GPT e l'IA Generativa come strumento. Devi verificare quest'episodio e condividerlo con i tuoi studenti universitari. [Leggi di più](https://www.embracingdigital.org/en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW49-it","image":"./briefs/edw-49/it/thumbnail.png","lang":"it","summary":"Intel ha recentemente annunciato la scissione della società di software di intelligenza artificiale Articul8, sostenuta da DigitalBridge. La mossa è volta a migliorare le capacità di intelligenza artificiale aziendale. Articul8 si concentrerà sullo sviluppo di soluzioni avanzate di intelligenza artificiale, sfruttando l'esperienza di Intel nel campo. Questa mossa strategica sottolinea l'impegno di Intel nel promuovere le tecnologie di intelligenza artificiale per applicazioni industriali più ampie."},{"id":217,"type":"News Brief","title":"2023-3-5","tags":null,"body":"\n\n## Intelligenza Artificiale\n\nI Chatbot basati su Intelligenza Artificiale generativa sono lontani dalla perfezione. ChatGPT, il chatbot di Bing di Microsoft, Galactica di Meta (un'IA generativa progettata per aiutare gli scienziati con compiti come annotare proteine o scrivere codice) e altri sistemi sono stati rimossi o limitati dopo essere stati trovati a generare informazioni non affidabili o errate o a cadere in reazioni emotive che sembrano addirittura minacciose.\n\nI governi degli Stati Uniti e dell'Europa stanno collaborando in uno studio di ricerca sull'intelligenza artificiale al fine di sviluppare strategie per regolamentare e favorire l'innovazione nell'AI. Lo studio coprirà cinque aree: previsioni meteorologiche e climatiche estreme, gestione delle emergenze, miglioramenti nella salute e nella medicina, ottimizzazione della rete elettrica e ottimizzazione dell'agricoltura. Tra i partecipanti ci sono il Dipartimento dell'Energia degli Stati Uniti, il Dipartimento dell'Agricoltura, il Pentagono, l'Amministrazione Nazionale Oceanica e Atmosferica, agenzie di salute e scienze e i loro omologhi europei.\n\n[https://www.axios.com/2023/03/01/ai-research-us-eu](https://www.axios.com/2023/03/01/ai-research-us-eu)\n\nAirdot Deploy: Distribuisce automaticamente modelli di machine learning e li scala. Identifica automaticamente i pacchetti necessari, comprende le dipendenze dei moduli, rifattorizza il codice, costruisce API REST intorno al modello di machine learning, lo confeziona in un container, avvia l'infrastruttura, lo scala automaticamente su e giù e configura avvisi e monitoraggio automatizzati, tutto con una sola riga di codice. Tutto questo per il tuo team DevOps.\n\n[https://www.airdot.io/blog/announcing-airdot-deploy-ml](https://www.airdot.io/blog/announcing-airdot-deploy-ml)\n\n## Cibersicurezza.\n\nUn rapporto di Tenable rivela che gli attacchi informatici vengono principalmente effettuati utilizzando vulnerabilità conosciute per le quali esistono già patch disponibili. Gli attori delle minacce continuano ad exploitare vulnerabilità che le organizzazioni non sono riuscite a correggere o risolvere, tra cui difetti di gravità elevata in Microsoft Exchange e soluzioni di rete privata virtuale.\n\n[https://www.helpnetsecurity.com/2023/03/03/known-exploitable-vulnerabilities/?web_view=true](https://www.helpnetsecurity.com/2023/03/03/known-exploitable-vulnerabilities/?web_view=true)\n\nI CISO municipalizzati affrontano sfide crescenti di fronte all'aumento delle minacce cibernetiche, con gli attacchi ransomware che rappresentano la preoccupazione maggiore. Oakland, in California, ha recentemente dichiarato lo stato di emergenza a seguito di un attacco ransomware del Playgroup che ha interrotto i sistemi telefonici e i servizi non di emergenza. Questo attacco si inserisce in una serie di attacchi ransomware contro governi locali negli Stati Uniti, tra cui quelli di Baltimore, New Orleans, Pensacola e Atlanta.\n\n[https://www.csoonline.com/article/3688958/municipal-cisos-grapple-with-challenges-as-cyber-threats-soar.html](https://www.csoonline.com/article/3688958/municipal-cisos-grapple-with-challenges-as-cyber-threats-soar.html)\n\nIl presidente Biden ha firmato il Quantum Computing Cybersecurity Preparedness Act, che richiede alle agenzie federali di dare la priorità all'utilizzo di tecnologie resistenti alla quantistica. La legge impone linee guida per valutare i sistemi critici con gli standard crittografici post-quantistici. Questo è in risposta alle paure che la tecnologia quantistica renda vulnerabile la crittografia esistente a essere violata rapidamente.\n\n[https://fedscoop.com/biden-signs-quantum-computing-cybersecurity-act-into-law/](https://fedscoop.com/biden-signs-quantum-computing-cybersecurity-act-into-law/)\n\n## Calcolo ubiquo\n\nIl rapporto annuale di Accenture sul cloud banking ha scoperto che le banche che mirano alla migrazione verso il cloud dei sistemi principali si trovano di fronte a un importante fattore di rischio nella difficoltà di reperire talenti nel cloud. Le banche percepiscono la migrazione principale come ad alto rischio a causa della mancanza di personale con competenze nel cloud e della difficoltà di reclutare le competenze richieste nell'attuale ambiente di lavoro. L'adozione del cloud pubblico rappresenta sia un aggiornamento della sicurezza che un fattore di rischio, riflettendo la mancanza di adozione del cloud nell'industria bancaria.\n\n[https://www.ciodive.com/news/banks-finance-cloud-migration-skils-gap-cybersecurity/644169/](https://www.ciodive.com/news/banks-finance-cloud-migration-skils-gap-cybersecurity/644169/)\n\nLa società di data warehouse basata su cloud Snowflake prevede di aggiungere oltre 1.000 dipendenti nell'attuale anno fiscale, secondo il CFO Mike Scarpelli durante la call sugli utili del Q4 dell'azienda. Ciò segue l'aggiunta di 1.900 persone lo scorso anno, in contrasto con la tendenza al downsizing tra le altre grandi aziende tecnologiche. Snowflake prevede di dare la priorità alle assunzioni nel prodotto, nell'ingegneria e nelle vendite.\n\n[https://www.ciodive.com/news/Snowflake-expands-workforce-extends-AWS-partnership/644034/](https://www.ciodive.com/news/Snowflake-expands-workforce-extends-AWS-partnership/644034/)\n\nSecondo gli esperti del settore, i CIO devono ristrutturare i loro dipartimenti e strategie IT per sfruttare appieno la trasformazione del cloud. Neil Holden, CIO presso il gruppo Halfords, ritiene che i dipartimenti IT debbano operare in modo diverso a causa del cloud e di ciò che significa per l'azienda. Holden ha riorganizzato il suo team per assicurarsi che potessero massimizzare le capacità e le opportunità commerciali fornite dal cloud.\n\n[https://www.cio.com/article/463595/transforming-it-for-cloud-success.html](https://www.cio.com/article/463595/transforming-it-for-cloud-success.html)\n\n## Podcast sull'Abbraccio della Trasformazione Digitale\n\nGuarda l'episodio completo di questa settimana \"Innovazione come servizio\", in cui Darren intervista Andrew Cohen, direttore generale di Netsurit.\n\n[https://www.embracingdigital.org/episode-EDT127](https://www.embracingdigital.org/episode-EDT127)\n\n\n\n","guests":null,"link":"/brief-EDW5-it","image":"./briefs/edw-5/it/thumbnail.png","lang":"it","summary":"Summary"},{"id":218,"type":"News Brief","title":"2024-1-14","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","sandworm","hacking","zyxelsecurity","miraibotnet","sechack","bitcoinhack","cryptojacking","openai","aijobs","airegulation","ainetworks","mitai","aiwarfare","taiwanai","israelai","edgecomputing","iotsecurity","5ginorbit","iridiumnetwork","digitaltransformation","zero5gtrust","dataassurance"],"body":"\n\n\n## Cybersicurezza\n\n\nUna nuova ricerca di Forescout mette in discussione l'attribuzione cyber negli incidenti di hacking, rendendo difficile identificare con precisione i colpevoli. Il gruppo di hacking Sandworm potrebbe non essere stato coinvolto negli attacchi cibernetici che hanno preso di mira ventidue organizzazioni energetiche danesi nel maggio duemilaventitre, che hanno sfruttato una vulnerabilità di sicurezza nel firewall Zyxel e hanno dispiegato varianti del botnet Mirai su host infetti tramite un vettore di accesso iniziale sconosciuto. I risultati evidenziano le sfide nell'attribuire le minacce informatiche. [Leggi di più](https://thehackernews.com/2024/01/new-findings-challenge-attribution-in.html)\n\n\nL'account Twitter della Commissione per i Valori Mobiliari e le Borse degli Stati Uniti (SEC) è stato violato, con la diffusione di informazioni false su fondi negoziati in borsa basati sul Bitcoin. L'FBI sta indagando sull'hack, e la SEC ha confermato che è stato il risultato di un individuo che ha preso il controllo dell'account attraverso un terzo. L'incidente solleva preoccupazioni sulla vulnerabilità della piattaforma alla disinformazione. Gli analisti della sicurezza esprimono preoccupazione per la mancanza di autenticazione a due fattori, e i legislatori hanno criticato la SEC per aver potenzialmente minato i mercati. [Leggi di più](https://www.wired.com/story/sec-x-account-hack-investigation/)\n\n\nLe autorità ucraine, con l'aiuto di Europol e un fornitore di servizi cloud, hanno arrestato un uomo di ventinove anni a Mykolaiv per aver orchestrato un sofisticato schema di cryptojacking. Il sospetto ha infiltrato millecinquecento account appartenenti a una nota azienda statunitense utilizzando strumenti personalizzati di forza bruta. Ha creato oltre un milione di computer virtuali per garantire il funzionamento del malware, guadagnando oltre due milioni di dollari in profitti illeciti. Il cryptojacking sfrutta le credenziali compromesse sulle piattaforme cloud, consentendo l'uso non autorizzato delle risorse di calcolo per estrarre criptovalute. L'arresto del sospetto ha avuto luogo il nove gennaio. [Leggi di più](https://thehackernews.com/2024/01/29-year-old-ukrainian-cryptojacking.html)\n\n## Intelligenza Artificiale\n\n\nIl CEO di OpenAI, Sam Altman, ha espresso preoccupazione riguardo alla rapida penetrazione dell'intelligenza artificiale (IA) nella società. La descrive come la più veloce rivoluzione tecnologica, sottolineando la rapidità con cui la società deve adattarsi. Altman crede che il progresso nell'IA porterà a cambiamenti nei lavori, ma pensa anche che creerà nuove e migliori opportunità. Altman discute della necessità di un organismo di regolamentazione globale per supervisionare i robusti sistemi IA, considerando il loro impatto potenziale sulla società e sull'equilibrio geopolitico. [Leggi di più](https://www.livemint.com/technology/gadgets/amazon-republic-day-sale-top-5-smartwatches-with-up-to-77-discounts-11705312172154.html)\n\n\nUna delle sfide legate all'intelligenza artificiale (IA) e alle reti neurali è comprendere come funzionano. I ricercatori del MIT hanno sviluppato un nuovo sistema di IA che studia e spiega il comportamento delle reti neurali per affrontare questo problema. Questo sistema utilizza modelli di linguaggio pre-addestrati e consente una migliore comprensione dei calcoli della rete neurale. Inoltre, i ricercatori hanno introdotto il benchmark FIND per valutare l'accuratezza delle tecniche di interpretazione. Nonostante alcune limitazioni, il benchmark FIND è uno strumento prezioso per valutare l'efficacia delle procedure di interpretabilità. [Leggi di più](https://www.marktechpost.com/2024/01/13/mit-researchers-developed-a-new-method-that-uses-artificial-intelligence-to-automate-the-explanation-of-complex-neural-networks/)\n\n\nTaiwan e Israele stanno usando l'intelligenza artificiale per affrontare diverse sfide. Taiwan ha impiegato strategie innovative per contrastare l'interferenza straniera nelle loro elezioni, utilizzando strumenti di intelligenza artificiale per segnalare contenuti fuorvianti, stabilendo iniziative anti-disinformazione e monitorando internet per la manipolazione delle informazioni. Nel frattempo, l'esercito di Israele utilizza un sistema di intelligenza artificiale chiamato \"il Vangelo\" per localizzare i bersagli più rapidamente, riducendo le vittime civili e identificando tunnel e lanciatori di missili di Hamas. Nonostante le preoccupazioni riguardo agli errori algoritmici e al numero di morti tra i cittadini palestinesi, l'uso dell'intelligenza artificiale da parte di Israele è visto come un potenziale cambiamento di gioco nella guerra tattica. [Leggi di più](https://lynnwoodtimes.com/2024/01/14/artificial-intelligence-240114/)\n\n## Edge Computing\n\n\n\nGli Stati Uniti e l'Unione Europea hanno concordato una roadmap congiunta per un programma di etichettatura dei consumatori per prodotti per la casa intelligente e dispositivi connessi. Il programma presenterà un marchio di fiducia cyber sulla confezione del dispositivo per indicare la conformità con gli standard di sicurezza. La Federal Communications Commission sta guidando l'iniziativa e mira a finalizzare la politica e gli standard entro la fine del due mila ventiquattro. Il programma informerà i consumatori sulla sicurezza cibernetica dei dispositivi IoT, promuovendo consapevolezza e sicurezza. [Leggi di più](https://www.nextgov.com/cybersecurity/2024/01/eu-signs-iot-safety-label-plan/393328/)\n\n\n\nLa connettività IoT 5G dallo spazio è all'orizzonte, espandendo il computing edge oltre la tradizionale produzione in mattoni e malta. Iridium Communications ha recentemente lanciato il Project Stardust, un servizio di rete 5G che sfrutta la sua costellazione di satelliti in orbita bassa terrestre. Il servizio è progettato per supportare servizi 5G, dispositivi IoT, messaggistica, servizi di emergenza e tracciamento degli asset. Iridium ha iniziato a testare il servizio nel due mila venti tre e prevede di lanciarlo commercialmente nel due mila ventisei. [Leggi di più](https://www.sdxcentral.com/articles/news/iridiums-project-stardust-satellite-strategy-supports-5g-iot-from-space/2024/01/)\n\n\nNel duemilaventitre, IoT ha visto sviluppi significativi come la Direttiva sulla Cybersecurity NIS2 dell'UE, licenziamenti da parte di importanti attori tecnologici che influenzano l'IoT, il 5G nello spazio, e iniziative guidate dalla sostenibilità. Renesas ha acquisito il produttore di chip cellulari IoT Sequans per duecentoquarantanove milioni di dollari, mentre le guerre del cloud IoT si sono intensificate con Google che ha chiuso il suo servizio Core IoT. Pragmatic Semiconductor ha raccolto trecentoottantanove milioni e trecentomila dollari, e Samsara è diventata la miglior azione IoT in termini di prestazioni. L'India ha avviato il dispiegamento nazionale di contatori intelligenti, e i progressi dell'IA generativa e dell'IoT si sono combinati per fornire riparazioni guidate e insegnare ai robot con sistemi di visione. Wow! Che anno! [Leggi di più](https://iot-analytics.com/iot-2023-in-review/)\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nQuesta settimana, Darren ospiterà il suo podcast con due interviste. La prima intervista si concentrerà sulla sicurezza Zero Trust in 5G, e la seconda si concentrerà sul miglioramento dell'Assicurazione dei Dati nelle architetture cloud, concentrando l'attenzione sull'Abbracciare Zero Trust. Ascoltando, potrai imparare sulle ultime trasformazioni digitali. Abbiamo avuto un ottimo mese il mese scorso, con oltre sessantamila ascolti del podcast. Grazie per aver condiviso con i tuoi amici. [Leggi di più](https://www.embracingdigital.org/en)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW50-it","image":"./briefs/edw-50/it/thumbnail.png","lang":"it","summary":"Notizie sulla trasformazione digitale per la settimana del 15 gennaio 2024, che includono aggiornamenti su Cybersecurity, intelligenza artificiale e edge computing. Questa settimana, l'attacco all'SEC suscita allarmi, l'IA viene utilizzata per spiegare l'IA e il 5G viene implementato nello spazio."},{"id":219,"type":"News Brief","title":"2024-1-21","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms","tapestorage","filestorage","cloudstorage","sql","nosql","cpra","dataprivacy","cisa","openai","pentagon","ibm","quantumcomputing","nuclearecurity","csuite","deepfake","mcafee","digitaltransformation"],"body":"\n\n\n## Gestione dei Dati\n\n\nHammerspace ha recentemente integrato la memorizzazione su nastro nel suo sistema di file globale per migliorare le capacità di gestione dei dati. Questa integrazione consente agli utenti di accedere e gestire con efficienza i dati su diversi supporti di memorizzazione, promuovendo la flessibilità nelle soluzioni di archiviazione dei file. La soluzione attuale offerta da Hammerspace stabilisce un sistema di file globale che copre più centri di elaborazione dati, cloud e confini tradizionali di edge. [Leggi di più](https://www.techtarget.com/searchstorage/news/366566738/Hammerspaces-global-file-system-now-includes-tape)\n\n<hr>\n\n\nLa gestione dei dati eterogenei è essenziale per le imprese moderne. Toad Data Studio supporta SQL, NoSQL e database cloud, fornendo capacità complete di gestione del database. La compatibilità cross-platform semplifica i flussi di lavoro, l'ottimizzazione delle query migliora le prestazioni del database e gli strumenti di collaborazione consentono un lavoro di squadra efficiente. Pertanto, Toad Data Studio è una risorsa indispensabile per la gestione e l'amministrazione dei database in vari ambienti. [Leggi di più](https://www.infoworld.com/article/3712250/toad-data-studio-manages-sql-nosql-and-cloud-databases.html)\n\n<hr>\n\n\nSe gestisci un'attività in California, è fondamentale prepararsi per l'imminente California Privacy Rights Act (CPRA) perfezionando le tue pratiche sulla privacy dei dati. Migliorando la gestione dei dati, i meccanismi di consenso e le strategie di conformità, puoi soddisfare i requisiti CPRA e rimanere in vantaggio nella protezione della privacy del consumatore. Si raccomanda di implementare misure proattive per garantire che la tua attività si conformi pienamente al CPRA. [Leggi di più](https://www.jdsupra.com/legalnews/prepare-for-the-cpra-by-improving-your-7537199/)\n\n<hr>\n\n## Cybersecurity\n\n\nLa CISA ha rilasciato una guida completa per la risposta agli incidenti di sicurezza informatica, specifica per le aziende idriche. La guida è progettata per aiutare le aziende idriche a rispondere in modo efficace agli incidenti di sicurezza informatica e a mitigare le potenziali minacce informatiche. Fornisce preziose informazioni e funge da risorsa per le aziende idriche per rafforzare le loro capacità di risposta agli incidenti. Questa mossa rappresenta un passo significativo nella lotta contro gli attacchi informatici alle infrastrutture critiche nel settore dell'acqua. [Leggi di più](https://www.techtarget.com/searchsecurity/news/366566740/CISA-posts-incident-response-guide-for-water-utilities)\n\n<hr>\n\n\nOpenAI ha stretto una partnership con il Pentagono su un'iniziativa di cybersecurity, rappresentando un cambiamento rispetto alla sua posizione precedente. Sfruttando l'esperienza di OpenAI, la partnership mira a sviluppare le capacità di cybersecurity per la difesa. Questo sviluppo evidenzia il ruolo in evoluzione dell'IA negli sforzi di sicurezza nazionale, con OpenAI che contribuisce attivamente ai progetti di cybersecurity in collaborazione con il Pentagono. [Leggi di più](https://www.semafor.com/article/01/16/2024/openai-is-working-with-the-pentagon-on-cybersecurity-projects)\n\n<hr>\n\n\n\nIBM ha avvertito che l'emergere del calcolo quantistico potrebbe comportare una grave minaccia per la sicurezza informatica. La preoccupazione è che i computer quantistici potrebbero rompere i metodi di crittografia ampiamente utilizzati, rendendo necessario lo sviluppo di misure di sicurezza resistenti al quantico. Si sta esortando le organizzazioni a prendere misure proattive per prepararsi alle future sfide poste dal calcolo quantistico nella sicurezza informatica. [Leggi di più](https://www.bloomberg.com/news/articles/2024-01-17/quantum-computing-to-spark-cybersecurity-armageddon-ibm-says)\n\n<hr>\n\n## Intelligenza Artificiale\n\n\nL'integrazione dell'intelligenza artificiale (AI) nei processi decisionali all'interno della sicurezza atomica solleva domande stimolanti su come le tecnologie dell'AI potrebbero influenzare la stabilità, la dinamica della fiducia e l'equilibrio strategico complessivo nel contesto delle capacità nucleari. È fondamentale garantire un'implementazione responsabile dell'AI per evitare conseguenze non volute che potrebbero minacciare la sicurezza e la stabilità globale. Il bisogno critico di un'integrazione affidabile dell'AI sottolinea l'importanza di fornire un ambiente internazionale sicuro e stabile nel contesto delle capacità nucleari. [Leggi di più](https://warontherocks.com/2024/01/artificial-intelligence-and-nuclear-stability/)\n\n<hr>\n\n\nL'intelligenza artificiale (AI) è sulla buona strada per sconvolgere la suite executive in tre modi significativi. Gli esecutivi possono aspettarsi cambiamenti nei processi decisionali, nella dinamica della forza lavoro e nel ruolo complessivo dei leader. Man mano che l'AI continua a evolversi, il suo impatto trasformativo ridefinisce i paradigmi di leadership tradizionali. Si incoraggiano gli esecutivi ad adattarsi a questi cambiamenti e a sfruttare strategicamente l'IA per un vantaggio competitivo nell'ambiente aziendale dinamico. [Leggi di più](https://www.cio.com/article/1293438/3-ways-ai-is-set-to-disrupt-the-c-suite.html)\n\n<hr>\n\n\nMcAfee ha lanciato un sistema di rilevazione audio fasullo alimentato dall'intelligenza artificiale per affrontare la crescente minaccia dei contenuti audio manipolati. La tecnologia è progettata per identificare e mitigare i rischi associati all'audio fasullo, sottolineando la necessità di soluzioni avanzate di rilevazione e prevenzione. Questo riflette l'importanza crescente dell'intelligenza artificiale nel contrastare le minacce emergenti nei media manipolati e nel potenziare le misure di sicurezza informatica. [Leggi di più](https://www.artificialintelligence-news.com/2024/01/08/mcafee-unveils-ai-powered-deepfake-audio-detection/)\n\n<hr>\n\n## Abbracciando la Trasformazione Digitale\n\n\n\nL'ultimo episodio di Darren nel podcast \"Abbracciando la Trasformazione Digitale\" approfondisce il mondo della gestione dei dati di ricerca e sviluppo nella produzione. Esamina le complessità della raccolta e dell'analisi dei dati, dalla ricerca pura innovativa al processo di produzione più prevedibile. È un'analisi perspicace delle sfide e delle opportunità della trasformazione digitale in questo campo. [Leggi di più](https://www.embracingdigital.org)\n\n<hr>\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW51-it","image":"./briefs/edw-51/it/thumbnail.png","lang":"it","summary":"Preparati per le notizie di questa settimana sulla Trasformazione Digitale del 22 gennaio 2024, che presenta storie sulla gestione dei dati, la cybersecurity e l'intelligenza artificiale. Questa settimana, abbiamo notizie sui diritti alla privacy dei dati in California, consigli su come proteggere la tua organizzazione da cyber-attacchi legati all'IA e alla computazione quantistica, e uno sguardo su come l'IA viene utilizzata per assistere il governo nel prendere decisioni in tempo di guerra."},{"id":220,"type":"News Brief","title":"2023-3-12","tags":null,"body":"\n\n## Intelligenza artificiale\n\nMicrosoft conferma che la nuova versione del suo popolare chatbot di intelligenza artificiale sarà in grado di trasformare il testo in VIDEO. GPT-4 e gli sviluppi futuri cambieranno per sempre il modo in cui pensiamo all'intelligenza artificiale. Questa potente IA può elaborare testo e numeri, video, immagini e altro ancora. Microsoft ha spiegato che GPT-4 sarebbe \"multimodale\". Holger Kenn, Direttore della Strategia Aziendale di Microsoft Germany, ha spiegato che ciò consentirebbe all'IA dell'azienda di tradurre il testo dell'utente in immagini, musica e video.\n\nAI per sostituire gli attori? Immaginate di utilizzare l'AI per creare un film senza assumere attori reali o scrivere un libro completamente illustrato di 200 pagine in un solo giorno. Sì, avete letto bene, il GPT-4 rende possibile utilizzare l'intelligenza artificiale per quasi tutto ciò che potete immaginare.\n\nSchrodinger: un simulatore di mercato finanziario multi-agente completamente interattivo integrato con ChatGPT. Citadel, uno dei fondi di investimento più di successo al mondo, sta discutendo per ottenere una licenza ChatGPT a livello aziendale. ChatGPT può produrre codice corretto con una strategia di esecuzione degli scambi semplice.\n\n[https://www.youtube.com/watch?v=tvzO79V9uq4](https://www.youtube.com/watch?v=tvzO79V9uq4)\n\n## Gestione dei dati\n\n\"Zero\" è la nuova parola del giorno, con la \"Data Alliance\" che ha coniato il termine Zero-Copy per le nuove architetture dati distribuite. L'integrazione Zero-Copy è un concetto che consente ai dati di essere condivisi tra diversi sistemi senza copiarli. L'approccio tradizionale di copiare i dati da un sistema all'altro può portare a inefficienze, problemi di coerenza dei dati e vulnerabilità della sicurezza.\n\n[http://tdan.com/the-data-centric-revolution-zero-copy-integration/30462](http://tdan.com/the-data-centric-revolution-zero-copy-integration/30462)\n\nLa pandemia COVID-19 ha accelerato la visione dei dati ovunque, nel cloud, nei data center, nei laptop e nei dispositivi IoT. Questa proliferazione dei dati ha costretto le organizzazioni IT a rivalutare le loro strategie dati. Sono necessarie nuove strategie e soluzioni gestionali dati distribuite che siano più comprehensive nel gestire tipologie di dati eterogenei, tra cui dati strutturati, semi-strutturati e non strutturati.\n\n[https://www.engineeringnews.co.za/article/modern-data-management-platforms-are-vital-for-solving-modern-data-management-problems-2023-03-14/rep_id:4136](https://www.engineeringnews.co.za/article/modern-data-management-platforms-are-vital-for-solving-modern-data-management-problems-2023-03-14/rep_id:4136)\n\nLa complessità del governo dei dati sta guidando i cambiamenti organizzativi, compresa l'emergere del ruolo di responsabile dei dati nelle organizzazioni. I responsabili dei dati stanno iniziando a gestire l'accesso ai dati, le preoccupazioni sulla privacy e la gestione del ciclo di vita dei dati. La collocazione dei responsabili dei dati nell'organizzazione è ancora oggetto di un sano dibattito poiché le organizzazioni maturano le proprie strutture incentrate sui dati.\n\n[https://www.techtarget.com/searchdatamanagement/tip/Data-stewardship-Essential-to-data-governance-strategies](https://www.techtarget.com/searchdatamanagement/tip/Data-stewardship-Essential-to-data-governance-strategies)\n\n## Cibersicurezza\n\nUn kit di phishing AiTM open source ha trovato diversi acquirenti nel mondo del crimine informatico per la sua capacità di orchestrare attacchi in scala. Microsoft Threat Intelligence tiene traccia dell'attore minaccioso dietro lo sviluppo del kit sotto il nome emergente DEV-1101. Un attacco di phishing AiTM di solito comporta un attore minaccioso che cerca di rubare e intercettare la password e i cookie di sessione di un obiettivo, dispiegando un server proxy tra l'utente e il sito web.\n\n[https://thehackernews.com/2023/03/microsoft-warns-of-large-scale-use-of.html](https://thehackernews.com/2023/03/microsoft-warns-of-large-scale-use-of.html)\n\nL'Agenzia per la sicurezza informatica e dell'infrastruttura (CISA) ha avvertito le organizzazioni che gestiscono infrastrutture critiche sulle vulnerabilità dei ransomware nei loro dispositivi. L'avviso include un elenco di dispositivi che gli attaccanti potrebbero mirare e raccomanda alle organizzazioni di valutare le proprie reti per possibili rischi. CISA ha un nuovo programma pilota di allerta alle vulnerabilità dei ransomware (RVWP) con due obiettivi: scansionare le reti delle entità delle infrastrutture critiche e aiutare le organizzazioni vulnerabili a correggere le falle prima di essere attaccati.\n\n[https://www.bleepingcomputer.com/news/security/cisa-now-warns-critical-infrastructure-of-ransomware-vulnerable-devices/](https://www.bleepingcomputer.com/news/security/cisa-now-warns-critical-infrastructure-of-ransomware-vulnerable-devices/)\n\nUn rapporto di Drata evidenzia le principali tendenze di conformità per il 2023. Il rapporto descrive lo spostamento verso il monitoraggio continuo della conformità e la necessità di strumenti di automazione per raggiungere la conformità. Sottolinea inoltre l'aumento dell'attenzione alle normative sulla privacy e l'importanza crescente della gestione del rischio del fornitore. Il rapporto raccomanda alle aziende di dare la priorità ai loro sforzi di conformità, di utilizzare strumenti di automazione e di rimanere aggiornati sui requisiti normativi in evoluzione per evitare potenziali multe e danni reputazionali.\n\n[https://drata.com/resources/2023-compliance-trends](https://drata.com/resources/2023-compliance-trends)\n\n## Podcast sull'abbracciare la trasformazione digitale.\n\nGuarda l'episodio completo di questa settimana intitolato \"Chiudere il divario delle competenze digitali\", dove Darren intervista Jon Gottfried di Major League Hacking.\n\n[https://www.embracingdigital.org/episode-EDT128](https://www.embracingdigital.org/episode-EDT128)\n\n\n\n","guests":null,"link":"/brief-EDW6-it","image":"./briefs/edw-6/it/thumbnail.png","lang":"it","summary":"Summary"},{"id":221,"type":"News Brief","title":"2023-3-19","tags":["ai","compute","datamanagement"],"body":"\n\n## Intelligenza Artificiale\n\nNella sezione “Potenziale per comportamenti emergenti rischiosi” del rapporto tecnico dell'azienda, OpenAI ha collaborato con il Centro di Ricerca sull'allineamento per testare le abilità di GPT-4. Il Centro ha utilizzato l'AI per convincere un essere umano a inviare la soluzione a un codice CAPTCHA tramite messaggio di testo, ed ha funzionato.\n\n[https://gizmodo.com/gpt4-open-ai-chatbot-task-rabbit-chatgpt-1850227471](https://gizmodo.com/gpt4-open-ai-chatbot-task-rabbit-chatgpt-1850227471)\n\nLe caratteristiche o i difetti del Copilot di Microsoft? Dipende dalla prospettiva!! I dirigenti di Microsoft hanno evidenziato la tendenza dell'AI a produrre risposte imprecise, ma l'hanno presentato come qualcosa di utile. Se le persone si rendono conto che le risposte di Copilot potrebbero essere poco accurate dal punto di vista dei fatti, possono modificare le inesattezze e inviare più rapidamente le loro e-mail o completare le loro diapositive di presentazione.\n\n[https://www.cnbc.com/2023/03/16/microsoft-justifies-ais-usefully-wrong-answers.html?__source=sharebar|linkedin&par=sharebar](https://www.cnbc.com/2023/03/16/microsoft-justifies-ais-usefully-wrong-answers.html?__source=sharebar|linkedin&par=sharebar)\n\nGoogle Health ha annunciato Med-PaLM 2, una nuova versione innovativa del suo grande modello di linguaggio medico. Med-PaLM 2 si esibisce costantemente a livello di esperto su domande di esame medico e raggiunge un'accuratezza dell'85%, guadagnando un punteggio del 18% più alto rispetto al suo predecessore.\n\n## Calcolo Ubiquitario\n\nPresto potresti nuotare sopra un data center 😊 Un'azienda britannica di tecnologia, Deep Green, pianifica di installare piccoli data center presso le piscine pubbliche in tutto il Regno Unito. Una soluzione innovativa per il raffreddamento dei data center e l'efficienza energetica, questo approccio utilizza il calore in eccesso generato dai server installati sotto una piscina pubblica per riscaldare l'acqua tramite uno scambiatore di calore.\n\nIl governo degli Stati Uniti ha lanciato una nuova iniziativa per aiutare le organizzazioni a rilevare le falle di sicurezza nei servizi cloud di Microsoft. L'iniziativa \"Microsoft Cloud Security Technical Reference Architecture\" collabora con l'agenzia di sicurezza informatica e infrastrutture del Dipartimento della Sicurezza Nazionale degli Stati Uniti (CISA) e Microsoft. Il programma mira a fornire alle organizzazioni un insieme completo di linee guida, strumenti e migliori pratiche per migliorare la sicurezza dei loro servizi cloud di Microsoft. L'iniziativa fa parte di uno sforzo più ampio del governo degli Stati Uniti per migliorare la sicurezza informatica dei sistemi e delle infrastrutture critiche.\n\n[https://www.techradar.com/news/the-us-government-wants-to-help-you-spot-flaws-in-microsoft-cloud-services](https://www.techradar.com/news/the-us-government-wants-to-help-you-spot-flaws-in-microsoft-cloud-services)\n\nSecondo un recente sondaggio, l'83% dei Chief Information Officer (CIO) ritiene di dover fare di più con meno nel 2023. Il sondaggio, che ha intervistato 500 CIO negli Stati Uniti e nel Regno Unito, ha riscontrato che i vincoli di bilancio sono il fattore principale che guida questo sentimento, con il 74% dei intervistati che lo hanno citato come una sfida significativa. Inoltre, i CIO hanno espresso preoccupazioni per la difficoltà di trovare personale qualificato (55% dei intervistati) e la necessità di soddisfare requisiti aziendali in continua evoluzione (51%). Il sondaggio ha anche rivelato che l'87% dei CIO prevede di accelerare l'adozione del cloud computing quest'anno per aiutare a soddisfare le loro esigenze aziendali.\n\n[https://www.cloudcomputing-news.net/news/2023/mar/13/83-of-cios-must-do-more-with-less-in-2023/](https://www.cloudcomputing-news.net/news/2023/mar/13/83-of-cios-must-do-more-with-less-in-2023/)\n\n## Gestione dei dati\n\nUn sondaggio condotto da TDWI ha rilevato che le organizzazioni stanno adottando una strategia di gestione dei dati per migliorare la qualità dei dati e ridurre i silos. Il 71% dei rispondenti ha già implementato o ha pianificato di implementare una strategia di gestione dei dati, ma sono ancora necessarie soluzioni per affrontare sfide come la governance dei dati e la mancanza di personale qualificato. Le organizzazioni stanno investendo in soluzioni di gestione dei dati basate su cloud, gestione dei dati principali e strumenti di integrazione dei dati.\n\n[https://tdwi.org/articles/2023/03/23/diq-all-data-management-0323.aspx](https://tdwi.org/articles/2023/03/23/diq-all-data-management-0323.aspx)\n\nL'intelligenza artificiale (AI) ha il potenziale per aiutare a risolvere il problema dell'eccessivo sovraccarico dei dati IT. I reparti IT hanno bisogno di aiuto per gestire il volume di dati. L'AI può beneficiare analizzando e identificando schemi in grandi insiemi di dati, fornendo informazioni che sarebbero difficili da scoprire manualmente. Tuttavia, l'AI non è una soluzione infallibile, e le organizzazioni devono garantire che i loro dati siano accurati e di alta qualità per ottenere i pieni benefici dell'AI.\n\n[https://www.infoworld.com/article/3689668/can-ai-solve-it-s-eternal-data-problem.html](https://www.infoworld.com/article/3689668/can-ai-solve-it-s-eternal-data-problem.html)\n\nUn nuovo rapporto rivela l'importanza della gestione dei dati per le imprese. Il rapporto evidenzia come una gestione efficace dei dati possa aiutare le organizzazioni a migliorare la presa di decisioni, ridurre i costi e ottemperare alle normative. Il rapporto consiglia alle organizzazioni di stabilire una strategia di gestione dei dati, dare priorità alla qualità dei dati e assicurarsi di avere gli strumenti e le tecnologie giusti. Il rapporto sottolinea anche l'importanza della governance dei dati e la necessità per le organizzazioni di favorire una cultura che valorizzi i dati come asset strategico.\n\n[https://solutionsreview.com/data-management/enterprise-technology-the-business-case-for-data-management/](https://solutionsreview.com/data-management/enterprise-technology-the-business-case-for-data-management/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW7-it","image":"./briefs/edw-7/it/thumbnail.png","lang":"it","summary":"Sommario"},{"id":222,"type":"News Brief","title":"2023-3-26","tags":["ai","compute","cybersecurity"],"body":"\n\n## Calcolo Ubiquo\n\nGordon Moore, il co-fondatore della Intel Corporation e inventore della Legge di Moore, è deceduto il 24 marzo 2023, all'età di 92 anni. Nato nel 1929, Moore ha co-fondato Intel nel 1968 e ha ricoperto la carica di CEO dal 1975 al 1987. È conosciuto soprattutto per la sua previsione, la Legge di Moore, secondo cui il numero di transistor su un microchip raddoppierà approssimativamente ogni due anni, portando ad una crescita esponenziale della potenza di calcolo. Questa previsione si è mantenuta per oltre 50 anni e ha svolto un ruolo vitale nell'impulsare lo sviluppo dell'industria tecnologica.\n\nIl 4004, il primo microprocessore di Intel, debuttò nel 1971 come primo microprocessore commercialmente disponibile. Inizialmente progettato per calcolatrici, trovò rapidamente applicazioni in altri settori, come i controllori di semafori e le casse registratrici elettroniche. Il 4004 conteneva 2.300 transistor su un'unica piastra e contribuì a stabilire Intel come un grande attore dell'industria dei semiconduttori. Oggi, i microprocessori vengono utilizzati in vari dispositivi, dai telefoni intelligenti ai supercomputer.\n\nIntel ha annunciato la disponibilità della sua ultima serie di processori Xeon Max Scalable, basata sull'architettura Sapphire Rapids. La serie Xeon Max presenta 100 miliardi di transistor SuperFin a 10 nm, accelerazione AI ed encryption e supporto PCIe 5.0, fornendo prestazioni e sicurezza migliorate per i carichi di lavoro di elaborazione aziendale. Ciò corrisponde a 40 milioni di transistor in più nel processore più recente rispetto al loro primo processore oltre 50 anni fa.\n\n[https://www.datacenterdynamics.com/en/news/intel-announces-xeon-max-sapphire-rapids-cpus/](https://www.datacenterdynamics.com/en/news/intel-announces-xeon-max-sapphire-rapids-cpus/)\n\n## Intelligenza Artificiale\n\nChatGPT, un grande modello di lingua addestrato da OpenAI, ha riscontrato un problema tecnico che lo ha fatto essere offline per diverse ore. Il problema, causato da un bug nel sistema, ha colpito la funzione di cronologia del modello, rendendolo incapace di accedere alle sue precedenti conversazioni. OpenAI ha risolto il problema, e ChatGPT è ora completamente operativo. L'incidente serve come promemoria dei potenziali rischi di affidarsi all'AI e dell'importanza di avere sistemi robusti per affrontare problemi tecnici.\n\n[https://www.independent.co.uk/tech/chatgpt-down-bug-issue-history-b2306269.html](https://www.independent.co.uk/tech/chatgpt-down-bug-issue-history-b2306269.html)\n\nBard, un modello di intelligenza artificiale sviluppato da Google come concorrente del GPT di OpenAI, è ora disponibile per l'uso pubblico. Bard, che utilizza un approccio diverso alla modellizzazione del linguaggio rispetto al GPT, mira a generare testi più creativi e diversi consentendo agli utenti di inserire i loro prompt e le limitazioni. Si prevede che il rilascio di Bard per l'uso pubblico accelererà lo sviluppo di nuove applicazioni di elaborazione del linguaggio naturale e farà avanzare il campo della modellizzazione linguistica dell'IA.\n\n[https://www.bloomberg.com/news/articles/2023-03-21/google-chatgpt-rival-bard-now-open-to-public-use](https://www.bloomberg.com/news/articles/2023-03-21/google-chatgpt-rival-bard-now-open-to-public-use)\n\nUn nuovo metodo di coltivazione, la Sinicocoltura, prevede di piantare diverse specie vegetali insieme ad alta densità. Tuttavia, può essere un processo complesso a causa della diversa velocità di crescita e delle stagioni. I ricercatori hanno sviluppato un robot per seminare, potare e raccogliere piante in crescita di vegetazione densa per affrontare questo problema. Il piccolo e flessibile corpo del robot sarà utile nella Sinicocoltura su larga scala, rendendolo un passo essenziale per raggiungere l'agricoltura sostenibile e la neutralità carbonica.\n\n[https://www.sciencedaily.com/releases/2023/03/230320102001.htm](https://www.sciencedaily.com/releases/2023/03/230320102001.htm)\n\n## Sicurezza informatica\n\nL'agenzia per la sicurezza cibernetica e l'infrastruttura degli Stati Uniti (CISA) ha rilasciato un nuovo strumento per rilevare attività maligne nei servizi cloud Microsoft. Lo strumento Sparrow può scansionare ambienti Azure e Microsoft 365 alla ricerca di segni di hacking e altre attività non autorizzate. Sparrow utilizza dati open source e algoritmi di intelligenza artificiale per identificare potenziali minacce e fornire agli utenti raccomandazioni operative per prevenire ulteriori danni. Il rilascio di Sparrow fa parte degli sforzi in corso di CISA per migliorare la sicurezza dei sistemi basati su cloud e proteggere contro gli attacchi informatici.\n\n[https://www.bleepingcomputer.com/news/security/new-cisa-tool-detects-hacking-activity-in-microsoft-cloud-services/](https://www.bleepingcomputer.com/news/security/new-cisa-tool-detects-hacking-activity-in-microsoft-cloud-services/)\n\nI veicoli elettrici di Tesla sono stati hackerati due volte durante il concorso annuale di sfruttamento Pwn2Own organizzato dalla Zero Day Initiative. Un team di ricercatori è stato in grado di sfruttare una vulnerabilità nel sistema di infotainment di un Modello 3 per prendere il controllo dei fari, degli altoparlanti e di altre funzionalità del veicolo. Un altro team ha utilizzato un bug nello stesso approccio per eseguire il codice e ottenere accesso ai dati della macchina. Tesla ha poi rilasciato una patch over-the-air per correggere le vulnerabilità.\n\n[https://www.securityweek.com/tesla-hacked-twice-at-pwn2own-exploit-contest/](https://www.securityweek.com/tesla-hacked-twice-at-pwn2own-exploit-contest/)\n\nIntel ha annunciato la sua nuova piattaforma Core vPro di 13a generazione, che presenta funzionalità di sicurezza basate su hardware progettate per ridurre la superficie di attacco della piattaforma. La nuova piattaforma include Intel Hardware Shield, che utilizza la rilevazione delle minacce a livello di CPU per fornire un processo di avvio sicuro, e la tecnologia di controllo del flusso di esecuzione Intel, che aiuta a prevenire attacchi di programmazione orientata al ritorno (ROP). La piattaforma include anche la tecnologia di rilevamento delle minacce di Intel, che utilizza l'apprendimento automatico per identificare potenziali minacce alla sicurezza. La piattaforma Core vPro di 13a generazione è rivolta ai clienti commerciali che cercano funzionalità di sicurezza avanzate per proteggersi contro cyber attacchi sempre più sofisticati.\n\n[https://www.securityweek.com/intel-boasts-attack-surface-reduction-with-new-13th-gen-core-vpro-platform/](https://www.securityweek.com/intel-boasts-attack-surface-reduction-with-new-13th-gen-core-vpro-platform/)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW8-it","image":"./briefs/edw-8/it/thumbnail.png","lang":"it","summary":"Riepilogo"},{"id":223,"type":"News Brief","title":"2023-4-2","tags":["ai","compute","edge","cybersecurity","datamanagement","advancedcomms"],"body":"\n\n## Sicurezza informatica\n\nIl nuovo malware macOS MacStealer ruba i dati e le password di iCloud Keychain. Un nuovo malware per il furto di informazioni ha preso di mira il sistema operativo macOS di Apple per sottrarre informazioni sensibili dai dispositivi compromessi. MacStealer è l'ultimo esempio di una minaccia che utilizza Telegram come piattaforma di comando e controllo (C2) per esfiltrare dati.\n\nMicrosoft rilascia una patch per la vulnerabilità della privacy di aCropalypse negli strumenti di cattura schermo di Windows. Microsoft ha rilasciato un aggiornamento fuori programma per risolvere una vulnerabilità che compromette la privacy nel suo strumento di modifica degli screenshot per Windows 10 e 11. La vulnerabilità, chiamata aCropalypse, consentirebbe agli attori maligni di recuperare le parti modificate degli screenshot, potenzialmente rivelando informazioni sensibili che potrebbero essere state ritagliate.\n\nOpenAI rivela il bug di Redis dietro l'incidente di esposizione dei dati degli utenti di ChatGPT. OpenAI ha dichiarato che un bug nella libreria open-source Redis era responsabile dell'esposizione delle informazioni personali degli altri utenti e dei titoli delle chat nel servizio ChatGPT della start-up all'inizio della settimana. Il problema, emerso il 20 marzo 2023, ha permesso a determinati utenti di visualizzare brevi descrizioni delle conversazioni degli altri utenti dalla barra laterale della cronologia delle chat, suscitando preoccupazione dall'azienda.\n\n## Intelligenza artificiale\n\nQuesto è IMPORTANTE: Elon Musk, Bill Gates e altri leader tecnologici chiedono una pausa nella corsa all'IA \"fuori controllo\". Più di 1.100 firme importanti hanno appena firmato una lettera aperta chiedendo \"a tutti i laboratori di IA di fermarsi per almeno 6 mesi immediatamente\". La lettera, firmata anche dal CEO di OpenAI, ha detto che la pausa dovrebbe applicarsi ai sistemi di intelligenza artificiale \"più potenti di GPT-4\". Ha inoltre detto che esperti indipendenti dovrebbero utilizzare la pausa proposta per sviluppare e implementare congiuntamente un insieme di protocolli condivisi per strumenti di IA sicuri \"oltre ogni ragionevole dubbio\".\n\n[https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/](https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/)\n\nCerebras Systems rilascia sette nuovi modelli GPT addestrati su sistemi su larga scala basati su wafer CS-2. È la prima volta che un'azienda utilizza sistemi di intelligenza artificiale non basati su GPU per addestrare LLM fino a 13 miliardi di parametri e condivide i modelli, i pesi e la ricetta di addestramento tramite la licenza Apache 2.0 standard del settore. La serie comprende sette modelli GPT con da 111 milioni a 13 miliardi di parametri. In genere, un'operazione del genere richiede diversi mesi, ma questo lavoro è stato completato in poche settimane. Tutti e sette i modelli Cerebras-GPT sono immediatamente disponibili su Hugging Face e sullo zoo dei modelli Cerebras su GitHub.\n\n[https://www.marketwatch.com/press-release/cerebras-systems-releases-seven-new-gpt-models-trained-on-cs-2-wafer-scale-systems-2023-03-28](https://www.marketwatch.com/press-release/cerebras-systems-releases-seven-new-gpt-models-trained-on-cs-2-wafer-scale-systems-2023-03-28)\n\nGoogle Bard con Wordle – avrebbe potuto andare meglio. Dopo aver corretto il bot e ricordandogli di indovinare solo parole di cinque lettere, si è scusato e è tornato con la parola SLANTS, poi ha continuato con diverse variazioni della parola SLANT ☹\n\n[https://www.techradar.com/news/i-tried-to-use-google-bard-to-help-me-with-wordle-but-it-didnt-go-well](https://www.techradar.com/news/i-tried-to-use-google-bard-to-help-me-with-wordle-but-it-didnt-go-well)\n\n## Bordo intelligente\n\nBT ha collaborato con Amazon Web Services (AWS) per testare il calcolo al margine 5G a Manchester utilizzando AWS Wavelength. La prova indagherà su come il calcolo al margine possa migliorare le prestazioni della rete 5G di BT in tre aree chiave: realtà aumentata, giochi immersivi e automazione industriale. Lo scopo è migliorare l'esperienza del cliente fornendo servizi più veloci e affidabili. La prova fa parte di una collaborazione più ampia tra le due società per esplorare il potenziale del calcolo al margine nel Regno Unito.\n\n[https://www.edgecomputing-news.com/2023/03/29/bt-uses-aws-wavelength-for-5g-edge-trial-in-manchester/](https://www.edgecomputing-news.com/2023/03/29/bt-uses-aws-wavelength-for-5g-edge-trial-in-manchester/)\n\nComcast ha annunciato partnership ampliate volte a migliorare la connettività in edifici e ambienti intelligenti. Le partnership includono accordi con il fornitore di infrastrutture avanzate di misurazione Sensus e BuildingIQ, un provider di soluzioni di gestione dell'energia basate sull'intelligenza artificiale. L'obiettivo è fornire una gestione energetica più intelligente, una gestione dell'acqua migliore e una migliore automazione degli edifici. Queste partnership fanno parte degli sforzi di Comcast per migliorare la connettività per i clienti commerciali attraverso la sua rete di hotspot Wi-Fi, sensori e altri dispositivi IoT.\n\n[https://www.edgeir.com/comcast-focuses-connectivity-on-smarter-buildings-environments-with-expanded-partnerships-20230331](https://www.edgeir.com/comcast-focuses-connectivity-on-smarter-buildings-environments-with-expanded-partnerships-20230331)\n\n\n\n","guests":["Darren W Pulsipher"],"link":"/brief-EDW9-it","image":"./briefs/edw-9/it/thumbnail.png","lang":"it","summary":"Sommario"}]