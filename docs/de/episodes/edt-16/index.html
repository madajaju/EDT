<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!-- Dynamischer Seitentitel -->
        <title>Digitale Transformation annehmen</title>

        <!-- Meta-Beschreibung f√ºr SEO -->
        <meta name="description" content="&lt;p&gt;In dieser Episode spricht Darren dar√ºber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit √ºberraschenden Ergebnissen durchgef√ºhrt hat. Es k√∂nnte sich m√∂glicherweise darauf auswirken, wie wir in Zukunft √ºber Programmierung denken.&lt;/p&gt;
">

        <!-- Schl√ºsselw√∂rter f√ºr SEO -->
        <meta name="keywords" content="podcast, ki, edge computing, cybersicherheit, digitale transformation">

        <!-- Autor-Meta -->
        <meta name="author" content="Darren W Pulsipher">

        <!-- Open Graph-Meta-Tags f√ºr soziale Medien -->
        <meta property="og:title" content="Digitale Transformation annehmen">
        <meta property="og:description" content="&lt;p&gt;In dieser Episode spricht Darren dar√ºber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit √ºberraschenden Ergebnissen durchgef√ºhrt hat. Es k√∂nnte sich m√∂glicherweise darauf auswirken, wie wir in Zukunft √ºber Programmierung denken.&lt;/p&gt;
">
        <meta property="og:image" content="thumbnail.png">

        <meta property="og:url" content="https://embracingdigital.org">
        <meta property="og:type" content="website">

        <!-- Twitter-Karte-Meta-Tags -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:title" content="Digitale Transformation annehmen">
        <meta name="twitter:description" content="&lt;p&gt;In dieser Episode spricht Darren dar√ºber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit √ºberraschenden Ergebnissen durchgef√ºhrt hat. Es k√∂nnte sich m√∂glicherweise darauf auswirken, wie wir in Zukunft √ºber Programmierung denken.&lt;/p&gt;
">
        <meta name="twitter:image" content="thumbnail.png">

    <title>Digitale Transformation annehmen</title>

    <link rel="stylesheet" href="../../../css/styles.css">
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-P4XHVE79DL"></script>
    <script> window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-P4XHVE79DL'); </script>
</head>
<body>

<!-- üåç Navigationsleiste -->
<header>
    <div class="logo-container">
        <img src="../../../images/logo.png" alt="Digitale Transformation annehmen" class="site-icon">
    </div>
    <nav>
        <ul>
            <li><a href="../../../de/home/index.html">Startseite</a></li>
            <li><a href="../../../de/about.html">√úber uns</a></li>
            <li><a href="../../../de/episodes/index.html">Interviews</a></li>
            <li><a href="../../../de/briefs/index.html">Nachrichten</a></li>
            <li><a href="../../../de/community.html">Gemeinschaft</a></li>
            <li><a href="../../../de/guests/index.html">G√§ste</a></li>
            <li><a href="https://6704f0-2.myshopify.com/">Shop</a></li>
            <li><a href="../../../de/search.html">Suche</a></li>
            <li class="dropdown">
                <a href="#">Sprachen</a>
                <ul class="dropdown-menu">
                    <li><a href="../../../ar/home/index.html">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a></li> <!-- Arabisch -->
                    <li><a href="../../../de/home/index.html">Deutsch</a></li> <!-- Deutsch -->
                    <li><a href="../../../en/home/index.html">Englisch</a></li> <!-- Englisch -->
                    <li><a href="../../../fr/home/index.html">Franz√∂sisch</a></li> <!-- Franz√∂sisch -->
                    <li><a href="../../../it/home/index.html">Italienisch</a></li> <!-- Italienisch -->
                    <li><a href="../../../pt/home/index.html">Portugiesisch</a></li> <!-- Portugiesisch -->
                    <li><a href="../../../ja/home/index.html">Êó•Êú¨Ë™û</a></li> <!-- Japanisch -->
                </ul>
            </li>
        </ul>
    </nav>
</header>
<section id="one-episode">
    <h1 id="episode-title">#16 Verminderung der Aufnahme√ºberlastung mit Intel Optane DCPMM</h1>
    <div class="episode-container">
        <!-- YouTube Video Section -->
        <div class="video-container">
            <iframe width="auto" height="auto" src="https://www.youtube.com/embed/url?autoplay=1" title="Episode Playback"></iframe>
        </div>

        <!-- Podcast Audio Section -->
        <div class="podcast-container">
            <iframe width="100%" height="180" frameborder="no" scrolling="no" seamless="" src="https://share.transistor.fm/e/7ca179aa"></iframe>
        </div>
        <div class="show-summary">
            <p><p>In dieser Episode spricht Darren dar√ºber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit √ºberraschenden Ergebnissen durchgef√ºhrt hat. Es k√∂nnte sich m√∂glicherweise darauf auswirken, wie wir in Zukunft √ºber Programmierung denken.</p>
</p>

            <!-- Tags Section -->
            <div class="tags">
                
                    <a href="../../../de/search.html?query=artificialintelligence"><span>artificialintelligence</span></a>
                
                    <a href="../../../de/search.html?query=machinelearning"><span>machinelearning</span></a>
                
                    <a href="../../../de/search.html?query=edgecomputing"><span>edgecomputing</span></a>
                
                    <a href="../../../de/search.html?query=datamanagement"><span>datamanagement</span></a>
                
                    <a href="../../../de/search.html?query=multicloud"><span>multicloud</span></a>
                
                    <a href="../../../de/search.html?query=zerotrust"><span>zerotrust</span></a>
                
                    <a href="../../../de/search.html?query=process"><span>process</span></a>
                
                    <a href="../../../de/search.html?query=technology"><span>technology</span></a>
                
            </div>

            <!-- Guests Section -->
            <div class="guests">
                
                <a href="../../../de/guests/darren-w-pulsipher/index.html" target="_blank">Darren W Pulsipher</a>
            </div>
        </div>

        <!-- Show Notes Section -->
        <div class="show-notes">
            <h2>Service-Stapel-Details</h2>
<p>Ein Kunde in der Automobilindustrie hatte Schwierigkeiten, effektiv Informationen aus seinen Autos zu gewinnen und in sein Rechenzentrum zu √ºbertragen, um maschinelles Lernen und Analysen durchf√ºhren zu k√∂nnen. Es gab bereits Forschung in diesem Bereich, aber nur f√ºr eine kleine Anzahl von Autos, nicht f√ºr die hundert Millionen Autos des Kunden. Als ich mir den gesamten Service-Stack ansah und wie alles ins Rechenzentrum gelangte, wurde deutlich, dass die Daten√ºbernahme das Hauptproblem war: Wie kann ich so viele Daten aufnehmen und wie kann ich es schnell tun?</p>
<h2>Hoher √úberblick √ºber die Kafka-Architektur auf hoher Ebene</h2>
<p>Der Kunde wollte Kafka f√ºr ihre Daten√ºbernahme verwenden. Kafka ist ein Broker, der gut skalierbar ist, und der Schl√ºssel dazu ist, dass er mehrere Produzenten, verschiedene Verbraucher und viele Daten verarbeiten kann. Die Verwendung mehrerer Kafka-Broker, um Daten an den geeignetsten Stellen zu platzieren und abzuladen, bietet gro√üe Flexibilit√§t.</p>
<p>Kafka hingegen wurde haupts√§chlich f√ºr Nachrichtengr√∂√üen von etwa einem bis zehn Kilobyte konzipiert, w√§hrend die Kundendaten pro Fahrzeug etwa 240 Kilobyte betrugen. Es gibt zwar L√∂sungen, aber ich wollte die gesamte 240 Kilobyte-Nachricht in den Kafka-Bus einbringen, um sie nach Bedarf verschieben zu k√∂nnen.</p>
<h2>Leistungsspitzen-Bew√§hrte Methoden</h2>
<p>Ich habe mir die Leistungsempfehlungen anderer Personen angesehen, die mit Kafka arbeiten, um herauszufinden, ob ich es f√ºr meinen Kunden skalieren kann. Eine M√∂glichkeit zur Feinabstimmung besteht darin, die Puffergr√∂√üe zu erh√∂hen, um die gesamte Nachricht aufnehmen zu k√∂nnen, zusammen mit der Verwaltung der Stapelgr√∂√üe f√ºr optimale Leistung. Eine weitere erfolgreiche Praxis besteht darin, die Logs zu verteilen. Die Flexibilit√§t von Kafka erm√∂glicht es mir, die Daten in verschiedene Themenbereiche zu platzieren. Ich kann die Themenbereiche in mehrere Partitionen aufteilen, die sich √ºber mehrere Laufwerke erstrecken. Die Frage ist also, auf wie vielen Laufwerken ich die Kafka-Logs verteile. Dar√ºber hinaus m√∂chte ich die schnellstm√∂glichen Laufwerke haben.</p>
<p>Ein Beispiel, das ich untersucht habe, war LinkedIn. Ihre ver√∂ffentlichten Zahlen von vor einem Jahr besagen, dass sie 13 Millionen Nachrichten pro Sekunde verarbeiten k√∂nnen, oder 2,7 Gigabyte pro Sekunde. Sie geben an, dass sie etwa 1.100 Kafka-Broker und mehr als 60 in einem Cluster haben, das ist eine ziemlich gro√üe Konfiguration.</p>
<h2>Automobilraum</h2>
<p>Wenn ich mir die rohen Zahlen des Kunden anschaue (1,6 Millionen Nachrichten pro Sekunde und 800 Gigabyte pro Sekunde) und sie mit LinkedIn vergleiche, das wahrscheinlich nicht f√ºr 240 Kilobyte optimiert ist, komme ich auf 44.000 Broker. Wenn ich es optimiere, k√∂nnte ich wahrscheinlich auf 4.400 Broker kommen, was immer noch 240 Cluster sind. Das ist eine riesige Anzahl von Maschinen, also musste ich mir √ºberlegen, wie ich die Dinge schneller machen kann. Mit noch mehr Optimierung k√∂nnte ich wahrscheinlich auf 400 bis 500 Broker kommen, aber ich wollte sehen, was noch m√∂glich ist.</p>
<h2>Intel Optane DC Persistent Memory</h2>
<p>Ich habe nach unserem Optane Persistent Memory geschaut. Es passt in ein DDR4-Format und sitzt somit direkt am DDR4-Bus. Es gibt Module mit bis zu 512 Gigabyte, sodass ich in einem Zwei-Sockel-Server sechs Terabyte an persistentem Speicher haben kann. Ich wollte eine M√∂glichkeit finden, diese √§u√üerst zuverl√§ssige Technologie mit gro√üartigen Funktionen wie der integrierten Hardwareverschl√ºsselung zu nutzen, um mir bei der L√∂sung dieses Problems zu helfen.</p>
<h2>Unterst√ºtzung f√ºr eine Vielzahl von Anwendungen</h2>
<p>Es gibt zwei Betriebsmodi f√ºr diese Optane Memory: der direkte App-Modus und der Speichermodus. Der Speichermodus ist einfach. Es verwendet den persistenten Speicher als normalen RAM, da er g√ºnstiger ist als normaler DDR4. Es ist zwar nicht dasselbe wie DDR4, aber es ist nah genug dran, dass man in den meisten Anwendungen keinen Unterschied sieht. Im Direktmodus der App k√∂nnen Sie tats√§chlich direkt aus Ihrem Programm in den persistenten Speicher schreiben. Auf diese Weise muss ich Datenstrukturen nicht mehr manuell umwandeln und streamen; ich kann sie einfach in den persistenten Speicher schieben. Ich kann den Direktmodus der App auch als Dateisystem mounten, so dass er auf dem Speicherbus liegt, was viel schneller ist als auf dem IO-Bus. Nun, was kann ich mit diesem Speicher tun?</p>
<h2>Verwendung des Linux-Kernels</h2>
<p>Es gibt zwei Hauptwerkzeuge, die mit dem Linux-Kernel verwendet werden k√∂nnen: ndctl und ipmctl. Ndctl ist ein nichtfl√ºchtiger Speicherger√§te-Controller, und dann gibt es IPM, den Intel Persistent Memory Controller, mit dem ich diesen persistenten Speicher manipulieren und kontrollieren kann. Ich kann ihn im Memory-Modus oder im App-Direct-Modus einrichten. Ich musste ein bisschen √ºber diese Werkzeuge und wie sie funktionieren lernen.</p>
<h2>Ansatz der Aufnahme</h2>
<p>Mein erster Gedanke war, dass, wenn ich Kafka mehr Speicher mit gro√üen Puffergr√∂√üen gebe, es viel schneller laufen sollte. Code-√Ñnderungen in der Konfiguration w√§ren unn√∂tig oder minimal. Eine weitere Option bestand darin, Kafka so zu √§ndern, dass es in persistenten Speicher schreibt, anstatt auf ein Dateisystem zu schreiben, wodurch die Festplatte umgangen wird. Das letzte, worauf ich geachtet habe, war die Erstellung eines persistenten Dateisystems mit persistentem Speicher und dann das Platzieren der Kafka-Logs auf diesem neuen Dateisystem.</p>
<p>Die einfachste der drei Optionen war die erste ‚Äì mehr Speicher. Ich habe alle meine Aufgaben mit mehr Speicher ausgef√ºhrt, aber es gab keine Ver√§nderung in der Leistung. Der Grund daf√ºr ist, dass letztendlich meine Puffer gef√ºllt wurden und ich auf ein Laufwerk auslagern musste. Letztendlich musste alles in die Kafka-Logs, was mein Engpass war.</p>
<p>Die zweite Option beinhaltet das Umschreiben des Codes und das Warten auf Genehmigungen, also bin ich zur dritten Option √ºbergegangen. Die Ergebnisse dieses Experiments, bei dem ich die Logs auf dieses neue, ultraschnelle Dateisystem gezeigt habe, waren faszinierend. Schauen wir uns den Prozess und die Ergebnisse an.</p>
<h2>Testeinschr√§nkungen</h2>
<p>Um Hindernisse f√ºr die Leistungstestung zu beseitigen, habe ich das Netzwerk au√üer Acht gelassen, indem ich meinen Test auf derselben Maschine durchgef√ºhrt habe, auf der sich mein Broker befand. Au√üerdem habe ich zun√§chst nur Produzenten, dann nur Verbraucher und danach gemischte Tests durchgef√ºhrt, um die Unterschiede absch√§tzen zu k√∂nnen. Mein Ziel war es nicht, eine Gesamtverbesserung der Produktion zu betrachten, sondern herauszufinden, ob dies einen wirklichen Unterschied f√ºr einen einzelnen Broker macht.</p>
<h2>Erster Ansatz 50/50</h2>
<p>Das erste, was ich gemacht habe, war, die H√§lfte meines persistenten Speichers in den App-Direct-Modus zu versetzen und es in ein Dateisystem umzuwandeln. Die andere H√§lfte lie√ü ich als Speicher. Ich habe die Befehle &quot;ndctl&quot; und &quot;ipmctl&quot; verwendet und Namensr√§ume erstellt. Diese Dateisysteme habe ich eingebunden und meinen Test ausgef√ºhrt.</p>
<h2>√Ñndern der Nachrichtengr√∂√üe</h2>
<p>Ich habe die Tests f√ºr verschiedene Nachrichtengr√∂√üen durchgef√ºhrt. Ich habe eine bestimmte Optimierung erwartet, vor allem f√ºr 1 Kilobyte. Ich habe festgestellt, dass die Leistung bis zu etwa 10 Produzenten immer besser wurde. Ab dem Zeitpunkt, an dem ich mehr als 10 Produzenten hatte, wurde der Bus ges√§ttigt und es traten einige Schwankungen auf. Das sagt mir, dass ich etwas zwischengespeichert habe. Ich kann nun diese Zahlen mit dem vergleichen, was ich zuvor nur auf einer SATA-Festplatte f√ºr die Kafka-Protokolle getestet habe. Ich habe auch unsere Optane-NVMe-Laufwerke f√ºr die Protokolle ausprobiert.</p>
<h2>Technologievergleich</h2>
<p>Lassen Sie uns einen Blick auf die Unterschiede werfen. Bei 240 Kilobyte ist es mit einer normalen SATA-Festplatte ziemlich flach. Ich habe eine Verbesserung festgestellt, und dann nahm sie ab, als die Anzahl der Produzenten zunahm. Mit der Optane NVMe-Festplatte habe ich einen sch√∂nen H√∂hepunkt erreicht, fast doppelt so schnell wie eine SATA-Festplatte, was ich erwartet habe, denn es handelt sich um einen NVMe-Bus anstelle eines SATA-Busses. Der Pmem ist fast f√ºnfmal schneller als eine SATA-Festplatte und zweieinhalbmal schneller als die Optane NVMe-Festplatte. Das liegt daran, dass ich einen Speicherbus anstelle des SATA- oder NVMe-Busses verwende.</p>
<h2>Zus√§tzliche Optimierung (100% App Direkt)</h2>
<p>Dies lief schnell und ich habe diesen tempor√§ren 750 GB-Laufwerk schnell gef√ºllt. Da ich den Test noch ein wenig l√§nger durchf√ºhren musste, bin ich zur√ºckgegangen und habe meine Maschine so umkonfiguriert, dass sie den 100-prozentigen Direktanwendungsmodus verwendet, um jetzt die gesamten 1,5 Terabyte nutzen zu k√∂nnen.</p>
<h2>Optimiertes PMEM und 100% App Direct.</h2>
<p>Nachdem ich dies getan habe und dieselben Tests durchgef√ºhrt habe, habe ich ein √ºberraschendes Ergebnis erhalten. Ich konnte mehr Produzenten hinzuf√ºgen, und meine Durchsatzrate stieg um fast das Zwei- oder Dreifache. Nun ist sie zwischen 12 und 15 Mal schneller als eine SATA-Festplatte mit 25-30 Produzenten und einer Nachrichtengr√∂√üe von 240 Kilobytes. Das ist unglaublich und w√ºrde den Bedarf meiner Kunden an so vielen Brokern, Reihen und Reihen von Maschinen erheblich reduzieren. Ich habe den Test mehrmals durchgef√ºhrt, weil ich den Ergebnissen nicht glauben wollte. Ich habe einen unserer Architekten, der diese Technologie entworfen hat, angerufen und gelernt, dass einer der Gr√ºnde f√ºr die erh√∂hte Geschwindigkeit darin liegt, dass bei der Verwendung eines Teils des persistenten Speichers als Arbeitsspeicher die Daten durch zwei oder drei Hops gehen mussten, die im App-Direct-Modus nicht erforderlich sind. Dadurch wird die Konfliktmenge auf der Speicherleitung verringert, und die Durchsatzrate stieg dramatisch an.</p>
<h2>Aufruf zur Aktion</h2>
<p>Das Endergebnis ist, dass ich in der Lage war, Kafka mit Optane DC Persistent Memory als ultraschnelles Dateisystem zu verwenden, um erhebliche Verbesserungen der Durchsatzrate sowohl bei Produzenten als auch bei Konsumenten zu erzielen. Ein einzelner Broker kann jetzt 15-mal mehr Nachrichten und Durchsatz verarbeiten als zuvor, wodurch die Anzahl der f√ºr komplexe Systemarchitekturen ben√∂tigten Server verringert wird. Es ist an der Zeit, Ihre aktuelle Architektur zu √ºberpr√ºfen und zu sehen, ob dies Ihrem Unternehmen zugutekommen w√ºrde.</p>

        </div>
    </div>
    <div class="sponsor-container" >
        <p> Thank you to our sponsors for supporting this episode!</p>
        <p> Please help support future episodes by visiting our sponsors.</p>
        <ol>
        
        </ol>
    </div>
</section>
<footer id="footer">
    <div class="footer-content">
        <p>Urheberrecht &copy; 2025 Paidar Productions LLC</p>
        <p>Alle Rechte vorbehalten</p>
    </div>
</footer>
