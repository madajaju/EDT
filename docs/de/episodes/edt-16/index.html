<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Dynamischer Seitentitel -->
    <title>Embracing Digital Transformation</title>

    <!-- SEO -->
    <link rel="canonical" href="https://embracingdigital.org/de/home/">
    <meta name="description" content="&lt;p&gt;In dieser Episode spricht Darren darüber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit überraschenden Ergebnissen durchgeführt hat. Es könnte sich möglicherweise darauf auswirken, wie wir in Zukunft über Programmierung denken.&lt;/p&gt;
">
    <meta name="keywords" content="Digitale Transformation, Podcast, Interviews, Nachrichten, KI, Cybersicherheit, Edge Computing, Datenmanagement">
    <meta name="author" content="Dr. Darren W. Pulsipher">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Embracing Digital Transformation — Interviews, Nachrichten und Community">
    <meta property="og:description" content="&lt;p&gt;In dieser Episode spricht Darren darüber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit überraschenden Ergebnissen durchgeführt hat. Es könnte sich möglicherweise darauf auswirken, wie wir in Zukunft über Programmierung denken.&lt;/p&gt;
">
    <meta property="og:url" content="https://embracingdigital.org/de/home/">
    <meta property="og:image" content="https://embracingdigital.org/images/logo.png">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Embracing Digital Transformation — Interviews, Nachrichten und Community">
    <meta name="twitter:description" content="&lt;p&gt;In dieser Episode spricht Darren darüber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit überraschenden Ergebnissen durchgeführt hat. Es könnte sich möglicherweise darauf auswirken, wie wir in Zukunft über Programmierung denken.&lt;/p&gt;
">
    <meta name="twitter:image" content="https://embracingdigital.org/images/logo.png">

    <!-- Hreflang (Alternativen) -->
    <link rel="alternate" href="https://embracingdigital.org/de/home/" hreflang="de">
    <link rel="alternate" href="https://embracingdigital.org/fr/home/" hreflang="fr">
    <link rel="alternate" href="https://embracingdigital.org/it/home/" hreflang="it">
    <link rel="alternate" href="https://embracingdigital.org/pt/home/" hreflang="pt">
    <link rel="alternate" href="https://embracingdigital.org/ar/home/" hreflang="ar">
    <link rel="alternate" href="https://embracingdigital.org/ja/home/" hreflang="ja">
    <link rel="alternate" href="https://embracingdigital.org/en/home/" hreflang="en">
    <link rel="alternate" href="https://embracingdigital.org/de/home/" hreflang="x-default">

    <!-- Favicon & Styles -->
    <link rel="icon" href="/images/favicon.ico">
    <link rel="stylesheet" href="/css/styles.css">

    <!-- Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P4XHVE79DL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-P4XHVE79DL');
    </script>

    <!-- Schema.org: Organization + WebSite -->
    <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "Organization",
            "name": "Digitale Transformation gestalten",
            "url": "https://embracingdigital.org/",
            "logo": "https://embracingdigital.org/images/logo.png",
            "sameAs": [
                "https://www.youtube.com/@embracingdigital",
                "https://www.linkedin.com/company/embracing-digital-transformation"
            ]
        }
    </script>
    <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "WebSite",
            "name": "Digitale Transformation gestalten",
            "url": "https://embracingdigital.org/",
            "potentialAction": {
                "@type": "SearchAction",
                "target": "https://embracingdigital.org/de/search.html?query={query}",
                "query-input": "required name=query"
            }
        }
    </script>
</head>
<body>

<header role="banner">
    <!-- Logo -->
    <div class="logo-container">
        <a href="/de/home/" aria-label="Startseite — Digitale Transformation gestalten">
            <img src="/images/logo.png" alt="Logo — Digitale Transformation gestalten" class="site-icon">
        </a>
    </div>

    <!-- Mobile Navigation -->
    <button class="menu-toggle" aria-controls="primary-nav" aria-expanded="false" aria-label="Menü umschalten">☰</button>

    <!-- Hauptnavigation -->
    <nav id="primary-nav" aria-label="Hauptnavigation">
        <ul>
            <li><a href="/de/home/index.html" >Start</a></li>

            <li class="dropdown">
                <a href="/de/shows/index.html" aria-haspopup="true" aria-expanded="false">Sendungen</a>
                <ul class="dropdown-menu" role="menu">
                    <li role="none">
                        <a role="menuitem" href="/de/episodes/index.html" aria-label="Interviews — Digitale Transformation gestalten">
                            Digitale Transformation gestalten
                            <small class="nav-note">Interviews</small>
                        </a>
                    </li>
                    <li role="none">
                        <a role="menuitem" href="/de/briefs/index.html" aria-label="Nachrichten — Digital diese Woche">
                            Digital diese Woche
                            <small class="nav-note">Nachrichten</small>
                        </a>
                    </li>
                </ul>
            </li>

            <li><a href="/de/guests/index.html">Gäste</a></li>
            <li><a href="/de/articles/index.html">Artikel</a></li>

            <!-- Community -->
            <li class="dropdown">
                <a href="/de/community.html" aria-haspopup="true" aria-expanded="false">Community</a>
                <ul class="dropdown-menu" role="menu">
                    <li role="none"><a role="menuitem" href="/de/newsletter.html">Newsletter</a></li>
                    <li role="none"><a role="menuitem" href="https://www.patreon.com/embracingdigital" target="_blank" rel="noopener">Patreon</a></li>
                    <li role="none"><a role="menuitem" href="https://www.linkedin.com/company/embracing-digital-transformation" target="_blank" rel="noopener">LinkedIn Gruppe</a></li>
                </ul>
            </li>

            <li><a href="https://6704f0-2.myshopify.com/" target="_blank" rel="noopener">Shop</a></li>

            <!-- Über uns -->
            <li class="dropdown">
                <a href="/de/about.html" aria-haspopup="true" aria-expanded="false">Über uns</a>
                <ul class="dropdown-menu" role="menu">
                    <li role="none"><a role="menuitem" href="/de/about.html">Über die Sendung</a></li>
                    <li role="none"><a role="menuitem" href="/de/host.html">Moderator: Dr. Darren Pulsipher</a></li>
                    <li role="none"><a role="menuitem" href="/de/sponsors/index.html">Sponsoring & Kontakt</a></li>
                </ul>
            </li>

            <li><a href="/de/search.html">Suche</a></li>

            <!-- Sprachen -->
            <li class="dropdown">
                <a href="#" aria-haspopup="true" aria-expanded="false">Sprachen</a>
                <ul class="dropdown-menu" role="menu">
                    <li role="none"><a role="menuitem" href="/ar/home/index.html">العربية</a></li>
                    <li role="none"><a role="menuitem" href="/de/home/index.html">Deutsch</a></li>
                    <li role="none"><a role="menuitem" href="/en/home/index.html">English</a></li>
                    <li role="none"><a role="menuitem" href="/fr/home/index.html">Français</a></li>
                    <li role="none"><a role="menuitem" href="/it/home/index.html">Italiano</a></li>
                    <li role="none"><a role="menuitem" href="/pt/home/index.html">Português</a></li>
                    <li role="none"><a role="menuitem" href="/ja/home/index.html">日本語</a></li>
                </ul>
            </li>
        </ul>
    </nav>
</header>
<section id="one-episode">
    <h1 id="episode-title">#16 Verminderung der Aufnahmeüberlastung mit Intel Optane DCPMM</h1>
    <div class="episode-container">
        <!-- YouTube Video Section -->
        <div class="video-container">
            <iframe width="auto" height="auto" src="https://www.youtube.com/embed/url?autoplay=1" title="Episode Playback"></iframe>
        </div>

        <!-- Podcast Audio Section -->
        <div class="podcast-container">
            <iframe width="100%" height="180" frameborder="no" scrolling="no" seamless="" src="https://share.transistor.fm/e/7ca179aa"></iframe>
        </div>
        <div class="show-summary">
            <p><p>In dieser Episode spricht Darren darüber, wie man den Verzehr von Staus mit Intels Optane DC Persistent-Speicher verringern kann und das Experiment, das er mit überraschenden Ergebnissen durchgeführt hat. Es könnte sich möglicherweise darauf auswirken, wie wir in Zukunft über Programmierung denken.</p>
</p>

            <!-- Tags Section -->
            <div class="tags">
                
                    <a href="../../../de/search.html?query=artificialintelligence"><span>artificialintelligence</span></a>
                
                    <a href="../../../de/search.html?query=machinelearning"><span>machinelearning</span></a>
                
                    <a href="../../../de/search.html?query=edgecomputing"><span>edgecomputing</span></a>
                
                    <a href="../../../de/search.html?query=datamanagement"><span>datamanagement</span></a>
                
                    <a href="../../../de/search.html?query=multicloud"><span>multicloud</span></a>
                
                    <a href="../../../de/search.html?query=zerotrust"><span>zerotrust</span></a>
                
                    <a href="../../../de/search.html?query=process"><span>process</span></a>
                
                    <a href="../../../de/search.html?query=technology"><span>technology</span></a>
                
            </div>

            <!-- Guests Section -->
            <div class="guests">
                
                <a href="../../../de/guests/darren-w-pulsipher/index.html" target="_blank">Darren W Pulsipher</a>
            </div>
        </div>

        <!-- Show Notes Section -->
        <div class="show-notes">
            <h2>Service-Stapel-Details</h2>
<p>Ein Kunde in der Automobilindustrie hatte Schwierigkeiten, effektiv Informationen aus seinen Autos zu gewinnen und in sein Rechenzentrum zu übertragen, um maschinelles Lernen und Analysen durchführen zu können. Es gab bereits Forschung in diesem Bereich, aber nur für eine kleine Anzahl von Autos, nicht für die hundert Millionen Autos des Kunden. Als ich mir den gesamten Service-Stack ansah und wie alles ins Rechenzentrum gelangte, wurde deutlich, dass die Datenübernahme das Hauptproblem war: Wie kann ich so viele Daten aufnehmen und wie kann ich es schnell tun?</p>
<h2>Hoher Überblick über die Kafka-Architektur auf hoher Ebene</h2>
<p>Der Kunde wollte Kafka für ihre Datenübernahme verwenden. Kafka ist ein Broker, der gut skalierbar ist, und der Schlüssel dazu ist, dass er mehrere Produzenten, verschiedene Verbraucher und viele Daten verarbeiten kann. Die Verwendung mehrerer Kafka-Broker, um Daten an den geeignetsten Stellen zu platzieren und abzuladen, bietet große Flexibilität.</p>
<p>Kafka hingegen wurde hauptsächlich für Nachrichtengrößen von etwa einem bis zehn Kilobyte konzipiert, während die Kundendaten pro Fahrzeug etwa 240 Kilobyte betrugen. Es gibt zwar Lösungen, aber ich wollte die gesamte 240 Kilobyte-Nachricht in den Kafka-Bus einbringen, um sie nach Bedarf verschieben zu können.</p>
<h2>Leistungsspitzen-Bewährte Methoden</h2>
<p>Ich habe mir die Leistungsempfehlungen anderer Personen angesehen, die mit Kafka arbeiten, um herauszufinden, ob ich es für meinen Kunden skalieren kann. Eine Möglichkeit zur Feinabstimmung besteht darin, die Puffergröße zu erhöhen, um die gesamte Nachricht aufnehmen zu können, zusammen mit der Verwaltung der Stapelgröße für optimale Leistung. Eine weitere erfolgreiche Praxis besteht darin, die Logs zu verteilen. Die Flexibilität von Kafka ermöglicht es mir, die Daten in verschiedene Themenbereiche zu platzieren. Ich kann die Themenbereiche in mehrere Partitionen aufteilen, die sich über mehrere Laufwerke erstrecken. Die Frage ist also, auf wie vielen Laufwerken ich die Kafka-Logs verteile. Darüber hinaus möchte ich die schnellstmöglichen Laufwerke haben.</p>
<p>Ein Beispiel, das ich untersucht habe, war LinkedIn. Ihre veröffentlichten Zahlen von vor einem Jahr besagen, dass sie 13 Millionen Nachrichten pro Sekunde verarbeiten können, oder 2,7 Gigabyte pro Sekunde. Sie geben an, dass sie etwa 1.100 Kafka-Broker und mehr als 60 in einem Cluster haben, das ist eine ziemlich große Konfiguration.</p>
<h2>Automobilraum</h2>
<p>Wenn ich mir die rohen Zahlen des Kunden anschaue (1,6 Millionen Nachrichten pro Sekunde und 800 Gigabyte pro Sekunde) und sie mit LinkedIn vergleiche, das wahrscheinlich nicht für 240 Kilobyte optimiert ist, komme ich auf 44.000 Broker. Wenn ich es optimiere, könnte ich wahrscheinlich auf 4.400 Broker kommen, was immer noch 240 Cluster sind. Das ist eine riesige Anzahl von Maschinen, also musste ich mir überlegen, wie ich die Dinge schneller machen kann. Mit noch mehr Optimierung könnte ich wahrscheinlich auf 400 bis 500 Broker kommen, aber ich wollte sehen, was noch möglich ist.</p>
<h2>Intel Optane DC Persistent Memory</h2>
<p>Ich habe nach unserem Optane Persistent Memory geschaut. Es passt in ein DDR4-Format und sitzt somit direkt am DDR4-Bus. Es gibt Module mit bis zu 512 Gigabyte, sodass ich in einem Zwei-Sockel-Server sechs Terabyte an persistentem Speicher haben kann. Ich wollte eine Möglichkeit finden, diese äußerst zuverlässige Technologie mit großartigen Funktionen wie der integrierten Hardwareverschlüsselung zu nutzen, um mir bei der Lösung dieses Problems zu helfen.</p>
<h2>Unterstützung für eine Vielzahl von Anwendungen</h2>
<p>Es gibt zwei Betriebsmodi für diese Optane Memory: der direkte App-Modus und der Speichermodus. Der Speichermodus ist einfach. Es verwendet den persistenten Speicher als normalen RAM, da er günstiger ist als normaler DDR4. Es ist zwar nicht dasselbe wie DDR4, aber es ist nah genug dran, dass man in den meisten Anwendungen keinen Unterschied sieht. Im Direktmodus der App können Sie tatsächlich direkt aus Ihrem Programm in den persistenten Speicher schreiben. Auf diese Weise muss ich Datenstrukturen nicht mehr manuell umwandeln und streamen; ich kann sie einfach in den persistenten Speicher schieben. Ich kann den Direktmodus der App auch als Dateisystem mounten, so dass er auf dem Speicherbus liegt, was viel schneller ist als auf dem IO-Bus. Nun, was kann ich mit diesem Speicher tun?</p>
<h2>Verwendung des Linux-Kernels</h2>
<p>Es gibt zwei Hauptwerkzeuge, die mit dem Linux-Kernel verwendet werden können: ndctl und ipmctl. Ndctl ist ein nichtflüchtiger Speichergeräte-Controller, und dann gibt es IPM, den Intel Persistent Memory Controller, mit dem ich diesen persistenten Speicher manipulieren und kontrollieren kann. Ich kann ihn im Memory-Modus oder im App-Direct-Modus einrichten. Ich musste ein bisschen über diese Werkzeuge und wie sie funktionieren lernen.</p>
<h2>Ansatz der Aufnahme</h2>
<p>Mein erster Gedanke war, dass, wenn ich Kafka mehr Speicher mit großen Puffergrößen gebe, es viel schneller laufen sollte. Code-Änderungen in der Konfiguration wären unnötig oder minimal. Eine weitere Option bestand darin, Kafka so zu ändern, dass es in persistenten Speicher schreibt, anstatt auf ein Dateisystem zu schreiben, wodurch die Festplatte umgangen wird. Das letzte, worauf ich geachtet habe, war die Erstellung eines persistenten Dateisystems mit persistentem Speicher und dann das Platzieren der Kafka-Logs auf diesem neuen Dateisystem.</p>
<p>Die einfachste der drei Optionen war die erste – mehr Speicher. Ich habe alle meine Aufgaben mit mehr Speicher ausgeführt, aber es gab keine Veränderung in der Leistung. Der Grund dafür ist, dass letztendlich meine Puffer gefüllt wurden und ich auf ein Laufwerk auslagern musste. Letztendlich musste alles in die Kafka-Logs, was mein Engpass war.</p>
<p>Die zweite Option beinhaltet das Umschreiben des Codes und das Warten auf Genehmigungen, also bin ich zur dritten Option übergegangen. Die Ergebnisse dieses Experiments, bei dem ich die Logs auf dieses neue, ultraschnelle Dateisystem gezeigt habe, waren faszinierend. Schauen wir uns den Prozess und die Ergebnisse an.</p>
<h2>Testeinschränkungen</h2>
<p>Um Hindernisse für die Leistungstestung zu beseitigen, habe ich das Netzwerk außer Acht gelassen, indem ich meinen Test auf derselben Maschine durchgeführt habe, auf der sich mein Broker befand. Außerdem habe ich zunächst nur Produzenten, dann nur Verbraucher und danach gemischte Tests durchgeführt, um die Unterschiede abschätzen zu können. Mein Ziel war es nicht, eine Gesamtverbesserung der Produktion zu betrachten, sondern herauszufinden, ob dies einen wirklichen Unterschied für einen einzelnen Broker macht.</p>
<h2>Erster Ansatz 50/50</h2>
<p>Das erste, was ich gemacht habe, war, die Hälfte meines persistenten Speichers in den App-Direct-Modus zu versetzen und es in ein Dateisystem umzuwandeln. Die andere Hälfte ließ ich als Speicher. Ich habe die Befehle &quot;ndctl&quot; und &quot;ipmctl&quot; verwendet und Namensräume erstellt. Diese Dateisysteme habe ich eingebunden und meinen Test ausgeführt.</p>
<h2>Ändern der Nachrichtengröße</h2>
<p>Ich habe die Tests für verschiedene Nachrichtengrößen durchgeführt. Ich habe eine bestimmte Optimierung erwartet, vor allem für 1 Kilobyte. Ich habe festgestellt, dass die Leistung bis zu etwa 10 Produzenten immer besser wurde. Ab dem Zeitpunkt, an dem ich mehr als 10 Produzenten hatte, wurde der Bus gesättigt und es traten einige Schwankungen auf. Das sagt mir, dass ich etwas zwischengespeichert habe. Ich kann nun diese Zahlen mit dem vergleichen, was ich zuvor nur auf einer SATA-Festplatte für die Kafka-Protokolle getestet habe. Ich habe auch unsere Optane-NVMe-Laufwerke für die Protokolle ausprobiert.</p>
<h2>Technologievergleich</h2>
<p>Lassen Sie uns einen Blick auf die Unterschiede werfen. Bei 240 Kilobyte ist es mit einer normalen SATA-Festplatte ziemlich flach. Ich habe eine Verbesserung festgestellt, und dann nahm sie ab, als die Anzahl der Produzenten zunahm. Mit der Optane NVMe-Festplatte habe ich einen schönen Höhepunkt erreicht, fast doppelt so schnell wie eine SATA-Festplatte, was ich erwartet habe, denn es handelt sich um einen NVMe-Bus anstelle eines SATA-Busses. Der Pmem ist fast fünfmal schneller als eine SATA-Festplatte und zweieinhalbmal schneller als die Optane NVMe-Festplatte. Das liegt daran, dass ich einen Speicherbus anstelle des SATA- oder NVMe-Busses verwende.</p>
<h2>Zusätzliche Optimierung (100% App Direkt)</h2>
<p>Dies lief schnell und ich habe diesen temporären 750 GB-Laufwerk schnell gefüllt. Da ich den Test noch ein wenig länger durchführen musste, bin ich zurückgegangen und habe meine Maschine so umkonfiguriert, dass sie den 100-prozentigen Direktanwendungsmodus verwendet, um jetzt die gesamten 1,5 Terabyte nutzen zu können.</p>
<h2>Optimiertes PMEM und 100% App Direct.</h2>
<p>Nachdem ich dies getan habe und dieselben Tests durchgeführt habe, habe ich ein überraschendes Ergebnis erhalten. Ich konnte mehr Produzenten hinzufügen, und meine Durchsatzrate stieg um fast das Zwei- oder Dreifache. Nun ist sie zwischen 12 und 15 Mal schneller als eine SATA-Festplatte mit 25-30 Produzenten und einer Nachrichtengröße von 240 Kilobytes. Das ist unglaublich und würde den Bedarf meiner Kunden an so vielen Brokern, Reihen und Reihen von Maschinen erheblich reduzieren. Ich habe den Test mehrmals durchgeführt, weil ich den Ergebnissen nicht glauben wollte. Ich habe einen unserer Architekten, der diese Technologie entworfen hat, angerufen und gelernt, dass einer der Gründe für die erhöhte Geschwindigkeit darin liegt, dass bei der Verwendung eines Teils des persistenten Speichers als Arbeitsspeicher die Daten durch zwei oder drei Hops gehen mussten, die im App-Direct-Modus nicht erforderlich sind. Dadurch wird die Konfliktmenge auf der Speicherleitung verringert, und die Durchsatzrate stieg dramatisch an.</p>
<h2>Aufruf zur Aktion</h2>
<p>Das Endergebnis ist, dass ich in der Lage war, Kafka mit Optane DC Persistent Memory als ultraschnelles Dateisystem zu verwenden, um erhebliche Verbesserungen der Durchsatzrate sowohl bei Produzenten als auch bei Konsumenten zu erzielen. Ein einzelner Broker kann jetzt 15-mal mehr Nachrichten und Durchsatz verarbeiten als zuvor, wodurch die Anzahl der für komplexe Systemarchitekturen benötigten Server verringert wird. Es ist an der Zeit, Ihre aktuelle Architektur zu überprüfen und zu sehen, ob dies Ihrem Unternehmen zugutekommen würde.</p>

        </div>
    </div>
    <div class="sponsor-container" >
        <p> Thank you to our sponsors for supporting this episode!</p>
        <p> Please help support future episodes by visiting our sponsors.</p>
        <ol>
        
        </ol>
    </div>
</section>
<footer id="footer">
    <div class="footer-content">
        <p>Urheberrecht &copy; 2025 Paidar Productions LLC</p>
        <p>Alle Rechte vorbehalten</p>
    </div>
</footer>
<script>
    // year
    (function(){ var y=document.getElementById('y'); if(y){ y.textContent = new Date().getFullYear(); } })();

    // Guard for pages without nav
    const toggle = document.querySelector('.menu-toggle');
    const nav    = document.querySelector('nav#primary-nav');
    if (nav) {
        // Mobile: toggle .menu-open on <body>
        toggle?.addEventListener('click', () => {
            const open = document.body.classList.toggle('menu-open');
            toggle.setAttribute('aria-expanded', String(open));
        });

        // Dropdowns: tap/click + keyboard
        document.querySelectorAll('li.dropdown > a').forEach(link => {
            const li = link.parentElement;
            const submenu = li.querySelector('.dropdown-menu');

            link.addEventListener('click', (e) => {
                if (!submenu) return;
                e.preventDefault();

                // close others
                document.querySelectorAll('li.dropdown.open > a').forEach(a => {
                    if (a !== link) {
                        a.setAttribute('aria-expanded', 'false');
                        a.parentElement.classList.remove('open');
                    }
                });

                const isOpen = li.classList.toggle('open');
                link.setAttribute('aria-expanded', String(isOpen));
            });

            link.addEventListener('keydown', (e) => {
                if (e.key === 'ArrowDown') { e.preventDefault(); submenu?.querySelector('a')?.focus(); }
                if (e.key === 'Escape')    { li.classList.remove('open'); link.setAttribute('aria-expanded','false'); link.focus(); }
            });
        });

        // Close dropdowns on outside click
        document.addEventListener('click', (e) => {
            if (!e.target.closest('nav')) {
                document.querySelectorAll('li.dropdown.open > a').forEach(a => {
                    a.setAttribute('aria-expanded','false');
                    a.parentElement.classList.remove('open');
                });
            }
        });
    }
</script>

